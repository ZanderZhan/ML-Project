{
 "cells": [
  {
   "cell_type": "code",
   "id": "63b9e917-0237-4c71-b2ee-8cd73a7da58a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:28:24.527226Z",
     "start_time": "2025-10-24T09:28:20.907087Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "from torch.optim import AdamW\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "71b16d11-4ed0-48fa-bd73-86b6b0ff24bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:28:24.661246Z",
     "start_time": "2025-10-24T09:28:24.659537Z"
    }
   },
   "source": [
    "LABEL_NAMES = [\"bug\", \"enhancement\", \"question\"]\n",
    "NUM_LABELS = 3\n",
    "id2label = {0: \"bug\", 1: \"enhancement\", 2: \"question\"}\n",
    "label2id = {0: 0, 1: 1, 2: 2}\n",
    "batch_size = 4\n",
    "num_epochs = 4"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "0f9042b7-dabb-42fd-be1b-14914ae06f18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:28:24.686705Z",
     "start_time": "2025-10-24T09:28:24.667342Z"
    }
   },
   "source": [
    "# load data from preprocess dataset\n",
    "data_set = pd.read_csv('../dataset/preprocess/github-labels-top3-803k-0.1%.csv')\n",
    "\n",
    "# Split the data\n",
    "train_set, test_set = train_test_split(data_set, test_size=0.15, random_state=42, stratify=data_set['issue_label'])\n",
    "\n",
    "print(train_set.issue_label.value_counts())\n",
    "print(f\"Training set size (85% of 1%): {len(train_set)}\")\n",
    "print(f\"Test set size (15% of 1%): {len(test_set)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "issue_label\n",
      "0.0    341\n",
      "1.0    283\n",
      "2.0     59\n",
      "Name: count, dtype: int64\n",
      "Training set size (85% of 1%): 683\n",
      "Test set size (15% of 1%): 121\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "b65b2509",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:28:26.033534Z",
     "start_time": "2025-10-24T09:28:24.690820Z"
    }
   },
   "source": [
    "# tokenize `text` data using `BertTokenizer`\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    train_set.text.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(train_set['issue_label'].map(label2id).values, dtype=torch.long)\n",
    "\n",
    "encoded_data_test = tokenizer.batch_encode_plus(\n",
    "    test_set.text.values,\n",
    "    add_special_tokens=True,\n",
    "    return_attention_mask=True,\n",
    "    padding='longest',\n",
    "    truncation=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "input_ids_test = encoded_data_test['input_ids']\n",
    "attention_masks_test = encoded_data_test['attention_mask']\n",
    "labels_test = torch.tensor(test_set['issue_label'].map(label2id).values, dtype=torch.long)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "9bef8075-d5b6-4495-a0cd-dbe9e9dcbbe2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:28:26.377314Z",
     "start_time": "2025-10-24T09:28:26.374562Z"
    }
   },
   "source": [
    "print(type(input_ids_train),input_ids_train.shape,input_ids_train.dtype)\n",
    "print(type(attention_masks_test),attention_masks_test.shape,attention_masks_test.dtype)\n",
    "print(type(labels_train),labels_train.shape,labels_train.dtype)\n",
    "print(input_ids_train[:3])\n",
    "print(attention_masks_train[:3])\n",
    "print(labels_train[:3])\n",
    "print(input_ids_test[:3])\n",
    "print(attention_masks_test[:3])\n",
    "print(labels_test[:3])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([683, 512]) torch.int64\n",
      "<class 'torch.Tensor'> torch.Size([121, 512]) torch.int64\n",
      "<class 'torch.Tensor'> torch.Size([683]) torch.int64\n",
      "tensor([[  101,  2663,  4471,  ...,     0,     0,     0],\n",
      "        [  101, 18247,  4638,  ...,     0,     0,     0],\n",
      "        [  101,  5587, 28516,  ...,     0,     0,     0]])\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "tensor([1, 0, 1])\n",
      "tensor([[  101,  2070, 13109,  ...,     0,     0,     0],\n",
      "        [  101,  1996, 15882,  ...,     0,     0,     0],\n",
      "        [  101,  5587,  2000,  ...,     0,     0,     0]])\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "tensor([0, 0, 1])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "fc160e37-4507-4902-bc75-a77cac4ef590",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:28:26.391148Z",
     "start_time": "2025-10-24T09:28:26.386804Z"
    }
   },
   "source": [
    "#Create DataLoader for training/test\n",
    "# Create TensorDataset\n",
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_test = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
    "# Create DataLoader with random sampling\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    sampler=RandomSampler(dataset_train),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "    dataset_test,\n",
    "    sampler=RandomSampler(dataset_test),\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "# Display dataset info\n",
    "for i, batch in enumerate(dataloader_train):\n",
    "    print(f\"batch {i}: {[tensor.shape for tensor in batch]}\")\n",
    "    if i >= 2:  \n",
    "        break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0: [torch.Size([4, 512]), torch.Size([4, 512]), torch.Size([4])]\n",
      "batch 1: [torch.Size([4, 512]), torch.Size([4, 512]), torch.Size([4])]\n",
      "batch 2: [torch.Size([4, 512]), torch.Size([4, 512]), torch.Size([4])]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "30f8b97f-52e9-463b-8418-b31d563445f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:28:26.638024Z",
     "start_time": "2025-10-24T09:28:26.396250Z"
    }
   },
   "source": [
    "# set the Bert model\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "        \"google-bert/bert-base-uncased\",\n",
    "        num_labels=NUM_LABELS,\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False,\n",
    "    )\n",
    "    \n",
    "# Set label mappings\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "462fea51-3ef3-4cad-8570-5047c9b03bdb",
   "metadata": {},
   "source": [
    "Create AdamW optimizer"
   ]
  },
  {
   "cell_type": "code",
   "id": "43501b76-0495-4876-9ea9-66dd7e10f5a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:28:26.648059Z",
     "start_time": "2025-10-24T09:28:26.646044Z"
    }
   },
   "source": [
    "# Calculate total training steps\n",
    "total_steps = len(dataloader_train) * num_epochs\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-5,    # Learning rate\n",
    "    eps=1e-8,   # Epsilon to prevent division by zero\n",
    ")\n",
    "\n",
    "# Create linear scheduler with warmup\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,           # No warmup\n",
    "    num_training_steps=total_steps # Total training steps\n",
    ")\n",
    "\n",
    "print(f\"Total training steps: {total_steps}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training steps: 684\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "38f20f0d-6473-4254-86cb-97332276f182",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:28:26.656933Z",
     "start_time": "2025-10-24T09:28:26.654781Z"
    }
   },
   "source": [
    "def train_epoch(model, dataloader, optimizer, scheduler, epoch_num):\n",
    "    print(f\"\\n Starting Epoch {epoch_num} Training...\")\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # Progress bar\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch_num}\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=batch[0],\n",
    "            attention_mask=batch[1],\n",
    "            labels=batch[2]\n",
    "        )\n",
    "        \n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Update progress bar with loss only\n",
    "        progress_bar.set_postfix({\n",
    "            'batch_loss': f'{loss.item():.4f}',\n",
    "            'avg_loss': f'{total_loss/(progress_bar.n+1):.4f}'\n",
    "        })\n",
    "    \n",
    "    avg_train_loss = total_loss / len(dataloader)\n",
    "    \n",
    "    print(f\" Epoch {epoch_num} Training Completed\")\n",
    "    print(f\" Average Training Loss: {avg_train_loss:.4f}\")\n",
    "    \n",
    "    return avg_train_loss"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "5241f4e7-a494-4cc9-9ac0-294168a70125",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:28:26.663257Z",
     "start_time": "2025-10-24T09:28:26.661580Z"
    }
   },
   "source": [
    "def complete_training(model, train_dataloader, optimizer, scheduler, num_epochs):\n",
    "    print(\"Starting Complete Training...\")\n",
    "    train_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\n=== Epoch {epoch+1}/{num_epochs} ===\")\n",
    "        \n",
    "        # Training only\n",
    "        train_loss = train_epoch(model, train_dataloader, optimizer, scheduler, epoch+1)\n",
    "        train_losses.append(train_loss)\n",
    "    \n",
    "    print(f\"\\nTraining Completed! Total epochs: {num_epochs}\")\n",
    "    print(f\"  Final Training Loss: {train_losses[-1]:.4f}\")\n",
    "    \n",
    "    return train_losses"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "54513c9c-87da-4c2a-b6a6-a5cbdb3315ec",
   "metadata": {},
   "source": [
    "Evaluate model and compute micro-averaging metrics"
   ]
  },
  {
   "cell_type": "code",
   "id": "7750a2aa-2d3f-406d-9788-5833ba5b440f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:28:26.673573Z",
     "start_time": "2025-10-24T09:28:26.670092Z"
    }
   },
   "source": [
    "def evaluate_model(model, dataloader, label_names=None):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    print(\" Starting model evaluation...\")\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            # Unpack batch data\n",
    "            input_ids = batch[0]\n",
    "            attention_mask = batch[1]\n",
    "            labels = batch[2]\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            \n",
    "            # Get predictions\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            # Collect predictions and true labels\n",
    "            all_predictions.extend(predictions.numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    # Compute micro-averaging metrics\n",
    "    micro_precision, micro_recall, micro_f1, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_predictions, average='micro', zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Compute per-class metrics\n",
    "    per_class_precision, per_class_recall, per_class_f1, support = precision_recall_fscore_support(\n",
    "        all_labels, all_predictions, average=None, zero_division=0\n",
    "    )\n",
    "    \n",
    "    # Set default label names\n",
    "    if label_names is None:\n",
    "        label_names = [f'Label_{i}' for i in range(len(per_class_precision))]\n",
    "    \n",
    "    return {\n",
    "        'predictions': all_predictions,\n",
    "        'labels': all_labels,\n",
    "        'micro_metrics': {\n",
    "            'precision': micro_precision,\n",
    "            'recall': micro_recall,\n",
    "            'f1': micro_f1\n",
    "        },\n",
    "        'per_class_metrics': {\n",
    "            'precision': per_class_precision,\n",
    "            'recall': per_class_recall,\n",
    "            'f1': per_class_f1,\n",
    "            'support': support\n",
    "        },\n",
    "        'label_names': label_names\n",
    "    }"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "73fc138c-d91e-495b-9952-dda9ad85e065",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:28:26.909853Z",
     "start_time": "2025-10-24T09:28:26.907139Z"
    }
   },
   "source": [
    "def print_detailed_metrics(metrics, epoch_num=None, set_name=\"Test\"):\n",
    "    if epoch_num is not None:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\" Epoch {epoch_num} - {set_name} Set Detailed Metrics\")\n",
    "        print(f\"{'='*60}\")\n",
    "    else:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\" {set_name} Set Detailed Metrics\")\n",
    "        print(f\"{'='*50}\")\n",
    "    \n",
    "    micro_metrics = metrics['micro_metrics']\n",
    "    per_class_metrics = metrics['per_class_metrics']\n",
    "    label_names = metrics['label_names']\n",
    "    \n",
    "    # Print per-class metrics\n",
    "    print(\"\\n Per-Class Metrics:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Label':<15} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'Support':<10}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for i, label_name in enumerate(label_names):\n",
    "        print(f\"{label_name:<15} {per_class_metrics['precision'][i]:<10.4f} \"\n",
    "              f\"{per_class_metrics['recall'][i]:<10.4f} \"\n",
    "              f\"{per_class_metrics['f1'][i]:<10.4f} \"\n",
    "              f\"{per_class_metrics['support'][i]:<10}\")\n",
    "    \n",
    "    # Print global micro-averaging metrics\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'MICRO-AVG':<15} {micro_metrics['precision']:<10.4f} \"\n",
    "          f\"{micro_metrics['recall']:<10.4f} \"\n",
    "          f\"{micro_metrics['f1']:<10.4f} \"\n",
    "          f\"{np.sum(per_class_metrics['support']):<10}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n Global Micro-Averaging Metrics:\")\n",
    "    print(f\"   • Precision: {micro_metrics['precision']:.4f}\")\n",
    "    print(f\"   • Recall:    {micro_metrics['recall']:.4f}\")\n",
    "    print(f\"   • F1-Score:  {micro_metrics['f1']:.4f}\")\n"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "13793ba4-fbeb-447f-af60-e67d223ed612",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:54:18.508325Z",
     "start_time": "2025-10-24T09:28:26.915505Z"
    }
   },
   "source": [
    "# Complete training \n",
    "print(\"=== TRAINING PHASE ===\")\n",
    "train_losses = complete_training(\n",
    "    model=model,\n",
    "    train_dataloader=dataloader_train,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=num_epochs\n",
    ")\n",
    "\n",
    "# Test after training\n",
    "print(\"\\n Starting Final Test...\")\n",
    "metrics = evaluate_model(model, dataloader_test, LABEL_NAMES)\n",
    "print_detailed_metrics(metrics, set_name=\"Final Test\")\n",
    "\n",
    "model.save_pretrained('./trained_bert_model')\n",
    "print(\"\\n Model saved to './trained_bert_model'\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAINING PHASE ===\n",
      "Starting Complete Training...\n",
      "\n",
      "=== Epoch 1/4 ===\n",
      "\n",
      " Starting Epoch 1 Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 171/171 [06:21<00:00,  2.23s/it, batch_loss=1.0302, avg_loss=0.8681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 1 Training Completed\n",
      " Average Training Loss: 0.8681\n",
      "\n",
      "=== Epoch 2/4 ===\n",
      "\n",
      " Starting Epoch 2 Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 171/171 [05:34<00:00,  1.96s/it, batch_loss=0.2624, avg_loss=0.6312]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 2 Training Completed\n",
      " Average Training Loss: 0.6312\n",
      "\n",
      "=== Epoch 3/4 ===\n",
      "\n",
      " Starting Epoch 3 Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 171/171 [05:46<00:00,  2.03s/it, batch_loss=0.2737, avg_loss=0.4668]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 3 Training Completed\n",
      " Average Training Loss: 0.4668\n",
      "\n",
      "=== Epoch 4/4 ===\n",
      "\n",
      " Starting Epoch 4 Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 171/171 [07:56<00:00,  2.79s/it, batch_loss=0.0645, avg_loss=0.3726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 4 Training Completed\n",
      " Average Training Loss: 0.3726\n",
      "\n",
      "Training Completed! Total epochs: 4\n",
      "  Final Training Loss: 0.3726\n",
      "\n",
      " Starting Final Test...\n",
      " Starting model evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 31/31 [00:11<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " Final Test Set Detailed Metrics\n",
      "==================================================\n",
      "\n",
      " Per-Class Metrics:\n",
      "--------------------------------------------------\n",
      "Label           Precision  Recall     F1-Score   Support   \n",
      "--------------------------------------------------\n",
      "bug             0.7812     0.8197     0.8000     61        \n",
      "enhancement     0.7193     0.8200     0.7664     50        \n",
      "question        0.0000     0.0000     0.0000     10        \n",
      "--------------------------------------------------\n",
      "MICRO-AVG       0.7521     0.7521     0.7521     121       \n",
      "\n",
      " Global Micro-Averaging Metrics:\n",
      "   • Precision: 0.7521\n",
      "   • Recall:    0.7521\n",
      "   • F1-Score:  0.7521\n",
      "\n",
      " Model saved to './trained_bert_model'\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "125df242-5308-4013-b54b-f72a88e0c0ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T09:54:18.572501Z",
     "start_time": "2025-10-24T09:54:18.571144Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
