{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import files and Initialization",
   "id": "95ca9c98485acebf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T23:06:04.690237Z",
     "start_time": "2025-10-14T23:05:59.796423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_dataset_file_name = 'github-labels-top3-803k-train'\n",
    "train_dataset = pd.read_csv(f'../dataset/raw/{train_dataset_file_name}.csv')\n",
    "\n",
    "output_path = '../dataset/preprocess'\n",
    "\n",
    "print('train dataset counts:')\n",
    "print(train_dataset.count())"
   ],
   "id": "863795a2e5629921",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset counts:\n",
      "Unnamed: 0                  722899\n",
      "issue_url                   722899\n",
      "issue_label                 722899\n",
      "issue_created_at            722899\n",
      "issue_author_association    722899\n",
      "repository_url              722899\n",
      "issue_title                 722899\n",
      "issue_body                  651027\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## start processing the training data\n",
    "\n",
    "#### Step1: drop rows with empty/NAN in `issue_body`/`issue_title`"
   ],
   "id": "cad077ad023aace8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T23:06:05.115621Z",
     "start_time": "2025-10-14T23:06:04.693228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# empty_issue_body_data = train_dataset[train_dataset.issue_body.str.strip() == '']\n",
    "# print(empty_issue_body_data)\n",
    "train_dataset = train_dataset.dropna(subset=['issue_title', 'issue_body'])\n",
    "train_dataset = train_dataset[train_dataset.issue_body.str.strip() != '']\n",
    "\n",
    "print(train_dataset.count())"
   ],
   "id": "8400603bb40ade52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                  650659\n",
      "issue_url                   650659\n",
      "issue_label                 650659\n",
      "issue_created_at            650659\n",
      "issue_author_association    650659\n",
      "repository_url              650659\n",
      "issue_title                 650659\n",
      "issue_body                  650659\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Step2: drop rows which label is not in [bug, enhancement, question]",
   "id": "531c27f0d0c1e7ab"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T23:06:05.232983Z",
     "start_time": "2025-10-14T23:06:05.122362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "labels = ['bug', 'enhancement', 'question']\n",
    "\n",
    "# label_not_include_data = train_dataset[~train_dataset.issue_label.isin(labels)]\n",
    "# print(label_not_include_data)\n",
    "train_dataset = train_dataset[train_dataset.issue_label.isin(labels)]\n",
    "\n",
    "print(train_dataset.count())"
   ],
   "id": "28777b5ad2695b3d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                  650659\n",
      "issue_url                   650659\n",
      "issue_label                 650659\n",
      "issue_created_at            650659\n",
      "issue_author_association    650659\n",
      "repository_url              650659\n",
      "issue_title                 650659\n",
      "issue_body                  650659\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Step3: concatenate `issue_title` and `issue_body` into one metadata: `issue_data`.",
   "id": "cca0d105a9daed0e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T23:06:05.582272Z",
     "start_time": "2025-10-14T23:06:05.239298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset['issue_data'] = train_dataset.issue_title + \" \" + train_dataset.issue_body\n",
    "# print(raw_data_set.count())\n",
    "train_dataset = train_dataset.drop('issue_title', axis=1)\n",
    "train_dataset = train_dataset.drop('issue_body', axis=1)\n",
    "\n",
    "print(train_dataset.count())"
   ],
   "id": "185d2c76f6176075",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                  650659\n",
      "issue_url                   650659\n",
      "issue_label                 650659\n",
      "issue_created_at            650659\n",
      "issue_author_association    650659\n",
      "repository_url              650659\n",
      "issue_data                  650659\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Step4: replace tabs and breaks in the `issue_data` with `spaces`, then remove repeating whitespaces",
   "id": "788edc8944e3129d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T23:06:15.054414Z",
     "start_time": "2025-10-14T23:06:05.599034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset.issue_data = train_dataset.issue_data.replace(r'[\\t\\n\\r ]+', ' ', regex=True)\n",
    "\n",
    "print(train_dataset.issue_data.values[:1])"
   ],
   "id": "17cca365e5460a69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Welcome screen on every editor window is very tedious I just discovered Gitlens and find the functionality useful, thank you to all who contribute. I have about a dozen editor windows open, and the install process added a Gitlens welcome tab to each and every one of them. Combined with the snowflake effect, all of the sudden VScode was consuming 300-400% cpu and my fan was raging, as soon as I hunted them all down everything was back to fine. The welcome note content is great (although putting it on _all_ the windows is a bit much, don't know how much control you have on that). But overall it was a bit of a sour first-use experience, just wanted to provide that feedback.\"]\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Step5: split the data into training, validation and test\n",
    "\n",
    "1. 85% training data, in which 15% is validation data\n",
    "2. 15% test data"
   ],
   "id": "60efcb51d9a42500"
  },
  {
   "cell_type": "code",
   "id": "3101a70b22f4a431",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T23:06:24.121802Z",
     "start_time": "2025-10-14T23:06:15.068621Z"
    }
   },
   "source": [
    "train, test = train_test_split(train_dataset, test_size=0.15, random_state=42)\n",
    "train, validation = train_test_split(train, test_size=0.15, random_state=42)\n",
    "\n",
    "def write_data(data_frame, suffix):\n",
    "    data_counts = data_frame.issue_data.size\n",
    "    data_name = f'{output_path}/github-labels-{int(data_counts / 1000)}k-{suffix}.csv'\n",
    "    data_frame.to_csv(data_name)\n",
    "    print(f'write file: {data_name}')\n",
    "\n",
    "# write the whole precessed data\n",
    "write_data(train_dataset, 'all')\n",
    "\n",
    "# write the split data\n",
    "write_data(train, 'train')\n",
    "write_data(validation, 'validation')\n",
    "write_data(test, 'test')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write file: ../dataset/preprocess/github-labels-650k-all.csv\n",
      "write file: ../dataset/preprocess/github-labels-470k-train.csv\n",
      "write file: ../dataset/preprocess/github-labels-82k-validation.csv\n",
      "write file: ../dataset/preprocess/github-labels-97k-test.csv\n"
     ]
    }
   ],
   "execution_count": 43
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
