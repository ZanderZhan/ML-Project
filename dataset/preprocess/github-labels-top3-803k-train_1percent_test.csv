Unnamed: 0.1,Unnamed: 0,issue_url,issue_label,issue_created_at,issue_author_association,repository_url,issue_data
470988,523456,https://api.github.com/repos/traefik/yaegi/issues/1063,bug,2021-03-24T15:17:19Z,MEMBER,https://api.github.com/repos/traefik/yaegi,"Interface embedding error The following program `sample.go` triggers a panic: ```go package main type Error interface { error Message() string } type T struct { Msg string } func (t *T) Error() string { return t.Msg } func (t *T) Message() string { return ""message:"" + t.Msg } func newError() Error { return &T{""test""} } func main() { e := newError() println(e.Error()) } ``` Expected result: ```console $ go run ./sample.go test ``` Got: ```console $ yaegi ./sample.go run: ./sample.go:15:25: CFG post-order panic: runtime error: invalid memory address or nil pointer dereference goroutine 1 [running]: runtime/debug.Stack(0x1, 0x14000186e00, 0x40) /Users/marc/sdk/go1.16.2/src/runtime/debug/stack.go:24 +0x88 github.com/traefik/yaegi/interp.(*Interpreter).eval.func1(0x140001c5c40) /Users/marc/go/src/github.com/traefik/yaegi2/interp/interp.go:491 +0x94 panic(0x103949c20, 0x14000122db0) /Users/marc/sdk/go1.16.2/src/runtime/panic.go:965 +0x14c github.com/traefik/yaegi/interp.(*Interpreter).cfg.func2.1(0x14000482900) /Users/marc/go/src/github.com/traefik/yaegi2/interp/cfg.go:468 +0x9c panic(0x1038b08e0, 0x103e36a10) /Users/marc/sdk/go1.16.2/src/runtime/panic.go:965 +0x14c github.com/traefik/yaegi/interp.(*itype).methods.func1(0x14000196540, 0x140001c49f0) /Users/marc/go/src/github.com/traefik/yaegi2/interp/type.go:1069 +0x334 github.com/traefik/yaegi/interp.(*itype).methods.func1(0x140001977a0, 0x1400041b980) /Users/marc/go/src/github.com/traefik/yaegi2/interp/type.go:1062 +0x7c8 github.com/traefik/yaegi/interp.(*itype).methods(0x140001977a0, 0x1400041b980) /Users/marc/go/src/github.com/traefik/yaegi2/interp/type.go:1102 +0x98 github.com/traefik/yaegi/interp.(*itype).equals(0x14000485420, 0x140001977a0, 0x1) /Users/marc/go/src/github.com/traefik/yaegi2/interp/type.go:1017 +0xe0 github.com/traefik/yaegi/interp.(*itype).assignableTo(0x14000485420, 0x140001977a0, 0x14000482700) /Users/marc/go/src/github.com/traefik/yaegi2/interp/type.go:956 +0x38 github.com/traefik/yaegi/interp.(*Interpreter).cfg.func2(0x14000482900) /Users/marc/go/src/github.com/traefik/yaegi2/interp/cfg.go:1437 +0x4468 github.com/traefik/yaegi/interp.(*node).Walk(0x14000482900, 0x140001c5ab0, 0x140001c5a80) /Users/marc/go/src/github.com/traefik/yaegi2/interp/interp.go:231 +0xa0 github.com/traefik/yaegi/interp.(*node).Walk(0x14000482800, 0x140001c5ab0, 0x140001c5a80) /Users/marc/go/src/github.com/traefik/yaegi2/interp/interp.go:228 +0x5c github.com/traefik/yaegi/interp.(*node).Walk(0x14000482000, 0x140001c5ab0, 0x140001c5a80) /Users/marc/go/src/github.com/traefik/yaegi2/interp/interp.go:228 +0x5c github.com/traefik/yaegi/interp.(*node).Walk(0x1400014c400, 0x140001c5ab0, 0x140001c5a80) /Users/marc/go/src/github.com/traefik/yaegi2/interp/interp.go:228 +0x5c github.com/traefik/yaegi/interp.(*Interpreter).cfg(0x1400037c000, 0x1400014c400, 0x14000378808, 0x4, 0x14000378808, 0x4, 0x0, 0x0, 0x1400014c400) /Users/marc/go/src/github.com/traefik/yaegi2/interp/cfg.go:63 +0x16c github.com/traefik/yaegi/interp.(*Interpreter).eval(0x1400037c000, 0x140001903c0, 0x12c, 0x16cfaf8c8, 0x16, 0x0, 0x0, 0x0, 0x0, 0x0, ...) /Users/marc/go/src/github.com/traefik/yaegi2/interp/interp.go:518 +0x21c github.com/traefik/yaegi/interp.(*Interpreter).EvalPath(0x1400037c000, 0x16cfaf8c8, 0x16, 0x14000190200, 0x12c, 0x0, 0x0, 0x1036793b0) /Users/marc/go/src/github.com/traefik/yaegi2/interp/interp.go:405 +0xc4 main.runFile(0x1400037c000, 0x16cfaf8c8, 0x16, 0x1, 0x1) /Users/marc/go/src/github.com/traefik/yaegi2/cmd/yaegi/run.go:123 +0x84 main.run(0x14000138010, 0x1, 0x1, 0x14000106180, 0x1400006fea8) /Users/marc/go/src/github.com/traefik/yaegi2/cmd/yaegi/run.go:89 +0x724 main.main() /Users/marc/go/src/github.com/traefik/yaegi2/cmd/yaegi/yaegi.go:144 +0x324 ``` "
259215,288292,https://api.github.com/repos/cp-api/cap3/issues/39,enhancement,2021-01-04T12:50:32Z,NONE,https://api.github.com/repos/cp-api/cap3,Provide build models for basic viewpoints Initial submission. `ECLIPSE-555281` `POLARSYS-566` `christophe.gatti` `2015-10-13` `0.8.3`
521561,579669,https://api.github.com/repos/HFulcher/gapipy/issues/11,bug,2020-07-28T06:41:00Z,OWNER,https://api.github.com/repos/HFulcher/gapipy,_authenticate_service() will fail at RunTimeWarning rather than continuing **Describe the bug** When `_authenticate_service()` does not find a .env file a RunTime Warning is raised that terminates execution rather than allowing the method to continue and look in the environment. **To Reproduce** Steps to reproduce the behavior: 1. Run `client.authenticate()` **Expected behavior** A RunTime Warning should be raised but execution should continue and check for environment variables. If these don't exist then a ValueError would be raised. 
48270,53711,https://api.github.com/repos/rectorphp/rector/issues/5906,bug,2021-03-19T06:02:04Z,CONTRIBUTOR,https://api.github.com/repos/rectorphp/rector,"is_a() usage in the codebase Hi, I see many instances of `is_a()` usages in the codebase. It's not compatible with static reflection as it needs the classes loaded in runtime. It's fine when you ask about stuff that's already loaded (like PhpParser nodes, PHPStan classes, phpdoc-parser classes), but it shouldn't be used for analysed code."
657759,731127,https://api.github.com/repos/lsolano/ProtoPrimitives.NET/issues/1,bug,2021-05-13T21:54:23Z,OWNER,https://api.github.com/repos/lsolano/ProtoPrimitives.NET,"`ConfigurableString` fails with same value for Min and Max length. Adding the following tests to `StringLengthRange` and `ConfigurableString`, respectively both fail because of a bug in `StringLengthRange` constructor. * Test 1 for `StringLengthRange` constructor. ``` [TestFixture] internal sealed class ConstructorMessage { [Test] public void Accepts_Same_Value_For_Min_And_Max() { (StringLength min, StringLength max) = (new StringLength(11), new StringLength(11)); Assert.That(() => new StringLengthRange(min, max), Throws.Nothing); } } ``` _Fails with the following details:_ ``` Failed Accepts_Same_Value_For_Min_And_Max [23 ms] Error Message: Expected: No Exception to be thrown But was: <System.ArgumentOutOfRangeException: min must be less than or equals to (<=) max (11). (Parameter 'min') Actual value was 11. at Triplex.Validations.Utilities.ComparableRange-1.CheckUpperBoundary(TComparable& value, String& paramName, String& customMessage) at Triplex.Validations.Utilities.ComparableRange-1.IsWithin(TComparable& value, String& paramName, String& customMessage) at Triplex.Validations.ArgumentsHelpers.OutOfRangeChecks.CheckBoundaries[TComparable](TComparable& value, ComparableRange-1& range, String& paramName, String& customMessage) at Triplex.Validations.ArgumentsHelpers.OutOfRangeChecks.LessThan[TComparable](TComparable& value, TComparable& other, String& paramName, String& customMessage) at Triplex.Validations.Arguments.LessThan[TComparable](TComparable& value, TComparable& other, String& paramName, String& customMessage) at Triplex.ProtoDomainPrimitives.Numerics.StringLengthRange.Validate(StringLength& min, StringLength& max) in ~/src/main/cs/ProtoPrimitives.NET/Numerics/StringLengthRange.cs:line 38 at Triplex.ProtoDomainPrimitives.Numerics.StringLengthRange..ctor(StringLength& min, StringLength& max) in ~/src/main/cs/ProtoPrimitives.NET/Numerics/StringLengthRange.cs:line 19 at Triplex.ProtoDomainPrimitives.Tests.Numerics.StringLengthRangeFacts.ConstructorMessage.<>c__DisplayClass0_0.<Accepts_Same_Value_For_Min_And_Max>b__0() in ~/src/test/cs/ProtoPrimitives.NET.Tests/Numerics/StringLengthRangeFacts.cs:line 20 --- End of stack trace from previous location --- at NUnit.Framework.Internal.ExceptionHelper.Rethrow(Exception exception) at NUnit.Framework.Internal.Reflect.DynamicInvokeWithTransparentExceptions(Delegate delegate) at NUnit.Framework.Internal.ExceptionHelper.RecordException(Delegate parameterlessDelegate, String parameterName)> Stack Trace: at Triplex.ProtoDomainPrimitives.Tests.Numerics.StringLengthRangeFacts.ConstructorMessage.Accepts_Same_Value_For_Min_And_Max() in ~/src/test/cs/ProtoPrimitives.NET.Tests/Numerics/StringLengthRangeFacts.cs:line 20 ``` * Test 2 for `ConfigurableString` builder. Changing actual `Triplex.ProtoDomainPrimitives.Tests.Strings.ConfigurableStringFacts.Builder.WithLengthRangeMessage.With_Valid_LengthRange_Throws_Nothing()` ``` [TestCase(0, 4)] [TestCase(1, 4)] [TestCase(3, 4)] [TestCase(4, 4)] public void With_Valid_LengthRange_Throws_Nothing(int rawMin, int rawMax) { ConfigurableString.Builder builder = Create(_useSingleParamConstructor, _useSingleMessage); StringLengthRange range = new StringLengthRange(new StringLength(rawMin), new StringLength(rawMax)); Assert.That(() => builder.WithLengthRange(range, DefaultTooLongMessage, DefaultTooLongMessage), Throws.Nothing); } ``` _Fails with the following details:_ ``` Failed With_Valid_LengthRange_Throws_Nothing(4,4) [4 ms] Error Message: System.ArgumentOutOfRangeException : min must be less than or equals to (<=) max (4). (Parameter 'min') Actual value was 4. Stack Trace: at Triplex.Validations.Utilities.ComparableRange`1.CheckUpperBoundary(TComparable& value, String& paramName, String& customMessage) at Triplex.Validations.Utilities.ComparableRange`1.IsWithin(TComparable& value, String& paramName, String& customMessage) at Triplex.Validations.ArgumentsHelpers.OutOfRangeChecks.CheckBoundaries[TComparable](TComparable& value, ComparableRange`1& range, String& paramName, String& customMessage) at Triplex.Validations.ArgumentsHelpers.OutOfRangeChecks.LessThan[TComparable](TComparable& value, TComparable& other, String& paramName, String& customMessage) at Triplex.Validations.Arguments.LessThan[TComparable](TComparable& value, TComparable& other, String& paramName, String& customMessage) at Triplex.ProtoDomainPrimitives.Numerics.StringLengthRange.Validate(StringLength& min, StringLength& max) in ~/src/main/cs/ProtoPrimitives.NET/Numerics/StringLengthRange.cs:line 38 at Triplex.ProtoDomainPrimitives.Numerics.StringLengthRange..ctor(StringLength& min, StringLength& max) in ~/src/main/cs/ProtoPrimitives.NET/Numerics/StringLengthRange.cs:line 19 at Triplex.ProtoDomainPrimitives.Tests.Strings.ConfigurableStringFacts.Builder.WithLengthRangeMessage.With_Valid_LengthRange_Throws_Nothing(Int32 rawMin, Int32 rawMax) in ~/src/test/cs/ProtoPrimitives.NET.Tests/Strings/ConfigurableStringFacts/Builder/WithLengthRangeMessage.cs:line 60 ```"
212234,235995,https://api.github.com/repos/gus33000/UUPMediaCreator/issues/9,bug,2021-01-19T20:56:53Z,OWNER,https://api.github.com/repos/gus33000/UUPMediaCreator,Some Dlls are missing from Windows PE for Desktop editions Dlls required by Panther are missing from the sources directory. The windows team keeps adding new dlls ever since mid Iron dev cycle...
524194,582584,https://api.github.com/repos/infinum/datx/issues/110,enhancement,2019-03-31T15:46:45Z,MEMBER,https://api.github.com/repos/infinum/datx,"Version 2 wishlist Since version 1 is almost done, and it took a little bit longer than expected, let's start a wishlist for version 2 - features that would be nice to have, but would be a breaking change: * [x] Remove `CompatModel` & `CompatCollection` * [x] Remove deprecated `find` and `remove` * [x] Remove `setupModel` * [x] JSON API - disallow numeric IDs * [x] Rename `params` to `queryParams.custom` * [x] Separate `IRequestOptions` into three parts - `queryParams`, `networkConfig`, `cacheOptions` * [x] #132 - Implement ""Buckets"" [INTERNAL] * [x] #103 - Polymorphic relationships * [x] #131 - Caching revamp * [x] #34 - `fetchAll` revamp * [x] [Write a migration guide, update docs](https://datx.dev/docs/next/migration-guide/from-v1) * [x] #172 - consistent response data * [x] #173 - endpoint fn with explicit baseurl * [x] #154 - Prop mapping * [x] #164 - Polymorphic dynamic model types * [x] #130 - Add model dirty states ---------- * [x] #133 - Query builder * [ ] #153 - Read-only props # Breaking changes This list is made based on the current state of the `release/v2` branch ## `id` and `type` fields In v1, those weren't consistent - in some cases `id` and `type` were used to define the model, but in some other cases they had to be defined separately. In v2, this will be consistent and it will need to be defined explicitly. ## Removed deprecated stuff `CompatCollection`, `CompatModel`, `collection.find`, `collection.remove`, `setupModel` ## Stricter action support In v1, some of the mutations have been automatically wrapped into actions. In v2 this is only done in some cases where multiple changes are being done (e.g. the `model.update()` method). This will be a breaking change if you're using the MobX strict mode ## Snapshot/patch format changes The serialised format of the model is a bit different, more specifically the meta object inside of it. ## References to missing models In v1, if a model had a reference to another model that is not in a collection, it would return the model id instead of the instance. In v2, such models will be skipped - this means that the reference value will always be either a model or an array of models. ## JSON API pagination The pagination is now using methods instead of just plain property access: `await response.next` becomes `await response.next()` ## Caching `config.cache` is no longer a boolean, but a `CachingStrategy` enum instead. `true` maps to `CachingStrategy.CACHE_FIRST` and `false` maps to `CachingStrategy.NETWORK_ONLY`. ## JSON API Collection caching The static `cache` property on the collection is no longer a boolean. It's a `CachingStrategy` enum instead, without any default value (the global fallback is used) ## Response data is `null` instead of `[]` when no data In v1, empty data would fall back to `[]` during response parsing, which is not technically correct. In v2, the response data value will be the same as the API response. ## Endpoint function base URL In v1, the return value of the endpoint function would be appended to the base url, which made some operations where a model has a different base url much harder. In v2, this is not done (it's still done when there is no endpoint or when it's a string) - instead, the endpoint function receives a baseurl parameter, and you are responsible of prepending it to your endpoint url. # Deprecations ## `@prop` attribute * `@prop` -> `@Attribute()` * `@prop.toMany(Foo)` -> `@Attribute({ toMany: Foo })` * etc. ## `fetch` and `fetchAll` Deprecated in favour of `getOne` and `getMany`. They use the new methods internally, but force caching strategies that were used in the old methods before, to keep the compatibility. # Major new stuff ## JSON API getOne/getMany `getOne` and `getMany` behave similarly to `fetch` and `fetchAll` but make use of better caching strategies. Caching options can be defined globally (config object), on the collection level and on the request level. The options contain a maxAge value in seconds and the caching strategy type. Available caching strategies are: ```typescript export enum CachingStrategy { NETWORK_ONLY, // Ignore cache NETWORK_FIRST, // Fallback to cache only on network error STALE_WHILE_REVALIDATE, // Use cache and update it in background CACHE_ONLY, // Fail if nothing in cache CACHE_FIRST, // Use cache if available STALE_AND_UPDATE, // Use cache and update response once network is complete } ``` ## JSON API Collection caching The collection has a new static `maxCacheAge` value that is the maximal age of the cache in seconds. The default value is `undefined` (fallback to the global value). The collection `toJSON` will now also serialise and hydrate the cache that was linked to that collection."
289316,321732,https://api.github.com/repos/cezariuli/fleet_mgmt_system/issues/15,enhancement,2020-12-12T16:19:19Z,OWNER,https://api.github.com/repos/cezariuli/fleet_mgmt_system,"[DB] Create additional columns for Vehicles table. Create additional columns for Vehicles table. These columns can be null and will be optional to be used in different contexts. - transmission type ( boolean or enum ) - body (hatchback, sedan, break, coupe etc. ) - odometer - power ( kW / HP ) - fuel_consumption ( aggregate type) - luggage - navigation ( yes / no ) - air_conditioner ( automatic / manual / no ) - no_of_passenger ( 1 + 4 ) - no_of_doors - co2_emission ( g/km) To be determined later: - max_speed - color Update vehicle schema."
402532,447414,https://api.github.com/repos/eccentricdevotion/TARDIS/issues/496,bug,2021-05-12T20:37:00Z,NONE,https://api.github.com/repos/eccentricdevotion/TARDIS,"TARDIS remote area command broken **Describe the bug** `/tardisremote <player> <argument> area` causes internal errors. **To Reproduce** 1. Just run `/tardisremote <player> <argument> area` **Log files** Paste your server log (_showing the whole server startup to when the error occurs_) on a website like pastebin.com, and post a link here. Even if there are no errors in the log, it still contains useful information for troubleshooting. ``` 12.05 22:35:35 [Server] INFO DalekCraft issued server command: /tremote DalekCraft travel area 12.05 22:35:35 [Server] ERROR null 12.05 22:35:35 [Server] INFO org.bukkit.command.CommandException: Unhandled exception executing command 'tremote' in plugin TARDIS v4.6.1-b2263 12.05 22:35:35 [Server] INFO at org.bukkit.command.PluginCommand.execute(PluginCommand.java:47) ~[patched_1.16.5.jar:git-Paper-""809466f2e""] 12.05 22:35:35 [Server] INFO at org.bukkit.command.SimpleCommandMap.dispatch(SimpleCommandMap.java:159) ~[patched_1.16.5.jar:git-Paper-""809466f2e""] 12.05 22:35:35 [Server] INFO at org.bukkit.craftbukkit.v1_16_R3.CraftServer.dispatchCommand(CraftServer.java:810) ~[patched_1.16.5.jar:git-Paper-""809466f2e""] 12.05 22:35:35 [Server] INFO at net.minecraft.server.v1_16_R3.PlayerConnection.handleCommand(PlayerConnection.java:2171) ~[patched_1.16.5.jar:git-Paper-""809466f2e""] 12.05 22:35:35 [Server] INFO at net.minecraft.server.v1_16_R3.PlayerConnection.c(PlayerConnection.java:1986) ~[patched_1.16.5.jar:git-Paper-""809466f2e""] 12.05 22:35:35 [Server] INFO at net.minecraft.server.v1_16_R3.PlayerConnection.a(PlayerConnection.java:1939) ~[patched_1.16.5.jar:git-Paper-""809466f2e""] 12.05 22:35:35 [Server] INFO at net.minecraft.server.v1_16_R3.PacketPlayInChat.a(PacketPlayInChat.java:50) ~[patched_1.16.5.jar:git-Paper-""809466f2e""] 12.05 22:35:35 [Server] INFO at net.minecraft.server.v1_16_R3.PacketPlayInChat.a(PacketPlayInChat.java:8) ~[patched_1.16.5.jar:git-Paper-""809466f2e""] 12.05 22:35:35 [Server] INFO at net.minecraft.server.v1_16_R3.PlayerConnectionUtils.lambda$ensureMainThread$1(PlayerConnectionUtils.java:35) ~[patched_1.16.5.jar:git-Paper-""809466f2e""] 12.05 22:35:35 [Server] INFO at net.minecraft.server.v1_16_R3.TickTask.run(SourceFile:18) ~[patched_1.16.5.jar:git-Paper-""809466f2e""] 12.05 22:35:35 [Server] INFO at net.minecraft.server.v1_16_R3.IAsyncTaskHandler.executeTask(IAsyncTaskHandler.java:136) ~[patched_1.16.5.jar:git-Paper-""809466f2e""] 12.05 22:35:35 [Server] INFO at net.minecraft.server.v1_16_R3.IAsyncTaskHandlerReentrant.executeTask(SourceFile:23) ~[patched_1.16.5.jar:git-Paper-""809466f2e""] 12.05 22:35:35 [Server] INFO at net.minecraft.server.v1_16_R3.IAsyncTaskHandler.executeNext(IAsyncTaskHandler.java:109) ~[patched_1.16.5.jar:git-Paper-""809466f2e""] 12.05 22:35:35 [Server] INFO at net.minecraft.server.v1_16_R3.MinecraftServer.bb(MinecraftServer.java:1262) ~[patched_1.16.5.jar:git-Paper-""809466f2e""] 12.05 22:35:35 [Server] INFO at net.minecraft.server.v1_16_R3.MinecraftServer.executeNext(MinecraftServer.java:1255) ~[patched_1.16.5.jar:git-Paper-""809466f2e""] 12.05 22:35:35 [Server] INFO at net.minecraft.server.v1_16_R3.IAsyncTaskHandler.awaitTasks(IAsyncTaskHandler.java:119) ~[patched_1.16.5.jar:git-Paper-""809466f2e""] 12.05 22:35:35 [Server] INFO at net.minecraft.server.v1_16_R3.MinecraftServer.sleepForTick(MinecraftServer.java:1216) ~[patched_1.16.5.jar:git-Paper-""809466f2e""] 12.05 22:35:35 [Server] INFO at net.minecraft.server.v1_16_R3.MinecraftServer.w(MinecraftServer.java:1130) ~[patched_1.16.5.jar:git-Paper-""809466f2e""] 12.05 22:35:35 [Server] INFO at net.minecraft.server.v1_16_R3.MinecraftServer.lambda$a$0(MinecraftServer.java:289) ~[patched_1.16.5.jar:git-Paper-""809466f2e""] 12.05 22:35:35 [Server] INFO at java.lang.Thread.run(Thread.java:834) [?:?] 12.05 22:35:35 [Server] INFO Caused by: java.lang.ArrayIndexOutOfBoundsException: Index 3 out of bounds for length 3 12.05 22:35:35 [Server] INFO at me.eccentric_nz.TARDIS.commands.remote.TARDISRemoteCommands.onCommand(TARDISRemoteCommands.java:212) ~[?:?] 12.05 22:35:35 [Server] INFO at org.bukkit.command.PluginCommand.execute(PluginCommand.java:45) ~[patched_1.16.5.jar:git-Paper-""809466f2e""] 12.05 22:35:35 [Server] INFO ... 19 more ``` **`/tardis version` output** Please include an output of your `/tardis version`. ``` 16:36:18.704 [16:36:18] [Render thread/INFO] [minecraft/NewChatGui]: [CHAT] [TARDIS] Server version: git-Paper-""809466f2e"" (MC: 1.16.5) 16:36:18.704 [16:36:18] [Render thread/INFO] [minecraft/NewChatGui]: [CHAT] [TARDIS] TARDIS version: 4.6.1-b2263 16:36:18.704 [16:36:18] [Render thread/INFO] [minecraft/NewChatGui]: [CHAT] [TARDIS] TARDISChunkGenerator version: 4.6.1 16:36:18.705 [16:36:18] [Render thread/INFO] [minecraft/NewChatGui]: [CHAT] [TARDIS] PlaceholderAPI version: 2.10.9 16:36:18.705 [16:36:18] [Render thread/INFO] [minecraft/NewChatGui]: [CHAT] [TARDIS] LibsDisguises version: 10.0.24 16:36:18.705 [16:36:18] [Render thread/INFO] [minecraft/NewChatGui]: [CHAT] [TARDIS] Essentials version: 2.18.2.0 16:36:18.711 [16:36:18] [Render thread/INFO] [minecraft/NewChatGui]: [CHAT] [TARDIS] WorldGuard version: 7.0.4+f7ff984 16:36:18.711 [16:36:18] [Render thread/INFO] [minecraft/NewChatGui]: [CHAT] [TARDIS] Multiverse-Core version: 4.2.2-b812 16:36:18.711 [16:36:18] [Render thread/INFO] [minecraft/NewChatGui]: [CHAT] [TARDIS] WorldBorder version: 2.1.1 16:36:18.711 [16:36:18] [Render thread/INFO] [minecraft/NewChatGui]: [CHAT] [TARDIS] Checking for new TARDIS builds... ```"
148060,164571,https://api.github.com/repos/microsoft/microsoft-ui-xaml/issues/3574,bug,2020-11-09T06:23:38Z,NONE,https://api.github.com/repos/microsoft/microsoft-ui-xaml,"WinUI Dekstop app crashes on Navigate to View from another Library I have created the application with Navigation View contains Frame. While try to navigate to the view from another library using Frame.Navigate method application get crash. If the view is inside the same library, Frame.Navigate works properly. ![image](https://user-images.githubusercontent.com/74045266/98506348-46453b80-2281-11eb-8c68-cb1ba4dff2a3.png) **Steps to reproduce the bug** 1. Run the attached sample 2. Application get crash on Frame.Navigate **Expected behavior** Application should not throw any exception **Version Info** WinUI NuGet package version - 3.0.0-preview2.200713.0, Windows app type - WinUI Desktop app, OS version(s) - 10.0.18362.1139 Sample: [FrameNavigation.zip](https://github.com/microsoft/microsoft-ui-xaml/files/5508445/FrameNavigation.zip) "
417246,463794,https://api.github.com/repos/johnfactotum/foliate/issues/727,enhancement,2021-05-13T04:34:03Z,NONE,https://api.github.com/repos/johnfactotum/foliate,"Persist TTS location when pausing **Is your feature request related to a problem? Please describe.** I want to be able to save the TTS location, like an audiobook. So if I'm on a page and pause it, when I restart it'll be on the same word as when I paused it. **Describe the solution you'd like** Cache the TTS location, and reload it when resuming. **Describe alternatives you've considered** There are none. "
653533,726467,https://api.github.com/repos/pocoproject/poco/issues/3202,bug,2021-02-06T10:28:50Z,MEMBER,https://api.github.com/repos/pocoproject/poco,"JWT: ESxxx signature must include padding for ECDSA R and S values The signature for JWTs using the ES256, ES384 and ES512 algorithms must include proper padding for R and S values from the ECDSA signature. Failing to apply padding will lead to incorrect signatures if R and S values don't take 32 bytes each. "
149562,166256,https://api.github.com/repos/zebrunner/android-device/issues/33,enhancement,2021-01-17T14:06:18Z,CONTRIBUTOR,https://api.github.com/repos/zebrunner/android-device,made automationName=uiautomator2 as default change logic and specify for Android versions 4-6 AUTOMATION_NAME='Appium' And by default use uiautomator2 so we can support new versions without regenerating container
527243,586008,https://api.github.com/repos/CuBoulder/express_mono/issues/790,bug,2021-01-04T18:28:48Z,COLLABORATOR,https://api.github.com/repos/CuBoulder/express_mono,Filter Tips page is viewable by anonymous users A compose tips page is public when you are logged out of a site just type /filter/tips at the end of a URL such as https://www.colorado.edu/webcentral/filter/tips I discovered this when working with a client on their site map ![filter tip](https://user-images.githubusercontent.com/16137919/103566864-fdc08d80-4e7f-11eb-99b8-a2de0f9159d6.JPG) 
678537,754111,https://api.github.com/repos/metanorma/stepmod2mn/issues/14,enhancement,2021-02-25T03:39:52Z,NONE,https://api.github.com/repos/metanorma/stepmod2mn,"Convert ""Annex D EXPRESS-G diagrams"" In `resource_docs/*/resource.xml` files each schema is provided with diagram information: e.g. ```xml <schema_diag> <express-g> <imgfile file=""schema_diagexpg1.xml"" title=""The schemas of this part of ISO 10303""/> </express-g> </schema_diag> ``` ```xml <schema name=""application_context_schema"" number=""10231"" version=""8"" number.supersedes=""8369""> <introduction> ... </introduction> <fund_cons> ... </fund_cons> <express-g> <imgfile file=""application_context_schemaexpg1.xml""/> <imgfile file=""application_context_schemaexpg2.xml""/> </express-g> </schema> ``` These get rendered into Annex D (check the `xsl/` dir): (see `iso-10303-smrl/reference-docs/N10480_SMRL_v8_rc5/data/resource_docs/fundamentals_of_product_description_and_support/sys/d_expg.htm`) <img width=""1258"" alt=""Screenshot 2021-02-25 at 11 37 02 AM"" src=""https://user-images.githubusercontent.com/11865/109099287-ca063380-775d-11eb-869b-70056f4ac274.png""> There is this boilerplate: > Annex D > (informative) > > EXPRESS-G diagrams > > The diagrams in this annex correspond to the EXPRESS schemas specified in this part of ISO 10303. The diagrams use the EXPRESS-G graphical notation for the EXPRESS language. EXPRESS-G is defined in ISO 10303-11. And in particular you see that this XML: ```xml <express-g> <imgfile file=""application_context_schemaexpg1.xml""/> <imgfile file=""application_context_schemaexpg2.xml""/> </express-g> ``` is now: <img width=""584"" alt=""Screenshot 2021-02-25 at 11 37 44 AM"" src=""https://user-images.githubusercontent.com/11865/109099328-e1452100-775d-11eb-8976-4670dee0e096.png""> And when you click into it it shows this: <img width=""753"" alt=""Screenshot 2021-02-25 at 11 37 52 AM"" src=""https://user-images.githubusercontent.com/11865/109099345-e73b0200-775d-11eb-8028-7474c73a7e3d.png""> Basically it should be converted into an ADoc snippet of: ```adoc [appendix,obligation=informative] == EXPRESS-G diagrams ... .EXPRESS-G diagram of the application_context_schema (1 of 2) image::application_context_schemaexpg1.svg[] .EXPRESS-G diagram of the application_context_schema (2 of 2) image::application_context_schemaexpg2.svg[] ... ``` "
524829,583303,https://api.github.com/repos/we-are-number-1/yumble/issues/275,bug,2021-04-08T00:56:15Z,COLLABORATOR,https://api.github.com/repos/we-are-number-1/yumble,"[BUG] Completed Sessions Never Removed *** ## Completed Sessions Never Removed #### Describe the bug: When a session is completed ie a game of yumble is completed, it is possible to still join the room. This is because the game is never removed from the activeGames map in `Games.js` This is a potential memory leak that could cause the server to crash if not dealt with. ## Bug Report Body: ### To Reproduce the bug: 1. Finish a game of yumble 2. Create a new tab and rejoin the same game with the same code The expected behaviour is that the lobby code should be invalid OR should take you to the results screen of the completed game Screenshots - If applicable, add screenshots to help explain your problem. ![image](https://user-images.githubusercontent.com/49135923/113952103-21bdb180-9869-11eb-95e4-b9d6b7c6d6e8.png) Here you can see a room that has been joined without the host, as the room has been joined after the game has been completed."
354967,394629,https://api.github.com/repos/racket/racket/issues/3073,bug,2020-03-19T00:13:06Z,CONTRIBUTOR,https://api.github.com/repos/racket/racket,"linkl-bundle-table contains linklet? but not linkl? The tests here pass on BC but fail on CS, because the `linkl-bundle-table` on CS does not contain any `linkl?` values: ``` #lang racket/base (require compiler/zo-parse compiler/zo-marshal compiler/decompile racket/linklet racket/port) (define (compiled-expression->zo compiled) (define-values (in out) (make-pipe)) (display compiled out) (close-output-port out) (define y (port->bytes in)) (close-input-port in) (zo-parse (open-input-bytes y))) (define stx #'0) (define zo (compiled-expression->zo (compile-syntax stx))) (define tbl (linkl-bundle-table (hash-ref (linkl-directory-table zo) '()))) (module+ test (require rackunit) (check-true (ormap linkl? (hash-values tbl))) (check-false (ormap linklet? (hash-values tbl)))) ``` EDIT to be clear: - both tests pass on the BC 7.6 release - the first test fails on the CS 7.6 release and `(hash-ref tbl 0 #f)` returns `#f` - both tests fail on a recent CS (b69c1208b) and `(linklet? (hash-ref tbl 0))`"
267402,297390,https://api.github.com/repos/EGC-Hueznar/decide/issues/216,enhancement,2021-01-09T16:33:54Z,COLLABORATOR,https://api.github.com/repos/EGC-Hueznar/decide,"CE-021: Diferenciación del tipo de votación en el censo Se necesita que se añade un atributo en el modelo de Censo que permita distinguir entre los tipos de votaciones que están implementadas en el módulo de Votaciones. Estas votaciones son: Votacion Binaria, Votacion, Votacion Múltiple, Votación Preferencia."
234905,261242,https://api.github.com/repos/rauenzi/BetterDiscordAddons/issues/326,bug,2021-01-11T02:32:17Z,NONE,https://api.github.com/repos/rauenzi/BetterDiscordAddons,"[Bug] AccountDetailsPlus doesn't work anything (from BD beta) **Which plugin/theme is this about?** AccountDetailsPlus v0.1.10 plugin **Describe the Bug** Doesn't work completely anything. **To Reproduce** Please note I am using the BD Beta version. none of the features of this plugin work. After deactivation, reactivation the plugin, and it throws an error on the console. **Expected Behavior** The functionality of this plugin (typically the UserPopup and nickname indicator) should work properly. **Screenshots** ![capture](https://user-images.githubusercontent.com/36400787/104142810-76839480-5400-11eb-9e96-d33dc4e62d27.PNG) ![capture](https://user-images.githubusercontent.com/36400787/104142935-f7db2700-5400-11eb-9d68-c5f0183d7108.PNG) **Discord Version** Stable 74266 (98f1cc3) BD 1.0.0 (850d0cc) Host 0.0.309 Injector 0.6.2 Windows 10 64-Bit (10.0.19042) **Additional Context** <!-- Add any other context about the problem here. -->"
491648,546438,https://api.github.com/repos/RipcordSoftware/hvk8scluster/issues/27,enhancement,2021-03-02T23:21:17Z,CONTRIBUTOR,https://api.github.com/repos/RipcordSoftware/hvk8scluster,Simplify the preseed image creation process Invoke WSL from script to create the preseed ISO without needing user interaction at the console.
568434,631708,https://api.github.com/repos/SamPetherbridge/httpstatus.xyz/issues/1,bug,2021-01-02T10:18:44Z,OWNER,https://api.github.com/repos/SamPetherbridge/httpstatus.xyz,HEAD requests incorrectly returning content length header **Describe the bug** HTTP head requests are incorrectly returning a content length header when no body is returned. **Expected behavior** Content length header should not be returned. **Screenshots** ![image](https://user-images.githubusercontent.com/3715180/103455283-93043a80-4d37-11eb-8ee0-82d2a000635d.png) Expected Behaviour ![image](https://user-images.githubusercontent.com/3715180/103455299-aca58200-4d37-11eb-9010-73f9a5f94382.png) 
680632,756437,https://api.github.com/repos/argoproj/argo-helm/issues/310,enhancement,2020-04-16T18:53:17Z,NONE,https://api.github.com/repos/argoproj/argo-helm,Allow gcs config in artifactRepository section **Is your feature request related to a problem? Please describe.** Not able to specify gcs config (with json key file) in the artifactoryRepository section. User would have to use s3 api if gcs is the only choice for storage. **Describe the solution you'd like** Support gcs config. **Describe alternatives you've considered** use s3 api or minio with gcs gateway. 
31416,35006,https://api.github.com/repos/TheGrandCoding/che-sserver/issues/9,enhancement,2019-06-04T06:41:43Z,CONTRIBUTOR,https://api.github.com/repos/TheGrandCoding/che-sserver,"Loading/saving of saved game Allow clients to properly load from the saved game. At the moment, the server will load, then send a `LOAD:{json}` message to the client - this should be interpreted and correctly loaded, then the client could(?) send back a message perhaps indicating they have finished?"
271879,302354,https://api.github.com/repos/TESTgroup-BNL/spectratrait/issues/78,bug,2021-03-10T16:03:04Z,MEMBER,https://api.github.com/repos/TESTgroup-BNL/spectratrait,"Fix %RMSEP in the code - should be over the range not the mean @JulienLamour noticed an error in the calculation, Needs to be changed to match our reviewer responses and to match citations"
193341,215007,https://api.github.com/repos/jarun/nnn/issues/884,enhancement,2021-03-16T17:44:49Z,NONE,https://api.github.com/repos/jarun/nnn,cp/mv with plugins (fzcd / autojump) is there a way to select a file / multiple files; use a plugin to to change directory and cp/mv the selected file(s)? Currently I have to open / switch between tabs to copy / paste 
115667,128534,https://api.github.com/repos/Siphalor/nbt-crafting/issues/60,bug,2020-12-31T12:37:59Z,NONE,https://api.github.com/repos/Siphalor/nbt-crafting,"Compatibility issue with NBT crafting, Fabric Zero, and Random Patches **Version** Minecraft 1.16.4 NBT Crafting 2.0.3 Fabric Zero 0.2.0 Random Patches 2.1.0 MultiMC 0.6.11-1430 Fabric API 0.29.0 **Describe the bug** Running these three mods alongside each other creates a series of errors related to mixins. Disabling any one of the mods resolves the issue. Running all three together spams the log with errors. **To Reproduce** 1. Start minecraft running only Fabric API and the three mods in question. 2. Watch an Async Class PreLoader warning appear in the log followed by a series of errors. 3. Minecraft will still start. **Expected behavior** The game should start without errors in the log. **Log (short)** ``` [04:28:41] [Async Class PreLoader/WARN]: @Redirect conflict. Skipping randompatches.mixins.json:InputSlotFillerMixin->@Redirect::getSlotWithUnusedStack(Lnet/minecraft/class_1661;Lnet/minecraft/class_1799;)I with priority 1000, already redirected by nbtcrafting.mixins.json:MixinInputSlotFiller->@Redirect::playerInventoryFindStack(Lnet/minecraft/class_1661;Lnet/minecraft/class_1799;)I with priority 1000 [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: org.spongepowered.asm.mixin.transformer.throwables.MixinTransformerError: An unexpected critical error was encountered [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.transformer.MixinProcessor.applyMixins(MixinProcessor.java:363) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.transformer.MixinTransformer.transformClass(MixinTransformer.java:208) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.transformer.MixinTransformer.transformClassBytes(MixinTransformer.java:178) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.transformer.FabricMixinTransformerProxy.transformClassBytes(FabricMixinTransformerProxy.java:23) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at com.fox2code.fabriczero.FabricZeroTransformerHook.transformClassBytes(FabricZeroTransformerHook.java:41) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at net.fabricmc.loader.launch.knot.KnotClassDelegate.getPostMixinClassByteArray(KnotClassDelegate.java:157) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at net.fabricmc.loader.launch.knot.KnotClassLoader.loadClass(KnotClassLoader.java:150) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at java.lang.ClassLoader.loadClass(Unknown Source) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at java.lang.ClassLoader.defineClass1(Native Method) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at java.lang.ClassLoader.defineClass(Unknown Source) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at java.security.SecureClassLoader.defineClass(Unknown Source) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at net.fabricmc.loader.launch.knot.KnotClassLoader.loadClass(KnotClassLoader.java:163) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at java.lang.ClassLoader.loadClass(Unknown Source) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at java.lang.Class.forName0(Native Method) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at java.lang.Class.forName(Unknown Source) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at com.fox2code.fabriczero.mod.FabricZeroClient$1.run(FabricZeroClient.java:41) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: Caused by: org.spongepowered.asm.mixin.injection.throwables.InjectionError: Critical injection failure: Redirector getSlotWithUnusedStack(Lnet/minecraft/class_1661;Lnet/minecraft/class_1799;)I in randompatches.mixins.json:InputSlotFillerMixin failed injection check, (0/1) succeeded. Scanned 1 target(s). Using refmap randompatches-refmap.json [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.injection.struct.InjectionInfo.postInject(InjectionInfo.java:408) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.transformer.MixinTargetContext.applyInjections(MixinTargetContext.java:1291) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.transformer.MixinApplicatorStandard.applyInjections(MixinApplicatorStandard.java:1042) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.transformer.MixinApplicatorStandard.applyMixin(MixinApplicatorStandard.java:395) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.transformer.MixinApplicatorStandard.apply(MixinApplicatorStandard.java:320) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.transformer.TargetClassContext.applyMixins(TargetClassContext.java:345) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.transformer.MixinProcessor.applyMixins(MixinProcessor.java:569) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.transformer.MixinProcessor.applyMixins(MixinProcessor.java:351) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: ... 15 more ``` **Log (entire)** ``` MultiMC version: 0.6.11-1430 Minecraft folder is: E:/minecraft/multiMC/mmc-stable-win32/MultiMC/instances/Single Mod Test/.minecraft Java path is: C:/Program Files (x86)/Common Files/Oracle/Java/javapath/javaw.exe Java is version 1.8.0_271, using 64-bit architecture. Main Class: net.fabricmc.loader.launch.knot.KnotClient Native path: E:/minecraft/multiMC/mmc-stable-win32/MultiMC/instances/Single Mod Test/natives Traits: traits XR:Initial traits FirstThreadOnMacOS Libraries: E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/lwjgl/lwjgl-glfw/3.2.2/lwjgl-glfw-3.2.2.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/lwjgl/lwjgl-jemalloc/3.2.2/lwjgl-jemalloc-3.2.2.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/lwjgl/lwjgl-openal/3.2.2/lwjgl-openal-3.2.2.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/lwjgl/lwjgl-opengl/3.2.2/lwjgl-opengl-3.2.2.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/lwjgl/lwjgl-stb/3.2.2/lwjgl-stb-3.2.2.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/lwjgl/lwjgl-tinyfd/3.2.2/lwjgl-tinyfd-3.2.2.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/lwjgl/lwjgl/3.2.2/lwjgl-3.2.2.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/com/mojang/patchy/1.1/patchy-1.1.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/oshi-project/oshi-core/1.1/oshi-core-1.1.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/net/java/dev/jna/jna/4.4.0/jna-4.4.0.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/net/java/dev/jna/platform/3.4.0/platform-3.4.0.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/com/ibm/icu/icu4j/66.1/icu4j-66.1.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/com/mojang/javabridge/1.0.22/javabridge-1.0.22.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/net/sf/jopt-simple/jopt-simple/5.0.3/jopt-simple-5.0.3.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/io/netty/netty-all/4.1.25.Final/netty-all-4.1.25.Final.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/com/google/guava/guava/21.0/guava-21.0.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/apache/commons/commons-lang3/3.5/commons-lang3-3.5.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/commons-io/commons-io/2.5/commons-io-2.5.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/commons-codec/commons-codec/1.10/commons-codec-1.10.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/com/mojang/brigadier/1.0.17/brigadier-1.0.17.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/com/mojang/datafixerupper/4.0.26/datafixerupper-4.0.26.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/com/google/code/gson/gson/2.8.0/gson-2.8.0.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/com/mojang/authlib/2.1.28/authlib-2.1.28.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/apache/commons/commons-compress/1.8.1/commons-compress-1.8.1.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/apache/httpcomponents/httpclient/4.3.3/httpclient-4.3.3.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/apache/httpcomponents/httpcore/4.3.2/httpcore-4.3.2.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/it/unimi/dsi/fastutil/8.2.1/fastutil-8.2.1.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/apache/logging/log4j/log4j-api/2.8.1/log4j-api-2.8.1.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/apache/logging/log4j/log4j-core/2.8.1/log4j-core-2.8.1.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/com/mojang/text2speech/1.11.3/text2speech-1.11.3.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/net/fabricmc/intermediary/1.16.4/intermediary-1.16.4.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/net/fabricmc/tiny-mappings-parser/0.2.2.14/tiny-mappings-parser-0.2.2.14.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/net/fabricmc/sponge-mixin/0.8.2+build.24/sponge-mixin-0.8.2+build.24.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/net/fabricmc/tiny-remapper/0.3.0.70/tiny-remapper-0.3.0.70.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/net/fabricmc/access-widener/1.0.0/access-widener-1.0.0.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/net/fabricmc/fabric-loader-sat4j/2.3.5.4/fabric-loader-sat4j-2.3.5.4.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/com/google/jimfs/jimfs/1.2-fabric/jimfs-1.2-fabric.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/ow2/asm/asm/9.0/asm-9.0.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/ow2/asm/asm-analysis/9.0/asm-analysis-9.0.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/ow2/asm/asm-commons/9.0/asm-commons-9.0.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/ow2/asm/asm-tree/9.0/asm-tree-9.0.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/ow2/asm/asm-util/9.0/asm-util-9.0.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/net/fabricmc/fabric-loader/0.10.8/fabric-loader-0.10.8.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/com/mojang/minecraft/1.16.4/minecraft-1.16.4-client.jar Native libraries: E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/lwjgl/lwjgl-glfw/3.2.2/lwjgl-glfw-3.2.2-natives-windows.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/lwjgl/lwjgl-jemalloc/3.2.2/lwjgl-jemalloc-3.2.2-natives-windows.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/lwjgl/lwjgl-openal/3.2.2/lwjgl-openal-3.2.2-natives-windows.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/lwjgl/lwjgl-opengl/3.2.2/lwjgl-opengl-3.2.2-natives-windows.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/lwjgl/lwjgl-stb/3.2.2/lwjgl-stb-3.2.2-natives-windows.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/lwjgl/lwjgl-tinyfd/3.2.2/lwjgl-tinyfd-3.2.2-natives-windows.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/org/lwjgl/lwjgl/3.2.2/lwjgl-3.2.2-natives-windows.jar E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/com/mojang/text2speech/1.11.3/text2speech-1.11.3-natives-windows.jar Mods: [❌] advdebug-2.2.0.jar (disabled) [❌] amecs-1.3.2+mc.1.16.3.jar (disabled) [❌] antighost-1.16.4-fabric0.25.1-1.1.3.jar (disabled) [❌] autoconfig1u-3.3.1.jar (disabled) [❌] blame-2.2.5.jar (disabled) [❌] Cardinal-Components-API-2.7.10.jar (disabled) [❌] cloth-api-1.4.9.jar (disabled) [❌] config-2-4.8.3.jar (disabled) [❌] dark-loading-screen-1.5.0.jar (disabled) [❌] dawn-1.6.1.jar (disabled) [❌] DisableCustomWorldsAdvice-1.2.jar (disabled) [❌] dynamic-fps-1.2.1.jar (disabled) [✔️] fabric-api-0.29.0+1.16 [❌] fabric-chunkpregen-0.3.3.jar (disabled) [❌] fabric-language-kotlin-1.4.21+build.1.jar (disabled) [✔️] fabriczero-0.2.0 [❌] fastbench-2.3.jar (disabled) [❌] fastfurnace-2.3.jar (disabled) [❌] fatxporbs-0.0.9+1.16.4.jar (disabled) [❌] inventory-hotswap-1.16-1.1.1.jar (disabled) [❌] item-model-fix-0.2.4.jar (disabled) [❌] juke-fix-1.0.0.jar (disabled) [❌] konkrete_fabric_1.1.0_MC_1.16.3-1.16.4.jar (disabled) [❌] lithium-fabric-mc1.16.4-0.6.0.jar (disabled) [❌] modmenu-1.14.13+build.19.jar (disabled) [❌] mousewheelie-1.6.1+mc1.16.4.jar (disabled) [✔️] nbtcrafting-2.0.3+mc1.16.4 [❌] phosphor-fabric-mc1.16.3-0.7.0+build.10.jar (disabled) [✔️] randompatches-2.1.0 [❌] RoughlyEnoughItems-5.8.9.jar (disabled) [❌] smoothboot-fabric-1.16-1.3.1.jar (disabled) [❌] sodium-fabric-mc1.16.3-0.1.0.jar (disabled) [❌] spark-fabric.jar (disabled) [❌] YungsApi-1.16.4-Fabric-1.jar (disabled) Params: --username --version MultiMC5 --gameDir E:/minecraft/multiMC/mmc-stable-win32/MultiMC/instances/Single Mod Test/.minecraft --assetsDir E:/minecraft/multiMC/mmc-stable-win32/MultiMC/assets --assetIndex 1.16 --uuid --accessToken --userType --versionType release Window size: 854 x 480 Java Arguments: [-XX:HeapDumpPath=MojangTricksIntelDriversForPerformance_javaw.exe_minecraft.exe.heapdump, -Xms4096m, -Xmx4096m, -Duser.language=en] Minecraft process ID: 16036 Using onesix launcher. [04:28:30] [main/INFO]: Loading for game Minecraft 1.16.4 [04:28:31] [main/INFO]: [FabricLoader] Loading 53 mods: fabric-renderer-api-v1@0.4.0+cbe9176f3a, fabric-keybindings-v0@0.2.0+6a2618f53a, fabricloader@0.10.8, fabric-structure-api-v1@1.1.3+cbe9176f3a, fabriczero@0.2.0, fabric-containers-v0@0.1.9+a03e98793a, fabric-object-builder-api-v1@1.9.2+6a2618f53a, fabric-dimensions-v1@2.0.1+9a6c75813a, fabric-game-rule-api-v1@1.0.5+cbe9176f3a, fabric-api-base@0.2.0+ab87788d3a, fabric-rendering-data-attachment-v1@0.1.4+6a2618f53a, fabric-textures-v0@1.0.5+6a2618f53a, com_electronwill_night-config_core@3.6.3, randompatches@2.0.1, fabric-rendering-fluids-v1@0.1.12+6a2618f53a, fabric-blockrenderlayer-v1@1.1.4+6a2618f53a, fabric-lifecycle-events-v1@1.2.0+ffb68a873a, fabric-renderer-registries-v1@2.2.0+6a2618f53a, fabric-loot-tables-v1@1.0.1+6a2618f53a, fabric@0.29.0+1.16, fabric-particles-v1@0.2.3+cbe9176f3a, autoconfigtoml@1.0.0, fabric-networking-v0@0.3.1+2a4333d33a, minecraft@1.16.4, fabric-screen-handler-api-v1@1.1.0+6a2618f53a, fabric-networking-blockentity-v0@0.2.7+a03e98793a, cloth-basic-math@0.5.1, fabric-command-api-v1@1.0.9+6a2618f53a, fabric-tool-attribute-api-v1@1.2.5+6a2618f53a, fabric-renderer-indigo@0.4.3+6a2618f53a, com_electronwill_night-config_toml@3.6.3, fabric-item-api-v1@1.2.0+6a2618f53a, fabric-events-interaction-v0@0.4.1+6a2618f53a, fabric-crash-report-info-v1@0.1.2+b7f9825d3a, fabric-entity-events-v1@1.0.0+79b23bee3a, nbtcrafting@2.0.3+mc1.16.4, fabric-rendering-v0@1.1.1+6a2618f53a, fabric-rendering-v1@1.5.0+c26373133a, fabric-key-binding-api-v1@1.0.1+730711c63a, cloth-config2@4.8.3, autoconfig1u@3.3.1, fabric-resource-loader-v0@0.4.0+552549d53a, fabric-content-registries-v0@0.2.0+e77439c73a, fabric-tag-extensions-v0@1.1.0+e77439c73a, fabric-biome-api-v1@3.1.0+2e23b97c3a, fabric-registry-sync-v0@0.7.3+be155ae23a, fabric-commands-v0@0.2.1+cbe9176f3a, fabric-mining-levels-v0@0.1.2+6a2618f53a, fabric-networking-api-v1@1.0.0+4358fbc63a, fabric-events-lifecycle-v0@0.2.0+6a2618f53a, fabric-models-v0@0.2.0+cbe9176f3a, fabric-item-groups-v0@0.2.2+cbe9176f3a, fabric-object-builders-v0@0.7.1+6a2618f53a [04:28:31] [main/INFO]: SpongePowered MIXIN Subsystem Version=0.8.2 Source=file:/E:/minecraft/multiMC/mmc-stable-win32/MultiMC/libraries/net/fabricmc/sponge-mixin/0.8.2+build.24/sponge-mixin-0.8.2+build.24.jar Service=Knot/Fabric Env=CLIENT [04:28:31] [main/INFO]: FabricZero: Loaded! [04:28:31] [main/WARN]: Error loading class: me/shedaniel/rei/server/RecipeFinder (java.lang.ClassNotFoundException: me/shedaniel/rei/server/RecipeFinder) [04:28:31] [main/WARN]: @Mixin target me/shedaniel/rei/server/RecipeFinder was not found nbtcrafting.compat.mixins.json:MixinREIRecipeFinder [04:28:38] [main/INFO]: Environment: authHost='https://authserver.mojang.com', accountsHost='https://api.mojang.com', sessionHost='https://sessionserver.mojang.com', servicesHost='https://api.minecraftservices.com', name='PROD' [04:28:39] [main/INFO]: Setting user: Josheva [04:28:40] [Async Class PreLoader/INFO]: Preloading classes... [04:28:40] [main/INFO]: [STDOUT]: E:\minecraft\multiMC\mmc-stable-win32\MultiMC\libraries\com\mojang\minecraft\1.16.4\minecraft-1.16.4-client.jar [04:28:40] [main/INFO]: [Indigo] Registering Indigo renderer! [04:28:41] [main/INFO]: Backend library: LWJGL version 3.2.2 build 10 [04:28:41] [Async Class PreLoader/WARN]: @Redirect conflict. Skipping randompatches.mixins.json:InputSlotFillerMixin->@Redirect::getSlotWithUnusedStack(Lnet/minecraft/class_1661;Lnet/minecraft/class_1799;)I with priority 1000, already redirected by nbtcrafting.mixins.json:MixinInputSlotFiller->@Redirect::playerInventoryFindStack(Lnet/minecraft/class_1661;Lnet/minecraft/class_1799;)I with priority 1000 [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: org.spongepowered.asm.mixin.transformer.throwables.MixinTransformerError: An unexpected critical error was encountered [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.transformer.MixinProcessor.applyMixins(MixinProcessor.java:363) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.transformer.MixinTransformer.transformClass(MixinTransformer.java:208) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.transformer.MixinTransformer.transformClassBytes(MixinTransformer.java:178) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.transformer.FabricMixinTransformerProxy.transformClassBytes(FabricMixinTransformerProxy.java:23) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at com.fox2code.fabriczero.FabricZeroTransformerHook.transformClassBytes(FabricZeroTransformerHook.java:41) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at net.fabricmc.loader.launch.knot.KnotClassDelegate.getPostMixinClassByteArray(KnotClassDelegate.java:157) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at net.fabricmc.loader.launch.knot.KnotClassLoader.loadClass(KnotClassLoader.java:150) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at java.lang.ClassLoader.loadClass(Unknown Source) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at java.lang.ClassLoader.defineClass1(Native Method) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at java.lang.ClassLoader.defineClass(Unknown Source) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at java.security.SecureClassLoader.defineClass(Unknown Source) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at net.fabricmc.loader.launch.knot.KnotClassLoader.loadClass(KnotClassLoader.java:163) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at java.lang.ClassLoader.loadClass(Unknown Source) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at java.lang.Class.forName0(Native Method) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at java.lang.Class.forName(Unknown Source) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at com.fox2code.fabriczero.mod.FabricZeroClient$1.run(FabricZeroClient.java:41) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: Caused by: org.spongepowered.asm.mixin.injection.throwables.InjectionError: Critical injection failure: Redirector getSlotWithUnusedStack(Lnet/minecraft/class_1661;Lnet/minecraft/class_1799;)I in randompatches.mixins.json:InputSlotFillerMixin failed injection check, (0/1) succeeded. Scanned 1 target(s). Using refmap randompatches-refmap.json [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.injection.struct.InjectionInfo.postInject(InjectionInfo.java:408) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.transformer.MixinTargetContext.applyInjections(MixinTargetContext.java:1291) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.transformer.MixinApplicatorStandard.applyInjections(MixinApplicatorStandard.java:1042) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.transformer.MixinApplicatorStandard.applyMixin(MixinApplicatorStandard.java:395) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.transformer.MixinApplicatorStandard.apply(MixinApplicatorStandard.java:320) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.transformer.TargetClassContext.applyMixins(TargetClassContext.java:345) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.transformer.MixinProcessor.applyMixins(MixinProcessor.java:569) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: at org.spongepowered.asm.mixin.transformer.MixinProcessor.applyMixins(MixinProcessor.java:351) [04:28:41] [Async Class PreLoader/INFO]: [STDERR]: ... 15 more [04:28:44] [main/INFO]: Narrator library for x64 successfully loaded [04:28:44] [main/INFO]: Reloading ResourceManager: Default, Fabric Mods (Fabric Renderer API (v1), Fabric Key Bindings (v0), Fabric Loader, Fabric Structure API (v1), Fabric Zero, Fabric Containers (v0), Fabric Object Builder API (v1), Fabric Game Rule API (v1), Fabric API Base, Fabric Rendering Data Attachment (v1), Fabric Textures (v0), RandomPatches, Fabric Rendering Fluids (v1), Fabric BlockRenderLayer Registration (v1), Fabric Lifecycle Events (v1), Fabric Renderer Registries (v1), Fabric Loot Tables (v1), Fabric API, Fabric Particles (v1), AutoConfig-TOML, Fabric Networking (v0), Fabric Screen Handler API (v1), Fabric Networking Block Entity (v0), Fabric Command API (v1), Fabric Tool Attribute API (v1), Fabric Renderer - Indigo, Fabric Item API (v1), Fabric Events Interaction (v0), Fabric Crash Report Info (v1), Fabric Entity Events (v1), NBT Crafting, Fabric Rendering (v0), Fabric Rendering (v1), Fabric Key Binding API (v1), Cloth Config v4, Auto Config v1 Updated, Fabric Resource Loader (v0), Fabric Content Registries (v0), Fabric Tag Extensions (v0), Fabric Biome API (v1), Fabric Registry Sync (v0), Fabric Commands (v0), Fabric Mining Levels (v0), Fabric Networking API (v1), Fabric Events Lifecycle (v0), Fabric Models (v0), Fabric Item Groups (v0), Fabric Object Builders (v0)) [04:28:51] [main/INFO]: OpenAL initialized. [04:28:51] [main/INFO]: Sound engine started [04:28:52] [main/INFO]: Created: 1024x1024x4 minecraft:textures/atlas/blocks.png-atlas [04:28:52] [main/INFO]: Created: 256x128x4 minecraft:textures/atlas/signs.png-atlas [04:28:52] [main/INFO]: Created: 1024x512x4 minecraft:textures/atlas/banner_patterns.png-atlas [04:28:52] [main/INFO]: Created: 1024x512x4 minecraft:textures/atlas/shield_patterns.png-atlas [04:28:52] [main/INFO]: Created: 256x256x4 minecraft:textures/atlas/chest.png-atlas [04:28:52] [main/INFO]: Created: 512x256x4 minecraft:textures/atlas/beds.png-atlas [04:28:52] [main/INFO]: Created: 512x256x4 minecraft:textures/atlas/shulker_boxes.png-atlas [04:28:53] [main/INFO]: Created: 256x256x0 minecraft:textures/atlas/particles.png-atlas [04:28:53] [main/INFO]: Created: 256x256x0 minecraft:textures/atlas/paintings.png-atlas [04:28:53] [main/INFO]: Created: 256x128x0 minecraft:textures/atlas/mob_effects.png-atlas [04:29:20] [main/INFO]: Stopping! Exception in thread ""Async Class PreLoader"" Process exited with code 0. ```"
358608,398672,https://api.github.com/repos/Checkmarx/kics/issues/2107,enhancement,2021-02-19T14:26:16Z,CONTRIBUTOR,https://api.github.com/repos/Checkmarx/kics,"Update EC2 Network ACL Duplicate Rule query for AWS CloudFormation ### Platform AWS CloudFormation ### Provider AWS ### Description Updating ""getTraffic()"" method to consider more formats in which a value can be. "
88873,98787,https://api.github.com/repos/apache/buildstream/issues/1205,bug,2021-01-01T02:37:13Z,COLLABORATOR,https://api.github.com/repos/apache/buildstream,"Pylint configuration is busted [See original issue on GitLab](https://gitlab.com/BuildStream/buildstream/-/issues/1206) In GitLab by [[Gitlab user @cs-shadow]](https://gitlab.com/cs-shadow) on Nov 13, 2019, 13:23 ## Summary It seems like we should be getting certain warnings from `pylint` about our codebase but we aren't. I think this is happening because we messed up our pylint configuration when we moved sources into a `src` directory (I can take the blame for that). We currently invoke pylint as `pylint src/buildstream tests`. Locally, I tried `pylint src tests` by accident and got a few warnings on master, which was surprising. Later I realized that my invocation was more correct and the warnings were real things that we need to fix. ## Steps to reproduce ``` # This is what we currentl do - everything's fine! (lint) root[[Gitlab user @2428e3458936]](https://gitlab.com/2428e3458936):/src# pylint src/buildstream tests ------------------------------------------------------------------- Your code has been rated at 10.00/10 (previous run: 9.99/10, +0.01) # This is what I tried and got new warnings (lint) root[[Gitlab user @2428e3458936]](https://gitlab.com/2428e3458936):/src# pylint src tests ************* Module buildstream.plugins.sources.patch src/buildstream/plugins/sources/patch.py:83:4: W0221: Parameters differ from overridden 'fetch' method (arguments-differ) ************* Module buildstream.plugins.sources.bzr src/buildstream/plugins/sources/bzr.py:104:4: W0221: Parameters differ from overridden 'track' method (arguments-differ) src/buildstream/plugins/sources/bzr.py:118:4: W0221: Parameters differ from overridden 'fetch' method (arguments-differ) ************* Module buildstream.plugins.sources.tar src/buildstream/plugins/sources/tar.py:83:8: W0201: Attribute '__permission' defined outside __init__ (attribute-defined-outside-init) ************* Module buildstream.plugins.sources.local src/buildstream/plugins/sources/local.py:78:4: W0221: Parameters differ from overridden 'fetch' method (arguments-differ) src/buildstream/plugins/sources/local.py:42:0: W0611: Unused utils imported from buildstream (unused-import) ************* Module buildstream.plugins.sources._downloadablefilesource src/buildstream/plugins/sources/_downloadablefilesource.py:114:4: W0221: Parameters differ from overridden 'track' method (arguments-differ) src/buildstream/plugins/sources/_downloadablefilesource.py:131:4: W0221: Parameters differ from overridden 'fetch' method (arguments-differ) ************* Module buildstream.plugins.sources.pip src/buildstream/plugins/sources/pip.py:158:4: W0221: Parameters differ from overridden 'track' method (arguments-differ) src/buildstream/plugins/sources/pip.py:180:4: W0221: Parameters differ from overridden 'fetch' method (arguments-differ) ************* Module buildstream.plugins.sources.workspace src/buildstream/plugins/sources/workspace.py:61:4: W0221: Parameters differ from overridden 'track' method (arguments-differ) src/buildstream/plugins/sources/workspace.py:91:4: W0221: Parameters differ from overridden 'fetch' method (arguments-differ) src/buildstream/plugins/sources/workspace.py:38:0: W0611: Unused import os (unused-import) src/buildstream/plugins/sources/workspace.py:40:0: W0611: Unused CasBasedDirectory imported from buildstream.storage._casbaseddirectory (unused-import) src/buildstream/plugins/sources/workspace.py:42:0: W0611: Unused utils imported from buildstream (unused-import) ----------------------------------- Your code has been rated at 9.99/10 ``` ## What is the current bug behavior? Pylint warnings get hidden. ## What is the expected correct behavior? Pylint warnings are reported correctly."
298879,332316,https://api.github.com/repos/hzi-braunschweig/SORMAS-Project/issues/2567,bug,2020-07-29T10:52:29Z,NONE,https://api.github.com/repos/hzi-braunschweig/SORMAS-Project,"Import function records case as error even after skipping or picking an existing case or contact ### Bug Description When a user tries to import a case with the same EPID number as an already existing case, and selects ""pick an already existing case"" or ""Skip"", the system records it as an error. This shouldnt be so because both options on ""pick an already existing case"" and ""Skip"" should instruct the system to completely ignore the about to be imported case or contact ### Steps to Reproduce 1. Put on an import template, a case having the same name, Epid number, age and sex 2. Attempt running an import on SORMAS 3. On duplicate detection, select ""pick an already existing case"" or ""Skip"" 4. Check your error log or document ### Expected Behavior ### Screenshots ### System Details * Device: * SORMAS version: * Android version/Browser: ### Additional Information "
709140,788137,https://api.github.com/repos/PepperDash/Essentials/issues/632,enhancement,2021-02-25T23:48:01Z,CONTRIBUTOR,https://api.github.com/repos/PepperDash/Essentials,"[FEATURE]-Add Destination list to Basic Config class In addition to the class described in #276, we need to add a destination list configuration item to the basic config, similar to how the source lists are configured now. "
61470,68315,https://api.github.com/repos/tsivinsky/pomodoro/issues/1,enhancement,2021-03-27T20:46:47Z,OWNER,https://api.github.com/repos/tsivinsky/pomodoro,Notifications Send notifications when timer is over
626553,696303,https://api.github.com/repos/rstudio/rstudio/issues/4414,bug,2019-03-07T12:47:15Z,NONE,https://api.github.com/repos/rstudio/rstudio,"tab autocomplete triggers active bindings in a package namespace ### System details Version 1.2.1303 © 2009-2019 RStudio, Inc. Build 1310 (983ef73f) OS Version : Mojave MacOS R Version : 3.5.2 ### Steps to reproduce the problem 1. Build a skeleton package 2. Add a single active binding which prints a message 3. install/load the package 4. type package name then ::, then tab for autocomplete 5. observe that the active binding is executed ### Describe the problem in detail I think it is a bug that active bindings are executed during autocomplete attempts. There is no need to examine the contents of the data, AFAICS. In the case of active bindings, this causes execution of potentially heavy and interactive code, e.g. asking user if they wish to download data (hiding behind the active binding symbol). ### Describe the behavior you expected autocomplete should show the name of the active binding, but not execute the code therein. ### solution `bindingIsActive` in base package can be used to determine if a symbol is an active binding ### workaround disable autocompletion"
237889,264608,https://api.github.com/repos/hairyhenderson/gomplate/issues/996,bug,2020-12-10T06:50:06Z,NONE,https://api.github.com/repos/hairyhenderson/gomplate,"Empty line in stderr starting with v3.7.0 This is a minor issue that surfaced in our automated tests. Starting with v3.7.0, gomplate started throwing an empty line into stderr output: ``` docker@cli:/var/www$ touch in.tmpl # 3.6.0 docker@cli:/var/www$ ./gomplate --version gomplate version 3.6.0 docker@cli:/var/www$ ./gomplate --file in.tmpl docker@cli:/var/www$ # 3.7.0 docker@cli:/var/www$ ./gomplate --version gomplate version 3.7.0 docker@cli:/var/www$ ./gomplate --file in.tmpl docker@cli:/var/www$ ./gomplate --file in.tmpl 2>/dev/null docker@cli:/var/www$ ``` "
294256,327204,https://api.github.com/repos/libsdl-org/SDL-1.2/issues/339,bug,2021-02-10T21:05:50Z,COLLABORATOR,https://api.github.com/repos/libsdl-org/SDL-1.2,"Freezes coz of newly added key composition support # This bug report was migrated from our old Bugzilla tracker. **Reported in version:** 1.2.12 **Reported for operating system, platform:** Mac OS X (All), PowerPC # Comments on the original bug report: On 2007-08-18 23:12:46 +0000, manutoo wrote: > I reported freezes on the newsgroup here : http://article.gmane.org/gmane.comp.lib.sdl/34324 > > console.log contains : > ""2007-08-18 08:48:22.368 Tennis Elbow 2006[277] Exception raised during posting > of notification. Ignored. exception: *** -[NSLayoutManager > glyphRangeForTextContainer:]: given container does not appear in the list of > containers for this NSLayoutManager."" > > someone said he had the same trouble but with SDL 1.3 and pointed out this revision : > http://libsdl.org/cgi/viewvc.cgi?view=rev&revision=3217 > > Then, I commented out these lines : > 1- [field_edit interpretKeyEvents:[NSArray arrayWithObject:event]]; > 2- field_edit = [[NSTextView alloc] initWithFrame:r]; > > and now, the freezes seem to be gone ! (at least on my system, I still need to get confirmation from my users). On 2007-08-19 05:46:29 +0000, manutoo wrote: > One user just reported he didn't have freeze anymore and it also corrected the slowness he was experiencing on his G4 dual, OSX 10.4, GeForce4 MX AGP 64MB . On 2007-08-20 13:58:02 +0000, Will Glynn wrote: > Seconded. I see occasional-to-frequent crashes in an entirely distinct code base giving the same message on the console, though I haven't tried that workaround yet. I found this bug report via the below discussion as indexed by Google. On 2007-08-20 23:52:03 +0000, Sam Lantinga wrote: > > > *** This bug has been marked as a duplicate of bug 471 *** "
648238,720536,https://api.github.com/repos/lewiswatson55/SEM-Group19/issues/71,bug,2021-04-28T11:49:25Z,COLLABORATOR,https://api.github.com/repos/lewiswatson55/SEM-Group19,"[BUG] Hello world **Describe the bug** A clear and concise description of what the bug is. **To Reproduce** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected behavior** A clear and concise description of what you expected to happen. **Screenshots** If applicable, add screenshots to help explain your problem. **Desktop (please complete the following information):** - OS: [e.g. iOS] - Browser [e.g. chrome, safari] - Version [e.g. 22] **Smartphone (please complete the following information):** - Device: [e.g. iPhone6] - OS: [e.g. iOS8.1] - Browser [e.g. stock browser, safari] - Version [e.g. 22] **Additional context** Add any other context about the problem here. "
240342,267319,https://api.github.com/repos/Scratch-Dev-Team/Scratch-ConsoleBased-Extensions/issues/8,enhancement,2021-05-02T12:49:16Z,MEMBER,https://api.github.com/repos/Scratch-Dev-Team/Scratch-ConsoleBased-Extensions,"Recent Changes and new changes All the changes, redirecttoscratchproject.js was pretty much copy and paste, and I had to make some changes that should have been done in the first place (https://github.com/Scratch-Dev-Team/Scratch-ConsoleBased-Extensions/commit/36a503fd03be867b2536ba76e6fc5abe7273cd58#diff-3c445e62ae8dba31393b8060f3ccb62724ccf595162090b6d64d42465595e285) I would also like to have admin, and be the only admin of this repo. And what happened to the title? - [ ] Change back title/Make it work for both (adding on console may not work because of one of the bookmarklet code elements)"
530006,589078,https://api.github.com/repos/eclipse-vertx/vert.x/issues/3353,bug,2020-04-01T18:22:06Z,NONE,https://api.github.com/repos/eclipse-vertx/vert.x,"Vert.x doesn't handle Transfer-Encoding properly ### Version 3.8.5 ### Context When a client sends ""Transfer-Encoding: gzip, chunked"", Vert.x resets the client connection without sending a response. ### Do you have a reproducer? https://github.com/cristianokbc/vertx-starter ### Steps to reproduce 1. Clone the repository https://github.com/cristianokbc/vertx-starter 2. Start it using `mvn clean compile java:exec` 3. Make a POST request using the following curl command: ```sh curl http://localhost:8888 -H ""Transfer-Encoding: gzip, chunked"" -d @./data.gz -X POST -v ``` The client will be disconnected without any response: ``` * About to connect() to localhost port 8888 (#0) * Trying 127.0.0.1... * Connected to localhost (127.0.0.1) port 8888 (#0) > POST / HTTP/1.1 > User-Agent: curl/7.29.0 > Host: localhost:8888 > Accept: */* > Transfer-Encoding: gzip, chunked > Content-Type: application/x-www-form-urlencoded > > 8 * upload completely sent off: 15 out of 8 bytes * Empty reply from server * Connection #0 to host localhost left intact curl: (52) Empty reply from server ``` "
263457,293009,https://api.github.com/repos/oliverklee/ext-seminars/issues/693,bug,2021-01-23T19:21:20Z,OWNER,https://api.github.com/repos/oliverklee/ext-seminars,"Replace ExtensionManagementUtility::siteRelPath('seminars') … with the code from the (now deprecated) function, or maybe even something short: ```php PathUtility::stripPathSitePrefix(ExtensionManagementUtility::extPath($key)) ```"
615737,684273,https://api.github.com/repos/matryer/xbar/issues/651,bug,2021-03-19T15:02:14Z,NONE,https://api.github.com/repos/matryer/xbar,"Folders in the plugins directory get ""executed"" It would appear that xbar, when trying to execute all the scripts in the plugins directory, tries to execute directories. BitBar did not do this. ![Screen Shot 2021-03-19 at 8 41 39 AM](https://user-images.githubusercontent.com/1158916/111797618-ed209080-888e-11eb-84df-e42b2f24d6b4.png) The `Dir` function in `pkg/plugins/plugin.go` should include, in its ignore logic, something like this: ```go if file.IsDir() { // ignore directories continue } ``` I would have made a PR but the readme suggests opening an issue first. Thanks for this project. 😄 "
289334,321751,https://api.github.com/repos/rauldpm/InmobilIV/issues/39,enhancement,2021-01-10T17:55:04Z,OWNER,https://api.github.com/repos/rauldpm/InmobilIV,"El despligue de la imagen docker en el PaaS es muy lenta, desplegar Fat Jar El inicio de la imagen docker en el PaaS tarda demasiado y no arranca, produciéndose un estado erróneo, implementar la funcionalidad necesaria para la creación de archivos ejecutables FatJar y desplegar dicho fichero."
607311,674908,https://api.github.com/repos/bryntum/support/issues/224,bug,2020-01-23T13:29:57Z,MEMBER,https://api.github.com/repos/bryntum/support,Resize behaves wrong when dragging start outside the time axis left edge http://lh/bryntum-suite/scheduler/examples/basic/ Drag left resize handle way to the left ![event](https://user-images.githubusercontent.com/218570/72988769-368d6100-3ded-11ea-8e53-08dd58c21f45.gif) https://www.bryntum.com/forum/viewtopic.php?f=44&t=13183 
538583,598603,https://api.github.com/repos/jkopyto/CodersCamp2020.Project.JavaScript.NewsService/issues/18,enhancement,2020-12-27T13:02:23Z,OWNER,https://api.github.com/repos/jkopyto/CodersCamp2020.Project.JavaScript.NewsService,[Feature] SportDataAPI service ### Acceptance criteria **Functioning service that implements methods from [SportDataAPI](https://app.sportdataapi.com/documentation)** - [x] Create new service in `service` folder - [x] Implement proper methods based on proposed functionalities [Wiki](https://github.com/jkopyto/CodersCamp2020.Project.JavaScript.NewsService/wiki/%5BAPI%5D-SportDataApi) - [x] Test them by console.logging them (see how responses exactly looks like) - [x] Remove console log and write tests 
425539,473024,https://api.github.com/repos/JuriBurakov/docs/issues/5,bug,2020-12-18T15:58:29Z,OWNER,https://api.github.com/repos/JuriBurakov/docs,"Improve existing docs <!-- HUBBERS BEWARE! THE GITHUB/DOCS REPO IS PUBLIC TO THE ENTIRE INTERNET. OPEN AN ISSUE IN GITHUB/DOCS-CONTENT https://github.com/github/docs-content/issues/new/choose INSTEAD. --> <!-- For questions, ask in Discussions: https://github.com/github/docs/discussions Before you file an issue read the: - Code of Conduct: https://github.com/github/docs/blob/onboarding/CODE_OF_CONDUCT.md - Contributing guide: https://github.com/github/docs/blob/onboarding/CONTRIBUTING.md Check to make sure someone hasn't already opened a similar issue: https://github.com/github/docs/issues --> ### What article on docs.github.com is affected? <!-- Please link to the article you'd like to see updated --> ### What part(s) of the article would you like to see updated? <!-- Give as much detail as you can to help us understand the change you want to see. Why should the docs be changed? What use cases does it support? What is the expected outcome? --> ### Additional information <!-- Add any other context or screenshots about the feature request here. --> "
422012,469092,https://api.github.com/repos/meadsteve/talepy/issues/17,question,2020-06-23T15:31:06Z,NONE,https://api.github.com/repos/meadsteve/talepy,Persisting saga state What about instance crash in a middle step? Especially if it was a N of M retry. Who should persist the transaction metadata and how a recovery is supposed to happen?
571828,635468,https://api.github.com/repos/nhn/tui.editor/issues/1291,question,2020-12-08T15:10:05Z,NONE,https://api.github.com/repos/nhn/tui.editor,"Why window instance is required on the server. related issue https://github.com/nhn/tui.editor/issues/1222 Window instance is required for this editor, this is not a big problem. But, why window instance is also required in the `Viewer` component. I am using **NextJs with ReactJs**, i need to render markdown content on the server. Because of this problem, i am not able to render markdown content on the server. Although i can use `dynamic` provided by **nextJs** to render content on the client-side. But, we are not using a server-side rendering feature. ### Possible solution #### 1 fix the existing code #### 2 Create another `Viewer` component named like `ServerViewer` which doesn'trequire **window** instance. "
268766,298892,https://api.github.com/repos/adobe-fonts/source-sans/issues/194,question,2020-08-21T17:06:28Z,NONE,https://api.github.com/repos/adobe-fonts/source-sans,"Please consider increasing letter spacing in semibold and any bolder versions of the font I have an impression that while both vertical and horizontal lines are getting thicker and so words become more bright (not just vertical lines in the letters, but both vertical and horizontal, which increases the effect), the letter spacing doesn't catch up (or perhaps doesn't increase at all, I didn't check). The result is that words become glaringly bright (when white on black) contrasted with space between words and between lines. This makes longer tests hard to read (yes, I know bold fonts are not meant for long texts, but there the effect is very strong). I've spotted this, because due to bug https://github.com/adobe-fonts/source-sans-pro/issues/193, sometimes the bold font is rendered with increased letter spacing, which looks IMHO better (please have a look yourself and compare with the screenshots with minimal spacing and decide) and is definitely less tiring to read. [Edit: this is probably not a bug, after all, but just extra letter spacing from heavy hinting in libfreetype6.]"
372392,413970,https://api.github.com/repos/WWBN/AVideo/issues/4899,question,2021-04-09T09:18:55Z,NONE,https://api.github.com/repos/WWBN/AVideo,Pageload_time first page for mobile users slow ? The pageload_time of the first page only is slow on mobile devices with slow internet. It can be a visual effect of the white page from the last update that is no showing images. Users told me so i tried the latest update with the update before with limited internet speed with both cleared browser cache. Running on a fast Intel i7 with Virtual Box. I don't know but could the pageload_time being speed up skipping the *_thumbsSmallV2.jpg files so users see directly the image. They can click on the video_image instead of waiting untill the page is loaded ? I tried https://github.com/WWBN/AVideo/issues/4693 but i see no changes. **First video**: BEFORE updating Avideo https://user-images.githubusercontent.com/39981177/114155930-4fb2fc80-9922-11eb-9a87-c40d0512daf0.mp4 **Second video**: AFTER updating Avideo https://user-images.githubusercontent.com/39981177/114157665-2b581f80-9924-11eb-83e6-12192463c492.mp4 Testing with **SLOW** internet speed https://user-images.githubusercontent.com/39981177/114158149-aae5ee80-9924-11eb-821c-49ad9987a6d8.mp4 
372112,413662,https://api.github.com/repos/nf-core/circrna/issues/9,enhancement,2021-03-23T08:43:31Z,COLLABORATOR,https://api.github.com/repos/nf-core/circrna,quantification tool sets Include parameter such as `--tool_filter <union/intersection>` when multiple circRNA quant tools have been selected. 
413411,459512,https://api.github.com/repos/lokka30/LevelledMobs/issues/196,enhancement,2021-03-29T21:58:07Z,COLLABORATOR,https://api.github.com/repos/lokka30/LevelledMobs,"add aureliumskills support for custom drops Suggested by zaspany kuba#6655 Hi! Is there any way to connect levelledmobs with AureliumSkills? I mean, is there any way to levelledmobs drop items with aureliumskills modifier? look, aureliumskills is plugin that add skills etc. Its also adds modifiers to armor/weapons Its look like that (attached screenshot) ![aureliumskills](https://user-images.githubusercontent.com/18266662/112905299-cdb80d80-90af-11eb-83c1-820928ccace9.png) Possibly adding NBT support (issue #195 ) will solve this as well."
463995,515655,https://api.github.com/repos/GAA-UAM/scikit-fda/issues/318,bug,2021-02-08T17:02:45Z,CONTRIBUTOR,https://api.github.com/repos/GAA-UAM/scikit-fda,"_get_label_colors method created but not used Method not used in representation.py def _get_label_colors(n_labels, group_colors=None): """"""Get the colors of each label"""""" if group_colors is not None: if len(group_colors) != n_labels: raise ValueError(""There must be a color in group_colors "" ""for each of the labels that appear in "" ""group."") else: colormap = matplotlib.cm.get_cmap() group_colors = colormap(np.arange(n_labels) / (n_labels - 1)) return group_colors"
625756,695423,https://api.github.com/repos/frappe/frappe/issues/9782,bug,2020-03-25T10:38:13Z,COLLABORATOR,https://api.github.com/repos/frappe/frappe,"Deadlock found when trying to get lock During setup wizard in frappe_docker, this errror occors: ``` 172.18.0.1 - - [25/Mar/2020 10:31:55] ""POST /api/method/erpnext.accounts.doctype.account.chart_of_accounts.chart_of_accounts.validate_bank_account HTTP/1.1"" 200 - Traceback (most recent call last): File ""/workspace/development/frappe-bench/apps/frappe/frappe/utils/scheduler.py"", line 68, in enqueue_events_for_all_sites enqueue_events_for_site(site=site, queued_jobs=jobs_per_site[site]) File ""/workspace/development/frappe-bench/apps/frappe/frappe/utils/scheduler.py"", line 92, in enqueue_events_for_site log_and_raise() File ""/workspace/development/frappe-bench/apps/frappe/frappe/utils/scheduler.py"", line 85, in enqueue_events_for_site enqueue_events(site=site, queued_jobs=queued_jobs) File ""/workspace/development/frappe-bench/apps/frappe/frappe/utils/scheduler.py"", line 106, in enqueue_events update_modified=False) File ""/workspace/development/frappe-bench/apps/frappe/frappe/database/database.py"", line 662, in set_value list(keys) + [dt], debug=debug) File ""/workspace/development/frappe-bench/apps/frappe/frappe/database/database.py"", line 156, in sql self._cursor.execute(query, values) File ""/workspace/development/frappe-bench/env/lib/python3.7/site-packages/pymysql/cursors.py"", line 170, in execute result = self._query(query) File ""/workspace/development/frappe-bench/env/lib/python3.7/site-packages/pymysql/cursors.py"", line 328, in _query conn.query(q) File ""/workspace/development/frappe-bench/env/lib/python3.7/site-packages/pymysql/connections.py"", line 517, in query self._affected_rows = self._read_query_result(unbuffered=unbuffered) File ""/workspace/development/frappe-bench/env/lib/python3.7/site-packages/pymysql/connections.py"", line 732, in _read_query_result result.read() File ""/workspace/development/frappe-bench/env/lib/python3.7/site-packages/pymysql/connections.py"", line 1075, in read first_packet = self.connection._read_packet() File ""/workspace/development/frappe-bench/env/lib/python3.7/site-packages/pymysql/connections.py"", line 684, in _read_packet packet.check_error() File ""/workspace/development/frappe-bench/env/lib/python3.7/site-packages/pymysql/protocol.py"", line 220, in check_error err.raise_mysql_exception(self._data) File ""/workspace/development/frappe-bench/env/lib/python3.7/site-packages/pymysql/err.py"", line 109, in raise_mysql_exception raise errorclass(errno, errval) pymysql.err.OperationalError: (1213, 'Deadlock found when trying to get lock; try restarting transaction') ``` ![image](https://user-images.githubusercontent.com/14891507/77528421-37df1680-6e8e-11ea-904a-1b6fdd3bae7d.png) erpnext 12.x.x-develop frappe 12.4.1"
94417,104941,https://api.github.com/repos/symfony/symfony/issues/39734,bug,2021-01-06T08:40:30Z,NONE,https://api.github.com/repos/symfony/symfony,"[Twig] Creating new projects on PHP 7.1 not possible **Symfony version(s) affected**: 4.4 / Twig v2 **Description** When bootstrapping a new project using PHP 7.1 through `composer create-project symfony/website-skeleton`, there' a incompatibility: `twig/extra-bundle` is installed in v3.2.0 and `twig/twig` in v2.13.1. Building the container calls `registerUndefinedTokenParserCallback` in `Twig\Extra\TwigExtraBundle\DependencyInjection\Compiler\MissingExtensionSuggestorPass`, but this method is not available in Twig v2. ``` !! 08:33:00 CRITICAL [php] Uncaught Error: Call to undefined method Twig\Environment::registerUndefinedTokenParserCallback() [""exception"" => Error { …}] !! !! In srcApp_KernelDevDebugContainer.php line 1546: !! !! Attempted to call an undefined method named ""registerUndefinedTokenParserCallback"" of class ""Twig\Environment"". !! Did you mean to call e.g. ""registerUndefinedFilterCallback"" or ""registerUndefinedFunctionCallback""? !! !! !! cache:clear [--no-warmup] [--no-optional-warmers] [-h|--help] [-q|--quiet] [-v|vv|vvv|--verbose] [-V|--version] [--ansi] [--no-ansi] [-n|--no-interaction] [-e|--env ENV] [--no-debug] [--] <command> ``` "
459236,510393,https://api.github.com/repos/prebid/prebid-server/issues/1776,bug,2021-03-25T07:29:15Z,CONTRIBUTOR,https://api.github.com/repos/prebid/prebid-server,"Authorization leak through headers If ""test"" is specified in the call to PBS, the debug info coming back contains all headers sent to the endpoints. e.g. There can be a basic authentication key exposed. Even though it's not the actual user/password it feels like not something that should be publicly exposed. "
198796,221030,https://api.github.com/repos/LMH01/MGT2_Mod_Tool/issues/52,bug,2021-05-02T11:38:16Z,OWNER,https://api.github.com/repos/LMH01/MGT2_Mod_Tool,Genre export/import will not copy the languages correctly **Describe the bug** Title **Desktop (please complete the following information):** - OS: Windows - Version 2.0.0 and 2.0.1 
545130,605894,https://api.github.com/repos/ktorio/ktor/issues/1669,question,2020-02-24T01:24:20Z,NONE,https://api.github.com/repos/ktorio/ktor,"Does ktor support androidNative in mpp project ? I have a mpp project with androidNative/iOS/jvm I want to write HttpClient in common but I find androidNative can't import HttpClient. ``` implementation(""io.ktor:ktor-client-core:$ktor_version"") implementation(""io.ktor:ktor-client-curl:$ktor_version"") => All Error ``` So, does ktor support androidNative ?? Thanks."
672362,747283,https://api.github.com/repos/RUCAIBox/RecBole/issues/745,question,2021-03-01T13:44:46Z,NONE,https://api.github.com/repos/RUCAIBox/RecBole,"CFKG模型问题 您好，想问几个问题 1、CFKG模型是不是就是直接把user-item交互数据构建为KG然后进行KGE吗？还是也加上了外部知识图谱？ 2、您的代码中注释到“In this version, we sample recommender data and knowledge data separately, and put them together for training.“我不太理解这个版本是做了怎样的改动，能麻烦您简单解释下吗？"
602715,669816,https://api.github.com/repos/upstage-org/mobilise/issues/19,enhancement,2020-08-21T14:06:24Z,CONTRIBUTOR,https://api.github.com/repos/upstage-org/mobilise,Erase pen as a user i can select an eraser tool from the drawing toolbox to delete a described area 
247275,275022,https://api.github.com/repos/skilkis/tudelft-light/issues/43,bug,2021-03-16T17:25:42Z,OWNER,https://api.github.com/repos/skilkis/tudelft-light,Twoside geometry definition cannot be overwritten The declaration of an alternate geometry in the `report.cls` file when the `twoside` option is used prevents the user from modifying the default geometry using the `\PassOptionsToPackage` macro. This is detrimental towards keeping the template as easily configurable as possible.
544258,604942,https://api.github.com/repos/PrestaShop/PrestaShop/issues/22500,bug,2020-12-18T15:17:45Z,CONTRIBUTOR,https://api.github.com/repos/PrestaShop/PrestaShop,"Adding invalid parameter to Language form and ""No picture"" image causes a crash. <!-- **************************** DO NOT disclose security issues here, contact security@prestashop.com instead! **************************** --> #### Describe the bug When you enter invalid parameters to language(whether add or edit) and add a new ""No Picture"" image you get a crash, but ""No Picture"" image saves anyway. #### Expected behavior When adding an invalid parameter to language proper error should be shown and not an exception. Also, it shouldn't save ""No Picture"" image if form is invalid. #### Steps to Reproduce Steps to reproduce the behavior: 1. International -> Language 2. Edit Your primary language 3. Add invalid value( for exampel name = aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa ). 4. Add ""No picture"" image. 5. Save (Should get crash here) 6. Check products in front office, products with no image should have the image you have added (which should have not happened). **Screenshots** ![image](https://user-images.githubusercontent.com/47781757/102630621-7243be80-4155-11eb-83c9-5cefaa348025.png) #### Additional information * PrestaShop version: 1.7.8(develop). * PHP version: 7.2 "
675505,750763,https://api.github.com/repos/zeek/spicy/issues/901,bug,2021-04-29T05:49:43Z,MEMBER,https://api.github.com/repos/zeek/spicy,Unit attributes cannot access bitfields ``` module Test; public type X = unit { : Y; }; type Y = unit { bits: bitfield(8) { all: 0..7; }; } &convert=self.bits.all; ``` ``` [error] test.spicy:13:12: type does not have field 'bits' [error] test.spicy:13:12: 'auto' type has not been resolved [error] spicy-driver: aborting after errors ```
165004,183452,https://api.github.com/repos/adonutwithsprinklez/CodeNameEmpty/issues/104,bug,2021-04-07T14:55:09Z,OWNER,https://api.github.com/repos/adonutwithsprinklez/CodeNameEmpty,"Consumable items that don't have modifiers in their json file can crash the game There is a bug that has only appeared once to me, where if the consumable item has no modifiers in the json file, then there is a chance that a ""self.modifer is not defined"" error will occur, crashing the game."
390696,434286,https://api.github.com/repos/wp-media/wp-rocket/issues/3536,question,2021-01-31T14:50:33Z,CONTRIBUTOR,https://api.github.com/repos/wp-media/wp-rocket,"Font-display option Hello the Rocket Team 😊 I just saw this issue #3375 in the changelog. I read lately that the best option by default would be ""optional"" https://simonhearne.com/2021/layout-shifts-webfonts/ for the font-display property to avoid Layout Shift. This is a tricky option for WP Rocket because you are at the border between design of the website and performance (or at least one of the Google arbitrary indicator), and this choice clearly depend on the website design and your user (client) choice in this matter. Optional make the font loading totally optional to avoid a shift. If the font doesn't load quickly enough the first time, it won't be displayed at all. The second time the user visit the page, the font should be in cache and loaded almost instantly. I don't say this should be an option in the WP Rocket Options, it's up to you to evaluate that. I just say it's difficult to make the choice for the end-client. Thanks for reading 🙂"
178516,198464,https://api.github.com/repos/ehang-io/nps/issues/698,enhancement,2020-11-27T09:01:19Z,NONE,https://api.github.com/repos/ehang-io/nps,"如何从源码自己编译npc/nps 想打个log看下异常情况，想加log,client文件夹里面没有发现main方法。 不会编译~"
147388,163824,https://api.github.com/repos/arturo-lang/arturo/issues/55,enhancement,2021-01-19T09:23:38Z,COLLABORATOR,https://api.github.com/repos/arturo-lang/arturo,"Label PRs automatically This can be easily done with an action like: https://github.com/actions/labeler The `.github/labeler.yml` file already exists, but unless there is a proper workflow set up, it's not going to work. "
263638,293206,https://api.github.com/repos/AR-js-org/AR.js/issues/214,question,2021-01-24T10:27:50Z,NONE,https://api.github.com/repos/AR-js-org/AR.js,"Nft pattern creation is slow with nodejs marker creator but fast with web marker creator **Do you want to request a *feature* or report a *bug*?** bug **What is the current behavior?** If I try to create a marker from a 2000x2000 hiro image it takes 10min with nodejs version (https://github.com/Carnaux/NFT-Marker-Creator) but only a few second with web version (https://carnaux.github.io/NFT-Marker-Creator/) **If the current behavior is a bug, please provide the steps to reproduce.** Create a 2000x2000 image from hiro and use the creators. **Please mention other relevant information such as the browser version, Operating System and Device Name** windows 10, google chrome, the nodejs version tried in linux **What is the expected behavior?** The nodejs marker creator creates marker fast like the web version. "
202795,225500,https://api.github.com/repos/saschadiercks/personalNews/issues/19,enhancement,2020-12-09T19:02:19Z,OWNER,https://api.github.com/repos/saschadiercks/personalNews,"Add pull to refresh Add pull to refresh, so users using this as a PWA can easily refresh the conten"
356468,396287,https://api.github.com/repos/maxtheaxe/pollen/issues/8,enhancement,2021-03-15T18:01:07Z,OWNER,https://api.github.com/repos/maxtheaxe/pollen,message composition backend connection only needs to pass in (and probably verify) message details to appropriate backend component upon pressing send button
32973,36747,https://api.github.com/repos/Anuken/Mindustry/issues/5123,bug,2021-04-18T14:47:27Z,NONE,https://api.github.com/repos/Anuken/Mindustry,"Cannot Click Anything **Platform**: Windows 64-bit **Build**: Release 126.2 **Issue**: I possess an issue rendering the game unplayable: I must click every menu option multiple times within a specific area for anything to occur. I can scroll by dragging in options, and select sliders normally, however. I downloaded both via Steam and Itch.io, but to no avail. **Steps to reproduce**: Play the game. **Link(s) to mod(s) used**: N/A **Save file**: I have never begun a game. The issue initiates immediately upon opening and loading the main menu. **(Crash) logs**: N/A --- *Place an X (no spaces) between the brackets to confirm that you have read the line below.* - [x] **I have updated to the latest release (https://github.com/Anuken/Mindustry/releases) to make sure my issue has not been fixed.** - [X] **I have searched the closed and open issues to make sure that this problem has not already been reported.** "
183534,204030,https://api.github.com/repos/PluginBugs/Issues-ItemsAdder/issues/704,bug,2021-02-23T11:52:22Z,NONE,https://api.github.com/repos/PluginBugs/Issues-ItemsAdder,"[BUG] Server Resouce Packs: Prompt - Not working **Describe the bug** If server added client as ""Server Resouce Packs: Prompt"" pack.zip will not downloaded. If admin type /iatexture or /iatexture all prompt screen is coming. Clicking yes will download the pack.zip and working fine after. **To Reproduce** Join the server **Expected behavior** Ask client Prompt when join. This is bug ? Or all users have to set ""Server Resouce Packs: Enabled"""
690190,767084,https://api.github.com/repos/danye72/smarther-v1/issues/3,bug,2021-05-06T15:55:36Z,COLLABORATOR,https://api.github.com/repos/danye72/smarther-v1,The folder config/smarther is not created with the first run of the update command The folder config/smarther is not created with the first run of the update command
635114,705889,https://api.github.com/repos/robertwitt/TODOer/issues/21,enhancement,2021-04-10T18:44:48Z,OWNER,https://api.github.com/repos/robertwitt/TODOer,Read TaskList API - [x] Implement TaskList model - [x] Describe path in Open API spec - [x] Enhance repository - [x] Enhance domain service - [x] Implement middleware
531676,590929,https://api.github.com/repos/hovancik/stretchly/issues/453,enhancement,2019-08-19T10:55:28Z,NONE,https://api.github.com/repos/hovancik/stretchly,"Screen option Hello, Can you add an option to choose which monitor will display the alert? Bcs the alert pop up on my 2 monitors and it would be great choose it! Thank you"
111551,123991,https://api.github.com/repos/dotnet/aspnetcore/issues/28131,enhancement,2020-11-25T01:29:43Z,NONE,https://api.github.com/repos/dotnet/aspnetcore,Add password history check in the asp.net core identity I found the asp.net core identity doesn't check the password history when you change the password. I suggest that we could add this feature in the identity as a opinion. 
13741,15307,https://api.github.com/repos/TeamNewPipe/NewPipe/issues/5612,bug,2021-02-17T08:35:18Z,NONE,https://api.github.com/repos/TeamNewPipe/NewPipe,"video description not shown for any video since the 0.20 update on android tablet no video description is shown for any video I tried. <!-- IF YOU DON'T FILL IN THE TEMPLATE PROPERLY, YOUR ISSUE IS LIABLE TO BE CLOSED. If you feel tired/lazy right now, open your issue some other time. We'll wait. --> <!-- The comments between these brackets won't show up in the submitted issue (as you can see in the Preview). --> ### Checklist <!-- This checklist is COMPULSORY. The first box has been checked for you to show you how it is done. --> - [x] I am using the latest version - 0.20.10 - [x] I checked, but didn't find any duplicates (open OR closed) of this issue in the repo. <!-- Seriously, check. O_O --> - [x] I have read the contribution guidelines given at https://github.com/TeamNewPipe/NewPipe/blob/HEAD/.github/CONTRIBUTING.md. - [x] This issue contains only one bug. I will open one issue for every bug report I want to file. ### Steps to reproduce the bug open any video, click on the 'v' symbol. ### Actual behaviour only the ""share""-icon and the ""open in browser""-icon appears. ### Expected behavior video description schould be shown ### Screenshots/Screen recordings example: https://m.youtube.com/watch?v=QKdLP1cP3Dg Tablet newpipe: ![grafik](https://user-images.githubusercontent.com/1601159/108177087-1076e500-7103-11eb-9cf6-8937a6f0b1c9.png) Tablet Browser: ![grafik](https://user-images.githubusercontent.com/1601159/108177215-38664880-7103-11eb-950f-aacc6e2ef8d1.png) ### Logs <!-- If your bug includes a crash (where you're shown the Error Report page with a bunch of info), tap on ""Copy formatted report"" at the bottom and paste it here: --> <!-- That's right, here! --> <!-- Please fill this out when you do not provide a log generate by NewPipe --> ### Device info - Android version/Custom ROM version: 8.0.0 - Device model: huawei BAH2-W19 "
590251,655933,https://api.github.com/repos/inonoob/pirowflo/issues/12,bug,2021-02-03T20:41:07Z,OWNER,https://api.github.com/repos/inonoob/pirowflo,"SmartRow if rower stop values don't go to zero With the SmartRow configuration, if the rower is at full stop the following values must be set to 0 like it is done with the S4 monitor code def WRvalueStandstill(self): self.WRvalue_standstill = self.WRValues self.WRvalue_standstill.update({'stroke_rate': 0}) self.WRvalue_standstill.update({'instantaneous pace': 0}) self.WRvalue_standstill.update({'speed': 0}) self.WRvalue_standstill.update({'watts': 0})"
283974,315812,https://api.github.com/repos/airyhq/airy/issues/1236,bug,2021-03-12T15:48:28Z,CONTRIBUTOR,https://api.github.com/repos/airyhq/airy,SearchFields in filter for conversations in inbox are not displayed properly and not all names are displayed ![Screenshot 2021-03-12 at 12 30 27](https://user-images.githubusercontent.com/49147864/110963142-033fc580-8352-11eb-8a3a-22d8e05a3a79.png) 
147668,164141,https://api.github.com/repos/VictorElexpe/mejorarLaUni/issues/11,enhancement,2021-01-18T23:13:47Z,OWNER,https://api.github.com/repos/VictorElexpe/mejorarLaUni,"Add feedback on failed login Display some information when a user has introduced a wrong password. Tried before. Unlucky. ### Main problems? - Alert info when failed auth keeps being displayed after a succesful login - Need to figure out how to use DOM, javascript and React (Next.js) ### Where? - We want to implement this feature in the navBar component. ### Possible solution? - Implement a timeout to make the alert dissapear by itself. - Maybe [this](https://jasonwatmore.com/post/2020/04/11/react-hooks-bootstrap-alert-notifications)? Left to be implement. TO-DO."
46406,51651,https://api.github.com/repos/cyrus-and/gdb-dashboard/issues/239,question,2021-05-14T21:13:34Z,NONE,https://api.github.com/repos/cyrus-and/gdb-dashboard,"[Question] Display layout in a vertical split. I'm using just the output and the source sections, is there a way I can view them in a veritical split window? (same terminal)"
134242,149214,https://api.github.com/repos/ministryofjustice/laa-court-data-adaptor/issues/426,bug,2021-02-26T18:26:51Z,NONE,https://api.github.com/repos/ministryofjustice/laa-court-data-adaptor,"NoMethodError: undefined method `positive?' for nil:NilClass Sentry Issue: [LAA-COURT-DATA-ADAPTOR-Z](https://sentry.io/organizations/ministryofjustice/issues/2066113679/?referrer=github_integration) ``` NoMethodError: undefined method `positive?' for nil:NilClass app/services/api/search_prosecution_case.rb:16:in `successful_response?' response.status == 200 && response.body[""totalResults""].positive? app/services/api/search_prosecution_case.rb:10:in `call' record_search_results if successful_response? app/services/application_service.rb:5:in `call' new(*args, &block).call app/controllers/api/internal/v1/prosecution_cases_controller.rb:8:in `index' @prosecution_cases = Api::SearchProsecutionCase.call(transformed_params) ... (66 additional frame(s) were not displayed) ```"
682649,758705,https://api.github.com/repos/microsoft/vscode-cmake-tools/issues/1787,bug,2021-04-20T14:20:48Z,NONE,https://api.github.com/repos/microsoft/vscode-cmake-tools,"Wrong evaluation of CMakePresets.json https://github.com/microsoft/vscode-cmake-tools/blob/develop/docs/cmake-presets.md#supported-cmake-and-cmakepresetsjson-versions says ""CMake Tools reads and evaluates CMakePresets.json and CMakeUserPresets.json, and does not invoke CMake directly with the --preset option."", unfortunately with CMake Tools 1.7.0 the evaluation is not equivalent to the one done by CMake. https://cmake.org/cmake/help/latest/manual/cmake-presets.7.html#macro-expansion says ""All macros are evaluated in the context of the preset being used, even if the macro is in a field that was inherited from another preset."". And when using ``` { ""version"": 2, ""cmakeMinimumRequired"": { ""major"": 3, ""minor"": 20, ""patch"": 0 }, ""configurePresets"": [ { ""name"": ""Base"", ""hidden"": true, ""generator"": ""Ninja"", ""binaryDir"": ""build/${presetName}"" }, { ""name"": ""Complete"", ""inherits"": ""Base"" } ] } ``` and using the ""Complete"" preset CMake Tools uses `build/Base` as binaryDir while CMake uses `build/Complete`. "
400187,444789,https://api.github.com/repos/jjburton/cgmTools/issues/198,enhancement,2021-02-01T10:59:26Z,COLLABORATOR,https://api.github.com/repos/jjburton/cgmTools,"Pipeline - Project. Adding empty.txt to folders for gitHub to recognise the folder Unfortunatly gitHub will not identify empty folders. Can we add, on verifying the folder drivers for export, create an empty.txt file so that gitHub will pick up the folders?"
528673,587593,https://api.github.com/repos/ray-project/ray/issues/15077,bug,2021-04-02T00:28:32Z,CONTRIBUTOR,https://api.github.com/repos/ray-project/ray,"[core] Raylet crashes during task retry. Check failed: overflow_cpu_instances[i] == 0 Should not be overflow <!--Please include [tune], [rllib], [autoscaler] etc. in the issue title if relevant--> ### What is the problem? *Ray version and other system information (Python version, TensorFlow version, OS):* 2.0dev If a task submits another task and then fails, there is an assertion check that crashes the raylet. ### Reproduction (REQUIRED) Please provide a short code snippet (less than 50 lines if possible) that can be copy-pasted to reproduce the issue. The snippet should have **no external library dependencies** (i.e., use fake or mock data / environments): This script works if the child task is killed and crashes if the parent task is killed. ```python import ray import signal import os import time TEST_ARGS = True KILL_PARENT = True @ray.remote class PidActor: def __init__(self): self.child_pid = None self.parent_pid = None def set_child_pid(self, pid): if self.child_pid is None: self.child_pid = pid def get_child_pid(self): return self.child_pid def set_parent_pid(self, pid): if self.parent_pid is None: self.parent_pid = pid def get_parent_pid(self): return self.parent_pid @ray.remote def child(pid_actor, ref): pid_actor.set_child_pid.remote(os.getpid()) time.sleep(3) @ray.remote def parent(pid_actor): pid_actor.set_parent_pid.remote(os.getpid()) if TEST_ARGS: x = ray.put(""x"" * 1000000) else: x = ""x"" ray.get(child.remote(pid_actor, x)) ray.init() pid_actor = PidActor.remote() p = parent.remote(pid_actor) pid = None while pid is None: if KILL_PARENT: pid = ray.get(pid_actor.get_parent_pid.remote()) else: pid = ray.get(pid_actor.get_child_pid.remote()) time.sleep(1) os.kill(pid, signal.SIGKILL) ray.get(p) ``` If the code snippet cannot be run by itself, the issue will be closed with ""needs-repro-script"". - [x] I have verified my script runs in a clean environment and reproduces the issue. - [x] I have verified the issue also occurs with the [latest wheels](https://docs.ray.io/en/master/installation.html). "
380579,423082,https://api.github.com/repos/robburger/terraform-pr-commenter/issues/6,bug,2021-01-30T12:35:27Z,NONE,https://api.github.com/repos/robburger/terraform-pr-commenter,"Error: Argument list too long Hi! First of all, thanks for the great tool. Been using it for few days and really digging it. I'm trying to publish a plan output of a larger environment, but I get an error ""Error: Argument list too long"". The plan output is around ~2800 rows long."
548955,610122,https://api.github.com/repos/bytedance/IconPark/issues/128,bug,2021-01-21T07:26:25Z,CONTRIBUTOR,https://api.github.com/repos/bytedance/IconPark,"Vue Icon Park 使用文档描述问题 环境: * node@14.15.1 * npm@6.14.8 * vue@2.6.12 按照文档使用 ![image](https://user-images.githubusercontent.com/14804014/105317241-f11c9300-5bfc-11eb-9a7a-86cee2b16b47.png) 执行报错 ![image](https://user-images.githubusercontent.com/14804014/105316394-c251ed00-5bfb-11eb-8155-960ad8b7fb95.png) 检查发现 `all.ts` 中 ```typescript if (!(type in IconMap)) { throw new Error(`${type} is not a valid icon type name`); } ``` 解决方法，`type` 应该为大写，和 `IconType ` 一样 ```html <icon-park type=""Home"" theme=""filled""/> ``` 最后建议 * 修改文档为大写写法 或者 * 支持 `x-y` 这样的写法，和 官网图标 name 一致 就我个人而言，我更习惯于第二种 "
98601,109559,https://api.github.com/repos/JSTOR-Labs/plant-humanities/issues/108,bug,2021-02-08T18:54:24Z,COLLABORATOR,https://api.github.com/repos/JSTOR-Labs/plant-humanities,Italics in map titles I am still seeing underscores in map titles instead of italicized formatting (see Boxwood paragraph 4.
262613,292063,https://api.github.com/repos/Unity-Technologies/arfoundation-samples/issues/755,bug,2021-03-03T10:11:52Z,NONE,https://api.github.com/repos/Unity-Technologies/arfoundation-samples,"[Bug] iOS build of Image Tracking scenes not working - Tracking images seemingly not recognized **Unity bug report case number** n/a **Describe the bug** Sample app's Image Tracking scenes don't seem to work on iPad Air 4th Gen. Camera seems fine, but it doesn't recognize the ""1"", ""2"" or ""Rafflesia"" sample images. **To Reproduce** Steps to reproduce the behavior: 1. Build to iOS 2. Copy to MacBook 3. chmod +x on build 4. import into xcode 5. set up auto-certificate signing 6. set destination to iPad (Air 4th Gen) 7. Run 8. All scenes seem functional except the image tracking scenes (single tracker & multi-tracker) **Expected behavior** Camera scans image - 3D asset laid over the tracker image (Android build seems fine) **Actual behavior** Camera scans image(s) but doesn't seem to recognize the images **Smartphone (please complete the following information):** - Device: iPad (Air 4th Gen) - OS: latest - Unity version 2020.2.1f1 - ARFoundation version 4.1.3 "
680083,755826,https://api.github.com/repos/terraform-providers/terraform-provider-azurerm/issues/11836,enhancement,2021-05-24T09:32:10Z,NONE,https://api.github.com/repos/terraform-providers/terraform-provider-azurerm,"Support for Service Tags on azurerm_route_table routes <!--- Please keep this note for the community ---> ### Community Note * Please vote on this issue by adding a 👍 [reaction](https://blog.github.com/2016-03-10-add-reactions-to-pull-requests-issues-and-comments/) to the original issue to help the community and maintainers prioritize this request * Please do not leave ""+1"" or ""me too"" comments, they generate extra noise for issue followers and do not help prioritize the request * If you are interested in working on this issue or have submitted a pull request, please leave a comment <!--- Thank you for keeping this note for the community ---> ### Description Support for Service Tags in Route Table routes address prefix argument, similar functionality to NSG Rules. ### New or Affected Resource(s) <!--- Please list the new or affected resources and data sources. ---> * azurerm_route_table ### Potential Terraform Configuration <!--- Information about code formatting: https://help.github.com/articles/basic-writing-and-formatting-syntax/#quoting-code ---> ```hcl resource ""azurerm_route_table"" ""example"" { name = ""acceptanceTestSecurityGroup1"" location = azurerm_resource_group.example.location resource_group_name = azurerm_resource_group.example.name disable_bgp_route_propagation = false route { name = ""route1"" address_prefix = ""BatchNodeManagement"" next_hop_type = ""vnetlocal"" } tags = { environment = ""Production"" } } ``` ### References https://azure.microsoft.com/en-gb/updates/public-preview-service-tags-for-user-defined-routing/ NSG Rules Tags: https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/network_security_group#source_address_prefix * #0000 "
269034,299191,https://api.github.com/repos/libsdl-org/SDL/issues/1952,bug,2021-02-11T00:07:05Z,COLLABORATOR,https://api.github.com/repos/libsdl-org/SDL,"CMake project never enables xinput support on Windows # This bug report was migrated from our old Bugzilla tracker. **Reported in version:** HG 2.0 **Reported for operating system, platform:** Windows (All), All # Comments on the original bug report: On 2015-08-21 02:58:43 +0000, Alex Szpakowski wrote: > When using the CMake project to build SDL on Windows, it is never able to find xinput.h and so prevents the xinput gamepad support from being compiled. > > The cmake configuration gives this output: > > -- Looking for xinput.h > -- Looking for xinput.h - not found > > The rest of the windows/directx-related headers are found successfully. > > xinput.h definitely exists in the expected locations on my system - the Visual Studio project seems to find it fine and builds SDL's xinput code successfully. (My Xbox 360 gamepad is registered as an xinput gamecontroller when using the VS project, but isn't when using CMake.) > > Tested using VS2013, running Windows 8.1. On 2015-08-28 22:06:08 +0000, Alex Szpakowski wrote: > This commit should fix it: https://hg.libsdl.org/SDL/rev/3d08cb641cd5 "
625154,694751,https://api.github.com/repos/neilotoole/sq/issues/90,bug,2021-03-11T20:00:17Z,NONE,https://api.github.com/repos/neilotoole/sq,"MySQL driver options are stripped during ""add"" Trying to add a MySQL host with old passwords: sq add --handle=@segv 'mysql://user:password@host/database?allowOldPasswords=1' sq: failed to ping @segv [mysql://segv:****@segvdb/segv]: this user requires old password authentication. If you still want to use it, please add 'allowOldPasswords=1' to your DSN. See also https://github.com/go-sql-driver/mysql/wiki/old_passwords Stepping through the code shows this line: https://github.com/neilotoole/sq/blob/b7cb0a0b66a981e5c4d16b7f533eeb241d4c1f04/drivers/mysql/mysql.go#L410 resulting a dsn of: ""user:password@tcp(host)/database"" It is possible that I'm misunderstanding how to add driver options."
497176,552587,https://api.github.com/repos/SinEstresOrrantia/strezless_musick_productionz/issues/5,enhancement,2021-04-08T19:36:32Z,OWNER,https://api.github.com/repos/SinEstresOrrantia/strezless_musick_productionz,"Strezless Practice // ... { ""type"": ""articles"", ""id"": ""1"", ""attributes"": { ""title"": ""Rails is Omakase"" }, ""relationships"": { ""author"": { ""links"": { ""self"": ""/articles/1/relationships/author"", ""related"": ""/articles/1/author"" }, ""data"": { ""type"": ""people"", ""id"": ""9"" } } } } // ..."
283075,314801,https://api.github.com/repos/dyl10s/TimeTracker/issues/56,enhancement,2021-02-21T16:01:21Z,OWNER,https://api.github.com/repos/dyl10s/TimeTracker,Investigate slow build times for the frontend CI of the application When the CI build is running the frontend build is really slow. We should swap this to a nonproduction build
680337,756097,https://api.github.com/repos/ralphlange/opcua/issues/101,enhancement,2021-04-11T12:19:01Z,OWNER,https://api.github.com/repos/ralphlange/opcua,"Simplify and improve iocShell interface to show() routines Just one iocShell command: `opcuaShow`. Support wildcard patterns using '*' and '?'. Search for names in sessions, subscriptions and record names."
363634,404242,https://api.github.com/repos/kframework/k/issues/1850,bug,2021-03-11T16:05:58Z,CONTRIBUTOR,https://api.github.com/repos/kframework/k,"[Bug] krun - --dry-run doesn't save temporary files K Version --------- ``` $ kompile --version RV-K version 1.0-SNAPSHOT Git revision: 4c3c90e Git branch: add-ref-default.nix Build date: Tue Mar 30 14:29:27 EEST 2021 ``` Description ----------- Running `krun` with `--dry-run` prints a command that can't be executed because some temporary files are missing. But those files are present after executing the command with `--save-temps`. Input Files ----------- File: `test.k` ``` module TEST imports INT syntax FOO ::= ""foo"" configuration <k> foo ~> $PGM:Int </k> rule <k> foo => #Bottom ... </k> endmodule ``` File: `2.test` ``` 1 ``` Reproduction Steps ------------------ ``` $ kompile --backend haskell -d . test.k [Warning] Compiler: Could not find main syntax module with name TEST-SYNTAX in definition. Use --syntax-module to specify one. Using TEST as default. $ krun --search-final --dry-run --haskell-backend-command /home/andrei/kore/.build/kore/bin/kore-exec -d . 2.test /home/andrei/kore/.build/kore/bin/kore-exec ./test-kompiled/definition.kore --module TEST --pattern .krun-2021-03-11-17-48-49-xUJZdjQeBL/tmp.in.zXImruBIo3 --output .krun-2021-03-11-17-48-49-xUJZdjQeBL/result.kore --searchType FINAL --search .krun-2021-03-11-17-48-49-xUJZdjQeBL/tmp.pattern.PmSzl0lJTD ``` Then execute the resuled command. In this case it's ``` $ /home/andrei/kore/.build/kore/bin/kore-exec ./test-kompiled/definition.kore --module TEST --pattern .krun-2021-03-11-17-48-49-xUJZdjQeBL/tmp.in.zXImruBIo3 --output .krun-2021-03-11-17-48-49-xUJZdjQeBL/result.kore --searchType FINAL --search .krun-2021-03-11-17-48-49-xUJZdjQeBL/tmp.pattern.PmSzl0lJTD .krun-2021-03-11-17-48-49-xUJZdjQeBL/tmp.pattern.PmSzl0lJTD: copyFile:atomicCopyFileContents:withReplacementFile:copyFileToHandle:openBinaryFile: does not exist (No such file or directory) ``` Expected Behavior ----------------- The command printed by using `--dry-run` should give the same result as ``` $ krun --search-final --haskell-backend-command /home/andrei/kore/.build/kore/bin/kore-exec -d . 2.test ``` which is ``` #Bottom ```"
258454,287441,https://api.github.com/repos/pyccel/pyccel/issues/825,bug,2021-03-29T11:24:47Z,NONE,https://api.github.com/repos/pyccel/pyccel,"obscure error message when a function argument is missing **Describe the bug** When a function is called with one (or more) argument(s) missing, the error message is obscure **To Reproduce** Provide code to reproduce the behavior: ```python def f(b:'int'): print(b) def g(a:'int'): f() ``` Provide the generated code, or the error message: ``` ERROR at code generation stage pyccel: |fatal [codegen]: ***.py| Pyccel has encountered syntax that has not been implemented yet. Please create an issue at https://github.com/pyccel/pyccel/issues and provide a small example of your problem. Do not forget to specify your target language ``` **Expected behavior** The error message should indicate that an argument is missing (and where) **Language** Fortran and c "
228580,254203,https://api.github.com/repos/kingkevin05/taskinator/issues/3,enhancement,2021-02-22T16:35:28Z,OWNER,https://api.github.com/repos/kingkevin05/taskinator,Change Task ## Requirements * Add two status task lists * Add buttons to change tasks * Delete a task * Edit a task * Add drop down menu to change task status * Move task based on status task list
110853,123217,https://api.github.com/repos/BarryCap/BarryCap.github.io/issues/1,bug,2021-01-04T07:51:34Z,OWNER,https://api.github.com/repos/BarryCap/BarryCap.github.io,"Favicon's not working The new favicon **is not working on Chrome and in other browsers**. Inexplicably, it works perfectly on Firefox and Edge. Maybe it's due to compression (even if PNG compression is only used for the included big images). Or maybe Chrome doesn't support 512p favicons."
144224,160317,https://api.github.com/repos/Bisaloo/fundiversity/issues/12,enhancement,2020-12-15T16:25:53Z,COLLABORATOR,https://api.github.com/repos/Bisaloo/fundiversity,Warn user when computing FRic with many species/many traits `geometry::convhulln()` used in `fd_fric()` has some limitation in data size. In order to avoid wasting computer time we should probably issue a warning for large size datasets (many species × many traits) to say that the computation may fail in this case.
580439,645004,https://api.github.com/repos/CdHebert/weather-app/issues/1,enhancement,2021-04-20T20:07:52Z,OWNER,https://api.github.com/repos/CdHebert/weather-app,get api fetch request to work description add fetch api request make request work properly
114099,126791,https://api.github.com/repos/disclave/disclave/issues/125,bug,2021-04-12T14:22:25Z,MEMBER,https://api.github.com/repos/disclave/disclave,Long URL display problem on mobile Using PWA: ![Screenshot_20210412-162130.jpg](https://user-images.githubusercontent.com/9074960/114409949-4092af80-9bab-11eb-9d72-35b321f8e05e.jpg)
559509,621812,https://api.github.com/repos/ahmedkaludi/accelerated-mobile-pages/issues/4879,bug,2020-12-18T09:53:26Z,COLLABORATOR,https://api.github.com/repos/ahmedkaludi/accelerated-mobile-pages,Validation Errors when WP Daddy Builder Pro is active https://secure.helpscout.net/conversation/1365177499/170109/
407697,453164,https://api.github.com/repos/weacast/weacast-core/issues/36,bug,2021-04-29T07:35:34Z,MEMBER,https://api.github.com/repos/weacast/weacast-core,"$geoNear, $near, and $nearSphere are not allowed in this context ### Steps to reproduce Issue a request on e.g. probe results using the following parameters: ```js query.geometry = { $near: { $geometry: [long, lat], $maxDistance: 1000 } } ``` ### Expected behavior We should get results near the target location. ### Actual behavior The following error is raised: `$geoNear, $near, and $nearSphere are not allowed in this context`. Related to https://github.com/feathersjs-ecosystem/feathers-mongodb/issues/185 and could be fixed by either upgrading feathers-mongodb or using [$geoWithin](https://docs.mongodb.com/manual/reference/method/db.collection.countDocuments/#query-restrictions) instead. ### System configuration Tell us about the applicable parts of your setup. **Operating System**: Windows **Module versions**: 1.4 **NodeJS version**: 12 "
536531,596316,https://api.github.com/repos/nf-core/ampliseq/issues/133,enhancement,2020-02-20T14:49:09Z,CONTRIBUTOR,https://api.github.com/repos/nf-core/ampliseq,"Input Manifest format validation Hi, As of commit 7c589af , nf-core/dev can accept manifest files as input instead of read files. Such manifest has very strict requirements: must be tab-separated, have exactly the following 3 labels in the same ordes: sampleID, forwardReads, reverseReads. @drpatelh 's idea is to add a single process that checks the design file and (possibly) reformats it to suit the requirements of the pipeline. Something like [this example](https://github.com/nf-core/atacseq/blob/fa1e3f8993cd20e249b9df09d29c5498eff311d2/main.nf#L308-L322). By executing a [single script written in Python](https://github.com/nf-core/atacseq/blob/master/bin/check_design.py), the example simply avoids confusion in the manifest file format, for example with name variables, merging across lanes etc if you use both `--manifest` and `--reads`. The validation script decides what the names look like and avoids typo errors. "
608652,676388,https://api.github.com/repos/ctoec/data-collection/issues/1154,bug,2021-02-04T16:14:19Z,MEMBER,https://api.github.com/repos/ctoec/data-collection,"Not all funding spaces are correctly marked in change request form ## Background from user: > I noticed that our funding for School Readiness was not checked on the Home Page regarding Sites/Funding. Not sure if this has anything to do with the children not showing, but I did just make that change and checked the SR box. confirmed in prod, CDC spaces are checked, PSR and CSR are not All funding spaces exist in DB ## Acceptance Criteria - PSR AND CSR fundings are appropriately checked if organization has them - `Request updated name` becomes `Request site name change` in the site change form (Users seem confused and a few put their own names in there) - ChangeFundingSpaceRequest tracks funding_space id in addition to the funding space string (optional FK for existing funding spaces!) - If possible, we only write rows that are diff from existing state (either when a funding space should be added or removed)"
104892,116563,https://api.github.com/repos/pekrau/Anubis/issues/330,enhancement,2021-02-18T16:20:56Z,OWNER,https://api.github.com/repos/pekrau/Anubis,"Collaborator field in grant Simplify this process: We kindly ask you to: 1. State name and email address of all collaborators (if any) in the approved project “grant dossier” in Anubis. 2. Forward the attached documents to all project collaborators 3. Make sure that all the collaborators upload: a. template.xlxs), that specify the budget for her/his part of the project b. namn på dok villkorsbilaga.pdf). Condition for funding (edited) "
434720,483279,https://api.github.com/repos/phelewski/aws-codepipeline-dashboard/issues/3,enhancement,2021-05-21T11:54:05Z,OWNER,https://api.github.com/repos/phelewski/aws-codepipeline-dashboard,Create easy way for new developers to contribute to the project There should be a way to setup and work on the project in a repeatable manor across several developer platforms. This would allow more people to contribute for new feature requests and bug fixes. This should be something simple like using `Pipenv` to create and maintain the virtual environment.
358900,399004,https://api.github.com/repos/adhdtech/DRP/issues/166,enhancement,2021-05-30T19:33:54Z,OWNER,https://api.github.com/repos/adhdtech/DRP,"DRP Shell - Stream Watch add target node option When watching a stream, add option to specify a target node instead of a scope. This way the user can watch local and non-advertised streams on remote nodes."
557445,619540,https://api.github.com/repos/Etimo/etimo-id/issues/51,enhancement,2021-01-14T19:48:39Z,CONTRIBUTOR,https://api.github.com/repos/Etimo/etimo-id,"Make ReSharper in Visual Studio respect the .editorconfig When opening the solution in Visual Studio 2019 with ReSharper, there are a lot of errors regarding code style. We want ReSharper to respect the .editorconfig file. Is it missing settings or can ReSharper be configured to respect it fully?"
134702,149744,https://api.github.com/repos/UnigramDev/Unigram/issues/2240,bug,2021-02-12T21:05:11Z,COLLABORATOR,https://api.github.com/repos/UnigramDev/Unigram,"""is speaking"" indicator in group calls is inaccurate I often happen to see that no-one is talking from the members list, but there is one person or more people talking in that moment."
274303,305061,https://api.github.com/repos/catima/catima/issues/300,bug,2021-01-06T13:58:27Z,CONTRIBUTOR,https://api.github.com/repos/catima/catima,"Style inconsistencies Style inconsistencies due to the bootstrap update. - Menu - Data edition mode - Bookmarks We'll update this issue if we find more style inconsistencies. <img width=""2296"" alt=""menu"" src=""https://user-images.githubusercontent.com/1675064/103775737-c80dd700-502e-11eb-9cb7-41fc9aa9f7d0.png""> <img width=""2763"" alt=""data_overflow"" src=""https://user-images.githubusercontent.com/1675064/103775748-ca703100-502e-11eb-90d6-f5ccb8b1d55b.png""> <img width=""2395"" alt=""fav"" src=""https://user-images.githubusercontent.com/1675064/103775755-ce03b800-502e-11eb-8225-d9ba3a346e64.png""> "
651210,723890,https://api.github.com/repos/sul-dlss/dor-services-app/issues/1312,bug,2020-11-03T22:09:32Z,CONTRIBUTOR,https://api.github.com/repos/sul-dlss/dor-services-app,"FromFedora mapping error: #/components/schemas/DescriptiveStructuredValue does not allow null values ``` Error: #/components/schemas/DescriptiveStructuredValue does not allow null values (2 errors) ``` Examples: druid:bm056hv8204, druid:pp689kh8248"
529464,588481,https://api.github.com/repos/GoZaddy/buycoins_sdk/issues/9,enhancement,2021-02-04T06:38:10Z,OWNER,https://api.github.com/repos/GoZaddy/buycoins_sdk,Write methods for the BuycoinsSDK class Write methods for the BuycoinsSDK class. This method should make use of the classes from issue #8 in its return values
675196,750424,https://api.github.com/repos/AlbertSuarez/object-cut/issues/7,bug,2021-04-09T08:45:24Z,OWNER,https://api.github.com/repos/AlbertSuarez/object-cut,"bug: Rotation based on meta-data **Describe the bug** Images with rotation meta-data should be rotated since currently every viewer tool display images in the correct rotation, which then ObjectCut is outputting the processed image rotated, which confuses the end-user. **To Reproduce** Based on the [maracuja](https://rapidapi.com/user/maracuja) request on the [RapidAPI discussion thread](https://rapidapi.com/objectcut.api/api/background-removal/discussions?issueId=21144&issueTitle=Image-90%C2%B0-oriented-(rotation)), sending an image meta-data rotated is outputting a result image with a different rotation. **Expected behavior** ObjectCut should return the image in the correct rotation, if possible. **Screenshots** This can be found in the RapidAPI thread specified above. **Additional context** None. "
319842,355570,https://api.github.com/repos/olivierkes/manuskript/issues/734,question,2020-02-07T18:53:23Z,NONE,https://api.github.com/repos/olivierkes/manuskript,Creating multiple worlds I am working on a trilogy that has multiple worlds. Is there a way to create multiple worlds with this program? Based on what I am seeing it cannot be done. Does anyone have a suggestion?
651985,724759,https://api.github.com/repos/comic/grand-challenge.org/issues/1476,bug,2020-08-20T10:02:38Z,MEMBER,https://api.github.com/repos/comic/grand-challenge.org,"retina_api.tasks.cache_archive_data performs too many queries There is a periodic very high read load on the database, I've tracked this down to the task `retina_api.tasks.cache_archive_data`, which creates a lot of queries, and almost exhausts our provisioned IOPS when running: https://sentry.io/organizations/grand-challenge/performance/summary/?project=303639&query=&statsPeriod=30d&transaction=grandchallenge.retina_api.tasks.cache_archive_data Please use `select_related` or `prefetch_related`, in pytest you have access to the assert (max) num queries fixtures https://pytest-django.readthedocs.io/en/latest/helpers.html#django_assert_num_queries that can help with reducing this."
331725,368792,https://api.github.com/repos/syslog-ng/syslog-ng/issues/3678,question,2021-05-17T09:55:23Z,NONE,https://api.github.com/repos/syslog-ng/syslog-ng,"Where to check syslog_facility_code and syslog_severity_code I am sending logs to syslog-ng and then kafka but it is showing me only that log which has facility code 1 and severity code 5, i am seeing on kafka side when consumer pulls the messages. In client side(source side) i provided only `ip:514` is there any option so that i can check that i am consuming all the messages of client.Because it showing me only user-level (facility code 1) and severity code 5 my syslog-ng conf file ``` @version: 3.30 @include ""scl.conf"" #@module mod-java @define kafka-implementation kafka-c # syslog-ng configuration file. # # This should behave pretty much like the original syslog on RedHat. But # it could be configured a lot smarter. # # See syslog-ng(8) and syslog-ng.conf(5) for more information. # # Note: it also sources additional configuration files (*.conf) # located in /etc/syslog-ng/conf.d/ options { flush_lines (0); time_reopen (10); log_fifo_size (1000); chain_hostnames (off); use_dns (no); use_fqdn (no); create_dirs (no); keep_hostname (yes); }; source s_network { network( transport(""udp"") port(514) ); }; rewrite r_rewrite_set { set( ""pfsense"", value(""tags"") ); }; destination d_kafka { kafka ( bootstrap-servers(""kafka_ip:9092"") topic(""pfsense"") message(""$(format-json time=$ISODATE tags host=$HOST message='${MSGHDR}${MSG}')"") ); }; log{ source(s_network); rewrite(r_rewrite_set); destination(d_kafka); }; # Source additional configuration files (.conf extension only) @include ""/etc/syslog-ng/conf.d/*.conf"" # vim:ft=syslog-ng:ai:si:ts=4:sw=4:et: ```"
53980,60057,https://api.github.com/repos/Informasjonsforvaltning/dataset-catalog-gui/issues/152,bug,2021-05-11T11:48:21Z,CONTRIBUTOR,https://api.github.com/repos/Informasjonsforvaltning/dataset-catalog-gui,"Listen for oppdateringsfrekvens vises på engelsk I datasett registrering er hele løsningen på norsk bokmål, men listen til oppdateringsfrekvens vises på engelsk, denne bør endres til norsk. ![image.png](https://images.zenhubusercontent.com/5f9a823ccff8726db3db553b/a2d15971-fbde-430f-887e-594776fc31a4)"
710060,789168,https://api.github.com/repos/gem/oq-engine/issues/6695,bug,2021-04-15T11:17:39Z,MEMBER,https://api.github.com/repos/gem/oq-engine,"Universal install script: modifications needed for Windows 1. Python on Windows does not have the module `pwd`, so the import may need to be skipped on Windows 2. The _venv_/bin/ directory on Linux/Mac is called _venv_/Scripts/ on Windows, so the script is unable to find `pip` 3. In the printed messages, forward slashes should be printed as backslashes instead on Windows Other potential issues: - `getpass.getuser()` can fail on Python 3.6 on Windows, and the error message is related to the failure to `import pwd` Thanks to @jamaldabbeek for testing the script on Windows"
552344,613863,https://api.github.com/repos/cryptoadvance/specter-desktop/issues/763,question,2020-12-09T00:30:43Z,NONE,https://api.github.com/repos/cryptoadvance/specter-desktop,"User Experience Wish - Selecting Wallets - default to ""Transactions"" page instead of ""Receive"" page. I have a few test wallets loaded up in Specter - when I click on each wallet, I watch myself wishing that Specter would default to ""Transactions"" page where I could see the history and balances. Instead it defaults to ""Receive"" with the next address. Perhaps a Preference option for this behavior would be delicious? (Again - newbie here - not sure if these small wishes are useful here or if I should just hit the Telegram group - thanks)"
369225,410459,https://api.github.com/repos/opensearch-project/OpenSearch/issues/703,enhancement,2021-05-13T18:32:25Z,NONE,https://api.github.com/repos/opensearch-project/OpenSearch,​OpenSearch Copyright 2021 OpenSearch Contributors This product includes software developed by Elasticsearch (http://www.elastic.co). Copyright 2009-2018 Elasticsearch This product includes software developed by The Apache Software Foundation (http://www.apache.org/) This product includes software developed by Joda.org (http://www.joda.org/). **Is your feature request related to a problem? Please describe.** A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] **Describe the solution you'd like** A clear and concise description of what you want to happen. **Describe alternatives you've considered** A clear and concise description of any alternative solutions or features you've considered. **Additional context** Add any other context or screenshots about the feature request here.
273200,303821,https://api.github.com/repos/PX4/PX4-Autopilot/issues/12056,enhancement,2019-05-22T09:57:08Z,CONTRIBUTOR,https://api.github.com/repos/PX4/PX4-Autopilot,"VTOL Gazebo Simulation: weird MC behaviour Hi, On the current (21 May 2019) master branch, I noticed that the standard VTOL on Gazebo wasn't behaving nicely when in MC mode. It calculates oscillating setpoints for pitch and roll, see log here: [https://logs.px4.io/plot_app?log=c0a081c3-c38a-4464-b584-e591baddc3cb](http://url) This log was created after a clean build (make clean followed by make px4_sitl_default gazebo_standard_vtol) with Gazebo v9.8, QGC v3.5.2, Ubuntu 18.04. The mission: [Dummy_MC_loop.zip](https://github.com/PX4/Firmware/files/3206726/Dummy_MC_loop.zip) Any ideas where this behaviour comes from? "
298703,332118,https://api.github.com/repos/airshipit/airshipctl/issues/405,bug,2020-11-12T19:46:44Z,NONE,https://api.github.com/repos/airshipit/airshipctl,"'AirshipCTLSettings' does not exist anymore, documentation fix required **Describe the bug** The documentation on plugins located here https://docs.airshipit.org/airshipctl/plugins.html#accessing-airshipctl-settings or here https://github.com/airshipit/airshipctl/blob/master/docs/source/plugins.md#accessing-airshipctl-settings is not relevant anymore since the whole subfolder 'environment' under ""opendev.org/airship/airshipctl/pkg/"" has been purged. **Steps To Reproduce** Go to the links provided in the description above... **Expected behavior** The documentation must reflect the code as much as possible. **Environment** - airshipctl Version: v0.1.0 (from Master) - Operating System: Ubuntu 20.04 LTS - Kernel version: 5.4.0-48-generic - Kubernetes Version: N/A - Go version: go1.15.2 linux/amd64 - Hardware specs (e.g. 4 vCPUs, 16GB RAM, bare metal vs VM): VM (4 vCPU), 8GB RAM, 60GB HDD "
491717,546515,https://api.github.com/repos/radekkozak/discordian/issues/32,bug,2021-02-24T09:51:33Z,OWNER,https://api.github.com/repos/radekkozak/discordian,"When toggling the preview the page sometimes backs to the first line As issued by @leoxy here [https://forum.obsidian.md/t/discordian-theme/10880/37](https://forum.obsidian.md/t/discordian-theme/10880/37) : ""When toggling the preview button (or press ctrl+e), I find sometimes the page backs to the first line wherever the cursor is. The gif illustrates the problem, and the example file is attached"" [eg2.md.zip](https://github.com/radekkozak/discordian/files/6034996/eg2.md.zip) ![issue-with-preview](https://user-images.githubusercontent.com/2744747/108982446-1a15c500-768e-11eb-9c90-cc3b9bfa0053.gif) "
324893,361177,https://api.github.com/repos/fossasia/open-event-frontend/issues/6685,bug,2021-02-13T05:00:37Z,MEMBER,https://api.github.com/repos/fossasia/open-event-frontend,"Organizer Speaker Info: CC Email not delivered Speakers can be notified by email, but there is also a CC field to send an email elsewhere. The CC email does not seem to work. ![Screenshot from 2021-02-13 05-58-31](https://user-images.githubusercontent.com/1583873/107842060-c0291b80-6dc0-11eb-92b5-c5661a26e0f1.png) "
591594,657461,https://api.github.com/repos/h2oai/wave/issues/616,bug,2021-03-16T14:15:16Z,NONE,https://api.github.com/repos/h2oai/wave,"Hovering over the plot legend triggers endless loop of select_marks events when enabled #### Wave SDK Version, OS 0.12.1, Linux, Firefox #### Actual behavior I am using ui.plot_card with events=['select_marks'] and multiple groups, which forces the legend to appear at the bottom of the plot. When mouse is hovered over the legend, it triggers an infinite loop of events sent to the wave app. #### Expected behavior It might make sense to distinguish between the legend hovering and clicking events. #### Steps To Reproduce The following example with legend/groups added should be enough to reproduce: https://h2oai.github.io/wave/docs/examples/plot-events/ ![image](https://user-images.githubusercontent.com/12784356/111322700-7a829b80-8669-11eb-857c-42eb34695019.png) "
389473,432924,https://api.github.com/repos/gavinIRL/RHBot/issues/38,bug,2021-04-17T07:50:34Z,OWNER,https://api.github.com/repos/gavinIRL/RHBot,Add fallback if can't detect current char Add fallback if can't detect current char. Will simply use the last known position instead of freezing/pausing.
85003,94503,https://api.github.com/repos/ibrahimhillowle/B1-template/issues/4,bug,2021-02-05T13:23:53Z,OWNER,https://api.github.com/repos/ibrahimhillowle/B1-template,"De elementen in de .row klasse worden nu onder elkaar getoond, zorg er met behulp van de CSS voor dat ze horizontaal/op de regel naast elkaar staan."
570326,633789,https://api.github.com/repos/airflow-helm/charts/issues/80,question,2021-03-02T15:53:53Z,NONE,https://api.github.com/repos/airflow-helm/charts,"How to provide several secrets to secretsMap? <!-- ⚠️ BEFORE you submit an issue, please check if a similar issue already exists --> **What is your question?** Hello. How to provide several secrets to secretsMap to mount into web pod? If I provide one (secretsMap: ""secret1""). Everything works fine. But how to provide 2nd one? I tried several options and usually get something like that.. Error: UPGRADE FAILED: YAML parse error on airflow/templates/webserver/webserver-deployment.yaml: error converting YAML to JSON: yaml: line 104: did not find expected key"
331446,368485,https://api.github.com/repos/Annosz/UIInfoSuite2/issues/20,enhancement,2021-01-04T17:29:24Z,NONE,https://api.github.com/repos/Annosz/UIInfoSuite2,"Robin Building Status A super-helpful feature of UI Info Suite is that when you upgrade a tool at the Blacksmith, an icon will appear that shows you when the tool is ready to be retrieved. In a similar way, I propose that UI Info Suite should show an icon when you construct a building at the Carpenter's Shop. This way, you can more easily keep track of how many more days it will take for a building to complete without taking extensive/tedious notes. Naturally, this feature should work for both new building construction and for building upgrades. (They take different amounts of days.) For this feature, the mod would likely have to be loaded with a list of building times for each specific building. However, there aren't that many buildings, so this shouldn't be too bad."
135900,151060,https://api.github.com/repos/INGEOTEC/text_models/issues/73,enhancement,2020-12-25T15:12:06Z,MEMBER,https://api.github.com/repos/INGEOTEC/text_models,TextModel arguments https://github.com/INGEOTEC/text_models/blob/e329d00863d20b2807cc8b7462e6777c17edbf42/text_models/vocabulary.py#L423
168428,187280,https://api.github.com/repos/scikit-activeml/scikit-activeml/issues/85,question,2021-01-11T14:50:17Z,COLLABORATOR,https://api.github.com/repos/scikit-activeml/scikit-activeml,More restrictive check_cost_matrix? - Should each cost matrix contain at least one value > 0? - Should check_cost_matrix allow negative costs?
586712,651980,https://api.github.com/repos/bylins/mud/issues/665,question,2020-01-23T06:06:46Z,OWNER,https://api.github.com/repos/bylins/mud,Ошибка с экспой при множественных рипах ![image](https://user-images.githubusercontent.com/42086238/72960674-ac7ad380-3dbf-11ea-872b-4da2db034546.png) 
558920,621166,https://api.github.com/repos/prominic/Moonshine-IDE/issues/767,enhancement,2020-12-18T10:37:06Z,COLLABORATOR,https://api.github.com/repos/prominic/Moonshine-IDE,"Improvement for ""Select SDK"" window - better describe similar sdk As part of this issue we need to improve ""Select SDK"" window where user have list of his sdk's which he can pickup. We need to take care of scenario where we could open two or more times for example Flex SDK. Entries showed on the list may confuses user cause Description column will contains same value. Example where I have same SDK, but different location. ![same_sdk](https://user-images.githubusercontent.com/24554795/102605273-56282900-4125-11eb-936b-03c2883b1b25.png) "
550581,611924,https://api.github.com/repos/fluttercommunity/import_sorter/issues/34,bug,2020-10-27T23:03:23Z,NONE,https://api.github.com/repos/fluttercommunity/import_sorter,"flutter_gen Package Import Gets Deleted **Describe the bug** Without a comment on the same line the `import 'package:flutter_gen/gen_l10n/translations.dart';` gets removed when running `flutter pub run import_sorter:main`. **To Reproduce** You can just add the import to your main.dart file after creating a new project. It won't be able to build, but running `flutter pub run import_sorter:main` after saving the file still deletes the import. _Note: even after there are no build errors it still deletes it_ **Expected behavior** The import should not be deleted. **Meta Information:** - Dart Version: *2.10.2* - `import_sorter` Version: *4.2.2* - Is it a Flutter project? *Yes* - What version of Flutter are you using (if flutter project): *1.22.2* **Additional Context** The import is sorted correctly if you add a comment to the same line. For example: `import 'package:flutter_gen/gen_l10n/translations.dart';` // gets removed `import 'package:flutter_gen/gen_l10n/translations.dart'; // import_sorter:keep` // gets sorted correctly "
717056,796942,https://api.github.com/repos/chloejiwon/chloejiwon.github.io/issues/5,enhancement,2020-12-24T01:27:04Z,NONE,https://api.github.com/repos/chloejiwon/chloejiwon.github.io,댓글 기능을 추가해주세요 제곧내
126924,141046,https://api.github.com/repos/fastai/nbdev/issues/379,enhancement,2021-01-14T01:15:44Z,MEMBER,https://api.github.com/repos/fastai/nbdev,Use Jekyll Theme instead of vendoring all required files Using a Jekyll theme will increase maintainability by allowing us to push fixes and improvements to the Jekyll components without requiring manual intervention. 
554565,616308,https://api.github.com/repos/brave/brave-browser/issues/9955,enhancement,2020-05-27T02:42:33Z,NONE,https://api.github.com/repos/brave/brave-browser,"[Android] Support cosmetic filtering on Android ## Description <!-- Provide a brief description of the issue --> I enabled cometic filtering in brave://flags, enable ads blocking in setting and update in brave://components ## Steps to reproduce <!-- Please add a series of steps to reproduce the issue --> 1. enter brave://flags and enable cosmetic filtering 2. restart brave 2 times and open brave again 3. go to https://apkmirror.com and still see the white space ## Actual result <!-- Please add screenshots if needed --> [screenshot1](https://imgur.com/wc43vRv) [screenshot2](https://imgur.com/3LbV4Vf) ## Expected result No white space ## Issue happens on <!-- Mention yes or no --> - Current Play Store version? yes - Beta build? no ## Device details - Install type (ARM, x86): ARM64 - Device (Phone, Tablet, Phablet): Huawei P20 pro - Android version: Android 10 ## Brave version 1.8.112 ### Additional information <!-- Any additional information, related issues, extra QA steps, configuration or data that might be necessary to reproduce the issue --> I found this [link](https://community.brave.com/t/cosmetic-filter-on-android/109789) but there's no solution yet "
166885,185574,https://api.github.com/repos/jmgutierreza/exp_info_comport/issues/1,enhancement,2020-12-09T18:06:31Z,COLLABORATOR,https://api.github.com/repos/jmgutierreza/exp_info_comport,"Trabajar en branch ‘working_space’ La forma de trabajar con branches debe ser la sgte: 1. Crear un branch llamado 'working_space' 1. En caso los dos estén programando, crear un branch por cada colaborador 1. Hacer los cambios en sus branches 1. Combinar los cambios con 'working_space' usando un pull request 1. Repetir el proceso hasta llegar a una versión funcional del código 1. Cuando haya una versión funcional, llevan loa cambios de 'working_space' a 'master' con un pull request Esto hará que siempre tengan versiones funcionales en master para testear en el lab, pero si quieren hacen un cambio que podría ""quebrar"" el código, lo pueden chequear en 'working_space' Si solo uno está trabajando con el código, esa persona siempre debería usar el branch 'working_space' como si branch propio y el resto de pasos serían los mismos"
495099,550290,https://api.github.com/repos/neooblaster/zcl_log_util/issues/5,enhancement,2020-12-21T15:40:59Z,OWNER,https://api.github.com/repos/neooblaster/zcl_log_util,GIT - Issue on installation Issue with : - [x] FUGR : ZCL_LOG_UTIL - [x] PROG : ZCL_LOG_UTIL_TEST_CASES - [x] PROG : ZCL_LOG_UTIL_EXAMPLE - [ ] AVAS : fa163e8bc7911eeb8be0053b22a9c1b7 (cancel) 
69555,77314,https://api.github.com/repos/IntelRealSense/librealsense/issues/4408,enhancement,2019-07-11T12:02:51Z,NONE,https://api.github.com/repos/IntelRealSense/librealsense,"T265 adding an auxiliary Serial & Power port for embedded systems. Allow me to make a System Modification Request here, for adding an auxiliary Serial & Power port for embedded systems. This port would offer a direct connection for smaller systems to read the signal on a serial interface without having to load any specific driver. This port would also be used for power using a 5 Volts regulated supply. Here is what could be the auxiliary pinout: - Vcc - TX - RX - GND We would use the existing USB connected to a computer in order to set the speed and data stream. As for example, in **ArduPilot** we are using this message to for the vision systems: https://mavlink.io/en/messages/common.html#VISION_POSITION_ESTIMATE Field Name | Type | Units | Description usec | uint64_t | us | x | float | m | Global X position y | float | m | Global Y position z | float | m | Global Z position roll | float | rad | Roll angle pitch | float | rad | Pitch angle yaw | float | rad | Yaw angle covariance ** reset_counter** This way we could feed directly the Flight Controller (or any other embedded control system) and use the T265 without having to read and retransmit the signal using an onboard ""Companion Computer'' that adds weight and complexity. Here is a picture of my development vehicle using the Nvidia NANO as the ""Companion Computer"", and I show (orange line) how the system could be simplified using the auxiliary port to feed signal directly to Flight Computer , the **cube**. ![image](https://user-images.githubusercontent.com/12484190/61049356-34fcce00-a3b2-11e9-9c68-32fa48b31426.png) "
506187,562578,https://api.github.com/repos/opensourcepos/opensourcepos/issues/3058,question,2020-12-29T18:38:33Z,NONE,https://api.github.com/repos/opensourcepos/opensourcepos,"Cannot install using Docker ### Background information __IMPORTANT: If you choose to ignore this issue report template, your issue will be closed as we cannot help without the requested information.__ Please make sure you tick (add an x between the square brackets with no spaces) the following check boxes: - [ ] Reporting an issue of an unmodified OSPOS installation - [x] Checked [open and closed issues](https://github.com/opensourcepos/opensourcepos/issues?utf8=%E2%9C%93&q=is%3Aissue) and no similar issue was already reported (please make sure you searched!) - [x] Read [README](https://github.com/opensourcepos/opensourcepos/blob/master/README.md), [WHATS_NEW](https://github.com/opensourcepos/opensourcepos/blob/master/WHATS_NEW.txt), [INSTALL.md](https://github.com/opensourcepos/opensourcepos/blob/master/INSTALL.md) and [UPGRADE](https://github.com/opensourcepos/opensourcepos/blob/master/UPGRADE.txt) - [x] Read the [FAQ](https://github.com/opensourcepos/opensourcepos#faq) for any known install and/or upgrade gotchas (in specific PHP extensions installed) - [x] Read the [wiki](https://github.com/opensourcepos/opensourcepos/wiki) - [ ] Executed any database upgrade scripts if an upgrade pre 3.0.0 (e.g. database/2.4_to_3.0.sql) - [x] Aware the installation code is in [bintray](https://bintray.com/jekkos/opensourcepos/opensourcepos/view/files?sort=updated&order=asc#files) (see README), and [GitHub master](https://github.com/opensourcepos/opensourcepos/tree/master) is for [developers only](https://github.com/opensourcepos/opensourcepos/wiki/Development-setup) and therefore not complete nor stable ### Installation information - OSPOS version is: [3.3.2](https://github.com/opensourcepos/opensourcepos/releases/download/3.3.2/opensourcepos.20200903075833.3.3.2.bb309c.zip) and I also tried the [3.3.3](https://bintray.com/jekkos/opensourcepos/download_file?file_path=opensourcepos.20201005204712.master.eb9e9d.zip) - Docker installation: Docker version 20.10.1, build 831ebea | docker-compose version 1.27.4, build 40524192 - Envsubst: Lastest from its GitHub repo ### Issue / Bug / Question / New Feature I tried to download the https://github.com/opensourcepos/opensourcepos/releases/download/3.3.2/opensourcepos.20200903075833.3.3.2.bb309c.zip file, then unzip it. I did the environment variables set up to then perform the `docker-compose build` and `docker-compose up`. However, I get Nginx error (`nginx exited with code 1`). I noticed this `envsubst: error while reading ""standard input"": Is a directory` too. I'm sending the full docker-compose up log: ```bash $ docker-compose up WARNING: The OSPOS_DOMAIN_NAME variable is not set. Defaulting to a blank string. Creating network ""opensourcepos332_db_net"" with the default driver Creating network ""opensourcepos332_app_net"" with the default driver Creating volume ""opensourcepos332_uploads"" with local driver Creating volume ""opensourcepos332_logs"" with local driver Creating certbot ... done Creating mysql ... done Creating phpmyadmin ... done Creating ospos ... done Creating nginx ... done Attaching to certbot, mysql, ospos, phpmyadmin, nginx certbot | Saving debug log to /var/log/letsencrypt/letsencrypt.log mysql | 2020-12-29 18:20:40+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 1:10.3.27+maria~focal started. certbot | certbot | - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - certbot | certbot | No renewals were attempted. certbot | - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - ospos | AH00558: apache2: Could not reliably determine the server's fully qualified domain name, using 192.168.208.3. Set the 'ServerName' directive globally to suppress this message nginx | envsubst: error while reading ""standard input"": Is a directory phpmyadmin | AH00558: apache2: Could not reliably determine the server's fully qualified domain name, using 192.168.208.4. Set the 'ServerName' directive globally to suppress this message mysql | 2020-12-29 18:20:40+00:00 [Note] [Entrypoint]: Switching to dedicated user 'mysql' nginx | 2020/12/29 18:20:43 [emerg] 1#1: no ""events"" section in configuration nginx | nginx: [emerg] no ""events"" section in configuration ospos | AH00558: apache2: Could not reliably determine the server's fully qualified domain name, using 192.168.208.3. Set the 'ServerName' directive globally to suppress this message ospos | [Tue Dec 29 18:20:41.971448 2020] [mpm_prefork:notice] [pid 1] AH00163: Apache/2.4.38 (Debian) PHP/7.3.25 configured -- resuming normal operations ospos | [Tue Dec 29 18:20:41.971509 2020] [core:notice] [pid 1] AH00094: Command line: 'apache2 -D FOREGROUND' phpmyadmin | AH00558: apache2: Could not reliably determine the server's fully qualified domain name, using 192.168.208.4. Set the 'ServerName' directive globally to suppress this message mysql | 2020-12-29 18:20:40+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 1:10.3.27+maria~focal started. phpmyadmin | [Tue Dec 29 18:20:42.108543 2020] [mpm_prefork:notice] [pid 1] AH00163: Apache/2.4.38 (Debian) PHP/7.4.13 configured -- resuming normal operations phpmyadmin | [Tue Dec 29 18:20:42.108623 2020] [core:notice] [pid 1] AH00094: Command line: 'apache2 -D FOREGROUND' mysql | 2020-12-29 18:20:40+00:00 [Note] [Entrypoint]: Initializing database files mysql | mysql | mysql | PLEASE REMEMBER TO SET A PASSWORD FOR THE MariaDB root USER ! mysql | To do so, start the server, then issue the following commands: mysql | mysql | '/usr/bin/mysqladmin' -u root password 'new-password' mysql | '/usr/bin/mysqladmin' -u root -h password 'new-password' mysql | mysql | Alternatively you can run: mysql | '/usr/bin/mysql_secure_installation' mysql | mysql | which will also give you the option of removing the test mysql | databases and anonymous user created by default. This is mysql | strongly recommended for production servers. mysql | mysql | See the MariaDB Knowledgebase at http://mariadb.com/kb or the mysql | MySQL manual for more instructions. mysql | mysql | Please report any problems at http://mariadb.org/jira mysql | mysql | The latest information about MariaDB is available at http://mariadb.org/. mysql | You can find additional information about the MySQL part at: mysql | http://dev.mysql.com mysql | Consider joining MariaDB's strong and vibrant community: mysql | https://mariadb.org/get-involved/ mysql | mysql | 2020-12-29 18:20:43+00:00 [Note] [Entrypoint]: Database files initialized mysql | 2020-12-29 18:20:43+00:00 [Note] [Entrypoint]: Starting temporary server mysql | 2020-12-29 18:20:43+00:00 [Note] [Entrypoint]: Waiting for server startup mysql | 2020-12-29 18:20:43 0 [Note] mysqld (mysqld 10.3.27-MariaDB-1:10.3.27+maria~focal) starting as process 120 ... mysql | 2020-12-29 18:20:43 0 [Note] InnoDB: Using Linux native AIO mysql | 2020-12-29 18:20:43 0 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins mysql | 2020-12-29 18:20:43 0 [Note] InnoDB: Uses event mutexes mysql | 2020-12-29 18:20:43 0 [Note] InnoDB: Compressed tables use zlib 1.2.11 mysql | 2020-12-29 18:20:43 0 [Note] InnoDB: Number of pools: 1 mysql | 2020-12-29 18:20:43 0 [Note] InnoDB: Using SSE2 crc32 instructions mysql | 2020-12-29 18:20:43 0 [Note] InnoDB: Initializing buffer pool, total size = 256M, instances = 1, chunk size = 128M mysql | 2020-12-29 18:20:43 0 [Note] InnoDB: Completed initialization of buffer pool mysql | 2020-12-29 18:20:43 0 [Note] InnoDB: If the mysqld execution user is authorized, page cleaner thread priority can be changed. See the man page of setpriority(). mysql | 2020-12-29 18:20:44 0 [Note] InnoDB: 128 out of 128 rollback segments are active. mysql | 2020-12-29 18:20:44 0 [Note] InnoDB: Creating shared tablespace for temporary tables mysql | 2020-12-29 18:20:44 0 [Note] InnoDB: Setting file './ibtmp1' size to 12 MB. Physically writing the file full; Please wait ... mysql | 2020-12-29 18:20:44 0 [Note] InnoDB: File './ibtmp1' size is now 12 MB. mysql | 2020-12-29 18:20:44 0 [Note] InnoDB: Waiting for purge to start mysql | 2020-12-29 18:20:44 0 [Note] InnoDB: 10.3.27 started; log sequence number 1625443; transaction id 20 mysql | 2020-12-29 18:20:44 0 [Note] InnoDB: Loading buffer pool(s) from /var/lib/mysql/ib_buffer_pool mysql | 2020-12-29 18:20:44 0 [Note] Plugin 'FEEDBACK' is disabled. mysql | 2020-12-29 18:20:44 0 [Warning] 'user' entry 'root@3dbc0cfbf4eb' ignored in --skip-name-resolve mode. mysql | 2020-12-29 18:20:44 0 [Warning] 'proxies_priv' entry '@% root@3dbc0cfbf4eb' ignored in --skip-name-resolve mode. mysql | 2020-12-29 18:20:44 0 [Note] InnoDB: Buffer pool(s) load completed at 201229 18:20:44 mysql | 2020-12-29 18:20:44 0 [Note] Reading of all Master_info entries succeeded mysql | 2020-12-29 18:20:44 0 [Note] Added new Master_info '' to hash table mysql | 2020-12-29 18:20:44 0 [Note] mysqld: ready for connections. mysql | Version: '10.3.27-MariaDB-1:10.3.27+maria~focal' socket: '/var/run/mysqld/mysqld.sock' port: 0 mariadb.org binary distribution nginx exited with code 1 mysql | 2020-12-29 18:20:44+00:00 [Note] [Entrypoint]: Temporary server started. mysql | Warning: Unable to load '/usr/share/zoneinfo/leap-seconds.list' as time zone. Skipping it. mysql | Warning: Unable to load '/usr/share/zoneinfo/leapseconds' as time zone. Skipping it. nginx exited with code 1 mysql | Warning: Unable to load '/usr/share/zoneinfo/tzdata.zi' as time zone. Skipping it. nginx exited with code 1 mysql | 2020-12-29 18:20:47 10 [Warning] 'proxies_priv' entry '@% root@3dbc0cfbf4eb' ignored in --skip-name-resolve mode. mysql | 2020-12-29 18:20:47+00:00 [Note] [Entrypoint]: Creating database ospos mysql | 2020-12-29 18:20:47+00:00 [Note] [Entrypoint]: Creating user cabokini mysql | 2020-12-29 18:20:47+00:00 [Note] [Entrypoint]: Giving user cabokini access to schema ospos mysql | mysql | 2020-12-29 18:20:47+00:00 [Note] [Entrypoint]: /usr/local/bin/docker-entrypoint.sh: running /docker-entrypoint-initdb.d/database.sql nginx exited with code 1 mysql | mysql | mysql | 2020-12-29 18:20:49+00:00 [Note] [Entrypoint]: Stopping temporary server mysql | 2020-12-29 18:20:49 0 [Note] mysqld (initiated by: root[root] @ localhost []): Normal shutdown mysql | 2020-12-29 18:20:49 0 [Note] Event Scheduler: Purging the queue. 0 events mysql | 2020-12-29 18:20:49 0 [Note] InnoDB: FTS optimize thread exiting. mysql | 2020-12-29 18:20:49 0 [Note] InnoDB: Starting shutdown... mysql | 2020-12-29 18:20:49 0 [Note] InnoDB: Dumping buffer pool(s) to /var/lib/mysql/ib_buffer_pool mysql | 2020-12-29 18:20:49 0 [Note] InnoDB: Buffer pool(s) dump completed at 201229 18:20:49 nginx exited with code 1 nginx | envsubst: error while reading ""standard input"": Is a directory nginx | 2020/12/29 18:20:43 [emerg] 1#1: no ""events"" section in configuration nginx | nginx: [emerg] no ""events"" section in configuration nginx | envsubst: error while reading ""standard input"": Is a directory nginx | 2020/12/29 18:20:44 [emerg] 1#1: no ""events"" section in configuration nginx | nginx: [emerg] no ""events"" section in configuration nginx | envsubst: error while reading ""standard input"": Is a directory nginx | 2020/12/29 18:20:45 [emerg] 1#1: no ""events"" section in configuration nginx | nginx: [emerg] no ""events"" section in configuration nginx | envsubst: error while reading ""standard input"": Is a directory nginx | 2020/12/29 18:20:46 [emerg] 1#1: no ""events"" section in configuration nginx | nginx: [emerg] no ""events"" section in configuration nginx | envsubst: error while reading ""standard input"": Is a directory nginx | 2020/12/29 18:20:47 [emerg] 1#1: no ""events"" section in configuration nginx | nginx: [emerg] no ""events"" section in configuration nginx | envsubst: error while reading ""standard input"": Is a directory nginx | 2020/12/29 18:20:50 [emerg] 1#1: no ""events"" section in configuration nginx | nginx: [emerg] no ""events"" section in configuration mysql | 2020-12-29 18:20:51 0 [Note] InnoDB: Shutdown completed; log sequence number 3553224; transaction id 750 mysql | 2020-12-29 18:20:51 0 [Note] InnoDB: Removed temporary tablespace data file: ""ibtmp1"" mysql | 2020-12-29 18:20:51 0 [Note] mysqld: Shutdown complete mysql | mysql | 2020-12-29 18:20:52+00:00 [Note] [Entrypoint]: Temporary server stopped mysql | mysql | 2020-12-29 18:20:52+00:00 [Note] [Entrypoint]: MySQL init process done. Ready for start up. mysql | mysql | 2020-12-29 18:20:52 0 [Note] mysqld (mysqld 10.3.27-MariaDB-1:10.3.27+maria~focal) starting as process 1 ... mysql | 2020-12-29 18:20:52 0 [Note] InnoDB: Using Linux native AIO mysql | 2020-12-29 18:20:52 0 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins mysql | 2020-12-29 18:20:52 0 [Note] InnoDB: Uses event mutexes mysql | 2020-12-29 18:20:52 0 [Note] InnoDB: Compressed tables use zlib 1.2.11 mysql | 2020-12-29 18:20:52 0 [Note] InnoDB: Number of pools: 1 mysql | 2020-12-29 18:20:52 0 [Note] InnoDB: Using SSE2 crc32 instructions mysql | 2020-12-29 18:20:52 0 [Note] InnoDB: Initializing buffer pool, total size = 256M, instances = 1, chunk size = 128M mysql | 2020-12-29 18:20:52 0 [Note] InnoDB: Completed initialization of buffer pool mysql | 2020-12-29 18:20:52 0 [Note] InnoDB: If the mysqld execution user is authorized, page cleaner thread priority can be changed. See the man page of setpriority(). mysql | 2020-12-29 18:20:52 0 [Note] InnoDB: 128 out of 128 rollback segments are active. mysql | 2020-12-29 18:20:52 0 [Note] InnoDB: Creating shared tablespace for temporary tables mysql | 2020-12-29 18:20:52 0 [Note] InnoDB: Setting file './ibtmp1' size to 12 MB. Physically writing the file full; Please wait ... mysql | 2020-12-29 18:20:52 0 [Note] InnoDB: File './ibtmp1' size is now 12 MB. mysql | 2020-12-29 18:20:52 0 [Note] InnoDB: 10.3.27 started; log sequence number 3553224; transaction id 751 mysql | 2020-12-29 18:20:52 0 [Note] InnoDB: Loading buffer pool(s) from /var/lib/mysql/ib_buffer_pool mysql | 2020-12-29 18:20:52 0 [Note] Plugin 'FEEDBACK' is disabled. mysql | 2020-12-29 18:20:52 0 [Note] Server socket created on IP: '::'. mysql | 2020-12-29 18:20:52 0 [Warning] 'proxies_priv' entry '@% root@3dbc0cfbf4eb' ignored in --skip-name-resolve mode. mysql | 2020-12-29 18:20:52 0 [Note] Reading of all Master_info entries succeeded mysql | 2020-12-29 18:20:52 0 [Note] Added new Master_info '' to hash table mysql | 2020-12-29 18:20:52 0 [Note] mysqld: ready for connections. mysql | Version: '10.3.27-MariaDB-1:10.3.27+maria~focal' socket: '/var/run/mysqld/mysqld.sock' port: 3306 mariadb.org binary distribution mysql | 2020-12-29 18:20:52 0 [Note] InnoDB: Buffer pool(s) load completed at 201229 18:20:52 nginx exited with code 1 nginx exited with code 1 nginx exited with code 1 nginx exited with code 1 nginx exited with code 1 ``` I also tried the 3.3.3 version from bintray, but I got a problem with nginx/docker too: ```bash $ export $(echo $(cat ../env_ospos | sed 's/#.*//g'| xargs) | envsubst) $ docker-compose up Creating network ""opensourcepos333_db_net"" with the default driver Creating network ""opensourcepos333_app_net"" with the default driver Creating volume ""opensourcepos333_uploads"" with local driver Creating volume ""opensourcepos333_logs"" with local driver Creating mysql ... done Creating certbot ... done Creating ospos ... done Creating phpmyadmin ... done Creating nginx ... done Attaching to mysql, certbot, phpmyadmin, ospos, nginx certbot | Saving debug log to /var/log/letsencrypt/letsencrypt.log mysql | 2020-12-29 18:32:35+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 1:10.3.27+maria~focal started. certbot | certbot | - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - certbot | certbot | No renewals were attempted. certbot | - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - mysql | 2020-12-29 18:32:35+00:00 [Note] [Entrypoint]: Switching to dedicated user 'mysql' nginx | 2020/12/29 18:32:38 [emerg] 1#1: open() ""/etc/letsencrypt/options-ssl-nginx.conf"" failed (2: No such file or directory) in /etc/nginx/nginx.conf:34 nginx | nginx: [emerg] open() ""/etc/letsencrypt/options-ssl-nginx.conf"" failed (2: No such file or directory) in /etc/nginx/nginx.conf:34 mysql | 2020-12-29 18:32:35+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 1:10.3.27+maria~focal started. ospos | AH00558: apache2: Could not reliably determine the server's fully qualified domain name, using 172.23.0.4. Set the 'ServerName' directive globally to suppress this message phpmyadmin | AH00558: apache2: Could not reliably determine the server's fully qualified domain name, using 172.23.0.3. Set the 'ServerName' directive globally to suppress this message ospos | AH00558: apache2: Could not reliably determine the server's fully qualified domain name, using 172.23.0.4. Set the 'ServerName' directive globally to suppress this message ospos | [Tue Dec 29 18:32:37.527915 2020] [mpm_prefork:notice] [pid 1] AH00163: Apache/2.4.38 (Debian) PHP/7.3.25 configured -- resuming normal operations ospos | [Tue Dec 29 18:32:37.527987 2020] [core:notice] [pid 1] AH00094: Command line: 'apache2 -D FOREGROUND' phpmyadmin | AH00558: apache2: Could not reliably determine the server's fully qualified domain name, using 172.23.0.3. Set the 'ServerName' directive globally to suppress this message mysql | 2020-12-29 18:32:36+00:00 [Note] [Entrypoint]: Initializing database files phpmyadmin | [Tue Dec 29 18:32:37.470349 2020] [mpm_prefork:notice] [pid 1] AH00163: Apache/2.4.38 (Debian) PHP/7.4.13 configured -- resuming normal operations phpmyadmin | [Tue Dec 29 18:32:37.470445 2020] [core:notice] [pid 1] AH00094: Command line: 'apache2 -D FOREGROUND' mysql | mysql | mysql | PLEASE REMEMBER TO SET A PASSWORD FOR THE MariaDB root USER ! mysql | To do so, start the server, then issue the following commands: mysql | mysql | '/usr/bin/mysqladmin' -u root password 'new-password' mysql | '/usr/bin/mysqladmin' -u root -h password 'new-password' mysql | mysql | Alternatively you can run: mysql | '/usr/bin/mysql_secure_installation' mysql | mysql | which will also give you the option of removing the test mysql | databases and anonymous user created by default. This is mysql | strongly recommended for production servers. mysql | mysql | See the MariaDB Knowledgebase at http://mariadb.com/kb or the mysql | MySQL manual for more instructions. mysql | mysql | Please report any problems at http://mariadb.org/jira mysql | mysql | The latest information about MariaDB is available at http://mariadb.org/. mysql | You can find additional information about the MySQL part at: mysql | http://dev.mysql.com mysql | Consider joining MariaDB's strong and vibrant community: mysql | https://mariadb.org/get-involved/ mysql | mysql | 2020-12-29 18:32:38+00:00 [Note] [Entrypoint]: Database files initialized mysql | 2020-12-29 18:32:38+00:00 [Note] [Entrypoint]: Starting temporary server mysql | 2020-12-29 18:32:38+00:00 [Note] [Entrypoint]: Waiting for server startup mysql | 2020-12-29 18:32:38 0 [Note] mysqld (mysqld 10.3.27-MariaDB-1:10.3.27+maria~focal) starting as process 120 ... mysql | 2020-12-29 18:32:38 0 [Note] InnoDB: Using Linux native AIO mysql | 2020-12-29 18:32:38 0 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins mysql | 2020-12-29 18:32:38 0 [Note] InnoDB: Uses event mutexes mysql | 2020-12-29 18:32:38 0 [Note] InnoDB: Compressed tables use zlib 1.2.11 mysql | 2020-12-29 18:32:38 0 [Note] InnoDB: Number of pools: 1 mysql | 2020-12-29 18:32:38 0 [Note] InnoDB: Using SSE2 crc32 instructions mysql | 2020-12-29 18:32:38 0 [Note] InnoDB: Initializing buffer pool, total size = 256M, instances = 1, chunk size = 128M mysql | 2020-12-29 18:32:38 0 [Note] InnoDB: Completed initialization of buffer pool mysql | 2020-12-29 18:32:38 0 [Note] InnoDB: If the mysqld execution user is authorized, page cleaner thread priority can be changed. See the man page of setpriority(). mysql | 2020-12-29 18:32:39 0 [Note] InnoDB: 128 out of 128 rollback segments are active. mysql | 2020-12-29 18:32:39 0 [Note] InnoDB: Creating shared tablespace for temporary tables mysql | 2020-12-29 18:32:39 0 [Note] InnoDB: Setting file './ibtmp1' size to 12 MB. Physically writing the file full; Please wait ... mysql | 2020-12-29 18:32:39 0 [Note] InnoDB: File './ibtmp1' size is now 12 MB. mysql | 2020-12-29 18:32:39 0 [Note] InnoDB: 10.3.27 started; log sequence number 1625443; transaction id 20 mysql | 2020-12-29 18:32:39 0 [Note] InnoDB: Loading buffer pool(s) from /var/lib/mysql/ib_buffer_pool mysql | 2020-12-29 18:32:39 0 [Note] Plugin 'FEEDBACK' is disabled. mysql | 2020-12-29 18:32:39 0 [Warning] 'user' entry 'root@e40fc0f79dc4' ignored in --skip-name-resolve mode. mysql | 2020-12-29 18:32:39 0 [Warning] 'proxies_priv' entry '@% root@e40fc0f79dc4' ignored in --skip-name-resolve mode. mysql | 2020-12-29 18:32:39 0 [Note] InnoDB: Buffer pool(s) load completed at 201229 18:32:39 mysql | 2020-12-29 18:32:39 0 [Note] Reading of all Master_info entries succeeded mysql | 2020-12-29 18:32:39 0 [Note] Added new Master_info '' to hash table mysql | 2020-12-29 18:32:39 0 [Note] mysqld: ready for connections. mysql | Version: '10.3.27-MariaDB-1:10.3.27+maria~focal' socket: '/var/run/mysqld/mysqld.sock' port: 0 mariadb.org binary distribution nginx exited with code 1 mysql | 2020-12-29 18:32:39+00:00 [Note] [Entrypoint]: Temporary server started. nginx exited with code 1 mysql | Warning: Unable to load '/usr/share/zoneinfo/leap-seconds.list' as time zone. Skipping it. mysql | Warning: Unable to load '/usr/share/zoneinfo/leapseconds' as time zone. Skipping it. nginx exited with code 1 mysql | Warning: Unable to load '/usr/share/zoneinfo/tzdata.zi' as time zone. Skipping it. mysql | 2020-12-29 18:32:41 10 [Warning] 'proxies_priv' entry '@% root@e40fc0f79dc4' ignored in --skip-name-resolve mode. mysql | 2020-12-29 18:32:41+00:00 [Note] [Entrypoint]: Creating database ospos mysql | 2020-12-29 18:32:41+00:00 [Note] [Entrypoint]: Creating user cabokini mysql | 2020-12-29 18:32:41+00:00 [Note] [Entrypoint]: Giving user cabokini access to schema ospos mysql | mysql | 2020-12-29 18:32:42+00:00 [Note] [Entrypoint]: /usr/local/bin/docker-entrypoint.sh: running /docker-entrypoint-initdb.d/database.sql nginx exited with code 1 mysql | mysql | mysql | 2020-12-29 18:32:43+00:00 [Note] [Entrypoint]: Stopping temporary server mysql | 2020-12-29 18:32:43 0 [Note] mysqld (initiated by: root[root] @ localhost []): Normal shutdown mysql | 2020-12-29 18:32:43 0 [Note] Event Scheduler: Purging the queue. 0 events mysql | 2020-12-29 18:32:43 0 [Note] InnoDB: FTS optimize thread exiting. mysql | 2020-12-29 18:32:43 0 [Note] InnoDB: Starting shutdown... mysql | 2020-12-29 18:32:43 0 [Note] InnoDB: Dumping buffer pool(s) to /var/lib/mysql/ib_buffer_pool mysql | 2020-12-29 18:32:43 0 [Note] InnoDB: Buffer pool(s) dump completed at 201229 18:32:43 nginx exited with code 1 mysql | 2020-12-29 18:32:45 0 [Note] InnoDB: Shutdown completed; log sequence number 3564060; transaction id 750 mysql | 2020-12-29 18:32:45 0 [Note] InnoDB: Removed temporary tablespace data file: ""ibtmp1"" mysql | 2020-12-29 18:32:45 0 [Note] mysqld: Shutdown complete mysql | mysql | 2020-12-29 18:32:45+00:00 [Note] [Entrypoint]: Temporary server stopped mysql | mysql | 2020-12-29 18:32:45+00:00 [Note] [Entrypoint]: MySQL init process done. Ready for start up. mysql | mysql | 2020-12-29 18:32:45 0 [Note] mysqld (mysqld 10.3.27-MariaDB-1:10.3.27+maria~focal) starting as process 1 ... mysql | 2020-12-29 18:32:45 0 [Note] InnoDB: Using Linux native AIO mysql | 2020-12-29 18:32:45 0 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins mysql | 2020-12-29 18:32:45 0 [Note] InnoDB: Uses event mutexes mysql | 2020-12-29 18:32:45 0 [Note] InnoDB: Compressed tables use zlib 1.2.11 mysql | 2020-12-29 18:32:45 0 [Note] InnoDB: Number of pools: 1 mysql | 2020-12-29 18:32:45 0 [Note] InnoDB: Using SSE2 crc32 instructions mysql | 2020-12-29 18:32:45 0 [Note] InnoDB: Initializing buffer pool, total size = 256M, instances = 1, chunk size = 128M mysql | 2020-12-29 18:32:45 0 [Note] InnoDB: Completed initialization of buffer pool mysql | 2020-12-29 18:32:45 0 [Note] InnoDB: If the mysqld execution user is authorized, page cleaner thread priority can be changed. See the man page of setpriority(). mysql | 2020-12-29 18:32:45 0 [Note] InnoDB: 128 out of 128 rollback segments are active. mysql | 2020-12-29 18:32:45 0 [Note] InnoDB: Creating shared tablespace for temporary tables mysql | 2020-12-29 18:32:45 0 [Note] InnoDB: Setting file './ibtmp1' size to 12 MB. Physically writing the file full; Please wait ... mysql | 2020-12-29 18:32:45 0 [Note] InnoDB: File './ibtmp1' size is now 12 MB. mysql | 2020-12-29 18:32:45 0 [Note] InnoDB: 10.3.27 started; log sequence number 3564060; transaction id 751 mysql | 2020-12-29 18:32:45 0 [Note] Plugin 'FEEDBACK' is disabled. mysql | 2020-12-29 18:32:45 0 [Note] InnoDB: Loading buffer pool(s) from /var/lib/mysql/ib_buffer_pool mysql | 2020-12-29 18:32:45 0 [Note] Server socket created on IP: '::'. mysql | 2020-12-29 18:32:45 0 [Warning] 'proxies_priv' entry '@% root@e40fc0f79dc4' ignored in --skip-name-resolve mode. mysql | 2020-12-29 18:32:45 0 [Note] Reading of all Master_info entries succeeded mysql | 2020-12-29 18:32:45 0 [Note] Added new Master_info '' to hash table mysql | 2020-12-29 18:32:45 0 [Note] mysqld: ready for connections. mysql | Version: '10.3.27-MariaDB-1:10.3.27+maria~focal' socket: '/var/run/mysqld/mysqld.sock' port: 3306 mariadb.org binary distribution mysql | 2020-12-29 18:32:45 0 [Note] InnoDB: Buffer pool(s) load completed at 201229 18:32:45 nginx exited with code 1 nginx exited with code 1 ``` The `../env_ospos` file that I used above is a copy of `docker/.env` (from master). Did I miss something and/or did something wrong? 😢 I just downloaded the zips, unzipped them to then perform the docker-compose build and up, following the docs."
426442,474021,https://api.github.com/repos/pgpainless/pgpainless/issues/70,bug,2021-02-04T17:04:13Z,MEMBER,https://api.github.com/repos/pgpainless/pgpainless,Exception Constructing Key Sometimes the `KeyFlagBasedSelectionStrategyTest.testSelectKeysFromKeyRing` test throws an exception. Note that the exception happes infrequently (in this case once in 50 repetitions). It appears to be caused by a private key encoding having incorrect length? ``` Exception constructing key org.bouncycastle.openpgp.PGPException: Exception constructing key at org.bouncycastle.openpgp.operator.bc.BcPGPKeyConverter.getPrivateKey(Unknown Source) at org.pgpainless.implementation.BcImplementationFactory.jceToBcKeyPair(BcImplementationFactory.java:156) at org.pgpainless.implementation.BcImplementationFactory.getPGPKeyPair(BcImplementationFactory.java:131) at org.pgpainless.key.generation.KeyRingBuilder.generateKeyPair(KeyRingBuilder.java:371) at org.pgpainless.key.generation.KeyRingBuilder$WithAdditionalUserIdOrPassphraseImpl$BuildImpl.build(KeyRingBuilder.java:268) at org.pgpainless.util.selection.key.KeyFlagBasedSelectionStrategyTest.testSelectKeysFromKeyRing(KeyFlagBasedSelectionStrategyTest.java:142) at jdk.internal.reflect.GeneratedMethodAccessor2.invoke(Unknown Source) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:566) at org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:688) at org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60) at org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131) at org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:149) at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:140) at org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestTemplateMethod(TimeoutExtension.java:92) at org.junit.jupiter.engine.execution.ExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(ExecutableInvoker.java:115) at org.junit.jupiter.engine.execution.ExecutableInvoker.lambda$invoke$0(ExecutableInvoker.java:105) at org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106) at org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64) at org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45) at org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37) at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:104) at org.junit.jupiter.engine.execution.ExecutableInvoker.invoke(ExecutableInvoker.java:98) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$6(TestMethodTestDescriptor.java:210) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:206) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:131) at org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:65) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:139) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:32) at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:212) at org.junit.platform.engine.support.hierarchical.NodeTestTask$DefaultDynamicTestExecutor.execute(NodeTestTask.java:192) at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:139) at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.lambda$execute$2(TestTemplateTestDescriptor.java:107) at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177) at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) at java.base/java.util.stream.IntPipeline$1$1.accept(IntPipeline.java:180) at java.base/java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:104) at java.base/java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:699) at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497) at java.base/java.util.stream.ReferencePipeline$7$1.accept(ReferencePipeline.java:274) at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1655) at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497) at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:107) at org.junit.jupiter.engine.descriptor.TestTemplateTestDescriptor.execute(TestTemplateTestDescriptor.java:42) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:139) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84) at java.base/java.util.ArrayList.forEach(ArrayList.java:1541) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:38) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:143) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84) at java.base/java.util.ArrayList.forEach(ArrayList.java:1541) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:38) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$5(NodeTestTask.java:143) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$7(NodeTestTask.java:129) at org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137) at org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:127) at org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73) at org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:126) at org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:84) at org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:32) at org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57) at org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:51) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:248) at org.junit.platform.launcher.core.DefaultLauncher.lambda$execute$5(DefaultLauncher.java:211) at org.junit.platform.launcher.core.DefaultLauncher.withInterceptedStreams(DefaultLauncher.java:226) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:199) at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:132) at org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.processAllTestClasses(JUnitPlatformTestClassProcessor.java:99) at org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.access$000(JUnitPlatformTestClassProcessor.java:79) at org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor.stop(JUnitPlatformTestClassProcessor.java:75) at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:566) at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36) at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24) at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33) at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94) at com.sun.proxy.$Proxy5.stop(Unknown Source) at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.base/java.lang.reflect.Method.invoke(Method.java:566) at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36) at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24) at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182) at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164) at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:413) at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64) at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48) at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56) at java.base/java.lang.Thread.run(Thread.java:834) Caused by: java.lang.RuntimeException: private key encoding has incorrect length at org.bouncycastle.crypto.util.PrivateKeyFactory.getRawKey(Unknown Source) at org.bouncycastle.crypto.util.PrivateKeyFactory.createKey(Unknown Source) at org.bouncycastle.openpgp.operator.bc.BcPGPKeyConverter.implGetPrivateKeyPKCS8(Unknown Source) ... 130 more KeyFlagBasedSelectionStrategyTest > repetition 47 of 50 FAILED org.bouncycastle.openpgp.PGPException at KeyFlagBasedSelectionStrategyTest.java:142 Caused by: java.lang.RuntimeException at KeyFlagBasedSelectionStrategyTest.java:142 ```
381837,424461,https://api.github.com/repos/raineorshine/npm-check-updates/issues/696,enhancement,2020-07-10T08:19:03Z,CONTRIBUTOR,https://api.github.com/repos/raineorshine/npm-check-updates,"Allow by-package overrides for semver level and possibly other config - [x] I have searched for [similar issues](https://github.com/raineorshine/npm-check-updates/issues) - [x] I am using the latest version of `npm-check-updates` - [x] I am using `node >= 10.17` --------------------------- ## Current Behavior Using `reject`, I can wholly prevent updates on a particular package. ## Expected Behavior I'd like to be able to get patch or minor fixes for a given package, while still preventing it from having major bumps (e.g., bootstrap). I'm cool if this is passed right away to the idea heap--just would be a nice to have, thanks!"
158227,175916,https://api.github.com/repos/amakhnia/wi21-cse110-lab3/issues/8,enhancement,2021-01-22T05:19:10Z,OWNER,https://api.github.com/repos/amakhnia/wi21-cse110-lab3,"CSS Topics Part Resolve Issue once this is complete: - Comments - Colors: _rgb(r, g, b), rgba(r, g, b, a) #FFF, #FFFFFF hsl(h, s, l), hsla(h, s, l, a) Color name (i.e ‘green’)_ - Backgrounds _background-color_ - Borders _border-style border-color border-width border-radius_ - Unit _3 relative 3 absolute_"
504046,560241,https://api.github.com/repos/3b1b/manim/issues/1347,bug,2021-02-04T07:48:30Z,CONTRIBUTOR,https://api.github.com/repos/3b1b/manim,"ShowCreation not working for 3d Mobjects ### Bug ShowCreation Animation is not working for three-dimensional mobjects. **Code**: ``` class CubeCreation(Scene): def construct(self): cube = Cube() self.add(cube) self.play(ShowCreation(cube)) self.wait() class SphereCreation(Scene): def construct(self): sphere = Sphere() self.add(sphere) self.play(ShowCreation(sphere)) self.wait() ``` **Error traceback**: For Cube Creation, I am getting this: >""..manim\manimlib\animation\creation.py"", line 30, in interpolate_submobject >&nbsp;start_submob, *self.get_bounds(alpha) > >""..manim\manimlib\mobject\types\surface.py"", line 113, in pointwise_become_partial >&nbsp;for arr in smobject.get_surface_points_and_nudged_points() > >""..manim\manimlib\mobject\types\surface.py"", line 132, in get_partial_points_array >&nbsp;col = interpolate(points[:, index], points[:, index + 1], residue) > >""..manim\manimlib\mobject\types\surface.py"", line 113, in <listcomp> >&nbsp;for arr in smobject.get_surface_points_and_nudged_points() > >IndexError: index 0 is out of bounds for axis 1 with size 0 For SphereCreation, >The video is rendered but there is no sphere in the video, it's just blank background. "
666114,740390,https://api.github.com/repos/Garderoben/MudBlazor/issues/1085,bug,2021-03-04T17:09:02Z,NONE,https://api.github.com/repos/Garderoben/MudBlazor,"MudDatePicker not showing required error messages. As stated in the title, the DatePicker control does not display validation messages like other input controls. ``` <MudDatePicker @bind-Date=""date"" Label=""Birthdate"" Editable=""true"" Required=""true"" RequiredError=""REQUIRED"" /> @code { DateTime? date = null; } ``` See screenshot below: ![image](https://user-images.githubusercontent.com/5040055/110001252-2d560f80-7ce2-11eb-8b0a-c1b839bf07cc.png) "
251296,279518,https://api.github.com/repos/frappe/erpnext/issues/25213,bug,2021-04-05T23:43:12Z,NONE,https://api.github.com/repos/frappe/erpnext,"[V13] ERPNext mobile app status 404 <!-- Welcome to ERPNext issue tracker! Before creating an issue, please heed the following: 1. This tracker should only be used to report bugs and request features / enhancements to ERPNext - For questions and general support, checkout the manual https://erpnext.com/docs/user/manual/en or use https://discuss.erpnext.com - For documentation issues, refer to https://github.com/frappe/erpnext_com 2. Use the search function before creating a new issue. Duplicates will be closed and directed to the original discussion. 3. When making a bug report, make sure you provide all required information. The easier it is for maintainers to reproduce, the faster it'll be fixed. 4. If you think you know what the reason for the bug is, share it with us. Maybe put in a PR 😉 --> ## Description of the issue Both **Android and iOS** apps report status 404 on trying to login ## Context information (for bug reports) ERPNext/Frappe installation was updated from V13-beta to V13 release. **Output of `bench version`** ``` erpnext 13.0.0 frappe 13.0.1 ``` ## Steps to reproduce the issue 1. Open ERPNext App 2. Choose your ERPNext installation's URL 3. Attempt to login ### Observed result ![image](https://user-images.githubusercontent.com/8848627/113639439-6a415900-9636-11eb-9699-100f0f37d280.png) ""https://example.org failed with status 404"" ### Expected result The home page ### Stacktrace / full error message From nginx server: ``` ""GET /api/method/frappe.www.desk.get_desk_assets?build_version=1604086648.0 HTTP/1.1"" 404 26283 ""-"" ""Mozilla/5.0 (Linux; Android 11; SM-G975U Build/RP1A.200720.012; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/89.0.4389.105 Mobile Safari/537.36"" ""-"" ``` ## Additional information Standard ERPNext installation."
515653,573059,https://api.github.com/repos/roadiz/roadiz/issues/390,enhancement,2021-04-28T15:05:45Z,NONE,https://api.github.com/repos/roadiz/roadiz,Distinguer le nom des noeuds dans la recherche ![image (69)](https://user-images.githubusercontent.com/83358667/116427035-f3b60680-a843-11eb-87a5-21847314422f.png) 
508903,565578,https://api.github.com/repos/LeftTwixWand/Algorithms/issues/1,bug,2021-02-16T21:48:19Z,OWNER,https://api.github.com/repos/LeftTwixWand/Algorithms,Hashing algorithm works wrong Simple hashing algorithm always generating 0 hash. https://github.com/LeftTwixWand/Algorithms/blob/master/Go/DataStructures/hashtable/hashtable.go#L49
332655,369828,https://api.github.com/repos/GoogleChrome/web.dev/issues/4867,bug,2021-03-10T17:32:31Z,NONE,https://api.github.com/repos/GoogleChrome/web.dev,"Doesn't wait for Node.JS Website Servers from Repl.it to ""Wake Up"" **web.dev doesn't wait for Node.js Web Servers from [Repl.it](https://repl.it)** When going to /measure and typing in one of my node.js Server Websites that hadn't (as repl.it calls it) ""Woken Up"" yet, so I didn't get the right stats, and an Error Message Occurred. **To Reproduce** Steps to reproduce the behavior: 1. Go to [Measure on web.dev](https://web.dev/measure) 2. Enter a repl.it web server without visiting it first(EXAMPLE: https://replcoin.drewnolt.repl.co ) NOTE: you should probably do this around early morning(like around 7:30 AM PST), as the website probably hasn't woken up yet. 3. Run an audit 4. See error and stats. 5. Then, go to the website that you just ran an audit on. 6. Wait for it to wake up and load. 7. Then run another audit on that same website. 8. The stats will look different, as the server has been manually started. "
493317,548294,https://api.github.com/repos/tommyjons/github-slideshow/issues/1,bug,2021-01-21T12:38:44Z,NONE,https://api.github.com/repos/tommyjons/github-slideshow,"Getting Started with GitHub # :wave: Welcome to GitHub Learning Lab's ""Introduction to GitHub"" To get started, I’ll guide you through some important first steps in coding and collaborating on GitHub. :point_down: _This arrow means you can expand the window! Click on them throughout the course to find more information._ <details><summary>What is GitHub?</summary> <hr> ## What is GitHub? I'm glad you asked! Many people come to GitHub because they want to contribute to open source <sup>[:book:](https://help.github.com/articles/github-glossary/#open-source)</sup> projects, or they're invited by teammates or classmates who use it for their projects. Why do people use GitHub for these projects? **At its heart, GitHub is a collaboration platform.** From software to legal documents, you can count on GitHub to help you do your best work with the collaboration and security tools your team needs. With GitHub, you can keep projects completely private, invite the world to collaborate, and streamline every step of your project. **GitHub is also a powerful version control tool.** GitHub uses Git <sup>[:book:](https://help.github.com/articles/github-glossary/#git)</sup>, the most popular open source version control software, to track every contribution and contributor <sup>[:book:](https://help.github.com/articles/github-glossary/#contributor)</sup> to your project--so you know exactly where every line of code came from. **GitHub helps people do much more.** GitHub is used to build some of the most advanced technologies in the world. Whether you're visualizing data or building a new game, there's a whole community and set of tools on GitHub that can get you to the next step. This course starts with the basics, but we'll dig into the rest later! :tv: [Video: What is GitHub?](https://www.youtube.com/watch?v=w3jLJU7DT5E) <hr> </details><br> <details><summary>Exploring a GitHub repository</summary> <hr> ## Exploring a GitHub repository :tv: [Video: Exploring a repository](https://www.youtube.com/watch?v=R8OAwrcMlRw) ### More features The video covered some of the most commonly-used features. Here are a few other items you can find in GitHub repositories: - Project boards: Create Kanban-style task tracking board within GitHub - Wiki: Create and store relevant project documentation - Insights: View a drop-down menu that contains links to analytics tools for your repository including: - Pulse: Find information about the work that has been completed and the work that’s in-progress in this project dashboard - Graphs: Graphs provide a more granular view of the repository activity including who contributed to the repository, who forked it, and when they completed the work ### Special Files In the video you learned about a special file called the README.md. Here are a few other special files you can add to your repositories: - CONTRIBUTING.md: The `CONTRIBUTING.md` is used to describe the process for contributing to the repository. A link to the `CONTRIBUTING.md` file is shown anytime someone creates a new issue or pull request. - ISSUE_TEMPLATE.md: The `ISSUE_TEMPLATE.md` is another file you can use to pre-populate the body of an issue. For example, if you always need the same types of information for bug reports, include it in the issue template, and every new issue will be opened with your recommended starter text. <hr> </details> ### Using issues This is an issue <sup>[:book:](https://help.github.com/articles/github-glossary/#issue)</sup>: a place where you can have conversations about bugs in your code, code review, and just about anything else. Issue titles are like email subject lines. They tell your collaborators what the issue is about at a glance. For example, the title of this issue is Getting Started with GitHub. <details><summary>Using GitHub Issues</summary> ## Using GitHub issues Issues are used to discuss ideas, enhancements, tasks, and bugs. They make collaboration easier by: - Providing everyone (even future team members) with the complete story in one place - Allowing you to cross-link to other issues and pull requests <sup>[:book:](https://help.github.com/articles/github-glossary/#pull-request)</sup> - Creating a single, comprehensive record of how and why you made certain decisions - Allowing you to easily pull the right people and teams into a conversation with @-mentions :tv: [Video: Using issues](https://www.youtube.com/watch?v=Zhj46r5D0nQ) <hr> </details> <details><summary>Managing notifications</summary> <hr> ## Managing notifications :tv: [Video: Watching, notifications, stars, and explore](https://www.youtube.com/watch?v=ocQldxF7fMY) Once you've commented on an issue or pull request, you'll start receiving email notifications when there's activity in the thread. ### How to silence or unmute specific conversations 1. Go to the issue or pull request 2. Under _""Notifications""_, click the **Unsubscribe** button on the right to silence notifications or **Subscribe** to unmute them You'll see a short description that explains your current notification status. ### How to customize notifications in Settings 1. Click your profile icon 2. Click **Settings** 3. Click **Notifications** from the menu on the left and [adjust your notification preferences](https://help.github.com/articles/managing-notification-delivery-methods/) ### Repository notification options * **Watch**: You'll receive a notification when a new issue, pull request or comment is posted, and when an issue is closed or a pull request is merged * **Not watching**: You'll no longer receive notifications unless you're @-mentioned * **Ignore**: You'll no longer receive any notifications from the repository ### How to review notifications for the repositories you're watching 1. Click your profile icon 2. Click **Settings** 3. Click **Notification** from the menu on the left 4. Click on the [things you’re watching](https://github.com/watching) link 5. Select the **Watching** tab 6. Click the **Unwatch** button to disable notifications, or **Watch** to enable them <hr> </details> <hr> <h3 align=""center"">Keep reading below to find your first task</h3> "
169955,188978,https://api.github.com/repos/YCPRadioTelescope/YCP-RT-ControlRoom/issues/165,enhancement,2020-09-14T15:21:10Z,NONE,https://api.github.com/repos/YCPRadioTelescope/YCP-RT-ControlRoom,"Implement slip ring alongside limit switch telescope Right now, we have limit switches as the only type of Radio Telescope we can use, but we also want to have a slip ring as an option. ~~After the user is asked if they would like to create a new telescope (#164), the user will be asked whether the telescope uses a slip ring or not. This setting will be saved to the database with the new radio telescope, and the user will be able to find this setting again in the ""Settings"" menu of the ""Diagnostics Form"" (such a menu will be created in #168).~~ The telescope will be set to ""slip ring"" by default once development with hard stops concludes. What slip ring code will involve: - Bypass azimuth limit switches/stops - Also remove the option to use the overrides for those switches - Calculate shortest travel distance with full 360-degree rotation - Save slip ring/limit switch setting as an enum in the database (`radio_telescope.telescope_type`) - Back end issue: https://github.com/YCPRadioTelescope/RT-Contracts/issues/54 - Communicate with the Mechanical Engineering team with their progress on this"
137247,152561,https://api.github.com/repos/Aktanusa/CookieMonster/issues/731,bug,2021-03-28T08:57:37Z,COLLABORATOR,https://api.github.com/repos/Aktanusa/CookieMonster,"Garden reward is not correct **Describe the bug** Probably something wrong with how we calculate maturity. I have a save file, should be fixable."
273936,304647,https://api.github.com/repos/IBM/FHIR/issues/2174,bug,2021-03-30T18:46:36Z,MEMBER,https://api.github.com/repos/IBM/FHIR,FHIRTerminologyGuide contains link to non-existent fhir-operation-term module **Describe the bug** The [FHIR Server Terminology Extended Operations section](https://ibm.github.io/FHIR/guides/FHIRTerminologyGuide#fhir-server-terminology-extended-operations) of the FHIRTerminologyGuide mentions and links to a project fhir-operation-term that does not/no longer exists. **To Reproduce** Steps to reproduce the behavior: 1. Navigate to [the link](https://ibm.github.io/FHIR/guides/FHIRTerminologyGuide#fhir-server-terminology-extended-operations) 2. Click on 'fhir-operation-term' 3. See Resource Not Found (404) error **Expected behavior** Documentation mentions the correct project and has valid links. 
605092,672454,https://api.github.com/repos/broadinstitute/bibtutils/issues/4,bug,2021-03-03T18:41:01Z,NONE,https://api.github.com/repos/broadinstitute/bibtutils,"base64 not imported in gcp.pubsub the base64 module is not imported in pubsub.py, leading to a crash if the function attempts to extract data from the pubsub."
1026,1143,https://api.github.com/repos/lingster/drf-api-tracking/issues/10,enhancement,2020-03-10T22:35:32Z,OWNER,https://api.github.com/repos/lingster/drf-api-tracking,add charts to the api data see: https://findwork.dev/blog/adding-charts-to-django-admin/ 
239688,266613,https://api.github.com/repos/jakelw96/taskmaster-pro/issues/5,enhancement,2021-04-06T04:01:04Z,OWNER,https://api.github.com/repos/jakelw96/taskmaster-pro,Customize/improve user experience **Description:** - Periodically check if tasks are overdue. - Implement custom fonts and icons. - Customize UI colors.
82367,91569,https://api.github.com/repos/srikanth-lingala/zip4j/issues/255,question,2020-11-10T10:40:37Z,NONE,https://api.github.com/repos/srikanth-lingala/zip4j,"Is there any way to lower the requirements to Java 6? Hello, I would like to utilize the zip4j library in MATLAB, but one version of it only uses Java 6. Is there any way to lower the requirements to Java 6? Or is there a specific reason that zip4j requires Java 7?"
325797,362190,https://api.github.com/repos/scalameta/metals/issues/1695,bug,2020-05-05T16:10:05Z,COLLABORATOR,https://api.github.com/repos/scalameta/metals,"Scala3 found issues In repo: https://github.com/kpbochenek/dotty-complex --- Wrong hint?(mouse is on `Red`): ![2020-05-05-171336_541x117_scrot](https://user-images.githubusercontent.com/10478402/81083151-81426d00-8ef4-11ea-866e-e345e95e4814.png) I think it should be something like: `case Red: com.kpbochenek.example.dotty.SimpleEnum.Red` --- Wrong hint(mouse is on `Green`): ![2020-05-05-172315_740x99_scrot](https://user-images.githubusercontent.com/10478402/81083771-44c34100-8ef5-11ea-9295-a26a422f4109.png) Funny enough hints are okay for other cases(except first). --- Selecting `color` highlights whole (...) block and doesn't highlight all occurrences. Also searching for references of `color` doesn't work. ![2020-05-05-173108_284x88_scrot](https://user-images.githubusercontent.com/10478402/81085348-68878680-8ef7-11ea-9b2f-1c8a07126b50.png) Selecting a place where `color` is used correctly highlights everything(even declaration place) --- Jumping to definition of String works most of time except this case, where it finds 3 definitions(because misinterprets it as `makeColor` function ?? ![2020-05-05-180036_353x177_scrot](https://user-images.githubusercontent.com/10478402/81087721-59560800-8efa-11ea-8a5d-2a2fd23ab30d.png) --- Highlight ends in half of next word :) Also searching for references being on `Cancelable` yields no results, but searching on any other `Cancelable` yields 5 results ![2020-05-05-180802_351x66_scrot](https://user-images.githubusercontent.com/10478402/81088559-63c4d180-8efb-11ea-82be-84c0f698ed9c.png) "
614302,682682,https://api.github.com/repos/NVIDIA/DALI/issues/2678,question,2021-02-15T23:09:33Z,NONE,https://api.github.com/repos/NVIDIA/DALI,"Error Installing DALI Tensorflow plugin OS: Ubuntu 20.04 Cuda Version: release 11.1, V11.1.105 Tensorflow Version: 2.4.1 I was able to run the pip command to install DALI just fine, but when I ran the command to install the tensorflow plugin I got the following error: ``` ERROR: Command errored out with exit status 1: command: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-9yswhsu2/nvidia-dali-tf-plugin-cuda110/setup.py'""'""'; __file__='""'""'/tmp/pip-install-9yswhsu2/nvidia-dali-tf-plugin-cuda110/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-nd28juzi cwd: /tmp/pip-install-9yswhsu2/nvidia-dali-tf-plugin-cuda110/ Complete output (56 lines): running bdist_wheel running build running build_py creating build creating build/lib.linux-x86_64-3.8 creating build/lib.linux-x86_64-3.8/nvidia creating build/lib.linux-x86_64-3.8/nvidia/dali_tf_plugin copying nvidia/dali_tf_plugin/dali_tf_plugin.py -> build/lib.linux-x86_64-3.8/nvidia/dali_tf_plugin copying nvidia/dali_tf_plugin/__init__.py -> build/lib.linux-x86_64-3.8/nvidia/dali_tf_plugin running egg_info writing nvidia_dali_tf_plugin_cuda110.egg-info/PKG-INFO writing dependency_links to nvidia_dali_tf_plugin_cuda110.egg-info/dependency_links.txt writing requirements to nvidia_dali_tf_plugin_cuda110.egg-info/requires.txt writing top-level names to nvidia_dali_tf_plugin_cuda110.egg-info/top_level.txt reading manifest file 'nvidia_dali_tf_plugin_cuda110.egg-info/SOURCES.txt' reading manifest template 'MANIFEST.in' writing manifest file 'nvidia_dali_tf_plugin_cuda110.egg-info/SOURCES.txt' copying nvidia/dali_tf_plugin/Acknowledgements.txt -> build/lib.linux-x86_64-3.8/nvidia/dali_tf_plugin copying nvidia/dali_tf_plugin/COPYRIGHT -> build/lib.linux-x86_64-3.8/nvidia/dali_tf_plugin copying nvidia/dali_tf_plugin/LICENSE -> build/lib.linux-x86_64-3.8/nvidia/dali_tf_plugin running build_ext Traceback (most recent call last): File ""<string>"", line 1, in <module> File ""/tmp/pip-install-9yswhsu2/nvidia-dali-tf-plugin-cuda110/setup.py"", line 37, in <module> setup(name='nvidia-dali-tf-plugin-cuda110', File ""/usr/lib/python3/dist-packages/setuptools/__init__.py"", line 144, in setup return distutils.core.setup(**attrs) File ""/usr/lib/python3.8/distutils/core.py"", line 148, in setup dist.run_commands() File ""/usr/lib/python3.8/distutils/dist.py"", line 966, in run_commands self.run_command(cmd) File ""/usr/lib/python3.8/distutils/dist.py"", line 985, in run_command cmd_obj.run() File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 223, in run self.run_command('build') File ""/usr/lib/python3.8/distutils/cmd.py"", line 313, in run_command self.distribution.run_command(command) File ""/usr/lib/python3.8/distutils/dist.py"", line 985, in run_command cmd_obj.run() File ""/usr/lib/python3.8/distutils/command/build.py"", line 135, in run self.run_command(cmd_name) File ""/usr/lib/python3.8/distutils/cmd.py"", line 313, in run_command self.distribution.run_command(command) File ""/usr/lib/python3.8/distutils/dist.py"", line 985, in run_command cmd_obj.run() File ""/tmp/pip-install-9yswhsu2/nvidia-dali-tf-plugin-cuda110/setup.py"", line 24, in run helper = InstallerHelper(plugin_dest_dir = os.path.join(self.build_lib, 'nvidia', 'dali_tf_plugin')) File ""/tmp/pip-install-9yswhsu2/nvidia-dali-tf-plugin-cuda110/dali_tf_plugin_install_tool.py"", line 32, in __init__ self.tf_compiler = get_tf_compiler_version() File ""/tmp/pip-install-9yswhsu2/nvidia-dali-tf-plugin-cuda110/dali_tf_plugin_utils.py"", line 52, in get_tf_compiler_version s = str(subprocess.check_output(cmd, shell=True)) File ""/usr/lib/python3.8/subprocess.py"", line 411, in check_output return run(*popenargs, stdout=PIPE, timeout=timeout, check=True, File ""/usr/lib/python3.8/subprocess.py"", line 512, in run raise CalledProcessError(retcode, process.args, subprocess.CalledProcessError: Command 'strings -a /usr/lib/python3/dist-packages/tensorflow/libtensorflow_framework.so.2 | grep ""GCC: (""' returned non-zero exit status 1. ---------------------------------------- ERROR: Failed building wheel for nvidia-dali-tf-plugin-cuda110 ``` I loaded up /usr/lib/python3/dist-packages/tensorflow/libtensorflow_framework.so.2, and it doesn't have any instances of ""GCC: ("", and in fact, it seems to be a binary, not a text file. Any ideas what I should do?"
134018,148960,https://api.github.com/repos/fancy-regex/fancy-regex/issues/59,enhancement,2020-09-27T11:41:53Z,CONTRIBUTOR,https://api.github.com/repos/fancy-regex/fancy-regex,"Add Regex::captures_iter See https://docs.rs/regex/1.3.9/regex/struct.Regex.html#method.captures_iter Currently, you will have to call `captures_from_pos` repeatedly to get this. Would be good to add this as API. Other things such as the replace API would also make use of it (#49)."
223273,248305,https://api.github.com/repos/ModDota/dota-tutorial/issues/315,bug,2021-03-15T21:59:35Z,MEMBER,https://api.github.com/repos/ModDota/dota-tutorial,CH3 - Point out Riki / give the player vision of him when he appears Right now his voice line starts. Portrait doesn't show because he is not visible to the player. Also the player doesn't know where he spawns in the first place.
186845,207778,https://api.github.com/repos/udisoft/roadmap/issues/702,bug,2021-01-08T16:14:28Z,COLLABORATOR,https://api.github.com/repos/udisoft/roadmap,"IPI e Despesa Acessória não estão somando no total da nota Base ""decio"", segundo o Caio contador o valor total correto seria 15205,59 (8332,45 + IPI 5869,73 + DA 1003,41) ![WhatsApp Image 2021-01-08 at 13 11 53](https://user-images.githubusercontent.com/49871294/104037347-5d39d880-51b3-11eb-8c26-3ff84564fcad.jpeg) "
19721,21947,https://api.github.com/repos/raphw/byte-buddy/issues/975,question,2020-11-18T10:04:43Z,NONE,https://api.github.com/repos/raphw/byte-buddy,"Intermittent AttachNotSupportedException: target xxx not found When running tests on a compatibility build on IBM JDK 8.0.6.15, we are sometimes getting this exception in our CI environment: ``` java.lang.IllegalStateException: Could not initialize plugin: interface org.mockito.plugins.MockMaker (alternate: null) at org.mockito.internal.configuration.plugins.PluginLoader$1.invoke(PluginLoader.java:74) at com.sun.proxy.$Proxy11.isTypeMockable(Unknown Source) at org.mockito.internal.util.MockUtil.typeMockabilityOf(MockUtil.java:29) at org.mockito.internal.util.MockCreationValidator.validateType(MockCreationValidator.java:22) at org.mockito.internal.creation.MockSettingsImpl.validatedSettings(MockSettingsImpl.java:240) at org.mockito.internal.creation.MockSettingsImpl.build(MockSettingsImpl.java:228) at org.mockito.internal.MockitoCore.mock(MockitoCore.java:61) at org.mockito.Mockito.mock(Mockito.java:1908) at org.mockito.Mockito.mock(Mockito.java:1880) at com.hazelcast.jet.elastic.impl.ElasticSourcePTest.setUp(ElasticSourcePTest.java:73) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55) at java.lang.reflect.Method.invoke(Method.java:508) at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24) at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78) at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.junit.runners.Suite.runChild(Suite.java:128) at org.junit.runners.Suite.runChild(Suite.java:27) at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290) at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71) at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288) at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58) at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268) at org.junit.runners.ParentRunner.run(ParentRunner.java:363) at org.apache.maven.surefire.junitcore.JUnitCore.run(JUnitCore.java:55) at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.createRequestAndRun(JUnitCoreWrapper.java:137) at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.executeLazy(JUnitCoreWrapper.java:119) at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:87) at org.apache.maven.surefire.junitcore.JUnitCoreWrapper.execute(JUnitCoreWrapper.java:75) at org.apache.maven.surefire.junitcore.JUnitCoreProvider.invoke(JUnitCoreProvider.java:158) at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384) at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345) at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126) at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418) Caused by: java.lang.IllegalStateException: Failed to load interface org.mockito.plugins.MockMaker implementation declared in java.lang.ClassLoader$CompoundEnumeration@dcb072e4 at org.mockito.internal.configuration.plugins.PluginInitializer.loadImpl(PluginInitializer.java:54) at org.mockito.internal.configuration.plugins.PluginLoader.loadPlugin(PluginLoader.java:57) at org.mockito.internal.configuration.plugins.PluginLoader.loadPlugin(PluginLoader.java:44) at org.mockito.internal.configuration.plugins.PluginRegistry.<init>(PluginRegistry.java:22) at org.mockito.internal.configuration.plugins.Plugins.<clinit>(Plugins.java:19) at org.mockito.internal.util.MockUtil.<clinit>(MockUtil.java:24) ... 42 more Caused by: org.mockito.exceptions.base.MockitoInitializationException: Could not initialize inline Byte Buddy mock maker. (This mock maker is not supported on Android.) Java : 1.8 JVM vendor name : IBM Corporation JVM vendor version : 2.9 JVM name : IBM J9 VM JVM version : 8.0.6.15 - pxa6480sr6fp15-20200724_01(SR6 FP15) JVM info : JRE 1.8.0 Linux amd64-64-Bit Compressed References 20200724_452227 (JIT enabled, AOT enabled) OpenJ9 - 4ce4b9d OMR - 08b0594 IBM - 70917a2 OS name : Linux OS version : 3.10.0-693.11.1.el7.x86_64 at org.mockito.internal.creation.bytebuddy.InlineByteBuddyMockMaker.<init>(InlineByteBuddyMockMaker.java:168) at java.lang.J9VMInternals.newInstanceImpl(Native Method) at java.lang.Class.newInstance(Class.java:1852) at org.mockito.internal.configuration.plugins.PluginInitializer.loadImpl(PluginInitializer.java:49) ... 47 more Caused by: java.lang.IllegalStateException: Error during attachment using: net.bytebuddy.agent.ByteBuddyAgent$AttachmentProvider$Compound@3e42524 at net.bytebuddy.agent.ByteBuddyAgent.install(ByteBuddyAgent.java:427) at net.bytebuddy.agent.ByteBuddyAgent.install(ByteBuddyAgent.java:401) at net.bytebuddy.agent.ByteBuddyAgent.install(ByteBuddyAgent.java:353) at net.bytebuddy.agent.ByteBuddyAgent.install(ByteBuddyAgent.java:330) at org.mockito.internal.creation.bytebuddy.InlineByteBuddyMockMaker.<clinit>(InlineByteBuddyMockMaker.java:104) ... 50 more Caused by: java.lang.reflect.InvocationTargetException at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:90) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55) at java.lang.reflect.Method.invoke(Method.java:508) at net.bytebuddy.agent.Attacher.install(Attacher.java:99) at net.bytebuddy.agent.ByteBuddyAgent.install(ByteBuddyAgent.java:422) ... 54 more Caused by: com.sun.tools.attach.AttachNotSupportedException: target 147127 not found at com.ibm.tools.attach.attacher.OpenJ9VirtualMachine.attachTargetImpl(OpenJ9VirtualMachine.java:150) at com.ibm.tools.attach.attacher.OpenJ9VirtualMachine.lambda$attachTarget$1(OpenJ9VirtualMachine.java:128) at com.ibm.tools.attach.attacher.OpenJ9VirtualMachine$$Lambda$10/00000000A8ECCFE0.run(Unknown Source) at java.security.AccessController.doPrivileged(AccessController.java:734) at com.ibm.tools.attach.attacher.OpenJ9VirtualMachine.attachTarget(OpenJ9VirtualMachine.java:130) at com.ibm.tools.attach.attacher.OpenJ9AttachProvider.attachVirtualMachine(OpenJ9AttachProvider.java:65) at com.ibm.tools.attach.attacher.OpenJ9AttachProvider.attachVirtualMachine(OpenJ9AttachProvider.java:48) at com.sun.tools.attach.VirtualMachine.attach(VirtualMachine.java:208) ... 60 more ``` We didn't manage to reproduce it anywhere else. Never happened on Hotspot. We are using byte-buddy 1.10.15 via Mockito 3.5.13."
372766,414381,https://api.github.com/repos/keepassxreboot/keepassxc/issues/6169,bug,2021-02-23T06:36:04Z,MEMBER,https://api.github.com/repos/keepassxreboot/keepassxc,"OSUtils is used before qApp is initialized ## Overview After #6030 was merged we introduced a crash on Linux where `osUtils->canPreventScreenCapture()` is being called in `src/main.cpp` before `Application app(argc, argv);` initializes qApp which is used in the singleton pattern of OSUtils to initialize the class on first call. I suggest we make it an ifdef instead of using OSUtils as the condition whether we can prevent screen capture or not cannot change during runtime anyway. Additionally to prevent this from happening silently in the future we should check qApp in `*Utils::instance()` before passing it along."
406641,451995,https://api.github.com/repos/sdv-dev/SDGym/issues/79,enhancement,2021-05-17T15:35:48Z,MEMBER,https://api.github.com/repos/sdv-dev/SDGym,"Add a way to collect cached results * SDGym version: 0.3.0 ### Description Apart from producing a single dataframe or CSV file with the scores obtained by all the Synthesizers, SDGym has the option to store intermediate results, scores and error logs as the different tasks are run, which are kept inside the `cache_dir`. However, if the sdgym process is cut for some reason, there is no way to find all the intermediate results and put them together as a single CSV file again. It would be interesting to have a `collect_results` function and an `sdgym collect` command that would do this job and allow producing a single scores CSV file from a collection of intermediate cached results."
317180,352634,https://api.github.com/repos/yohann-kevin/testApiMeteo/issues/4,bug,2021-01-16T16:32:03Z,OWNER,https://api.github.com/repos/yohann-kevin/testApiMeteo,fix : bug btn search bug btn search
501809,557759,https://api.github.com/repos/facebookresearch/wav2letter/issues/946,bug,2021-02-03T14:20:53Z,NONE,https://api.github.com/repos/facebookresearch/wav2letter,"cmake not finishing When using cmake to compile I get these errors, I have made sure that the symbolic link cuda points to the cuda 11 but that does not help mitigate this. cmake .. -DCMAKE_BUILD_TYPE=Release -DFL_BUILD_TESTS=OFF -DFL_BUILD_EXAMPLES=OFF -DFL_BUILD_APP_IMGCLASS=OFF -DFL_BUILD_APP_LM=OFF && make -j$(nproc) I get this warning and then error [ 90%] Linking CXX executable bin/asr/fl_asr_sfx_apply [ 90%] Linking CXX executable bin/asr/fl_asr_tutorial_inference_ctc [ 91%] Linking CXX executable bin/asr/fl_asr_tutorial_finetune_ctc [ 91%] Linking CXX executable bin/asr/fl_asr_decode /usr/bin/ld: warning: libnvrtc.so.10.0, needed by /opt/arrayfire/lib64/libafcuda.so.3.7.1, not found (try using -rpath or -rpath-link) /usr/bin/ld: warning: libcublas.so.10.0, needed by /opt/arrayfire/lib64/libafcuda.so.3.7.1, not found (try using -rpath or -rpath-link) /usr/bin/ld: warning: libcufft.so.10.0, needed by /opt/arrayfire/lib64/libafcuda.so.3.7.1, not found (try using -rpath or -rpath-link) /usr/bin/ld: warning: libcusolver.so.10.0, needed by /opt/arrayfire/lib64/libafcuda.so.3.7.1, not found (try using -rpath or -rpath-link) /usr/bin/ld: warning: libcusparse.so.10.0, needed by /opt/arrayfire/lib64/libafcuda.so.3.7.1, not found (try using -rpath or -rpath-link) /usr/bin/ld: /opt/arrayfire/lib64/libafcuda.so.3.7.1: undefined reference to `nvrtcGetErrorString@libnvrtc.so.10.0' collect2: error: ld returned 1 exit status make[2]: *** [CMakeFiles/fl_asr_sfx_apply.dir/build.make:159: bin/asr/fl_asr_sfx_apply] Error 1 make[1]: *** [CMakeFiles/Makefile2:1244: CMakeFiles/fl_asr_sfx_apply.dir/all] Error 2 /usr/bin/ld: /opt/arrayfire/lib64/libafcuda.so.3.7.1: undefined reference to `cusolverDnSgesvd_bufferSize@libcusolver.so.10.0' collect2: error: ld returned 1 exit status make[2]: *** [CMakeFiles/fl_asr_decode.dir/build.make:159: bin/asr/fl_asr_decode] Error 1 make[1]: *** [CMakeFiles/Makefile2:146: CMakeFiles/fl_asr_decode.dir/all] Error 2 make: *** [Makefile:141: all] Error 2"
110155,122439,https://api.github.com/repos/PostHog/posthog/issues/2848,bug,2021-01-05T08:11:50Z,CONTRIBUTOR,https://api.github.com/repos/PostHog/posthog,"Sessions page with lots of unique elements leads to N+1 queries ## In what situation are you experiencing subpar performance? Sessions page on my self-hosted instance never loads. Part of this is https://github.com/PostHog/posthog/issues/2739, but measuring what's happening on the backend also exposed another issue: a N+1 loading elements here: https://github.com/PostHog/posthog/blob/3f7e95d14a5df70e5e5eaaf4a93517e6e2c94878/posthog/queries/sessions_list.py#L116-L120. I think the list of hash_ids is either too long or we're doing another query when processing the results here https://github.com/PostHog/posthog/blob/3f7e95d14a5df70e5e5eaaf4a93517e6e2c94878/posthog/queries/sessions_list.py#L104-L109 ## How to reproduce 1. Have a lot of unique elements on page (e.g. `data-some-attribute=""unique-id""`), measure 2. Open sessions page, count postgres queries made 3. See a very high number. ## Environment - [x] self-hosted PostHog, version/commit: 1.9.0 ## Additional context Elements are used very little on the actual sessions page. If you open a session and within an event, there's a Elements tab + a button to create an action. Both of these could load asynchronously which should speed up the page a lot. :) #### *Thank you* for your performance issue report – we want PostHog to go supersonic! "
477043,530163,https://api.github.com/repos/onflow/flow-cli/issues/190,bug,2021-04-16T16:57:06Z,MEMBER,https://api.github.com/repos/onflow/flow-cli,"Sending a transaction shows different IDs ### Instructions When sending a transaction, the output shows different IDs, not sure why: ``` Sending transaction with ID eddb3dd6f10fabf6873d1578306722dd510d4b21fd00c5757a8aee3a67e3e48c ID 1cff804f008c5618dd8b7fe77382d90d6f713058c91cc1275fdcc1c6d9a626a1 Status SEALED Payer 16fdd39a7bf5afd6 Events Index 0 Type A.7e60df042a9c0868.FlowToken.TokensWithdrawn Tx ID 1cff804f008c5618dd8b7fe77382d90d6f713058c91cc1275fdcc1c6d9a626a1 Values amount (UFix64) 1.00000000 from ({}?) 16fdd39a7bf5afd6 ``` ### Problem The first ID (`eddb3dd6f10fabf6873d1578306722dd510d4b21fd00c5757a8aee3a67e3e48c`) seems to be wrong, the second ID is valid (`1cff804f008c5618dd8b7fe77382d90d6f713058c91cc1275fdcc1c6d9a626a1`). ### Steps to Reproduce - ### Acceptance Criteria IDs should be consistent and valid "
138635,154085,https://api.github.com/repos/Ysurac/openmptcprouter/issues/1411,bug,2020-11-24T00:36:01Z,NONE,https://api.github.com/repos/Ysurac/openmptcprouter,"VPN Tunnel Down <!--- Use this template, else issue may be closed automatically --> ## Expected Behavior <!--- In English please. --> <!--- Tell us what should happen --> VPN Tunnel to work ## Current Behavior <!--- In English please. --> <!--- Tell us what happens instead of the expected behavior --> VPN tunnel is not working despite being enabled ## Possible Solution <!--- In English please. --> <!--- Not obligatory, but suggest a fix/reason for the bug, --> ## Steps to Reproduce the Problem 1. ? 2.? 3.? ## Context (Environment) <!--- How has this issue affected you? What are you trying to accomplish? --> <!--- Providing context helps us come up with a solution that is most useful in the real world --> <!--- Provide a general summary of the issue in the Title above --> Here are all my settings dhcp.@dnsmasq[0]=dnsmasq dhcp.@dnsmasq[0].domainneeded='1' dhcp.@dnsmasq[0].localise_queries='1' dhcp.@dnsmasq[0].local='/lan/' dhcp.@dnsmasq[0].domain='lan' dhcp.@dnsmasq[0].expandhosts='1' dhcp.@dnsmasq[0].readethers='1' dhcp.@dnsmasq[0].leasefile='/tmp/dhcp.leases' dhcp.@dnsmasq[0].localservice='1' dhcp.@dnsmasq[0].noresolv='1' dhcp.@dnsmasq[0].nonegcache='1' dhcp.@dnsmasq[0].rebind_protection='0' dhcp.@dnsmasq[0].server='/lan/' '/use-application-dns.net/' '10.255.255.1#53' '10.255.254.1#53' '127.0.0.1#5353' '127.0.0.1#5353' '127.0.0.1#5353' '127.0.0.1#5353' '127.0.0.1#5353' '127.0.0.1#5353' dhcp.@dnsmasq[0].rebind_domain='plex.direct' dhcp.@dnsmasq[0].ipset='/googlevideo.com/omr_dscp-cs4,omr_dscp6-cs4' '/nflxvideo.net/omr_dscp-cs4,omr_dscp6-cs4' '/s3.ll.dash.row.aiv-cdn.net/omr_dscp-cs4,omr_dscp6-cs4' '/d25xi40x97liuc.cloudfront.net/omr_dscp-cs4,omr_dscp6-cs4' '/aiv-delivery.net/omr_dscp-cs4,omr_dscp6-cs4' '/audio-fa.scdn.com/omr_dscp-cs4,omr_dscp6-cs4' '/deezer.com/omr_dscp-cs4,omr_dscp6-cs4' '/sndcdn.com/omr_dscp-cs4,omr_dscp6-cs4' '/last.fm/omr_dscp-cs4,omr_dscp6-cs4' '/v.redd.it/omr_dscp-cs4,omr_dscp6-cs4' '/googletagmanager.com/omr_dscp-cs2,omr_dscp6-cs2' '/google.com/omr_dscp-cs2,omr_dscp6-cs2' '/fbcdn.net/omr_dscp-cs4,omr_dscp6-cs4,omr_dscp-cs2,omr_dscp6-cs2' '/akamaihd.net/omr_dscp-cs2,omr_dscp6-cs2' '/whatsapp.net/omr_dscp-cs2,omr_dscp6-cs2' '/whatsapp.com/omr_dscp-cs2,omr_dscp6-cs2' '/googleapis.com/omr_dscp-cs2,omr_dscp6-cs2' '/hwcdn.net/omr_dscp-cs2,omr_dscp6-cs2' '/download.qq.com/omr_dscp-cs1,omr_dscp6-cs1' '/gs2.ww.prod.dl.playstation.net/omr_dscp-cs1,omr_dscp6-cs1' '/dropbox.com/omr_dscp-cs1,omr_dscp6-cs1' '/dropboxstatic.com/omr_dscp-cs1,omr_dscp6-cs1' '/dropbox-dns.com/omr_dscp-cs1,omr_dscp6-cs1' '/log.getdropbox.com/omr_dscp-cs1,omr_dscp6-cs1' '/drive.google.com/omr_dscp-cs1,omr_dscp6-cs1' '/drive-thirdparty.googleusercontent.com/omr_dscp-cs1,omr_dscp6-cs1' '/gvt1.com/omr_dscp-cs1,omr_dscp6-cs1' '/mmg-fna.whatsapp.net/omr_dscp-cs1,omr_dscp6-cs1' '/upload.youtube.com/omr_dscp-cs1,omr_dscp6-cs1' '/upload.video.google.com/omr_dscp-cs1,omr_dscp6-cs1' '/windowsupdate.com/omr_dscp-cs1,omr_dscp6-cs1' '/update.microsoft.com/omr_dscp-cs1,omr_dscp6-cs1' '/spotify.ac/omr_dst_bypass_eth1,omr6_dst_bypass_eth1,omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ac/omr_dst_bypass_eth1,omr6_dst_bypass_eth1,omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ae/omr_dst_bypass_eth1,omr6_dst_bypass_eth1,omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ae/omr_dst_bypass_eth1,omr6_dst_bypass_eth1,omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.africa/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.africa/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.africa/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ag/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ag/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ag/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ai/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ai/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ai/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.am/omr_dst_bypass_eth1,omr6_dst_bypass_eth1,omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.am/omr_dst_bypass_eth1,omr6_dst_bypass_eth1,omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.app/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.app/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.app/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ar/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ar/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ar/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.arab/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.arab/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.arab/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.as/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.as/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.as/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.asia/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.asia/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.asia/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.at/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.at/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.at/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.audio/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.audio/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.audio/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.author/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.author/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.author/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.aws/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.aws/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.aws/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.az/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.az/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.az/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ba/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ba/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ba/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.band/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.band/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.band/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bar/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bar/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bar/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bayern/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bayern/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bayern/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.be/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.be/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.be/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bet/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bet/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bet/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bg/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bg/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bg/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bi/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bi/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bi/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bio/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bio/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bio/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.biz/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.biz/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.biz/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.black/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.black/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.black/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.blog/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.blog/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.blog/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.blue/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.blue/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.blue/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bo/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bo/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bo/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bs/omr_dst_bypass_eth1,omr6_dst_bypass_eth1,omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bs/omr_dst_bypass_eth1,omr6_dst_bypass_eth1,omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.by/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.by/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.by/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bz/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bz/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.bz/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ca/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ca/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ca/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cam/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cam/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cam/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.car/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.car/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.car/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.casa/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.casa/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.casa/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cc/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cc/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cc/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cf/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cf/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cf/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ch/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ch/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ch/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cl/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cl/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cl/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.click/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.click/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.click/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cloud/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cloud/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cloud/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cm/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cm/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cm/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cn/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cn/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cn/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.co/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.co/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.co/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.com/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.com/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.com/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cpa/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cpa/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cpa/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cz/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cz/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.cz/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.de/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.de/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.de/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.design/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.design/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.design/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.dev/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.dev/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.dev/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.dj/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.dj/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.dj/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.dk/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.dk/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.dk/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.earth/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.earth/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.earth/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ee/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ee/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ee/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.engineering/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.engineering/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.engineering/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.es/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.es/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.es/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.fi/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.fi/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.fi/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.fit/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.fit/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.fit/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.fm/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.fm/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.fm/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.fr/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.fr/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.fr/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.fun/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.fun/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.fun/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ga/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ga/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ga/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.gg/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.gg/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.gg/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.gift/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.gift/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.gift/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.global/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.global/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.global/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.gq/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.gq/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.gq/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.gr/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.gr/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.gr/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.green/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.green/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.green/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.gw/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.gw/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.gw/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.help/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.help/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.help/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.hr/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.hr/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.hr/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.hu/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.hu/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.hu/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.icu/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.icu/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.icu/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.id/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.id/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.id/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ie/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ie/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ie/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.in/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.in/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.in/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.inc/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.inc/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.inc/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.info/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.info/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.info/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ink/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ink/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ink/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.io/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.io/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.io/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ir/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ir/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ir/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.it/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.it/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.it/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.jobs/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.jobs/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.jobs/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.jp/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.jp/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.jp/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ke/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ke/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ke/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.kim/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.kim/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.kim/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.kr/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.kr/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.kr/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.kz/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.kz/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.kz/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.la/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.la/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.la/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.link/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.link/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.link/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.lk/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.lk/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.lk/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.llp/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.llp/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.llp/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.lol/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.lol/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.lol/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.love/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.love/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.love/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.lt/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.lt/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.lt/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.luxe/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.luxe/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.luxe/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.lv/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.lv/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.lv/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ma/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ma/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ma/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.md/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.md/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.md/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.me/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.me/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.me/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.menu/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.menu/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.menu/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.miami/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.miami/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.miami/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.mk/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.mk/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.mk/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ml/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ml/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ml/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.mn/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.mn/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.mn/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.mobi/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.mobi/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.mobi/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.moe/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.moe/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.moe/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.mom/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.mom/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.mom/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.net/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.net/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.net/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.nl/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.nl/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.nl/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.no/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.no/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.no/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.nu/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.nu/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.nu/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.nyc/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.nyc/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.nyc/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.observer/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.observer/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.observer/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.one/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.one/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.one/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ooo/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ooo/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ooo/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.org/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.org/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.org/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.page/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.page/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.page/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.party/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.party/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.party/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pe/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pe/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pe/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pet/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pet/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pet/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ph/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ph/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ph/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pink/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pink/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pink/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pk/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pk/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pk/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pl/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pl/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pl/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pm/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pm/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pm/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.politie/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.politie/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.politie/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pro/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pro/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pro/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.promo/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.promo/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.promo/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pt/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pt/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pt/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pw/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pw/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.pw/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.realty/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.realty/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.realty/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.rest/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.rest/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.rest/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ro/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ro/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ro/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.rocks/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.rocks/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.rocks/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.rs/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.rs/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.rs/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ru/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ru/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ru/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.rw/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.rw/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.rw/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.se/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.se/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.se/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.shop/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.shop/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.shop/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.si/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.si/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.si/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.site/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.site/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.site/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.sk/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.sk/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.sk/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.sl/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.sl/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.sl/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.sn/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.sn/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.sn/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.space/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.space/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.space/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.st/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.st/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.st/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.studio/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.studio/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.studio/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.su/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.su/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.su/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.sucks/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.sucks/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.sucks/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.surf/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.surf/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.surf/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.td/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.td/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.td/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tech/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tech/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tech/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tg/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tg/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tg/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tl/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tl/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tl/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tn/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tn/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tn/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.to/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.to/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.to/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tokyo/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tokyo/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tokyo/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tube/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tube/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tube/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tv/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tv/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tv/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tz/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tz/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.tz/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ua/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ua/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ua/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.uk/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.uk/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.uk/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.us/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.us/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.us/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.uz/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.uz/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.uz/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.vg/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.vg/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.vg/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.vip/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.vip/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.vip/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.vn/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.vn/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.vn/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.wang/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.wang/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.wang/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.website/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.website/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.website/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.work/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.work/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.work/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ws/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ws/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.ws/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--fiq228c5hs/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--fiq228c5hs/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--fiq228c5hs/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--fiqs8s/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--fiqs8s/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--fiqs8s/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--fiqz9s/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--fiqz9s/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--fiqz9s/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--kprw13d/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--kprw13d/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--kprw13d/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--mxtq1m/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--mxtq1m/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--mxtq1m/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--ngbrx/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--ngbrx/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--ngbrx/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--node/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--node/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--node/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--rhqv96g/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--rhqv96g/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--rhqv96g/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--ygbi2ammx/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--ygbi2ammx/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xn--ygbi2ammx/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xxx/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xxx/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xxx/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xyz/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xyz/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.xyz/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.yt/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.yt/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotify.yt/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/audio-fa.scdn.co/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/audio-fa.scdn.co/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/audio-fa.scdn.co/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotifycdn.net/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotifycdn.net/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/spotifycdn.net/omr_dst_bypass_eth1,omr6_dst_bypass_eth1' '/googlesyndication.com/omr_dst_bypass_eth5,omr6_dst_bypass_eth5,omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googlesyndication.com/omr_dst_bypass_eth5,omr6_dst_bypass_eth5,omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.am/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.am/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.am/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.amsterdam/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.amsterdam/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.amsterdam/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.app/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.app/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.app/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.ar/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.ar/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.ar/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.arab/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.arab/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.arab/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.asia/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.asia/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.asia/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.at/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.at/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.at/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.ba/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.ba/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.ba/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.barcelona/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.barcelona/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.barcelona/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.best/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.best/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.best/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.bh/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.bh/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.bh/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.bid/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.bid/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.bid/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.biz/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.biz/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.biz/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.blog/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.blog/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.blog/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.buzz/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.buzz/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.buzz/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.ca/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.ca/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.ca/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.cat/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.cat/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.cat/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.center/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.center/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.center/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.cf/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.cf/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.cf/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.ch/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.ch/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.ch/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.click/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.click/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.click/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.club/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.club/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.club/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.cn/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.cn/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.cn/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.co/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.co/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.co/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.company/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.company/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.company/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.cpa/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.cpa/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.cpa/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.cz/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.cz/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.cz/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.de/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.de/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.de/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.dk/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.dk/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.dk/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.ee/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.ee/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.ee/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.email/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.email/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.email/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.es/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.es/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.es/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.expert/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.expert/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.expert/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.fr/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.fr/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.fr/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.ge/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.ge/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.ge/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.gp/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.gp/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.gp/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.guru/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.guru/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.guru/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.hu/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.hu/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.hu/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.in/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.in/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.in/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.info/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.info/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.info/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.io/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.io/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.io/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.ir/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.ir/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.ir/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.is/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.is/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.is/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.it/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.it/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' '/googleads.it/omr_dst_bypass_eth5,omr6_dst_bypass_eth5' dhcp.lan=dhcp dhcp.lan.interface='lan' dhcp.lan.ra_slaac='1' dhcp.lan.ra_flags='managed-config' 'other-config' dhcp.lan.ignore='1' dhcp.lan.force='1' dhcp.lan.ra_default='1' dhcp.lan.dhcpv6='server' dhcp.wan=dhcp dhcp.wan.interface='wan' dhcp.wan.ignore='1' dhcp.odhcpd=odhcpd dhcp.odhcpd.maindhcp='0' dhcp.odhcpd.leasefile='/tmp/hosts/odhcpd' dhcp.odhcpd.leasetrigger='/usr/sbin/odhcpd-update' dhcp.odhcpd.loglevel='4' dhcp.@domain[0]=domain dhcp.@domain[0].name='scopeboss' dhcp.@domain[0].ip='192.168.1.46' dhcp.@domain[1]=domain dhcp.@domain[1].name='colour-computer' dhcp.@domain[1].ip='192.168.1.42' dhcp.@domain[2]=domain dhcp.@domain[2].name='HomeAssist' dhcp.@domain[2].ip='192.168.1.151' dhcp.@domain[3]=domain dhcp.@domain[3].name='inkpot' dhcp.@domain[3].ip='192.168.1.81' dropbear.@dropbear[0]=dropbear dropbear.@dropbear[0].PasswordAuth='on' dropbear.@dropbear[0].RootPasswordAuth='on' dropbear.@dropbear[0].Port='22' dscp.@classify[0]=classify dscp.@classify[0].direction='both' dscp.@classify[0].proto='icmp' dscp.@classify[0].class='cs5' dscp.@classify[0].comment='ICMP' dscp.@classify[1]=classify dscp.@classify[1].direction='both' dscp.@classify[1].proto='udp' dscp.@classify[1].class='cs5' dscp.@classify[1].src_port='53,123,5353' dscp.@classify[1].comment='DNS udp and NTP' dscp.@classify[2]=classify dscp.@classify[2].direction='both' dscp.@classify[2].proto='tcp' dscp.@classify[2].class='cs5' dscp.@classify[2].src_port='53,5353' dscp.@classify[2].comment='DNS tcp' dscp.@classify[3]=classify dscp.@classify[3].direction='both' dscp.@classify[3].proto='tcp' dscp.@classify[3].class='cs6' dscp.@classify[3].dest_port='65001,65301,65011' dscp.@classify[3].comment='OMR vpn' dscp.@classify[4]=classify dscp.@classify[4].direction='both' dscp.@classify[4].proto='udp' dscp.@classify[4].class='cs6' dscp.@classify[4].dest_port='65001' dscp.@classify[4].comment='OMR vpn' dscp.@domains[0]=domains dscp.@domains[0].name='googlevideo.com' dscp.@domains[0].class='cs4' dscp.@domains[0].comment='Youtube' dscp.@domains[1]=domains dscp.@domains[1].name='nflxvideo.net' dscp.@domains[1].class='cs4' dscp.@domains[1].comment='NetFlix' dscp.@domains[2]=domains dscp.@domains[2].name='s3.ll.dash.row.aiv-cdn.net' dscp.@domains[2].class='cs4' dscp.@domains[2].comment='AmazonVideo' dscp.@domains[3]=domains dscp.@domains[3].name='d25xi40x97liuc.cloudfront.net' dscp.@domains[3].class='cs4' dscp.@domains[3].comment='AmazonVideo' dscp.@domains[4]=domains dscp.@domains[4].name='aiv-delivery.net' dscp.@domains[4].class='cs4' dscp.@domains[4].comment='AmazonVideo' dscp.@domains[5]=domains dscp.@domains[5].name='fbcdn.net' dscp.@domains[5].class='cs4' dscp.@domains[5].comment='Facebook' dscp.@domains[6]=domains dscp.@domains[6].name='ttvnw.net' dscp.@domains[6].class='cs4' dscp.@domains[6].comment='Twitch' dscp.@domains[7]=domains dscp.@domains[7].name='vevo.com' dscp.@domains[7].class='cs4' dscp.@domains[7].comment='VeVo' dscp.@domains[8]=domains dscp.@domains[8].name='audio-fa.scdn.com' dscp.@domains[8].class='cs4' dscp.@domains[8].comment='Spotify' dscp.@domains[9]=domains dscp.@domains[9].name='deezer.com' dscp.@domains[9].class='cs4' dscp.@domains[9].comment='Deezer' dscp.@domains[10]=domains dscp.@domains[10].name='sndcdn.com' dscp.@domains[10].class='cs4' dscp.@domains[10].comment='SoundCloud' dscp.@domains[11]=domains dscp.@domains[11].name='last.fm' dscp.@domains[11].class='cs4' dscp.@domains[11].comment='last.fm' dscp.@domains[12]=domains dscp.@domains[12].name='v.redd.it' dscp.@domains[12].class='cs4' dscp.@domains[12].comment='reddit videos' dscp.@domains[13]=domains dscp.@domains[13].name='ttvnw.net' dscp.@domains[13].class='cs4' dscp.@domains[13].comment='twitch.tv' dscp.@domains[14]=domains dscp.@domains[14].name='googletagmanager.com' dscp.@domains[14].class='cs2' dscp.@domains[14].comment='cdn' dscp.@domains[15]=domains dscp.@domains[15].name='googleusercontent.com' dscp.@domains[15].class='cs2' dscp.@domains[15].comment='cdn' dscp.@domains[16]=domains dscp.@domains[16].name='google.com' dscp.@domains[16].class='cs2' dscp.@domains[16].comment='cdn' dscp.@domains[17]=domains dscp.@domains[17].name='fbcdn.net' dscp.@domains[17].class='cs2' dscp.@domains[17].comment='cdn' dscp.@domains[18]=domains dscp.@domains[18].name='akamaihd.net' dscp.@domains[18].class='cs2' dscp.@domains[18].comment='cdn' dscp.@domains[19]=domains dscp.@domains[19].name='whatsapp.net' dscp.@domains[19].class='cs2' dscp.@domains[19].comment='cdn' dscp.@domains[20]=domains dscp.@domains[20].name='whatsapp.com' dscp.@domains[20].class='cs2' dscp.@domains[20].comment='cdn' dscp.@domains[21]=domains dscp.@domains[21].name='googleapis.com' dscp.@domains[21].class='cs2' dscp.@domains[21].comment='cdn' dscp.@domains[22]=domains dscp.@domains[22].name='1e100.net' dscp.@domains[22].class='cs2' dscp.@domains[22].comment='cdn' dscp.@domains[23]=domains dscp.@domains[23].name='hwcdn.net' dscp.@domains[23].class='cs2' dscp.@domains[23].comment='cdn' dscp.@domains[24]=domains dscp.@domains[24].name='download.qq.com' dscp.@domains[24].class='cs1' dscp.@domains[24].comment='qq download' dscp.@domains[25]=domains dscp.@domains[25].name='steamcontent.com' dscp.@domains[25].class='cs1' dscp.@domains[25].comment='Steam download' dscp.@domains[26]=domains dscp.@domains[26].name='gs2.ww.prod.dl.playstation.net' dscp.@domains[26].class='cs1' dscp.@domains[26].comment='PSN download' dscp.@domains[27]=domains dscp.@domains[27].name='dropbox.com' dscp.@domains[27].class='cs1' dscp.@domains[27].comment='Dropbox' dscp.@domains[28]=domains dscp.@domains[28].name='dropboxstatic.com' dscp.@domains[28].class='cs1' dscp.@domains[28].comment='Dropbox' dscp.@domains[29]=domains dscp.@domains[29].name='dropbox-dns.com' dscp.@domains[29].class='cs1' dscp.@domains[29].comment='Dropbox' dscp.@domains[30]=domains dscp.@domains[30].name='log.getdropbox.com' dscp.@domains[30].class='cs1' dscp.@domains[30].comment='Dropbox' dscp.@domains[31]=domains dscp.@domains[31].name='drive.google.com' dscp.@domains[31].class='cs1' dscp.@domains[31].comment='Google Drive' dscp.@domains[32]=domains dscp.@domains[32].name='drive-thirdparty.googleusercontent.com' dscp.@domains[32].class='cs1' dscp.@domains[32].comment='Google Drive' dscp.@domains[33]=domains dscp.@domains[33].name='docs.google.com' dscp.@domains[33].class='cs1' dscp.@domains[33].comment='Google Docs' dscp.@domains[34]=domains dscp.@domains[34].name='docs.googleusercontent.com' dscp.@domains[34].class='cs1' dscp.@domains[34].comment='Google Docs' dscp.@domains[35]=domains dscp.@domains[35].name='gvt1.com' dscp.@domains[35].class='cs1' dscp.@domains[35].comment='PlayStore Download' dscp.@domains[36]=domains dscp.@domains[36].name='mmg-fna.whatsapp.net' dscp.@domains[36].class='cs1' dscp.@domains[36].comment='WhatsApp Files' dscp.@domains[37]=domains dscp.@domains[37].name='upload.youtube.com' dscp.@domains[37].class='cs1' dscp.@domains[37].comment='Youtube Upload' dscp.@domains[38]=domains dscp.@domains[38].name='upload.video.google.com' dscp.@domains[38].class='cs1' dscp.@domains[38].comment='Youtube Upload' dscp.@domains[39]=domains dscp.@domains[39].name='windowsupdate.com' dscp.@domains[39].class='cs1' dscp.@domains[39].comment='WindowsUpdate' dscp.@domains[40]=domains dscp.@domains[40].name='update.microsoft.com' dscp.@domains[40].class='cs1' dscp.@domains[40].comment='WindowsUpdate' dsvpn.vpn=dsvpn dsvpn.vpn.dev='tun0' dsvpn.vpn.localip='10.255.251.2' dsvpn.vpn.remoteip='10.255.251.1' dsvpn.vpn.host='51.195.168.66' dsvpn.vpn.key='D02F9EAAF334FB00208046AFE864E24DFB59BCAF01379A28424EDBAF4C9C1646' dsvpn.vpn.enable='0' dsvpn.vpn.port='65401' etherwake.setup=etherwake etherwake.setup.pathes='/usr/bin/etherwake /usr/bin/ether-wake' etherwake.setup.sudo='off' etherwake.setup.broadcast='off' etherwake.@target[0]=target etherwake.@target[0].name='example' etherwake.@target[0].mac='11:22:33:44:55:66' etherwake.@target[0].password='AABBCCDDEEFF' etherwake.@target[0].wakeonboot='off' firewall.@defaults[0]=defaults firewall.@defaults[0].syn_flood='1' firewall.@defaults[0].forward='REJECT' firewall.@defaults[0].input='REJECT' firewall.@defaults[0].output='REJECT' firewall.@defaults[0].disable_ipv6='1' firewall.@zone[0]=zone firewall.@zone[0].name='lan' firewall.@zone[0].input='ACCEPT' firewall.@zone[0].output='ACCEPT' firewall.@zone[0].forward='ACCEPT' firewall.@zone[0].mtu_fix='1' firewall.@zone[0].network='lan' firewall.@zone[0].auto_helper='0' firewall.@zone[1]=zone firewall.@zone[1].name='wan' firewall.@zone[1].input='REJECT' firewall.@zone[1].output='ACCEPT' firewall.@zone[1].forward='REJECT' firewall.@zone[1].masq='1' firewall.@zone[1].mtu_fix='1' firewall.@zone[1].network='wan' 'wan6' 'wan1' 'wan2' 'wan3' 'wan4' firewall.@forwarding[0]=forwarding firewall.@forwarding[0].src='lan' firewall.@forwarding[0].dest='wan' firewall.@rule[0]=rule firewall.@rule[0].name='Allow-DHCP-Renew' firewall.@rule[0].src='wan' firewall.@rule[0].proto='udp' firewall.@rule[0].dest_port='68' firewall.@rule[0].target='ACCEPT' firewall.@rule[0].family='ipv4' firewall.@rule[1]=rule firewall.@rule[1].name='Allow-Ping' firewall.@rule[1].src='wan' firewall.@rule[1].proto='icmp' firewall.@rule[1].icmp_type='echo-request' firewall.@rule[1].family='ipv4' firewall.@rule[1].target='ACCEPT' firewall.@rule[2]=rule firewall.@rule[2].name='Allow-IGMP' firewall.@rule[2].src='wan' firewall.@rule[2].proto='igmp' firewall.@rule[2].family='ipv4' firewall.@rule[2].target='ACCEPT' firewall.@rule[3]=rule firewall.@rule[3].name='Allow-DHCPv6' firewall.@rule[3].src='wan' firewall.@rule[3].proto='udp' firewall.@rule[3].src_ip='fc00::/6' firewall.@rule[3].dest_ip='fc00::/6' firewall.@rule[3].dest_port='546' firewall.@rule[3].family='ipv6' firewall.@rule[3].target='ACCEPT' firewall.@rule[4]=rule firewall.@rule[4].name='Allow-MLD' firewall.@rule[4].src='wan' firewall.@rule[4].proto='icmp' firewall.@rule[4].src_ip='fe80::/10' firewall.@rule[4].icmp_type='130/0' '131/0' '132/0' '143/0' firewall.@rule[4].family='ipv6' firewall.@rule[4].target='ACCEPT' firewall.@rule[5]=rule firewall.@rule[5].name='Allow-IPSec-ESP' firewall.@rule[5].src='wan' firewall.@rule[5].dest='lan' firewall.@rule[5].proto='esp' firewall.@rule[5].target='ACCEPT' firewall.@rule[6]=rule firewall.@rule[6].name='Allow-ISAKMP' firewall.@rule[6].src='wan' firewall.@rule[6].dest='lan' firewall.@rule[6].dest_port='500' firewall.@rule[6].proto='udp' firewall.@rule[6].target='ACCEPT' firewall.@rule[7]=rule firewall.@rule[7].name='Support-UDP-Traceroute' firewall.@rule[7].src='wan' firewall.@rule[7].dest_port='33434:33689' firewall.@rule[7].proto='udp' firewall.@rule[7].family='ipv4' firewall.@rule[7].target='REJECT' firewall.@rule[7].enabled='false' firewall.@include[0]=include firewall.@include[0].path='/etc/firewall.user' firewall.@rule[8]=rule firewall.@rule[8].enabled='1' firewall.@rule[8].target='ACCEPT' firewall.@rule[8].name='Allow-All-LAN-to-VPN' firewall.@rule[8].dest='vpn' firewall.@rule[8].src='lan' firewall.@rule[9]=rule firewall.@rule[9].enabled='1' firewall.@rule[9].target='ACCEPT' firewall.@rule[9].name='Allow-All-Ping' firewall.@rule[9].proto='icmp' firewall.@rule[9].dest='*' firewall.@rule[9].src='*' firewall.@rule[9].icmp_type='echo-request' firewall.@rule[10]=rule firewall.@rule[10].enabled='1' firewall.@rule[10].target='ACCEPT' firewall.@rule[10].name='Allow-VPN-ICMP' firewall.@rule[10].proto='icmp' firewall.@rule[10].src='vpn' firewall.@rule[11]=rule firewall.@rule[11].enabled='1' firewall.@rule[11].target='ACCEPT' firewall.@rule[11].name='Allow-Lan-to-Wan' firewall.@rule[11].dest='wan' firewall.@rule[11].src='lan' firewall.@rule[12]=rule firewall.@rule[12].enabled='1' firewall.@rule[12].target='ACCEPT' firewall.@rule[12].name='ICMPv6-Lan-to-OMR' firewall.@rule[12].src='lan' firewall.@rule[12].family='ipv6' firewall.@rule[12].proto='icmp' firewall.@rule[12].limit='1000/sec' firewall.@rule[12].icmp_type='echo-reply destination-unreachable echo-request router-advertisement router-solicitation time-exceeded' firewall.omr_server=include firewall.omr_server.path='/etc/firewall.omr-server' firewall.omr_server.reload='1' firewall.gre_tunnel=include firewall.gre_tunnel.path='/etc/firewall.gre-tunnel' firewall.gre_tunnel.reload='1' firewall.ss_rules=include firewall.ss_rules.path='/etc/firewall.ss-rules' firewall.ss_rules.reload='1' firewall.@redirect[0]=redirect firewall.@redirect[0].target='DNAT' firewall.@redirect[0].proto='udp' firewall.@redirect[0].src='vpn' firewall.@redirect[0].src_dport='1194' firewall.@redirect[0].dest='lan' firewall.@redirect[0].name='VPN' firewall.@redirect[0].dest_port='1194' firewall.@redirect[0].dest_ip='192.168.1.46' firewall.@nat[0]=nat firewall.@nat[0].proto='udp' firewall.@nat[0].src='lan' firewall.@nat[0].dest_ip='192.168.1.46' firewall.@nat[0].target='SNAT' firewall.@nat[0].snat_ip='192.168.100.1' firewall.@nat[0].dest_port='1194' firewall.@nat[0].name='VPN' firewall.@nat[1]=nat firewall.@nat[1].name='nextcloud' firewall.@nat[1].proto='tcp' firewall.@nat[1].src='lan' firewall.@nat[1].dest_ip='192.168.1.46' firewall.@nat[1].dest_port='5050' firewall.@nat[1].target='SNAT' firewall.@nat[1].snat_ip='192.168.100.1' firewall.@nat[1].enabled='0' firewall.@redirect[1]=redirect firewall.@redirect[1].target='DNAT' firewall.@redirect[1].proto='tcp' firewall.@redirect[1].src='vpn' firewall.@redirect[1].src_dport='80' firewall.@redirect[1].dest='lan' firewall.@redirect[1].dest_ip='192.168.1.46' firewall.@redirect[1].dest_port='5050' firewall.@redirect[2]=redirect firewall.@redirect[2].target='DNAT' firewall.@redirect[2].src_dport='1935' firewall.@redirect[2].dest='lan' firewall.@redirect[2].dest_ip='192.168.1.46' firewall.@redirect[2].dest_port='1935' firewall.@redirect[2].src='vpn' firewall.@redirect[2].name='RTMP Stream' firewall.fwlantovpn=forwarding firewall.fwlantovpn.src='lan' firewall.fwlantovpn.dest='vpn' firewall.v2ray=include firewall.v2ray.reload='1' firewall.v2ray.path='/etc/firewall.v2ray-rules' firewall.omr_bypass=include firewall.omr_bypass.path='/etc/firewall.omr-bypass' firewall.omr_bypass.reload='1' firewall.blockquicproxy=rule firewall.blockquicproxy.name='Block QUIC Proxy' firewall.blockquicproxy.proto='udp' firewall.blockquicproxy.dest_port='443' firewall.blockquicproxy.target='DROP' firewall.blockquicproxy.src='lan' firewall.blockquicall=rule firewall.blockquicall.name='Block QUIC All' firewall.blockquicall.proto='udp' firewall.blockquicall.src='*' firewall.blockquicall.dest='*' firewall.blockquicall.dest_port='443' firewall.blockquicall.target='DROP' firewall.@redirect[3]=redirect firewall.@redirect[3].target='DNAT' firewall.@redirect[3].src_dport='33001' firewall.@redirect[3].dest_ip='192.168.1.46' firewall.@redirect[3].dest_port='33001' firewall.@redirect[3].name='aspera' firewall.@redirect[3].src='lan' firewall.@redirect[3].dest='vpn' firewall.@redirect[3].enabled='0' firewall.@redirect[4]=redirect firewall.@redirect[4].target='DNAT' firewall.@redirect[4].name='Home Assistant' firewall.@redirect[4].src='vpn' firewall.@redirect[4].src_dport='8123' firewall.@redirect[4].dest='lan' firewall.@redirect[4].dest_ip='192.168.1.151' firewall.@redirect[4].dest_port='8123' firewall.zone_vpn=zone firewall.zone_vpn.name='vpn' firewall.zone_vpn.masq='1' firewall.zone_vpn.input='REJECT' firewall.zone_vpn.forward='ACCEPT' firewall.zone_vpn.output='ACCEPT' firewall.zone_vpn.mtu_fix='1' firewall.zone_vpn.network='glorytun' 'omrvpn' 'omr6in4' firewall.allow_dhcp_request_vpn=rule firewall.allow_dhcp_request_vpn.name='Allow-DHCP-Request-VPN' firewall.allow_dhcp_request_vpn.src='vpn' firewall.allow_dhcp_request_vpn.proto='udp' firewall.allow_dhcp_request_vpn.dest_port='67' firewall.allow_dhcp_request_vpn.target='ACCEPT' firewall.allow_dhcp_request_vpn.family='ipv4' firewall.miniupnpd=include firewall.miniupnpd.type='script' firewall.miniupnpd.path='/usr/share/miniupnpd/firewall.include' firewall.miniupnpd.family='any' firewall.miniupnpd.reload='1' firewall.@redirect[5]=redirect firewall.@redirect[5].target='DNAT' firewall.@redirect[5].name='stream.johnrogerscolour.co.uk' firewall.@redirect[5].src='vpn' firewall.@redirect[5].src_dport='80' firewall.@redirect[5].dest='lan' firewall.@redirect[5].dest_ip='192.168.1.46' firewall.@redirect[5].dest_port='6060' fstab.@global[0]=global fstab.@global[0].anon_swap='0' fstab.@global[0].anon_mount='0' fstab.@global[0].auto_swap='1' fstab.@global[0].auto_mount='1' fstab.@global[0].delay_root='5' fstab.@global[0].check_fs='0' fstab.@mount[0]=mount fstab.@mount[0].target='/boot' fstab.@mount[0].uuid='8DD0-86D5' fstab.@mount[0].enabled='0' fstab.@mount[1]=mount fstab.@mount[1].target='/' fstab.@mount[1].uuid='ff313567-e9f1-5a5d-9895-3ba130b4a864' fstab.@mount[1].enabled='0' glorytun.vpn=glorytun glorytun.vpn.port='65001' glorytun.vpn.dev='tun0' glorytun.vpn.mptcp='1' glorytun.vpn.proto='tcp' glorytun.vpn.mtuauto='1' glorytun.vpn.localip='10.255.255.2' glorytun.vpn.remoteip='10.255.255.1' glorytun.vpn.multiqueue='1' glorytun.vpn.host='51.195.168.66' glorytun.vpn.key='312EC4AC511941FD12376A145C1317A91A4979D6CC4AA8E660749152FA1C9CEF' glorytun.vpn.chacha20='1' glorytun.vpn.enable='1' glorytun_recipes.servertcp=glorytun_recipe glorytun_recipes.servertcp._description='Simple TCP server configuration' glorytun_recipes.servertcp._role='server' glorytun_recipes.servertcp.port='65001' glorytun_recipes.servertcp.dev='tun0' glorytun_recipes.servertcp.key='secretkey' glorytun_recipes.servertcp.listener='1' glorytun_recipes.servertcp.localip='192.168.99.1' glorytun_recipes.servertcp.remoteip='192.168.99.2' glorytun_recipes.servertcp.proto='tcp' glorytun_recipes.servertcp.enable='0' glorytun_recipes.clienttcp=glorytun_recipe glorytun_recipes.clienttcp._description='Simple TCP client configuration' glorytun_recipes.clienttcp._role='client' glorytun_recipes.clienttcp.port='65001' glorytun_recipes.clienttcp.dev='tun0' glorytun_recipes.clienttcp.host='vpnserver.example.org' glorytun_recipes.clienttcp.key='secretkey' glorytun_recipes.clienttcp.localip='192.168.99.2' glorytun_recipes.clienttcp.remoteip='192.168.99.1' glorytun_recipes.clienttcp.proto='tcp' glorytun_recipes.clienttcp.enable='0' glorytun_recipes.serverudp=glorytun_recipe glorytun_recipes.serverudp._description='Simple UDP server configuration' glorytun_recipes.serverudp._role='server' glorytun_recipes.serverudp.dev='tun0' glorytun_recipes.serverudp.bindport='65003' glorytun_recipes.serverudp.bind='192.168.99.1' glorytun_recipes.serverudp.key='secretkey' glorytun_recipes.serverudp.localip='192.168.99.1' glorytun_recipes.serverudp.remoteip='192.168.99.2' glorytun_recipes.serverudp.proto='udp' glorytun_recipes.serverudp.mtuauto='1' glorytun_recipes.serverudp.enable='0' glorytun_recipes.clientudp=glorytun_recipe glorytun_recipes.clientudp._description='Simple UDP client configuration' glorytun_recipes.clientudp._role='client' glorytun_recipes.clientudp.port='65003' glorytun_recipes.clientudp.dev='tun0' glorytun_recipes.clientudp.host='vpnserver.example.org' glorytun_recipes.clientudp.key='secretkey' glorytun_recipes.clientudp.localip='192.168.99.2' glorytun_recipes.clientudp.remoteip='192.168.99.1' glorytun_recipes.clientudp.proto='udp' glorytun_recipes.clientudp.mtuauto='1' glorytun_recipes.clientudp.enable='0' https-dns-proxy.config=main https-dns-proxy.config.update_dnsmasq_config='*' https-dns-proxy.@https-dns-proxy[0]=https-dns-proxy https-dns-proxy.@https-dns-proxy[0].bootstrap_dns='8.8.8.8,8.8.4.4' https-dns-proxy.@https-dns-proxy[0].resolver_url='https://dns.google/dns-query' https-dns-proxy.@https-dns-proxy[0].listen_addr='127.0.0.1' https-dns-proxy.@https-dns-proxy[0].listen_port='5053' https-dns-proxy.@https-dns-proxy[0].user='nobody' https-dns-proxy.@https-dns-proxy[0].group='nogroup' https-dns-proxy.@https-dns-proxy[1]=https-dns-proxy https-dns-proxy.@https-dns-proxy[1].bootstrap_dns='1.1.1.1,1.0.0.1' https-dns-proxy.@https-dns-proxy[1].resolver_url='https://cloudflare-dns.com/dns-query' https-dns-proxy.@https-dns-proxy[1].listen_addr='127.0.0.1' https-dns-proxy.@https-dns-proxy[1].listen_port='5054' https-dns-proxy.@https-dns-proxy[1].user='nobody' https-dns-proxy.@https-dns-proxy[1].group='nogroup' igmpproxy.@igmpproxy[0]=igmpproxy igmpproxy.@igmpproxy[0].quickleave='1' igmpproxy.@phyint[0]=phyint igmpproxy.@phyint[0].network='wan' igmpproxy.@phyint[0].zone='wan' igmpproxy.@phyint[0].direction='upstream' igmpproxy.@phyint[0].altnet='192.168.1.0/24' igmpproxy.@phyint[1]=phyint igmpproxy.@phyint[1].network='lan' igmpproxy.@phyint[1].zone='lan' igmpproxy.@phyint[1].direction='downstream' iperf.bouygues=server iperf.bouygues.host='bouygues.iperf.fr' iperf.bouygues.ipv4='1' iperf.bouygues.ipv6='1' iperf.bouygues.speed='10000' iperf.bouygues.ports='5200,5201,5202,5203,5204,5205,5206,5207,5208,5209' iperf.bouygues.tcp='1' iperf.bouygues.udp='0' iperf.bouygues.location='Europe' iperf.online_ipv4=server iperf.online_ipv4.host='ping.online.net' iperf.online_ipv4.ipv4='1' iperf.online_ipv4.ipv6='0' iperf.online_ipv4.speed='10000' iperf.online_ipv4.ports='5200,5201,5202,5203,5204,5205,5206,5207,5208,5209' iperf.online_ipv4.tcp='1' iperf.online_ipv4.udp='1' iperf.online_ipv4.location='Europe' iperf.online_ipv6=server iperf.online_ipv6.host='ping.online.net' iperf.online_ipv6.ipv4='0' iperf.online_ipv6.ipv6='1' iperf.online_ipv6.speed='10000' iperf.online_ipv6.ports='5200,5201,5202,5203,5204,5205,5206,5207,5208,5209' iperf.online_ipv6.tcp='1' iperf.online_ipv6.udp='1' iperf.online_ipv6.location='Europe' iperf.serverius=server iperf.serverius.host='speedtest.serverius.net' iperf.serverius.ipv4='1' iperf.serverius.ipv6='1' iperf.serverius.speed='10000' iperf.serverius.ports='5002' iperf.serverius.tcp='1' iperf.serverius.udp='1' iperf.serverius.location='Europe' iperf.eenet=server iperf.eenet.host='iperf.eenet.ee' iperf.eenet.ipv4='1' iperf.eenet.ipv6='0' iperf.eenet.ports='5201' iperf.eenet.tcp='1' iperf.eenet.udp='1' iperf.eenet.location='Europe' iperf.volia=server iperf.volia.host='iperf.volia.net' iperf.volia.ipv4='1' iperf.volia.ipv6='0' iperf.volia.ports='5201' iperf.volia.tcp='1' iperf.volia.udp='1' iperf.volia.location='Europe' iperf.it_north=server iperf.it_north.host='iperf.it-north.net' iperf.it_north.ipv4='1' iperf.it_north.ipv6='0' iperf.it_north.speed='1000' iperf.it_north.ports='5200,5201,5202,5203,5204,5205,5206,5207,5208,5209' iperf.it_north.tcp='1' iperf.it_north.udp='1' iperf.it_north.location='Asia' iperf.biznet=server iperf.biznet.host='iperf.biznetnetworkds.com' iperf.biznet.ipv4='1' iperf.biznet.ipv6='1' iperf.biznet.speed='1000' iperf.biznet.ports='5201,5202,5203' iperf.biznet.tcp='1' iperf.biznet.udp='0' iperf.biznet.location='Asia' iperf.scottlinux=server iperf.scottlinux.host='iperf.scottlinux.com' iperf.scottlinux.ipv4='1' iperf.scottlinux.ipv6='1' iperf.scottlinux.speed='1000' iperf.scottlinux.ports='5201' iperf.scottlinux.tcp='1' iperf.scottlinux.udp='1' iperf.scottlinux.location='America' iperf.he=server iperf.he.host='iperf.he.net' iperf.he.ipv4='1' iperf.he.ipv6='1' iperf.he.ports='5201' iperf.he.tcp='1' iperf.he.udp='1' iperf.he.location='America' iperf.vps=server iperf.vps.host='51.195.168.66' iperf.vps.ports='65400' iperf.vps.ipv4='1' iperf.vps.ipv6='0' iperf.vps.speed='1000' iperf.vps.tcp='1' iperf.vps.udp='1' iperf.vps.user='openmptcprouter' iperf.vps.password='openmptcprouter' iperf.vps.key='LS0tLS1CRUdJTiBQVUJMSUMgS0VZLS0tLS0KTUlJQklqQU5CZ2txaGtpRzl3MEJBUUVGQUFPQ0FROEFNSUlCQ2dLQ0FRRUF3NmhRQjVNWFlkQ1lkT3B3b1REcgpFVGJJOVZmeUU1ZHBvSmNiWkU4ZGJQOUNkODdNajZtUnNqamd0VE5RcytPTnBSZ3locElyN3ZnRkVXNEFxd3cwCm9kMS9yL1g3YVBIMjYwaGM2RG1NMEVWczlZcm1OZVgyMmFRVnVnejFVbzZGZktEU2tzc0Q4MlpUTWE2eW10b1IKMFZLZ3RjTG9ZdXNDSkc1Zm5qejlSRjhZbHhJdDdyVmtyZS9LTVZaNTNyUFg1aGwveXJ3NU54UFQ4aHdQMlpXQgpKRGFISDc4ek5MMGs1Z1djY0hCWTVrUnBFNSt2Z2lhS25vMGJKQlpnaXVlYmVCYmZzenJwTVVrNllpdEtvOFBRCklpYUsvVEVmYkxxMWRpTE9Tc3hJV0RRSWRqOEx2RkFRVHF0QjJHNHJ1bUxMVDYrK1hNRVhYVmZleGk3SHBZYjIKRVFJREFRQUIKLS0tLS1FTkQgUFVCTElDIEtFWS0tLS0tCg==' luci.main=core luci.main.lang='auto' luci.main.resourcebase='/luci-static/resources' luci.main.ubuspath='/ubus/' luci.main.mediaurlbase='/luci-static/openmptcprouter' luci.flash_keep=extern luci.flash_keep.uci='/etc/config/' luci.flash_keep.dropbear='/etc/dropbear/' luci.flash_keep.openvpn='/etc/openvpn/' luci.flash_keep.passwd='/etc/passwd' luci.flash_keep.opkg='/etc/opkg.conf' luci.flash_keep.firewall='/etc/firewall.user' luci.flash_keep.uploads='/lib/uci/upload/' luci.languages=internal luci.languages.ar='العربية (Arabic)' luci.languages.bg='български (Bulgarian)' luci.languages.bn='বাংলা (Bengali)' luci.languages.ca='Català (Catalan)' luci.languages.cs='Čeština (Czech)' luci.languages.de='Deutsch (German)' luci.languages.el='Ελληνικά (Greek)' luci.languages.en='English' luci.languages.es='Español (Spanish)' luci.languages.fi='Suomi (Finnish)' luci.languages.fr='Français (French)' luci.languages.he='עִבְרִית (Hebrew)' luci.languages.hi='हिंदी (Hindi)' luci.languages.hu='Magyar (Hungarian)' luci.languages.it='Italiano (Italian)' luci.languages.ja='日本語 (Japanese)' luci.languages.ko='한국어 (Korean)' luci.languages.mr='Marāṭhī (Marathi)' luci.languages.ms='Bahasa Melayu (Malay)' luci.languages.no='Norsk (Norwegian)' luci.languages.pl='Polski (Polish)' luci.languages.pt='Português (Portuguese)' luci.languages.pt_br='Português do Brasil (Brazilian Portuguese)' luci.languages.ro='Română (Romanian)' luci.languages.ru='Русский (Russian)' luci.languages.sk='Slovenčina (Slovak)' luci.languages.sv='Svenska (Swedish)' luci.languages.tr='Türkçe (Turkish)' luci.languages.uk='Українська (Ukrainian)' luci.languages.vi='Tiếng Việt (Vietnamese)' luci.languages.zh_cn='简体中文 (Chinese Simplified)' luci.languages.zh_tw='繁體中文 (Chinese Traditional)' luci.sauth=internal luci.sauth.sessionpath='/tmp/luci-sessions' luci.sauth.sessiontime='3600' luci.ccache=internal luci.ccache.enable='1' luci.themes=internal luci.themes.Argon='/luci-static/argon' luci.themes.OpenMPTCProuter='/luci-static/openmptcprouter' luci.apply=internal luci.apply.rollback='90' luci.apply.holdoff='4' luci.apply.timeout='5' luci.apply.display='1.5' luci.diag=internal luci.diag.ping='openmptcprouter.com' luci.diag.dns='openmptcprouter.com' luci.diag.route='openmptcprouter.com' luci.diag.iperf3='ping-ams1.online.net' luci.diag.getip='ip.openmptcprouter.com' mail.default=smtp mlvpn.general=mlvpn mlvpn.general.timeout='30' mlvpn.general.reorder_buffer_size='64' mlvpn.general.loss_tolerence='50' mlvpn.general.mode='client' mlvpn.general.firstport='65201' mlvpn.general.host='51.195.168.66' mlvpn.general.password='2aTuHV6NwIIcmpkVwxoh7v3oThvaj15wTPe8szBbES4=' mlvpn.general.loss_tolerance='50' mlvpn.general.interface_name='mlvpn0' mlvpn.general.enable='0' network.loopback=interface network.loopback.ifname='lo' network.loopback.proto='static' network.loopback.ipaddr='127.0.0.1' network.loopback.netmask='255.0.0.0' network.loopback.multipath='off' network.loopback.macaddr='00:00:00:00:00:00' network.loopback.metric='1' network.globals=globals network.globals.multipath='enable' network.globals.mptcp_path_manager='fullmesh' network.globals.mptcp_scheduler='blest' network.globals.mptcp_debug='0' network.globals.mptcp_fullmesh_num_subflows='1' network.globals.mptcp_fullmesh_create_on_err='1' network.globals.mptcp_ndiffports_num_subflows='1' network.globals.ula_prefix='fd98:efdf:0eb4::/48' network.globals.mptcp_syn_retries='8' network.globals.congestion='bbr' network.globals.mptcp_checksum='0' network.lan=interface network.lan.proto='static' network.lan.ipaddr='192.168.100.1' network.lan.netmask='255.255.255.0' network.lan.delegate='0' network.lan.multipath='off' network.lan.ip4table='lan' network.lan.device='/sys/devices/pci0000:00/0000:00:1c.0/0000:01:00.0/net/eth0' network.lan.metric='2' network.lan.macaddr='00:e0:67:1f:ed:c5' network.lan.ifname='eth0' network.lan.modalias='pci:v00008086d0000150Csv00008086sd00000000bc02sc00i00' network.lan.defaultroute='0' network.lan.peerdns='0' network.wan1=interface network.wan1.ifname='eth1' network.wan1.proto='static' network.wan1.ip4table='wan' network.wan1.defaultroute='0' network.wan1.macaddr='00:e0:67:1f:ed:cd' network.wan1.metric='3' network.wan1.peerdns='0' network.wan1.device='/sys/devices/pci0000:00/0000:00:1c.1/0000:02:00.0/net/eth1' network.wan1.ipv6='0' network.wan1.label='Home Broadband' network.wan1.ipaddr='192.168.1.155' network.wan1.netmask='255.255.255.0' network.wan1.gateway='192.168.1.1' network.wan1.downloadspeed='10000' network.wan1.uploadspeed='2500' network.wan1.multipath='on' network.wan1.mtu='1500' network.wan1.modalias='pci:v00008086d0000150Csv00008086sd00000000bc02sc00i00' network.wan2=interface network.wan2.ifname='eth5' network.wan2.proto='static' network.wan2.ip4table='wan' network.wan2.defaultroute='0' network.wan2.macaddr='00:e0:67:1f:ed:d1' network.wan2.metric='4' network.wan2.peerdns='0' network.wan2.device='/sys/devices/pci0000:00/0000:00:1c.5/0000:06:00.0/net/eth5' network.wan2.ipv6='0' network.wan2.ipaddr='192.168.18.23' network.wan2.netmask='255.255.255.0' network.wan2.gateway='192.168.18.1' network.wan2.label='EE 4G LTE' network.wan2.multipath='master' network.wan2.mtu='1500' network.wan2.modalias='pci:v00008086d0000150Csv00008086sd00000000bc02sc00i00' network.wan3=interface network.wan3.proto='static' network.wan3.ip4table='wan' network.wan3.multipath='on' network.wan3.defaultroute='0' network.wan3.macaddr='00:e0:67:1f:ed:cf' network.wan3.metric='5' network.wan3.peerdns='0' network.wan3.device='/sys/devices/pci0000:00/0000:00:1c.3/0000:04:00.0/net/eth3' network.wan3.ipv6='0' network.wan3.ipaddr='192.168.5.23' network.wan3.netmask='255.255.255.0' network.wan3.gateway='192.168.5.1' network.wan3.label='Three' network.wan3.ifname='eth3' network.wan3.mtu='1500' network.wan3.modalias='pci:v00008086d0000150Csv00008086sd00000000bc02sc00i00' network.wan4=interface network.wan4.ifname='eth4' network.wan4.proto='static' network.wan4.ip4table='wan' network.wan4.multipath='on' network.wan4.defaultroute='0' network.wan4.macaddr='00:e0:67:1f:ed:d0' network.wan4.metric='6' network.wan4.peerdns='0' network.wan4.device='/sys/devices/pci0000:00/0000:00:1c.4/0000:05:00.0/net/eth4' network.wan4.ipv6='0' network.wan4.label='Vodafone 4G LTE' network.wan4.ipaddr='192.168.8.23' network.wan4.netmask='255.255.255.0' network.wan4.gateway='192.168.8.1' network.wan4.mtu='1500' network.wan4.modalias='pci:v00008086d0000150Csv00008086sd00000000bc02sc00i00' network.lan_rule=rule network.lan_rule.lookup='lan' network.lan_rule.priority='100' network.omrvpn=interface network.omrvpn.ip4table='vpn' network.omrvpn.multipath='off' network.omrvpn.leasetime='12h' network.omrvpn.type='tunnel' network.omrvpn.txqueuelen='1000' network.omrvpn.ipv6='0' network.omrvpn.metric='7' network.omrvpn.proto='none' network.omrvpn.ifname='tun0' network.omr6in4=interface network.omr6in4.proto='6in4' network.omr6in4.ip4table='vpn' network.omr6in4.multipath='off' network.omr6in4.auto='0' network.omr6in4.metric='8' network.omr6in4.ip6addr='fe80::a00:2/126' network.omr6in4.gateway='fe80::a00:1/126' network.omr6in4.ipaddr='10.255.251.2' network.omr6in4.peeraddr='10.255.251.1' omr-bypass.all=interface omr-bypass.m6replay=proto omr-bypass.m6replay.url='m6web.fr' '6play.fr' '6cloud.fr' omr-bypass.mycanal=proto omr-bypass.mycanal.url='mycanal.fr' 'canal-plus.com' omr-bypass.minecraft=proto omr-bypass.minecraft.url='authserver.mojang.com' omr-bypass.lesnumeriques=proto omr-bypass.lesnumeriques.url='lesnumeriques.com' 'botscorner.com' 'app.botscorner.com' omr-bypass.disneyplus=proto omr-bypass.disneyplus.url='bamgrid.com' 'disney-plus.net' omr-bypass.@dpis[0]=dpis omr-bypass.@dpis[0].proto='whatsappfiles' omr-bypass.@dpis[0].interface='tun0' omr-bypass.@dpis[0].enabled='0' omr-bypass.@dpis[1]=dpis omr-bypass.@dpis[1].proto='whatsapp' omr-bypass.@dpis[1].interface='tun0' omr-bypass.@dpis[1].enabled='0' omr-bypass.@dpis[2]=dpis omr-bypass.@dpis[2].proto='spotify' omr-bypass.@dpis[2].interface='eth1' omr-bypass.@dpis[3]=dpis omr-bypass.@dpis[3].proto='google' omr-bypass.@dpis[3].interface='eth5' omr-bypass.@dpis[4]=dpis omr-bypass.@dpis[4].proto='zoom' omr-bypass.@dpis[4].interface='tun0' omr-bypass.@dpis[5]=dpis omr-bypass.@dpis[5].proto='twitch' omr-bypass.@dpis[5].interface='eth1' omr-bypass.lo=interface omr-bypass.lo.id='1' omr-bypass.eth0=interface omr-bypass.eth0.id='2' omr-bypass.eth1=interface omr-bypass.eth1.id='3' omr-bypass.eth5=interface omr-bypass.eth5.id='4' omr-bypass.eth3=interface omr-bypass.eth3.id='5' omr-bypass.eth4=interface omr-bypass.eth4.id='6' omr-bypass.tun0=interface omr-bypass.tun0.id='7' omr-bypass.mlvpn0=interface omr-bypass.mlvpn0.id='7' omr-bypass.@dpis[6]=dpis omr-bypass.@dpis[6].proto='whatsappcall' omr-bypass.@dpis[6].interface='tun0' omr-bypass.@dpis[6].enabled='0' omr-bypass.mlvpn=interface omr-bypass.mlvpn.id='7' omr-bypass.@dpis[7]=dpis omr-bypass.@dpis[7].proto='googledocs' omr-bypass.@dpis[7].interface='eth1' omr-bypass.@dpis[8]=dpis omr-bypass.@dpis[8].proto='youtube' omr-bypass.@dpis[8].interface='eth1' omr-bypass.@dpis[8].enabled='0' omr-bypass.@dpis[9]=dpis omr-bypass.@dpis[9].proto='vevo' omr-bypass.@dpis[9].interface='eth5' omr-bypass.@dpis[10]=dpis omr-bypass.@dpis[10].proto='bittorrent' omr-bypass.@dpis[10].enabled='0' omr-bypass.@dpis[10].interface='tun0' omr-bypass.@dpis[11]=dpis omr-bypass.@dpis[11].proto='steam' omr-bypass.@dpis[11].interface='eth5' omr-bypass.@domains[0]=domains omr-bypass.@domains[0].name='rtmp://a.rtmp.youtube.com/live2' omr-bypass.@domains[0].interface='tun0' omr-bypass.@domains[0].enabled='0' omr-bypass.@domains[1]=domains omr-bypass.@domains[1].name='https://www.scan.co.uk/' omr-bypass.@domains[1].interface='eth1' omr-bypass.@domains[1].note='s' omr-bypass.@domains[1].enabled='0' omr-bypass.@dest_port[0]=dest_port omr-bypass.@dest_port[0].proto='udp' omr-bypass.@dest_port[0].interface='eth1' omr-bypass.@dest_port[0].dport='59668' omr-bypass.@src_port[0]=src_port omr-bypass.@src_port[0].sport='59668' omr-bypass.@src_port[0].proto='udp' omr-bypass.@src_port[0].interface='eth1' omr-quota.wan1=interface omr-quota.wan1.enabled='0' omr-quota.wan1.txquota='100000' omr-quota.wan1.rxquota='400000' omr-quota.wan1.ttquota='500000' omr-quota.wan1.interval='10' omr-quota.wan1.interface='wan1' omr-quota.wan2=interface omr-quota.wan2.enabled='0' omr-quota.wan2.txquota='100000' omr-quota.wan2.rxquota='400000' omr-quota.wan2.ttquota='500000' omr-quota.wan2.interval='10' omr-quota.wan2.interface='wan2' omr-tracker.defaults=defaults omr-tracker.defaults.enabled='1' omr-tracker.defaults.hosts='4.2.2.1' '8.8.8.8' '8.8.4.4' '9.9.9.9' '1.1.1.1' '1.0.0.1' '1.2.4.8' '80.67.169.12' '80.67.169.40' '114.114.114.114' '114.114.115.115' omr-tracker.defaults.timeout='2' omr-tracker.defaults.tries='2' omr-tracker.defaults.interval='2' omr-tracker.defaults.interval_tries='1' omr-tracker.defaults.type='ping' omr-tracker.defaults.wait_test='1' omr-tracker.proxy=shadowsocks omr-tracker.proxy.enabled='1' omr-tracker.proxy.hosts='1.1.1.1' '1.0.0.1' '212.27.48.10' '198.27.92.1' '151.101.129.164' '198.11.132.250' '77.88.55.77' '74.82.42.42' '176.103.130.130' omr-tracker.proxy.timeout='10' omr-tracker.proxy.tries='3' omr-tracker.proxy.interval_tries='1' omr-tracker.proxy.interval='5' omr-tracker.proxy.wait_test='1' omr-tracker.server=server omr-tracker.server.enabled='1' omr-tracker.server.tries='3' omr-tracker.server.timeout='10' omr-tracker.server.interval='5' omr-tracker.server.wait_test='1' omr-tracker.omrvpn=interface omr-tracker.omrvpn.type='none' omr-tracker.omrvpn.timeout='6' omr-tracker.omrvpn.tries='2' omr-tracker.omrvpn.interval='4' omr-tracker.omrvpn.mail_alert='0' omr-tracker.omrvpn.enabled='1' openmptcprouter.settings=settings openmptcprouter.settings.enabled='1' openmptcprouter.settings.master='balancing' openmptcprouter.settings.disable_ipv6='1' openmptcprouter.settings.check_ipv4_website='http://ip.openmptcprouter.com' openmptcprouter.settings.check_ipv6_website='http://ipv6.openmptcprouter.com' openmptcprouter.settings.status_vps_timeout='2' openmptcprouter.settings.status_getip_timeout='2' openmptcprouter.settings.scaling_governor='performance' openmptcprouter.settings.ha='0' openmptcprouter.settings.shadowsocks_disable='0' openmptcprouter.settings.firstboot='0' openmptcprouter.settings.disable_fastopen='1' openmptcprouter.settings.external_check='1' openmptcprouter.settings.debug='0' openmptcprouter.settings.disablegwping='0' openmptcprouter.settings.defaultgw='1' openmptcprouter.settings.disableserverping='0' openmptcprouter.settings.enable_nodelay='0' openmptcprouter.settings.scaling_min_freq='400000' openmptcprouter.settings.scaling_max_freq='2400000' openmptcprouter.settings.proxy='v2ray' openmptcprouter.settings.version='0.56.5' openmptcprouter.settings.tracebox='1' openmptcprouter.settings.vnstat_backup='0' openmptcprouter.settings.vpn='glorytun_tcp' openmptcprouter.vps=server openmptcprouter.vps.username='openmptcprouter' openmptcprouter.vps.master='1' openmptcprouter.vps.backup='0' openmptcprouter.vps.port='65500' openmptcprouter.vps.password='7A62BD1AD3D2767AB2FD4F65F3D688782CD8F7EDF71BD34EE870E1280889AAA2' openmptcprouter.vps.ip='51.195.168.66' openmptcprouter.vps.redirect_ports='1' openmptcprouter.vps.pihole='1' openmptcprouter.vps.machine='x86_64' openmptcprouter.vps.kernel='5.4.74-mptcp' openmptcprouter.vps.available_vpn='glorytun_tcp' 'glorytun_udp' 'dsvpn' 'openvpn' 'mlvpn' openmptcprouter.vps.get_config='0' openmptcprouter.vps.omr_version='0.1022' openmptcprouter.vps.admin_error='0' openmptcprouter.vps.lastbackup='1606177705.9315975' openmptcprouter.vps.nofwredirect='1' openmptcprouter.vps.token='eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJvcGVubXB0Y3Byb3V0ZXIiLCJleHAiOjE2MDYyNjQzMjJ9.mM4GcsPeAuGDfQp9EsZ5nM57OlOCUGecaqjJmkdyo4w' openmptcprouter.vps.lastchange='1606177923' openmptcprouter.omr=router openmptcprouter.omr.shadowsocks='up' openmptcprouter.omr.detected_public_ipv4='51.195.168.66' openmptcprouter.omr.detected_ss_ipv4='51.195.168.66' openmptcprouter.omr.v2ray='up' openmptcprouter.omrvpn=interface openmptcprouter.omrvpn.multipath='off' openmptcprouter.omrvpn.metric='7' openmptcprouter.omrvpn.state='down' openmptcprouter.loopback=interface openmptcprouter.loopback.multipath='off' openmptcprouter.loopback.metric='1' openmptcprouter.lan=interface openmptcprouter.lan.multipath='off' openmptcprouter.lan.metric='2' openmptcprouter.lan.multipathvpn='0' openmptcprouter.omr6in4=interface openmptcprouter.omr6in4.multipath='off' openmptcprouter.omr6in4.metric='8' openmptcprouter.latest_versions=latest_versions openmptcprouter.latest_versions.omr='0.56.5' openmptcprouter.latest_versions.vps='0.1022' openmptcprouter.latest_versions.lc='1606177334' openmptcprouter.wan1=interface openmptcprouter.wan1.metric='3' openmptcprouter.wan1.multipathvpn='0' openmptcprouter.wan1.asn='ORANGE-PCS' openmptcprouter.wan1.mptcp_status='MPTCP enabled' openmptcprouter.wan1.multipath='on' openmptcprouter.wan1.mtu='1500' openmptcprouter.wan1.manufacturer='huawei' openmptcprouter.wan1.state='up' openmptcprouter.wan1.publicip='2.27.64.180' openmptcprouter.wan1.latency_previous='12' openmptcprouter.wan1.latency='11' openmptcprouter.wan2=interface openmptcprouter.wan2.metric='4' openmptcprouter.wan2.multipathvpn='0' openmptcprouter.wan2.mptcp_status='MPTCP enabled' openmptcprouter.wan2.multipath='master' openmptcprouter.wan2.mtu='1500' openmptcprouter.wan2.asn='ORANGE-PCS' openmptcprouter.wan2.state='up' openmptcprouter.wan2.manufacturer='huawei' openmptcprouter.wan2.publicip='109.249.185.107' openmptcprouter.wan2.lc='1606177923' openmptcprouter.wan2.latency='20' openmptcprouter.wan2.latency_previous='20' openmptcprouter.wan3=interface openmptcprouter.wan3.multipath='on' openmptcprouter.wan3.metric='5' openmptcprouter.wan3.multipathvpn='0' openmptcprouter.wan3.asn='H3GUK' openmptcprouter.wan3.mptcp_status='MPTCP enabled' openmptcprouter.wan3.mtu='1500' openmptcprouter.wan3.manufacturer='huawei' openmptcprouter.wan3.state='up' openmptcprouter.wan3.publicip='92.40.170.144' openmptcprouter.wan3.lc='1606177922' openmptcprouter.wan3.latency_previous='41' openmptcprouter.wan3.latency='51' openmptcprouter.wan4=interface openmptcprouter.wan4.multipath='on' openmptcprouter.wan4.metric='6' openmptcprouter.wan4.multipathvpn='0' openmptcprouter.wan4.mptcp_status='MPTCP enabled' openmptcprouter.wan4.manufacturer='huawei' openmptcprouter.wan4.mtu='1500' openmptcprouter.wan4.asn='VODAFONE_UK_ASN' openmptcprouter.wan4.state='up' openmptcprouter.wan4.publicip='185.69.145.220' openmptcprouter.wan4.lc='1606177922' openmptcprouter.wan4.latency_previous='32' openmptcprouter.wan4.latency='28' openvpn.custom_config=openvpn openvpn.custom_config.enabled='0' openvpn.custom_config.config='/etc/openvpn/my-vpn.conf' openvpn.sample_server=openvpn openvpn.sample_server.enabled='0' openvpn.sample_server.port='1194' openvpn.sample_server.proto='udp' openvpn.sample_server.dev='tun' openvpn.sample_server.ca='/etc/openvpn/ca.crt' openvpn.sample_server.cert='/etc/openvpn/server.crt' openvpn.sample_server.key='/etc/openvpn/server.key' openvpn.sample_server.dh='/etc/openvpn/dh2048.pem' openvpn.sample_server.server='10.8.0.0 255.255.255.0' openvpn.sample_server.ifconfig_pool_persist='/tmp/ipp.txt' openvpn.sample_server.keepalive='10 120' openvpn.sample_server.persist_key='1' openvpn.sample_server.persist_tun='1' openvpn.sample_server.user='nobody' openvpn.sample_server.status='/tmp/openvpn-status.log' openvpn.sample_server.verb='3' openvpn.sample_client=openvpn openvpn.sample_client.enabled='0' openvpn.sample_client.client='1' openvpn.sample_client.dev='tun' openvpn.sample_client.proto='udp' openvpn.sample_client.remote='my_server_1 1194' openvpn.sample_client.resolv_retry='infinite' openvpn.sample_client.nobind='1' openvpn.sample_client.persist_key='1' openvpn.sample_client.persist_tun='1' openvpn.sample_client.user='nobody' openvpn.sample_client.ca='/etc/openvpn/ca.crt' openvpn.sample_client.cert='/etc/openvpn/client.crt' openvpn.sample_client.key='/etc/openvpn/client.key' openvpn.sample_client.verb='3' openvpn.omr=openvpn openvpn.omr.dev='tun0' openvpn.omr.port='65301' openvpn.omr.cipher='AES-256-CBC' openvpn.omr.proto='tcp-client' openvpn.omr.ncp_disable='1' openvpn.omr.auth_nocache='1' openvpn.omr.client='1' openvpn.omr.tls_client='1' openvpn.omr.reneg_sec='0' openvpn.omr.allow_recursive_routing='1' openvpn.omr.sndbuf='0' openvpn.omr.rcvbuf='0' openvpn.omr.route_delay='5' openvpn.omr.key='/etc/luci-uploads/client.key' openvpn.omr.cert='/etc/luci-uploads/client.crt' openvpn.omr.ca='/etc/luci-uploads/ca.crt' openvpn.omr.enabled='0' openvpn.omr.remote='51.195.168.66' openvpn_recipes.server_tun_ptp=openvpn_recipe openvpn_recipes.server_tun_ptp._description='Simple server configuration for a routed point-to-point VPN' openvpn_recipes.server_tun_ptp._role='server' openvpn_recipes.server_tun_ptp.dev='tun' openvpn_recipes.server_tun_ptp.ifconfig='10.0.0.1 10.0.0.2' openvpn_recipes.server_tun_ptp.secret='shared-secret.key' openvpn_recipes.server_tun_ptp.keepalive='10 60' openvpn_recipes.server_tun_ptp.comp_lzo='yes' openvpn_recipes.server_tun_ptp.verb='3' openvpn_recipes.server_tun_ptp.mssfix='1420' openvpn_recipes.client_tun_ptp=openvpn_recipe openvpn_recipes.client_tun_ptp._description='Simple client configuration for a routed point-to-point VPN' openvpn_recipes.client_tun_ptp._role='client' openvpn_recipes.client_tun_ptp.dev='tun' openvpn_recipes.client_tun_ptp.remote='vpnserver.example.org' openvpn_recipes.client_tun_ptp.ifconfig='10.0.0.2 10.0.0.1' openvpn_recipes.client_tun_ptp.secret='shared-secret.key' openvpn_recipes.client_tun_ptp.nobind='1' openvpn_recipes.client_tun_ptp.comp_lzo='yes' openvpn_recipes.client_tun_ptp.verb='3' openvpn_recipes.server_tun=openvpn_recipe openvpn_recipes.server_tun._description='Server configuration for a routed multi-client VPN' openvpn_recipes.server_tun._role='server' openvpn_recipes.server_tun.dev='tun' openvpn_recipes.server_tun.server='10.0.100.0 255.255.255.0' openvpn_recipes.server_tun.ca='ca.crt' openvpn_recipes.server_tun.cert='server.crt' openvpn_recipes.server_tun.key='server.key' openvpn_recipes.server_tun.dh='dh1024.pem' openvpn_recipes.server_tun.keepalive='10 60' openvpn_recipes.server_tun.comp_lzo='yes' openvpn_recipes.server_tun.verb='3' openvpn_recipes.server_tun.mssfix='1420' openvpn_recipes.client_tun=openvpn_recipe openvpn_recipes.client_tun._description='Client configuration for a routed multi-client VPN' openvpn_recipes.client_tun._role='client' openvpn_recipes.client_tun.client='1' openvpn_recipes.client_tun.dev='tun' openvpn_recipes.client_tun.remote='vpnserver.example.org' openvpn_recipes.client_tun.pkcs12='my_client.p12' openvpn_recipes.client_tun.remote_cert_tls='server' openvpn_recipes.client_tun.comp_lzo='yes' openvpn_recipes.client_tun.nobind='1' openvpn_recipes.client_tun.persist_key='1' openvpn_recipes.client_tun.persist_tun='1' openvpn_recipes.client_tun.verb='3' openvpn_recipes.client_tun.reneg_sec='0' openvpn_recipes.client_tun.float='1' openvpn_recipes.server_tap_bridge=openvpn_recipe openvpn_recipes.server_tap_bridge._description='Server configuration for an ethernet bridge VPN' openvpn_recipes.server_tap_bridge._role='server' openvpn_recipes.server_tap_bridge.dev='tap' openvpn_recipes.server_tap_bridge.server_bridge='192.168.1.1 255.255.255.0 192.168.1.128 192.168.1.254' openvpn_recipes.server_tap_bridge.ca='ca.crt' openvpn_recipes.server_tap_bridge.cert='server.crt' openvpn_recipes.server_tap_bridge.key='server.key' openvpn_recipes.server_tap_bridge.dh='dh1024.pem' openvpn_recipes.server_tap_bridge.keepalive='10 60' openvpn_recipes.server_tap_bridge.comp_lzo='yes' openvpn_recipes.server_tap_bridge.verb='3' openvpn_recipes.server_tap_bridge.mssfix='1420' openvpn_recipes.client_tap_bridge=openvpn_recipe openvpn_recipes.client_tap_bridge._description='Client configuration for an ethernet bridge VPN' openvpn_recipes.client_tap_bridge._role='client' openvpn_recipes.client_tap_bridge.client='1' openvpn_recipes.client_tap_bridge.dev='tap' openvpn_recipes.client_tap_bridge.remote='vpnserver.example.org' openvpn_recipes.client_tap_bridge.ca='ca.crt' openvpn_recipes.client_tap_bridge.cert='my_client.crt' openvpn_recipes.client_tap_bridge.key='my_client.key' openvpn_recipes.client_tap_bridge.dh='dh1024.pem' openvpn_recipes.client_tap_bridge.remote_cert_tls='server' openvpn_recipes.client_tap_bridge.comp_lzo='yes' openvpn_recipes.client_tap_bridge.nobind='1' openvpn_recipes.client_tap_bridge.persist_key='1' openvpn_recipes.client_tap_bridge.verb='3' openvpn_recipes.client_tap_bridge.reneg_sec='0' openvpn_recipes.client_tap_bridge.float='1' rpcd.@rpcd[0]=rpcd rpcd.@rpcd[0].socket='/var/run/ubus.sock' rpcd.@rpcd[0].timeout='120' rpcd.@login[0]=login rpcd.@login[0].username='root' rpcd.@login[0].password='$p$root' rpcd.@login[0].read='*' rpcd.@login[0].write='*' shadowsocks-libev.hi=ss_redir shadowsocks-libev.hi.server='sss0' shadowsocks-libev.hi.local_port='1100' shadowsocks-libev.hi.mode='tcp_and_udp' shadowsocks-libev.hi.timeout='1000' shadowsocks-libev.hi.verbose='0' shadowsocks-libev.hi.syslog='1' shadowsocks-libev.hi.reuse_port='1' shadowsocks-libev.hi.mptcp='1' shadowsocks-libev.hi.ipv6_first='1' shadowsocks-libev.hi.local_address='0.0.0.0' shadowsocks-libev.hi.no_delay='0' shadowsocks-libev.hi.fast_open='0' shadowsocks-libev.hi.ebpf='0' shadowsocks-libev.hi2=ss_redir shadowsocks-libev.hi2.server='sss0' shadowsocks-libev.hi2.local_address='0.0.0.0' shadowsocks-libev.hi2.local_port='1100' shadowsocks-libev.hi2.mode='tcp_and_udp' shadowsocks-libev.hi2.timeout='1000' shadowsocks-libev.hi2.verbose='0' shadowsocks-libev.hi2.syslog='1' shadowsocks-libev.hi2.reuse_port='1' shadowsocks-libev.hi2.mptcp='1' shadowsocks-libev.hi2.ipv6_first='1' shadowsocks-libev.hi2.no_delay='0' shadowsocks-libev.hi2.fast_open='0' shadowsocks-libev.hi2.ebpf='0' shadowsocks-libev.ss_rules=ss_rules shadowsocks-libev.ss_rules.src_default='forward' shadowsocks-libev.ss_rules.dst_default='forward' shadowsocks-libev.ss_rules.local_default='forward' shadowsocks-libev.ss_rules.server='sss0' shadowsocks-libev.ss_rules.redir_tcp='all' shadowsocks-libev.ss_rules.redir_udp='hi2' shadowsocks-libev.sss0=server shadowsocks-libev.sss0.server_port='65101' shadowsocks-libev.sss0.server='51.195.168.66' shadowsocks-libev.sss0.key='lRwsBoGPFLF4Gyv7UX2B8MERrBbc2GiRRwH3YggGuvA=' shadowsocks-libev.sss0.obfs_host='ip66.ip-51-195-168.eu' shadowsocks-libev.sss0.obfs_plugin='v2ray' shadowsocks-libev.sss0.obfs_type='http' shadowsocks-libev.sss0.method='chacha20-ietf-poly1305' shadowsocks-libev.sss0.obfs='0' shadowsocks-libev.sss0.disabled='1' shadowsocks-libev.dns=ss_tunnel shadowsocks-libev.dns.mode='tcp_and_udp' shadowsocks-libev.dns.server='sss0' shadowsocks-libev.dns.local_port='5353' shadowsocks-libev.dns.tunnel_address='8.8.8.8:53' shadowsocks-libev.dns.disabled='1' shadowsocks-libev.hi3=ss_redir shadowsocks-libev.hi3.server='sss0' shadowsocks-libev.hi3.local_address='0.0.0.0' shadowsocks-libev.hi3.local_port='1101' shadowsocks-libev.hi3.mode='tcp_and_udp' shadowsocks-libev.hi3.timeout='1000' shadowsocks-libev.hi3.reuse_port='1' shadowsocks-libev.hi3.syslog='1' shadowsocks-libev.hi3.mptcp='1' shadowsocks-libev.hi3.verbose='0' shadowsocks-libev.hi3.no_delay='0' shadowsocks-libev.hi3.fast_open='0' shadowsocks-libev.hi3.ebpf='0' shadowsocks-libev.hi4=ss_redir shadowsocks-libev.hi4.server='sss0' shadowsocks-libev.hi4.local_address='0.0.0.0' shadowsocks-libev.hi4.local_port='1101' shadowsocks-libev.hi4.mode='tcp_and_udp' shadowsocks-libev.hi4.timeout='1000' shadowsocks-libev.hi4.reuse_port='1' shadowsocks-libev.hi4.syslog='1' shadowsocks-libev.hi4.mptcp='1' shadowsocks-libev.hi4.verbose='0' shadowsocks-libev.hi4.no_delay='0' shadowsocks-libev.hi4.fast_open='0' shadowsocks-libev.hi4.ebpf='0' shadowsocks-libev.tracker=ss_local shadowsocks-libev.tracker.server='sss0' shadowsocks-libev.tracker.local_address='127.0.0.1' shadowsocks-libev.tracker.local_port='1111' shadowsocks-libev.tracker.mode='tcp_and_udp' shadowsocks-libev.tracker.timeout='600' shadowsocks-libev.tracker.syslog='0' shadowsocks-libev.tracker.reuse_port='1' shadowsocks-libev.tracker.mptcp='1' shadowsocks-libev.tracker.verbose='0' shadowsocks-libev.tracker.no_delay='0' shadowsocks-libev.tracker.fast_open='0' shadowsocks-libev.tracker.ebpf='0' snmpd.@agent[0]=agent snmpd.@agent[0].agentaddress='UDP:161,UDP6:161' snmpd.@agentx[0]=agentx snmpd.@agentx[0].agentxsocket='/var/run/agentx.sock' snmpd.public=com2sec snmpd.public.secname='ro' snmpd.public.source='default' snmpd.public.community='public' snmpd.private=com2sec snmpd.private.secname='rw' snmpd.private.source='localhost' snmpd.private.community='private' snmpd.public_v1=group snmpd.public_v1.group='public' snmpd.public_v1.version='v1' snmpd.public_v1.secname='ro' snmpd.public_v2c=group snmpd.public_v2c.group='public' snmpd.public_v2c.version='v2c' snmpd.public_v2c.secname='ro' snmpd.public_usm=group snmpd.public_usm.group='public' snmpd.public_usm.version='usm' snmpd.public_usm.secname='ro' snmpd.private_v1=group snmpd.private_v1.group='private' snmpd.private_v1.version='v1' snmpd.private_v1.secname='rw' snmpd.private_v2c=group snmpd.private_v2c.group='private' snmpd.private_v2c.version='v2c' snmpd.private_v2c.secname='rw' snmpd.private_usm=group snmpd.private_usm.group='private' snmpd.private_usm.version='usm' snmpd.private_usm.secname='rw' snmpd.all=view snmpd.all.viewname='all' snmpd.all.type='included' snmpd.all.oid='.1' snmpd.public_access=access snmpd.public_access.group='public' snmpd.public_access.context='none' snmpd.public_access.version='any' snmpd.public_access.level='noauth' snmpd.public_access.prefix='exact' snmpd.public_access.read='all' snmpd.public_access.write='none' snmpd.public_access.notify='none' snmpd.private_access=access snmpd.private_access.group='private' snmpd.private_access.context='none' snmpd.private_access.version='any' snmpd.private_access.level='noauth' snmpd.private_access.prefix='exact' snmpd.private_access.read='all' snmpd.private_access.write='all' snmpd.private_access.notify='all' snmpd.@system[0]=system snmpd.@system[0].sysLocation='office' snmpd.@system[0].sysContact='bofh@example.com' snmpd.@system[0].sysName='OpenMPTCProuter' snmpd.@exec[0]=exec snmpd.@exec[0].name='filedescriptors' snmpd.@exec[0].prog='/bin/cat' snmpd.@exec[0].args='/proc/sys/fs/file-nr' snmpd.@engineid[0]=engineid snmpd.@engineid[0].engineidtype='3' snmpd.@engineid[0].engineidnic='eth0' snmpd.general=snmpd snmpd.general.network='lan' snmpd.general.enabled='0' snmpd.general.ipv6cpipv4='1' sqm.eth1=queue sqm.eth1.enabled='0' sqm.eth1.interface='eth1' sqm.eth1.download='85000' sqm.eth1.upload='10000' sqm.eth1.qdisc='fq_codel' sqm.eth1.script='simple.qos' sqm.eth1.qdisc_advanced='0' sqm.eth1.linklayer='none' sqm.eth1.debug_logging='0' sqm.eth1.verbosity='5' sqm.wan1=queue sqm.wan1.qdisc='fq_codel' sqm.wan1.script='simple.qos' sqm.wan1.qdisc_advanced='0' sqm.wan1.linklayer='none' sqm.wan1.debug_logging='0' sqm.wan1.verbosity='5' sqm.wan1.interface='eth1' sqm.wan1.enabled='0' sqm.wan1.iqdisc_opts='autorate-ingress nat dual-dsthost' sqm.wan1.eqdisc_opts='nat dual-srchost' sqm.wan1.download='9500' sqm.wan1.upload='2375' sqm.wan2=queue sqm.wan2.interface='eth5' sqm.wan2.qdisc='fq_codel' sqm.wan2.script='simple.qos' sqm.wan2.qdisc_advanced='0' sqm.wan2.linklayer='none' sqm.wan2.enabled='0' sqm.wan2.debug_logging='0' sqm.wan2.verbosity='5' sqm.wan2.download='0' sqm.wan2.upload='0' sqm.wan2.iqdisc_opts='autorate-ingress nat dual-dsthost' sqm.wan2.eqdisc_opts='nat dual-srchost' sqm.wan3=queue sqm.wan3.interface='eth3' sqm.wan3.qdisc='fq_codel' sqm.wan3.script='simple.qos' sqm.wan3.qdisc_advanced='0' sqm.wan3.linklayer='none' sqm.wan3.enabled='0' sqm.wan3.debug_logging='0' sqm.wan3.verbosity='5' sqm.wan3.download='0' sqm.wan3.upload='0' sqm.wan3.iqdisc_opts='autorate-ingress nat dual-dsthost' sqm.wan3.eqdisc_opts='nat dual-srchost' sqm.wan4=queue sqm.wan4.interface='eth4' sqm.wan4.qdisc='fq_codel' sqm.wan4.script='simple.qos' sqm.wan4.qdisc_advanced='0' sqm.wan4.linklayer='none' sqm.wan4.enabled='0' sqm.wan4.debug_logging='0' sqm.wan4.verbosity='5' sqm.wan4.download='0' sqm.wan4.upload='0' sqm.wan4.iqdisc_opts='autorate-ingress nat dual-dsthost' sqm.wan4.eqdisc_opts='nat dual-srchost' sqm.lan=queue sqm.lan.interface='eth0' sqm.lan.qdisc='fq_codel' sqm.lan.script='simple.qos' sqm.lan.qdisc_advanced='0' sqm.lan.linklayer='none' sqm.lan.enabled='0' sqm.lan.debug_logging='0' sqm.lan.verbosity='5' sqm.lan.download='0' sqm.lan.upload='0' sqm.lan.iqdisc_opts='autorate-ingress nat dual-dsthost' sqm.lan.eqdisc_opts='nat dual-srchost' system.@system[0]=system system.@system[0].hostname='OpenMPTCProuter' system.@system[0].timezone='UTC' system.@system[0].log_size='64' system.@system[0].urandom_seed='0' system.@system[0].ttylogin='1' system.ntp=timeserver system.ntp.enabled='1' system.ntp.server='0.openwrt.pool.ntp.org' '1.openwrt.pool.ntp.org' '2.openwrt.pool.ntp.org' '3.openwrt.pool.ntp.org' system.ntp.use_dhcp='0' system.ntp.enable_server='1' system.@rngd[0]=rngd system.@rngd[0].device='/dev/urandom' system.@rngd[0].enabled='1' ttyd.@ttyd[0]=ttyd ttyd.@ttyd[0].interface='@lan' ttyd.@ttyd[0].command='/usr/libexec/login.sh' ucitrack.@network[0]=network ucitrack.@network[0].init='network' ucitrack.@network[0].affects='dhcp' 'radvd' 'glorytun' 'dsvpn' 'mptcpovervpn' 'omr6in4' 'omr-quota' 'omr-tracker' 'openmptcprouter' ucitrack.@wireless[0]=wireless ucitrack.@wireless[0].affects='network' ucitrack.@firewall[0]=firewall ucitrack.@firewall[0].init='firewall' ucitrack.@firewall[0].affects='luci-splash' 'qos' 'miniupnpd' 'sqm' ucitrack.@olsr[0]=olsr ucitrack.@olsr[0].init='olsrd' ucitrack.@dhcp[0]=dhcp ucitrack.@dhcp[0].init='dnsmasq' ucitrack.@dhcp[0].affects='odhcpd' ucitrack.@odhcpd[0]=odhcpd ucitrack.@odhcpd[0].init='odhcpd' ucitrack.@dropbear[0]=dropbear ucitrack.@dropbear[0].init='dropbear' ucitrack.@httpd[0]=httpd ucitrack.@httpd[0].init='httpd' ucitrack.@fstab[0]=fstab ucitrack.@fstab[0].exec='/sbin/block mount' ucitrack.@qos[0]=qos ucitrack.@qos[0].init='qos' ucitrack.@system[0]=system ucitrack.@system[0].init='led' ucitrack.@system[0].exec='/etc/init.d/log reload' ucitrack.@system[0].affects='luci_statistics' 'dhcp' ucitrack.@luci_splash[0]=luci_splash ucitrack.@luci_splash[0].init='luci_splash' ucitrack.@ntpclient[0]=ntpclient ucitrack.@ntpclient[0].init='ntpclient' ucitrack.@samba[0]=samba ucitrack.@samba[0].init='samba' ucitrack.@tinyproxy[0]=tinyproxy ucitrack.@tinyproxy[0].init='tinyproxy' ucitrack.@glorytun[0]=glorytun ucitrack.@glorytun[0].init='glorytun' ucitrack.@glorytun[0].affects='glorytun-udp' 'openmptcprouter-vps' ucitrack.@glorytun-udp[0]=glorytun-udp ucitrack.@glorytun-udp[0].init='glorytun-udp' ucitrack.@mptcpovervpn[0]=mptcpovervpn ucitrack.@mptcpovervpn[0].init='mptcpovervpn' ucitrack.@macvlan[0]=macvlan ucitrack.@macvlan[0].init='macvlan' ucitrack.@upnpd[0]=upnpd ucitrack.@upnpd[0].init='miniupnpd' ucitrack.@shadowsocks-libev[0]=shadowsocks-libev ucitrack.@shadowsocks-libev[0].init='shadowsocks-libev' ucitrack.@shadowsocks-libev[0].affects='omr-tracker' ucitrack.@mlvpn[0]=mlvpn ucitrack.@mlvpn[0].init='mlvpn' ucitrack.@mail[0]=mail ucitrack.@mail[0].init='mail' ucitrack.@omr-bypass[0]=omr-bypass ucitrack.@omr-bypass[0].init='omr-bypass' ucitrack.@snmpd[0]=snmpd ucitrack.@snmpd[0].init='snmpd' ucitrack.@sqm[0]=sqm ucitrack.@sqm[0].init='sqm' ucitrack.@mptcp[0]=mptcp ucitrack.@mptcp[0].init='mptcp' ucitrack.@omr-quota[0]=omr-quota ucitrack.@omr-quota[0].init='omr-quota' ucitrack.@omr-tracker[0]=omr-tracker ucitrack.@omr-tracker[0].init='omr-tracker' ucitrack.@openmptcprouter[0]=openmptcprouter ucitrack.@openmptcprouter[0].init='openmptcprouter' uhttpd.main=uhttpd uhttpd.main.listen_http='0.0.0.0:80' '[::]:80' uhttpd.main.listen_https='0.0.0.0:443' '[::]:443' uhttpd.main.home='/www' uhttpd.main.rfc1918_filter='1' uhttpd.main.max_requests='3' uhttpd.main.max_connections='100' uhttpd.main.cert='/etc/uhttpd.crt' uhttpd.main.key='/etc/uhttpd.key' uhttpd.main.cgi_prefix='/cgi-bin' uhttpd.main.lua_prefix='/cgi-bin/luci=/usr/lib/lua/luci/sgi/uhttpd.lua' uhttpd.main.tcp_keepalive='1' uhttpd.main.ubus_prefix='/ubus' uhttpd.main.redirect_https='0' uhttpd.main.script_timeout='240' uhttpd.main.network_timeout='240' uhttpd.main.http_keepalive='0' uhttpd.defaults=cert uhttpd.defaults.days='730' uhttpd.defaults.key_type='rsa' uhttpd.defaults.bits='2048' uhttpd.defaults.ec_curve='P-256' uhttpd.defaults.country='ZZ' uhttpd.defaults.state='Somewhere' uhttpd.defaults.location='Unknown' uhttpd.defaults.commonname='openmptcprouter' unbound.@unbound[0]=unbound unbound.@unbound[0].add_extra_dns='0' unbound.@unbound[0].add_local_fqdn='1' unbound.@unbound[0].add_wan_fqdn='0' unbound.@unbound[0].dhcp_link='none' unbound.@unbound[0].dhcp4_slaac6='0' unbound.@unbound[0].dns64='0' unbound.@unbound[0].dns64_prefix='64:ff9b::/96' unbound.@unbound[0].domain='lan' unbound.@unbound[0].domain_type='static' unbound.@unbound[0].edns_size='1280' unbound.@unbound[0].extended_stats='0' unbound.@unbound[0].hide_binddata='1' unbound.@unbound[0].interface_auto='1' unbound.@unbound[0].localservice='1' unbound.@unbound[0].manual_conf='0' unbound.@unbound[0].num_threads='1' unbound.@unbound[0].query_minimize='0' unbound.@unbound[0].query_min_strict='0' unbound.@unbound[0].rate_limit='0' unbound.@unbound[0].rebind_localhost='0' unbound.@unbound[0].rebind_protection='1' unbound.@unbound[0].resource='default' unbound.@unbound[0].root_age='9' unbound.@unbound[0].ttl_min='120' unbound.@unbound[0].unbound_control='0' unbound.@unbound[0].validator='0' unbound.@unbound[0].validator_ntp='1' unbound.@unbound[0].verbosity='1' unbound.@unbound[0].trigger_interface='lan' 'wan' unbound.@unbound[0].listen_port='5353' unbound.@unbound[0].protocol='ip4_only' unbound.@unbound[0].enabled='1' unbound.@unbound[0].recursion='aggressive' unbound.@zone[0]=zone unbound.@zone[0].enabled='0' unbound.@zone[0].fallback='1' unbound.@zone[0].url_dir='https://www.internic.net/domain/' unbound.@zone[0].zone_type='auth_zone' unbound.@zone[0].server='lax.xfr.dns.icann.org' 'iad.xfr.dns.icann.org' unbound.@zone[0].zone_name='.' 'arpa.' 'in-addr.arpa.' 'ip6.arpa.' unbound.@zone[1]=zone unbound.@zone[1].enabled='0' unbound.@zone[1].fallback='1' unbound.@zone[1].resolv_conf='1' unbound.@zone[1].zone_type='forward_zone' unbound.@zone[1].zone_name='isp-bill.example.com.' 'isp-mail.example.net.' upnpd.config=upnpd upnpd.config.download='1024' upnpd.config.upload='512' upnpd.config.internal_iface='lan' upnpd.config.port='5000' upnpd.config.upnp_lease_file='/var/run/miniupnpd.leases' upnpd.config.igdv1='1' upnpd.config.enabled='1' upnpd.config.uuid='aa64875a-57f6-46ba-a693-8aa57c1d360e' upnpd.@perm_rule[0]=perm_rule upnpd.@perm_rule[0].action='allow' upnpd.@perm_rule[0].ext_ports='1024-65535' upnpd.@perm_rule[0].int_addr='0.0.0.0/0' upnpd.@perm_rule[0].int_ports='1024-65535' upnpd.@perm_rule[0].comment='Allow high ports' upnpd.@perm_rule[1]=perm_rule upnpd.@perm_rule[1].action='deny' upnpd.@perm_rule[1].ext_ports='0-65535' upnpd.@perm_rule[1].int_addr='0.0.0.0/0' upnpd.@perm_rule[1].int_ports='0-65535' upnpd.@perm_rule[1].comment='Default deny' v2ray.main=v2ray v2ray.main.v2ray_file='/usr/bin/v2ray' v2ray.main.mem_percentage='0' v2ray.main.loglevel='warning' v2ray.main.access_log='/dev/null' v2ray.main.error_log='/var/log/v2ray-error.log' v2ray.main.inbounds='omr' 'omrtest' v2ray.main.outbounds='omrout' 'omrexit' v2ray.main.enabled='1' v2ray.main_dns=dns v2ray.main_dns.hosts='example.com|127.0.0.1' v2ray.main_dns.enabled='0' v2ray.main_policy=policy v2ray.main_policy.enabled='1' v2ray.main_policy.levels='policy_level_0' v2ray.policy_level_0=policy_level v2ray.policy_level_0.level='0' v2ray.policy_level_0.handshake='4' v2ray.policy_level_0.conn_idle='2400' v2ray.policy_level_0.uplink_only='0' v2ray.policy_level_0.downlink_only='0' v2ray.policy_level_0.buffer_size='512' v2ray.main_transparent_proxy=transparent_proxy v2ray.main_transparent_proxy.proxy_mode='default' v2ray.main_transparent_proxy.apnic_delegated_mirror='apnic' v2ray.main_transparent_proxy.gfwlist_mirror='github' v2ray.main_transparent_proxy.redirect_udp='1' v2ray.main_transparent_proxy.redirect_port='1897' v2ray.omrout=outbound v2ray.omrout.tag='omrout_tunnel' v2ray.omrout.protocol='vless' v2ray.omrout.s_vmess_port='65228' v2ray.omrout.s_vmess_user_alter_id='0' v2ray.omrout.s_vless_port='65228' v2ray.omrout.s_vless_user_encryption='none' v2ray.omrout.s_vless_user_alter_id='0' v2ray.omrout.ss_network='tcp' v2ray.omrout.ss_security='tls' v2ray.omrout.ss_tls_allow_insecure='1' v2ray.omrout.ss_tls_disable_system_root='1' v2ray.omrout.ss_tls_cert_usage='verify' v2ray.omrout.ss_tls_cert_file='/etc/luci-uploads/client.crt' v2ray.omrout.ss_tls_key_file='/etc/luci-uploads/client.key' v2ray.omrout.mux_concurrency='8' v2ray.omrout.s_vmess_address='51.195.168.66' v2ray.omrout.s_vless_address='51.195.168.66' v2ray.omrout.s_vmess_user_security='chacha20-poly1305' v2ray.omrout.s_vless_user_security='chacha20-poly1305' v2ray.omrout.s_vmess_user_id='1e9f43ab-053f-4f5a-bf61-fa9e5dee189f' v2ray.omrout.s_vless_user_id='1e9f43ab-053f-4f5a-bf61-fa9e5dee189f' v2ray.omr=inbound v2ray.omr.tag='omrtunnel' v2ray.omr.port='1897' v2ray.omr.protocol='dokodemo-door' v2ray.omr.s_dokodemo_door_network='tcp' 'udp' v2ray.omr.ss_sockopt_tproxy='redirect' v2ray.omr.ss_sockopt_tcp_fast_open='1' v2ray.omr.s_dokodemo_door_follow_redirect='1' v2ray.omr.listen='0.0.0.0' v2ray.omr6=inbound v2ray.omr6.tag='omrtunnel6' v2ray.omr6.listen='::' v2ray.omr6.port='1898' v2ray.omr6.protocol='dokodemo-door' v2ray.omr6.s_dokodemo_door_network='tcp' 'udp' v2ray.omr6.ss_sockopt_tproxy='tproxy' v2ray.omr6.ss_sockopt_tcp_fast_open='1' v2ray.omr6.s_dokodemo_door_follow_redirect='1' v2ray.omrtest=inbound v2ray.omrtest.port='1111' v2ray.omrtest.protocol='socks' v2ray.omrtest.listen='127.0.0.1' v2ray.omrtest.s_socks_auth='noauth' v2ray.omrtest.s_socks_udp='1' v2ray.omrtest.s_socks_ip='127.0.0.1' v2ray.omrtest.s_socks_userlevel='0' v2ray.main_reverse=reverse v2ray.main_reverse.enabled='1' v2ray.main_reverse.bridges='omrbridge|omr.lan' v2ray.omrexit=outbound v2ray.omrexit.protocol='freedom' v2ray.omrexit.tag='out' v2ray.omrrouting=routing_rule v2ray.omrrouting.type='field' v2ray.omrrouting.inbound_tag='omrbridge' v2ray.omrrouting.outbound_tag='omrout_tunnel' v2ray.omrrouting.domain='full:omr.lan' v2ray.omrroutingo=routing_rule v2ray.omrroutingo.type='field' v2ray.omrroutingo.inbound_tag='omrbridge' v2ray.omrroutingo.outbound_tag='out' v2ray.main_routing=routing v2ray.main_routing.enabled='1' v2ray.main_routing.rules='omrrouting' 'omrroutingo' vnstat.@vnstat[0]=vnstat vnstat.@vnstat[0].interface='eth0' 'eth1' 'eth5' 'eth3' 'eth4' 'tun0' ## Specifications - OpenMPTCProuter version: <!--- (Last is not a version) --> 0.56.5 - OpenMPTCProuter VPS version: <!--- (Last is not a version) --> 0.1022.5.4.74 - OpenMPTCProuter platform: <!--- (RPI2/RPI3/x86/x86_64) --> x86-64 <!--- (please do not attach text files) -->"
114167,126864,https://api.github.com/repos/bitcoin/bitcoin/issues/19449,bug,2020-07-05T14:57:09Z,MEMBER,https://api.github.com/repos/bitcoin/bitcoin,"qa: Intermittent failure in p2p_compactblocks.py https://cirrus-ci.com/task/5882340478025728?command=ci#L291 <details><summary>log excerpt</summary> <p> ``` stdout: 2020-07-05T14:39:05.494000Z TestFramework (INFO): Initializing test directory /tmp/cirrus-ci-build/ci/scratch/test_runner/test_runner_₿_🏃_20200705_143741/p2p_compactblocks_152 2020-07-05T14:39:12.900000Z TestFramework (INFO): Testing SENDCMPCT p2p message... 2020-07-05T14:39:16.140000Z TestFramework (INFO): Testing compactblock construction... 2020-07-05T14:40:34.386000Z TestFramework (INFO): Testing compactblock requests (segwit node)... 2020-07-05T14:40:34.948000Z TestFramework (INFO): Testing getblocktxn requests (segwit node)... 2020-07-05T14:40:36.204000Z TestFramework (INFO): Testing getblocktxn handler (segwit node should return witnesses)... 2020-07-05T14:40:38.129000Z TestFramework (INFO): Testing compactblock requests/announcements not at chain tip... 2020-07-05T14:40:40.544000Z TestFramework (INFO): Testing handling of incorrect blocktxn responses... 2020-07-05T14:40:41.370000Z TestFramework (INFO): Testing reconstructing compact blocks from all peers... 2020-07-05T14:40:42.182000Z TestFramework (INFO): Testing end-to-end block relay... 2020-07-05T14:40:43.530000Z TestFramework (ERROR): Assertion failed Traceback (most recent call last): File ""/tmp/cirrus-ci-build/ci/scratch/build/bitcoin-x86_64-pc-linux-gnu/test/functional/test_framework/test_framework.py"", line 117, in main self.run_test() File ""/tmp/cirrus-ci-build/ci/scratch/build/bitcoin-x86_64-pc-linux-gnu/test/functional/p2p_compactblocks.py"", line 837, in run_test self.test_end_to_end_block_relay([self.segwit_node, self.old_node]) File ""/tmp/cirrus-ci-build/ci/scratch/build/bitcoin-x86_64-pc-linux-gnu/test/functional/p2p_compactblocks.py"", line 697, in test_end_to_end_block_relay assert ""cmpctblock"" in l.last_message AssertionError 2020-07-05T14:40:43.629000Z TestFramework (INFO): Stopping nodes 2020-07-05T14:40:47.031000Z TestFramework (WARNING): Not cleaning up dir /tmp/cirrus-ci-build/ci/scratch/test_runner/test_runner_₿_🏃_20200705_143741/p2p_compactblocks_152 2020-07-05T14:40:47.031000Z TestFramework (ERROR): Test failed. Test logging available at /tmp/cirrus-ci-build/ci/scratch/test_runner/test_runner_₿_🏃_20200705_143741/p2p_compactblocks_152/test_framework.log 2020-07-05T14:40:47.032000Z TestFramework (ERROR): 2020-07-05T14:40:47.032000Z TestFramework (ERROR): Hint: Call /tmp/cirrus-ci-build/ci/scratch/build/bitcoin-x86_64-pc-linux-gnu/test/functional/combine_logs.py '/tmp/cirrus-ci-build/ci/scratch/test_runner/test_runner_₿_🏃_20200705_143741/p2p_compactblocks_152' to consolidate all logs 2020-07-05T14:40:47.032000Z TestFramework (ERROR): 2020-07-05T14:40:47.032000Z TestFramework (ERROR): If this failure happened unexpectedly or intermittently, please file a bug and provide a link or upload of the combined log. 2020-07-05T14:40:47.032000Z TestFramework (ERROR): https://github.com/bitcoin/bitcoin/issues 2020-07-05T14:40:47.033000Z TestFramework (ERROR): stderr: ``` </p> </details>"
326011,362430,https://api.github.com/repos/conan-io/conan-center-index/issues/4184,bug,2021-01-09T05:14:35Z,CONTRIBUTOR,https://api.github.com/repos/conan-io/conan-center-index,"[package] poco/1.9.4: Not compile on Windows ### Package and Environment Details (include every applicable attribute) * Package Name/Version: **poco/1.9.4** * Operating System+version: **Windows** * Compiler+version: **MSVC 19.28.29335.0** * Conan version: **conan latest** * Python version: **Python 3.7.9** ### Steps to reproduce (Include if Applicable) Use ezored (ezored.github.io) default steps for windows. ### Logs (Include/Attach if Applicable) <details><summary>Click to expand log</summary> ``` [more errors] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: __cdecl Poco::Net::CertificateValidationException::CertificateValidationException(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,int)"" (??0CertificateValidationException@Net@Poco@@QEAA@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@H@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: __cdecl Poco::Net::CertificateValidationException::CertificateValidationException(int)"" (??0CertificateValidationException@Net@Poco@@QEAA@H@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: __cdecl Poco::Net::InvalidCertificateException::InvalidCertificateException(class Poco::Net::InvalidCertificateException const &)"" (??0InvalidCertificateException@Net@Poco@@QEAA@AEBV012@@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: __cdecl Poco::Net::InvalidCertificateException::InvalidCertificateException(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,int)"" (??0InvalidCertificateException@Net@Poco@@QEAA@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@0H@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: __cdecl Poco::Net::InvalidCertificateException::InvalidCertificateException(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,class Poco::Exception const &,int)"" (??0InvalidCertificateException@Net@Poco@@QEAA@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBVException@2@H@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: __cdecl Poco::Net::InvalidCertificateException::InvalidCertificateException(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,int)"" (??0InvalidCertificateException@Net@Poco@@QEAA@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@H@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: __cdecl Poco::Net::InvalidCertificateException::InvalidCertificateException(int)"" (??0InvalidCertificateException@Net@Poco@@QEAA@H@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: __cdecl Poco::Net::SSLConnectionUnexpectedlyClosedException::SSLConnectionUnexpectedlyClosedException(class Poco::Net::SSLConnectionUnexpectedlyClosedException const &)"" (??0SSLConnectionUnexpectedlyClosedException@Net@Poco@@QEAA@AEBV012@@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: __cdecl Poco::Net::SSLConnectionUnexpectedlyClosedException::SSLConnectionUnexpectedlyClosedException(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,int)"" (??0SSLConnectionUnexpectedlyClosedException@Net@Poco@@QEAA@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@0H@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: __cdecl Poco::Net::SSLConnectionUnexpectedlyClosedException::SSLConnectionUnexpectedlyClosedException(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,class Poco::Exception const &,int)"" (??0SSLConnectionUnexpectedlyClosedException@Net@Poco@@QEAA@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBVException@2@H@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: __cdecl Poco::Net::SSLConnectionUnexpectedlyClosedException::SSLConnectionUnexpectedlyClosedException(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,int)"" (??0SSLConnectionUnexpectedlyClosedException@Net@Poco@@QEAA@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@H@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: __cdecl Poco::Net::SSLConnectionUnexpectedlyClosedException::SSLConnectionUnexpectedlyClosedException(int)"" (??0SSLConnectionUnexpectedlyClosedException@Net@Poco@@QEAA@H@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: __cdecl Poco::Net::SSLContextException::SSLContextException(class Poco::Net::SSLContextException const &)"" (??0SSLContextException@Net@Poco@@QEAA@AEBV012@@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: __cdecl Poco::Net::SSLContextException::SSLContextException(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,int)"" (??0SSLContextException@Net@Poco@@QEAA@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@0H@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: __cdecl Poco::Net::SSLContextException::SSLContextException(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,class Poco::Exception const &,int)"" (??0SSLContextException@Net@Poco@@QEAA@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBVException@2@H@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: __cdecl Poco::Net::SSLContextException::SSLContextException(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,int)"" (??0SSLContextException@Net@Poco@@QEAA@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@H@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: __cdecl Poco::Net::SSLContextException::SSLContextException(int)"" (??0SSLContextException@Net@Poco@@QEAA@H@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: __cdecl Poco::Net::SSLException::SSLException(class Poco::Net::SSLException const &)"" (??0SSLException@Net@Poco@@QEAA@AEBV012@@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: __cdecl Poco::Net::SSLException::SSLException(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,int)"" (??0SSLException@Net@Poco@@QEAA@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@0H@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: __cdecl Poco::Net::SSLException::SSLException(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,class Poco::Exception const &,int)"" (??0SSLException@Net@Poco@@QEAA@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@AEBVException@2@H@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: __cdecl Poco::Net::SSLException::SSLException(class std::basic_string<char,struct std::char_traits<char>,class std::allocator<char> > const &,int)"" (??0SSLException@Net@Poco@@QEAA@AEBV?$basic_string@DU?$char_traits@D@std@@V?$allocator@D@2@@std@@H@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: __cdecl Poco::Net::SSLException::SSLException(int)"" (??0SSLException@Net@Poco@@QEAA@H@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: virtual __cdecl Poco::Net::CertificateValidationException::~CertificateValidationException(void)"" (??1CertificateValidationException@Net@Poco@@UEAA@XZ) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: virtual __cdecl Poco::Net::InvalidCertificateException::~InvalidCertificateException(void)"" (??1InvalidCertificateException@Net@Poco@@UEAA@XZ) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: virtual __cdecl Poco::Net::SSLConnectionUnexpectedlyClosedException::~SSLConnectionUnexpectedlyClosedException(void)"" (??1SSLConnectionUnexpectedlyClosedException@Net@Poco@@UEAA@XZ) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: virtual __cdecl Poco::Net::SSLContextException::~SSLContextException(void)"" (??1SSLContextException@Net@Poco@@UEAA@XZ) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: virtual __cdecl Poco::Net::SSLException::~SSLException(void)"" (??1SSLException@Net@Poco@@UEAA@XZ) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: class Poco::Net::CertificateValidationException & __cdecl Poco::Net::CertificateValidationException::operator=(class Poco::Net::CertificateValidationException const &)"" (??4CertificateValidationException@Net@Poco@@QEAAAEAV012@AEBV012@@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: class Poco::Net::InvalidCertificateException & __cdecl Poco::Net::InvalidCertificateException::operator=(class Poco::Net::InvalidCertificateException const &)"" (??4InvalidCertificateException@Net@Poco@@QEAAAEAV012@AEBV012@@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: class Poco::Net::SSLConnectionUnexpectedlyClosedException & __cdecl Poco::Net::SSLConnectionUnexpectedlyClosedException::operator=(class Poco::Net::SSLConnectionUnexpectedlyClosedException const &)"" (??4SSLConnectionUnexpectedlyClosedException@Net@Poco@@QEAAAEAV012@AEBV012@@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: class Poco::Net::SSLContextException & __cdecl Poco::Net::SSLContextException::operator=(class Poco::Net::SSLContextException const &)"" (??4SSLContextException@Net@Poco@@QEAAAEAV012@AEBV012@@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: class Poco::Net::SSLException & __cdecl Poco::Net::SSLException::operator=(class Poco::Net::SSLException const &)"" (??4SSLException@Net@Poco@@QEAAAEAV012@AEBV012@@Z) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: virtual char const * __cdecl Poco::Net::CertificateValidationException::className(void)const "" (?className@CertificateValidationException@Net@Poco@@UEBAPEBDXZ) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: virtual char const * __cdecl Poco::Net::InvalidCertificateException::className(void)const "" (?className@InvalidCertificateException@Net@Poco@@UEBAPEBDXZ) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: virtual char const * __cdecl Poco::Net::SSLConnectionUnexpectedlyClosedException::className(void)const "" (?className@SSLConnectionUnexpectedlyClosedException@Net@Poco@@UEBAPEBDXZ) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: virtual char const * __cdecl Poco::Net::SSLContextException::className(void)const "" (?className@SSLContextException@Net@Poco@@UEBAPEBDXZ) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: virtual char const * __cdecl Poco::Net::SSLException::className(void)const "" (?className@SSLException@Net@Poco@@UEBAPEBDXZ) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: virtual class Poco::Exception * __cdecl Poco::Net::CertificateValidationException::clone(void)const "" (?clone@CertificateValidationException@Net@Poco@@UEBAPEAVException@3@XZ) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: virtual class Poco::Exception * __cdecl Poco::Net::InvalidCertificateException::clone(void)const "" (?clone@InvalidCertificateException@Net@Poco@@UEBAPEAVException@3@XZ) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: virtual class Poco::Exception * __cdecl Poco::Net::SSLConnectionUnexpectedlyClosedException::clone(void)const "" (?clone@SSLConnectionUnexpectedlyClosedException@Net@Poco@@UEBAPEAVException@3@XZ) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] PocoNetSSLWinmd.lib(SSLException.obj) : error LNK2005: ""public: virtual class Poco::Exception * __cdecl Poco::Net::SSLContextException::clone(void)const "" (?clone@SSLContextException@Net@Poco@@UEBAPEAVException@3@XZ) already defined in PocoNetSSLmd.lib(SSLException.obj) [D:\a\ezored\ezored\build\windows_app\Release\x86_64\target\ezored.vcxproj] ``` </details> Related: https://github.com/pocoproject/poco/issues/3181"
642297,713882,https://api.github.com/repos/neovim/neovim/issues/14228,bug,2021-03-27T14:12:50Z,NONE,https://api.github.com/repos/neovim/neovim,"LuaJIT: attempt to index global 'jit' (a nil value) <!-- Before reporting: search existing issues and check the FAQ. --> - `nvim --version`: NVIM v0.5.0-dev+1178-gf0ace6d41 - `vim -u DEFAULTS` (version: ) behaves differently? No - Operating system/version: Android 9 - Terminal name/version: Termux - `$TERM`: xterm-256color ### Steps to reproduce using `nvim -u NORC` - start nvim - then, `:lua print(jit.version)` <!-- # Alternative for shell-related problems: --> <!-- # env -i TERM=ansi-256color ""$(which nvim)"" --> ## Problem When calling `:lua(jit.version)` when compiled with `PREFER_LUA=ON` results in ``` E5108: Error executing lua [string "":lua""]:1: attempt to index global 'jit' (a nil value) ```"
113792,126455,https://api.github.com/repos/helgoboss/realearn/issues/5,enhancement,2020-07-17T08:47:14Z,NONE,https://api.github.com/repos/helgoboss/realearn,"Play Region target For Live purposes a common use case for Control Surfaces is to determine which region is currently played/looped. In other software they may be clips or scenes, but for my experience the most straightforward thing to do in reaper is to work with regions. It would be great to have a trigger that goes like ""go to region x when cursor reaches the next region marker"". I have currently implemented this using a custom action that combines sws and standard reaper actions, and I correctly trigger the actions using a midi surface. The big issue is feedback, which is fundamental, because while I'm playing live I'd like to know which one of the regions is being played. This can be achieved by lighting it with another color (or maybe flashing, or whatever, but let's say lit with another color). I have no clue about how much a hassle can it be to implement this, I just want to mention that maybe a combination of custom actions + a check on whether the cursor in inside the region can be a cheaper way to do this.. Maybe (= Thank you very much"
274606,305400,https://api.github.com/repos/felangel/bloc/issues/2118,question,2021-01-30T08:03:55Z,NONE,https://api.github.com/repos/felangel/bloc,"Page view inside tab with bloc state change Hi i have the following screen(Stats Monthly Daily) with stateful widget with TickerProviderStateMixin to use the pageview and a list. Pageview swipe left and right works fine. Whenever user changes the tab (lets say Day Month Year). I need to refresh the page with new content from sqliteDb. but its not working that way, showing the same view(expect Month chart. result Day chart). If i debug, create method never called or bloc provider returning the old bloc i think. APPBAR ======= TabBar( onTap: (i) { event = ChartTryEventMonth(); context.read<ChartTryBloc>().add(event); } PAGE BLOC ========= @override Stream<ChartTryState> mapEventToState( ChartTryEvent event, ) async* { if(event is ChartTryEventMonth){ yield ChartTryState(type: ""MONTH""); } PAGE VIEW BUILD() ======== BlocBuilder<ChartTryBloc , ChartTryState>(builder: (context , state){ return Container( height: 100, width: 200, child: PageView.builder( controller: _pageController, itemBuilder: (context , index){ return Container( child: Center( child: BlocProvider(lazy : false , create: (_) => SimpleCompBloc()..add(SceLoad(type: state.type)), child: SingleChartView(),), ), ); }, itemCount: 100, ), ); }) class SingleChartView extends StatelessWidget { @override Widget build(BuildContext context) { return BlocBuilder<SimpleCompBloc, SimpleCompState>(builder: (context , state){ if(state.list == null){ return Container( child: Text(""Loading""), ); } else if(state.list != null){ return Container( child: Text(""${state.type}${state.list.length}""), ); } return CircularProgressIndicator(); }); } } class SimpleCompBloc extends Bloc<SimpleCompEvent, SimpleCompState> { SimpleCompBloc() : super(SimpleCompState()); @override Stream<SimpleCompState> mapEventToState( SimpleCompEvent event, ) async* { if(event is SceLoad){ // sleep(Duration(seconds: 3)); yield SimpleCompState(); await Future.delayed(Duration(seconds: 3)); final list= List<String>(); list.add(""raja""); yield SimpleCompState(list: list , type : event.type ); } } } "
265657,295440,https://api.github.com/repos/st-universe/core/issues/384,enhancement,2020-12-15T13:49:06Z,MEMBER,https://api.github.com/repos/st-universe/core,"Nach beamen ""zum Schiff wechseln"" / Button ""zum Schiff wechseln"" Beamt man etwas vom Koloniebildschirm zu einem Schiff, wird die Meldung herausgegeben dass Waren transferiert wurden. Jedoch ist es immernoch umständlich aus dem Koloniebildschirm direkt auf das Schiff zu wechseln. Den Schiffsnamen in dieser Meldung könnte man direkt mit dem Schiff selbst verlinken, sodass ein Klick auf den Namen in der Meldung einen direkt zum Schiff führt. Weiterhin wär es ideal einen Button neben den beiden Beambutton im Koloniebildschirm einzubauen, welcher ein direktes Wechseln, zum in der Liste ausgewählten Schiff, ermöglicht."
277092,308169,https://api.github.com/repos/joeltio/bento-box/issues/18,bug,2021-01-11T01:48:18Z,COLLABORATOR,https://api.github.com/repos/joeltio/bento-box,Fix SDK Doc misrendering ### 1. Fix `bento.graph.compile` Usage example in [SDK docs](https://joeltio.github.io/bento-box/graph/index.html) not rendering correctly: ![image](https://user-images.githubusercontent.com/15938899/104141556-5220bb80-53f2-11eb-8b3a-64fe9b147d92.png). This should show an code example with syntax highlighting and proper indention. --- ### 2. Fix Args of `bento.graph.ast`: ![Screenshot from 2021-01-13 10-28-48](https://user-images.githubusercontent.com/15938899/104398698-394b0e00-558a-11eb-8f59-a628a8a9304f.png) --- ### 3. `bento.graph.ecs.GraphComponent` usage: ![Screenshot from 2021-01-13 10-30-04](https://user-images.githubusercontent.com/15938899/104398805-6992ac80-558a-11eb-88f8-ddf248c6fbdd.png) --- ### 4. `bento.graph.transforms.transform_ifelse` docs: ![Screenshot from 2021-01-13 10-33-09](https://user-images.githubusercontent.com/15938899/104399020-d3ab5180-558a-11eb-839c-c803fae5928c.png) 
268589,298697,https://api.github.com/repos/SAP/spartacus/issues/11241,bug,2021-02-23T18:59:48Z,CONTRIBUTOR,https://api.github.com/repos/SAP/spartacus,"A11Y. ""show more"" toggle doesn't work with keyboard **Setup** 3.1.0.RC2 Server Links CCV2 (CX 2011.1): -- b2c - https://spartacusstore.cg79x9wuu9-eccommerc1-p5-public.model-t.myhybris.cloud/electronics-spa/en/USD/ -- b2b - https://b2bspastore.cg79x9wuu9-eccommerc1-p5-public.model-t.myhybris.cloud/powertools-spa/en/USD/ Linux (CX 2005.6): -- b2c - http://spartacus-dev2.eastus.cloudapp.azure.com:4200/electronics-spa/en/USD/ -- b2b - http://spartacus-dev2.eastus.cloudapp.azure.com:5200/powertools-spa/en/USD/ **Steps to Reproduce (Using Keyboard Only):** 1. Navigate to B2C Storefront 2. Search for HOME 3. From product listing page, select Home Theatre product. 4. Tab until arriving to ""show more"" toggle. 5. Press Enter key. **Expected Results:** 5. Toggle works and a small image of Home Theatre System is shown. Caption is changed to ""show less"". **Actual Results:** 5. Nothing happens. "
80460,89446,https://api.github.com/repos/Jaimss/moducore/issues/25,enhancement,2021-02-01T23:57:41Z,OWNER,https://api.github.com/repos/Jaimss/moducore,"replace FileManager#getString move `FileManager#getString` to `FileManager#getMessage` which returns a `MessageComponent`, then just call `MessageComponent#sendMessage(Player)` won't be possible in every situation cause `CommandSender`s, but it should be used where possible to support markdown "
117768,130864,https://api.github.com/repos/AdventurePHP/code/issues/566,bug,2021-01-27T21:22:52Z,MEMBER,https://api.github.com/repos/AdventurePHP/code,"[ID#325] Der HtmlLinkTag erstellt keine TagLibs in ihm. Reporter: General Crime Created: 2017-11-02 Updated: 2017-11-03 Assigned To: ChristianAchatz Priority: normal Severity: kleinerer Fehler Status: erledigt Product version: 3.3 Solved in version: 3.4 Target version: *** **Description:** Der HtmlLinkTag kann z.B. nicht mit (html:getstring) verwendet werden oder anderen TagLibs ******* **Notes:** @ChristianAchatz 2017-11-03 09:04 Perfekt, dann ist das Issue hiermit erledigt! :) =-= @General Crime 2017-11-02 22:46 Ich habe nichts dagegen. =-= @ChristianAchatz 2017-11-02 19:43 Hallo Christian, vielen Dank für deinen Beitrag! Tolle Erweiterung des Tags! :) Hab deinen Pull-Request direkt gemerged. Damit können wir das Issue auch direkt schließen - wenn du einverstanden bist! =-= @General Crime 2017-11-02 11:11 Pull Request #20 behebt das Problem. "
703023,781332,https://api.github.com/repos/jc21/nginx-proxy-manager/issues/828,bug,2021-01-15T10:26:24Z,NONE,https://api.github.com/repos/jc21/nginx-proxy-manager,"UNKNOWN_CODE_PLEASE_REPORT: SSL connection is required. Please specify SSL options and retry. **Checklist** Yes it works fine with the maria db from the docker compose setup. **Describe the bug** I'm trying to use my existing mysql server, and I think everything is set up right but I get the above error about ssl. I'm assuming it means SSL as related to the mysql connection. **To Reproduce** Not sure **Expected behavior** I hoped it would connect to mysql **Screenshots** ```` [services.d] starting services [services.d] done. ❯ Enabling IPV6 in hosts: /etc/nginx/conf.d ❯ /etc/nginx/conf.d/include/ip_ranges.conf ❯ /etc/nginx/conf.d/include/force-ssl.conf ❯ /etc/nginx/conf.d/include/letsencrypt-acme-challenge.conf ❯ /etc/nginx/conf.d/include/ssl-ciphers.conf ❯ /etc/nginx/conf.d/include/block-exploits.conf ❯ /etc/nginx/conf.d/include/proxy.conf ❯ /etc/nginx/conf.d/include/assets.conf ❯ /etc/nginx/conf.d/include/resolvers.conf ❯ /etc/nginx/conf.d/default.conf ❯ /etc/nginx/conf.d/production.conf ❯ Enabling IPV6 in hosts: /data/nginx [1/15/2021] [10:22:34 AM] [Global ] › ✖ error UNKNOWN_CODE_PLEASE_REPORT: SSL connection is required. Please specify SSL options and retry. [1/15/2021] [10:22:35 AM] [Global ] › ✖ error UNKNOWN_CODE_PLEASE_REPORT: SSL connection is required. Please specify SSL options and retry. [1/15/2021] [10:22:37 AM] [Global ] › ✖ error UNKNOWN_CODE_PLEASE_REPORT: SSL connection is required. Please specify SSL options and retry. ```` **Operating System** Docker on Ubuntu 20.04 **Additional context** the mysql server is an azure mysql server"
343129,381438,https://api.github.com/repos/FrancoisCapon/LoginToASqlite3DatabaseWithoutCredentialsWithAdminer/issues/3,bug,2021-05-21T16:30:43Z,NONE,https://api.github.com/repos/FrancoisCapon/LoginToASqlite3DatabaseWithoutCredentialsWithAdminer,"Getting stdClass::$orgTable error same as like adminer-4.8.1 Hello, I have seen a bug in the dev build for sqlite, which is ![image](https://user-images.githubusercontent.com/83438329/119169521-bb3ecc80-ba7f-11eb-9a33-3489fd6b34cd.png) ` Warning: Undefined property: stdClass::$orgtable in C:\Bitnami\apachephp\Apache24\htdocs\adminer\adminer-dev.php on line 679 ` This bug is also present in adminer 4.8.1 on line number 1478. php version 8.0.3 windows 8.1 x64 apache 2.4 dataset was a simple table with three columns and 10 rows."
504558,560812,https://api.github.com/repos/kofrasa/mingo/issues/155,enhancement,2020-09-21T16:43:45Z,NONE,https://api.github.com/repos/kofrasa/mingo,"add option to disable $where clause **Is your feature request related to a problem? Please describe.** I'm trying to use mingo to allow querying a just subset of data via an API, but i'd like to not allow `$where` or any eval clauses. **Describe the solution you'd like** As a user of `mingo`, for security purposes, I'd like to not allow any evals in queries such as `$where: ""this.foo && this.bar""`, is theres a way to disable it? **Additional context** Heres the reference on how to disable this in the mongodb documentation: ![image](https://user-images.githubusercontent.com/364566/93795825-cab6fe80-fbee-11ea-9d38-4990e292548b.png) > source: https://docs.mongodb.com/manual/reference/operator/query/where/#javascript-enablement"
117584,130660,https://api.github.com/repos/felixblaschke/simple_animations/issues/48,enhancement,2020-12-15T22:31:43Z,NONE,https://api.github.com/repos/felixblaschke/simple_animations,"More colors combinations Hi, I'd like to report a suggestion: I've been looking exactly for the effect you named ""Plasma"" and it looks amazing. I think I would be even greater if there was a simple way to have more than 2 colors (particles of different colors?)"
571409,634998,https://api.github.com/repos/hajimehoshi/ebiten/issues/1484,bug,2021-02-08T15:56:30Z,OWNER,https://api.github.com/repos/hajimehoshi/ebiten,cmd/ebitenmobile: Update gomobile version after some issues are fixed * https://github.com/golang/go/issues/44162 * https://github.com/golang/go/issues/44121
571289,634869,https://api.github.com/repos/PikaMug/Quests/issues/1640,bug,2021-03-12T20:08:50Z,NONE,https://api.github.com/repos/PikaMug/Quests,"Entities Not Recognized In Quests Conditions GUI <!-- Thanks for submitting a bug report! Please answer the following questions: --> **What is your Quests version / build number (do _not_ say ""latest"")?** **Version:**4.0.0-rc.4-b191 **Describe the problem and how to replicate it. Any console errors to post _using a pastebin_?** When in the /quests conditions gui, you are given the option to create a condition for a player riding an entity. Of the list of entities given, only the animal entities (pig, donkey, etc.) are recognized while all other entities (MinecartCommand, Minecart, etc.) prompt me with a message saying ""X is not a valid mob name"". Manually entering in the unrecognized entities does not work either and leads to the entire condition being ""removed"" from ingame. **If applicable, can you provide an example quest from quests.yml _using a pastebin_?** N/A"
170647,189737,https://api.github.com/repos/nixgates/plugin.video.seren/issues/318,bug,2021-01-04T00:07:49Z,NONE,https://api.github.com/repos/nixgates/plugin.video.seren,"[BUG] - next up missing the show name on titan binge skin **Describe the bug** Using the titan binge skin the next up is missing the text for the show name, while is still shows the episode details. This was not an issue on the old seren. It's present on widgets and within the add-on itself **To Reproduce** Steps to reproduce the behavior: 1. Using the titan binge skin, create a widget for next up 2. Once the widget is populated, observe the text does not look right on the widget. The show name is missing 3. In the add-on go to my shows > next up 4. Observe there are no show names here either with similar behaviour as widgets **Expected behavior** Widget and add-on should display the show name like it did on previous versions of seren rather than leaving a blank gap **Screenshots** ![IMG_20210103_235527](https://user-images.githubusercontent.com/76923908/103492101-a0e1ba80-4e20-11eb-8106-8e5401f98430.jpg) ![IMG_20210104_000406](https://user-images.githubusercontent.com/76923908/103492145-d1295900-4e20-11eb-812e-0eb6197d7494.jpg) **Kodi Version (please complete the following information):** - Kodi Version: 18.9 - Seren 2.0.8 "
686260,762695,https://api.github.com/repos/topcoder-platform/forums/issues/339,bug,2020-12-30T07:52:38Z,COLLABORATOR,https://api.github.com/repos/topcoder-platform/forums,"Issues when user post the comment/discussion while the attachment is being uploaded **Steps** 1. Launch the application and login as a copilot user 2. Open a new discussion and attach some files 3. While the attachments are being uploaded, post the discussion **Result** - the attachment name is showing as 'Uploading' and clicking it will open the same discussion - the editor will show the attachments again after the file upload completes [Screencast 2020-12-30.zip](https://github.com/topcoder-platform/forums/files/5753412/Screencast.2020-12-30.zip) "
707654,786492,https://api.github.com/repos/dekkerglen/CubeCobra/issues/1784,enhancement,2021-01-01T08:06:09Z,CONTRIBUTOR,https://api.github.com/repos/dekkerglen/CubeCobra,"Add mouseover text on cube previews As a user, when I place my cursor on a truncated cube title in a cube preview card, I want a mouseover text to appear showing the full name of the cube"
564266,627074,https://api.github.com/repos/godotengine/godot/issues/27142,bug,2019-03-16T22:08:34Z,NONE,https://api.github.com/repos/godotengine/godot,"Area2D stops working when you click on an area2d node in the inspector <!-- Please search existing issues for potential duplicates before filing yours: https://github.com/godotengine/godot/issues?q=is%3Aissue --> **Godot version:** <!-- Specify commit hash if non-official. --> v3.1.stable.official **OS/device including version:** <!-- Specify GPU model and drivers if graphics-related. --> Windows 10 **Issue description:** <!-- What happened, and what was expected. --> For some reason I noticed if an Area2D node is selected in the editor inspector and you run your game, the Area2D node that you clicked on will no longer work until you click off of it in the editor inspector and restart your game. **Steps to reproduce:** 1. Click on an Area2D node. 2. Run your game. 3. Area2D node no longer works."
553943,615627,https://api.github.com/repos/keijiro/KlakNDI/issues/111,question,2021-03-25T21:01:14Z,NONE,https://api.github.com/repos/keijiro/KlakNDI,"Stability: functions intermittently on Ubuntu KlakNDI is working really well for me on MacOS Catalina (testing using Sienna NDI Monitor on another Mac). I've been trying to get it working on my Pop OS (Ubuntu 20.04) machine but I only get it working very occasionally and can't identify the reason why it won't work consistently. I'm running Unity 2019.4.23f1 with .NET 2.0. I installed the NDI SDK 4.6.2, and this could be the problem. You specified v4.0.1 but I couldn't find it anywhere, is this important? This is what happens when I try it: - I attach the sender component to the main camera, and chose 'game view' for simplicity - after a few seconds I can see the scene on the NDI monitor - I set the game resolution to 1920x1080 - when I press play, the image disappears from the monitor, but it can still see the NDI device on the network - once in about every 20 tries, I can get the live stream working and stable I'm sorry I don't have more specific information, I'm just not getting any errors and it works sometimes. Any suggestions would be greatly appreciated!"
710864,790059,https://api.github.com/repos/chunky-dev/chunky/issues/927,bug,2021-05-08T20:45:00Z,MEMBER,https://api.github.com/repos/chunky-dev/chunky,"Paintings don't work with 1.14+ resourcepacks Paintings textures were changed in 1.14 so they are not found by chunky anymore. Instead of using a single texture with all paintings, the textures are now split into multiple files in `/assets/minecraft/textures/painting/`. The border and back of a painting is in `back.png`."
11849,13206,https://api.github.com/repos/MiguelRipoll23/homebridge-securitysystem/issues/101,question,2021-04-10T17:56:34Z,NONE,https://api.github.com/repos/MiguelRipoll23/homebridge-securitysystem,HomeKit notification when last person go out Is there way to automate alarm arm when the last person go out of the home without confirmation? Now the notification tell me confirmation to do that. Thanks for this plug in.
54074,60156,https://api.github.com/repos/NubeIO/rubix-point-server/issues/189,question,2021-01-22T00:36:27Z,COLLABORATOR,https://api.github.com/repos/NubeIO/rubix-point-server,"GenericPoint Rework ### Generic Point Related #187 **Mostly discussion topic for now until full scope of generic point is decided** Maybe two point types: - **Writable** - i.e. set_point that can be written from cloud (Over `HTTP PATCH`) - **Not Writable / Input Only** - i.e. data point that comes from internal service (i.e. wires, node-red) (This is the current implementation)(updated over MQTT as currently implemented) These two should be kept separate as a `non-writable / input only` point might be coming from some new data source from node-red (example) and should not be writable by a user/cloud"
522220,580395,https://api.github.com/repos/mexyn/statev_v2_issues/issues/745,bug,2020-12-05T10:55:11Z,NONE,https://api.github.com/repos/mexyn/statev_v2_issues,Waffe verstecken <!-- Bitte die Vorlage unten vollständig ausfüllen --> Stefan_Ebering <!-- Mit welchem Character wurde das Verhalten in-game ausgelöst/beobachtet --> 05.12.20 ca. 11.00 Uhr <!-- Wann exakt (Datum / Uhrzeit) ist der Fehler beobachtet worden --> Man kann Waffe im Schlüsselbund verstecken <!--- Beschreibe den Fehler --> Sollte nicht gehen <!--- Beschreibe wie es richtigerweise sein sollte --> Geholsterte Waffe in das Schlüsselbund ziehen <!--- Beschreibe Schritt für Schritt wie man den Fehler nachstellen kann --> https://www.youtube.com/watch?v=hfbThF4smUs&feature=youtu.be 
606669,674205,https://api.github.com/repos/tiangolo/fastapi/issues/3155,question,2021-05-01T20:34:40Z,NONE,https://api.github.com/repos/tiangolo/fastapi,"OpenApi docs for subclass of list of pydantic BaseModel ### First check * [x ] I added a very descriptive title to this issue. * [x ] I used the GitHub search to find a similar issue and didn't find it. * [x ] I searched the FastAPI documentation, with the integrated search. * [x ] I already searched in Google ""How to X in FastAPI"" and didn't find any information. * [x ] I already read and followed all the tutorial in the docs and didn't find an answer. * [x ] I already checked if it is not related to FastAPI but to [Pydantic](https://github.com/samuelcolvin/pydantic). * [x ] I already checked if it is not related to FastAPI but to [Swagger UI](https://github.com/swagger-api/swagger-ui). * [x ] I already checked if it is not related to FastAPI but to [ReDoc](https://github.com/Redocly/redoc). * [x ] After submitting this, I commit to one of: * Read open issues with questions until I find 2 issues where I can help someone and add a comment to help there. * I already hit the ""watch"" button in this repository to receive notifications and I commit to help at least 2 people that ask questions in the future. * Implement a Pull Request for a confirmed bug. <!-- I'm asking all this because answering questions and solving problems in GitHub issues consumes a lot of time. I end up not being able to add new features, fix bugs, review Pull Requests, etc. as fast as I wish because I have to spend too much time handling issues. All that, on top of all the incredible help provided by a bunch of community members that give a lot of their time to come here and help others. That's a lot of work they are doing, but if more FastAPI users came to help others like them just a little bit more, it would be much less effort for them (and you and me 😅). --> ### Example Here's a self-contained, [minimal, reproducible, example](https://stackoverflow.com/help/minimal-reproducible-example) with my use case: <!-- Replace the code below with your own self-contained, minimal, reproducible, example, if I (or someone) can copy it, run it, and see it right away, there's a much higher chance I (or someone) will be able to help you --> ```Python from typing import List from fastapi import FastAPI from pydantic import BaseModel app = FastAPI() class MyModel(BaseModel): a: int class MyModelList(List[MyModel]): ... # Bunch of useful methods # version 1. This one has working openapi docs @app.get(""/with_docs"", response_model=List[MyModel]) def foo(): return [MyModel(a=10)] # version 2. How to make docs here works? @app.get(""/without_docs"", response_model=MyModelList) def foo2(): res = MyModelList() res.append(MyModel(a=10)] return res ``` ### Description I search for a way to generate docs for type that is subclass of list of pydantic BaseModel. I have a bunch of usefull methods that operate on that list that's why I don't want to use version 1. I tried multiinheritance and other things but nothing worked."
619336,688270,https://api.github.com/repos/microting/eform-casetemplate-base/issues/109,enhancement,2021-05-31T07:58:19Z,MEMBER,https://api.github.com/repos/microting/eform-casetemplate-base,Bump Microting.eForm from 5.2.3 to 5.2.4 TBD
228306,253902,https://api.github.com/repos/hoffstadt/DearPyGui/issues/496,bug,2021-01-20T20:48:20Z,OWNER,https://api.github.com/repos/hoffstadt/DearPyGui,Table Callback Data not being sent **Version of Dear PyGui:** Version: 0.6.137 **OS** Operating System: All **My Issue/Question** Callback data is not being passed to the callback. 
405555,450769,https://api.github.com/repos/ap-oc/exocortex/issues/1,enhancement,2021-02-03T07:42:20Z,OWNER,https://api.github.com/repos/ap-oc/exocortex,"a composition of cube and euclidean space for graph trees if graph trees were to be organized in three-dimensional space they'd have to be organized by X, Y, Z cube axis as well as H, V degree axis so a point would be at X:1 Y:1 Z:1 H:1 V:1 X, Y, Z would likely be derived from however H and V are generated. "
309827,344485,https://api.github.com/repos/memoriesadrift/we-find/issues/25,enhancement,2021-05-14T10:13:33Z,OWNER,https://api.github.com/repos/memoriesadrift/we-find,"Implement full multilingual support Many parts of the app do not handle multilinguality correctly, we need to implement this,"
123782,137555,https://api.github.com/repos/Cache-and-Cookies/msmr/issues/21,enhancement,2021-02-16T20:15:35Z,MEMBER,https://api.github.com/repos/Cache-and-Cookies/msmr,About Page - Using the MSMR ![image](https://user-images.githubusercontent.com/65472533/108116580-cb52a480-7069-11eb-97ec-15bf8188b9e3.png) 
311154,345957,https://api.github.com/repos/scipp/scipp/issues/1559,bug,2021-01-18T14:33:35Z,MEMBER,https://api.github.com/repos/scipp/scipp,"Plotting or Rebin bug with thickness 1. Run the following in a notebook ```python import scipp as sc import numpy as np x = sc.Variable(['x', 'y', 'z'], values=np.ones((10, 10, 10))) sc.plot.plot(x) ``` 2. Then increase thickness 3. Then hit rescale - No change in colour scale implies doesn’t seem to be summing as I increase thickness as set rescale. Can you check?"
288325,320633,https://api.github.com/repos/cubecart/v6/issues/2815,bug,2021-03-11T06:25:48Z,NONE,https://api.github.com/repos/cubecart/v6,"Potential Image Cropper Issue Hey, I manage to run into another issue with the file manager. We'll I'm not sure if this is an issue or if it was designed this way, but when I open the image cropper and try to crop, the crop window is fixed to the top left corner making it impossible for me to crop the image (unless I actually want to crop the top left corner). When I try to move the crop window I do see the 4 arrows but the crop window will not move. I've tested it on both my install and your demo site. Same thing on both. Again, not sure if this was intentional or not but it would be excellent If I could reposition the crop window. Thanks."
145961,162236,https://api.github.com/repos/owncloud/product/issues/179,bug,2020-08-25T09:04:17Z,MEMBER,https://api.github.com/repos/owncloud/product,"Propfind to trashbin endpoint requires UUID ### Steps to reproduce 1. Make propfind request to trashbin api endpoint using the username of your user `curl -k -u einstein:relativity -X PROPFIND https://localhost:9200/remote.php/dav/trash-bin/einstein -v` Response: `< HTTP/1.1 405 Method Not Allowed ....` 2. Make propfind request to the same endpoint using the UUID of your user `curl -k -u einstein:relativity -X PROPFIND https://localhost:9200/remote.php/dav/trash-bin/4c510ada-c86b-4815-8820-42cdf82c3d51 -v` Response: `<?xml version=""1.0"" encoding=""utf-8""?><d:multistatus xml.....` ### Expected behavior It must be possible to make request to trashbin endpoint using username."
517456,575053,https://api.github.com/repos/risoflora/brookframework/issues/23,bug,2021-03-07T03:43:58Z,NONE,https://api.github.com/repos/risoflora/brookframework,"M.ToCString() has a bug If the parameter is a double-byte string(E.g. Chinese), the function will return a garbled string. **Steps to reproduce:** TestCode： procedure THTTPServer.DoRequest(ASender: TObject; ARequest: TBrookHTTPRequest; AResponse: TBrookHTTPResponse); begin //Path contains Chinese AResponse.Download('G:\编程\TestFiles\1.txt'); end; Open the browser and it will prompt File not found, click the breakpoint on the function sg_httpres_download, you will find that the variable filename is garbled ![1](https://user-images.githubusercontent.com/30143806/110228184-1c9fd680-7f3a-11eb-8562-5d8d7972b45f.png) ![2](https://user-images.githubusercontent.com/30143806/110228185-1dd10380-7f3a-11eb-8503-7184f95fa494.png) **Environment:** - Windows 10 Enterprise - Delphi 10.2 - Brook 5.4.7 - Sagui 3.3.1 x86 In fact, PAnsiChar(AnsiString(AFileName)) can be used to solve this problem. procedure TBrookHTTPResponse.Download(const AFileName: TFileName; AStatus: Word); var M: TMarshaller; R: cint; begin SgLib.Check; if FCompressed then begin R := sg_httpres_zdownload(FHandle, PAnsiChar(AnsiString(AFileName)), AStatus); CheckZLib(R); end else R := sg_httpres_download(FHandle, PAnsiChar(AnsiString(AFileName)), AStatus); CheckAlreadySent(R); if R = ENOENT then raise EFileNotFoundException.Create(SFileNotFound); SgLib.CheckLastError(R); end; "
105893,117688,https://api.github.com/repos/rundeck/rundeck-cli/issues/346,bug,2021-02-18T14:37:51Z,NONE,https://api.github.com/repos/rundeck/rundeck-cli,"""rd project set"" command fails ( error 500 ) in the first run if more than 3 parameters are used ### How To Reproduce: **4 parameters** :shows error 500 only in the first run ``` $ rd projects create -p my_test_group9 # Created project: # my_test_group9 $ rd projects configure set -p my_test_group9 -- --project.globals.property1=""test-value1"" --project.globals.property2=""test-value2"" --project.description=""Testing Group 1"" --project.disable.executions=""true"" Error: (no message) Request failed: 500 Server Error $ $rd projects configure set -p my_test_group9 -- --project.globals.property1=""test-value1"" --project.globals.property2=""test-value2"" --project.description=""Testing Group 1"" --project.disable.executions=""true"" $ ``` **Less than 3 parameters**: always succeeds ( EXPECTED BEHAVIOR) ``` $rd projects create -p my_test_group9 # Created project: # my_test_group9 $ $rd projects configure set -p my_test_group9 -- --project.globals.property1=""test-value1"" --project.globals.property2=""test-value2"" --project.description=""Testing Group 1"" $ ``` *** The same steps using ""rd update"" always succeeds. "
580757,645360,https://api.github.com/repos/sems/sems.dev/issues/32,enhancement,2020-06-27T13:23:16Z,OWNER,https://api.github.com/repos/sems/sems.dev,Intergrate Unsplash Intergrate unsplash view/download counter. https://unsplash.com/developers
127414,141611,https://api.github.com/repos/cloudfordream/Traduction-i18n-CodeIgniter-3/issues/2,question,2020-11-02T13:05:32Z,NONE,https://api.github.com/repos/cloudfordream/Traduction-i18n-CodeIgniter-3,"Default language whtout language abbreviation Hi, is possibile to set the default language without the language abbreviation in the url? For example: $config['language_abbr_enable'] = TRUE; $config['language_abbr'] = ""en""; Url: https://www.example.com/en $config['language_abbr_enable'] = FALSE; $config['language_abbr'] = ""en""; Url: https://www.example.com/ Thanks "
212758,236575,https://api.github.com/repos/orange-cloudfoundry/paas-templates/issues/409,enhancement,2019-05-24T21:25:01Z,MEMBER,https://api.github.com/repos/orange-cloudfoundry/paas-templates,"offline buildpacks for .net, r and nginx ### Expected behavior As a platform operator, i want to offer offline buildpacks for: - dotnet - r - nginx ### Observed behavior Missing build for these buildpacks see https://github.com/orange-cloudfoundry/ci-buildpack-cached/issues/11 <!-- ### Affected release Reproduced on version x.y --> <!-- specify release note version here --> <!-- ### Traces and logs Remember this is a public repo. DON'T leak credentials or Orange internal URLs. Automation may be applied in the future. * [ ] I have reviewed provided traces against secrets (credentials, internal URLs) that should not be leake, manually of using some tools such as [truffle-hog file:///user/dxa4481/codeprojects/mytraces.txt](https://github.com/dxa4481/truffleHog#truffle-hog) --> "
90474,100556,https://api.github.com/repos/aws-amplify/amplify-ios/issues/1136,bug,2021-04-01T21:37:43Z,NONE,https://api.github.com/repos/aws-amplify/amplify-ios,"Random crashes when doing initial sync using 1.7.1 **Describe the bug** The software crashes with an uncaught exception during initial sync. The point where it crashes appears to be random, but I've yet to complete a single run. So currently it's only the question when it crashes and not if. **To Reproduce** Remove the app from the phone and install from scratch. When opening the app, initial sync starts and eventually crashes. **Expected behavior** I expected to app not to crash. **Screenshots** I've captured 3 crashes. They all appear to happen in `ReconcileAndSaveQueue.addOperation` in the async part. ### Number 1: ![variant_0](https://user-images.githubusercontent.com/67764399/113355953-d6c00d80-9341-11eb-87b0-a5cc25343510.png) The corresponding dump is: ``` 2021-04-01 23:13:23.749777+0200 WhatsLeft[71077:9799898] -[NSIndexPath count]: unrecognized selector sent to instance 0x8000000000000000 2021-04-01 23:13:23.750905+0200 WhatsLeft[71077:9799898] *** Terminating app due to uncaught exception 'NSInvalidArgumentException', reason: '-[NSIndexPath count]: unrecognized selector sent to instance 0x8000000000000000' *** First throw call stack: ( 0 CoreFoundation 0x00007fff20421af6 __exceptionPreprocess + 242 1 libobjc.A.dylib 0x00007fff20177e78 objc_exception_throw + 48 2 CoreFoundation 0x00007fff204306f7 +[NSObject(NSObject) instanceMethodSignatureForSelector:] + 0 3 CoreFoundation 0x00007fff20426036 ___forwarding___ + 1489 4 CoreFoundation 0x00007fff20428068 _CF_forwarding_prep_0 + 120 5 libswiftCore.dylib 0x00007fff2fcde508 $sSD8_VariantVyq_SgxciM + 456 6 libswiftCore.dylib 0x00007fff2fcde2d3 $sSDyq_SgxciM + 131 7 AmplifyPlugins 0x0000000104edd137 $s14AmplifyPlugins21ReconcileAndSaveQueueC12addOperation_9modelNameyAA0cd5LocaleH0C_SStFyycfU_ + 1079 8 AmplifyPlugins 0x0000000104d359d0 $sIeg_IeyB_TR + 48 9 libdispatch.dylib 0x0000000105c117ec _dispatch_call_block_and_release + 12 10 libdispatch.dylib 0x0000000105c129c8 _dispatch_client_callout + 8 11 libdispatch.dylib 0x0000000105c19296 _dispatch_lane_serial_drain + 796 12 libdispatch.dylib 0x0000000105c19f67 _dispatch_lane_invoke + 439 13 libdispatch.dylib 0x0000000105c25de2 _dispatch_workloop_worker_thread + 882 14 libsystem_pthread.dylib 0x00007fff61167499 _pthread_wqthread + 314 15 libsystem_pthread.dylib 0x00007fff61166467 start_wqthread + 15 ) libc++abi.dylib: terminating with uncaught exception of type NSException CoreSimulator 732.18.6 - Device: iPhone 12 (D7A94644-D54D-445B-96AD-C32877B39A92) - Runtime: iOS 14.4 (18D46) - DeviceType: iPhone 12 terminating with uncaught exception of type NSException *** Terminating app due to uncaught exception 'NSInvalidArgumentException', reason: '-[NSIndexPath count]: unrecognized selector sent to instance 0x8000000000000000' (Recorded stack frame) ``` ### Number 2: ![variant_1](https://user-images.githubusercontent.com/67764399/113356086-096a0600-9342-11eb-85e3-93cfe8d2a2b1.png) dump: ``` 2021-04-01 23:16:24.777461+0200 WhatsLeft[71091:9803170] -[__NSCFNumber count]: unrecognized selector sent to instance 0x8000000000000000 2021-04-01 23:16:24.778540+0200 WhatsLeft[71091:9803170] *** Terminating app due to uncaught exception 'NSInvalidArgumentException', reason: '-[__NSCFNumber count]: unrecognized selector sent to instance 0x8000000000000000' *** First throw call stack: ( 0 CoreFoundation 0x00007fff20421af6 __exceptionPreprocess + 242 1 libobjc.A.dylib 0x00007fff20177e78 objc_exception_throw + 48 2 CoreFoundation 0x00007fff204306f7 +[NSObject(NSObject) instanceMethodSignatureForSelector:] + 0 3 CoreFoundation 0x00007fff20426036 ___forwarding___ + 1489 4 CoreFoundation 0x00007fff20428068 _CF_forwarding_prep_0 + 120 5 libswiftCore.dylib 0x00007fff2fcde508 $sSD8_VariantVyq_SgxciM + 456 6 libswiftCore.dylib 0x00007fff2fcde2d3 $sSDyq_SgxciM + 131 7 AmplifyPlugins 0x0000000109c23137 $s14AmplifyPlugins21ReconcileAndSaveQueueC12addOperation_9modelNameyAA0cd5LocaleH0C_SStFyycfU_ + 1079 8 AmplifyPlugins 0x0000000109a7b9d0 $sIeg_IeyB_TR + 48 9 libdispatch.dylib 0x000000010a9577ec _dispatch_call_block_and_release + 12 10 libdispatch.dylib 0x000000010a9589c8 _dispatch_client_callout + 8 11 libdispatch.dylib 0x000000010a95f296 _dispatch_lane_serial_drain + 796 12 libdispatch.dylib 0x000000010a95ff67 _dispatch_lane_invoke + 439 13 libdispatch.dylib 0x000000010a96bde2 _dispatch_workloop_worker_thread + 882 14 libsystem_pthread.dylib 0x00007fff61167499 _pthread_wqthread + 314 15 libsystem_pthread.dylib 0x00007fff61166467 start_wqthread + 15 ) libc++abi.dylib: terminating with uncaught exception of type NSException CoreSimulator 732.18.6 - Device: iPhone 12 (D7A94644-D54D-445B-96AD-C32877B39A92) - Runtime: iOS 14.4 (18D46) - DeviceType: iPhone 12 terminating with uncaught exception of type NSException *** Terminating app due to uncaught exception 'NSInvalidArgumentException', reason: '-[__NSCFNumber count]: unrecognized selector sent to instance 0x8000000000000000' (Recorded stack frame) ``` ### Number 3: ![variant_2](https://user-images.githubusercontent.com/67764399/113356166-26063e00-9342-11eb-829a-645942fff36c.png) dump: ``` 2021-04-01 23:22:06.565112+0200 WhatsLeft[71142:9807755] -[NSIndexPath count]: unrecognized selector sent to instance 0x8000000000000000 2021-04-01 23:22:06.566641+0200 WhatsLeft[71142:9807755] *** Terminating app due to uncaught exception 'NSInvalidArgumentException', reason: '-[NSIndexPath count]: unrecognized selector sent to instance 0x8000000000000000' *** First throw call stack: ( 0 CoreFoundation 0x00007fff20421af6 __exceptionPreprocess + 242 1 libobjc.A.dylib 0x00007fff20177e78 objc_exception_throw + 48 2 CoreFoundation 0x00007fff204306f7 +[NSObject(NSObject) instanceMethodSignatureForSelector:] + 0 3 CoreFoundation 0x00007fff20426036 ___forwarding___ + 1489 4 CoreFoundation 0x00007fff20428068 _CF_forwarding_prep_0 + 120 5 libswiftCore.dylib 0x00007fff2fcde508 $sSD8_VariantVyq_SgxciM + 456 6 libswiftCore.dylib 0x00007fff2fcde2d3 $sSDyq_SgxciM + 131 7 AmplifyPlugins 0x000000010a615691 $s14AmplifyPlugins21ReconcileAndSaveQueueC12addOperation_9modelNameyAA0cd5LocaleH0C_SStFyycfU_y7Combine11SubscribersO10CompletionOy_0A014DataStoreErrorOGcfU_ + 609 8 Combine 0x00007fff4b9f0fab $s7Combine11SubscribersO4SinkC7receive10completionyAC10CompletionOy_q_G_tF + 443 9 Combine 0x00007fff4b9f14f0 $s7Combine11SubscribersO4SinkCy_xq_GAA10SubscriberA2aGP7receive10completionyAC10CompletionOy_7FailureQzG_tFTW + 16 10 Combine 0x00007fff4b9fd30a $s7Combine18PassthroughSubjectC7ConduitC6finish10completionyAA11SubscribersO10CompletionOy_q_G_tF + 506 11 Combine 0x00007fff4b9fe307 $s7Combine18PassthroughSubjectC4send10completionyAA11SubscribersO10CompletionOy_q_G_tFyAA11ConduitBaseCyxq_GXEfU_TA + 23 12 Combine 0x00007fff4ba33d14 $s7Combine11ConduitBaseCyxq_Gs5Error_pIggzo_ADsAE_pIegnzo_sAER_r0_lTRTA + 20 13 libswiftCore.dylib 0x00007fff2fd10fb9 $sSTsE7forEachyyy7ElementQzKXEKF + 377 14 Combine 0x00007fff4ba3370d $s7Combine11ConduitListO7forEachyyyAA0B4BaseCyxq_GKXEKF + 173 15 Combine 0x00007fff4b9fcccb $s7Combine18PassthroughSubjectC4send10completionyAA11SubscribersO10CompletionOy_q_G_tF + 395 16 AmplifyPlugins 0x000000010a60f72d $s14AmplifyPlugins30ReconcileAndLocalSaveOperationC14notifyFinished33_4F53EB7891A305E9B7C11EE1A3424A6DLLyyF + 157 17 AmplifyPlugins 0x000000010a60a677 $s14AmplifyPlugins30ReconcileAndLocalSaveOperationC7respond2toyAC5StateO_tF + 2071 18 AmplifyPlugins 0x000000010a609ba6 $s14AmplifyPlugins30ReconcileAndLocalSaveOperationC11modelSchema11remoteModel14storageAdapter12stateMachineAC0A00kI0V_14AWSPluginsCore12MutationSyncVyAK03AnyK0VGAA013StorageEngineM0_pSgAA05StateO0CyAC0W0OAC6ActionOGSgtcfcyAVcfU_yycfU_ + 70 19 AmplifyPlugins 0x000000010a46d9d0 $sIeg_IeyB_TR + 48 20 libdispatch.dylib 0x000000010b3497ec _dispatch_call_block_and_release + 12 21 libdispatch.dylib 0x000000010b34a9c8 _dispatch_client_callout + 8 22 libdispatch.dylib 0x000000010b351296 _dispatch_lane_serial_drain + 796 23 libdispatch.dylib 0x000000010b351f67 _dispatch_lane_invoke + 439 24 libdispatch.dylib 0x000000010b35dde2 _dispatch_workloop_worker_thread + 882 25 libsystem_pthread.dylib 0x00007fff61167499 _pthread_wqthread + 314 26 libsystem_pthread.dylib 0x00007fff61166467 start_wqthread + 15 ) libc++abi.dylib: terminating with uncaught exception of type NSException CoreSimulator 732.18.6 - Device: iPhone 12 (D7A94644-D54D-445B-96AD-C32877B39A92) - Runtime: iOS 14.4 (18D46) - DeviceType: iPhone 12 terminating with uncaught exception of type NSException *** Terminating app due to uncaught exception 'NSInvalidArgumentException', reason: '-[NSIndexPath count]: unrecognized selector sent to instance 0x8000000000000000' (Recorded stack frame) ``` Notice, that the crash seems to originate from either line 79 or 84, if I interpret this correctly. **Environment(please complete the following information):** - Amplify Framework Version: 1.7.1. - Dependency Manager: Cocoapods - Swift Version: 5, Xcode 12.4 - CLI Version: 4.45.0 - Include any relevant log output under `~/.amplify/logs/amplify-cli-<issue-date>.log`: ``` ~ % cat .amplify/logs/amplify-cli-2021-04-01.log 2021-04-01T21:32:03.158Z|info : amplify version core ``` **Device Information (please complete the following information):** - Device: only tried simulator - iOS Version: 14.4 - Specific to simulators: "
324252,360472,https://api.github.com/repos/substrate-developer-hub/substrate-node-template/issues/144,bug,2021-02-23T17:34:04Z,NONE,https://api.github.com/repos/substrate-developer-hub/substrate-node-template,"Substrate-Node-template Compiling Failure - with Apple M1 Chip, Big Sur 11.2.1 OS **Description** _Tell us what happened. I follow all the steps mentioned on the procedure mentioned at https://substrate.dev/docs/en/tutorials/create-your-first-substrate-chain/setup When executing ""$make build"" on the node template, everything is running fine, excepted for compiling ""librocksdb-sys v6.11.4"". It fails at that step **Steps to Reproduce** _Replace the example steps below with actual steps to reproduce the bug you're reporting._ 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected vs. Actual Behavior** The Node Template should finish compiling without any error. **Environment** _Describe the environment in which you encountered this bug. Use the list below as a starting point and add additional information if you think it's relevant._ - Operating system: Big Sur 11.2.1 with Apple M1 Chip - Template version/tag: 2.0.1 - Rust version (run `rustup show`): Default host: aarch64-apple-darwin rustup home: /Users/lemaimn/.rustup installed toolchains -------------------- stable-aarch64-apple-darwin (default) nightly-aarch64-apple-darwin installed targets for active toolchain -------------------------------------- aarch64-apple-darwin wasm32-unknown-unknown active toolchain ---------------- stable-aarch64-apple-darwin (default) rustc 1.50.0 (cb75ad5db 2021-02-10) **Logs, Errors or Screenshots** .... Compiling jsonrpc-ipc-server v15.1.0 error: failed to run custom build command for `librocksdb-sys v6.11.4` Caused by: process didn't exit successfully: `/Users/lemaimn/Documents/blockchain/devCode/Substrate/myFirstSubstrate3/substrate-node-template/target/release/build/librocksdb-sys-e9a581271a3b2145/build-script-build` (exit code: 101) --- stderr thread 'main' panicked at 'libclang error; possible causes include: - Invalid flag syntax - Unrecognized flags - Invalid flag arguments - File I/O errors - Host vs. target architecture mismatch If you encounter an error missing from this list, please file an issue or a PR!', /Users/lemaimn/.cargo/registry/src/github.com-1ecc6299db9ec823/bindgen-0.54.0/src/ir/context.rs:573:15 note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace warning: build failed, waiting for other jobs to finish... error: build failed make: *** [build] Error 101 **Additional Information** _Please add any other details that you think may help us solve your problem._ "
300631,334243,https://api.github.com/repos/carbon-design-system/carbon-for-ibm-dotcom/issues/4890,bug,2021-01-13T13:21:22Z,NONE,https://api.github.com/repos/carbon-design-system/carbon-for-ibm-dotcom,"Web component: Footer - language selector - Footer region is not present in Web components. Where as footer region is present in React. ## Detailed description Issue: Footer region is not present in Web components. Where as footer region is present in React. Expected: Just like the react Env, Provide the footer section within the footer region for web component as well. ## Additional information "
590672,656415,https://api.github.com/repos/ptarmiganlabs/butler/issues/125,enhancement,2021-02-10T18:38:40Z,COLLABORATOR,https://api.github.com/repos/ptarmiganlabs/butler,"Streamline configuration of user activity reporting to Slack with ditto reporting for Teams **Is your feature request related to a problem? Please describe.** This will be a breaking change in that the config file format changes, but the upside is that configuration of Teams, Slack and email notifications is done in a consistent way. Previously Slack was configured using this YAML: ```yaml slackConfig: enable: false webhookURL: <fill in your web hook URL from Slack> loginNotificationChannel: sense-user-activity # Slack channel to which user activity data is sent taskFailureChannel: sense-task-failure # Slack channel to which task failure notifications are sent taskAbortedChannel: sense-task-aborted # Slack channel to which task stopped notifications are sent ``` That was fine while there was only a limited set of Slack notification options built into Butler. With the coming notification features (i.e. using templates for Slack reload notifications) things are more complex and diverse though. Having the same config syntax for Slack, Teams and email (and possibly other future channels) would be a good thing, even if it's a breaking change. Skip the YAML above and move it to `Butler.slackNotification.userSessionEvents` instead. Teams has the same config layout. "
654138,727126,https://api.github.com/repos/mareinc/mare/issues/661,bug,2021-03-01T21:54:44Z,NONE,https://api.github.com/repos/mareinc/mare,Fix to #637 - Weekend Family Connections Receiving error message when attempting to view Weekend Family Connections as type in Placement Report ![image.png](https://images.zenhubusercontent.com/5abc0adc4b5806bc2bccd5cb/163a8335-83d4-4087-b192-bcc68b7fd38c)
102211,113584,https://api.github.com/repos/appsmithorg/appsmith/issues/2870,bug,2021-02-04T06:47:24Z,CONTRIBUTOR,https://api.github.com/repos/appsmithorg/appsmith,[Bug] Re-sizing the column must be smooth Steps to reproduce: 1) Add a table 2) Navigate to column and try to resize Expectation : It is expected that the column resizing must be smooth Please refer the video https://www.loom.com/share/265f7286ce47426da0a3ff7ca2e8a84b
443493,492991,https://api.github.com/repos/asafnisan/todolist/issues/312,bug,2021-03-26T13:13:21Z,OWNER,https://api.github.com/repos/asafnisan/todolist,"Potential file inclusion via variable CWE-22 KONDUKTO A **medium** severity vulnerability has been discovered in your project. Project Name: **TestIssueCriteria** Scanner Name: **gosec** Cwe ID: **22** Cwe Name: **Improper Limitation of a Pathname to a Restricted Directory (Path Traversal)** Cwe Link: https://cwe.mitre.org/data/definitions/22.html File: services/services.go Line: 113 <details><summary>Code:</summary> <pre> <code> fileContent, err := ioutil.ReadFile(indexPath) </code> </pre> </details> Language: go Tool Description: Potential file inclusion via variable "
676158,751484,https://api.github.com/repos/skirwan/clan-lord-client-issues/issues/101,bug,2020-11-28T07:50:57Z,OWNER,https://api.github.com/repos/skirwan/clan-lord-client-issues,"I am sometimes unable to hear the pine flute when I play it… Largo: I am sometimes unable to hear the pine flute when I play it in a duet, even though my duet partner hears it. Sometimes when bards play a trio with both a flute and a polyphonic instrument like the harp or lyra, all parts play correctly, except in the flute's voice. I noticed this last night with Coriakin's piece especially! It sounds fucking cool 100% of the time to be honest (like I really wish I could have 21 flute voices at once omg), but is kind of a hindrance.<br /><br />https://clieunk.slack.com/archives/C018PCWS9T2/p1603727930074200<br /><br />Geotzou<br /><br />i am not privvy to Clieunk's code, and i am also no bard, so some questions might be dumb... the first question i would have is to establish reproducibility. can you reproduce the behavior 100% of the time you try it in the specific config you saw it happen?<br /><br />Largo<br /><br />It's happened multiple times in multiple settings. It's tricky because bard music - especially trios - is contingent on bards being around. And usually the context isn't 'will you do that three more times for me to see if I can replicate this'. It may be worth getting a few together for exactly that, though! :)<br /><br />I will say that I was using version 21 because I don't check slack much! I will be a better alpha tester from here on out and will inform if the behavior still happens.<br /><br />Soul Hunter<br /><br />Step one is upgrade 9 releases forward <br /><br />Geotzou<br /><br />yeah, agreed, first thing is being up to date, although that may change nothing at all<br /><br />Then the next step is trying to get some kind of reproducibility. Even better, if you can shrink some bard duet and still exhibit the behavior, it would be even better. Like what if you only play 30 notes each? what if the pine flute plays first? what if it starts synchronously? what if pine flute plays last?<br /><br />also i am not entirely clear on the way multiple bards hook a same piece together. but what if the ""initiator"" is the pine flute player? what if he is just the ""follower"" ?<br /><br />also, your comment about polyphonic instruments makes me wonder if enough MIDI channels have been opened to account for all the instruments instead of assuming one channel/instrument or some sort of miscount like that, but this is way above my head already so Skirwan will have to take over tonight."
226798,252231,https://api.github.com/repos/ryichk/react-sandbox/issues/6,enhancement,2021-04-03T12:48:02Z,OWNER,https://api.github.com/repos/ryichk/react-sandbox,Learn TypeScript [TypeScript Documentation](https://www.typescriptlang.org/docs/) [TypeScript Deep Dive - japanese](https://typescript-jp.gitbook.io/deep-dive/) [仕事ですぐに使えるTypeScript](https://future-architect.github.io/typescript-guide) [サバイバルTypeScript](https://book.yyts.org/)
192200,213739,https://api.github.com/repos/cpm-cmake/CPM.cmake/issues/222,bug,2021-02-23T20:07:01Z,NONE,https://api.github.com/repos/cpm-cmake/CPM.cmake,"Parent project options are being cancelled If the parent project has an option that conflicts with the child project, the child project is messing with the scope of the parent project. For instance ```cmake message(""BUILD_EXAMPLES=${BUILD_EXAMPLES}"") CPMAddPackage( NAME pareto GIT_REPOSITORY https://github.com/alandefreitas/pareto.git GIT_TAG v1.2.0 OPTIONS ""BUILD_MATPLOT_TARGETS OFF"" ""BUILD_EXAMPLES OFF"" ) add_executable(spatial_containers spatial_containers.cpp) target_link_libraries(spatial_containers PUBLIC pareto) message(""BUILD_EXAMPLES=${BUILD_EXAMPLES}"") ``` gives me ```cmake BUILD_EXAMPLES=ON -- CPM: adding package pareto@1.2.0 (v1.2.0) -- Looking for min -- Looking for min - not found BUILD_EXAMPLES=OFF ``` which is a problem because some option names are quite common. Some projects create have prefixes in their options but most projects don't. Of course, people can manually do ```cmake set(BUILD_EXAMPLES_PREV ${BUILD_EXAMPLES}) message(""BUILD_EXAMPLES=${BUILD_EXAMPLES}"") CPMAddPackage( NAME pareto GIT_REPOSITORY https://github.com/alandefreitas/pareto.git GIT_TAG v1.2.0 OPTIONS ""BUILD_EXAMPLES OFF"" ) add_executable(spatial_containers spatial_containers.cpp) target_link_libraries(spatial_containers PUBLIC pareto) set(BUILD_EXAMPLES ${BUILD_EXAMPLES_PREV} CACHE BOOL """" FORCE) message(""BUILD_EXAMPLES=${BUILD_EXAMPLES}"") ``` for all options but that defeats the purpose of the OPTIONS arguments, which is to do what we cannot already do with FetchContent."
366759,407710,https://api.github.com/repos/DankMemer/dank-memer-suggestions-and-bugs/issues/1107,bug,2020-07-21T13:34:56Z,NONE,https://api.github.com/repos/DankMemer/dank-memer-suggestions-and-bugs,"Cheese XP Loss/Bank Balance If you have a full bank (or almost full), and you happen to use cheese but get the lactose intolerance effect, your bank balance will decrease along with your XP. With a full bank, this may leave you with more bank balance than the bank should be able to hold. ![DM_Bug](https://user-images.githubusercontent.com/54752853/88061383-0b31c780-cb2d-11ea-9879-75a10e4c6099.jpg) "
166608,185260,https://api.github.com/repos/sp614x/optifine/issues/5034,bug,2020-11-15T02:45:20Z,NONE,https://api.github.com/repos/sp614x/optifine,"[1.8.x] Optfine's fullscreen not working in Mac's New Update (Big Sur) <img width=""854"" alt=""Screen Shot 2020-11-15 at 1 25 15 pm"" src=""https://user-images.githubusercontent.com/74478364/99161768-9290ef80-2749-11eb-9d02-691f4aaa0a66.png""> When going into fullscreen on Optifine (this doesn't happen in vanilla Minecraft) it will give you a completely blank white screen (Not Mac's native fullscreen setting, Optifine's fullscreen. Accessible by going to Settings > Video > Other > Fullscreen.) Although it is still playable without using Optfine's fullscreen I get worse fps and since I use a different resolution my GUI scale is messed up. As far as I know this bug effects 1.7 - 1.8 Optifine. It may affect other versions but I have not tested it. Before the Big Sur update on Mac, it would work perfectly fine. To get to this bug you have to be on Mac (I assume it doesn't affect windows, but I don't know) and go into Optifine fullscreen. By going to Settings > Video > Other > Fullscreen. The versions I've tried are 1.7 and 1.8, but it most likely affects other versions. I've used it with Lunar Client (which has Optifine preinstalled), Badlion Client (which has Optifine preinstalled), and on the default Minecraft launcher. It is preinstalled on Lunar Client and Badlion Client and on the default Minecraft launcher I put Optifine 1.8 L5 in the mods folder. I used the forge version. The only mods I used were Lunar Client and Badlion Client. And when I used it on the default Minecraft there were no other mods. The game did not crash it just would stay on the white screen forever until I closed it. I can not get on the debug menu. It doesn't happen in vanilla Minecraft. It made no difference if I used mods (I only used Lunar Client and Badlion Client) Since Fabric is not available in 1.7 or 1.8 I do not know if it still happens on Fabric. But I assume it does because this doesn't happen on vanilla which makes it seem like it is something in Optifine. "
395249,439318,https://api.github.com/repos/neo4j/neo4j/issues/12682,bug,2021-02-27T23:17:32Z,NONE,https://api.github.com/repos/neo4j/neo4j,"failing query I discovered a cypher query that fails in Neo4j versions 4.2.x, and runs in Neo4j versions 4.1.x Neo4j Version: 4.2.3 Operating System: Windows 10 API: Cypher ## Steps to reproduce 1. create 2 nodes `CREATE (:person)-[:knows]->(:person)` 2. execute the following query ``` MATCH (x) CALL { WITH x RETURN x AS y } WITH y AS z CALL { WITH z RETURN z AS w UNION WITH z MATCH (z)-[]->(w) RETURN w } RETURN w ``` ## Expected behavior the query should return a result ## Actual behavior The query fails with `ERROR: Neo.DatabaseError.Statement.ExecutionFailed`"
699094,776988,https://api.github.com/repos/AnaMoros/Weather-Project/issues/1,enhancement,2021-04-30T12:34:19Z,OWNER,https://api.github.com/repos/AnaMoros/Weather-Project,UV Index find the right weather API to receive uv index data 
700868,778956,https://api.github.com/repos/alpheios-project/alignment-editor-new/issues/371,enhancement,2021-05-09T06:42:01Z,MEMBER,https://api.github.com/repos/alpheios-project/alignment-editor-new,Update language summary modal window From online meeting with @abrasax Add check - if a text is TEI format Show what texts are already tokenized
255036,283664,https://api.github.com/repos/Grafikart/Grafikart.fr/issues/183,bug,2021-01-11T21:26:54Z,NONE,https://api.github.com/repos/Grafikart/Grafikart.fr,"[BETA] Marquage comme lus Le bouton ""Marquer tous comme lus"" sur /forum ne marche pas et essai d'appeler https://beta.grafikart.fr/[object%20MouseEvent] cf video https://user-images.githubusercontent.com/25200594/104240273-17ec0400-545c-11eb-8353-a0b9f311999a.mp4 "
111654,124102,https://api.github.com/repos/pmulholland42/spacecraft-map/issues/26,enhancement,2020-12-30T20:42:08Z,OWNER,https://api.github.com/repos/pmulholland42/spacecraft-map,"Add labels Objects (planets, moons, etc.) should be labeled on the map with their name. This should be toggleable via the setting. They should also not appear when they would be in the way of other things, or when the object is too small. Still need to work out the details of how that should work."
522196,580368,https://api.github.com/repos/MaxKeppeler/bottom-sheets/issues/23,bug,2021-01-01T18:19:34Z,NONE,https://api.github.com/repos/MaxKeppeler/bottom-sheets,"Color Sheet disableSwitchColorView icon remains **Describe the bug** On the color sheet, `disableSwitchColorView()` disables the ability to switch to the custom color view. However, the icon still remains - it just doesn't do anything. **Library Version:** 1.1.0 **To Reproduce** Steps to reproduce the behavior: 1. Add `disableSwitchColorView()` to the code 2. The icon to switch the color view remains **Expected behavior** The icon should go away if `disableSwitchColorView()` is enabled. **Screenshots** I've attached a video showing this bug in the sample app [Sample app](https://user-images.githubusercontent.com/74878137/103444136-90cdad80-4c5d-11eb-961e-3af6a62ea061.mp4) "
488305,542695,https://api.github.com/repos/dansomething/coc-java-debug/issues/16,question,2020-12-15T00:34:19Z,NONE,https://api.github.com/repos/dansomething/coc-java-debug,"Multiple Vimspector debugging sessions at the same time? I'm using coc-java-debug under NeoVim 0.4.4. Now I'd like to debug a few applications at the same time since they communicate with each other via API requests and/or queues. However it seems at the moment if I launch a new debugging session via `CocCommand java.debug.vimspector.start`, it replaces the existing one instead of starting a new one. Is it possible to have multiple debugging sessions at the same time?"
712189,791535,https://api.github.com/repos/elabftw/elabftw/issues/2647,bug,2021-05-06T10:47:15Z,NONE,https://api.github.com/repos/elabftw/elabftw,"admin and sysadmin panel isn't accessible after update to version 4.0.0 # Question / free support Hey guys, I just updated my elabftw from 3.6.7 to 4.0.0. It's running on 4.0.0 now, and I everything seems to be fine. However, when I check the admin or sysadmin panel only an empty page is displayed. Cleaning cache, or changing broswer didn't solve it... I do run my elabftw via DigitalOcean in a Droplet with Docker and access it via a domain. Any clues what could trigger this? By switching broswer from Firefox to Chrome I get at least an error message ""This page isn’t working. XXXXXX is currently unable to handle this request. HTTP ERROR 500"". As we already discussed on Gitter I attached the logs from elabftw. Further I added the content of the .php file. However, I wasn't sure if you relate to line 388 of the code or to your commented line 388. In the attached php_log.txt both ranges of the code are copied. [logs_bwiebeer.txt](https://github.com/elabftw/elabftw/files/6433815/logs_bwiebeer.txt) [php_log.txt](https://github.com/elabftw/elabftw/files/6433812/php_log.txt) "
418958,465721,https://api.github.com/repos/italia/guida-sviluppo-gestione-software-libero/issues/7,enhancement,2020-12-30T09:17:21Z,MEMBER,https://api.github.com/repos/italia/guida-sviluppo-gestione-software-libero,Consider adding CODE_OF_CONDUCT A code of conduct section should be included in the guide so that: a) readers know what that is all about; b) readers may consider adopting one in their repo.
291855,324549,https://api.github.com/repos/glushchenko/fsnotes/issues/981,bug,2020-09-14T10:54:25Z,COLLABORATOR,https://api.github.com/repos/glushchenko/fsnotes,Crash when app in background <!-- NOTE: ignoring this template will lead to your issue being dealt with more slowly --> **Describe the bug** App was just running in background. **Supporting Files** [FSNotes_2020-09-14-115121_matt.crash.zip](https://github.com/glushchenko/fsnotes/files/5217949/FSNotes_2020-09-14-115121_matt.crash.zip) https://pastebin.com/raw/sQm0Pz55 **Desktop (please complete the following information):** - OS: macOS - OS version: 10.14.6 - FSNotes version: 4.6.2 
107179,119119,https://api.github.com/repos/Emersont1/big-finish-downloader/issues/18,enhancement,2021-01-18T10:14:19Z,OWNER,https://api.github.com/repos/Emersont1/big-finish-downloader,"Make it close more cleanly currently it aborts when it closes, i think i need to rearrange the destructor order"
440284,489472,https://api.github.com/repos/vladmandic/human/issues/56,bug,2021-01-05T18:30:05Z,NONE,https://api.github.com/repos/vladmandic/human,"Cannot use mesh model without enabling iris model I get an exception when I call warmup(""full""). It works if I enabled the iris model. Unhandled Rejection (TypeError): Cannot read property '0' of undefined Human.detectFace src/human.js:310 307 | 308 | // calculate iris distance 309 | // iris: array[ center, left, top, right, bottom] > 310 | const irisSize = (face.annotations.leftEyeIris && face.annotations.rightEyeIris) | ^ 311 | /* average human iris size is 11.7mm */ 312 | ? 11.7 * Math.max(Math.abs(face.annotations.leftEyeIris[3][0] - face.annotations.leftEyeIris[1][0]), Math.abs(face.annotations.rightEyeIris[4][1] - face.annotations.rightEyeIris[2][1])) 313 | : 0; View compiled async src/human.js:392 389 | resolve({ error: 'could not convert input to tensor' }); 390 | return; 391 | } > 392 | this.perf.image = Math.trunc(now() - timeStamp); | ^ 393 | this.analyze('Get Image:'); 394 | 395 | // run face detection followed by all models that rely on face bounding box: face mesh, age, gender, emotion "
410186,455931,https://api.github.com/repos/xgcm/xgcm/issues/246,bug,2020-09-28T14:45:14Z,NONE,https://api.github.com/repos/xgcm/xgcm,"Relative vorticity plot in example_MOM6.ipynb displayed wrongly [BUG] **What happened**: Here is what I get when trying to run ``example_MOM6.ipynb`` with the lates `xgcm` (note parallel lines in the North). Might well be not related to ``xgcm`` but to cartopy or matplotlib. ![image](https://user-images.githubusercontent.com/3407313/94446423-ebf88b80-01a8-11eb-8060-31b3f3e5dea3.png) **What you expected to happen**: ![image](https://user-images.githubusercontent.com/3407313/94446468-f9157a80-01a8-11eb-867a-22e62dab517c.png) **xgcm version and environment**: <details> <!-- To get the version number of xgcm do `import xgcm; print(xgcm.__version__)`--> 0.4.0 , but I am at commit e0eae1e0e Probably also most relevant. I guess: ``cartopy==0.18.0``, ``matplotlib==3.3.2``. <!-- Paste the output of `conda list` from your shell here. --> ``` appnope 0.1.0 py36h9f0ad1d_1001 conda-forge argon2-cffi 20.1.0 py36h9de38fb_1 conda-forge async_generator 1.10 py_0 conda-forge attrs 20.2.0 pyh9f0ad1d_0 conda-forge backports 1.0 py_2 conda-forge backports.functools_lru_cache 1.6.1 py_0 conda-forge beautifulsoup4 4.9.2 pypi_0 pypi bleach 3.2.1 pyh9f0ad1d_0 conda-forge bokeh 2.2.1 py36h9f0ad1d_0 conda-forge boost-cpp 1.74.0 he5d75e3_0 conda-forge brotlipy 0.7.0 py36h9de38fb_1000 conda-forge bzip2 1.0.8 haf1e3a3_3 conda-forge c-ares 1.16.1 haf1e3a3_3 conda-forge ca-certificates 2020.6.20 hecda079_0 conda-forge cairo 1.16.0 ha8983da_1005 conda-forge cartopy 0.18.0 py36heb902f8_2 conda-forge certifi 2020.6.20 py36h9f0ad1d_0 conda-forge cffi 1.14.3 py36h6a9c9ac_0 conda-forge cfitsio 3.470 hdf94aef_6 conda-forge cftime 1.2.1 pypi_0 pypi chardet 3.0.4 py36h9f0ad1d_1007 conda-forge click 7.1.2 pyh9f0ad1d_0 conda-forge cloudpickle 1.6.0 py_0 conda-forge contextvars 2.4 py_0 conda-forge cryptography 3.1.1 py36h54f4bc5_0 conda-forge curl 7.71.1 hcb81553_6 conda-forge cycler 0.10.0 py_2 conda-forge cytoolz 0.11.0 py36h9de38fb_0 conda-forge dask 2.28.0 py_0 conda-forge dask-core 2.28.0 py_0 conda-forge dbus 1.13.6 h2f22bb5_0 conda-forge decorator 4.4.2 py_0 conda-forge defusedxml 0.6.0 py_0 conda-forge distributed 2.28.0 py36h9f0ad1d_0 conda-forge docopt 0.6.2 pypi_0 pypi docrep 0.2.7 py_0 conda-forge entrypoints 0.3 py36h9f0ad1d_1001 conda-forge expat 2.2.9 hb1e8313_2 conda-forge fontconfig 2.13.1 h79c0d67_1002 conda-forge freetype 2.10.2 h8da9a1a_0 conda-forge freexl 1.0.5 h0b31af3_1002 conda-forge fsspec 0.8.3 py_0 conda-forge future 0.18.2 py36h9f0ad1d_1 conda-forge gdal 3.1.2 py36h060f065_1 conda-forge geos 3.8.1 h4a8c4bd_0 conda-forge geotiff 1.6.0 h4e9c399_1 conda-forge gettext 0.19.8.1 h46ab8bc_1002 conda-forge giflib 5.2.1 h0b31af3_2 conda-forge glib 2.66.0 hdb5fb44_0 conda-forge hdf4 4.2.13 h84186c3_1003 conda-forge hdf5 1.10.6 nompi_haae91d6_101 conda-forge heapdict 1.0.1 py_0 conda-forge icu 67.1 hb1e8313_0 conda-forge idna 2.10 pyh9f0ad1d_0 conda-forge immutables 0.14 py36h37b9a7d_0 conda-forge importlib-metadata 2.0.0 py36h9f0ad1d_0 conda-forge importlib_metadata 2.0.0 0 conda-forge ipykernel 5.3.4 py36h95af2a2_0 conda-forge ipython 5.8.0 py36_1 conda-forge ipython_genutils 0.2.0 py_1 conda-forge ipywidgets 7.5.1 pyh9f0ad1d_1 conda-forge jinja2 2.11.2 pyh9f0ad1d_0 conda-forge jpeg 9d h0b31af3_0 conda-forge json-c 0.13.1 h575e443_1002 conda-forge jsonschema 3.2.0 py36h9f0ad1d_1 conda-forge jupyter 1.0.0 py_2 conda-forge jupyter_client 6.1.7 py_0 conda-forge jupyter_console 5.2.0 py36_1 conda-forge jupyter_core 4.6.3 py36h9f0ad1d_1 conda-forge jupyterlab_pygments 0.1.1 pyh9f0ad1d_0 conda-forge kealib 1.4.13 h40102fb_1 conda-forge kiwisolver 1.2.0 py36h863e41a_0 conda-forge krb5 1.17.1 h75d18d8_3 conda-forge lcms2 2.11 h174193d_0 conda-forge libblas 3.8.0 17_openblas conda-forge libcblas 3.8.0 17_openblas conda-forge libclang 10.0.1 default_hf57f61e_1 conda-forge libcurl 7.71.1 h9bf37e3_6 conda-forge libcxx 10.0.1 h5f48129_0 conda-forge libdap4 3.20.6 h993cace_1 conda-forge libedit 3.1.20191231 h0678c8f_2 conda-forge libev 4.33 haf1e3a3_1 conda-forge libffi 3.2.1 hb1e8313_1007 conda-forge libgdal 3.1.2 h6dfbaa8_1 conda-forge libgfortran 4.0.0 h2d743fc_11 conda-forge libgfortran4 7.5.0 h2d743fc_11 conda-forge libiconv 1.16 haf1e3a3_0 conda-forge libkml 1.3.0 h8ca2c65_1012 conda-forge liblapack 3.8.0 17_openblas conda-forge libllvm10 10.0.1 h009f743_3 conda-forge libnetcdf 4.7.4 nompi_hc5b2cf3_105 conda-forge libnghttp2 1.41.0 h7580e61_2 conda-forge libopenblas 0.3.10 openmp_h63d9170_4 conda-forge libpng 1.6.37 hb0a8c7a_2 conda-forge libpq 12.3 h489d428_0 conda-forge libsodium 1.0.18 haf1e3a3_1 conda-forge libspatialite 4.3.0a h231dce8_1039 conda-forge libssh2 1.9.0 h8a08a2b_5 conda-forge libtiff 4.1.0 h2ae36a8_6 conda-forge libwebp-base 1.1.0 h0b31af3_3 conda-forge libxml2 2.9.10 h2c6e4a5_2 conda-forge llvm-openmp 10.0.1 h28b9765_0 conda-forge locket 0.2.0 py_2 conda-forge lz4-c 1.9.2 hb1e8313_3 conda-forge markupsafe 1.1.1 py36h9de38fb_1 conda-forge matplotlib-base 3.3.2 py36h534ab7b_0 conda-forge mistune 0.8.4 py36h37b9a7d_1001 conda-forge msgpack-python 1.0.0 py36h863e41a_1 conda-forge mysql-common 8.0.21 2 conda-forge mysql-libs 8.0.21 hfb8f7af_2 conda-forge nbclient 0.5.0 py_0 conda-forge nbconvert 6.0.6 py36h9f0ad1d_0 conda-forge nbformat 5.0.7 py_0 conda-forge ncurses 6.2 hb1e8313_1 conda-forge nest-asyncio 1.4.0 py_1 conda-forge netcdf4 1.5.4 pypi_0 pypi notebook 6.1.4 py36h9f0ad1d_0 conda-forge nspr 4.20 h0a44026_1000 conda-forge nss 3.47 hc0980d9_0 conda-forge numpy 1.19.1 py36h2fc57d0_2 conda-forge olefile 0.46 py_0 conda-forge openjpeg 2.3.1 h254dc36_3 conda-forge openssl 1.1.1h haf1e3a3_0 conda-forge owslib 0.20.0 py_0 conda-forge packaging 20.4 pyh9f0ad1d_0 conda-forge pandas 1.1.2 py36h27176af_0 conda-forge pandoc 2.10.1 haf1e3a3_0 conda-forge pandocfilters 1.4.2 py_1 conda-forge partd 1.1.0 py_0 conda-forge pcre 8.44 h4a8c4bd_0 conda-forge pexpect 4.8.0 py36h9f0ad1d_1 conda-forge pickleshare 0.7.5 py36h9f0ad1d_1001 conda-forge pillow 7.2.0 py36h2ae5dfa_1 conda-forge pip 20.2.3 py_0 conda-forge pixman 0.38.0 h01d97ff_1003 conda-forge poppler 0.89.0 h3232a60_1 conda-forge poppler-data 0.4.9 1 conda-forge postgresql 12.3 h62ab893_0 conda-forge proj 7.1.0 h45baca5_1 conda-forge prometheus_client 0.8.0 pyh9f0ad1d_0 conda-forge prompt_toolkit 1.0.15 py_1 conda-forge psutil 5.7.2 py36h9de38fb_0 conda-forge ptyprocess 0.6.0 py_1001 conda-forge pycparser 2.20 pyh9f0ad1d_2 conda-forge pydap 3.2.2 pypi_0 pypi pyepsg 0.4.0 py_0 conda-forge pygments 2.7.1 py_0 conda-forge pyopenssl 19.1.0 py_1 conda-forge pyparsing 2.4.7 pyh9f0ad1d_0 conda-forge pyproj 2.6.1.post1 py36hbb77884_1 conda-forge pyqt 5.12.3 py36haa9e2f4_3 conda-forge pyqt5-sip 4.19.18 pypi_0 pypi pyqtchart 5.12 pypi_0 pypi pyqtwebengine 5.12.1 pypi_0 pypi pyrsistent 0.17.3 py36h9de38fb_0 conda-forge pyshp 2.1.2 pyh9f0ad1d_0 conda-forge pysocks 1.7.1 py36h9f0ad1d_1 conda-forge python 3.6.11 hc38f9c5_2_cpython conda-forge python-dateutil 2.8.1 py_0 conda-forge python_abi 3.6 1_cp36m conda-forge pytz 2020.1 pyh9f0ad1d_0 conda-forge pyyaml 5.3.1 py36h9de38fb_0 conda-forge pyzmq 19.0.2 py36hd529914_0 conda-forge qt 5.12.9 h717870c_0 conda-forge qtconsole 4.7.7 pyh9f0ad1d_0 conda-forge qtpy 1.9.0 py_0 conda-forge readline 8.0 h0678c8f_2 conda-forge requests 2.24.0 pyh9f0ad1d_0 conda-forge scipy 1.5.2 py36h01b1e2b_0 conda-forge send2trash 1.5.0 py_0 conda-forge setuptools 49.6.0 py36h9f0ad1d_1 conda-forge shapely 1.7.1 py36h1e0b1ed_0 conda-forge simplegeneric 0.8.1 py_1 conda-forge six 1.15.0 pyh9f0ad1d_0 conda-forge sortedcontainers 2.2.2 pyh9f0ad1d_0 conda-forge soupsieve 2.0.1 pypi_0 pypi sqlite 3.33.0 h960bd1c_0 conda-forge tbb 2019.9 ha1b3eb9_1 conda-forge tblib 1.6.0 py_0 conda-forge terminado 0.9.1 py36h9f0ad1d_0 conda-forge testpath 0.4.4 py_0 conda-forge tiledb 2.0.8 h8973ade_1 conda-forge tk 8.6.10 hb0a8c7a_0 conda-forge toolz 0.11.1 py_0 conda-forge tornado 6.0.4 py36h37b9a7d_1 conda-forge traitlets 4.3.3 py36h9f0ad1d_1 conda-forge typing_extensions 3.7.4.2 py_0 conda-forge tzcode 2020a h0b31af3_0 conda-forge urllib3 1.25.10 py_0 conda-forge wcwidth 0.2.5 pyh9f0ad1d_2 conda-forge webencodings 0.5.1 py_1 conda-forge webob 1.8.6 pypi_0 pypi wheel 0.35.1 pyh9f0ad1d_0 conda-forge widgetsnbextension 3.5.1 py36h9f0ad1d_1 conda-forge xarray 0.16.1 py_0 conda-forge xerces-c 3.2.3 h0a0444a_1 conda-forge xgcm 0.4.0 pypi_0 pypi xz 5.2.5 haf1e3a3_1 conda-forge yaml 0.2.5 haf1e3a3_0 conda-forge zeromq 4.3.2 h4a8c4bd_3 conda-forge zict 2.0.0 py_0 conda-forge zipp 3.2.0 py_0 conda-forge zlib 1.2.11 h7795811_1009 conda-forge zstd 1.4.5 h289c70a_2 conda-forge ``` </details> "
406311,451626,https://api.github.com/repos/sparkfun/Arduino_Apollo3/issues/290,bug,2020-10-19T09:10:18Z,NONE,https://api.github.com/repos/sparkfun/Arduino_Apollo3,"Same MAC address for two Artemis Thing Plus Hi, I don't know if you can help me with this problem, but I try anyway :) I have to use two Artemis Thing Plus in my BLE system. The problem is that the MAC address they expose is the same, so I can't connect to both at the same time. Does anyone have any idea if it is possible to change the MAC address? Thanks a lot to anyone who will answer."
4692,5225,https://api.github.com/repos/Hyperconix/MVCExample/issues/2,enhancement,2021-02-17T14:11:47Z,COLLABORATOR,https://api.github.com/repos/Hyperconix/MVCExample,"Modifying View 3 and 4 Following the example code in View1, modify View3 and View4 to properly partake in the subscribe/notify protocol with the model: They need to implement the Observer interface; they need to subscribe to the model, and their updatemethods should have method headers compatible with the Observer interface. At the same time, you can comment out from Controller2 everything to do with the ""Refresh views"" button, as it will become redundant."
547951,609029,https://api.github.com/repos/ahammadshawki8/PostgreSQL-For-Absolute-Beginners/issues/1,enhancement,2021-03-03T01:57:07Z,OWNER,https://api.github.com/repos/ahammadshawki8/PostgreSQL-For-Absolute-Beginners,"Go through the entire repo and solved spelling mistakes I figured out that there are a few spelling mistakes remaining in different parts of this repo. It happened because of fast typing. So, if anyone is new to PostgreSQL or wants to revise the basics of PostgreSQL, then they can help me solve the spelling mistakes in the code comments when they are going through each and every file. It will be really helpful. Also please make sure that while you are going through the scripts and changing spellings, you can add/remove spacings to make the scripts visually attractive/readable."
516959,574503,https://api.github.com/repos/FabricMC/Enigma/issues/210,bug,2020-04-04T15:37:14Z,MEMBER,https://api.github.com/repos/FabricMC/Enigma,Closing mappings doesn't remove javadocs from the current view Possibly related to #190. Example: (everything here was mapped before) ![](https://user-images.githubusercontent.com/6596629/78454846-4655db00-76a3-11ea-9d7b-04dd14f0aef2.png)
173307,192703,https://api.github.com/repos/newrelic/docs-website/issues/483,enhancement,2020-12-28T16:34:23Z,CONTRIBUTOR,https://api.github.com/repos/newrelic/docs-website,"Build index, 404 pages, attribute dictionary for Japanese site ## Summary We need to build our pages (under the `/pages` directory) for /jp sub-url. We can do this either by an existing plugin ([`gatsby-plugin-intl`](https://www.gatsbyjs.com/plugins/gatsby-plugin-intl/) ) or by building our own plugin to build these pages. (I'd recommend the former). This is just getting the pages to build with the jp suburl, internationalizing the content is in a different PR. ## AC * [ ] pages build for japanese and english url"
95372,106005,https://api.github.com/repos/infinum/eightshift-boilerplate/issues/224,enhancement,2020-11-13T15:40:54Z,CONTRIBUTOR,https://api.github.com/repos/infinum/eightshift-boilerplate,"Add generator for privacy data handling In order to be GDPR compliant, we could add a generator for a class / page that handles user data deletion on request. Reference: https://github.com/dingo-d/woo-solo-api/blob/feature/2.0.0-update/src/Privacy/DataHandling.php"
341312,379424,https://api.github.com/repos/kyma-project/control-plane/issues/216,enhancement,2020-09-21T12:58:38Z,MEMBER,https://api.github.com/repos/kyma-project/control-plane,"Reuse common clients' logic in control-plane <!-- Thank you for your contribution. Before you submit the issue: 1. Search open and closed issues for duplicates. 2. Read the contributing guidelines. --> **Description** In control-plane we use many clients for internal services, mostly in case of testing those dependencies. Having those in `internal` directory prevents from importing the clients in `tests` directory. This was part of investigation in [#1303](https://github.com/kyma-incubator/compass/issues/1303) and partially fixed from KEB perspective in #204 . Next step would be to unify rest of the duplicated clients code in control-plane repository and move the common package to the root directory, like we have in [kyma-project/kyma](https://github.com/kyma-project/kyma/tree/master/common): ``` . ├── common │   ├── director │   │   ├── client.go │   ├── gardener │   ├── hyperscaler │   ├── provisioner │   ├── other-code-shared-between-tests-and-components ├── components │   ├── kubeconfig-service │   ├── kyma-environment-broker │   ├── metris │   ├── provisioner │   └── schema-migrator ├── docs ├── installation ├── resources ├── scripts ├── tests └── tools ``` Therefore, all teams involved in `control-plane` development should be marked as CODEOWNERS of this directory. <!-- Provide a clear and concise description of the feature. --> At the moment, those are places where somehow duplicated code was found: - [ ] [`control-plane/tests/provisioner-tests/test/testkit`](https://github.com/kyma-project/control-plane/tree/master/tests/provisioner-tests/test/testkit) - framefrog, @janmedrek - [ ] [`control-plane/tests/e2e/provisioning/internal/hyperscaler/azure`](https://github.com/kyma-project/control-plane/tree/master/tests/e2e/provisioning/internal/hyperscaler/azure) - skydivingtunas, @anishj0shi **Reasons** Refactoring these parts will result in cleaner code without unnecessary code duplication. <!-- Explain why we should add this feature. Provide use cases to illustrate its benefits. --> **Attachments** <!-- Attach any files, links, code samples, or screenshots that will convince us to your idea. --> "
49886,55513,https://api.github.com/repos/adoptium/temurin-build/issues/2583,bug,2021-04-16T20:30:32Z,CONTRIBUTOR,https://api.github.com/repos/adoptium/temurin-build,"Smoke test javaVendorVersion failed with jdk8 Smoke test javaVendorVersion failed with jdk8 as no system property `java.vendor.version` ``` 14:35:52 at net.adoptopenjdk.test.VendorPropertiesTest$AdoptOpenJDKPropertiesChecks.javaVendorVersion(VendorPropertiesTest.java:162) 14:35:52 at net.adoptopenjdk.test.VendorPropertiesTest.vmPropertiesPointToVendor(VendorPropertiesTest.java:84) 14:35:52 at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ``` https://ci.adoptopenjdk.net/job/build-scripts/job/jobs/job/jdk8u/job/jdk8u-linux-x64-hotspot_SmokeTests/5/console Test check javaVendorVersion by `System.getProperty(""java.vendor.version"")` . #2544 add meta data to java.vendor.version for jdk11+. Should jdk8 have system property `java.vendor.version`? Could someone please confirm this? If not we will need to limit tests to jdk11+. Otherwise this need to be fixed. "
236281,262801,https://api.github.com/repos/jellyfin/jellyfin/issues/4957,bug,2021-01-05T07:44:23Z,NONE,https://api.github.com/repos/jellyfin/jellyfin,"Some files arent playable after updating git-version from 2020-12-31 to 2021-01-04 And again me (im sorry ;-) ) wanted to watch my series yesterday and couldnt play it. Trying to play some other files and they where playing as expected. The only thing i did was updating the jellyfin-git-version i was using this morning. So with the git version from 2021-01-04 i get the shown errormessage when i play the files. **-> Resolution: Downgrade to the git version from 2020-12-31 and the files are played correctly.** So something happened in these 4 days brakes the possibility to play these files. ``` [2021-01-04 22:16:03.470 +01:00] [ERR] Error processing request. URL ""GET"" ""/Users/c507141120344f8eb8b72f6dafbd0272/Items/dc7a7c033cd3a42f3ea4b27d1a4eb39e"". SysteObject reference not set to an instance of an objectm.NullReferenceException: Object reference not set to an instance of an object. at Emby.Server.Implementations.Dto.DtoService.AttachPeople(BaseItemDto dto, BaseItem item) at Emby.Server.Implementations.Dto.DtoService.GetBaseItemDtoInternal(BaseItem item, DtoOptions options, User user, BaseItem owner) at Emby.Server.Implementations.Dto.DtoService.GetBaseItemDto(BaseItem item, DtoOptions options, User user, BaseItem owner) at Jellyfin.Api.Controllers.UserLibraryController.GetItem(Guid userId, Guid itemId) at lambda_method807(Closure , Object ) at Microsoft.AspNetCore.Mvc.Infrastructure.ActionMethodExecutor.AwaitableObjectResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, Object controller, Object[] arguments) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeActionMethodAsync>g__Awaited|12_0(ControllerActionInvoker invoker, ValueTask`1 actionResultValueTask) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.<InvokeNextActionFilterAsync>g__Awaited|10_0(ControllerActionInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Rethrow(ActionExecutedContextSealed context) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.InvokeInnerFilterAsync() --- End of stack trace from previous location --- at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeNextResourceFilter>g__Awaited|24_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.Rethrow(ResourceExecutedContextSealed context) at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.InvokeFilterPipelineAsync() --- End of stack trace from previous location --- at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeAsync>g__Awaited|17_0(ResourceInvoker invoker, Task task, IDisposable scope) at Microsoft.AspNetCore.Routing.EndpointMiddleware.<Invoke>g__AwaitRequestTask|6_0(Endpoint endpoint, Task requestTask, ILogger logger) at Jellyfin.Server.Middleware.ServerStartupMessageMiddleware.Invoke(HttpContext httpContext, IServerApplicationHost serverApplicationHost, ILocalizationManager localizationManager) at Jellyfin.Server.Middleware.WebSocketHandlerMiddleware.Invoke(HttpContext httpContext, IWebSocketManager webSocketManager) at Jellyfin.Server.Middleware.IpBasedAccessValidationMiddleware.Invoke(HttpContext httpContext, INetworkManager networkManager, IServerConfigurationManager serverConfigurationManager) at Jellyfin.Server.Middleware.LanFilteringMiddleware.Invoke(HttpContext httpContext, INetworkManager networkManager, IServerConfigurationManager serverConfigurationManager) at Microsoft.AspNetCore.Authorization.Policy.AuthorizationMiddlewareResultHandler.HandleAsync(RequestDelegate next, HttpContext context, AuthorizationPolicy policy, PolicyAuthorizationResult authorizeResult) at Microsoft.AspNetCore.Authorization.AuthorizationMiddleware.Invoke(HttpContext context) at Swashbuckle.AspNetCore.ReDoc.ReDocMiddleware.Invoke(HttpContext httpContext) at Swashbuckle.AspNetCore.SwaggerUI.SwaggerUIMiddleware.Invoke(HttpContext httpContext) at Swashbuckle.AspNetCore.Swagger.SwaggerMiddleware.Invoke(HttpContext httpContext, ISwaggerProvider swaggerProvider) at Microsoft.AspNetCore.Authentication.AuthenticationMiddleware.Invoke(HttpContext context) at Jellyfin.Server.Middleware.RobotsRedirectionMiddleware.Invoke(HttpContext httpContext) at Jellyfin.Server.Middleware.LegacyEmbyRouteRewriteMiddleware.Invoke(HttpContext httpContext) at Microsoft.AspNetCore.ResponseCompression.ResponseCompressionMiddleware.Invoke(HttpContext context) at Jellyfin.Server.Middleware.ResponseTimeMiddleware.Invoke(HttpContext context) at Jellyfin.Server.Middleware.ExceptionMiddleware.Invoke(HttpContext context) ```"
641759,713281,https://api.github.com/repos/ata4/angrylion-rdp-plus/issues/12,bug,2017-09-09T20:32:21Z,NONE,https://api.github.com/repos/ata4/angrylion-rdp-plus,Conkers Bad Fur Day Dynamic Shadows are broken with AL+ 
80025,88964,https://api.github.com/repos/appsmithorg/appsmith/issues/1228,enhancement,2020-10-15T12:35:39Z,NONE,https://api.github.com/repos/appsmithorg/appsmith,"[Feature] New Screen advising mobile users switch to a desktop for Appsmith ## Summary Appsmith experience isn't ideal on mobile devices. After a mobile signup, we should communicate that appsmith isn't yet supported for mobiles. ## Screen Design <img width=""300"" alt=""Screenshot 2020-10-15 at 6 05 12 PM"" src=""https://user-images.githubusercontent.com/65771350/96123964-fb016c80-0f10-11eb-96fa-cc7cdf7707b1.png""> "
447344,497211,https://api.github.com/repos/payloadcms/payload/issues/94,bug,2021-03-11T03:00:59Z,CONTRIBUTOR,https://api.github.com/repos/payloadcms/payload,"Payload config validation prevents custom dashboard component # Bug Report https://github.com/payloadcms/payload/discussions/93#discussioncomment-466106 Payload Config `admin.components.views` is not passing validaiton even though it is valid: ```js components: { views: { Dashboard: () => <div>Hello</div>, }, }, ``` ## Expected Behavior Payload should start and not throw a validation error. ## Current Behavior There is a validation error thrown on startup. ## Possible Solution change the payload config validation for `admin.components.views.dashboard` to have a custom component ## Steps to Reproduce <!--- Steps to reproduce this bug. Include any code, if relevant --> 1. Create a project with a payload config that has `admin.components.views.Dashboard` set to a custom component 2. start the app ## Detailed Description Payload v0.4.4 "
544346,605041,https://api.github.com/repos/lima1/PureCN/issues/173,question,2021-04-22T11:44:37Z,NONE,https://api.github.com/repos/lima1/PureCN,"Ranked Solutions do not match up with log-likelihood values I've got a strange scenario where the ranking of the solutions don't appear to match up with the reported log-likelihood values. Here is the output overview plot when you take the PureCN output directly: ![purecn_overview_1](https://user-images.githubusercontent.com/3268173/115708881-72083980-a368-11eb-9dd1-a71f9628bd3b.png) When you extract the log-likelihood values extracted from the output (`ret`) of the `runAbsoluteCN` function: ```r #' Get PureCN candidate solutions dataframe #' #' @param purecn_output get_purecn_candidate_solutions_df <- function(purecn_output) { out_df <- purrr::map_dbl(purecn_output$results, purrr::pluck, ""purity"") %>% tibble::enframe(name = ""solution_id"", value = ""purity"") %>% dplyr::left_join( purrr::map_dbl(purecn_output$results, purrr::pluck, ""ploidy"") %>% tibble::enframe(name = ""solution_id"", value = ""ploidy""), by = ""solution_id"" ) %>% dplyr::left_join( purrr::map_dbl(purecn_output$results, purrr::pluck, ""log.likelihood"") %>% tibble::enframe(name = ""solution_id"", value = ""cn_llik""), by = ""solution_id"" ) %>% dplyr::left_join( purrr::map_dbl( purecn_output$results, purrr::pluck, ""total.log.likelihood"" ) %>% tibble::enframe(name = ""solution_id"", value = ""total_llik""), by = ""solution_id"" ) %>% dplyr::left_join( purrr::map(purecn_output$results, purrr::pluck, ""SNV.posterior"") %>% purrr::map_dbl(purrr::pluck, ""llik"") %>% tibble::enframe(name = ""solution_id"", value = ""snv_llik""), by = ""solution_id"" ) return(out_df) } get_purecn_candidate_solutions_df(ret) ``` ```r # A tibble: 10 x 6 solution_id purity ploidy cn_llik total_llik snv_llik <int> <dbl> <dbl> <dbl> <dbl> <dbl> 1 1 0.11 2.09 52660. -284239. -310521. 2 2 0.28 2.06 51248. -284150. -309749. 3 3 0.55 2.00 45660. -280050. -302880. 4 4 0.36 4.07 51693. -312928. -338738. 5 5 0.42 6.00 51211. -340828. -366398. 6 6 0.24 5.13 52710. -387899. -414205. 7 7 0.28 3.06 51431. -442310. -468001. 8 8 0.27 1.08 51837. -544194. -570089. 9 9 0.48 3.06 50170. -695980. -721041. 10 10 0.42 1.05 46749. -1108316. -1131678. ``` Here the top ranked solution (i.e. 1) doesn't actually have the highest `total_llik`. In fact, it's the 3rd ranked solution that actually has the highest `total_llik`. Based on the code, there appears to be a `.rankResults` function that should be run in the `runAbsoluteCN` function. When you do this: ```r ret$results <- PureCN:::.rankResults(ret$results) get_purecn_candidate_solutions_df(ret) ``` ```r # A tibble: 10 x 6 solution_id purity ploidy cn_llik total_llik snv_llik <int> <dbl> <dbl> <dbl> <dbl> <dbl> 1 1 0.55 2.00 45660. -280050. -302880. 2 2 0.28 2.06 51248. -284150. -309749. 3 3 0.11 2.09 52660. -284239. -310521. 4 4 0.36 4.07 51693. -312928. -338738. 5 5 0.42 6.00 51211. -340828. -366398. 6 6 0.24 5.13 52710. -387899. -414205. 7 7 0.28 3.06 51431. -442310. -468001. 8 8 0.27 1.08 51837. -544194. -570089. 9 9 0.48 3.06 50170. -695980. -721041. 10 10 0.42 1.05 46749. -1108316. -1131678. ``` And then plot the overview: ```r PureCN:::plotAbs(ret, type = ""overview"") ``` ![purecn_overview_2](https://user-images.githubusercontent.com/3268173/115708900-7896b100-a368-11eb-8c73-c3ab98c474d6.png) You get a overview plot that has the solutions ranked correctly according to the log-likelihood values Any idea what could explain what happened here? This is based on Pure CN 1.20.0. "
151834,168809,https://api.github.com/repos/AlexxIT/XiaomiGateway3/issues/172,question,2021-01-12T08:00:59Z,NONE,https://api.github.com/repos/AlexxIT/XiaomiGateway3,"Xiaomi Aqara MFKZQ01LM Cube Controller - actions problem Hi! I have an Aqara Cube with a hacked Xiaomi Gateway 3 ( ZNDMWG03LM ) I have 3 entity for cube : sensor.0xxxxxxxxxxxxxxxx_action battery zigbee. I would like to use the cube with actions (flip180, flip90, rotate, slide, tap, shake) I think that the action would be for that, but i can only use it for a state> alert. As a device I can only use for trigger with the battery. Can it be used like this? How? "
130568,145140,https://api.github.com/repos/cherryaudio/store-issues/issues/49,bug,2021-04-07T14:05:35Z,NONE,https://api.github.com/repos/cherryaudio/store-issues,"New Manufacturers' Filter on Bundles and Modules Store Pages - Manufacturers' Names Not Showing Browser Report: Microsoft Edge Version 89.0.774.68 on Windows 10 ### Description: The text for the manufacturers' names appears to be black on a black background - select any line and the text is there, just not visible in normal use. ### Detailed steps to reproduce the issue: As displayed when open up the store page: <img width=""238"" alt=""Normal list as displayed"" src=""https://user-images.githubusercontent.com/12783814/113880165-24f66600-97b3-11eb-8dcc-0dfbcfb3c51b.png""> Click and drag over the first few rows shows the text is there: <img width=""235"" alt=""Selecting the first few rows by clicking and dragging mouse over them"" src=""https://user-images.githubusercontent.com/12783814/113880172-26279300-97b3-11eb-8eb3-b4dd9d4edc6c.png""> "
612680,680874,https://api.github.com/repos/intellij-rust/intellij-rust/issues/6802,bug,2021-02-05T05:57:28Z,NONE,https://api.github.com/repos/intellij-rust/intellij-rust,"error: Unrecognized option: 'message-format' adding `--message-format=json-diagnostic-rendered-ansi` to the end of the command may cause ""Unrecorized option: 'message-format'"" when there's more command line argument in between, for example this will fail: ``` cargo clippy --fix --allow-dirty --allow-staged -Z unstable-options -- -W clippy::all -W clippy::pedantic -W clippy::nursery --message-format=json-diagnostic-rendered-ansi ``` I suggest adding arg to the beginning of the cargo command, this works: ``` cargo clippy --message-format=json-diagnostic-rendered-ansi --fix --allow-dirty --allow-staged -Z unstable-options -- -W clippy::all -W clippy::pedantic -W clippy::nursery ``` Ref: https://github.com/intellij-rust/intellij-rust/blob/3ee981094ed16b4958e1eb36539e8b05de63da0b/src/main/kotlin/org/rust/cargo/runconfig/buildtool/CargoBuildManager.kt#L293"
33944,37839,https://api.github.com/repos/MarechJ/hll_rcon_tool/issues/18,enhancement,2020-08-03T01:16:47Z,OWNER,https://api.github.com/repos/MarechJ/hll_rcon_tool,"Link perma bans and blacklist Currently when you apply a permaban to someone this person also gets blacklisted (useful for multi servers as they share the same DB). However if you remove that perma ban the blacklist stays and you have to remove it manually. To implement this both the ban and the unban commands should manage database records using the steamid to identify the player, and if a link exists remove the blacklist on unban. The code should be fail proof, meaning that failing to unblacklist should not result in a failure for the unban, same cause for the ban"
520646,578640,https://api.github.com/repos/microsoft/vscode-cpptools/issues/6314,bug,2020-10-14T03:19:27Z,COLLABORATOR,https://api.github.com/repos/microsoft/vscode-cpptools,"Prevent probing of compilers that are not gcc, clang, or a variant We should add a verification that a compiler is probeable, and avoid any subsequent probe attempts if it is not. Currently, only gcc, clang, and variants of those, are probeable. For example, if a user has a `compile_commands.json` that refers to a C/C++ compiler we do not support (i.e. gomacc.exe), we may probe it for each entry (if args differ, since we don't know what args are relevant), resulting in way too many, slow compiler-probe operations that will never succeed. We could use a single check to determine if a compiler is probeable or not. If not, we can avoid any subsequent probing of that executable."
155323,172687,https://api.github.com/repos/libDrive/libDrive/issues/2,bug,2021-02-04T20:30:07Z,NONE,https://api.github.com/repos/libDrive/libDrive,"Heroku Error Deployed just fine but when tried to visit the server, it crashed. ![Screenshot](https://user-images.githubusercontent.com/18643014/106951505-dba77d00-6755-11eb-9cea-9377ea347387.jpg) "
30206,33643,https://api.github.com/repos/pradyunsg/furo/issues/108,bug,2021-03-20T16:00:20Z,NONE,https://api.github.com/repos/pradyunsg/furo,"Method signature can overlap on the `[source]` link **Describe the bug** In some cases, the method signature can overlap on the `[source]` link. Here's a preview: https://jack1142-minimal-repro.readthedocs.io/en/latest/ And a bit different one (with usage of `sphinxcontrib_trio` extension): https://jack1142-red-prs.readthedocs.io/en/v3-some_furo_stuff/framework_commands.html#redbot.core.commands.help.RedHelpFormatter.help_filter_func **To Reproduce** The code of minimal repro is here: https://github.com/jack1142/furo/tree/issue_108_minimal_repro **Expected behavior** I expected the method signature to wrap appropriately. **Screenshots** ![image](https://user-images.githubusercontent.com/6032823/111876160-c8ffa500-899d-11eb-91bf-ed423a41b687.png) ![image](https://user-images.githubusercontent.com/6032823/111875486-56d99100-899a-11eb-881b-072a3ffe7d69.png) **Desktop (please complete the following information):** - OS: Windows - Browser: Chrome 89, Opera 74, Firefox 86, Edge 89 - Screen Width: over 830px (I have 1080p screen) **Smartphone (please complete the following information):** Doesn't happen on my smartphone (Galaxy S20, Android 11, Chrome 89), although it does seem that some contents don't get wrapped causing horizontal scrolling to be required. **Additional context** Add any other context about the problem here. "
92805,103138,https://api.github.com/repos/connext/vector-modal/issues/27,bug,2021-02-03T23:28:48Z,MEMBER,https://api.github.com/repos/connext/vector-modal,Connecting to iframe: failed to validate outbound update ![image](https://user-images.githubusercontent.com/22877754/106822557-3779e500-6634-11eb-8e34-8ebb8d7322dc.png) Scott is seeing the above error with his widget on DG. His logs: ![image](https://user-images.githubusercontent.com/22877754/106822693-685a1a00-6634-11eb-927e-547aaea713ec.png) Here's his indexedDB: ![image](https://user-images.githubusercontent.com/22877754/106822730-77d96300-6634-11eb-94f1-969203991ead.png) 
696318,773915,https://api.github.com/repos/zephyrproject-rtos/zephyr/issues/35613,bug,2021-05-25T12:59:48Z,COLLABORATOR,https://api.github.com/repos/zephyrproject-rtos/zephyr,[Coverity CID: 225900] Out-of-bounds access in tests/net/lib/dns_addremove/src/main.c Static code scan issues found in file: https://github.com/zephyrproject-rtos/zephyr/tree/374629af906a24add294b1c3b945128cb6a486e8/tests/net/lib/dns_addremove/src/main.c Category: Memory - corruptions Function: `test_dns_reconfigure_callback` Component: Tests CID: [225900](https://scan9.coverity.com/reports.htm#v29726/p12996/mergedDefectId=225900) Details: https://github.com/zephyrproject-rtos/zephyr/blob/374629af906a24add294b1c3b945128cb6a486e8/tests/net/lib/dns_addremove/src/main.c#L449 Please fix or provide comments in coverity using the link: https://scan9.coverity.com/reports.htm#v29271/p12996. Note: This issue was created automatically. Priority was set based on classification of the file affected and the impact field in coverity. Assignees were set using the CODEOWNERS file. 
209955,233462,https://api.github.com/repos/jtothebell/fake-08/issues/48,bug,2021-03-14T14:00:12Z,OWNER,https://api.github.com/repos/jtothebell/fake-08,Dank tomb green outline From u/bruno84000 on Reddit Dank Tomb has a green square permanently around the protagonist.
622686,691989,https://api.github.com/repos/pawlean/25DaysOfGiphiness/issues/7,enhancement,2017-12-03T19:39:01Z,COLLABORATOR,https://api.github.com/repos/pawlean/25DaysOfGiphiness,"Play Christmas music Spun out from #1. Not sure how we'd want to do this, but we could play a Christmas tune/jingle each time someone opens a GIF? Alternatively, each time a Santa is launched, it could play ""ho ho ho, Merry Christmas!"" or something? 😆 "
176180,195877,https://api.github.com/repos/leMaik/chunky/issues/23,bug,2021-01-17T17:32:43Z,NONE,https://api.github.com/repos/leMaik/chunky,"Exception when trying to render ### Java Version ``` >java --version openjdk 15.0.1 2020-10-20 OpenJDK Runtime Environment (build 15.0.1+9-18) OpenJDK 64-Bit Server VM (build 15.0.1+9-18, mixed mode, sharing) ``` ### JavaFX Version openjfx-11.0.2_windows-x64_bin-sdk ### Launch Command java --module-path ""C:\Program Files\Java\javafx-sdk-11.0.2\lib"" --add-modules=javafx.controls,javafx.base,javafx.graphics,javafx.fxml -jar ChunkyLauncher.jar --launcher ### Launcher Options ![image](https://user-images.githubusercontent.com/26907766/104850817-35e8b700-58e9-11eb-8c56-0b0ea5dcf9f1.png) ### Steps to Reproduce 1. Open my world 2. Select some Chunks (in this case a 2x2 block) 3. Switch to ""Render Preview"" tab 4. Click on the play button and wait for the progress bar to complete 5. An error is logged, and nothing is rendered: ``` Exception in thread ""Scene Manager"" java.lang.NullPointerException: Cannot invoke ""se.llbit.chunky.world.WorldTexture.store(java.io.DataOutputStream)"" because ""waterColors"" is null at se.llbit.chunky.resources.OctreeFileFormat.store(OctreeFileFormat.java:129) at se.llbit.chunky.renderer.scene.Scene.saveOctree(Scene.java:1884) at se.llbit.chunky.renderer.scene.Scene.saveScene(Scene.java:472) at se.llbit.chunky.renderer.scene.SynchronousSceneManager.saveScene(SynchronousSceneManager.java:130) at se.llbit.chunky.renderer.scene.AsynchronousSceneManager.lambda$saveScene$1(AsynchronousSceneManager.java:122) at se.llbit.chunky.renderer.scene.AsynchronousSceneManager.run(AsynchronousSceneManager.java:81) ``` "
316136,351462,https://api.github.com/repos/AustinScola/seligimus/issues/108,enhancement,2021-02-15T23:16:11Z,OWNER,https://api.github.com/repos/AustinScola/seligimus,Change equal attributes decorator to specify attributes Change the equal attributes decorator to accept a attributes to compare or maybe attributes to ignore? Or both? The default behavior should still be to compare all instance attributes.
425652,473150,https://api.github.com/repos/external-secrets/kubernetes-external-secrets/issues/516,enhancement,2020-10-19T06:13:54Z,NONE,https://api.github.com/repos/external-secrets/kubernetes-external-secrets,Updating RBAC API version to v1 At Helm 3.3 ClusterRole and ClusterRoleBinding api version was updated to rbac.authorization.k8s.io/**v1​** (https://helm.sh/docs/topics/rbac/). We should update the chart [rbac.yam](https://github.com/godaddy/kubernetes-external-secrets/blob/master/charts/kubernetes-external-secrets/templates/rbac.yaml#L2) as well. 
658658,732120,https://api.github.com/repos/mishoo/UglifyJS/issues/4956,bug,2021-05-23T21:17:07Z,NONE,https://api.github.com/repos/mishoo/UglifyJS,"Uglify JS breaking change from 3.10.4 to 3.13.7 **Uglify version 3.13.7** **JavaScript input** [uglifyissue.zip](https://github.com/mishoo/UglifyJS/files/6528927/uglifyissue.zip) Zip contents: * Test.ts - original source TypeScript * Test.js - compiled TypeScript with pure 'tsc' to es5 with await/async polyfill * testmin.3.10.4.js - uglify output from version `3.10.4` * testmin.3.13.7.js - uglify output from version `3.13.7` **The `uglifyjs` CLI command executed or `minify()` options used:** ``` const uglify = require(""uglify-js""); const result = uglify.minify(fs.readFileSync(/* source input path */)); fs.writeFileSync(""output.js"", result.code); ``` **JavaScript output or error produced.** *Test Case 1: Raw JS output:* ``` > node Test.js Expecting 3 iterations Finished iteration i1 Finished iteration i2 Finished iteration i3 Ran 3 iterations ``` *Test Case : UglifyJS output 3.10.4:* ``` > node testmin.3.10.4.js Expecting 3 iterations Finished iteration i1 Finished iteration i2 Finished iteration i3 Ran 3 iterations ``` *Test Case : UglifyJS output 3.13.7:* ``` > node testmin.3.13.7.js Expecting 3 iterations Finished iteration i1 (node:18191) UnhandledPromiseRejectionWarning: TypeError: (0 , i[r]) is not a function ... ... ```"
631702,702059,https://api.github.com/repos/zacharyshupp/SAM.TestModule/issues/1,bug,2021-04-12T22:32:10Z,OWNER,https://api.github.com/repos/zacharyshupp/SAM.TestModule,"issue 1 **Describe the bug** A clear and concise description of what the bug is. **To Reproduce** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected behavior** A clear and concise description of what you expected to happen. **Screenshots** If applicable, add screenshots to help explain your problem. **System Details (please complete the following information):** - OS: [e.g. iOS] - PowerShell Version: [e.g. 7.1] - Module Version: [e.g. 0.1.0] **Additional context** Add any other context about the problem here. "
234381,260662,https://api.github.com/repos/redboxllc/scuttle/issues/43,bug,2021-01-19T09:48:23Z,NONE,https://api.github.com/repos/redboxllc/scuttle,"Propagate container failure to pod status We have a pod that runs tests (main container) and an istio sidecar. Once scuttle is added to the flow, even if the test container has failed tests, the entire pod enters 'Completed' state as appose to an 'Error' state (which occurs if scuttle is not present). Is it possible to propagate the status of the failed test container to the pod? e.g ``` NAME READY STATUS RESTARTS AGE test 0/2 Error 0 38m ``` and not: ``` NAME READY STATUS RESTARTS AGE test 0/2 Completed 0 38m ``` error as seen in pod: ``` containerStatuses: - containerID: docker://... image: istio/proxyv2:1.5.8 name: istio-proxy state: terminated: containerID: docker://... exitCode: 0 finishedAt: ""2021-01-19T09:36:40Z"" reason: Completed startedAt: ""2021-01-19T09:07:19Z"" - containerID: docker://... name: test state: terminated: containerID: docker://... exitCode: 120 finishedAt: ""2021-01-19T09:36:40Z"" reason: Error startedAt: ""2021-01-19T09:07:19Z"" ``` lean pod yaml: ``` apiVersion: v1 kind: Pod metadata: name: test annotations: sidecar.istio.io/inject: ""true"" restartPolicy: Never containers: - name: test command: [""scuttle"", ""/bin/sh"", ""-c""] env: - name: ENVOY_ADMIN_API value: ""http://127.0.0.1:15000"" - name: ISTIO_QUIT_API value: ""http://127.0.0.1:15000"" ```"
294088,327017,https://api.github.com/repos/GluuFederation/oxAuth/issues/1321,enhancement,2020-04-20T05:33:20Z,NONE,https://api.github.com/repos/GluuFederation/oxAuth,"Add live metric endpoints to oxAuth ### Feature Request Add live metric endpoints to oxAuth. ### Proposed Design The proposed design is to add live metric output per openmetrics standards to stream data directly into metric servers such as prometheus. In this first version, the live metrics endpoint should report on successful grants by type. "
619962,688982,https://api.github.com/repos/JenShin-368/GenshinImpactCalculator/issues/78,bug,2021-04-18T09:13:55Z,COLLABORATOR,https://api.github.com/repos/JenShin-368/GenshinImpactCalculator,Keqing Optimizer Bug **Describe the bug** Right now the Optimizer doesn't work for Keqing. **To Reproduce** https://discordapp.com/channels/787335702182494218/787335764965851197/832966462326177812
598438,665054,https://api.github.com/repos/supercollider/supercollider/issues/5339,bug,2021-02-07T08:46:13Z,NONE,https://api.github.com/repos/supercollider/supercollider,"BinaryOpUGen's pow implementation returns negative values ## Environment * SuperCollider version: 3.11.0 * Operating system: Mac Mojave 10.14.6 * Other details (Qt version, audio driver, etc.): ## Steps to reproduce ```supercollider -10.pow(2); ({ K2A.ar(-10).pow(2).poll; }.play) ``` ## Expected vs. actual behavior compare the output of the two operations above. the BinaryOpUGen pow operation is returning -100. this is mathematically incorrect and inconsistent with the sclang operation."
141114,156847,https://api.github.com/repos/amor71/LiuAlgoTrader/issues/154,bug,2021-01-21T23:35:09Z,CONTRIBUTOR,https://api.github.com/repos/amor71/LiuAlgoTrader,"[ENH] Throttle API requests to support polygon's free plan for market miners? Sorry for the spam of tickets, but I noticed this while running some tests. **Is your feature request related to a problem? Please describe.** Essentially it currently seems that I have setup everything correctly (YAY). I started the example setup with running the miner.toml under the examples section and the `swing-momentum/portfolio.py` like such: ``` [miners.portfolio] filename = ""swing-momentum/portfolio.py"" portfolio_size = 2000 debug = true index = 'SP500' rank_days = 90 atr_days = 20 risk_factor = 0.002 indicators = ['SMA100'] ``` initially I was getting errors like the following: ``` [load_data()][9942]2021-01-21 22:43:05.755232:loading 200 days for symbol MMM (1/505) [main()][9942]2021-01-21 22:43:07.067853:[ERROR] aborted w/ exception object of type 'NoneType' has no len() Traceback (most recent call last): File ""/.venv/lib/python3.8/site-packages/liualgotrader-0.0.86-py3.8.egg/EGG-INFO/scripts/market_miner"", line 73, in main await asyncio.gather(*task_list) File ""swing-momentum/portfolio.py"", line 178, in run await self.load_data(symbols) File ""swing-momentum/portfolio.py"", line 67, in load_data tlog(f""loaded {len(self.data_bars[symbol])} data-points"") TypeError: object of type 'NoneType' has no len() ``` which I now believed to have traced down on how polygon behaves under the free plan. In the dashboard I can see that 5 requests per minute are getting answered correctly, but the rest is refused due to rate limitation of the free plan (see https://polygon.io/pricing). ![Selection_2021-01-22_00-13-17](https://user-images.githubusercontent.com/6849390/105424655-05d24880-5c48-11eb-8ef5-014a58132cc7.png) From my end it seems if one is rate limited the call to [`daily_bars`](https://github.com/amor71/LiuAlgoTrader/blob/5ad4e46db126698399d338c4488aa4983385c2d8/examples/swing-momentum/portfolio.py#L61) will return `Ǹone` (and not throw an Exception) causing all sorts of issues. **Describe the solution you'd like** The 'perfect' solution I could imagine is either some rate limitation build in into LiuAlgoTrader, or using another free endpoint without rate limitation that allows to fetch daily data (e.g. yahoo finance). Certainly if I know my strategies return the expenses needed to pay for the premium for polygon this problem would not exist...but I'm not there yet ;-) "
442545,491956,https://api.github.com/repos/GateNLP/python-gatenlp/issues/89,bug,2021-04-10T10:14:43Z,MEMBER,https://api.github.com/repos/GateNLP/python-gatenlp,"Pampac: rename ""data"" to ""matches"" in parameters and attributes ""data"" was originally chosen because it represents all the 'data' related to name, but to understand intuitively what this represents ""matches"" is the better term. Should document somewhere that matches information is only created for patterns with a name."
394630,438627,https://api.github.com/repos/GDQuest/gdscript-docs-maker/issues/79,bug,2021-02-12T19:01:49Z,NONE,https://api.github.com/repos/GDQuest/gdscript-docs-maker,"generate_reference not filtering directories. **I'm submitting a...** <!-- Write an `x` in the corresponding box. --> <!-- Example: --> <!-- [x] Bug report. --> - [x] Bug report. - [ ] Feature request. ## Bug report ## <!-- If you're reporting a bug, please fill this section. --> The current behaviour is: When I invoke generate_reference with ` ./generate_reference ./ -d Entities -d Scenes -o docs/ -f markdown` i get a complete listing of my Godot project files and the terminal shows the following error. `./generate_reference: line 108: test: too many arguments` and the temporary file is identical to the source file - ``` tool extends SceneTree # Finds and generates a code reference from gdscript files. var Collector: SceneTree = load(""Collector.gd"").new() # A list of directories to collect files from. var directories := [""res://""] # If true, explore each directory recursively var is_recursive: = true # A list of patterns to filter files. var patterns := [""*.gd""] func _init() -> void: var files := PoolStringArray() for dirpath in directories: files.append_array(Collector.find_files(dirpath, patterns, is_recursive)) var json: String = Collector.print_pretty_json(Collector.get_reference(files)) Collector.save_text(""res://reference.json"", json) ``` I would expect no error message and only the requested directories listed in the reference.json file. I think that the section ```' if test $directories_override != """"; then args=$(echo $directories_override | sed -r 's/([-._a-zA-Z0-9]+)/""\1"",/g' | sed -r 's/,$//') sed -ri ""s/^var directories.+/var directories := [$args]/"" $file_ref_collector fi ``` is incorrect and should be ``` if test ""$directories_override"" != """"; then args=$(echo $directories_override | sed -r 's/([-._a-zA-Z0-9]+)/""\1"",/g' | sed -r 's/,$//') # echo ""args for overriding directory: "" $args sed -ri ""s/^var directories.+/var directories := [$args]/"" $file_ref_collector fi ``` note the quotation marks around the `$directories_override`. if I make that change to the code then the temporary file created is ``` tool extends SceneTree # Finds and generates a code reference from gdscript files. var Collector: SceneTree = load(""Collector.gd"").new() # A list of directories to collect files from. var directories := [""Entities"", ""Scenes""] # If true, explore each directory recursively var is_recursive: = true # A list of patterns to filter files. var patterns := [""*.gd""] func _init() -> void: var files := PoolStringArray() for dirpath in directories: files.append_array(Collector.find_files(dirpath, patterns, is_recursive)) var json: String = Collector.print_pretty_json(Collector.get_reference(files)) Collector.save_text(""res://reference.json"", json) ``` and the refernce.json only includes the desired directories. I am currently using a Manjaro linux box with all current updates installed, VSCode 1.53.2 and running the command in a VSCode terminal. I hope this is of help Douglas "
668991,743556,https://api.github.com/repos/hrkfdn/ncspot/issues/411,enhancement,2021-01-28T01:22:06Z,NONE,https://api.github.com/repos/hrkfdn/ncspot,"Default playlist sort I have a few playlists with tons of songs and I'm constantly adding new ones, as well as usually playing these latests songs first. The way it is now, I have to either scroll through 3k songs or use 'sort added d', both of those needing to be done every single time I open the playlist, which is tedious. Reading the documentation I haven't found a way to select a default playlist sort in the config file, could one be added eventually?"
256720,285535,https://api.github.com/repos/microsoft/vscode/issues/119751,bug,2021-03-24T07:02:45Z,NONE,https://api.github.com/repos/microsoft/vscode,"Visual glitches (squares) on Terminal with Zoom < 100% Issue Type: <b>Bug</b> VS Code have too large interface font size by default, so I use it with Zoom < 100% (at 80%). And after last couple of updates (from version 1.51 maybe or earlier) the Terminal starts to show the visual gliches, here is screenshot: ![image](https://user-images.githubusercontent.com/336662/112268491-1c1c7500-8c88-11eb-9dab-c1548a26143e.png) If I change terminal window size, or touch the Zoom (in or out) - they are immediately disappearing, but shows again after some later interactions. With Zoom = 100% this issue is not reproducible. Clearing terminal via `clear` or `reset` commands didn't help. VS Code version: Code 1.54.1 (f30a9b73e8ffc278e71575118b6bf568f04587c8, 2021-03-04T22:38:50.094Z) OS version: Linux x64 5.8.0-45-generic Remote OS version: Linux x64 4.15.0-20-generic Remote OS version: Linux x64 5.4.0-66-generic <details> <summary>System Info</summary> |Item|Value| |---|---| |CPUs|Intel(R) Core(TM) i3-4360 CPU @ 3.70GHz (4 x 3691)| |GPU Status|2d_canvas: enabled<br>gpu_compositing: enabled<br>multiple_raster_threads: enabled_on<br>oop_rasterization: disabled_off<br>opengl: enabled_on<br>protected_video_decode: unavailable_off<br>rasterization: disabled_software<br>skia_renderer: enabled_on<br>video_decode: disabled_software<br>vulkan: disabled_off<br>webgl: enabled<br>webgl2: enabled| |Load (avg)|2, 2, 2| |Memory (System)|15.54GB (0.43GB free)| |Process Argv|--no-sandbox --unity-launch --crash-reporter-id bc4064db-5144-4d00-b73a-13a771c022a6| |Screen Reader|no| |VM|0%| |DESKTOP_SESSION|plasma| |XDG_CURRENT_DESKTOP|KDE| |XDG_SESSION_DESKTOP|KDE| |XDG_SESSION_TYPE|x11| |Item|Value| |---|---| |Remote|SSH: brick-k| |OS|Linux x64 4.15.0-20-generic| |CPUs|Intel Xeon E5 (Sandy Bridge) (12 x 2399)| |Memory (System)|23.54GB (0.88GB free)| |VM|0%| |Item|Value| |---|---| |Remote|SSH: dgd| |OS|Linux x64 5.4.0-66-generic| |CPUs|Intel Xeon Processor (Cascadelake) (2 x 2095)| |Memory (System)|7.78GB (0.75GB free)| |VM|0%| </details><details><summary>Extensions (26)</summary> Extension|Author (truncated)|Version ---|---|--- quasar-snippets|abd|1.0.0 systemd-unit-file|coo|1.0.6 drupal-8-snippets|dss|0.0.2 vscode-firefox-debug|fir|2.9.2 vue-snippets|hol|1.0.4 vue|jcb|0.1.5 dotenv|mik|1.0.1 remote-ssh|ms-|0.65.1 remote-ssh-edit|ms-|0.65.1 jinjahtml|sam|0.16.0 svg-preview|Sim|2.8.3 rewrap|stk|1.14.0 twig|wha|1.0.2 vscode-intelephense-client|bme|1.6.3 vscode-mysql-client2|cwe|3.6.0 vscode-eslint|dba|2.1.19 gitlens|eam|11.3.0 php-debug|fel|1.14.11 gitlab-workflow|Git|3.15.0 escape-quotes|mil|1.10.0 language-gettext|mro|0.2.0 vetur|oct|0.33.1 indent-rainbow|ode|7.5.0 vscode-gitweblinks|red|2.4.0 change-case|wma|1.0.0 php-sniffer|won|1.3.0 </details><details> <summary>A/B Experiments</summary> ``` vsliv368:30146709 vsreu685:30147344 python383cf:30185419 vspor879:30202332 vspor708:30202333 vspor363:30204092 vstry914:30276682 pythonvsdeb440:30248342 pythonvsded773:30248341 pythonvspyt875:30259475 pythontbcf:30265426 vspre833cf:30267465 vsdfh931:30275552 vshan820:30276952 ``` </details> <!-- generated by issue reporter -->"
395809,439928,https://api.github.com/repos/bagelbyheart/spacenoider/issues/6,enhancement,2021-03-10T18:34:45Z,OWNER,https://api.github.com/repos/bagelbyheart/spacenoider,"Weapons should modify player appearance I figure this can be accomplished a few ways and both are pretty simple. 1. Store the new appearance table for the bullet in question within it's entity definition, ie, within `vulcan={...}`. 2. Either draw that sprite in front of the player sprite *OR* have it replace the player animation table."
688944,765702,https://api.github.com/repos/open-rmf/rmf_traffic_editor/issues/333,enhancement,2021-04-09T07:11:33Z,CONTRIBUTOR,https://api.github.com/repos/open-rmf/rmf_traffic_editor,"building map server crashes when an image file is not present Currently `building_map_server` crashes when a referenced image file is not present. It would be nicer to just print a warning and continue, since lots of RMF still works fine (traffic management, etc) even when there is a missing building map file. In the future, perhaps we could generate a placeholder ""warning"" image so it's clear why the UI's have no background image(s)."
365247,406018,https://api.github.com/repos/lmc-eu/php-coding-standard/issues/19,bug,2018-05-11T11:42:04Z,MEMBER,https://api.github.com/repos/lmc-eu/php-coding-standard,"Missing typehints are not detected It seems phpdoc_add_missing_param_annotation (aka PhpdocAddMissingParamAnnotationFixer) does not work as I expected - it only works if there is already at least something (even just comment) in phpdoc. If phpdoc is missing, it won't say anything :-/. This causes no error: ```php public function missingTypes($text, $date): void { // ... } ``` While this will: ```php /** * You should use types. Really. */ public function missingTypes($text, $date): void { // ... } ``` And it will suggest this change: ```diff /** * You should use types. Really. + * @param mixed $text + * @param mixed $date */ public function missingTypes($text, $date): void { ``` But this is expected behavior of the Fixer: https://github.com/FriendsOfPHP/PHP-CS-Fixer/issues/2464 So we should find something to handle this properly."
587774,653166,https://api.github.com/repos/WeakAuras/WeakAuras-Companion/issues/1015,bug,2021-04-19T16:57:40Z,NONE,https://api.github.com/repos/WeakAuras/WeakAuras-Companion,"Client won't start minimized <!-- WeakAuras Companion 2.0.0 ""Error in updater"" An issue in the Electron version in this build break the updater. Please manually upgrade your Companion version from https://github.com/WeakAuras/WeakAuras-Companion/releases/latest More information at https://www.patreon.com/posts/about-companion-32871243 --> **Operating System:** - [ x] Windows - [ ] Mac - [ ] Linux **Companion Version:** ``` 3.2.2 ``` **Companion App Console Log:** ``` electron/js2c/renderer_init.js:13 (electron) The remote module is deprecated. Use https://github.com/electron/remote instead. log @ electron/js2c/renderer_init.js:13 app.0cb7ee51.js:1 validateWowpath app.0cb7ee51.js:1 buildVersionList 2app.0cb7ee51.js:1 buildAccountList app.0cb7ee51.js:1 updaterHandler: update-not-available app.0cb7ee51.js:1 updaterHandler: checkForUpdates app.0cb7ee51.js:1 promisesWagoCallsComplete app.0cb7ee51.js:1 promisesWagoDataCallsComplete app.0cb7ee51.js:1 no data received for InterruptTracker app.0cb7ee51.js:1 no data received for PartyCDs app.0cb7ee51.js:1 writeAddonData ``` **WeakAuras Version:** ``` /run print(WeakAuras.versionString) in-game. ``` **WeakAuras Errors:** ``` 1. Install https://mods.curse.com/addons/wow/BugSack 2. Install https://mods.curse.com/addons/wow/bug-grabber 3. Try to do whatever it is you're having a problem with again 4. Check your minimap for an icon that looks like a bag. Is it green, or is it red? • GREEN • WeakAuras is working correctly. • Either you found a behavioral bug, or you are just doing it wrong :) • Explain the steps you took, and we will try to figure out what happened. • RED • There are error messages. Click on the red bag to see them. • Copy & Paste here all of the error messages (there may be more than one, click the 'previous' button on the dialog to see previous ones ``` **Describe the bug** Client doesn't start minimized after updating to 3.2.2 despite the option being checked. Tried to check/uncheck. Also tried to uncheck, restart, check again, restart. **To Reproduce** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected behavior** A clear and concise description of what you expected to happen. **Screenshots** If applicable, add screenshots to help explain your problem. **Include a .zip file containing:** `%programfiles%\World of Warcraft\_retail_\WTF\Account\<AccountName>\SavedVariables\WeakAuras.lua` AND `%appdata%\weakauras-companion\config.json` "
342432,380674,https://api.github.com/repos/tallpauley/wordsiv/issues/6,enhancement,2021-05-09T22:50:22Z,OWNER,https://api.github.com/repos/tallpauley/wordsiv,"Expand Unit Testing Need it on MarkovModel, as well as testing all the parameter permutations behave as planned on all the models. We will need to create mock data files to test how all the parameters work. We will leave the source package installation and loading to the higher-level tests."
261880,291257,https://api.github.com/repos/mathieulagrange/doce/issues/38,enhancement,2020-09-25T13:48:27Z,OWNER,https://api.github.com/repos/mathieulagrange/doce,express dead branches in settings tree ? factor._ignore.factor.modality_selector factor._ignore.factor.factor_to_ignore
290620,323166,https://api.github.com/repos/Psychoanalytic-Electronic-Publishing/PEP-Web-User-Interface/issues/487,bug,2021-05-04T15:19:49Z,COLLABORATOR,https://api.github.com/repos/Psychoanalytic-Electronic-Publishing/PEP-Web-User-Interface,"Download RIS file downloads CSV When viewing results of a search there is a download option. If you click RIS it downloads a csv. If we've implemented RIS it should download that. If not, disable the option. ![Screen Shot 2021-05-04 at 11 18 45 AM](https://user-images.githubusercontent.com/3603329/117027271-8b937480-acca-11eb-939d-2879d6030509.png) "
422613,469769,https://api.github.com/repos/Azure/azure-sdk-for-java/issues/19848,bug,2021-03-15T10:13:11Z,NONE,https://api.github.com/repos/Azure/azure-sdk-for-java,"azure-spring-cloud-starter-eventhubs stops picking up events and won't start again till service restart Hi, We observed a weird problem that is near impossible for us to debug. After some time of working fine our EventHub listener stops picking up new events (no idea why). Logs look fine as always, e.g. ``` 2021-03-15 10:10:52.315 INFO [qiaspace-device-registration,,,] 1 --- [ elastic-15] c.a.m.e.PartitionBasedLoadBalancer : Starting load balancer for 06bbbb0e-f94f-476d-b330-d3fc229922dc 2021-03-15 10:10:52.315 INFO [qiaspace-device-registration,,,] 1 --- [ elastic-15] c.a.m.e.PartitionBasedLoadBalancer : CheckpointStore returned 2 ownership records 2021-03-15 10:10:52.315 INFO [qiaspace-device-registration,,,] 1 --- [ elastic-15] c.a.m.e.PartitionBasedLoadBalancer : Event Hubs service returned 2 partitions 2021-03-15 10:10:52.316 INFO [qiaspace-device-registration,,,] 1 --- [ elastic-15] c.a.m.e.PartitionBasedLoadBalancer : Number of active ownership records 2 2021-03-15 10:10:52.316 INFO [qiaspace-device-registration,,,] 1 --- [ elastic-15] c.a.m.e.PartitionBasedLoadBalancer : Number of active event processors 1 2021-03-15 10:10:52.316 INFO [qiaspace-device-registration,,,] 1 --- [ elastic-15] c.a.m.e.PartitionBasedLoadBalancer : Expected min partitions per event processor = 2, expected number of event processors with additional partition = 0 2021-03-15 10:10:52.316 INFO [qiaspace-device-registration,,,] 1 --- [ elastic-15] c.a.m.e.PartitionBasedLoadBalancer : Load is balanced with this event processor owning 2 partitions 2021-03-15 10:10:52.318 INFO [qiaspace-device-registration,,,] 1 --- [ elastic-15] c.a.m.e.PartitionBasedLoadBalancer : Load balancing completed successfully ``` Load balancing is done regularly, but for some reason until I restart the service it is not picking up new events. I have literally no idea what can we do to help investigate the problem. Same thing happen with integration as well as binder. It seams to have worked fine earlier when we used @AzureListener (but we moved to webflux, and that way does not work without spring-web)"
587839,653238,https://api.github.com/repos/NBA-BSA/ref_tracking_metrics/issues/11,enhancement,2021-05-14T14:25:24Z,COLLABORATOR,https://api.github.com/repos/NBA-BSA/ref_tracking_metrics,Quarter Stats Create query that has ref by quarter in a game.
132006,146736,https://api.github.com/repos/haydenkd/taskinator/issues/5,enhancement,2021-01-08T00:51:37Z,OWNER,https://api.github.com/repos/haydenkd/taskinator,Add Persistence and Optimization ## Requirements * Use localStorage to save tasks * Refactor code
682887,758966,https://api.github.com/repos/mapbox/mapbox-navigation-android/issues/4270,bug,2021-04-15T14:30:11Z,NONE,https://api.github.com/repos/mapbox/mapbox-navigation-android,"Maneuver directions incorrect <!-- Hello and thanks for contributing! To help us diagnose your problem quickly, please: - Include a minimal demonstration of the bug, including code, logs, and screenshots. - Ensure you can reproduce the bug using the latest release. - Only post to report a bug or request a feature; direct all other questions to: https://stackoverflow.com/questions/tagged/mapbox --> **Android API:** 30 **Mapbox Navigation SDK version:** 2.0.0-beta.5 ### Steps to trigger behavior 1. Clone this project (I'm using commit: a773c3833fa037bd3b64b33b5df34a524b9e4658 ) 1. Fix up the `example` app in this project (this involves about an hour of faff sorting out build/gradle problems etc as there is no top level `build.gradle`). Activity code should be unchanged. 1. Choose ""Turn by Turn navigation"" 1. Plot a route around a roundabout ### Expected behavior The turn icon should represent the maneuver that's about to be made ### Actual behavior The icon is incorrect, e.g (from the app that I'm developing) <img src=""https://user-images.githubusercontent.com/20515901/114885483-97dc8e00-9dfe-11eb-984c-ecf390c70f0f.png"" width=""320"" /> It's telling me to go hard right instead of left. Here is a video of it happening in the mapbox demo app: https://drive.google.com/file/d/1V2PLxOXc6ZTQXleAgbP9eIt4-d_DxrWI/view?usp=sharing "
300483,334080,https://api.github.com/repos/lets-talk/chat-utils/issues/100,enhancement,2021-01-27T13:17:23Z,NONE,https://api.github.com/repos/lets-talk/chat-utils,[lt-root] DX improvements mod lerna scripts and add tools like commitizen to standarized commit messages
288492,320822,https://api.github.com/repos/bonzibudd/Fluent-Metro/issues/33,bug,2020-09-20T15:03:08Z,OWNER,https://api.github.com/repos/bonzibudd/Fluent-Metro,Make glyphs use better antialiasing method Current bitmaps appear slightly dotted due to the incorrect antialiasing method being used. This will be changed in bulk once I find a better method.
219459,244033,https://api.github.com/repos/QBDI/QBDI/issues/70,enhancement,2018-08-03T13:55:52Z,MEMBER,https://api.github.com/repos/QBDI/QBDI,"Reduce size of Windows QBDI static library For a reason yet to be investigated, QBDI static library on Windows weighs more than 100 MB :( It doesn't impact the size of binaries linked with it. But reducing the size of Windows QBDI static library could avoid wasting space."
473970,526773,https://api.github.com/repos/amocrm/amocrm-api-php/issues/246,question,2021-02-12T14:44:49Z,NONE,https://api.github.com/repos/amocrm/amocrm-api-php,"Возможная причина неверной работы автообновления токенов Срок жизни refresh token составляет 3 месяца. По истечении этого срока мы вынуждены вручную менять refresh token, так как он не обновляется. Нужно снова обращаться к файлу авторизации examples/get_token.php и давать приложению доступ."
333241,370457,https://api.github.com/repos/niconiahi/chakra-paginator/issues/15,enhancement,2021-02-10T08:35:23Z,NONE,https://api.github.com/repos/niconiahi/chakra-paginator,"Current page Hi, I need to set the current page manually. I checked the code it seems you have currentPage and setCurrentPage internally. is that possible for you to expose them for us to set it at first?? I am reading currentPage from URL query params and it should be set as currentPage thanks "
384193,427081,https://api.github.com/repos/GeekInTheNorth/all-in-skate-challenge/issues/37,enhancement,2021-02-14T00:30:22Z,OWNER,https://api.github.com/repos/GeekInTheNorth/all-in-skate-challenge,"Update the statistics page to show weekly skates and not daily As the event gets longer, the skate statistics chart will end up with too many points of data. Change these to be weeks from the launch date."
262621,292073,https://api.github.com/repos/freqtrade/freqtrade/issues/5040,question,2021-05-27T21:57:24Z,NONE,https://api.github.com/repos/freqtrade/freqtrade,"freqtrade library not found (Docker) (Raspberry Pi) * Operating system: Rasbian (32-bit) Model 3b+ * Python Version: 2.7.16 & 3.7.3 * CCXT version: No Output * Freqtrade Version: ERROR: for ft_userdata_freqtrade_run UnixHTTPConnectionPool(host='localhost', port=None): Read timed out. (read timeout=60) ## Your question Unable to run any strategy because the freqtrade python library is missing? python3 Solipsis_v5.py Traceback (most recent call last): File ""Solipsis_v5.py"", line 3, in <module> import freqtrade.vendor.qtpylib.indicators as qtpylib ModuleNotFoundError: No module named 'freqtrade' pip install -e . Directory '.' is not installable. File 'setup.py' not found. [Log file](https://github.com/freqtrade/freqtrade/files/6557039/Freqtrade.log) "
128079,142347,https://api.github.com/repos/ManonMarizy/RentYourWilder/issues/3,enhancement,2021-02-03T11:26:52Z,OWNER,https://api.github.com/repos/ManonMarizy/RentYourWilder,US14-J'ai accès à une page donnant plus de détails sur un wilder - avatar - notes - description
281475,313029,https://api.github.com/repos/panzerdp/clipboardy/issues/3,enhancement,2016-03-25T12:31:15Z,NONE,https://api.github.com/repos/panzerdp/clipboardy,"Doesn't work on GitHub but works on StackOverflow Doesn't work on GitHub but works on StackOverflow Can't find why, how this can be solved? "
150177,166939,https://api.github.com/repos/rarangogi/git_web_practice/issues/2,bug,2021-02-15T00:56:41Z,NONE,https://api.github.com/repos/rarangogi/git_web_practice,"ISSUE 2: Corrección de páginas 1 y 4 ### Identificador de corrección: `FIX2` Recuerde actualizar el repositorio local (`git pull`) antes de continuar. ### Errores a corregir: - En `pagina1.html` y `pagina4.html`. Los links a las páginas siguientes apuntan a rutas equivocadas. ### Soluciones: - En `pagina1.html`, cambiar el link de navegación con id `enlace1` por `pagina2.html` y colocarle el nombre correcto `Mi segunda página HTML`. - En `pagina4.html`, cambiar el link de navegación con id `enlace4` por `pagina5.html` y colocarle el nombre correcto `Mi quinta página HTML`."
186691,207606,https://api.github.com/repos/yoshikazuendo/write-github-script/issues/11,bug,2021-05-02T07:16:12Z,NONE,https://api.github.com/repos/yoshikazuendo/write-github-script,"It's alive! ## Great Job so far! Like before, now we have to wait for the workflow to run so that we can see the results. <details> <summary>Workflow not running? Click here for some troubleshooting.</summary> Try the following troubleshooting steps: 1. Click on the [Actions tab](https://github.com/yoshikazuendo/write-github-script/actions) to see the status of your workflow run. See [Managing a workflow run](https://help.github.com/en/actions/configuring-and-managing-workflows/managing-a-workflow-run) on GitHub Help for more information. 1. Edit your [workflow file]( https://github.com/yoshikazuendo/write-github-script/edit/main/.github/workflows/my-workflow.yml) and look for errors in the linter built into the browser. 1. Look for the [workflow trigger](https://help.github.com/en/actions/reference/events-that-trigger-workflows) and ensure you are performing an action that triggers that workflow. If you need to make changes to your code, remove the [main branch protection](https://github.com/yoshikazuendo/write-github-script/settings/branches) and merge your changes into the `main` branch. </details> --- I'll respond here once it has completed! "
332735,369911,https://api.github.com/repos/Tedeapolis/development/issues/451,question,2021-03-09T10:19:46Z,CONTRIBUTOR,https://api.github.com/repos/Tedeapolis/development,KMAR - Comserv (burgerraad) **Beschrijf zo duidelijk mogelijk de feature** de vraag om toe te voegen dat de kmar /comserv en /endcomserv kunnen doen **Wat lost deze feature op?** De (h)OvJ's kunnen in hun zaken geen comserv gebruiken om de straf uit te delen als dit nodig is
3667,4100,https://api.github.com/repos/rauenzi/BetterDiscordApp/issues/692,bug,2021-04-11T13:25:16Z,NONE,https://api.github.com/repos/rauenzi/BetterDiscordApp,"[Bug] BetterDiscord does not start - Only showing ""Settings"" Tab **Describe the Bug** After installing, only the settings tab is available. Themes, Plugins, Custom CSS tabs etc do not appear and the BetterDiscord logo keeps flashing at the bottom right of Discord. **To Reproduce** Fresh install of Discord & Better Discord, through the BetterDiscord installer. **Expected Behavior** Simply that betterdiscord starts correctly. **Screenshots** ![image](https://user-images.githubusercontent.com/77465726/114305351-16bc8880-9ad8-11eb-898a-9376fb15cf2e.png) **Discord Version** Stable 81972 (9bccc1c) ![image](https://user-images.githubusercontent.com/77465726/114305309-f1c81580-9ad7-11eb-97fb-1ef3d0b343da.png) **Additional Context** I tried to reinstall Discord and BetterDiscord many times but I have always this problem. And the problem can't comes from my computer because I recently reset it. Besides, I already had this problem before I reset it."
252068,280377,https://api.github.com/repos/sanger/General-Backlog-Items/issues/154,bug,2021-05-21T09:09:46Z,MEMBER,https://api.github.com/repos/sanger/General-Backlog-Items,DPL-021 Bug - update date tested field **Describe the bug** Lighthouse lab uploaded plate map data with the incorrect `Date Tested` field. **RT Ticket Number** 719720 **To do:** - [x] write SQL query to update `lighthouse_sample` table @neilsycamore - [x] write mongo query to update `sample` collection @pjvv - [x] send email to notify about changes to be made @neilsycamore - [x] run on UAT and production MLWH @neilsycamore - [x] run on UAT and production mongo @pjvv 
564929,627816,https://api.github.com/repos/spencerwooo/onedrive-cf-index/issues/147,question,2021-03-30T16:30:08Z,NONE,https://api.github.com/repos/spencerwooo/onedrive-cf-index,"Help How to set password to protect base path only, not the file How to set password to protect base path only, not the file?"
435588,484234,https://api.github.com/repos/metersphere/metersphere/issues/1531,enhancement,2021-03-01T07:35:27Z,NONE,https://api.github.com/repos/metersphere/metersphere,[FEATURE]自动化场景在批量执行时，建议给个执行顺序，同时执行的话，对资源要求很高 **请描述您的需求或者改进建议.** **请描述你建议的实现方案**
702726,781003,https://api.github.com/repos/TimoBechtel/socketdb/issues/21,enhancement,2021-02-18T11:21:50Z,OWNER,https://api.github.com/repos/TimoBechtel/socketdb,"Always wait for server to confirm changes # what Wait for the server to confirm changes before saving it locally. # why Currently, when changing data (`delete/set`), that data will be stored locally before sending it to the server. This has the following benefits: - subscriptions (`once/on`) will be triggered instantly, so when used in a ui for example, changes will be applied immediately without the need to wait for the server - lower network overhead: the server does not need to send back data coming from a client, as the client already has that data (although, this is not implemented yet) However this solution has one major drawback: **What happens if the server rejects updates?** Let's say you write a plugin, that introduces a permission system. So when a user does not have permission to update data for a certain path, the server will not store that data. Now we either need to: - check permission on client side before sending, so the server does not need to reject in the first place - or: the server needs to send back an update that reverts the changes previously made Both solutions are not ideal, so instead I think the client should be rewritten, so that it will not store changes locally, except when coming from the server. So `set` will not trigger `on/once` directly anymore and instead `once/on` will be triggered only when the server has sent back the update. Also, it should always notify subscribers locally, and not check for differences first. To reduce network overhead (as the server now HAS to send updates back to the client), we might introduce a ""pending"" state on the client side: So updates are still stored locally, but in a pending state first. The server then only needs to send back a ""success"" or ""rejected"" message for the update. As soon as the client receives the confirmation, it will store the value locally and trigger the listeners. We might introduce a unique id for every update, so we can send update confirmations per update. "
177403,197239,https://api.github.com/repos/chomieu/Project-1/issues/25,enhancement,2020-12-22T20:04:26Z,COLLABORATOR,https://api.github.com/repos/chomieu/Project-1,ADD ability to auto-save after every voice recognition request / session. Save button on page would be for saving manual edits.
608159,675845,https://api.github.com/repos/cdr/code-server/issues/3355,bug,2021-05-11T18:34:12Z,NONE,https://api.github.com/repos/cdr/code-server,"Wrong symlink for `node_modules.asar` ## OS/Web Information - Web Browser: chrome - Local OS: Win 10 - Remote OS: Ubuntu Bionic (linuxserver docker) - Remote Architecture: x86_64 - `code-server --version`: 3.10.0 ## Steps to Reproduce 1. Install extension Bracket Pair Colorizer 2 2. Check the remote extension host log 3. ## Expected Should enable properly ## Actual Error message: ``` [2021-05-11 14:16:02.450] [exthost] [info] ExtensionService#_doActivateExtension CoenraadS.bracket-pair-colorizer-2 {""startup"":true,""extensionId"":{""value"":""CoenraadS.bracket-pair-colorizer-2"",""_lower"":""coenraads.bracket-pair-colorizer-2""},""activationEvent"":""*""} [2021-05-11 14:16:02.450] [exthost] [info] ExtensionService#loadCommonJSModule file:///config/extensions/coenraads.bracket-pair-colorizer-2-0.1.4/out/src/extension [2021-05-11 14:16:02.679] [exthost] [error] Activating extension CoenraadS.bracket-pair-colorizer-2 failed due to an error: [2021-05-11 14:16:02.679] [exthost] [error] Error: Cannot find module '/usr/local/share/.config/yarn/global/node_modules/code-server/lib/vscode/node_modules.asar/vscode-textmate' Require stack: - /config/extensions/coenraads.bracket-pair-colorizer-2-0.1.4/out/src/textMateLoader.js - /config/extensions/coenraads.bracket-pair-colorizer-2-0.1.4/out/src/settings.js - /config/extensions/coenraads.bracket-pair-colorizer-2-0.1.4/out/src/documentDecorationManager.js - /config/extensions/coenraads.bracket-pair-colorizer-2-0.1.4/out/src/extension.js - /usr/local/share/.config/yarn/global/node_modules/code-server/lib/vscode/out/vs/loader.js - /usr/local/share/.config/yarn/global/node_modules/code-server/lib/vscode/out/bootstrap-amd.js - /usr/local/share/.config/yarn/global/node_modules/code-server/lib/vscode/out/bootstrap-fork.js at Function.Module._resolveFilename (internal/modules/cjs/loader.js:815:15) at Function.Module._load (internal/modules/cjs/loader.js:667:27) at Function.i._load (/usr/local/share/.config/yarn/global/node_modules/code-server/lib/vscode/out/vs/workbench/services/extensions/node/extensionHostProcess.js:106:27950) at Function.S._load (/usr/local/share/.config/yarn/global/node_modules/code-server/lib/vscode/out/vs/workbench/services/extensions/node/extensionHostProcess.js:106:24660) at Function.a._load (/usr/local/share/.config/yarn/global/node_modules/code-server/lib/vscode/out/vs/workbench/services/extensions/node/extensionHostProcess.js:96:58822) at Module.require (internal/modules/cjs/loader.js:887:19) at require (internal/modules/cjs/helpers.js:74:18) at TextMateLoader.getNodeModule (/config/extensions/coenraads.bracket-pair-colorizer-2-0.1.4/out/src/textMateLoader.js:106:16) at TextMateLoader.loadTextMate (/config/extensions/coenraads.bracket-pair-colorizer-2-0.1.4/out/src/textMateLoader.js:109:21) at new TextMateLoader (/config/extensions/coenraads.bracket-pair-colorizer-2-0.1.4/out/src/textMateLoader.js:18:27) at new Settings (/config/extensions/coenraads.bracket-pair-colorizer-2-0.1.4/out/src/settings.js:10:31) at new DocumentDecorationManager (/config/extensions/coenraads.bracket-pair-colorizer-2-0.1.4/out/src/documentDecorationManager.js:9:25) at activate (/config/extensions/coenraads.bracket-pair-colorizer-2-0.1.4/out/src/extension.js:6:37) at Function._callActivateOptional (/usr/local/share/.config/yarn/global/node_modules/code-server/lib/vscode/out/vs/workbench/services/extensions/node/extensionHostProcess.js:92:14813) at Function._callActivate (/usr/local/share/.config/yarn/global/node_modules/code-server/lib/vscode/out/vs/workbench/services/extensions/node/extensionHostProcess.js:92:14486) at /usr/local/share/.config/yarn/global/node_modules/code-server/lib/vscode/out/vs/workbench/services/extensions/node/extensionHostProcess.js:92:12643 at processTicksAndRejections (internal/process/task_queues.js:97:5) at async Promise.all (index 2) at async Promise.all (index 0) ``` ## Logs See above ## Screenshot N/A ## Notes The issue seems to be that `node_modules.asar` is incorrectly symlinked when code-server is installed via yarn. ``` root@tower:/usr/local/share/.config/yarn/global/node_modules/code-server/lib/vscode# ls -al total 20 drwxr-xr-x 1 root root 150 May 10 19:46 . drwxr-xr-x 1 root root 46 May 10 19:45 .. drwxr-xr-x 1 root root 2024 May 10 19:48 extensions drwxr-xr-x 1 root root 2196 May 10 19:48 node_modules lrwxrwxrwx 1 root root 23 May 10 19:45 node_modules.asar -> lib/vscode/node_modules drwxr-xr-x 1 root root 318 May 10 19:45 out -rw-r--r-- 1 root root 5285 May 10 19:45 package.json -rw-r--r-- 1 root root 5947 May 10 19:45 product.json drwxr-xr-x 1 root root 16 May 10 19:45 resources ``` The symlink should point to `node_modules` and not `lib/vscode/node_modules` Fixing the symlink fixes the issue, the extension is activated properly. It seems PR #2197 attempted the symlink but perhaps incorrectly (did not dig into the code). This issue can be reproduced in VS Code: Not tested "
451697,502015,https://api.github.com/repos/crist074/docker-automation/issues/1,enhancement,2021-05-14T21:07:10Z,OWNER,https://api.github.com/repos/crist074/docker-automation,Add POST api tests Include POST api test cases in APITests.cs
14118,15723,https://api.github.com/repos/sampotts/plyr/issues/2024,bug,2020-11-20T02:09:46Z,NONE,https://api.github.com/repos/sampotts/plyr,"Double click fullscreen fail on plyr 3.6.3 ### Expected behaviour Go fullscreen when double clicked ### Actual behaviour Not go fullscreen, and throws error on console `Uncaught TypeError: this.enter is not a function` ### Steps to reproduce 1. go to plyr 3.6.3 player. example : [https://plyr.io](https://plyr.io) 2. double click / tap the player ### Environment happen everywhere i can test. - Browser: Chrome, Firefox, Edge - Version: Latest - Operating System: Windows, Android - Version: 10 ### Console errors (if any) Uncaught TypeError: this.enter is not a function ### Link to where the bug is happening https://plyr.io not happening in previous ver. "
104387,115990,https://api.github.com/repos/empus/armour/issues/52,enhancement,2020-04-13T01:08:44Z,OWNER,https://api.github.com/repos/empus/armour,Enhance list entries to support flags - noident: only match those with ~ in ident - onlykick: only kick matching blacklisted clients (do not place ban) - nochans: only match those who are seen in no other channels
704933,783475,https://api.github.com/repos/Kong/go-pdk/issues/48,enhancement,2020-12-15T18:07:49Z,NONE,https://api.github.com/repos/Kong/go-pdk,"Exposing prometheus metrics from a plugin Hello, We're using kong with custom plugins written in go to handle our authentication logic. We would like to monitor these plugins by exposing metrics in the prometheus plugin (we already have the prometheus plugin in place). I noticed that the prometheus plugin now exposes the internal prometheus object. [Relevant PR here.](https://github.com/Kong/kong-plugin-prometheus/pull/78) I was wondering if there's any way to access this prometheus object from within golang plugins to create our custom metrics. Thank you."
70353,78204,https://api.github.com/repos/QEDan/links_clustering/issues/2,question,2021-04-30T15:08:32Z,NONE,https://api.github.com/repos/QEDan/links_clustering,"Error while clustering the streaming audio data at higher hyperparameter values i.e. cluster_similarity_threshold, subcluster_similarity_threshold and pair_similarity_maximum. I am using [Resemblyzer](https://github.com/resemble-ai/Resemblyzer) to encode the streaming input audio coming from the microphone and using links clustering to cluster the audio embedding. At low values of hyperparams, I am getting underwhelming results (new cluster not being created even with the change in speaker). When hyper params are set to high values (say (0.7, 0.7, 0.7)) I am getting the following error: > Traceback (most recent call last): File ""C:\Users\e13356\Downloads\audio_analysis_online\audio_analysis_online_2\Resemblyzer\nono2.py"", line 156, in <module> main() File ""C:\Users\e13356\Downloads\audio_analysis_online\audio_analysis_online_2\Resemblyzer\nono2.py"", line 130, in main predicted_cluster = links_cluster.predict(vector) File ""C:\Users\e13356\Downloads\audio_analysis_online\audio_analysis_online_2\Resemblyzer\links_clustering\links_cluster.py"", line 96, in predict self.update_cluster(best_subcluster_cluster_id, best_subcluster_id) File ""C:\Users\e13356\Downloads\audio_analysis_online\audio_analysis_online_2\Resemblyzer\links_clustering\links_cluster.py"", line 180, in update_cluster raise ValueError(f""Connected subcluster of {sc_idx} "" ValueError: Connected subcluster of 0 was not found in cluster list of 0. I have the following questions: 1) How to resolve the aforementioned error. 2) How to efficiently tune the hyperparameters. (I tried going through the paper but didn't understand much) 3) Is there a better way to perform this whole operation. Here is my code: ``` import re import sys import numpy as np import pyaudio from six.moves import queue from resemblyzer import preprocess_wav, VoiceEncoder from pathlib import Path from links_clustering.links_cluster import LinksCluster import wave CHUNK = 16000 FORMAT = pyaudio.paInt16 CHANNELS = 2 RATE = 16000 RECORD_SECONDS = 20 WAVE_OUTPUT_FILENAME = ""voice.wav"" p = pyaudio.PyAudio() # Audio recording parameters RATE = 44100 CHUNK = int(RATE/10) # 100ms encoder = VoiceEncoder(""cpu"") links_cluster = LinksCluster(0.7, 0.7, 0.7) #LinksCluster(0.8, 0.7, 0.85) class MicrophoneStream(object): """"""Opens a recording stream as a generator yielding the audio chunks."""""" def __init__(self, rate, chunk): self._rate = rate self._chunk = chunk # Create a thread-safe buffer of audio data self._buff = queue.Queue() self.closed = True def __enter__(self): self._audio_interface = pyaudio.PyAudio() self._audio_stream = self._audio_interface.open( format=pyaudio.paInt16, # The API currently only supports 1-channel (mono) audio # https://goo.gl/z757pE channels=2, rate=self._rate, input=True, frames_per_buffer=self._chunk, # Run the audio stream asynchronously to fill the buffer object. # This is necessary so that the input device's buffer doesn't # overflow while the calling thread makes network requests, etc. stream_callback=self._fill_buffer, ) self.closed = False return self def __exit__(self, type, value, traceback): self._audio_stream.stop_stream() self._audio_stream.close() self.closed = True # Signal the generator to terminate so that the client's # streaming_recognize method will not block the process termination. self._buff.put(None) self._audio_interface.terminate() def _fill_buffer(self, in_data, frame_count, time_info, status_flags): """"""Continuously collect data from the audio stream, into the buffer."""""" self._buff.put(in_data) return None, pyaudio.paContinue def generator(self): while not self.closed: # Use a blocking get() to ensure there's at least one chunk of # data, and stop iteration if the chunk is None, indicating the # end of the audio stream. chunk = self._buff.get() if chunk is None: return data = [chunk] # Now consume whatever other data's still buffered. while True: try: chunk = self._buff.get(block=False) if chunk is None: return data.append(chunk) except queue.Empty: break yield b"""".join(data) def main(): with MicrophoneStream(RATE, CHUNK) as stream: audio_generator = stream.generator() print(audio_generator) for content in audio_generator: write_frame('WAVE_OUTPUT_FILENAME_{}.wav'.format(i), content) numpy_array = np.frombuffer(content, dtype=np.int16) wav = preprocess_wav(numpy_array) _, cont_embeds, wav_splits = encoder.embed_utterance(wav, return_partials=True, rate=16) for vector in cont_embeds: predicted_cluster = links_cluster.predict(vector) print(predicted_cluster) if __name__ == ""__main__"": main() ```"
528296,587174,https://api.github.com/repos/mishoo/UglifyJS/issues/4891,bug,2021-05-01T16:57:01Z,COLLABORATOR,https://api.github.com/repos/mishoo/UglifyJS,"ufuzz failiure ```js // original code // (beautified) var _calls_ = 10, a = 100, b = 10, c = 0; --b + (a++ + ~((/[a2][^e]+$/ ^ 23..toString(), ""bar"" % 1) < (a && (a.next = (NaN - 3) / (""b"" | /[a2][^e]+$/)))) || 3).toString()[--b + (3 in { static: delete a, then: b--, [a++ + (""b"" in { undefined: typeof a == ""function"" && --_calls_ >= 0 && a(a && a.Infinity), 1.5: [ a && typeof a.undefined == ""function"" && --_calls_ >= 0 && (a && a.Infinity, a.undefined)(), ..."""" + a ], ""\t"": typeof f1 == ""function"" && --_calls_ >= 0 && f1() })]: a++ + [ (c = c + 1) + (b = a), [ (c = c + 1) + +b ].null, function arguments_2() { ({ [(c = 1 + c, (0 * 0 >> (5 && this)) * (this & ""foo"" ^ 4 << NaN))]: (c = 1 + c, a += (25 >> undefined < (true || ""object"")) / (arguments_2 && (arguments_2.NaN += (2 <= NaN, this && Infinity)))) }).c; typeof undefined_2; }() ].c, done: false in [ a++ + a++, (c = c + 1) + { ""-2"": a++ + (({}, ""undefined"") >>> (4 ^ /[a2][^e]+$/) | (5 || true) ^ ""function"" % true), async: 38..toString() in [ --b + b++, a++ + [ (c = 1 + c, a && (a[c = 1 + c, (c = c + 1, [ , 0 ].length === 2) == 3 >>> ""bar"" === void (NaN & [ , 0 ][1])] += null >> -5) && this > -5, ([] || -2) && """" << 0), (c = 1 + c, 4 / -2 && ""undefined"" + true || void (23..toString() == true)), (c = 1 + c, a && (a.foo = (3 || ""a"") !== (a && ({ """": a.Infinity } = { """": null - 0 })) && !(0 * -0))) ][c = 1 + c, (-5 % 5 != (c = c + 1, 0)) * ((25 > ""c"") << (([ , 0 ].length === 2) >= /[a2][^e]+$/))], (c = c + 1) + /[a2][^e]+$/ ], [--b + (25 in { __proto__: b-- || {}, undefined: a++ + ~b, """": (c = c + 1) + ((a && (a.a += ""undefined"" !== NaN)) >>> {} / -1 <= ((c = c + 1, 3) >= 38..toString() >> -0)), set: typeof (c = 1 + c, (24..toString() && 1 || """" << this) >> +(([ , 0 ].length === 2) >= 38..toString())) })]: b ^= a }.length ], NaN: ++a })]; console.log(null, a, b, c, Infinity, NaN, undefined); ``` ```js // uglified code // (beautified) var n = 10, t = 100, i = 10, e = 0; --i, (t++ + (23..toString(), ~(NaN < (t && (t.next = (NaN - 3) / 0)))) || 3).toString()[--i + (3 in { static: delete t, then: i--, [t++ + (""b"" in { undefined: ""function"" == typeof t && 0 <= --n && t(t && t.Infinity), 1.5: [ t && ""function"" == typeof t.undefined && 0 <= --n && (t && t.Infinity, t.undefined)(), ..."""" + t ], ""\t"": ""function"" == typeof f1 && 0 <= --n && f1() })]: t++ + [ (e += 1) + t, [ (e += 1) + +t ][""null""], function f() { e = 1 + e, NaN, e = 1 + e, t += (25 >> undefined < !0) / (f && (f.NaN += (NaN, this && Infinity))); }() ].c, done: !1 in [ t++ + t++, (e += 1) + { ""-2"": 5 + t++, async: 38..toString() in [ --i + i++, t++ + [ (e = 1 + e, t && (t[e = 1 + e, 3 == (e += 1, 2 === [ , 0 ].length) === void NaN] += 0), 0), ""undefined"" + !0, (e = 1 + (e = 1 + e), t && (t.foo = 3 !== (t && ({ """": t.Infinity } = { """": 0 })) && !0)) ][e = 1 + e, (-0 != (e += 1, 0)) * (!1 << (/[a2][^e]+$/ <= (2 === [ , 0 ].length)))], (e += 1) + /[a2][^e]+$/ ], [--i + (25 in { __proto__: i-- || {}, undefined: t++ + ~i, """": (e += 1) + ((t && (t.a += ""undefined"" !== NaN)) >>> {} / -1 <= (e += 1, 38..toString() >> -0 <= 3)), set: (e = 1 + e, typeof ((24..toString() ? 1 : """" << this) >> +((2 === [ , 0 ].length) >= 38..toString()))) })]: i ^= t }.length ], NaN: ++t })], console.log(null, t, i, e, Infinity, NaN, undefined); ``` ``` original result: null NaN 101 14 Infinity NaN undefined uglified result: null NaN 5 14 Infinity NaN undefined ``` ```js // reduced test case (output will differ) // (beautified) var a = 0, b = 0; 0..toString[{ [0]: a++ + [ b = a, b ], done: { ""async"": 0..toString(), [{ __proto__: b--, """": a.a += 0 }]: 0 } }]; console.log(b); // output: 0 // // minify: -1 // // options: { // ""ie8"": true, // ""toplevel"": true, // ""mangle"": { // ""v8"": true // }, // ""output"": { // ""v8"": true // }, // ""validate"": true // } ``` ``` minify(options): { ""ie8"": true, ""toplevel"": true, ""mangle"": { ""v8"": true }, ""output"": { ""v8"": true } } Suspicious compress options: collapse_vars reduce_vars Suspicious options: toplevel ```"
668657,743188,https://api.github.com/repos/grayfallstown/Chia-Plot-Status/issues/33,enhancement,2021-05-11T19:51:53Z,NONE,https://api.github.com/repos/grayfallstown/Chia-Plot-Status,"Health based on file modification date If I understand correctly the health field bases it on the modification date of the log file and this should work in most cases. In my configuration the log file is written to a share on a nas, I don't know why but in this case the last modification date of the file always remains the same as the creation date. The program shows the alert (Dead?) when in reality the log is growing, couldn't you also base it on this aspect?"
563345,626047,https://api.github.com/repos/Plant-for-the-Planet-org/planet-webapp/issues/809,bug,2021-02-11T07:24:09Z,COLLABORATOR,https://api.github.com/repos/Plant-for-the-Planet-org/planet-webapp,Going back from single project should take the user to the previous page Going back from single project should take the user to the previous page instead of default home page. Visit any project page directly from some other page instead of the home page. (can be done in andalucia tenant or sat1 tenant). Use router.back function to achieve this. https://nextjs.org/docs/api-reference/next/router#routerback
622951,692279,https://api.github.com/repos/brandon-lind/kaky/issues/109,bug,2021-03-13T17:25:58Z,COLLABORATOR,https://api.github.com/repos/brandon-lind/kaky,Error when trying to update profile As a worker I tried to change my profile and this error stopped me: this.isWorker is not a function
149051,165691,https://api.github.com/repos/cli/cli/issues/2999,enhancement,2021-02-18T22:25:50Z,MEMBER,https://api.github.com/repos/cli/cli,"interactive select in gist view I'd like `gist view` (no arguments) to open a selectable list of the user's most recent 10 gists to avoid the `gist list`, copy, `gist view <pasted id>` flow. "
65227,72517,https://api.github.com/repos/weianofsteel/saliejung/issues/77,bug,2021-02-13T13:52:41Z,COLLABORATOR,https://api.github.com/repos/weianofsteel/saliejung,"Work/AgodaFlight: 更新最後一個段落 **Outcome** ### Introduce the Core Flight Feature to Customers After we launched the feature for A/B testing, over 16K users have interacted with it within one week. And we still look for more suppliers to join to offer more options. Although we reached a few people, we found only 5.02% of the users complete the flow for selecting seats. One assumption is that we place the ""done"" the CTA to finish the flow to the last segment on purpose. We force users to go through all the flight segments to increase the touchpoint that says some people might ignore it and fail to select the seats. Another assumption is that most of our bookings are domestic and low-cost carriers now. The need to choose seats are not crucial to customers. *Due to confidential restriction, please reach out for more details. ![image](https://user-images.githubusercontent.com/30551196/107851609-e17c1d00-6e3d-11eb-99d8-c46445709544.png) "
79501,88395,https://api.github.com/repos/LLNL/hiop/issues/109,bug,2020-11-18T20:13:06Z,COLLABORATOR,https://api.github.com/repos/LLNL/hiop,"sparse-develop branch lacking implementations of RAJA functions Branch `ci-cmake-fix#107` contains only fixes to CMake changes integrated into branch `develop`. Building branch `ci-cmake-fix#107` on newell produces: ``` /people/manc568/projects/hiop/src/LinAlg/hiopLinAlgFactory.cpp: In static member function ‘static hiop::hiopMatrixSparse* hiop::LinearAlgebraFactory::createMatr ixSparse(int, int, int)’: /people/manc568/projects/hiop/src/LinAlg/hiopLinAlgFactory.cpp:173:71: error: invalid new-expression of abstract class type ‘hiop::hiopMatrixRajaSparseTriplet’ return new hiopMatrixRajaSparseTriplet(rows, cols, nnz, mem_space_); ^ ``` Which appears to be an error independent from library discovery code. I believe this is because functions have been added to sparse matrix interface (such as `copyDiagMatrixToSubblock`) without RAJA implementations, therefor breaking all RAJA/Umpire code. This issue branches off of issue #107. CC @pelesh @cnpetra @nychiang "
569349,632722,https://api.github.com/repos/FourInchKnife/Minecraft-Server-Modpack/issues/29,enhancement,2021-05-16T23:23:27Z,OWNER,https://api.github.com/repos/FourInchKnife/Minecraft-Server-Modpack,Requiem Expansions Three epic mods that make Requiem better: https://www.curseforge.com/minecraft/mc-mods/requiem-pandemonium-expansion https://www.curseforge.com/minecraft/mc-mods/dark-rites-bewitchment-addon https://www.curseforge.com/minecraft/mc-mods/memento-mori-addon-for-requiem
184385,204995,https://api.github.com/repos/BlazorFluentUI/BlazorFluentUI/issues/254,bug,2021-01-05T07:02:41Z,NONE,https://api.github.com/repos/BlazorFluentUI/BlazorFluentUI,"Navigation vertical scrollbar issue Hi I'm currently playing around with your Demo Website and I noticed that the left navigation's vertical scrollbar was disappear when i lunch the program version 4.0.2,but we can see the scrollbar in the version 3.1.6 That is on the Server Side Demo Site. I haven't tested the wasm version so far."
138664,154121,https://api.github.com/repos/JessicaJeyanthiran/run-buddy/issues/2,enhancement,2021-03-07T18:27:03Z,OWNER,https://api.github.com/repos/JessicaJeyanthiran/run-buddy,"Contact Form for Reach Out Section # Contact Form for Reach Out Section ## Content Requirements * Heading: ""Contact Us"" * Name: Input Text field * Message: Large message area"
331606,368660,https://api.github.com/repos/knadh/listmonk/issues/362,question,2021-05-17T20:17:56Z,CONTRIBUTOR,https://api.github.com/repos/knadh/listmonk,"The ""default"" template is only the default half the time There are two completely different templates at play. They start out the same, but as soon as you change one it becomes apparent that the modified one is used sometimes, the original other times. The static file `email-templates/default.tpl` is used at the start and is what initially fills the database's idea of a ""default template."" Editing the database one will change the default for campaign emails. It will *not* change the default template used for subscribe messages, etc. For that you have to edit the static `email_templates/base.html`. Which is spiffy, but editing the static file doesn't update the database's default campaign template. The upshot is that to actually change the default template you have to update it it two places."
665055,739209,https://api.github.com/repos/10up/distributor/issues/689,question,2021-01-06T23:27:50Z,NONE,https://api.github.com/repos/10up/distributor,"External Connection I have 2 different subdomains (site1: learning.sitename.com and site 2: employee.sitename.com) that I am trying to connect. External connections on both sites use /wp-json U/P is the primary admin in profile page User is admin on both sites I am getting the following message External Connection URL http://learning.sitename.com/wp-json Limited connection established. Authentication failed due to invalid credentials. Push distribution unavailable. Pull distribution limited to basic content, i.e. title and content body. I have reviewed all the posts about how to fix this issue and can not figure out a solution. Can someone provide me some guidance please "
637227,708205,https://api.github.com/repos/aissat/easy_localization/issues/241,enhancement,2020-08-27T09:07:48Z,NONE,https://api.github.com/repos/aissat/easy_localization,Logger issue Could you add an option to disable standard logging? ``` [Easy Localization] Start [Easy Localization] Init state [Easy Localization] Build [Easy Localization] Saved locale loaded en_GB [Easy Localization] Load asset from assets/locales [Easy Localization] Init Localization Delegate [Easy Localization] Init provider ``` Add either `bool enableLogging` or `Function(String message) onLog` so that I can decide how to do the logging.
539837,600012,https://api.github.com/repos/m4reko/soffan-group16-a2/issues/2,enhancement,2021-02-08T15:57:27Z,COLLABORATOR,https://api.github.com/repos/m4reko/soffan-group16-a2,Integrate Travis-CI Add Travis-CI functionality to this repository.
21871,24343,https://api.github.com/repos/exoscoriae/eXoWin3x/issues/10,bug,2020-12-04T12:02:02Z,COLLABORATOR,https://api.github.com/repos/exoscoriae/eXoWin3x,"S.T.O.R.M. (1996) Now that the game uses ECE the change disk user message needs to change from ""ctrl-F3"" to ""ctrl-F4"""
574817,638772,https://api.github.com/repos/touchtypie/touchtypie/issues/90,enhancement,2021-05-18T22:18:47Z,MEMBER,https://api.github.com/repos/touchtypie/touchtypie,Student response unfocused when switching back from environment scene ## Current Student response unfocused when switching back from environment scene ## Expectation Student response focused when switching back from environment scene
351761,391065,https://api.github.com/repos/QLSCO/ProjectAlpha/issues/23,enhancement,2021-04-23T16:22:38Z,MEMBER,https://api.github.com/repos/QLSCO/ProjectAlpha,Align GPA labels with the top The GPA label(i.e. The unweighted GPA: ) should be aligned with the top of the div in stead of the center. That way users can interact with the app without having to scroll down. 
651564,724286,https://api.github.com/repos/nonlinear-labs-dev/C15/issues/2548,enhancement,2021-04-06T16:47:27Z,MEMBER,https://api.github.com/repos/nonlinear-labs-dev/C15,"MIDI Settings - Mappings: Weitere Einträge für ""None"" und 7-Bit-Controller (s.u.) Jedes der acht Menüs bekommt am Anfang den Eintrag ""None"". Jeden Eintrag der Form ""CC nn (LSB: CC mm)"" sollten wir ersetzen durch solche zwei Einträge: CC nn CC nn + CC mm (LSB) Damit haben User, die bereits viele CCs belegt haben, die Möglichkeit, Konflikte mit unseren LSB-CCs zu vermeiden, haben dann natürlich nur noch eine 7-Bit-Auflösung. Die Einstellungen wirken identisch für Send und Receive. Die Listen werden ziemlich lang, aber die angezeigte Belegung sieht sauber aus."
461385,512773,https://api.github.com/repos/divanov11/Mumble/issues/131,enhancement,2021-04-04T01:05:54Z,COLLABORATOR,https://api.github.com/repos/divanov11/Mumble,"Toggle Comment Button The comment button should probably hide / show a comment textarea & button near the comment you are trying to reply to, ![Screen Shot 2021-04-03 at 9 04 36 PM](https://user-images.githubusercontent.com/1868782/113495499-35ab9100-94c0-11eb-855d-391ef5a5e27a.png) "
544643,605364,https://api.github.com/repos/pytorch/fairseq/issues/3213,question,2021-02-04T09:52:36Z,NONE,https://api.github.com/repos/pytorch/fairseq,"Loading mBART checkpoint for multilingual translation I am trying to load the mBART checkpoint to perform multilingual translation as suggested [here](https://github.com/pytorch/fairseq/tree/master/examples/multilingual#training). When the program attempts to load the pre-trained checkpoint, it gives the following error. ``` Traceback (most recent call last): File ""/local/wasiahmad/software/anaconda3/bin/fairseq-train"", line 33, in <module> sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')()) File ""/home/wasiahmad/workspace/fairseq/fairseq_cli/train.py"", line 348, in cli_main distributed_utils.call_main(args, main) File ""/home/wasiahmad/workspace/fairseq/fairseq/distributed_utils.py"", line 187, in call_main main(args, **kwargs) File ""/home/wasiahmad/workspace/fairseq/fairseq_cli/train.py"", line 106, in main extra_state, epoch_itr = checkpoint_utils.load_checkpoint(args, trainer) File ""/home/wasiahmad/workspace/fairseq/fairseq/checkpoint_utils.py"", line 137, in load_checkpoint reset_meters=args.reset_meters, File ""/home/wasiahmad/workspace/fairseq/fairseq/trainer.py"", line 252, in load_checkpoint state = checkpoint_utils.load_checkpoint_to_cpu(filename) File ""/home/wasiahmad/workspace/fairseq/fairseq/checkpoint_utils.py"", line 169, in load_checkpoint_to_cpu f, map_location=lambda s, l: default_restore_location(s, ""cpu"") File ""/local/wasiahmad/software/anaconda3/lib/python3.6/site-packages/torch/serialization.py"", line 592, in load return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args) File ""/local/wasiahmad/software/anaconda3/lib/python3.6/site-packages/torch/serialization.py"", line 852, in _load result = unpickler.load() File ""/local/wasiahmad/software/anaconda3/lib/python3.6/site-packages/torch/serialization.py"", line 844, in persistent_load load_tensor(data_type(size), size, key, _maybe_decode_ascii(location)) File ""/local/wasiahmad/software/anaconda3/lib/python3.6/site-packages/torch/serialization.py"", line 830, in load_tensor tensor_file = io.BytesIO(size_long + zip_file.get_record(name)) RuntimeError: [enforce fail at inline_container.cc:143] . PytorchStreamReader failed reading file data/94565435476624: file read failed ``` Environment: ``` Name: fairseq, Version: 0.9.0 Name: torch, Version: 1.5.1 ``` I tried to load the checkpoints by simply running the following python code snippet and it works. ``` path='path2checkpoint' saved_params = torch.load( path, map_location=lambda storage, loc: storage ) ``` But when I try to load the mBART or CRISS model checkpoint with fairseq-train (using --restore-file), I get the above error. "
597701,664248,https://api.github.com/repos/telerik/kendo-angular/issues/2261,bug,2019-05-15T09:11:35Z,CONTRIBUTOR,https://api.github.com/repos/telerik/kendo-angular,"Menu is not closed when blurred **Describe the bug** When using iOS and we open the Menu, then it is not closed if it is blurred. **To Reproduce** Use the basic usage example: https://www.telerik.com/kendo-angular-ui/components/menus/menu/#toc-menu-overview 1. Open the Menu. 2. Try to blur the menu. "
496957,552349,https://api.github.com/repos/Fammeo/Fammeo/issues/380,bug,2021-02-19T05:48:40Z,NONE,https://api.github.com/repos/Fammeo/Fammeo,"Click Days should not go to home page ### When user click on days it goes to the home page, it clouds not happened, please remove the click event of days in service details ![image](https://user-images.githubusercontent.com/77724114/108463266-10fab180-72a4-11eb-855b-f80bdf304c93.png) "
403065,447998,https://api.github.com/repos/PluginBugs/Issues-ItemsAdder/issues/782,bug,2021-03-24T18:44:42Z,NONE,https://api.github.com/repos/PluginBugs/Issues-ItemsAdder,"[BUG] ChatControlRed channels emoji broken Hello, Emojis do not work with ChatControlRed using plugin channels. But it works when I turn them off and use basic chat. I am using ItemsAdder 2.2.5 and ChatControlRed 10.3.1. I am under PaperSpigot 1.16.5 - 565. I have had this problem for several weeks. I have already contacted the developer of ChatControlRed and told me to direct me to you. The link to the request is attached: https://github.com/kangarko/ChatControl-Red/issues/830 Tylwen"
165719,184245,https://api.github.com/repos/tresorone/tresor-import/issues/1395,bug,2021-01-31T17:36:29Z,COLLABORATOR,https://api.github.com/repos/tresorone/tresor-import,"[Consorsbank] Diese Datei wird nicht importiert ## Description > Diese Datei wird nicht importiert - hilf uns, den Import zu verbessern 👉 KAUF_878367267_ord121048098_001_wknA0D8Q4_dat20180108_id670209969.pdf ## Document <details><summary>KAUF_878367267_ord121048098_001_wknA0D8Q4_dat20180108_id670209969.pdf</summary><p> ```json [ [ ""Consorsbank ist eine eingetragene Marke der BNP Paribas S.A. Niederlassung Deutschland."", ""Standort Nürnberg: Bahnhofstraße 55, 90402 Nürnberg, HRB Nürnberg 31129, USt-IdNr. DE191528929"", ""Fon +49 (0) 911 / 369-30 00, Fax +49 (0) 911 / 369-10 00, info@consorsbank.de, www.consorsbank.de"", ""Sitz der BNP Paribas S.A.: 16, boulevard des Italiens, 75009 Paris, Frankreich, Registergericht: R.C.S. Paris 662 042 449"", ""Président du Conseil d‘Administration (Präsident des Verwaltungsrates): Jean Lemierre, Directeur Général (Generaldirektor): Jean-Laurent Bonnafé"", ""Consorsbank • 90318 Nürnberg"", ""ORDERABRECHNUNG"", ""KAUF"", ""AM 08.01.2018"", ""UM"", ""09:04:05"", ""XETRA FRANKFURT"", """", """", """", """", """", ""Depotnummer"", """", """", ""Vermerk der Bank"", ""1000"", ""02"", ""Hinweis für Orderabrechnungen und Depotbuchungsanzeigen:"", ""Einwendungen wegen Unrichtigkeit oder Unvollständigkeit dieser Mitteilung müssen unverzüglich erhoben werden, vgl. Nummer B. Ziffer I. 11 (4) und (5) der"", ""Allgemeinen Geschäftsbedingungen (AGB Banken)."", ""Machen Sie Ihre Einwendungen in Textform geltend, genügt die Absendung innerhalb der Sechs-Wochen-Frist an die Consorsbank (Revision) oder per Fax oder"", ""Mail an die unten angegebenen Adressen. Das Unterlassen rechtzeitiger Einwendungen gilt als Genehmigung."", ""Bezeichnung"", ""WKN"", ""ISIN"", ""IS.DJ U.S.SELEC.DIV.U.ETF"", ""A0D8Q4"", ""DE000A0D8Q49"", ""Einheit"", ""Umsatz"", ""ST"", ""16,00000"", ""Kurs"", ""58,420000"", ""EUR"", ""P.ST."", ""Kurswert"", ""EUR"", ""934,72"", ""Börsenplatzgebühr"", ""EUR"", ""1,50"", ""Provision"", ""EUR"", ""5,00"", ""Grundgebühr"", ""EUR"", ""4,95"", ""Wert 10.01.2018"", ""EUR"", ""946,17"", """", ""Bestand zugunsten Girosammelverwahrung"", """" ] ] ``` </p></details> --- Issue submitted with https://import.tresor.one"
396034,440169,https://api.github.com/repos/blaqkube/mysql-operator/issues/146,enhancement,2021-01-22T07:08:03Z,OWNER,https://api.github.com/repos/blaqkube/mysql-operator,"Add an Operation API to handle complex operations ## Is your feature request related to a problem? Please describe We need to be able to schedule operations like a restart of the StatefulSet to upgrade MySQL or a change to the parameters that also require a restart of the instance. This is also useful to upgrade the agent or the exporter. We want those operations to show up as scheduled and be executed as part of the maintenance Window. ## Describe the solution you'd like Add an Operation API and add an admission webhook to prevent users from using them. ## Describe alternatives you've considered We could have added the data directly to the Instance.Status but there are many concern with that, including compatibility way more complex to maintain. ## Note This depends on #144 "
580261,644800,https://api.github.com/repos/pjnalls/Angularization/issues/27,enhancement,2021-02-18T17:19:35Z,OWNER,https://api.github.com/repos/pjnalls/Angularization,Document generating `get-really-good-at-js` [(GRG@JS...?) Working Project Title] from within root of the repo with Angular CLI Here's a great blog post by the Angular team about strict mode and why you should opt into it when prompted by Angular CLI: https://blog.angular.io/with-best-practices-from-the-start-d64881a16de8
359609,399795,https://api.github.com/repos/blaec/movie-library/issues/44,enhancement,2021-05-21T17:54:51Z,OWNER,https://api.github.com/repos/blaec/movie-library,use redux toolkit cleared on page reload - can keep it in local storage
528851,587794,https://api.github.com/repos/BlackArch/blackarch/issues/2969,bug,2021-01-04T04:12:18Z,MEMBER,https://api.github.com/repos/BlackArch/blackarch,"Broken tool: CMSScanner - [x] I have searched open and closed issues for duplicates - [x] I am submitting a bug report for existing functionality that does not work as intended ---------------------------------------- ### Bug description Describe here the issue that you are experiencing. CMSScanner fails during upgrade process Traceback: ``` ( 573/2283) upgrading cmsscanner [######################] 100% [DEPRECATED] The `--path` flag is deprecated because it relies on being remembered across bundler invocations, which bundler will no longer do in future versions. Instead please use `bundle config set --local path 'vendor/bundle'`, and stop using this flag Don't run Bundler as root. Bundler can ask for sudo if it is needed, and installing your bundle as root will break this application for all non-root users on this machine. Fetching gem metadata from https://rubygems.org/......... Fetching gem metadata from https://rubygems.org/. Resolving dependencies... Bundler could not find compatible versions for gem ""rspec-core"": In snapshot (Gemfile.lock): rspec-core (= 3.9.2) In Gemfile: rspec (~> 3.10.0) was resolved to 3.10.0, which depends on rspec-core (~> 3.10.0) rspec-its (~> 1.3.0) was resolved to 1.3.0, which depends on rspec-core (>= 3.0.0) Running `bundle update` will rebuild your snapshot from scratch, using only the gems in your Gemfile, which may resolve the conflict. ``` "
156336,173819,https://api.github.com/repos/KnuckleCracker/CW4-bug-tracker/issues/768,bug,2021-02-27T15:36:23Z,CONTRIBUTOR,https://api.github.com/repos/KnuckleCracker/CW4-bug-tracker,Deleting a unit from a ui callback produces and exception InvalidOperationException: Collection was modified; enumeration operation may not execute Happens if a UI button deletes one or more selected custom units.
495120,550317,https://api.github.com/repos/Sage/carbon/issues/3532,bug,2021-01-04T11:53:08Z,NONE,https://api.github.com/repos/Sage/carbon,"Placeholder text for default select component is darker than placeholder text for multiselect and filterable select components ### Current behaviour <!-- The placeholder ""Please Select..."" text that is displayed by default for a select component appears to be a darker shade of grey when compared to the placeholder text that is displayed by the MultiSelect or Filterable Select components --> ### Expected behaviour Would expect the default styling for the placeholder text to be identical for all 3 components ### Reproducible example Difference can be seen in storybook examples: - Default/Single Select: https://carbon.sage.com/?path=/story/design-system-select--basic - MultiSelect: https://carbon.sage.com/?path=/story/design-system-select-multiselect--basic - Filterable: https://carbon.sage.com/?path=/story/design-system-select-filterable--basic ### Your environment <!-- PLEASE FILL THIS OUT --> | Software | Version(s) | | ---------------- | ---------- | | carbon-react | v54.3.4 | "
43986,48965,https://api.github.com/repos/Spessman-Incorporated/Spessman/issues/3,enhancement,2021-02-26T15:39:27Z,CONTRIBUTOR,https://api.github.com/repos/Spessman-Incorporated/Spessman,"Character ragdoll controller ### Description Create a ragdoll controller that comports all kinds of ragdolls, have it use a _bool_ to control ragdolling and make sure its **networked**. - Create character ragdoll - Create ragdoll manager - Make character ragdoll. - Add an impulse force based on **CharacterMovement**.**_currentMovement_** when ragdolled while walking. ### Media ### Related issues ### Problems "
249279,277273,https://api.github.com/repos/outline/outline/issues/1017,enhancement,2019-08-12T16:17:51Z,NONE,https://api.github.com/repos/outline/outline,"Read-only Access for Collections Hi @tommoor, Thanks a ton for all your doing on this project. We have a self-hosted version of Outline running on Heroku. I know there was a discussion about collection permissions ( #668 ), but I'm having a hard time finding a way to change a user to read-only access on a collection. Is this a current feature? We have a couple of collections that we want users to be able to read but not edit. "
203922,226735,https://api.github.com/repos/felangel/bloc/issues/2182,question,2021-03-02T11:45:12Z,NONE,https://api.github.com/repos/felangel/bloc,"BlocListener listens after the route has been popped Hi Felix, This is the reproduction code https://gist.github.com/aliyazdi75/a273a2e2306126acfc5b3a6a495b40ba and there is a `BlocListener` on the Dialog page. After the Dialog page has been poped, `BlocListener` still listens on state changes. Is that an expected behavior? Actual output: ``` I/flutter ( 5401): hi Felix :) I/flutter ( 5401): Also me Should not print! ``` Expected output: ``` I/flutter ( 5401): hi Felix :) ```"
355623,395356,https://api.github.com/repos/PyCQA/pylint/issues/3536,enhancement,2020-04-28T13:20:01Z,NONE,https://api.github.com/repos/PyCQA/pylint,"arguments-differ is triggered if just arg names changed ```python class fruit: def _do_actions(self, fruit_name: str): pass class orange(fruit): def _do_actions(self, orange_name: str): # will trigger arguments-differ pass ``` I think we should differentiate errors: 1. `arguments-differ` if something changed except the names (i.e., number of args, their types, or args become kwargs, or so.). 2. a new error: `arguments-renamed` should be raised only if a name was changed. But arguments changed in a way that old arguments change their positions (i.e. swapped) `arguments-differ` should be raise anyway: ```python class fruit: def xxx(self, a: str, b: str): pass class orange(fruit): def xxx(self, b: str, a:str): # MUST trigger arguments-differ pass ``` Rationale: If I just add `# pylint: disable=arguments-differ` it would hide other arguments-related errors in this line. As a workaround I can write something like: ```python class orange(fruit): def _do_actions(self, fruit_name: str): # will trigger arguments-differ super()._do_actions(fruit_name) orange_name = fruit_name # use orange_name in the code. ``` but this is slightly stupid. I would not like to do such a trick just to silence the linter. "
262660,292115,https://api.github.com/repos/SMUnlimited/AMAI/issues/28,question,2021-02-01T10:11:24Z,NONE,https://api.github.com/repos/SMUnlimited/AMAI,"Unable to download Heyo! Thank you for the work put in this. I am unable to install the bat. file into the files. Whenever I click on it or use the command prompt, it opens and closes almost immediately. (Have 0 programming experience)"
558524,620742,https://api.github.com/repos/scantnik/Scantnik2021/issues/2,bug,2021-04-01T22:01:12Z,COLLABORATOR,https://api.github.com/repos/scantnik/Scantnik2021,La conversión a Pascales está mal hecha // Conversion to Pascals is wrong La conversión a Pascales está mal hecha // Conversion to Pascals is wrong _Originally posted by @Xabier41 in https://github.com/scantnik/Scantnik2021/issues/1#issuecomment-812009405_
220423,245126,https://api.github.com/repos/tauri-apps/tauri/issues/1390,bug,2021-03-25T11:52:30Z,NONE,https://api.github.com/repos/tauri-apps/tauri,"Is there any api for removing listener? I'm using js api `event.listen` for function callbacks, and I just found that when I refresh my page (in tour window) the listener repeats, is there an api for removing an event listener in js? Thanks. ![image](https://user-images.githubusercontent.com/2951879/112468644-7c540980-8da3-11eb-8d9d-bd127e97082c.png) "
99951,111066,https://api.github.com/repos/ESinclair81/Make-A-Read-Me/issues/4,enhancement,2021-02-11T20:43:46Z,OWNER,https://api.github.com/repos/ESinclair81/Make-A-Read-Me,Generate Markdown of ReadME • Output Data to Markdown File
564816,627691,https://api.github.com/repos/WPS/domain-story-modeler/issues/76,bug,2020-02-12T14:04:12Z,NONE,https://api.github.com/repos/WPS/domain-story-modeler,Safe/Load error **Describe the bug** We ran into a bug while saving/loading the .dst file. It seems that at some point information of the model is lost. When loading the save file an error message appears and half of the model is gone. We had the original page still open so we tried multiple times to save with the same result. **To Reproduce** The according .dst file is attached (as txt). [wps_modeler.dst.txt](https://github.com/WPS/domain-story-modeler/files/4192689/wps_modeler.dst.txt) Steps to reproduce the behavior: 1. Go to www.wps.de/modeler 2. Click on import file 3. Select the attached .dst file 4. See error message **Screenshots** This is how it should look: ![image](https://user-images.githubusercontent.com/60971646/74339624-bf703a80-4da4-11ea-985d-d51910dd3ee2.png) This is the error: ![image](https://user-images.githubusercontent.com/60971646/74340696-aa94a680-4da6-11ea-8417-62497f8b4748.png) This is how it looks: ![image](https://user-images.githubusercontent.com/60971646/74340740-c5ffb180-4da6-11ea-98cf-c5fb80c9ed29.png) **Desktop:** - Modeler Version: v1.0.0 - Browser: Chrome 79.0.3945.130 64Bit - OS: Windows 10 **Additional context** It seems that the browserversion or the project itself is causing the error. We worked with another browser (Chrome 80.0.3987.100) on a different project and hat no problems. 
219706,244310,https://api.github.com/repos/chengkangzai/eatwhat/issues/11,enhancement,2020-08-24T09:39:56Z,OWNER,https://api.github.com/repos/chengkangzai/eatwhat,Feature :: Find Food by team 1. Implement user role 2. Implement firebase rule by user role https://firebase.google.com/docs/firestore/security/insecure-rules#role-based-access Role as below 1. Team Owner 2. Project Owner (Feedback management) 3. Normal user
602343,669394,https://api.github.com/repos/Azure/aks-engine/issues/4318,bug,2021-03-09T15:53:59Z,NONE,https://api.github.com/repos/Azure/aks-engine,"unable to connect to K8S self-managed cluster (hosted on Azure Stack ) after nodes shutdown from portal **We encountered a problem to access the K8S Cluster after the shutdown of VMs from the portal, bellow the error: The connection to the server X.X.X.X was refused - did you specify the right host or port? We have already done the Export of the kubeconfig file, but the problem persist always **Steps To Reproduce** - We deployed API model with AKS Engine on Azure Stack - We exported the kubeconfig and we were able to manage our cluster - Shutdown the VMs from the portal **Expected behavior** We should connect properly to the cluster **AKS Engine version** v0.55.4 **Kubernetes version** 1.17.11 Is there a way to shutdown properly the K8S Cluster without the need to redeploy the entire cluster? We can't keep the VMs running all the time "
598340,664949,https://api.github.com/repos/Stardust-Discord/Octave/issues/67,bug,2020-10-21T15:51:28Z,NONE,https://api.github.com/repos/Stardust-Discord/Octave,"it is not showing the music that is playing when you do_play —— **Describe the bug** A clear and concise description of what the bug is. **To Reproduce** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected behavior** A clear and concise description of what you expected to happen. **Screenshots** If applicable, add screenshots to help explain your problem. **Additional context** Add any other context about the problem here. "
136286,151488,https://api.github.com/repos/EHDEN/CatalogueExport/issues/27,bug,2021-02-02T16:45:50Z,NONE,https://api.github.com/repos/EHDEN/CatalogueExport,"errorReportSql.txt file: intermediate errors are overwritten **Describe the bug** The bug was also discussed here: https://github.com/OHDSI/DatabaseConnector/issues/132 If an error is generated by the DatabaseConnector::executeSql() function, the SQL error is written in a file (""errorReportSql.txt"" by default) with an opening mode ""w+"". When a tryCatch statement is used to handle the error; the DatabaseConnector::executeSql() function overwrites the previous error so intermediate errors are overwritten and lost. ```R tryCatch({ DatabaseConnector::executeSql(connection = connection, sql = mainSql$sql) # for example here delta <- Sys.time() - start ParallelLogger::logInfo(sprintf(""[Main Analysis] [COMPLETE] %d (%f %s)"", as.integer(mainSql$analysisId), delta, attr(delta, ""units""))) }, error = function(e) { ParallelLogger::logError(sprintf(""Analysis %d -- ERROR %s"", mainSql$analysisId, e)) }) ``` "
647223,719395,https://api.github.com/repos/Waiviogit/waivio/issues/2518,bug,2021-04-23T11:30:04Z,COLLABORATOR,https://api.github.com/repos/Waiviogit/waivio,"Throws to the top, when scrolling the blog **Severity**: Minor **Steps to reproduce**: 1. Open the object https://waiviodev.com/object/xnm-formal-city-bar-with-apples6e5fy9-/blog/@waivio_diana-ch 2. Scroll posts **Expected result**: Smooth scrolling of all posts **Actual result**: Throws to the top, when scrolling the blog https://user-images.githubusercontent.com/67378322/115864992-5e300680-a440-11eb-877f-063bd7a67d8d.mp4 "
357366,397279,https://api.github.com/repos/sairish2001/makesmatheasy.github.io/issues/106,bug,2021-03-11T15:10:53Z,OWNER,https://api.github.com/repos/sairish2001/makesmatheasy.github.io,"Copyright text is overlapping the SideNav ![image](https://user-images.githubusercontent.com/60106112/110808313-dd5ee600-82a9-11eb-97e3-ed562aac695e.png) It must be at the last of Sidenav, with smaller font-size"
197224,219284,https://api.github.com/repos/TheUltimateC0der/Deemixrr/issues/3,enhancement,2020-09-10T21:47:29Z,NONE,https://api.github.com/repos/TheUltimateC0der/Deemixrr,"Database support I was about to start setting this up when I noticed that the example docker-compose.yml uses MSSQL as its storage engine. Coming from an open source background I would expect this to either use mysql/mariadb, or even sqlite. I will admit, I'm biased against MS based products, and would assume the motivation might be familiarity? If there is a performance or feature related argument I would be glad to be educated. MySQL: Probably an industry standard for many open source projects, likely to already be running on a host machine MariaDB: Same as above, somewhat better performance and other perks. Sqlite: Lightweight, can save into main config directory, no dependencies on other images (most of my other services use something like this) Postgres: Better performance I believe, I'm no expect on it but some admins prefer it Flat files: Depends on what you are storing, if it is a config file with credentials and a list of artists maybe the DB isn't even a necessary tool? Often with tools like this, you see the default storage engine sqlite/flat files, with the option for a more performant database for advanced users. I'm still considering using this tool as-is, but currently have two options: 1. Take the MSSQL requirement, knowing it will run but have reservations and an icky feeling in the back of my mind 2. Try to point it at an existing MySQL container, cross my fingers and hope it works."
292746,325537,https://api.github.com/repos/lgarzonr/git_web_practice/issues/1,bug,2021-02-10T00:53:33Z,NONE,https://api.github.com/repos/lgarzonr/git_web_practice,"ISSUE 1: Corrección de páginas 5 y 3 ### Identificador de corrección: `FIX1` ### Errores a corregir: - En `pagina5.html`. La imagen y el título de la página no corresponden. - En `pagina3.html`. El link a la página siguiente apunta a una dirección equivocada. ### Soluciones: - En `pagina5.html`, cambiar la ruta de la imagen con id `imagen5` por `../imagenes/BD5.gif` y el texto del título con id `titulo5` por `Mi quinta página HTML`. - En `pagina3.html`, cambiar el link de navegación con id `enlace3` por `pagina4.html` y colocarle el nombre correcto `Mi cuarta página HTML`."
536672,596471,https://api.github.com/repos/department-of-veterans-affairs/va.gov-team/issues/18926,bug,2021-01-25T16:15:25Z,CONTRIBUTOR,https://api.github.com/repos/department-of-veterans-affairs/va.gov-team,"Find a VA Form [BUG] - Invalid character in VA DB PDF URL is causing ""not found"" error. ## What happened? When attempting to download the PDF for VA Form 10-3888, a message appears saying the form is not found. Currently, https://www.va.gov/find-forms/about-form-10-0388/ download PDF link is: https://www.va.gov/vaforms/medical/pdf/10-0388%cover.pdf. The URL needs to be corrected in the VA Forms DB by the VA Forms managers. ## Specs: - Device: Any - Browser: Any - Test User: N/A ## Steps to Reproduce - URL: https://www.va.gov/find-forms/about-form-10-0388/, then click on the **Download VA Form 10-0388 (PDF)** link - Test User _(if applicable)_: N/A ## Desired behavior - When the **Download VA Form 10-0388 (PDF)** is clicked, the applicable VA form should be downloaded. ## Acceptance Criteria - When the **Download VA Form 10-0388 (PDF)** is clicked, the applicable VA form should be downloaded. ## How to configure this issue - [ ] **Attached to a Milestone** (when will this be completed?) - [ ] **Attached to Epic** (what body of work is this a part of? possibly `Ongoing Maintenance`) - [ ] **Labeled with Team** (`product support`, `analytics-insights`, `operations`, `triage`, `tools-improvements`) - [ ] **Labeled with Practice Area** (`backend`, `frontend`, `devops`, `design`, `research`, `product`, `ia`, `qa`, `analytics`, `contact center`, `research`, `accessibility`, `content`) - [ ] **Labeled with `Bug`** "
746,826,https://api.github.com/repos/luc-github/ESP3D/issues/545,bug,2020-12-20T18:30:09Z,NONE,https://api.github.com/repos/luc-github/ESP3D,"[BUG] Asking for printer configuration on an ESP3D-flashed SonOff turns the SonOff off In ""Smoothieware target"" mode, with ESP3D running on a Sonoff device that controls the power of the 3D printer, asking for the printer configuration turns the printer off, making the configuration data useless (it cannot be saved onto the printer). **To Reproduce** Steps to reproduce the behavior: 1. Turn the Sonoff ON using [ESP201]P12 V1 2. Click on ESP3D ""Printer tab"" 3. Clink on the Printer configuration ""button"" 4. The printer turns off (the configuration cannot be saved) **Expected behavior** Asking for the printer configuration should not change the GPIOs (especially GPIO 12). **ESP3D Firmware:** No firmware change, the issue has been there for quite a time. SDK: 2.2.1(cfd48f3) FW version: 2.1.1.b7 ESP8266/8586 WebUI version: 2.1b68 **Target Firmware:** - Smoothieware - Smoothie Build version master-1089498NOMSD, Build date Dec 15 2016 12:45:49 **Board used (please complete the following information):** - MCU: ESP8266 - Name: Plain Sonoff device - Flash size:1M - Available Size for update: 502.17 KB(Ok) - Available Size for SPIFFS: 125.25 KB "
603331,670494,https://api.github.com/repos/hartwork/wnpp.debian.net/issues/6,enhancement,2020-04-06T23:38:18Z,NONE,https://api.github.com/repos/hartwork/wnpp.debian.net,"Support query parameter “reporter” This is a feature request. For example I would like to check all requests I reported. It already has a “Reporter” field so this feature seems practical. As a stretch goal, maybe we can have one more parameter called `age-range` accepting values like `20-100`, or half-bounded interval like `50-` (no less than 50) and `-50` (no greater than 50)."
314970,350175,https://api.github.com/repos/NetchX/Netch/issues/591,bug,2021-03-23T04:26:07Z,NONE,https://api.github.com/repos/NetchX/Netch,1.8.3-Beta2版本启动加速之后，停止加速，再启动出现报错弹窗 未处理异常 无法枚举进程模块 和log，加速无法启动 **Describe the bug** 启动加速之后，停止加速，再启动**有概率**会出现报错弹窗和log，加速无法启动，需要等待较长时间再启动才正常 **To Reproduce** 1. Open Netch 2. 点击启动 3. 点击停止 4. 点击启动（问题出现） **Log** ![image](https://user-images.githubusercontent.com/8756469/112092519-a1455280-8bd2-11eb-9da9-c9173d44fc51.png) 因为我这会把Netch重启了，没法复现了，只有截图了。。。 **Screenshots** ![image](https://user-images.githubusercontent.com/8756469/112092575-c0dc7b00-8bd2-11eb-935f-f9fd22d1e99c.png) **Environment (please complete the following information):** OS: Windows 10 Pro 64-bit 20H2 Netch Version: 1.8.3-Beta2 **Additional context** 有概率出现。。不是每次都会这样。。。。 
680613,756415,https://api.github.com/repos/argoproj/argo-helm/issues/401,enhancement,2020-07-09T21:41:56Z,NONE,https://api.github.com/repos/argoproj/argo-helm,"PodSecurityPolicy support for argo workflow CRD deploy **Is your feature request related to a problem? Please describe.** Firstly, thank you for supporting and maintaining these argo helm charts. These are super helpful to me as i begin my argo workflow testing. As for the issue, I tried to search for open and closed issues related to this but was unable to find any info. Do we have any guidance on supporting `PodSecurityPolicy` for these helm charts ? **Describe the solution you'd like** List out a `PodSecurityPolicy` and tie it to a `ClusterRole` to ensure the `argo-server` and `argo-workflow-controller` serviceaccounts can use the PSP. **Describe alternatives you've considered** I am working on testing this install on a cluster that has PSP enabled. Will report on findings in this issue. Just wanted to get some community feedback here. "
590002,655645,https://api.github.com/repos/ctm/mb2-doc/issues/514,enhancement,2021-02-07T00:20:46Z,OWNER,https://api.github.com/repos/ctm/mb2-doc,"Allow observers to see four-color deck @clauclauclaudia: > &hellip;I'd love to be able to view 4-color as an observer... either by having a persistent preference or by having a button in the observer window&hellip; I agree, both to give observers an easier time with badugi based games and also to give them a tiny taste of the UI that they'll have inflicted on them when they play. I'm ""temporarily"" tagging this `high priority`, but I may wind up changing my mind in the cool grey light of dawn."
66991,74477,https://api.github.com/repos/rapid7/metasploit-framework/issues/8812,bug,2017-08-08T23:18:38Z,CONTRIBUTOR,https://api.github.com/repos/rapid7/metasploit-framework,"Inconsistent printing of `peer` in auxiliary login modules Output is inconsistent for different login brute-force auxiliary modules throughout the framework. Some make use of `print_brute`. Some output the `peer` automatically while others require `peer` to be manually included in the module code. Some provide pretty progress output; others don't. Additionally, forgoing `peer` in the module output in some modules prevents the pretty brute-force progress output. The progress is important visual feedback for user experience, in particular because the default word lists used in various modules (`unix_users.txt` and `unix_passwords.txt`) result in a combined total of more than ~110,000 user/pass combinations. (24+ hours at 1 login attempt per second). ``` # wc -l data/wordlists/unix_users.txt 112 data/wordlists/unix_users.txt # wc -l data/wordlists/unix_passwords.txt 1008 data/wordlists/unix_passwords.txt ``` A few quick tests reveal that the `peer` must be specified in the `print_*` method in a `Msf::Auxiliary` modules, unless a `Msf::Exploit::Remote::*` library has been included (such as `Remote::Tcp` or `Remote::Ftp`, but not `Remote::Http` because it plays by its own rules) in which case the `peer` is printed automatically. However, in these instances the `peer` is still required else the pretty progress output is not shown, resulting in the `peer` being printed twice. Testing `modules/auxiliary/scanner/http/http_login.rb` - which doesn't print the `peer` - will start printing the `peer` if a `Msf::Exploit::Remote::*` library is included. One option would be to update all modules to use `print_brute` however there was unconfirmed speculation of deprecating this function a few years ago which hasn't come to fruition. For more details, see comments in #8566 and #8654 Related: #8811 "
353111,392577,https://api.github.com/repos/fortrade-studio/TikTok/issues/7,enhancement,2021-05-30T08:38:31Z,CONTRIBUTOR,https://api.github.com/repos/fortrade-studio/TikTok,"ENHANCEMENT : RESEND OTP SHOULD HAVE TIMER OF 1 MIN ### Resend Otp Should have a timer of 60 Sec which user have to wait before resending the otp again > **Currently User don't have any wait time before sending the otp again , So we Should add a timer which will allow user to re-send Otp to the user only after 60 sec .** "
590482,656202,https://api.github.com/repos/Garderoben/MudBlazor/issues/1619,bug,2021-05-21T05:25:32Z,CONTRIBUTOR,https://api.github.com/repos/Garderoben/MudBlazor,"MudMenu with MudButton as activator does not show menu popover MudMenu does not show popover, if MudButton is used as activator. Other elements work fine. https://try.mudblazor.com/snippet/GawPupGFPXSvGLaH "
409086,454706,https://api.github.com/repos/libsdl-org/SDL/issues/294,bug,2021-02-10T22:15:34Z,COLLABORATOR,https://api.github.com/repos/libsdl-org/SDL,"iphone keyboard doesn't send 'return' and 'backspace' events # This bug report was migrated from our old Bugzilla tracker. These attachments are available in the static archive: * ~~[fix the missing return event (iphone_return.patch, application/octet-stream, 2010-07-16 18:06:41 +0000, 1401 bytes)](https://bugzilla.libsdl.org/attachment.cgi?id=517)~~ * ~~[fix the missing return event (and a compiler warning) (iphone_return.patch, text/plain, 2010-07-16 18:22:44 +0000, 947 bytes)](https://bugzilla.libsdl.org/attachment.cgi?id=518)~~ * [fix return, backspace and multiple calls to keyboards (keycodes.patch, text/plain, 2011-02-01 02:25:48 +0000, 1384 bytes)](https://bugzilla.libsdl.org/attachment.cgi?id=564) **Reported in version:** HG 2.0 **Reported for operating system, platform:** iOS (All), iPhone/iPod touch # Comments on the original bug report: On 2010-07-16 18:06:41 +0000, Vittorio Giovara wrote: > Created attachment 517 > fix the missing return event > > my application builds a chat system so that users write and send their messages by pressing ENTER. > however i noticed that the ENTER event does never get sent from an iphone/ipad keyboard, thus no message can be sent. I've attached a small patch that fixes this, i used the 13th slot because it's the ""carriage return"" value in the ashii table. > > another issue, also the BACKSPACE has problems: when the keyboard appears it works fine, but if it gets hidden no more backspace are sent. Unfortunately i don't have a patch to fix this, but i hope that it can be fixed. On 2010-07-16 18:22:44 +0000, Vittorio Giovara wrote: > Created attachment 518 > fix the missing return event (and a compiler warning) > > sorry, i uploaded a corrupted patch; here is the one working against latest hg revision. On 2010-07-17 06:14:00 +0000, Vittorio Giovara wrote: > upon further inspection, also the RETURN event I added is sent only the first time the keyboard appears. > My guess is that there must be some kind of corruption in sending the RETURN and BACKSPACE event (the event is not really generated, so the problem shouldn't be in receiving events) On 2010-09-23 01:22:23 +0000, wrote: > It seems that textField (SDL_uikitview.m) doesn't call it's delegate when backspace key is pressed, but the keypress DOES erase content from textField (can be easily checked if you assign dummy text to textField.text property). It always happens after the second call to showKeyboard during the application runtime. On 2011-02-01 02:25:48 +0000, Vittorio Giovara wrote: > Created attachment 564 > fix return, backspace and multiple calls to keyboards > > i have attached an updated patch that fixes this behaviour On 2011-02-01 09:05:20 +0000, Sam Lantinga wrote: > Thanks for the patch! > http://hg.libsdl.org/SDL/rev/c63b901d97ab "
304546,338595,https://api.github.com/repos/tarantool/tarantool/issues/5628,bug,2020-12-15T10:20:02Z,CONTRIBUTOR,https://api.github.com/repos/tarantool/tarantool,"Fix bugs in memtx TX manager This is a cumulative ticket. There's a lot of problems that happen because TX manager cannot track read when it didn't find anything, or range read. We need to grab interval trees from vinyl to track those read. "
689097,765864,https://api.github.com/repos/flowacademyhu/iota-munkalap/issues/254,bug,2021-03-04T09:56:00Z,CONTRIBUTOR,https://api.github.com/repos/flowacademyhu/iota-munkalap,"BUG: Zárt munkalapot ne lehessen szerkeszteni Zárjunk le egy munkalapot a lakattal (az állapota Lezárt legyen). Elvárt: A szerkesztés gomb halvány, és nem kattintható, vagyis a munkalap nem szerkeszthető. Jelenlegi működés: A szerkesztés gomb halvány, de kattintható, megjelenik a szerkesztés űrlap, tudom szerkeszteni, és el is tudom menteni a változtatást."
636336,707230,https://api.github.com/repos/InceptionNetwork/issues/issues/15,bug,2021-02-14T09:35:16Z,MEMBER,https://api.github.com/repos/InceptionNetwork/issues,İsimlerde Cam Filmi Sorunu **Sunucu Adı:** Inception Roleplay **Hata Açıklaması:** /market den Cam Filmi satın almış araçlar yeni Nametag güncellemesinden sonra cam kapalı ilken Cam Filmi şeklinde yazmıyor. **Ekran Görüntüleri:** `-` **Ek Açıklama** `-`
645386,717349,https://api.github.com/repos/nitatemic/AlexandreDeLemeny-Makedone_3_12042021/issues/8,bug,2021-04-28T00:50:35Z,OWNER,https://api.github.com/repos/nitatemic/AlexandreDeLemeny-Makedone_3_12042021,Strange thing on loading ![chrome](https://user-images.githubusercontent.com/13944652/116329433-a26a3080-a7cb-11eb-8b14-918e17a1d4dc.gif) The loading of the site on a browser based on chromium. This is the expected behavior ![Firefox](https://user-images.githubusercontent.com/13944652/116329595-ff65e680-a7cb-11eb-95bd-63c301e13ee8.gif) Loading the site on firefox ![safari](https://user-images.githubusercontent.com/13944652/116329827-726f5d00-a7cc-11eb-90d2-2b2ff22f0cdb.gif) Loading the site on safari. Here it is a firework of bug. 
210209,233738,https://api.github.com/repos/codeforboston/safe-water/issues/75,question,2020-02-19T01:36:22Z,CONTRIBUTOR,https://api.github.com/repos/codeforboston/safe-water,Pull first draft of wiki I have created a first draft of the clean-water wiki on [my fork of the repo](http://github.com/h-clef/safe-water.wiki). Francois need to manually pull these files to to the main page.
568155,631398,https://api.github.com/repos/auth0/node-auth0/issues/564,enhancement,2020-12-31T20:48:21Z,NONE,https://api.github.com/repos/auth0/node-auth0,"Inconsistencies with API documentation For example, getUsersByEmail clearly has support for field filtering by passing in the ""fields"" argument: https://auth0.com/docs/api/management/v2#!/Users_By_Email/get_users_by_email But the sdk completely ignores these fields and only accepts an email for getUsersByEmail: https://github.com/auth0/node-auth0/blob/06304e0ab3528eef855d896088b0799587d707ca/src/management/index.js#L1018 Can we bring the sdk back to feature parity? There's little point in using an SDK if we have to go back to doing direct HTTP requests to actually access the complete API."
284818,316761,https://api.github.com/repos/Praxisprojekt2021/praxisprojekt/issues/69,enhancement,2021-04-12T17:48:47Z,CONTRIBUTOR,https://api.github.com/repos/Praxisprojekt2021/praxisprojekt,"Save Button Frontend ## Bereich <!--- falls anwendbar --> <!--- Bitte Unzutreffendes streichen --> * Frontend ## Beschreibung <!--- Beschreibung des Bugs (was sollte passieren, was ist passiert), gerne auch mit Screenshots, falls nötig --> Beim Speichern von Komponenten/Prozessen bleibt der Button immer grau, egal ob das Speichern klappt oder nicht ## Lösungsvorschläge <!--- wie kann der Fehler behoben werden, falls vorhanden --> Button grundsätzlich nicht ausgrauen/disablen, da durch LoadingPage der Fehler behoben wird ## Testen <!--- wie ist klar, dass der Fehler behoben wurde --> ## Verantwortlicher als funktionaler Reviewer - [ ] @tomhinzmann <!--- bitte entsprechende Person eintragen --> ### Anmerkungen <!--- Bestehen Abhängigkeiten zu anderen User Stories, die bspw. vorher erledigt werden müssen? --> "
188384,209491,https://api.github.com/repos/vdesabou/kafka-docker-playground/issues/430,bug,2021-03-19T17:19:55Z,NONE,https://api.github.com/repos/vdesabou/kafka-docker-playground,🔥 connect/connect-azure-sql-data-warehouse-sink Version: 1.0.4 🔗 Link to test: https://github.com/vdesabou/kafka-docker-playground/actions/runs/667662790
568534,631821,https://api.github.com/repos/zwave-js/zwavejs2mqtt/issues/119,enhancement,2020-12-30T07:32:00Z,MEMBER,https://api.github.com/repos/zwave-js/zwavejs2mqtt,[feat] Move docs to github pages Use [docsify](https://docsify.js.org/#/?id=docsify)
370386,411752,https://api.github.com/repos/TDex-network/tdex-daemon/issues/337,bug,2021-04-21T17:51:34Z,MEMBER,https://api.github.com/repos/TDex-network/tdex-daemon,"Panic after TradePropose ``` panic: runtime error: index out of range [6] with length 6 goroutine 24322 [running]: github.com/tdex-network/tdex-daemon/pkg/wallet.(*Wallet).BlindSwapTransactionWithData(0xc011a91c20, 0xc011c99000, 0x4b64, 0xc011c765d0, 0xc055d7b950, 0x0, 0x2c, 0x0, 0x0, 0xc011bebdd0) /tdex-daemon/pkg/wallet/blind.go:373 +0x7fb github.com/tdex-network/tdex-daemon/internal/core/application.fillProposal(0xc011b02c00, 0x18, 0x18, 0x1109e80, 0xc0109646c0, 0xc010f42a80, 0x33, 0x33, 0xc011b0b4a0, 0xf, ...) /tdex-daemon/internal/core/application/trade_service.go:648 +0xc05 github.com/tdex-network/tdex-daemon/internal/core/application.tradeManager.FillProposal(...) /tdex-daemon/internal/core/application/types.go:193 github.com/tdex-network/tdex-daemon/internal/core/application.(*tradeService).TradePropose(0xc0109f93e0, 0x1102de0, 0xc005d02690, 0xc01094b040, 0x40, 0xc01094b080, 0x40, 0x0, 0x1109e80, 0xc0109646c0, ...) /tdex-daemon/internal/core/application/trade_service.go:287 +0x775 github.com/tdex-network/tdex-daemon/internal/interfaces/grpc/handler.traderHandler.tradePropose(0x11050e0, 0xc0109f93e0, 0xc0516c07c0, 0x1108f20, 0xc005ef8820, 0xe20501, 0xc005ef8820) /tdex-daemon/internal/interfaces/grpc/handler/trade.go:213 +0x1cd github.com/tdex-network/tdex-daemon/internal/interfaces/grpc/handler.traderHandler.TradePropose(...) /tdex-daemon/internal/interfaces/grpc/handler/trade.go:64 github.com/tdex-network/tdex-protobuf/generated/go/trade._Trade_TradePropose_Handler(0xe3e880, 0xc005daac40, 0x1106940, 0xc0000ca3c0, 0x1, 0xdf9be0) /go/pkg/mod/github.com/tdex-network/tdex-protobuf@v0.0.0-20210324125236-78f6c6c0618b/generated/go/trade/trade_grpc.pb.go:282 +0x10b github.com/tdex-network/tdex-daemon/internal/interfaces/grpc/interceptor.streamLogger(0xe3e880, 0xc005daac40, 0x1106940, 0xc0000ca3c0, 0xc005e8ec80, 0x1025700, 0x1102de0, 0xc005d02690) /tdex-daemon/internal/interfaces/grpc/interceptor/logger.go:27 +0xbe google.golang.org/grpc.(*Server).processStreamingRPC(0xc0000c8700, 0x110a840, 0xc0107e9d40, 0xc010dbe800, 0xc010a39110, 0x1596880, 0x0, 0x0, 0x0) /go/pkg/mod/google.golang.org/grpc@v1.32.0/server.go:1448 +0x522 google.golang.org/grpc.(*Server).handleStream(0xc0000c8700, 0x110a840, 0xc0107e9d40, 0xc010dbe800, 0x0) /go/pkg/mod/google.golang.org/grpc@v1.32.0/server.go:1521 +0xc9c google.golang.org/grpc.(*Server).serveStreams.func1.2(0xc053dd6010, 0xc0000c8700, 0x110a840, 0xc0107e9d40, 0xc010dbe800) /go/pkg/mod/google.golang.org/grpc@v1.32.0/server.go:859 +0xa5 created by google.golang.org/grpc.(*Server).serveStreams.func1 /go/pkg/mod/google.golang.org/grpc@v1.32.0/server.go:857 +0x1fd ```"
677005,752417,https://api.github.com/repos/Atmelfan/scpi-rs/issues/6,bug,2020-09-07T10:07:31Z,OWNER,https://api.github.com/repos/Atmelfan/scpi-rs,[BUG] Missing math symbols **Describe the bug** When compiling to an embedded device some symbols might not be defined. - [x] `<f32|f64>.round()` - [ ] powi/roundf/etc from intrinsics used in lexical_core - [ ] Create regression test Replacing .round() can be done using libm. **To Reproduce** Compile scpi for a target which does not have these symbols. **Expected behavior** Library should compile. **Library and tool versions:** - scpi version: master - rust version: nightly 40-something - cargo version: **Additional context** A issue is that lexical_core which is used to parse numbers uses core intrinsics for some math operations which does not exist on all targets. Linking to libc `-lc` can make it compile but in my case segfaults later. A CI/CD test should be created to avoid regression. 
364728,405441,https://api.github.com/repos/RickyBaca28/Fig-It/issues/22,enhancement,2021-02-11T04:36:09Z,OWNER,https://api.github.com/repos/RickyBaca28/Fig-It,Create user service level # Description Just like `service/item.ts` we should create a `service/user.ts`!! ## TODO I expect 2 functions in this file - `createUser()` which creates a user - `getUser()` which gets a user given a username 
147125,163528,https://api.github.com/repos/ansible/ansibullbot/issues/903,enhancement,2018-05-04T03:21:54Z,CONTRIBUTOR,https://api.github.com/repos/ansible/ansibullbot,Reduce long lists of files down to globs in component comment. https://github.com/ansible/ansible/issues/36871#issuecomment-379059517 Most of that could have been foo/bar/*.
274832,305648,https://api.github.com/repos/AntaresSimulatorTeam/antares-xpansion/issues/67,enhancement,2021-03-10T12:55:41Z,MEMBER,https://api.github.com/repos/AntaresSimulatorTeam/antares-xpansion,Add default value for step parameters Use default value of `full `for _antares-xpansion-launcher_ `--step` parameter
344931,383445,https://api.github.com/repos/ita-social-projects/Car-Back-End/issues/252,bug,2021-02-19T15:39:31Z,NONE,https://api.github.com/repos/ita-social-projects/Car-Back-End,"400 error if '*' fields are empty in 'Add a car' function Environment: Asus ROG Phone 2, Android 9. Reproducible: Always reproduce Build v1.0.51 Preconditions: Enable internet connection, log in to our account. Steps to reproduce 1. Go to 'My profile' 2. Click on 'Add a car' 3. Fill in not all fields with '*' 4. Click on 'SAVE' button Actual result We got a page with 400error(Internal Server Error) Expected result We have to get a pop-up window with some information like 'Fill in all '*' fields' User story https://github.com/ita-social-projects/Car-Back-End/issues/33 https://user-images.githubusercontent.com/78917960/108526202-83d24f80-72d9-11eb-96a3-1eda3ff65112.mp4 "
298728,332144,https://api.github.com/repos/corso-android-ivan-morgillo/team-c/issues/53,enhancement,2021-02-10T10:30:50Z,CONTRIBUTOR,https://api.github.com/repos/corso-android-ivan-morgillo/team-c,"inserire refresh della lista delle ricette Vogliamo aggiungere la seguente funzionalità: Quando l'utente trascina verso il basso facciamo il refresh della schermata con le ricette. Oppure, invece della gesture, mettiamo aggiorna."
587367,652714,https://api.github.com/repos/wjdp/htmltest/issues/143,bug,2020-02-10T12:23:21Z,NONE,https://api.github.com/repos/wjdp/htmltest,"cannot put StripQueryExcludes into config file # Describe the bug Create a file .htmltest.yml containing ```yml StripQueryExcludes: [ ""https://marketplace.visualstudio.com"" ] ``` Running `htmltest` it seems that it fails to understand the file: ``` $ htmltest htmltest started at 01:20:19 on <nil> ======================================================================== panic: reflect.Set: value of type []interface {} is not assignable to type []string goroutine 1 [running]: reflect.Value.assignTo(0x131b960, 0xc00000d620, 0x97, 0x139ef83, 0xb, 0x131cce0, 0x0, 0x135c6c0, 0xccf1d99aede24742, 0x17) /home/travis/.gimme/versions/go1.13.6.linux.amd64/src/reflect/value.go:2403 +0x432 reflect.Value.Set(0x131cce0, 0xc0000d27a0, 0x197, 0x131b960, 0xc00000d620, 0x97) /home/travis/.gimme/versions/go1.13.6.linux.amd64/src/reflect/value.go:1537 +0xbd github.com/imdario/mergo.deepMerge(0x131cce0, 0xc0000d27a0, 0x197, 0x131b960, 0xc00000d620, 0x97, 0xc000101720, 0x1, 0xc00000d700, 0x0, ...) /home/travis/gopath/pkg/mod/github.com/imdario/mergo@v0.3.8/merge.go:165 +0x26cd github.com/imdario/mergo.deepMap(0x1398640, 0xc0000d26c0, 0x199, 0x1332560, 0xc000081a40, 0x15, 0xc000101720, 0x0, 0xc00000d700, 0x15, ...) /home/travis/gopath/pkg/mod/github.com/imdario/mergo@v0.3.8/map.go:102 +0x84f github.com/imdario/mergo._map(0x1335200, 0xc0000d26c0, 0x1332560, 0xc000081a40, 0xc00000e3d8, 0x1, 0x1, 0x1, 0x0) /home/travis/gopath/pkg/mod/github.com/imdario/mergo@v0.3.8/map.go:174 +0x204 github.com/imdario/mergo.MapWithOverwrite(...) /home/travis/gopath/pkg/mod/github.com/imdario/mergo@v0.3.8/map.go:140 github.com/wjdp/htmltest/htmltest.(*HTMLTest).setOptions(0xc0000d26c0, 0xc000081980) /home/travis/gopath/src/github.com/wjdp/htmltest/htmltest/options.go:150 +0x1ed github.com/wjdp/htmltest/htmltest.Test(0xc000081980, 0xc00000e018, 0xc000101d48, 0x1) /home/travis/gopath/src/github.com/wjdp/htmltest/htmltest/htmltest.go:47 +0xae main.run(0xc000081980, 0xc000081980) /home/travis/gopath/src/github.com/wjdp/htmltest/main.go:159 +0x207 main.main() /home/travis/gopath/src/github.com/wjdp/htmltest/main.go:66 +0x268 ``` I tried placing just the domain name into the list, but I get the same error every time. no matter what I put into `StripQueryExcludes`. Interestingly, even the empty list `StripQueryExcludes: []` fails. ## Versions - Mac OS X Mojave 10.14.6 - htmltest: 0.12.1 "
570784,634301,https://api.github.com/repos/JuliaImages/Images.jl/issues/942,question,2021-03-23T04:06:00Z,NONE,https://api.github.com/repos/JuliaImages/Images.jl,alternatives to `@test_approx_eq_sigma_eps` macro I noticed this while trying out test_approx_eq_sigma_eps() which is there in code and works just fine when used directly but is not exported I think so can't be used by public... https://github.com/JuliaImages/Images.jl/blob/810480a19c879bb3fa1598b6e7ac7801ecdcf4e3/src/algorithms.jl#L282 - are there methods available in Images that does image comparision other than ofcourse seeing images side by side?Visually or mathematical ways? - https://juliaimages.org/stable/democards/examples/spatial_transformation/image_diffview/#Image-Difference-View has some tricks but those are tricks 😅 - Relevant issues in past: - https://github.com/JuliaImages/Images.jl/issues/364 - https://github.com/JuliaImages/Images.jl/pull/390 @timholy implemented simple difference testing in https://github.com/JuliaImages/Images.jl/pull/367 but there haven't been much developement on that section I believe after that
429811,477801,https://api.github.com/repos/benbusby/whoogle-search/issues/287,bug,2021-04-13T16:01:44Z,NONE,https://api.github.com/repos/benbusby/whoogle-search,"[BUG] Docker shows container as “Unhealthy” After the most recent updates (I believe the last 3 commits), Docker again shows the container as ""Unhealthy"". Below is the health check. ``` {""Status"":""unhealthy"",""FailingStreak"":98,""Log"":[{""Start"":""2021-04-13T08:56:44.730335835-07:00"",""End"":""2021-04-13T08:56:44.949223012-07:00"",""ExitCode"":1,""Output"":""""},{""Start"":""2021-04-13T08:57:15.500682888-07:00"",""End"":""2021-04-13T08:57:15.707056244-07:00"",""ExitCode"":1,""Output"":""""},{""Start"":""2021-04-13T08:57:46.275134217-07:00"",""End"":""2021-04-13T08:57:46.495521038-07:00"",""ExitCode"":1,""Output"":""""},{""Start"":""2021-04-13T08:58:17.077553245-07:00"",""End"":""2021-04-13T08:58:17.294039045-07:00"",""ExitCode"":1,""Output"":""""},{""Start"":""2021-04-13T08:58:47.906687469-07:00"",""End"":""2021-04-13T08:58:48.130840141-07:00"",""ExitCode"":1,""Output"":""""}]} ```"
541731,602121,https://api.github.com/repos/LeonardSSH/coc-discord-rpc/issues/16,enhancement,2021-02-08T03:04:15Z,NONE,https://api.github.com/repos/LeonardSSH/coc-discord-rpc,"Feature request: add a vim lang icon. So, would it be possible that when editing a file with a `.vim` extension or your `.vimrc` to display a Vim logo/icon?"
41703,46443,https://api.github.com/repos/azavea/fb-gender-survey-dashboard/issues/78,bug,2021-01-25T13:37:15Z,CONTRIBUTOR,https://api.github.com/repos/azavea/fb-gender-survey-dashboard,"Question Search Bug The question search feature doesn't seem to work consistently. For example, ""Expense"" search results in ""our of your 10 neighbors, how many believe household expenses are the responsibility of men?"" but not the similar question ""how much do you agree that household expenses are..."" "
505230,561550,https://api.github.com/repos/weaveio/forum/issues/53,bug,2021-02-16T01:49:17Z,COLLABORATOR,https://api.github.com/repos/weaveio/forum,"When I enter the time, the app crashes. I thought it would take some time to reflect, so I left it for a day. However, the app has crashed as shown in the video below. location: 復職支援のtracker test24 反映に時間がかかってると思い一日置いたが、下の動画のようにアプリが落ちてしまった。 https://user-images.githubusercontent.com/78060608/108008671-37221680-7044-11eb-880a-0a1ea317f130.MP4"
460766,512086,https://api.github.com/repos/nstack-io/dotnetstandard-sdk/issues/20,bug,2020-06-17T12:41:24Z,COLLABORATOR,https://api.github.com/repos/nstack-io/dotnetstandard-sdk,Make sure the generator tool doesn't crash when asking for help Currently the generator tool crashes if the settings aren't set correct. It should fail pretty and also not crash when `--help` is used to get info on the parameters
575907,639995,https://api.github.com/repos/nextcloud/ocsms/issues/167,question,2017-01-31T05:18:44Z,NONE,https://api.github.com/repos/nextcloud/ocsms,"Enable two way synchronisation At the moment, ocsms is just an one way sync. Enable either two way sync or mention on Google Play Store as well as on Nextcloud App Store that this app is syncing only one way. More info: https://help.nextcloud.com/t/nextcloud-sms-1-11-4-one-way-or-two-way-sync/"
187156,208121,https://api.github.com/repos/mcchrish/nnn.vim/issues/93,bug,2021-05-09T06:46:00Z,COLLABORATOR,https://api.github.com/repos/mcchrish/nnn.vim,"Floating window broken when number of elements exceeds height I am seeing this with vim version 8.2.1767 and `nnn.vim` master. I have the following in .vimrc: ``` nnoremap <leader>n :NnnPicker %:p:h<CR> ""Floating window (neovim latest and vim with patch 8.2.191) let g:nnn#layout = { 'window': { 'width': 0.9, 'height': 0.6, 'highlight':'Debug' } } ``` When the number of elements are greater than the floating window height moving the arrow down corrupts the statusbar. Looks like a height calculation issue. ![](https://i.imgur.com/XZ1Whvu.png)"
394079,438015,https://api.github.com/repos/mezzio/mezzio-flash/issues/7,bug,2021-03-27T18:22:01Z,NONE,https://api.github.com/repos/mezzio/mezzio-flash,"flashNow() messages persist beyond the current request ### Bug Report #### Summary Messages set with `flashNow()` persist beyond the current request. I found this surprising and inconvenient, but feel like maybe it's intended. So I'll explore it here and suggest some potential changes. #### Current behavior Messages added via `flashNow()` are visible immediately, in the request in which they're added, and again in the subsequent request. Note that this does **not** contradict the documentation, which says: > When you create a flash message, it is available in the next request, but not the current request. If you want access to it in the current request **as well**, use the flashNow() method instead of flash(): (Emphasis mine) If this is in fact the expected behavior, I'm somewhat astonished. #### How to reproduce Implement the fairly common pattern of a form submission that redirects on success, but re-renders the form in the response to the POST on error. Use `flashNow()` in the error branch to display a message in the response (relying on the default `$hops = 1`) argument value). Resubmit the form so that the submission succeeds, and and the response redirects the user. Note that the error-info set via `flashNow()` is now displayed a second time. #### Expected behavior I'd expect messages set with `flashNow()` to be visible exclusively in the current request, at least by default. A strongly-opinionated change would be to simply remove the call to `$this->flash(...)` in the `flashNow()` implementation (and remove the `$hops` argument from `flashNow()` as well, I suppose). A more flexible fix would be to allow `flash()` to accept a `$hops` of zero, and change the default for `flashNow()` to zero `$hops`. Unfortunately, both of those options break BC. A BC-preserving fix would be to simply allow zero $hops. Then users of the class could at least get the behavior they'd like out of the implementation. As it stands now, I had to ""write"" my own implementation of `FlashMessagesInterface` that behaves as I'd expect. But that implementation was ""copy `FlashMessages` and remove [one line](https://github.com/mezzio/mezzio-flash/blob/460b5addbab0153416187fe7e565855517551cb0/src/FlashMessages.php#L100)"", which feels dirty and makes me sad. Finally, I'll say that I feel like I'm probably missing some obvious use-case where the current behavior is expected. If someone enlightened me, my consternation might evaporate. "
179450,199493,https://api.github.com/repos/STORM-IRIT/Radium-Engine/issues/664,bug,2021-01-26T12:15:08Z,CONTRIBUTOR,https://api.github.com/repos/STORM-IRIT/Radium-Engine,"Use of filesystem::lexically_normal not available in experimental Current version of `master` requires cxx_17 capabilities at this line: https://github.com/STORM-IRIT/Radium-Engine/blob/31523ca27aaa231751b9dff4e2c4343225ee2c00/src/Core/Resources/Resources.cpp#L31 Doc: https://en.cppreference.com/w/cpp/filesystem/path/lexically_normal As such, some compilers (e.g., gcc-7) cannot compile radium."
227492,253003,https://api.github.com/repos/PrismarineJS/mineflayer/issues/1767,question,2021-03-16T17:23:07Z,NONE,https://api.github.com/repos/PrismarineJS/mineflayer,"Chat Spammer ## Versions - mineflayer: 3.2.0 - server: Spigot - node: 14.16.0 How to force a bot to have a spammer when entering the server, messages must be from the config and different, and moreover, the limit for these messages must be in order to bypass the kicked from spamming system message a spam bot.chat('Message1') limit a chat message bot.chat('Message2') "
57814,64262,https://api.github.com/repos/jaegertracing/jaeger-operator/issues/1378,enhancement,2021-02-03T11:15:16Z,MEMBER,https://api.github.com/repos/jaegertracing/jaeger-operator,"Migrate usage of jaeger.tags The flag `jaeger.tags` has been deprecated for some time now, being removed in the next Jaeger version. This ticket is to change the operator to: - [ ] Change the default path to use agent.tags/collector.tags as appropriate - [ ] Create an upgrade script to change existing CRs to use the new flags"
285112,317084,https://api.github.com/repos/ealt/Frances/issues/32,enhancement,2021-05-22T03:00:01Z,OWNER,https://api.github.com/repos/ealt/Frances,Add support for 'in the corner' in clue Heather's clue is: `I was in the corner of the room.` There is currently no support for 'in the corner'
558068,620238,https://api.github.com/repos/convertigo/C8oForms/issues/385,bug,2021-03-24T17:17:42Z,CONTRIBUTOR,https://api.github.com/repos/convertigo/C8oForms,"Authenticated only form does not display ""Insufficient rights"" to external user **1.0.44-beta240** Published authenticated only form. Give link to a user that was not permitted, it ends up with an infinite orange loader instead of displaying the ""Insufficient rights"" message. "
85826,95412,https://api.github.com/repos/freezy/VisualPinball.Engine/issues/286,enhancement,2021-02-02T19:12:39Z,OWNER,https://api.github.com/repos/freezy/VisualPinball.Engine,"Correctly handle plunger inputs A plunger can be 1. plunged by pressing a key and fired by releasing a key (""key plunge"") 2. auto-plunged by the ROM (""fire"") 3. plunged with an analog stick or a h/w plunger (""analog plunge"") For 1. and 2. I think a switch device should do it. If the game has an analog plunger and not just auto-plunge, the plunger key would go into the ""key plunge"" switch and the ROM into ""fire"". For 3. we need some additional kind of input type."
84495,93943,https://api.github.com/repos/urapadmin/kiosk/issues/1090,bug,2021-05-13T23:59:28Z,OWNER,https://api.github.com/repos/urapadmin/kiosk,"migration issue when creating a new workstation did not show an error I looked into the log and it shows something like ""Migration ran into an endless loop"". So two issues here: - [x] The main issue that the workstation could not be created (and my hunch is that there were remnants from the old arch1900) An additional information is that Laurel was able to create an ""albert"" at thes same time. Capitalization might have decided whether or not the legacy remnants became relevant. _Originally posted by @urapadmin in https://github.com/urapadmin/kiosk/issues/1033#issuecomment-824139154_"
497018,552415,https://api.github.com/repos/listen1/listen1_chrome_extension/issues/402,bug,2020-12-31T02:00:22Z,OWNER,https://api.github.com/repos/listen1/listen1_chrome_extension,歌词滚动异常 有时歌词会连续滚动到最下位置
597764,664313,https://api.github.com/repos/usnistgov/NFIQ2/issues/131,enhancement,2021-01-25T14:38:36Z,MEMBER,https://api.github.com/repos/usnistgov/NFIQ2,Get score without declaring lists Add a simpler API to get the NFIQ 2 score: ```cpp unsigned int computeQualityScore( const NFIQ::FingerprintImageData &) const; ```
370253,411604,https://api.github.com/repos/HGustavs/LenaSYS/issues/10262,bug,2021-04-21T12:11:32Z,COLLABORATOR,https://api.github.com/repos/HGustavs/LenaSYS,"When cancelling an action with Esc, the box selection functionality is broken If you cancel a movement action by pressing escape, box selection causes the elements within the selection box to get pushed aside. ![example](https://user-images.githubusercontent.com/81541557/115551436-5ab74680-a2ab-11eb-8e4c-1ec1b6dd7d1b.png) "
213195,237071,https://api.github.com/repos/zwave-js/node-zwave-js/issues/54,bug,2019-04-28T18:05:16Z,MEMBER,https://api.github.com/repos/zwave-js/node-zwave-js,[Tracking] Implement `toLogEntry` in all CCs and their subclasses current implementation status: - [x] AlarmSensorCCGet - [x] AlarmSensorCCReport - [x] AlarmSensorCCSupportedGet _(empty CC)_ - [x] AlarmSensorCCSupportedReport - [x] AssociationCCGet - [x] AssociationCCRemove - [x] AssociationCCReport - [x] AssociationCCSet - [x] AssociationCCSupportedGroupingsGet _(empty CC)_ - [x] AssociationCCSupportedGroupingsReport - [x] AssociationGroupInfoCCCommandListGet - [x] AssociationGroupInfoCCCommandListReport - [x] AssociationGroupInfoCCInfoGet - [x] AssociationGroupInfoCCInfoReport - [x] AssociationGroupInfoCCNameGet - [x] AssociationGroupInfoCCNameReport - [x] BarrierOperatorCCEventSignalingGet - [x] BarrierOperatorCCEventSignalingReport - [x] BarrierOperatorCCEventSignalingSet - [x] BarrierOperatorCCGet _(empty CC)_ - [x] BarrierOperatorCCReport - [x] BarrierOperatorCCSet - [x] BarrierOperatorCCSignalingCapabilitiesGet _(empty CC)_ - [x] BarrierOperatorCCSignalingCapabilitiesReport - [x] BasicCCGet _(empty CC)_ - [x] BasicCCReport - [x] BasicCCSet - [x] BatteryCCGet _(empty CC)_ - [x] BatteryCCHealthGet _(empty CC)_ - [x] BatteryCCHealthReport - [x] BatteryCCReport - [x] BinarySensorCCGet - [x] BinarySensorCCReport - [x] BinarySensorCCSupportedGet _(empty CC)_ - [x] BinarySensorCCSupportedReport - [x] BinarySwitchCCGet _(empty CC)_ - [x] BinarySwitchCCReport - [x] BinarySwitchCCSet - [x] CRC16CCCommandEncapsulation - [x] CentralSceneCCConfigurationGet _(empty CC)_ - [x] CentralSceneCCConfigurationReport - [x] CentralSceneCCConfigurationSet - [x] CentralSceneCCNotification - [x] CentralSceneCCSupportedGet _(empty CC)_ - [x] CentralSceneCCSupportedReport - [x] ClimateControlScheduleCCChangedGet _(empty CC)_ - [x] ClimateControlScheduleCCChangedReport - [x] ClimateControlScheduleCCGet - [x] ClimateControlScheduleCCOverrideGet _(empty CC)_ - [x] ClimateControlScheduleCCOverrideReport - [x] ClimateControlScheduleCCOverrideSet - [x] ClimateControlScheduleCCReport - [x] ClimateControlScheduleCCSet - [x] ClockCCGet _(empty CC)_ - [x] ClockCCReport - [x] ClockCCSet - [x] ColorSwitchCCGet - [x] ColorSwitchCCReport - [x] ColorSwitchCCSet - [x] ColorSwitchCCStartLevelChange - [x] ColorSwitchCCStopLevelChange - [x] ColorSwitchCCSupportedGet _(empty CC)_ - [x] ColorSwitchCCSupportedReport - [x] ConfigurationCCBulkGet - [x] ConfigurationCCBulkReport - [x] ConfigurationCCBulkSet - [x] ConfigurationCCDefaultReset _(empty CC)_ - [x] ConfigurationCCError **(constructor only)** - [x] ConfigurationCCGet - [x] ConfigurationCCInfoGet - [x] ConfigurationCCInfoReport - [x] ConfigurationCCNameGet - [x] ConfigurationCCNameReport - [x] ConfigurationCCPropertiesGet - [x] ConfigurationCCPropertiesReport - [x] ConfigurationCCReport - [x] ConfigurationCCSet - [x] DeviceResetLocallyCCNotification _(empty CC)_ - [x] DoorLockCCCapabilitiesGet _(empty CC)_ - [x] DoorLockCCCapabilitiesReport - [x] DoorLockCCConfigurationGet _(empty CC)_ - [x] DoorLockCCConfigurationReport - [x] DoorLockCCConfigurationSet - [x] DoorLockCCOperationGet _(empty CC)_ - [x] DoorLockCCOperationReport - [x] DoorLockCCOperationSet - [x] EntryControlCCConfigurationGet _(empty CC)_ - [x] EntryControlCCConfigurationReport - [x] EntryControlCCConfigurationSet - [x] EntryControlCCEventSupportedGet _(empty CC)_ - [x] EntryControlCCEventSupportedReport - [x] EntryControlCCKeySupportedGet _(empty CC)_ - [x] EntryControlCCKeySupportedReport - [x] EntryControlCCNotification - [x] FibaroVenetianBlindCCGet **(constructor only)** - [x] FibaroVenetianBlindCCReport - [x] FibaroVenetianBlindCCSet - [x] FirmwareUpdateMetaDataCCActivationReport - [x] FirmwareUpdateMetaDataCCActivationSet - [x] FirmwareUpdateMetaDataCCGet - [x] FirmwareUpdateMetaDataCCMetaDataGet _(empty CC)_ - [x] FirmwareUpdateMetaDataCCMetaDataReport - [x] FirmwareUpdateMetaDataCCPrepareGet - [x] FirmwareUpdateMetaDataCCPrepareReport - [x] FirmwareUpdateMetaDataCCReport - [x] FirmwareUpdateMetaDataCCRequestGet - [x] FirmwareUpdateMetaDataCCRequestReport - [x] FirmwareUpdateMetaDataCCStatusReport - [x] IndicatorCCGet - [x] IndicatorCCReport - [x] IndicatorCCSet - [x] IndicatorCCSupportedGet - [x] IndicatorCCSupportedReport - [x] LanguageCCGet _(empty CC)_ - [x] LanguageCCReport - [x] LanguageCCSet - [x] LockCCGet _(empty CC)_ - [x] LockCCReport - [x] LockCCSet - [x] ManufacturerSpecificCCDeviceSpecificGet - [x] ManufacturerSpecificCCDeviceSpecificReport - [x] ManufacturerSpecificCCGet _(empty CC)_ - [x] ManufacturerSpecificCCReport - [x] MeterCCGet - [x] MeterCCReport - [x] MeterCCReset - [x] MeterCCSupportedGet _(empty CC)_ - [x] MeterCCSupportedReport - [x] MultiChannelAssociationCCGet - [x] MultiChannelAssociationCCRemove - [x] MultiChannelAssociationCCReport - [x] MultiChannelAssociationCCSet - [x] MultiChannelAssociationCCSupportedGroupingsGet _(empty CC)_ - [x] MultiChannelAssociationCCSupportedGroupingsReport - [x] MultiChannelCCAggregatedMembersGet - [x] MultiChannelCCAggregatedMembersReport - [x] MultiChannelCCCapabilityGet - [x] MultiChannelCCCapabilityReport - [x] MultiChannelCCCommandEncapsulation - [x] MultiChannelCCEndPointFind - [x] MultiChannelCCEndPointFindReport - [x] MultiChannelCCEndPointGet _(empty CC)_ - [x] MultiChannelCCEndPointReport - [x] MultiChannelCCV1CommandEncapsulation - [x] MultiChannelCCV1Get - [x] MultiChannelCCV1Report - [x] MultiCommandCCCommandEncapsulation - [x] MultilevelSensorCCGet - [x] MultilevelSensorCCGetSupportedScale - [x] MultilevelSensorCCGetSupportedSensor _(empty CC)_ - [x] MultilevelSensorCCReport - [x] MultilevelSensorCCSupportedScaleReport - [x] MultilevelSensorCCSupportedSensorReport - [x] MultilevelSwitchCCGet _(empty CC)_ - [x] MultilevelSwitchCCReport - [x] MultilevelSwitchCCSet - [x] MultilevelSwitchCCStartLevelChange - [x] MultilevelSwitchCCStopLevelChange _(empty CC)_ - [x] MultilevelSwitchCCSupportedGet _(empty CC)_ - [x] MultilevelSwitchCCSupportedReport - [x] NodeNamingAndLocationCCLocationGet _(empty CC)_ - [x] NodeNamingAndLocationCCLocationReport - [x] NodeNamingAndLocationCCLocationSet - [x] NodeNamingAndLocationCCNameGet _(empty CC)_ - [x] NodeNamingAndLocationCCNameReport - [x] NodeNamingAndLocationCCNameSet - [x] NotificationCCEventSupportedGet - [x] NotificationCCEventSupportedReport - [x] NotificationCCGet - [x] NotificationCCReport - [x] NotificationCCSet - [x] NotificationCCSupportedGet _(empty CC)_ - [x] NotificationCCSupportedReport - [x] ProtectionCCExclusiveControlGet _(empty CC)_ - [x] ProtectionCCExclusiveControlReport - [x] ProtectionCCExclusiveControlSet - [x] ProtectionCCGet _(empty CC)_ - [x] ProtectionCCReport - [x] ProtectionCCSet - [x] ProtectionCCSupportedGet _(empty CC)_ - [x] ProtectionCCSupportedReport - [x] ProtectionCCTimeoutGet _(empty CC)_ - [x] ProtectionCCTimeoutReport - [x] ProtectionCCTimeoutSet - [x] SceneActivationCCSet - [x] SceneActuatorConfigurationCCGet - [x] SceneActuatorConfigurationCCReport - [x] SceneActuatorConfigurationCCSet - [x] SceneControllerConfigurationCCGet - [x] SceneControllerConfigurationCCReport - [x] SceneControllerConfigurationCCSet - [x] SecurityCCCommandEncapsulation - [x] SecurityCCCommandEncapsulationNonceGet _(empty CC)_ - [x] SecurityCCCommandsSupportedGet _(empty CC)_ - [x] SecurityCCCommandsSupportedReport - [x] SecurityCCNetworkKeySet - [x] SecurityCCNetworkKeyVerify _(empty CC)_ - [x] SecurityCCNonceGet _(empty CC)_ - [x] SecurityCCNonceReport - [x] SecurityCCSchemeGet - [x] SecurityCCSchemeInherit - [x] SecurityCCSchemeReport **(constructor only)** - [x] SoundSwitchCCConfigurationGet _(empty CC)_ - [x] SoundSwitchCCConfigurationReport - [x] SoundSwitchCCConfigurationSet - [x] SoundSwitchCCToneInfoGet - [x] SoundSwitchCCToneInfoReport - [x] SoundSwitchCCTonePlayGet _(empty CC)_ - [x] SoundSwitchCCTonePlayReport - [x] SoundSwitchCCTonePlaySet - [x] SoundSwitchCCTonesNumberGet _(empty CC)_ - [x] SoundSwitchCCTonesNumberReport - [x] SupervisionCCGet - [x] SupervisionCCReport - [x] ThermostatFanModeCCGet _(empty CC)_ - [x] ThermostatFanModeCCReport - [x] ThermostatFanModeCCSet - [x] ThermostatFanModeCCSupportedGet _(empty CC)_ - [x] ThermostatFanModeCCSupportedReport - [x] ThermostatFanStateCCGet _(empty CC)_ - [x] ThermostatFanStateCCReport - [x] ThermostatModeCCGet _(empty CC)_ - [x] ThermostatModeCCReport - [x] ThermostatModeCCSet - [x] ThermostatModeCCSupportedGet _(empty CC)_ - [x] ThermostatModeCCSupportedReport - [x] ThermostatOperatingStateCCGet _(empty CC)_ - [x] ThermostatOperatingStateCCReport - [x] ThermostatSetbackCCGet _(empty CC)_ - [x] ThermostatSetbackCCReport - [x] ThermostatSetbackCCSet - [x] ThermostatSetpointCCCapabilitiesGet - [x] ThermostatSetpointCCCapabilitiesReport - [x] ThermostatSetpointCCGet - [x] ThermostatSetpointCCReport - [x] ThermostatSetpointCCSet - [x] ThermostatSetpointCCSupportedGet _(empty CC)_ - [x] ThermostatSetpointCCSupportedReport - [x] TimeCCDateGet _(empty CC)_ - [x] TimeCCDateReport - [x] TimeCCTimeGet _(empty CC)_ - [x] TimeCCTimeOffsetGet _(empty CC)_ - [x] TimeCCTimeOffsetReport - [x] TimeCCTimeOffsetSet - [x] TimeCCTimeReport - [x] TimeParametersCCGet _(empty CC)_ - [x] TimeParametersCCReport - [x] TimeParametersCCSet - [x] UserCodeCCCapabilitiesGet _(empty CC)_ - [x] UserCodeCCCapabilitiesReport - [x] UserCodeCCExtendedUserCodeGet - [x] UserCodeCCExtendedUserCodeReport - [x] UserCodeCCExtendedUserCodeSet - [x] UserCodeCCGet - [x] UserCodeCCKeypadModeGet _(empty CC)_ - [x] UserCodeCCKeypadModeReport - [x] UserCodeCCKeypadModeSet - [x] UserCodeCCMasterCodeGet _(empty CC)_ - [x] UserCodeCCMasterCodeReport - [x] UserCodeCCMasterCodeSet - [x] UserCodeCCReport - [x] UserCodeCCSet - [x] UserCodeCCUserCodeChecksumGet _(empty CC)_ - [x] UserCodeCCUserCodeChecksumReport - [x] UserCodeCCUsersNumberGet _(empty CC)_ - [x] UserCodeCCUsersNumberReport - [x] VersionCCCapabilitiesGet _(empty CC)_ - [x] VersionCCCapabilitiesReport - [x] VersionCCCommandClassGet - [x] VersionCCCommandClassReport - [x] VersionCCGet _(empty CC)_ - [x] VersionCCReport - [x] VersionCCZWaveSoftwareGet _(empty CC)_ - [x] VersionCCZWaveSoftwareReport - [x] WakeUpCCIntervalCapabilitiesGet _(empty CC)_ - [x] WakeUpCCIntervalCapabilitiesReport - [x] WakeUpCCIntervalGet _(empty CC)_ - [x] WakeUpCCIntervalReport 
263951,293556,https://api.github.com/repos/codewars/docs/issues/226,bug,2021-01-08T21:24:48Z,CONTRIBUTOR,https://api.github.com/repos/codewars/docs,"Links with anchors may not send the user at the correct height in the page https://docs.codewars.com/authoring/guidelines/submission-tests/#performance-tests with this, the user should land on the perf tests part, tho it's not the case (at least for me?). I believe it's somehow related to the rendering of the page and possibly its size: I temporarily saw the page width a different width, then the rendering finished, adding the sidebar on the left (maybe the right one too, not sure) and going to dark mode, then...: actual: land's here: ![image](https://user-images.githubusercontent.com/32236948/104065477-13c3aa80-5200-11eb-977f-22f291d57bea.png) expected: ![image](https://user-images.githubusercontent.com/32236948/104065530-2d64f200-5200-11eb-9f17-5f9dbfd83089.png) "
207378,230595,https://api.github.com/repos/NULL-header/ts-twitterer/issues/99,enhancement,2021-02-11T17:05:10Z,OWNER,https://api.github.com/repos/NULL-header/ts-twitterer,ルーティングの調整 サンプルAPIを調整し忘れていたので、APIのルーティングやWebpackの調整も含めて行う。
348189,387092,https://api.github.com/repos/puppetlabs/puppet-modulebuilder/issues/38,enhancement,2021-02-14T19:22:25Z,CONTRIBUTOR,https://api.github.com/repos/puppetlabs/puppet-modulebuilder,"New release Various changes have been merged recently. I'd like to be able to use them without a git checkout. If there's anything I can do to help a release, let me know."
125168,139095,https://api.github.com/repos/simple-icons/svg-to-pdf-bot/issues/2,bug,2021-02-18T15:08:01Z,MEMBER,https://api.github.com/repos/simple-icons/svg-to-pdf-bot,Change CI Provider Looks like [the problems that affected the main repo](https://github.com/simple-icons/simple-icons/issues/4124) have now reared their head here as well: https://travis-ci.com/github/simple-icons/svg-to-pdf-bot
643444,715162,https://api.github.com/repos/correctcomputation/checkedc-clang/issues/427,bug,2021-02-15T17:20:48Z,COLLABORATOR,https://api.github.com/repos/correctcomputation/checkedc-clang,"Merging fails incorrectly while converting bc benchmark In this example, merging the second declaration of `free` fails even though the declarations should be compatible. This affects the bc benchmark in PtrDist. ```c _Itype_for_any(T) void free(void * : itype(_Array_ptr<T>)); void b(void) { char **c; free(c); } void free(void *); ``` ``` /home/john/b.c:6:6: fatal error: merging failed for 'free' due to conflicting types for parameter 0 void free(void *); ^ ```"
517702,575326,https://api.github.com/repos/harrycoffey/python-random-quote/issues/4,bug,2021-02-19T15:01:42Z,NONE,https://api.github.com/repos/harrycoffey/python-random-quote,"Explore Python on your own Though you've completed this course, there's plenty more to learn. You can even use this program as a place to start. Here are some ideas for next steps: - [ ] Add some more quotes to your text file - [ ] Print out more than one quote at a time - [ ] Remove that extra line (called a newline) when printing - [ ] Learn about file writing and add quotes programmatically Give one or more of those a shot, then when you're really ready to move on, **close this issue**. "
504647,560908,https://api.github.com/repos/sgratzl/slack-cleaner/issues/90,question,2021-01-07T20:07:01Z,NONE,https://api.github.com/repos/sgratzl/slack-cleaner,"What OAuth scope/method is needed to be able to bulk delete messages <!-- A clear and concise description of what your question is. If possible add a CodePen or CodeSandbox link to illustrate your problem --> Want to use this to bulk delete old messages, mostly from bots. What permissions are needed? **Screenshots / Sketches** <!--If applicable, add screenshots or sketches to help explain your question.--> **Context** - Version: - Python Version: 3.7.5 **Additional context** <!--Add any other context about the question here.--> "
670322,745036,https://api.github.com/repos/premnirmal/StockTicker/issues/90,enhancement,2019-10-09T16:14:13Z,NONE,https://api.github.com/repos/premnirmal/StockTicker,"Display total holdings It would be very valuable to see somewhere the total amount of holdings (summing all stocks). Right now one can see the holdings for each separate stock and some them up on a calculator, but this is far from practical. For me, ""total holdings"" is the most valuable information to help understand my position."
154446,171701,https://api.github.com/repos/sqlalchemy/sqlalchemy/issues/6213,bug,2021-04-07T09:37:27Z,NONE,https://api.github.com/repos/sqlalchemy/sqlalchemy,"typing is used on Python 3.4 but not declared as a dependency **Describe the bug** The import `from typing import TYPE_CHECKING` in `lib/sqlalchemy/util/compat.py` is guarded with `if py3k:`. This is fine for SQLAlchemy 1.4, but not 1.3.x, which still supports Python 3.4. The `typing` module was added to Python's stdlib in 3.5. **Expected behavior** The import is guarded with `if py35:` or [`typing`](https://pypi.org/project/typing/) is listed in `install_requires` for Python 3.4. **To Reproduce** ```sh docker run --rm -it --entrypoint bash python:3.4-slim # python -m pip install sqlalchemy # python >>> import sqlalchemy ``` **Error** ``` Traceback (most recent call last): File ""<stdin>"", line 1, in <module> File ""/usr/local/lib/python3.4/site-packages/sqlalchemy/__init__.py"", line 8, in <module> from . import util as _util # noqa File ""/usr/local/lib/python3.4/site-packages/sqlalchemy/util/__init__.py"", line 14, in <module> from ._collections import coerce_generator_arg # noqa File ""/usr/local/lib/python3.4/site-packages/sqlalchemy/util/_collections.py"", line 16, in <module> from .compat import binary_types File ""/usr/local/lib/python3.4/site-packages/sqlalchemy/util/compat.py"", line 189, in <module> from typing import TYPE_CHECKING ImportError: No module named 'typing' ``` **Versions.** - OS: all - Python: 3.4 - SQLAlchemy: **1.3**.24 - Database: n/a - DBAPI: n/a **Additional context** n/a"
15583,17379,https://api.github.com/repos/SAP/fundamental-ngx/issues/4759,bug,2021-02-24T01:03:59Z,CONTRIBUTOR,https://api.github.com/repos/SAP/fundamental-ngx,"Theming selector on the doc site is missing #### Is this a bug, enhancement, or feature request? bug #### Briefly describe your proposal. the theme selector on the doc website is missing. #### Which versions of Angular and Fundamental Library for Angular are affected? (If this is a feature request, use current version.) latest main branch "
544572,605287,https://api.github.com/repos/innobead/huber/issues/27,bug,2021-02-07T07:46:14Z,OWNER,https://api.github.com/repos/innobead/huber,Incorrectly update to the recent release version of package instead of the latest version **Describe the bug** A clear and concise description of what the bug is. **To Reproduce** Steps to reproduce the behavior with debug log enabled. `--log-level=debug` **Expected behavior** A clear and concise description of what you expected to happen. **Environment** - OS version - run `uname -a` - Huber version - run `huber -V` **Additional context** Add any other context about the problem here. 
229771,255527,https://api.github.com/repos/YunPC/python-coding-study/issues/1,enhancement,2021-04-08T04:55:47Z,NONE,https://api.github.com/repos/YunPC/python-coding-study,210408_string_kjw - [x] isPalindrome - [x] reverseString
196083,218022,https://api.github.com/repos/ofiwg/libfabric/issues/5015,enhancement,2019-05-07T16:19:46Z,CONTRIBUTOR,https://api.github.com/repos/ofiwg/libfabric,"add fi_getopt/fi_setopt parameter to get/set alignment of MULTI-RECV messages From a libfabric-users email thread: I use a multi-recv buffer to receive metadata messages from clients. The first thing I have to do when I receive a message is memcpy it somewhere else so that it is 8-byte aligned, so that I don’t segfault when referencing fields in the message. It would be nice if there was a fi_setopt() variable for multi-recv buffers, say FI_MIN_MSG_ALIGNMENT, which the application could set to 8 or whatever, guaranteeing that as libfabric lands new messages into the multi-recv buffer that they would be aligned on 8-byte boundaries, so that an application could safely reference metadata messages in-place in the multi-recv buffer without segfaulting, avoiding constant memcpy calls. Reply from Sean: The API already allows the provider to perform alignment as needed, so I don't see any issue with supporting get/set calls to discover and, possible, set this. The app would still need to handle fi_setopt() failing if the alignment can't be supported. This would likely need to be set early on, maybe before an EP is enabled."
572406,636117,https://api.github.com/repos/kovidgoyal/kitty/issues/3501,bug,2021-04-19T13:18:21Z,NONE,https://api.github.com/repos/kovidgoyal/kitty,"Window rendering issues in Sway OS: Arch Linux WM: Sway As of the most recent update (0.20.0) Kitty windows have a large white bar at the top and a permanent drop shadow that does not resize with the window: ![2021-04-19T14:08:11,533794951+01:00](https://user-images.githubusercontent.com/8879583/115242297-a6d28180-a119-11eb-963c-13ea440d450d.png) **To Reproduce** Update kitty on Arch Linux to 0.20.0 and open a window in a Sway session. The issue persists with kitty --config NONE **Expected behavior** A normal looking terminal window ``` Output of kitty --debug-config ❯ kitty --debug-config kitty 0.20.0 created by Kovid Goyal Linux fnord 5.11.15-zen1-2-zen #1 ZEN SMP PREEMPT Sat, 17 Apr 2021 00:22:34 +0000 x86_64 Arch Linux \r (\l) LSB_VERSION=1.4 DISTRIB_ID=Arch DISTRIB_RELEASE=rolling DISTRIB_DESCRIPTION=""Arch Linux"" Loaded config files: /home/nick/.config/kitty/kitty.conf Running under: Wayland Config options different from defaults: background Color(red=6, green=16, blue=33) background_opacity 0.95 color0 Color(red=6, green=16, blue=33) color1 Color(red=34, green=84, blue=170) color10 Color(red=63, green=99, blue=170) color11 Color(red=147, green=156, blue=198) color12 Color(red=100, green=109, blue=175) color13 Color(red=150, green=109, blue=167) color14 Color(red=170, green=90, blue=116) color15 Color(red=192, green=195, blue=199) color2 Color(red=63, green=99, blue=170) color3 Color(red=147, green=156, blue=198) color4 Color(red=100, green=109, blue=175) color5 Color(red=150, green=109, blue=167) color6 Color(red=170, green=90, blue=116) color7 Color(red=192, green=195, blue=199) color8 Color(red=68, green=75, blue=88) color9 Color(red=34, green=84, blue=170) cursor Color(red=192, green=195, blue=199) font_family JetBrains Mono font_size 8.0 foreground Color(red=192, green=195, blue=199) remember_window_size False window_margin_width FloatEdges(left=20.0, top=20.0, right=20.0, bottom=20.0) ```"
532622,591978,https://api.github.com/repos/nextcloud/docker/issues/873,enhancement,2019-09-29T01:36:49Z,NONE,https://api.github.com/repos/nextcloud/docker,"Suggestion: Allow us to specify Upload Max Size in Docker-Compose <!-- Thanks for reporting issues back to Nextcloud! This is the issue tracker of Nextcloud, if you have any support question please check out https://nextcloud.com/support This is the bug tracker for the Server component. Find other components at https://github.com/nextcloud/ For reporting potential security issues please see https://nextcloud.com/security/ To make it possible for us to help you please fill out below information carefully. You can also use the Issue Template application to prefill most of the required information: https://apps.nextcloud.com/apps/issuetemplate If you are a customer, please submit your issue directly in the Nextcloud Portal https://portal.nextcloud.com so it gets resolved more quickly by our dedicated engineers. Note that Nextcloud is an open source project backed by Nextcloud GmbH. Most of our volunteers are home users and thus primarily care about issues that affect home users. Our paid engineers prioritize issues of our customers. If you are neither a home user nor a customer, consider paying somebody to fix your issue, do it yourself or become a customer. --> **Is your feature request related to a problem? Please describe.** Yes, I cannot change the ""Upload max size"", which is set to 2MB by default. I am using a docker-compose.yml file to easily start up nextcloud but, for the life of me, dont know how to edit this one crucial setting that honestly needs to be added. Maybe as an ENV setting or something **Describe the solution you'd like** Just like how I can mount the /html file, I should have an ""ENVIRONMENT"" setting that allows me to specify the upload max size, just like how you can specify SMTP settings and such. No, doing commands in the docker container itself is bad because if you copy that same docker-compose file and run it, you would have to remember what command you need to type to change the upload max size. **Describe alternatives you've considered** No need, its simple as that **Additional context** Allow us to change timezone, userid, usergroup (inside the container) and more with this. "
253784,282287,https://api.github.com/repos/kobajs/analytics-dashboard/issues/17,enhancement,2021-02-21T01:55:05Z,OWNER,https://api.github.com/repos/kobajs/analytics-dashboard,AnalyticsPriceReducer Request # Description This project needs to have this reducer to connect all needed states and functions to the components that feature #2 uses ## Expect - [x] Reducer implemented - [x] Tests implemented - [x] Connects to PortsSelect providing availablePorts and ports state/updaters - [x] Connects to MarketPositions providing marketPositions state/updaters - [x] Connects to MarketDatePicker providing dates state/updaters - [x] Connects to MarketRateChart providing marketRates state 
144954,161131,https://api.github.com/repos/phalcon/cphalcon/issues/15471,enhancement,2021-05-06T13:10:58Z,CONTRIBUTOR,https://api.github.com/repos/phalcon/cphalcon,"[BUG]: Phalcon v5.0.0-alpha.2 - whats wrong with models cache? **Describe the bug** I try to migrate to Phalcon v.5 (php8) or just still try it with my project- need to be sure they will work fine with next releases. And yes, they works almost fine... except something with cache stuff. The error i get is: `Fatal error: Uncaught TypeError: Phalcon\Mvc\Model\Resultset\Simple::__construct(): Argument #4 ($cache) must be of type ?Phalcon\Cache\Adapter\AdapterInterface, Phalcon\Cache given in v1\modules\client\controllers\ControllerBase.php on line 33` So, in this line i have: ```php $articles = \Models\Articles::find([ 'conditions' => 'is_global=1', 'cache' => [ 'key' => 'global-articles' ] ]); ``` ... and see is something related with models cache service. Its init like that: ```php /* * Set the models cache service */ $di->set('modelsCache', function () use ($config) { $lifetime = 60 * 60 * 24 * 7; // 7 days if ($config->development) { $lifetime = 60; // 1 min } // Create folder if did not exists $folder = BASE_PATH . 'cache/queries/'; $serializerFactory = new \Phalcon\Storage\SerializerFactory(); $adapter = new \Phalcon\Cache\Adapter\Stream($serializerFactory, [ 'storageDir' => $folder, 'lifetime' => $lifetime ]); $cache = new \Phalcon\Cache($adapter); return $cache; }); ``` Soo... maybe the mistake is Phalcon\Cache, but this works in Phalcon 4.x. So how must be changed? Thanks :) And may the force be with you! **Details** - Phalcon version: v5.0.0-alpha.2 - PHP Version: 8.0.6 - Operating System: Windows - Server: Apache "
263947,293551,https://api.github.com/repos/irllabs/roundaround/issues/49,bug,2021-01-03T23:27:43Z,NONE,https://api.github.com/repos/irllabs/roundaround,"A LOT of doing/undoing/doing again for many interactions Tried a collabo with 3 people, seeing LOTS of doing something (change a step, add a layer, change velocity/probability)..."
66434,73867,https://api.github.com/repos/searx/searx/issues/2455,enhancement,2021-01-10T09:25:02Z,NONE,https://api.github.com/repos/searx/searx,"Deep Web Search support **Is your feature request related to a problem? Please describe.** The current Deep Web search engines like Ahmia are not that good. **Describe the solution you'd like** That you can do all the normal things in Searx like searching for music or general,but you can set that it searches through the Deep Web instead of Clear Web. **Additional context** That obviously only works if you are using Tor. It could be hard to achieve,cause I don't know any Deep Web Search Engine that can do all the thing that you can do with Searx. Also you have to add a good safe mode,so that gore gets blocked,no one wants to see that,I just wanna browse some crappy sites."
669688,744329,https://api.github.com/repos/getsentry/sentry-java/issues/1178,enhancement,2021-01-17T05:30:23Z,NONE,https://api.github.com/repos/getsentry/sentry-java,"SentrySpanClientHttpRequestInterceptor should be in sentry-spring instead of sentry-spring-boot-starter _Platform:_ - [ ] Android -> If yes, which Device API (and compileSdkVersion/targetSdkVersion/Build tools) version? - [x] Java -> If yes, which Java (and sourceCompatibility/targetCompatibility) version? - [ ] Kotlin -> If yes, which Kotlin (and jvmTarget) version? - [ ] NDK -> If yes, which NDK/CMake version? - [ ] React-Native -> If yes, which version? - [ ] Timber -> If yes, which version? - [ ] Log4j2 -> If yes, which version? - [ ] Logback -> If yes, which version? - [ ] Spring -> If yes, which version? _IDE:_ - [ ] Android Studio -> If yes, which version? - [ ] IntelliJ -> If yes, which version? - [ ] Other -> If yes, which one? _Build system:_ - [ ] Gradle -> If yes, which version? - [ ] Buck -> If yes, which version? - [ ] Bazel -> If yes, which version? - [ ] Maven -> If yes, which version? - [ ] Other -> If yes, which one? _Android Gradle Plugin:_ - [ ] Yes -> If yes, which version? - [ ] No _Sentry Android Gradle Plugin:_ - [ ] Yes -> If yes, which version? - [ ] No _Proguard/R8:_ - [ ] Enabled - [ ] Disabled _Platform installed with:_ - [ ] JCenter - [ ] Bintray - [ ] Maven Central - [ ] Manually The version of the SDK: **4.0.0.alpha-2** --- I have the following issue: `SentrySpanClientHttpRequestInterceptor` does not have any Spring Boot dependencies and should be in `sentry-spring` so that Spring apps not using Spring Boot can use it. That would seem to be consistent with `SentryTracingFilter`'s presence in `sentry-spring`. "
608163,675849,https://api.github.com/repos/DSpace/dspace-angular/issues/1115,bug,2021-04-19T18:33:34Z,MEMBER,https://api.github.com/repos/DSpace/dspace-angular,"Private/Withdrawn filters no longer working in Administrative Search **Describe the bug** The Private/Withdrawn filters in the Administrative Search always seem to return zero results. **To Reproduce** Steps to reproduce the behavior: 1. Login as an Admin and go to https://demo7.dspace.org/admin/search 2. Currently, on the demo site, there is one Withdrawn item & one Private Item 3. Click the ""Withdrawn: Yes"" filter. You'll see zero results, even though one withdrawn item exists here: https://demo7.dspace.org/items/56cb766d-4b8a-40f6-a18f-0f8ae41e1ba1 * NOTE: After selecting this filter, the value strangely changes to ""True"" 4. Click the ""Private: Yes"" filter. You'll also see zero results, even though one private item exists here: https://demo7.dspace.org/items/517e94a2-f2c2-4653-8a92-ea718c14a1ee * NOTE: After selecting this filter, the value strangely changes to ""False"" **Expected behavior** Obviously, these filters should both work. Also, ideally the value shouldn't change from ""Yes"" to True/False"" after selecting it. Either the value should always be ""Yes/No"" or always be ""True/False"" (either is fine). "
26804,29867,https://api.github.com/repos/TeamNewPipe/NewPipe/issues/5467,bug,2021-01-20T22:43:58Z,MEMBER,https://api.github.com/repos/TeamNewPipe/NewPipe,"Update check is run too often ### Checklist This affects all NewPipe versions since the update check was implemented, basically. But yes, it applies to the latest version, too. - [x] I am using the latest version - 0.20.9 - [x] I checked, but didn't find any duplicates (open OR closed) of this issue in the repo. - [x] I have read the contribution guidelines given at https://github.com/TeamNewPipe/NewPipe/blob/HEAD/.github/CONTRIBUTING.md. - [x] This issue contains only one bug. I will open one issue for every bug report I want to file. ### Steps to reproduce the bug See following section. ### Actual behaviour The update check is run every time the app is opened freshly. To be precise, it occurs in `App.onCreate`. @B0pol thinks this method also runs when the device is rotated, which would be quite annoying. Since many people have switched to our own builds in the last couple of weeks (basically, since F-Droid has failed to provide up-to-date binaries), this starts to create some significant load on the server. It's not hitting any limits, but enough to increase the load count and trigger monitoring. There is also a privacy aspect. I was looking at the logs a bit. They're of course anonymized, but I can see clusters of same-range requests, close nearby. This probably could be abused to guesstimate how long and when people use NewPipe. As we don't want to gather any form of usage statistics (we also don't collect the current versions), we should do something against it. ### Expected behavior There needs to be some client-side rate limiting. It makes no sense to check for updates faster than, say, 6-12 hours. We don't release that often. A push solution would be nice, but we don't have anything like that in place, so we should keep polling. Just reduce the frequency. I suggest to let the server control these timeouts. This allows us to react on load peaks and similar things better. HTTP provides the `Expires` header, which seems to be a perfect match. I would combine this with some hardcoded limits to have some protection against configuration flaws on the server side. I could imagine having a lower limit of 6 hours, as well as a top limit of 48 or even 72 hours. The lower limit shall ensure that update checks aren't run too frequently even if the server doesn't implement the `Expires` header properly. The upper limit makes sure that update checks are run at least every couple days to protect against configuration mistakes. ### Screenshots/Screen recordings -/- ### Logs -/- (the only logs I have are server logs, and you know I won't share them with anyone) ### Device info Doesn't matter. Probably many different ones. "
11418,12745,https://api.github.com/repos/lislis/katharsis.lol/issues/83,enhancement,2021-02-17T12:41:14Z,OWNER,https://api.github.com/repos/lislis/katharsis.lol,favicon social media images
580405,644969,https://api.github.com/repos/BogdanCerovac/aXeSiA/issues/24,enhancement,2021-04-09T19:55:49Z,OWNER,https://api.github.com/repos/BogdanCerovac/aXeSiA,"Better summary of summaries in the reporting - statistically correct exponation Better algorithm needed to ""promote"" more serious issues higher and enable support for future scores that can be added. Maybe thinking of some kind of weights. TODO before coding: - think of weighting - not all issues have same weights, tools usually report the impact"
257421,286313,https://api.github.com/repos/department-of-veterans-affairs/va.gov-cms/issues/4897,enhancement,2021-04-01T17:52:50Z,CONTRIBUTOR,https://api.github.com/repos/department-of-veterans-affairs/va.gov-cms,"Style the date on EFF form displays per design (but without link) ## User Story or Problem Statement As an editor of a page with centralized content, i want to know when the centralized content was last updated ![Screenshot_2021-04-01__1_45_PM](https://user-images.githubusercontent.com/643678/113333914-0b57a900-92f1-11eb-8a5f-345e61c449c6.png) ## Acceptance Criteria - [ ] See screenshot - [ ] Set ""Show source updated date"" to yes on all Vet Center EFF field widgets (check with @rachel-kauff on this) ## Implementation steps - [ ] Theme the EFF form widget ## Not in scope - [ ] Linking the last updated metadata to the source. (That's in #4054) "
180075,200195,https://api.github.com/repos/Automattic/node-canvas/issues/977,bug,2017-08-30T06:55:39Z,CONTRIBUTOR,https://api.github.com/repos/Automattic/node-canvas,"Using font family multiple times results in default font ## Issue or Feature When registering multiple font files with the same font family, but different styles (like in `examples/font.js`), the default font is used instead of the given font files. When using different font family names for every font file, it works. Right now, `examples/font.js` creates this image: ![font2](https://user-images.githubusercontent.com/119684/29859100-da6b0ac4-8d60-11e7-8280-b70cb8b641de.png) As you can see, the `Pfennig` font is not used at all. Changing the font definitions like this (and changing the `font` property on the rendering context accordingly): ```js Canvas.registerFont(fontFile('Pfennig.ttf'), {family: 'Pfennig'}) Canvas.registerFont(fontFile('PfennigBold.ttf'), {family: 'PfennigBold', weight: 'bold'}) Canvas.registerFont(fontFile('PfennigItalic.ttf'), {family: 'PfennigItalic', style: 'italic'}) Canvas.registerFont(fontFile('PfennigBoldItalic.ttf'), {family: 'PfennigBoldItalic', weight: 'bold', style: 'italic'}) ``` This results in: ![font](https://user-images.githubusercontent.com/119684/29859081-c6c651cc-8d60-11e7-91ba-203c612cd19f.png) ## Your Environment * Version of node-canvas (e.g. 1.4.0): 2.0.0-alpha.3 * Environment (e.g. node 4.2.0 on Mac OS X 10.8): node 7.9.0 on macOS 10.12.6"
32445,36154,https://api.github.com/repos/nuxt-company/vue-telescope-analyzer/issues/34,bug,2021-01-27T15:13:31Z,NONE,https://api.github.com/repos/nuxt-company/vue-telescope-analyzer,"Firefox addon url is broken Firefox vue-telemetry addon url is broken, page not found. ### Reproduction Link https://addons.mozilla.org/en-US/firefox/addon/vue-telemetry/"
457186,508130,https://api.github.com/repos/threeplanetssoftware/apple_cloud_notes_parser/issues/17,bug,2020-12-21T20:09:12Z,NONE,https://api.github.com/repos/threeplanetssoftware/apple_cloud_notes_parser,"database disk image is malformed (SQLite3::CorruptException) ``` Starting Apple Notes Parser at Mon Dec 21 15:08:39 2020 Storing the results in /Users/dmd/Dropbox/bk/AppleNotes/2020_12_21-15_08_39 Created a new AppleBackup from Mac backup: /Users/dmd/Library/Group Containers/group.com.apple.notes/ Guessed Notes Version: 14 Skipping Note ID 19 due to a missing folder or account, check the debug log for more details. Skipping Note ID 25 due to a missing folder or account, check the debug log for more details. Updated AppleNoteStore object with 109 AppleNotes in 8 folders belonging to 1 accounts. Adding the ZICNOTEDATA.ZPLAINTEXT and ZICNOTEDATA.ZDECOMPRESSEDDATA columns, this takes a few seconds Traceback (most recent call last): 13: from notes_cloud_ripper.rb:125:in `<main>' 12: from notes_cloud_ripper.rb:125:in `each' 11: from notes_cloud_ripper.rb:127:in `block in <main>' 10: from /Users/dmd/Dropbox (Personal)/code/apple_cloud_notes_parser/lib/AppleNoteStore.rb:217:in `add_plain_text_to_database' 9: from /Users/dmd/Dropbox (Personal)/code/apple_cloud_notes_parser/lib/AppleNoteStore.rb:217:in `each' 8: from /Users/dmd/Dropbox (Personal)/code/apple_cloud_notes_parser/lib/AppleNoteStore.rb:220:in `block in add_plain_text_to_database' 7: from /System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/lib/ruby/gems/2.6.0/gems/sqlite3-1.3.13/lib/sqlite3/database.rb:137:in `execute' 6: from /System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/lib/ruby/gems/2.6.0/gems/sqlite3-1.3.13/lib/sqlite3/database.rb:95:in `prepare' 5: from /System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/lib/ruby/gems/2.6.0/gems/sqlite3-1.3.13/lib/sqlite3/database.rb:152:in `block in execute' 4: from /System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/lib/ruby/gems/2.6.0/gems/sqlite3-1.3.13/lib/sqlite3/database.rb:152:in `map' 3: from /System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/lib/ruby/gems/2.6.0/gems/sqlite3-1.3.13/lib/sqlite3/statement.rb:107:in `each' 2: from /System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/lib/ruby/gems/2.6.0/gems/sqlite3-1.3.13/lib/sqlite3/statement.rb:107:in `loop' 1: from /System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/lib/ruby/gems/2.6.0/gems/sqlite3-1.3.13/lib/sqlite3/statement.rb:108:in `block in each' /System/Library/Frameworks/Ruby.framework/Versions/2.6/usr/lib/ruby/gems/2.6.0/gems/sqlite3-1.3.13/lib/sqlite3/statement.rb:108:in `step': database disk image is malformed (SQLite3::CorruptException) ```"
360514,400781,https://api.github.com/repos/taosdata/TDengine/issues/583,bug,2019-09-29T09:19:47Z,NONE,https://api.github.com/repos/taosdata/TDengine,"No effect when assign values to the placeholder using Prepared Statement. 无论如何在对占位符赋值时指定Index，PreparedStatement依然会按照调用setXXX的顺序进行赋值。 例如如下报错信息： Para #6 is int, value = null Para #7 is char, value = ""abcd"" Para #2 is char, value = ""wtf"" Para #8 is boolean, value = true Para #3 is boolean, value = null java.sql.SQLException: TDengine Error: invalid SQL: invalid SQL: near ""values ('NULL','""abcd""','""wtf""',true,'NULL')"" syntax error 程序是期望按照从上到下的顺序，对6 7 2 8 3位置的占位符进行对应的赋值 但是实际上可以看见参数并未按照提供的占位符index（是6 7 2 8 3）进行赋值，而是按照调用的顺序赋值（1 2 3 4 5），导致('NULL','""abcd""','""wtf""',true,'NULL')的结果"
15291,17051,https://api.github.com/repos/denosaurs/mod.land/issues/19,bug,2021-04-09T11:37:25Z,CONTRIBUTOR,https://api.github.com/repos/denosaurs/mod.land,"Lint action fails because of files other than cnames.ts **Describe the bug** When you edit cnames.ts to add your domain and make a pull request, there are two checks that are run. First it checks if the file passes `deno fmt` and second it checks if the file passes `deno lint`. However, due to linting errors in files other than cnames.ts (that we little dinos didnt touch) it always fails. **To Reproduce** Steps to reproduce the behavior: * Fork repo * Edit cnames.ts and add your domain * Make sure you made no errors in cnames.ts * Make a pull request to the main repo **Expected behavior** The checks pass. **Additional context** All fmt checks pass but lint check fails on some other files. Fixes #18 "
38147,42510,https://api.github.com/repos/UZHASE/bnbexplorer-backend/issues/62,bug,2021-05-15T09:58:00Z,NONE,https://api.github.com/repos/UZHASE/bnbexplorer-backend,"ValueError: The provided filter criteria are too restrictive! Hi, this query returns a ValueError: http://localhost:8080/api/v1/airbnb-explorer/listings/recommendations?listingId=32990282&hostId=30698503&priceMin=50&priceMax=100&minNights=5&availability=90 <img width=""2528"" alt=""Screenshot 2021-05-15 at 11 56 29"" src=""https://user-images.githubusercontent.com/43517763/118356257-970d5800-b574-11eb-8db7-dd7675d041c7.png""> Is the problem that no similar listings were found? "
207432,230655,https://api.github.com/repos/bpmn-io/bpmn-js/issues/1367,bug,2020-11-09T13:58:22Z,NONE,https://api.github.com/repos/bpmn-io/bpmn-js,"Imports with SubProcesses fail __Describe the Bug__ When importing a file like the following: <details> <summary>Modelio-Export</summary> `<?xml version=""1.0"" encoding=""UTF-8"" standalone=""yes""?> <definitions xmlns=""http://www.omg.org/spec/BPMN/20100524/MODEL"" xmlns:ns2=""http://www.omg.org/spec/DD/20100524/DI"" xmlns:ns3=""http://www.omg.org/spec/DD/20100524/DC"" xmlns:ns4=""http://www.omg.org/spec/BPMN/20100524/DI"" targetNamespace=""http://www.omg.org/bpmn20""> <process isClosed=""false"" isExecutable=""false"" processType=""None"" name=""Process"" id=""modelio-041041b9-3ac4-4878-930a-e8af9cba12d1""> <sequenceFlow sourceRef=""modelio-57078e54-44a7-4403-891c-4fd71c8d3e85"" targetRef=""modelio-903c7131-8d64-4676-aa25-88780558d570"" name="""" id=""modelio-9acfe78d-ca28-470b-8581-875a7b474b88""/> <sequenceFlow sourceRef=""modelio-56567f6e-d67f-4369-9754-28fb4e9dec5f"" targetRef=""modelio-57078e54-44a7-4403-891c-4fd71c8d3e85"" name="""" id=""modelio-67a6df4b-a647-4b5d-9a4b-979383bab537""/> <startEvent isInterrupting=""true"" parallelMultiple=""false"" name=""Start"" id=""modelio-56567f6e-d67f-4369-9754-28fb4e9dec5f""> <ns5:outgoing xmlns:ns5=""http://www.omg.org/spec/BPMN/20100524/MODEL"" xmlns="""">modelio-67a6df4b-a647-4b5d-9a4b-979383bab537</ns5:outgoing> </startEvent> <subProcess triggeredByEvent=""false"" isForCompensation=""false"" startQuantity=""1"" completionQuantity=""1"" name=""Task"" id=""modelio-57078e54-44a7-4403-891c-4fd71c8d3e85""> <ns5:incoming xmlns:ns5=""http://www.omg.org/spec/BPMN/20100524/MODEL"" xmlns="""">modelio-67a6df4b-a647-4b5d-9a4b-979383bab537</ns5:incoming> <ns5:outgoing xmlns:ns5=""http://www.omg.org/spec/BPMN/20100524/MODEL"" xmlns="""">modelio-9acfe78d-ca28-470b-8581-875a7b474b88</ns5:outgoing> <sequenceFlow sourceRef=""modelio-0145f388-2188-49bf-9b5e-14b62648ac2e"" targetRef=""c664c1f0-2ea1-4338-903b-a3019c91472f"" name="""" id=""modelio-7baa2808-debf-49f7-b930-54c7e26dca34""/> <sequenceFlow sourceRef=""modelio-0aeaa618-26ef-4e4a-9975-b9b3c7a39a5a"" targetRef=""modelio-0145f388-2188-49bf-9b5e-14b62648ac2e"" name="""" id=""modelio-5ad2fea5-0158-4fd7-810b-14106460c968""/> <endEvent name=""Subtask end"" id=""c664c1f0-2ea1-4338-903b-a3019c91472f""> <ns5:incoming xmlns:ns5=""http://www.omg.org/spec/BPMN/20100524/MODEL"" xmlns="""">modelio-7baa2808-debf-49f7-b930-54c7e26dca34</ns5:incoming> </endEvent> <task isForCompensation=""false"" startQuantity=""1"" completionQuantity=""1"" name=""Subtask"" id=""modelio-0145f388-2188-49bf-9b5e-14b62648ac2e""> <ns5:incoming xmlns:ns5=""http://www.omg.org/spec/BPMN/20100524/MODEL"" xmlns="""">modelio-5ad2fea5-0158-4fd7-810b-14106460c968</ns5:incoming> <ns5:outgoing xmlns:ns5=""http://www.omg.org/spec/BPMN/20100524/MODEL"" xmlns="""">modelio-7baa2808-debf-49f7-b930-54c7e26dca34</ns5:outgoing> </task> <startEvent isInterrupting=""true"" parallelMultiple=""false"" name=""Subtask Start"" id=""modelio-0aeaa618-26ef-4e4a-9975-b9b3c7a39a5a""> <ns5:outgoing xmlns:ns5=""http://www.omg.org/spec/BPMN/20100524/MODEL"" xmlns="""">modelio-5ad2fea5-0158-4fd7-810b-14106460c968</ns5:outgoing> </startEvent> </subProcess> <endEvent name=""End"" id=""modelio-903c7131-8d64-4676-aa25-88780558d570""> <ns5:incoming xmlns:ns5=""http://www.omg.org/spec/BPMN/20100524/MODEL"" xmlns="""">modelio-9acfe78d-ca28-470b-8581-875a7b474b88</ns5:incoming> </endEvent> <ns5:boundaryEvent xmlns:ns5=""http://www.omg.org/spec/BPMN/20100524/MODEL"" xmlns="""" cancelActivity=""true"" attachedToRef=""modelio-57078e54-44a7-4403-891c-4fd71c8d3e85"" parallelMultiple=""false"" name=""Error"" id=""modelio-97bde2aa-d0d8-420d-89db-fa5251d75e41""> <ns5:errorEventDefinition/> </ns5:boundaryEvent> </process> <ns4:BPMNDiagram name="""" id=""modelio-22abb34f-059a-4e2d-9285-16aad425d7e4""> <ns4:BPMNPlane xmlns:ns5=""http://www.omg.org/spec/BPMN/20100524/MODEL"" xmlns="""" bpmnElement=""modelio-57078e54-44a7-4403-891c-4fd71c8d3e85""> <ns4:BPMNEdge bpmnElement=""modelio-7baa2808-debf-49f7-b930-54c7e26dca34"" id=""modelio-7baa2808-debf-49f7-b930-54c7e26dca34-gr""> <ns2:waypoint x=""10.0"" y=""21.0""/> <ns2:waypoint x=""5.0"" y=""21.0""/> </ns4:BPMNEdge> <ns4:BPMNEdge bpmnElement=""modelio-5ad2fea5-0158-4fd7-810b-14106460c968"" id=""modelio-5ad2fea5-0158-4fd7-810b-14106460c968-gr""> <ns2:waypoint x=""48.0"" y=""33.0""/> <ns2:waypoint x=""10.0"" y=""33.0""/> </ns4:BPMNEdge> <ns4:BPMNShape bpmnElement=""c664c1f0-2ea1-4338-903b-a3019c91472f"" id=""c664c1f0-2ea1-4338-903b-a3019c91472f-gr""> <ns3:Bounds x=""5.0"" y=""5.0"" width=""33.0"" height=""33.0""/> <ns4:BPMNLabel labelStyle=""9b8e5772-1232-4368-bd1b-233c2e0bf67d""> <ns3:Bounds x=""-4.0"" y=""38.0"" width=""51.0"" height=""16.0""/> </ns4:BPMNLabel> </ns4:BPMNShape> <ns4:BPMNShape bpmnElement=""modelio-0145f388-2188-49bf-9b5e-14b62648ac2e"" id=""modelio-0145f388-2188-49bf-9b5e-14b62648ac2e-gr""> <ns3:Bounds x=""10.0"" y=""10.0"" width=""90.0"" height=""46.0""/> </ns4:BPMNShape> <ns4:BPMNShape bpmnElement=""modelio-0aeaa618-26ef-4e4a-9975-b9b3c7a39a5a"" id=""modelio-0aeaa618-26ef-4e4a-9975-b9b3c7a39a5a-gr""> <ns3:Bounds x=""15.0"" y=""15.0"" width=""33.0"" height=""33.0""/> <ns4:BPMNLabel labelStyle=""9b8e5772-1232-4368-bd1b-233c2e0bf67d""> <ns3:Bounds x=""4.0"" y=""48.0"" width=""55.0"" height=""16.0""/> </ns4:BPMNLabel> </ns4:BPMNShape> </ns4:BPMNPlane> <ns4:BPMNLabelStyle id=""9b8e5772-1232-4368-bd1b-233c2e0bf67d""> <ns3:Font name=""Arial"" size=""9.0"" isBold=""false"" isItalic=""false""/> </ns4:BPMNLabelStyle> </ns4:BPMNDiagram> <ns4:BPMNDiagram name="""" id=""fee37d72-3972-42ec-b5fd-7fcbb2684e45""> <ns4:BPMNPlane xmlns:ns5=""http://www.omg.org/spec/BPMN/20100524/MODEL"" xmlns="""" bpmnElement=""modelio-041041b9-3ac4-4878-930a-e8af9cba12d1""> <ns4:BPMNEdge bpmnElement=""modelio-9acfe78d-ca28-470b-8581-875a7b474b88"" id=""modelio-9acfe78d-ca28-470b-8581-875a7b474b88-gr""> <ns2:waypoint x=""520.0"" y=""120.0""/> <ns2:waypoint x=""766.0"" y=""120.0""/> <ns2:waypoint x=""766.0"" y=""180.0""/> <ns2:waypoint x=""962.0"" y=""180.0""/> </ns4:BPMNEdge> <ns4:BPMNEdge bpmnElement=""modelio-67a6df4b-a647-4b5d-9a4b-979383bab537"" id=""modelio-67a6df4b-a647-4b5d-9a4b-979383bab537-gr""> <ns2:waypoint x=""188.0"" y=""140.0""/> <ns2:waypoint x=""329.0"" y=""140.0""/> <ns2:waypoint x=""329.0"" y=""105.0""/> <ns2:waypoint x=""420.0"" y=""105.0""/> </ns4:BPMNEdge> <ns4:BPMNShape bpmnElement=""modelio-56567f6e-d67f-4369-9754-28fb4e9dec5f"" id=""modelio-56567f6e-d67f-4369-9754-28fb4e9dec5f-gr""> <ns3:Bounds x=""152.0"" y=""122.0"" width=""36.0"" height=""36.0""/> <ns4:BPMNLabel labelStyle=""0afa366a-cd9e-4745-b47e-2c069fff9d1c""> <ns3:Bounds x=""158.0"" y=""165.0"" width=""20.0"" height=""16.0""/> </ns4:BPMNLabel> </ns4:BPMNShape> <ns4:BPMNShape isExpanded=""false"" bpmnElement=""modelio-57078e54-44a7-4403-891c-4fd71c8d3e85"" id=""modelio-57078e54-44a7-4403-891c-4fd71c8d3e85-gr""> <ns3:Bounds x=""420.0"" y=""90.0"" width=""100.0"" height=""80.0""/> </ns4:BPMNShape> <ns4:BPMNShape bpmnElement=""modelio-903c7131-8d64-4676-aa25-88780558d570"" id=""modelio-903c7131-8d64-4676-aa25-88780558d570-gr""> <ns3:Bounds x=""962.0"" y=""162.0"" width=""36.0"" height=""36.0""/> <ns4:BPMNLabel labelStyle=""0afa366a-cd9e-4745-b47e-2c069fff9d1c""> <ns3:Bounds x=""970.0"" y=""205.0"" width=""17.0"" height=""16.0""/> </ns4:BPMNLabel> </ns4:BPMNShape> <ns4:BPMNShape bpmnElement=""modelio-97bde2aa-d0d8-420d-89db-fa5251d75e41"" id=""modelio-97bde2aa-d0d8-420d-89db-fa5251d75e41-gr""> <ns3:Bounds x=""482.0"" y=""152.0"" width=""36.0"" height=""36.0""/> <ns4:BPMNLabel labelStyle=""0afa366a-cd9e-4745-b47e-2c069fff9d1c""> <ns3:Bounds x=""488.0"" y=""195.0"" width=""20.0"" height=""16.0""/> </ns4:BPMNLabel> </ns4:BPMNShape> </ns4:BPMNPlane> <ns4:BPMNLabelStyle id=""0afa366a-cd9e-4745-b47e-2c069fff9d1c""> <ns3:Font name=""Arial"" size=""9.0"" isBold=""false"" isItalic=""false""/> </ns4:BPMNLabelStyle> </ns4:BPMNDiagram> </definitions> ` </details> You will get the following error: `unsupported bpmnElement for <bpmndi:BPMNPlane"" />: <bpmn:SubProcess id=""modelio-57078e54-44a7-4403-891c-4fd71c8d3e85"" />` My guess is, this is related to this section of the bpmn-js code: https://github.com/bpmn-io/bpmn-js/blob/2dd1e1330509d3f6db7939ad8ae22b75144396bd/lib/import/BpmnTreeWalker.js#L217 Which only allows `Process` or `Collaboration` as `bpmnElement` for a BPMNPlane. __Steps to Reproduce__ 1. Save given example as `*.bpmn` or use `SubProcess-Reimport.bpmn` from [demo-files.zip] 2. Import into [demo.bpmn.io](https://demo.bpmn.io/new) Another way is to: 1. Create a new BPMN File with [demo.bpmn.io](https://demo.bpmn.io/new) including a populated subprocess 2. Export to File 3. Create a new BPMN Project with [Modelio](https://www.modelio.org/) 4. Import the File 5. Export as `*.bpmn` 6. Import into [demo.bpmn.io](https://demo.bpmn.io/new) __Expected Behavior__ Based on this quote from the spec: > A BPMNPlane can only reference a BaseElement of the types: Process, SubProcess, AdHocSubProcess, Transaction, Collaboration, Choreography or SubChoreography. -- https://www.omg.org/spec/BPMN/2.0/PDF no error should occur when importing the given example. __Environment__ - Version of [demo.bpmn.io](https://demo.bpmn.io/new) as of 2020-11-09 - [demo-files.zip] [demo-files.zip]: https://github.com/bpmn-io/bpmn-js/files/5510888/demo-files.zip "
179092,199091,https://api.github.com/repos/typegoose/typegoose/issues/522,question,2021-04-13T10:34:18Z,NONE,https://api.github.com/repos/typegoose/typegoose,"TypeScript Array SubDocument Hi, I have problems to get Array-SubDocuments working. ## What to include in your Questions My Code: ```ts import { prop, getModelForClass, Ref } from '@typegoose/typegoose' import { Base } from '@typegoose/typegoose/lib/defaultClasses' export class Pool extends Base { @prop({ required: true }) public name!: string } export class Bath extends Base { @prop({ required: true, unique: true }) public id!: string @prop({ ref: () => Pool, required: true, default: [] }) public pools!: Pool[] } ``` Problem: The type seems to be some kind of array instead of array-subdocument. I would expect functions like [mongoose.subdocumens-api](https://mongoosejs.com/docs/subdocs.html) and [mongoose-array-api](https://mongoosejs.com/docs/api/array.html) ```ts bath.pools.id('myid') // -> Error: Property 'id' does not exist on type 'Pool[]' bath.pools.set('myid', {}) // -> Error: Property 'set' does not exist on type 'Pool[]'. ``` I also tried the following, which still not allows to use the subdocuments-api. ```ts mongoose.Types.Array<Pool> ``` ## Versions ""mongoose"": ""5.10.18"" ""@typegoose/typegoose"": ""7.4.8"" "
324206,360424,https://api.github.com/repos/fossasia/open-event-frontend/issues/6865,bug,2021-03-01T16:04:17Z,MEMBER,https://api.github.com/repos/fossasia/open-event-frontend,"Virtual Event: Renaming event video room does not rename video room on sidepanel The issue is similar to https://github.com/fossasia/open-event-frontend/issues/6859. The video room seems to be created on the server with an initial name. If it is changed it does not change everywhere. Should we maybe rethink this and use a room ID in order to not confuse the video room ""microlocation"" and the server video room name? It seems like devs are confused about it. ![Screenshot from 2021-03-01 16-59-18](https://user-images.githubusercontent.com/1583873/109523859-1e881680-7ab0-11eb-81ec-d792c86ced3e.png) ![Screenshot from 2021-03-01 17-07-56](https://user-images.githubusercontent.com/1583873/109524349-b0901f00-7ab0-11eb-9982-a7289955b549.png) "
163130,181368,https://api.github.com/repos/PyCQA/pylint/issues/3275,bug,2019-11-27T13:45:13Z,NONE,https://api.github.com/repos/PyCQA/pylint,"false positive (used-before-assignment) due to assignment expression within a tuple <!-- Hi there! Thank you for discovering and submitting an issue. Before you submit this, make sure that the issue doesn't already exist or if it is not closed. Is your issue fixed on the preview release?: pip install pylint astroid --pre -U --> ### Steps to reproduce 1. Create file `examples/tuple.py` ```python values = ( a := 1, b := 2, c := a + b, ) print(values) function = lambda: ( a := 1, b := 2, c := a + b, ) print(function()) ``` 2. Run pylint ``` $ pylint examples/tuple.py ************* Module tuple examples/tuple.py:4:9: E0601: Using variable 'a' before assignment (used-before-assignment) examples/tuple.py:4:13: E0601: Using variable 'b' before assignment (used-before-assignment) examples/tuple.py:11:9: E0602: Undefined variable 'a' (undefined-variable) examples/tuple.py:11:13: E0602: Undefined variable 'b' (undefined-variable) ``` ### Current behavior Pylint returns error `E0601 (used-before-assignment)` when the left side of an assignment expression is used within the same tuple it was created in. Pylint returns error `E0602 (undefined-variable)` when the left side of an assignment expression is used within the same tuple it was created in, in a lambda. ### Expected behavior Pylint shouldn't detect `E0601` & `E0602` on these expressions because they are valid python3.8 code. ``` $ python examples/tuple.py (1, 2, 3) (1, 2, 3) ``` ### pylint --version output ``` pylint 2.4.4 astroid 2.3.3 Python 3.8.0 (default, Nov 2 2019, 00:46:27) [GCC 9.2.0] ``` "
64403,71600,https://api.github.com/repos/dlr-eoc/ukis-frontend-libraries/issues/14,enhancement,2020-06-17T12:22:59Z,MEMBER,https://api.github.com/repos/dlr-eoc/ukis-frontend-libraries,Allow Map OL Popup to pass an Angular Component ## Description Allow to pass a Angular Component in the layer popup so a user can create custom content in popups. ## Relevant Package This feature request is for [@dlr-eoc/....](https://github.com/dlr-eoc/ukis-frontend-libraries/packages) - @dlr-eoc/services-layers - @dlr-eoc/map-ol
72927,81085,https://api.github.com/repos/tobymao/18xx/issues/3573,enhancement,2021-01-28T07:13:15Z,NONE,https://api.github.com/repos/tobymao/18xx,"Planning mode **What's your idea?** - I want to plan the next few moves (or just a few companies nearly in a row). I want to disable syncing and just do the turns, then release them all at once (or at least what is currently valid). Let us know your proposed changes. This is almost like visitor mode, just let me do planning with the game tools, then I can decide what I like and commit just those bits. **Did you join the Slack?** No"
510144,566953,https://api.github.com/repos/Fyko/shopify-api-types/issues/18,enhancement,2021-02-25T06:19:57Z,OWNER,https://api.github.com/repos/Fyko/shopify-api-types,Create typings for Access Scopes resouce(s) https://shopify.dev/docs/admin-api/access-scopes
231550,257504,https://api.github.com/repos/ccxt/ccxt/issues/8509,question,2021-02-23T23:46:04Z,CONTRIBUTOR,https://api.github.com/repos/ccxt/ccxt,"OrderNotFound Error - Trying to fetch an order I'm trying to fetch an order from binance futures but I get an OrderNotFound Error. When I download the order history I see that the order is actually in there (last row). The order has been cancelled but this shouldn't be a problem right? Code: ```python import ccxt binance = getattr(ccxt, 'binance')({'apiKey': 'xxx', 'secret': 'xxx', 'enableRateLimit': True}) binance.options['defaultType'] = 'future' openOrder = binance.fetchOrder(11405693328, 'LINK/USDT') print(openOrder) ``` Error: ``` Traceback (most recent call last): File ""/home/kobej/.local/lib/python3.9/site-packages/ccxt/base/exchange.py"", line 592, in fetch response.raise_for_status() File ""/usr/lib/python3.9/site-packages/requests/models.py"", line 943, in raise_for_status raise HTTPError(http_error_msg, response=self) requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: https://fapi.binance.com/fapi/v1/order?timestamp=1614122831059&recvWindow=5000&symbol=LINKUSDT&orderId=11405693328&signature=fbcae97625e970950631ee8c217a4904fb0d407fab4e7422a531e78a73cbe88e During handling of the above exception, another exception occurred: Traceback (most recent call last): File ""/run/media/kobej/B204D33B04D300F1/Work/trabro2/test/fetchOrder.py"", line 9, in <module> openOrder = binance.fetchOrder(11405693328, 'LINK/USDT') File ""/home/kobej/.local/lib/python3.9/site-packages/ccxt/binance.py"", line 1901, in fetch_order response = getattr(self, method)(self.extend(request, query)) File ""/home/kobej/.local/lib/python3.9/site-packages/ccxt/base/exchange.py"", line 466, in inner return entry(_self, **inner_kwargs) File ""/home/kobej/.local/lib/python3.9/site-packages/ccxt/binance.py"", line 2702, in request response = self.fetch2(path, api, method, params, headers, body) File ""/home/kobej/.local/lib/python3.9/site-packages/ccxt/base/exchange.py"", line 487, in fetch2 return self.fetch(request['url'], request['method'], request['headers'], request['body']) File ""/home/kobej/.local/lib/python3.9/site-packages/ccxt/base/exchange.py"", line 608, in fetch self.handle_errors(http_status_code, http_status_text, url, method, headers, http_response, json_response, request_headers, request_body) File ""/home/kobej/.local/lib/python3.9/site-packages/ccxt/binance.py"", line 2696, in handle_errors self.throw_exactly_matched_exception(self.exceptions, error, feedback) File ""/home/kobej/.local/lib/python3.9/site-packages/ccxt/base/exchange.py"", line 505, in throw_exactly_matched_exception raise exact[string](message) ccxt.base.errors.OrderNotFound: binance {""code"":-2013,""msg"":""Order does not exist.""} ``` Order History: ![image](https://user-images.githubusercontent.com/42657049/108923606-6b479980-7639-11eb-9940-1ee4cca412d1.png) "
601814,668815,https://api.github.com/repos/kompics/kompicsbenches/issues/21,enhancement,2021-02-20T12:16:46Z,COLLABORATOR,https://api.github.com/repos/kompics/kompicsbenches,"Include length of sfx in Prepare msg of Paxos Small enhancement for the prepare phase of Paxos. By including the length of the Leader's suffix, `sfx_len`, in the Prepare message, we can further avoid followers to send redundant suffices. If a follower is in the same round but has a suffix of same length or less, it has a less or equally updated sequence as the leader and can therefore send an empty `sfx` in the Promise message as well. "
320966,356815,https://api.github.com/repos/ivanvinski/colorinho/issues/78,enhancement,2021-01-14T01:49:00Z,OWNER,https://api.github.com/repos/ivanvinski/colorinho,"Clean up and refactor architecture ## Summary Following the first iteration of clean up, I've gotten a better overview of the architecture. More specifically, I've gotten a better overview of how to implement game module to not only improve code quality, but also unit testability. I created UML diagram to think through the architecture of my last iteration of clean up. While I should follow the UML diagram as closely as possible for the game module implementation, the wiring of the module to Vue.js and Vuex should be done based on what I consider the best approach to be once the new game module is implemented. The entire codebase should be easily unit tested. ## Tasks * [x] Implement the level module * [x] Implement the tally module * [x] Implement the storage module * [x] Implement the utils module * [x] Implement the game module * [x] Clean up code and improve tests ## Diagram ![colorinho-diagram](https://user-images.githubusercontent.com/14854181/104533017-d3a26480-5611-11eb-8cd6-b0eba21c40cb.png) "
499195,554840,https://api.github.com/repos/f4exb/sdrangel/issues/865,enhancement,2021-04-22T20:06:58Z,OWNER,https://api.github.com/repos/f4exb/sdrangel,APT demod: processPixels takes too much time on the main thread The call to method `processPixels` [here](https://github.com/f4exb/sdrangel/blob/master/plugins/channelrx/demodapt/aptdemod.cpp#L174) (mostly what's behind) takes too much time and blocks the main thread for too long. This has quite undesirable side effects. The most visible is that the main spectrum is not moving smoothly anymore. Things gets worse as the image grows because the full image is processed at each new line so you have to wait a little bit to see the effect. More annoyingly if another plugin is present then its flow is disrupted which results for example in breaks in audio (for a plugin with audio) with messages showing that the sample FIFO is not processed fast enough. The simplest fix is to move this process to a separate thread as I am not sure the process itself can be optimized by processing only the current line. There must be a good reason to reprocess the full image as I have noticed that it improves over time. A fix is going to be posted to`master` shortly.
52508,58408,https://api.github.com/repos/citusdata/citus/issues/4589,bug,2021-01-27T11:22:07Z,MEMBER,https://api.github.com/repos/citusdata/citus,"Columnar gives NaN costs for empty tables in explain output When a table is empty, columnar gives NaN cost estimates, which can also throw off other estimates (e.g. join cost estimates also become NaN). ```sql postgres=# create table empty (x int, y int) using columnar; CREATE TABLE postgres=# explain select count(*) from empty ; ┌────────────────────────────────────────────────────────────────────────────┐ │ QUERY PLAN │ ├────────────────────────────────────────────────────────────────────────────┤ │ Aggregate (cost=NaN..NaN rows=1 width=8) │ │ -> Custom Scan (ColumnarScan) on empty (cost=0.00..NaN rows=1 width=0) │ └────────────────────────────────────────────────────────────────────────────┘ (2 rows) ```"
560573,622988,https://api.github.com/repos/YTVanced/Vanced/issues/607,enhancement,2021-03-31T18:57:12Z,NONE,https://api.github.com/repos/YTVanced/Vanced,"[Idea] Stop Timer for yt/music vanced **Description** There will be a button or somewhere where we can set a timer then, when that timer runs out it automatically kills/pause/stop the video/song/app You can set the timer to any time you want, hour/minutes this is useful for listening to music until you sleep so that you don't have to worry about the yt keep playing while you are sleeping "
120897,134338,https://api.github.com/repos/zwave-js/zwave-js-server/issues/75,enhancement,2021-01-31T16:45:34Z,COLLABORATOR,https://api.github.com/repos/zwave-js/zwave-js-server,Add supported CommandClasses to dumpNode It would be nice to also list the supported commandclasses of a node in the dump function. Usecase for this is to know upfront if a device supports e.g. Central Scene CC to create device triggers in the HA integration.
636603,707523,https://api.github.com/repos/thelindat/linden_inventory/issues/20,bug,2021-04-19T05:49:56Z,CONTRIBUTOR,https://api.github.com/repos/thelindat/linden_inventory,Inventory gets wiped **Describe the bug** If a player gets disconnected while they are in their inventory it gets wiped. This only appears to happen with player inventories not vehicle inventories. **To Reproduce** Steps to reproduce the behavior: 1. Open your inventory 2. press F8 and quit 3. Reconnect and your inventory is gone 
617931,686703,https://api.github.com/repos/wilhelmer/mkdocs-localsearch/issues/12,bug,2021-02-25T12:45:20Z,NONE,https://api.github.com/repos/wilhelmer/mkdocs-localsearch,"localsearch seems broken with mkdocs-material 7.0.0 update Hi @wilhelmer, Thanks for your continued support on the plugin! I´ve updated to localsearch 0.8.0 and followed your guidance (added {{ super() }} in the custom main.html). Since I´ve updated to material 7.0.0 (and 7.0.1) the localsearch is not working for me anymore. The search-index is created but the search box doesn´t open when active: ![image](https://user-images.githubusercontent.com/62448529/109155188-92a08280-776f-11eb-8193-fe4abbc49b9f.png) It works fine with material 6.2.8 and the identical configuration though: ![image](https://user-images.githubusercontent.com/62448529/109154811-1b6aee80-776f-11eb-9033-ec9e9d53fa47.png) I wonder if it breaks due to the changes in base.html or general architectural oberhaul of material v7. Any idea what I´m missing or how I can debug? Thanks René"
22505,25050,https://api.github.com/repos/weather-gov/api/issues/105,question,2020-08-28T20:36:44Z,NONE,https://api.github.com/repos/weather-gov/api,"Correct format for start and end query parameters filtering Regarding to [this documentation](https://api.weather.gov/openapi.json) there is a way to filter alerts between dates using the `start` and `end` query parameters. I tried many formats including the same format that the api uses to return dates and always got a BadRequest with this message `Parameter \""start\"" is invalid: This value is not a valid datetime`. Could you please provide the correct format to use to filter by date? Thanks"
467612,519702,https://api.github.com/repos/fj317/PumpBot/issues/77,bug,2021-03-21T14:00:26Z,NONE,https://api.github.com/repos/fj317/PumpBot,"Error code -2010 Hey mate, refering to the same issue of #73, I'm getting the same error now... Tried with my old version 1.4, as well as with 1.6, ending up with error code -2010 (from binance), saying ""Account has insufficient balance for requested action"". What's interesting is that this doesn't always happen.. Sometimes its working, sometimes it's not.. For me, it feels like the bot tries to place the sell order, before the buy order got executed, so it has insufficient balance to create the sell order.. Really weird somehow... You have any idea or are familiar with this issue? Trying to fix as well... What's weird is that code didn't change on my side since the last pump i participated and there, everything worked like a charm.... Maybe a problem with the Binance API?"
673495,748519,https://api.github.com/repos/darshan-hpc/darshan/issues/186,enhancement,2021-05-13T00:25:54Z,CONTRIBUTOR,https://api.github.com/repos/darshan-hpc/darshan,"add last_open and first_close counters In GitLab by @shanedsnyder on Apr 27, 2016, 09:25 We already have counters for first_open and last_close, but these additional counters will allow us to have a better understanding of how long the first open and last close operations really take. This enhancement would also allow us to better reason about cases where some processes are still writing a shared file while others are starting to close it: without knowing when the first close operation started, we can't easily tell at which points in the application processes began to move between I/O phases."
642794,714437,https://api.github.com/repos/Kruithne/wow.export/issues/186,enhancement,2021-04-21T21:12:36Z,OWNER,https://api.github.com/repos/Kruithne/wow.export,Use doodad sets from mwds for WMOs 0x80 on MODFFlags
404863,449995,https://api.github.com/repos/libsdl-org/SDL/issues/1794,bug,2021-02-10T23:56:55Z,COLLABORATOR,https://api.github.com/repos/libsdl-org/SDL,"Update copyright for 2015. # This bug report was migrated from our old Bugzilla tracker. **Reported in version:** HG 2.0 **Reported for operating system, platform:** Other, x86 # Comments on the original bug report: On 2015-03-16 01:42:59 +0000, Ryan C. Gordon wrote: > It's that's time again, just like in Bug # 2374. > > Can we check in a script that does this once a year? :) > > --ryan. On 2015-03-17 20:03:39 +0000, Sylvain wrote: > That should do the trick! > > > find . -type f -exec grep -Il """" {} \; \ > | grep -v \.hg \ > | while read i; \ > do \ > sed -ie ""s/\(.*Copyright.*\)[0-9]\{4\}\( *Sam Lantinga\)/\1`date +%Y`\2/"" ""$i""; \ > rm ""${i}e""; \ > done On 2015-04-07 04:57:59 +0000, Ryan C. Gordon wrote: > > (sorry if you get a lot of copies of this email, I'm marking several bugs at once) > > Marking bugs for the (mostly) final 2.0.4 TODO list. This means we're hoping to resolve this bug before 2.0.4 ships if possible. In a perfect world, the open bug count with the target-2.0.4 keyword is zero when we ship. > > (Note that closing a bug report as WONTFIX, INVALID or WORKSFORME might still happen.) > > --ryan. On 2015-05-26 13:28:29 +0000, Sam Lantinga wrote: > Done, thanks Sylvain! > https://hg.libsdl.org/SDL/rev/b94b6d0bff0f "
23559,26238,https://api.github.com/repos/learningequality/studio/issues/2960,bug,2021-02-17T13:18:03Z,CONTRIBUTOR,https://api.github.com/repos/learningequality/studio,"Channel Details > ""Contains content from"" section - links in the section lead to Not Found page ## Summary On the Channel Details page, the ""Contains content from"" section - all links in the section lead to Not Found page. ## Category BUG ## Usage Details Tested at: https://hotfixes.studio.learningequality.org/ Also experienced at the master branch. - Browser: Chrome, FF, Edge - Channel: lunab-pivib ## How to reproduce Preconditions: Channels created, content imported 1. Login to Studio 2. Click the ""i"" button of a channel 3. Scroll down to the ""Contains content from"" section 4. Click any of the links ## Screenshots ![Video-2021-02-17-150700](https://user-images.githubusercontent.com/72492554/108209626-31efc500-7133-11eb-85d1-2ce65c03cfff.gif) "
511514,568478,https://api.github.com/repos/opensourcepos/opensourcepos/issues/2958,enhancement,2020-10-03T08:26:49Z,NONE,https://api.github.com/repos/opensourcepos/opensourcepos,"Barcode In ITEM KIT ### Background information __IMPORTANT: If you choose to ignore this issue report template, your issue will be closed as we cannot help without the requested information.__ Please make sure you tick (add an x between the square brackets with no spaces) the following check boxes: - [] Reporting an issue of an unmodified OSPOS installation - [] Checked [open and closed issues](https://github.com/opensourcepos/opensourcepos/issues?utf8=%E2%9C%93&q=is%3Aissue) and no similar issue was already reported (please make sure you searched!) - [] Read [README](https://github.com/opensourcepos/opensourcepos/blob/master/README.md), [WHATS_NEW](https://github.com/opensourcepos/opensourcepos/blob/master/WHATS_NEW.txt), [INSTALL.md](https://github.com/opensourcepos/opensourcepos/blob/master/INSTALL.md) and [UPGRADE](https://github.com/opensourcepos/opensourcepos/blob/master/UPGRADE.txt) - [] Read the [FAQ](https://github.com/opensourcepos/opensourcepos#faq) for any known install and/or upgrade gotchas (in specific PHP extensions installed) - [] Read the [wiki](https://github.com/opensourcepos/opensourcepos/wiki) - [] Executed any database upgrade scripts if an upgrade pre 3.0.0 (e.g. database/2.4_to_3.0.sql) - [] Aware the installation code is in [bintray](https://bintray.com/jekkos/opensourcepos/opensourcepos/view/files?sort=updated&order=asc#files) (see README), and [GitHub master](https://github.com/opensourcepos/opensourcepos/tree/master) is for [developers only](https://github.com/opensourcepos/opensourcepos/wiki/Development-setup) and therefore not complete nor stable ### Installation information - OSPOS version is: 3.3.2 - OSPOS git commit hash is: - PHP version is: 7.4 - MySQL or MariaDB version is: - OS and version is: windows 10 - WebServer is: xampp - Selected language is: English - (If applicable) Docker installation: - (If applicable) Installation package for the LAMP/LEMP stack is: ### Issue / Bug / Question / New Feature Hi ! i have a small problem in item kit ! As if now we can add the barcode in item module and generate the barcode from item module But in Item Kit we cannot add the barcode , instead Auto incremented Kit Id is taken as barcode !. But i need a field to add a barcode in itemkit and that barcode should scanned in sale and receivings! Do any one can fix this issue ! Thanks in Advance "
230299,256108,https://api.github.com/repos/mozilla/bugbug/issues/2189,bug,2021-02-24T14:11:27Z,COLLABORATOR,https://api.github.com/repos/mozilla/bugbug,"Some bugs are duplicated in the changes artifact This is a regression, not sure when it was introduced."
491224,545954,https://api.github.com/repos/hl2guide/Filterlist-for-AdGuard/issues/59,bug,2021-04-01T10:43:43Z,NONE,https://api.github.com/repos/hl2guide/Filterlist-for-AdGuard,"new addition for filtersToIgnore: aom **Describe the bug** Filterlist 1, at line 1326127, has a rule which is simply: `aom` This blocks any response which contains the letters aom. An example of a site this rule breaks is `apsjobs.gov.au`, which returns a result: `CNAME www.apsjob.gov.au.00d5m0000008aomeay.live.siteforce.com` **Possible solution** This rule should be excluded with an update to your filtersToIgnore list with the rule: `filtersToIgnore.append('aom')` Also wish I could figure out where you store the filtersToIgnore in your Github code, so I could just make a change for you in a fork and submit a pull request."
717169,797068,https://api.github.com/repos/nrc-cnrc/EGSnrc/issues/300,bug,2017-06-05T14:38:11Z,MEMBER,https://api.github.com/repos/nrc-cnrc/EGSnrc,"Composite geometry cannot refer to objects defined in include file Input files in egs++ can contain the key-value pair `includefile = filename`, which inserts the content of file `filename`, as if the content of the file had been written in the input file. However, composite geometries cannot find geometries defined in the include file. At least the envelope geometry suffers this problem. For example: **box2.egsinp** ```ruby ### box 2 :start geometry: name = box2 library = egs_box box size = 1 1 1 :start media input: media = medium2 :stop media input: :stop geometry: ``` **include.egsinp** ```ruby :start geometry definition: ### box 1 :start geometry: name = box1 library = egs_box box size = 2 2 2 :start media input: media = medium1 :stop media input: :stop geometry: includefile = box2.egsinp ### insert box2 in box1 :start geometry: name = box2_in_box1 library = egs_genvelope base geometry = box1 inscribed geometries = box2 :stop geometry: simulation geometry = box2_in_box1 # error: no geometry with name box2 defined :stop geometry definition: ``` Trying to view the geometry **include.egsinp** yields a geometry not found error: ```bash $ egs_view include.egsinp createGeometry(envelope geometry): no geometry with name box2 defined ``` (Reported by Patrick Saull.)"
268121,298180,https://api.github.com/repos/meodai/raumgleiter/issues/135,enhancement,2020-10-30T16:45:12Z,NONE,https://api.github.com/repos/meodai/raumgleiter,"[New Feature]: Sound bei Projektvideos ## Issue **Describe the bug** Bei den Projekten sollte es möglich sein, Sound einzuschalten, z.B. https://raumgleiter.netlify.app/projekte/shoppi-tivoli-spreitenbach Kann durch Userinteraction geschehen, da automatischer Sound ja nicht möglich ist. Eigentlich wärs fast am Besten, wenn man bei einer solchen Animation zuerst bewusst den Playbutton drücken müsste, dann startet es gleich mit Sound "
501365,557262,https://api.github.com/repos/microsoft/botbuilder-js/issues/3236,bug,2021-01-28T11:24:32Z,NONE,https://api.github.com/repos/microsoft/botbuilder-js,"DC.cancelAllDialogs(true) is not cancelling the skill level dialog stack ## Versions ""botbuilder"": ""^4.11.0"", ""botbuilder-ai"": ""^4.11.0"", Typescript Node Js: v11.6.0 Windows 10 ## Describe the bug We have VA and Skill. When the user wants to cancel the dialog in the middle of the conversation, we are calling cancelAllDialogs(true) to cancel all the dialogs. But it's not canceling all the dialogs. Eg: **VA**: Click from below Department // here Department is the skill. **User**: Create an order - This utterance would connect to skill. **VA**: What do you want? -> [Served from Skill] **User**: Cancel // this utterance begins the CancelDialog **VA**: Are you sure you want to cancel the order? -> [Served from VA] // first step in CancelDialog waterfall to get the confirmation. **User**: Yes // **we are trying to cancel the dialogs** **VA**: Ok, Let's start over. // here all dialogs supposed to be closed. [Served from VA] // Closing the all dialogs in CancelDialog by using cancelAllDialogs(true). User: Show my previous order **VA**: Sorry, we are not supporting this. Please try again // **This is actually the next step of What do you want?. Since the dialog is not canceled this is continuing.** [Served from Skill] ## Expected behavior All dialogs should be canceled. But, when the dialog been served from VA and try to cancel by this method, then the dialogs are been canceled. This issue is only when we have connected to skill. Thanks, Sreekanth from Ecolab"
215686,239836,https://api.github.com/repos/airyhq/airy/issues/1638,bug,2021-04-26T10:28:11Z,CONTRIBUTOR,https://api.github.com/repos/airyhq/airy,"airy create doesn't use passed config dir Current airy cli version 0.18.0 <img width=""712"" alt=""Screenshot 2021-04-26 at 11 48 39"" src=""https://user-images.githubusercontent.com/54705263/116068160-3633e380-a68a-11eb-8852-9ec4114803a7.png""> Desired `airy create` should abide to passed `--config-dir` "
162893,181108,https://api.github.com/repos/dotnet/xharness/issues/397,enhancement,2020-12-10T17:05:05Z,NONE,https://api.github.com/repos/dotnet/xharness,"Introduce install, run-test, uninstall args for Android testing command I was working on enabling runtime test to run on Android devices. And the current runtime test infrastructure calls the xharness Android testing command once per Fact. That means the same Android app got installed and uninstalled multiple times per Xunit test file, which slows down the test dramatically. It would be nice to add an arg to tell the Android testing command to only install, uninstall or run-test. That way, the Android app only needs to install/uninstall once per test file in the initialize/cleanup methods. cc: @akoeplinger @MattGal "
196081,218020,https://api.github.com/repos/akkadotnet/akka.net/issues/4907,enhancement,2021-04-06T15:33:05Z,MEMBER,https://api.github.com/repos/akkadotnet/akka.net,"MNTR: make spec filtering more flexible Version: 1.4.18 The spec filtering we have for the MNTR today is not very well documented and is extremely brittle - i.e. I have to get the FQN of the method marked with `MultiNodeFact` spelled exactly right on the CLI. https://getakka.net/articles/testing/multi-node-testing.html#running-multi-node-tests I would strongly prefer it if the spec argument scheme followed what NBench does, which allows wildcard include / exclude filtering rules for this purpose: https://nbench.io/articles/running.html#commandline-arguments "
244742,272206,https://api.github.com/repos/eclipse/kitalpha/issues/525,enhancement,2021-01-08T15:29:25Z,NONE,https://api.github.com/repos/eclipse/kitalpha,"Lost editing description in properties view while changing the selection element The scenario: - Use capella and import or create a capella project - Open the aird file - From the Capella Project Explorer, select the package ""Operational Analysis"" - In the tab ""Description"" of the ""Properties"" view, we'll have a rich text - Try to edit the description with any text - From the Capella Project Explorer, change the selection to the package ""System Analysis"", edit the description with any text - Change the selection back to the package ""Operational Analysis"", the edited text a moment ago has been lost. The solution: - Save the editing description to the value of the element's feature whenever it is modified. `🆔 ECLIPSE-556149 / POLARSYS-1952` `👷 cong.bang.do` `📅 2018-02-07` `🔎 1.2.0`"
702449,780704,https://api.github.com/repos/tabler/tabler/issues/767,bug,2021-01-05T09:47:58Z,NONE,https://api.github.com/repos/tabler/tabler,"[BUG] Problem with masonry cards Hello. i have a problem with masonry cards. As in my example picture, very often the cards overlap like this. Here is the code I use, as in the Tabler documentation. ``` <div class=""row row-cards"" data-masonry='{ ""percentPosition"": true }'> <div class=""col-sm-4 col-md-4 col-lg-3 d-block h-auto""> <div class=""card card-sm""> .......... ``` https://ibb.co/P9mhyr8"
470309,522706,https://api.github.com/repos/SlimeKnights/TinkersConstruct/issues/4293,bug,2021-04-03T19:04:59Z,NONE,https://api.github.com/repos/SlimeKnights/TinkersConstruct,"[1.16] Smeltry alloys casting. **Issue description:** It alloys but when i pour into cast or basin it gives me another material. It just with ingot cast. I can cast sword, pickaxe head without any problem. **If crashed, link to crash report (use a site such as pastebin):** No crash. **Versions:** * Minecraft: 1.16.5 * Forge: 16.1.2 * Mantle: 1.6.79 * Tinkers Construct: 3.0.2.73 **Confirm below that this issue is not covered on the roadmap or ""Whats New?""** I don't think it is :D **Can it be reproduced with *just* Tinkers Construct? If not, list the other mods *required* to reproduce the issue.** Thermal Series. https://user-images.githubusercontent.com/45048634/113488523-6642f900-94c7-11eb-9133-8803c64fba7f.mp4 https://user-images.githubusercontent.com/45048634/113488530-6fcc6100-94c7-11eb-9ae4-56147fc12b84.mp4 "
88038,97855,https://api.github.com/repos/EduardoMay/iv-notas-app/issues/4,enhancement,2021-04-08T03:12:18Z,OWNER,https://api.github.com/repos/EduardoMay/iv-notas-app,Cambiar metodo de eliminar favoritos Usar la api para poder eliminar favorito
657704,731066,https://api.github.com/repos/hdavid16/DisjunctiveProgramming.jl/issues/6,bug,2021-05-13T22:17:49Z,OWNER,https://api.github.com/repos/hdavid16/DisjunctiveProgramming.jl,Perspective function Epsilon should not be a JuMP variable. Make it a scalar and a keyword argument.
358311,398341,https://api.github.com/repos/nextcloud/server/issues/22850,bug,2020-09-14T17:06:49Z,NONE,https://api.github.com/repos/nextcloud/server,"Bruteforce IP Whitelist doesn't work Still shows IP of that network thats been whitelisted in the select * from oc_bruteforce_attempts;"" ![image](https://user-images.githubusercontent.com/59488153/93116155-82459100-f682-11ea-81d2-13e171a7bee9.png) ![image](https://user-images.githubusercontent.com/59488153/93116083-6b06a380-f682-11ea-8303-100945646881.png) ![image](https://user-images.githubusercontent.com/59488153/93116179-8d002600-f682-11ea-9319-9a5e2091827f.png) ![image](https://user-images.githubusercontent.com/59488153/93116612-1a437a80-f683-11ea-8cad-63b5b297f627.png) ![image](https://user-images.githubusercontent.com/59488153/93116535-00a23300-f683-11ea-876e-31ba70fc1967.png) "
570596,634087,https://api.github.com/repos/TheDoctor0/openvas-docker-lite/issues/9,bug,2021-01-15T17:37:23Z,NONE,https://api.github.com/repos/TheDoctor0/openvas-docker-lite,"Profiles don't work Hi, When I try to run a scan with any profile other than the default profile, I get an error. Here is the command I run `python3 -u scan.py [IP] -f PDF -o scan.pdf -p ""Full and very deep""` and the result I got was this ``` Starting OpenVAS... Starting scan with settings: * Target: [IP] * Excluded hosts: * Scan profile: Full and very deep * Scan ports: All TCP and Nmap top 100 UDP * Alive tests: ICMP, TCP-ACK Service & ARP Ping * Max hosts: 10 * Max checks: 3 * Report format: PDF * Output file: scan.pdf Performed initial cleanup. Created target with id: 906b66b7-4970-449a-9f07-7f455f1478ee. [ERROR] Response: Response Error 404. Failed to find config '708f25c4-7489-11df-8094-002264764cea' ``` Any ideas what the reason and solution might be? Thanks in advance!"
214568,238608,https://api.github.com/repos/zero-to-mastery/breads-server/issues/4,enhancement,2020-04-22T04:31:39Z,COLLABORATOR,https://api.github.com/repos/zero-to-mastery/breads-server,"Users can see specifics of backend errors Users should only be able to see simple error messages ""Unauthorized"", ""Email needed"", etc."
232645,258719,https://api.github.com/repos/FHIR/GoFSH/issues/98,bug,2021-02-18T21:02:18Z,COLLABORATOR,https://api.github.com/repos/FHIR/GoFSH,GoFSH does not properly handle codes with spaces in the CodeSystem Reported on zulip: https://chat.fhir.org/#narrow/stream/215610-shorthand/topic/Codes.20with.20spaces
206415,229518,https://api.github.com/repos/redisson/redisson/issues/3473,bug,2021-03-12T15:10:00Z,NONE,https://api.github.com/repos/redisson/redisson,"redis stream 消费自动ack问题 redisson-spring-boot-starter 3.15.1 查看源码，在 RedissonStreamCommands.xReadGroup 中，没有处理readOptions的noack参数 <!-- Сonsider Redisson PRO https://redisson.pro version for advanced features and support by SLA. --> **Expected behavior** redis stream 手动 ack **Actual behavior** 无论设置成手动还是自动，均自动ack **Steps to reproduce or test case** ``` @Component public class StreamConsumerRunner implements ApplicationRunner, ApplicationListener<ContextClosedEvent> { static final Logger LOGGER = LoggerFactory.getLogger(StreamConsumerRunner.class); @Autowired RedisConnectionFactory redisConnectionFactory; @Autowired ThreadPoolTaskScheduler taskScheduler; @Autowired StringRedisTemplate stringRedisTemplate; private StreamMessageListenerContainer<String, MapRecord<String, String, String>> streamMessageListenerContainer; @Override public void run(ApplicationArguments args) throws Exception { // 创建配置对象 StreamMessageListenerContainerOptions<String, MapRecord<String, String, String>> streamMessageListenerContainerOptions = StreamMessageListenerContainerOptions .builder() // 一次性最多拉取多少条消息 .batchSize(10) // 执行消息轮询的执行器 .executor(this.taskScheduler) // 消息消费异常的handler .errorHandler(new ErrorHandler() { @Override public void handleError(Throwable t) { // throw new RuntimeException(t); t.printStackTrace(); } }) // 超时时间，设置为0，表示不超时（超时后会抛出异常） .pollTimeout(Duration.ZERO) // 序列化器 .serializer(new StringRedisSerializer()) .build(); // 根据配置对象创建监听容器对象 StreamMessageListenerContainer<String, MapRecord<String, String, String>> streamMessageListenerContainer = StreamMessageListenerContainer .create(this.redisConnectionFactory, streamMessageListenerContainerOptions); // 使用监听容器对象开始监听消费（使用的是手动确认方式） streamMessageListenerContainer.receive(Consumer.from(""group-1"", ""consumer-1-1""), StreamOffset.create(""mystream"", ReadOffset.lastConsumed()), message -> { LOGGER.info(""group-1, {}"", message); stringRedisTemplate.opsForStream().acknowledge(""group-1"", message); }); this.streamMessageListenerContainer = streamMessageListenerContainer; // 启动监听 this.streamMessageListenerContainer.start(); } @Override public void onApplicationEvent(ContextClosedEvent event) { LOGGER.info(""close""); this.streamMessageListenerContainer.stop(); } } ``` **Redis version** 5.0.10 **Redisson version** redisson-spring-boot-starter 3.15.1 **Redisson configuration** "
684976,761281,https://api.github.com/repos/hankcs/HanLP/issues/1634,bug,2021-03-19T07:10:29Z,NONE,https://api.github.com/repos/hankcs/HanLP,"convertToPinyinList方法，返回了所有同音字的拼音。 <!-- 提问请上论坛，不要发这里！ 提问请上论坛，不要发这里！ 提问请上论坛，不要发这里！ 以下必填，否则恕不受理。 --> **Describe the bug** convertToPinyinList方法，返回了所有同音字的拼音。 **Code to reproduce the issue** Provide a reproducible test case that is the bare minimum necessary to generate the problem. ```Java System.out.println(HanLP.convertToPinyinString(""你好"", "" "", false)); // ni hao hao ``` **Describe the current behavior** convertToPinyinList方法返回了多音字所有的拼音，导致返回的拼音字符串有多余的多音字，同时当需要转拼音字符串有中英混杂时，会出现报错IndexOutOfBoundaryException。1.7.8无此问题。 **Expected behavior** “你好”返回“ni hao”而不是“ni hao hao”。 **System information** - Linux、Windows - Python version: - HanLP version:1.8.0 **Other info / logs** Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. * [x] I've completed this form and searched the web for solutions. <!-- 发表前先搜索，此处一定要勾选！ --> <!-- 发表前先搜索，此处一定要勾选！ --> <!-- 发表前先搜索，此处一定要勾选！ -->"
570971,634514,https://api.github.com/repos/cortex-command-community/Cortex-Command-Community-Project-Data/issues/82,bug,2020-12-31T21:30:43Z,NONE,https://api.github.com/repos/cortex-command-community/Cortex-Command-Community-Project-Data,"Global Script ""Constant Gold Income"" keeps giving gold in the Editor Mode in the Metagame & Wave Defense **Describe the bug** The `Base.rte/Constant Gold Income` Global Script that's in CCCP keeps giving gold even while in the editor mode, and the editor mode stays open for as long as you wish in both the Metagame when you attack a site and when a round is over in Wave Defense. This means that when you stay in the editor mode for too long the scenario becomes way too easy and ruins the immersion."
401128,445853,https://api.github.com/repos/marceloglacial/2021-leal-e-clementino/issues/13,enhancement,2021-03-02T02:08:18Z,OWNER,https://api.github.com/repos/marceloglacial/2021-leal-e-clementino,Change Nav Links Behaviour Remove the coloured background on hover and add a simple underline on the links
174114,193606,https://api.github.com/repos/chartjs/chartjs-plugin-zoom/issues/82,enhancement,2017-06-02T20:01:39Z,NONE,https://api.github.com/repos/chartjs/chartjs-plugin-zoom,"Expose programmatic zoom and pan APIs resetZoom is the only exposed method, but we NEED a complete API, including such things as: wheel ""click"" zoom increment (for large datasets) and zoomIn zoomOut, so that we can in code set up our own buttons to control zooming based upon our recognition of dataset size. The reset method is on the right track but is woefully inadequate by itself! We also need properties! This plugin is seriously almost useless because of how ""closed"" it is. For example, we have no way to display to a user what the zoom amount IS. We should be able to populate, for example, a label to show ""200%,"" ""322%,"" ""685%,"" and so on, with a click on a ""Reset"" button restoring the ""100%"" zoom and displaying that fact to the user. In short, the plugin has promise, but at present it's far, far too limited and limiting to be practically useful in any production app. API DOCUMENTATION!"
219538,244121,https://api.github.com/repos/rethinkdb/rethinkdb-ts/issues/86,bug,2021-05-26T15:38:40Z,NONE,https://api.github.com/repos/rethinkdb/rethinkdb-ts,"Using cursor as an async iterator throws when it reaches the end According to the readme: > A cursor is already a readable stream, no need for toStream() > A readable stream is already an async iterator in node 10 no need for .asyncIterator() So according to my limited understanding of async iterators this should work: ```javascript const connection = await R.connect(options); const query = R.db(dbName).table(tableName); const cursor = await query.getCursor(connection); for await (const row of cursor) { console.log(JSON.stringify(row)); } ``` But this prints every row and then throws `RethinkDBError [ReqlDriverError]: No more rows in the cursor.` Shouldn't it just exit the loop when it reaches the end? I'm using node 14."
377402,419540,https://api.github.com/repos/fyne-io/fyne/issues/1604,bug,2020-11-25T09:59:43Z,NONE,https://api.github.com/repos/fyne-io/fyne,"SIGSEGV Sometimes When Closing a Program by Clicking a Button ### Describe the bug: I've noticed that sometimes my program faults with ""[signal SIGSEGV: segmentation violation code=0x1 addr=0xf8 pc=0x7fdae2aa6fc4]"". It doesn't happen every time, though, so I'm not sure exactly where it is going wrong, full error is here: https://hastebin.com/efiyuxofag.go ### To Reproduce: Steps to reproduce the behaviour: * Run any Fyne program on my system which closes the window by clicking a button widget, it will sometimes need to be ran lots of times until I can reproduce the exact error message. ### Example Code ``` package main import ( ""fyne.io/fyne/app"" ""fyne.io/fyne/container"" ""fyne.io/fyne/layout"" ""fyne.io/fyne/widget"" ""fmt"" ) func showConfirm(title, question string, callback func(bool)) { a := app.New() w := a.NewWindow(title) yes := widget.NewButton(""Yes"", func() { callback(true) w.Close() }) yes.Importance = widget.HighImportance w.SetContent(container.NewVBox( widget.NewLabel(question), container.NewHBox(layout.NewSpacer(), widget.NewButton(""No"", func() { callback(false) w.Close() }), yes, layout.NewSpacer()))) w.ShowAndRun() } func main() { showConfirm(""MyTitle"", ""Are you sure?"", func(b bool) { if b { fmt.Println(""Confirmed"") } }) } ``` ### Device (please complete the following information): - OS: Ubuntu Linux - Version: 20.04 - Go version: 1.12.1 - Fyne version: 0ca05dc12c03b8873d2f22caa6ce4c28988b3886 "
222147,247033,https://api.github.com/repos/OSGeo/grass/issues/1068,enhancement,2020-11-05T09:24:54Z,CONTRIBUTOR,https://api.github.com/repos/OSGeo/grass,"[Feat] wxGUI: Show the world map in Demolocation immediately after startup **Is your feature request related to a problem? Please describe.** Now, the world map is not shown immediately after startup. **Describe the solution you'd like** The first-time user will see the world map automatically after startup. "
652733,725583,https://api.github.com/repos/ros-planning/moveit2/issues/184,bug,2020-04-29T20:11:39Z,CONTRIBUTOR,https://api.github.com/repos/ros-planning/moveit2,"Throws wrong type error while parsing ompl_planning.yaml ### Description In loading the config yaml files for MoveItCPP in my [application](https://github.com/swri-robotics/collaborative-robotic-sanding/blob/moveit2-integration-test/crs_application/launch/main.launch.py), an incorrect yaml type error is thrown when parsing the ompl_planning.yaml file Overview of your issue here. I don't have a screen capture of the actual error message but it seemed to suggest that it expected a string but got a double instead. I was able to get it to accept the yaml file by placing quotes around the value assigned to `longest_valid_segment_fraction ` field in order to make it a string, [see here ](https://github.com/swri-robotics/collaborative-robotic-sanding/blob/adc30bdfcbf48c0981dc56bfe3998baf6c9ee136/crs_moveit2_config/config/ompl_planning.yaml#L183) ### Your environment * ROS Distro: [Eloquent] * OS Version: e.g. Ubuntu 18.04 * Source * master branch ### Steps to reproduce Load ompl_planning.yaml file which includes the `longest_valid_segment_fraction ` set to a double ### Expected behaviour MoveItCPP should load the yaml file and configure itself from it ### Actual behaviour Throws exception saying that it expected a string but got a double instead ### Backtrace or Console output Did't capture :( "
569888,633310,https://api.github.com/repos/rstudio/rstudio/issues/4655,bug,2019-04-17T05:37:43Z,NONE,https://api.github.com/repos/rstudio/rstudio,"Sending many lines to terminal fails on Ubuntu ### System details RStudio Edition : Desktop RStudio Version : 1.2.1502 OS Version : Ubuntu 18.04 R Version : 3.5.3 ### Steps to reproduce the problem - Start a terminal inside RStudio. - Start R inside the terminal. - Send a 500 lines of code using Ctrl-C / Shift-Insert or Ctrl-Alt-Enter - For me, it tries to send them really fast but fails - i.e. the R code shows an error like some of it didn't make it through. - If I run the code 80 or so lines at a time, it works fine. "
349778,388869,https://api.github.com/repos/Kaiserreich/Kaiserreich-4/issues/15152,bug,2021-04-29T08:43:51Z,NONE,https://api.github.com/repos/Kaiserreich/Kaiserreich-4,"Paternal Autocrat Netherlands in the Internationale **Quick questions** OS: HOI4 version: collie Kaiserreich version: 1.17.1 List any other mods used: none Were you using Steam? yes Were you in multiplayer? no Which expansions do you NOT have? none **Explanation of the issue:** i dont know much of what happened, i only know that in the middle of 1939, batavian commune had a paternal autocrat coup, and after that they still kept their syndie name and they were still in the internationale faction. **Steps to reproduce:** 1. 2. **Possible cause:** **Screenshots:** ![image](https://user-images.githubusercontent.com/82730394/116524479-1e559d00-a8e0-11eb-9cb2-18ec4914bc3e.png) "
660063,733668,https://api.github.com/repos/SirUbu/note-taker/issues/2,enhancement,2021-05-29T17:06:28Z,OWNER,https://api.github.com/repos/SirUbu/note-taker,Create Server ## Description - Add logic to launch Express.js on local port
631244,701545,https://api.github.com/repos/percipioglobal/craft/issues/76,enhancement,2021-02-17T17:59:40Z,CONTRIBUTOR,https://api.github.com/repos/percipioglobal/craft,Optimise organisms and molecules for Live Preview Currently some of our molecules error out when we try to build a page with Live Preview. Optimise the molecules and organisms as much as possible to prevent the defaults from erroring out.
439075,488137,https://api.github.com/repos/marceloglacial/2021-leal-e-clementino/issues/10,enhancement,2021-03-01T13:20:04Z,OWNER,https://api.github.com/repos/marceloglacial/2021-leal-e-clementino,Mobile designs https://www.figma.com/proto/d9otPaDYi5hGRlmxyMk5Sl/Leal-%26-Clementino-(2021)?node-id=257%3A0&viewport=1263%2C179%2C0.34200000762939453&scaling=scale-down
422166,469261,https://api.github.com/repos/bathi-atra/lotgd_ds/issues/4,bug,2021-05-28T15:52:38Z,NONE,https://api.github.com/repos/bathi-atra/lotgd_ds,"Stalltier-Editor defekt? Versucht man in der Grotte - Stalltiereditor ein Tier zu bearbeiten. Hier z.B. dem Schlaufuchs mehr Waldrunden zu geben dann tritt folgende Fehlermeldung auf [Fri May 28 17:41:35.709306 2021] [proxy_fcgi:error] [pid 23067:tid 139880658454272] [client xxxxxxxxxxxx] AH01071: Got error 'PHP message: PHP Fatal error: Uncaught Error: [] operator not supported for strings in /var/www/vhosts/xxxxxxxx.stratoserver.net/httpdocs/su_mounts.php:116\nStack trace:\n#0 {main}\n thrown in /var/www/vhosts/xxxxxxxx.stratoserver.net/httpdocs/su_mounts.php on line 116', referer: https://xxxxxxx.stratoserver.net/su_mounts.php?op=edit&id=73 Der Browser kann nichts anzeigen aber man kann zurück."
680717,756534,https://api.github.com/repos/sdkman/sdkman-cli/issues/905,bug,2021-04-29T11:30:06Z,NONE,https://api.github.com/repos/sdkman/sdkman-cli,"Bug: `sdk env install` does not also set the current shell versions **Bug report** The very useful `sdk env install` command added in #839 does not also set the versions in your shell (ie do an `sdk env`). Looking in the code for the [`env` command](https://github.com/sdkman/sdkman-cli/blob/afccde0db167c7661f8177e9aa57619f13598de4/src/main/bash/sdkman-env.sh#L26) confirms this. I was initially confused by this - having run `sdk env install`, I assumed that I would have the installed versions set in my shell. Do you consider this a bug and if so, would you accept a fix to make `__sdkman_setup_env` also call `__sdkman_load_env`? Edit: see discussion below - this behaviour might be better controlled through a command-line agument? **To reproduce** ``` $ echo 'gradle=7.0' > .sdkmanrc $ sdk env install $ gradle --version ``` **System info** - macOS 10.15.7 - zsh 5.8 (x86_64-apple-darwin19.6.0) - SDKMAN 5.11.0+644 "
674187,749301,https://api.github.com/repos/Spazzinq/FlightControl/issues/59,bug,2020-10-14T03:28:30Z,OWNER,https://api.github.com/repos/Spazzinq/FlightControl,"Permission Check NPE ***ALWAYS HAVE THE LATEST VERSION OF THE PLUGIN*** **Describe the bug** *(if not just an error)* ... **Error** *(if there's an error, use gist to paste it)* https://gist.github.com/Spazzinq/7c9a2d7ee03f3c1fcad305900ddb2b89 "
617872,686638,https://api.github.com/repos/BoostryJP/ibet-SmartContract/issues/302,bug,2021-05-25T11:04:07Z,CONTRIBUTOR,https://api.github.com/repos/BoostryJP/ibet-SmartContract,[BUG] Non-transferable tokens can be transferred by using the transfer application ### 1. Describe the bug - IbetShare tokens that are set to be non-transferable can be transferred by using the transfer application and approval function. ### 2. Expected behavior - Non-transferable tokens cannot be applied for when applying for transfer. - Non-transferable tokens cannot be approved for transfer. 
607163,674748,https://api.github.com/repos/Genivia/ugrep/issues/110,question,2021-03-15T08:09:57Z,NONE,https://api.github.com/repos/Genivia/ugrep,"Add Deb Package to Ubuntu Repo Hi, Can you add deb package into ubuntu repo?"
645681,717680,https://api.github.com/repos/hashicorp/terraform-provider-google/issues/8886,enhancement,2021-04-12T04:50:04Z,NONE,https://api.github.com/repos/hashicorp/terraform-provider-google,"(Beta) Interface argument missing from google_compute_region_disk <!--- Please leave this line, it helps our automation: [issue-type:enhancement] ---> <!--- Please keep this note for the community ---> ### Community Note * Please vote on this issue by adding a 👍 [reaction](https://blog.github.com/2016-03-10-add-reactions-to-pull-requests-issues-and-comments/) to the original issue to help the community and maintainers prioritize this request * Please do not leave ""+1"" or ""me too"" comments, they generate extra noise for issue followers and do not help prioritize the request * If you are interested in working on this issue or have submitted a pull request, please leave a comment. If the issue is assigned to the ""modular-magician"" user, it is either in the process of being autogenerated, or is planned to be autogenerated soon. If the issue is assigned to a user, that user is claiming responsibility for the issue. If the issue is assigned to ""hashibot"", a community member has claimed the issue already. <!--- Thank you for keeping this note for the community ---> ### Description It's possible to create a region disk with interface set to NVMe through the beta cli command `gcloud beta compute disks create`. This setting is necessary to create persistent disks that can be attached to confidential nodes. Support for this same argument was added to compute_disk in https://github.com/hashicorp/terraform-provider-google/issues/7532 See: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_disk#interface ``` --interface=INTERFACE Specifies the disk interface to use for attaching this disk. Valid values are SCSI and NVME. The default is SCSI. ``` ### New or Affected Resource(s) * google_compute_region_disk ### Potential Terraform Configuration Same as google_compute_disk: https://registry.terraform.io/providers/hashicorp/google/latest/docs/resources/compute_disk#interface ### References https://github.com/hashicorp/terraform-provider-google/issues/7532 * #0000 "
5488,6127,https://api.github.com/repos/urbit/landscape/issues/423,bug,2021-02-12T19:54:28Z,CONTRIBUTOR,https://api.github.com/repos/urbit/landscape,"publish: an admin cannot delete arbitrary posts commit: urbit/urbit@3e1726a This was included in the permissions work I assume, and needs to be surfaced up in the UI for admins. A menu should be provided as so: <img width=""799"" alt=""Screen Shot 2021-02-12 at 2 53 56 PM"" src=""https://user-images.githubusercontent.com/1195363/107816060-2cb10580-6d42-11eb-8911-7536899bdc23.png""> "
533773,593264,https://api.github.com/repos/nextcloud/android/issues/8195,bug,2021-03-21T15:04:30Z,NONE,https://api.github.com/repos/nextcloud/android,Crash while navigating task list not activating application ### Crash notification ``` ************ CAUSE OF ERROR ************ java.lang.NullPointerException: Attempt to invoke virtual method 'void com.owncloud.android.ui.fragment.FileDetailActivitiesFragment.markCommentsAsRead()' on a null object reference at com.owncloud.android.ui.fragment.FileDetailFragment$1.onPageScrolled(FileDetailFragment.java:242) at androidx.viewpager.widget.ViewPager.dispatchOnPageScrolled(ViewPager.java:1930) at androidx.viewpager.widget.ViewPager.onPageScrolled(ViewPager.java:1904) at androidx.viewpager.widget.ViewPager.pageScrolled(ViewPager.java:1842) at androidx.viewpager.widget.ViewPager.scrollToItem(ViewPager.java:694) at androidx.viewpager.widget.ViewPager.onLayout(ViewPager.java:1786) at android.view.View.layout(View.java:16636) at android.view.ViewGroup.layout(ViewGroup.java:5437) at android.widget.LinearLayout.setChildFrame(LinearLayout.java:1743) at android.widget.LinearLayout.layoutVertical(LinearLayout.java:1586) at android.widget.LinearLayout.onLayout(LinearLayout.java:1495) at android.view.View.layout(View.java:16636) at android.view.ViewGroup.layout(ViewGroup.java:5437) at android.widget.FrameLayout.layoutChildren(FrameLayout.java:336) at android.widget.FrameLayout.onLayout(FrameLayout.java:273) at android.view.View.layout(View.java:16636) at android.view.ViewGroup.layout(ViewGroup.java:5437) at android.widget.LinearLayout.setChildFrame(LinearLayout.java:1743) at android.widget.LinearLayout.layoutHorizontal(LinearLayout.java:1732) at android.widget.LinearLayout.onLayout(LinearLayout.java:1497) at android.view.View.layout(View.java:16636) at android.view.ViewGroup.layout(ViewGroup.java:5437) at com.google.android.material.appbar.HeaderScrollingViewBehavior.layoutChild(HeaderScrollingViewBehavior.java:148) at com.google.android.material.appbar.ViewOffsetBehavior.onLayoutChild(ViewOffsetBehavior.java:43) at com.google.android.material.appbar.AppBarLayout$ScrollingViewBehavior.onLayoutChild(AppBarLayout.java:1996) at androidx.coordinatorlayout.widget.CoordinatorLayout.onLayout(CoordinatorLayout.java:918) at android.view.View.layout(View.java:16636) at android.view.ViewGroup.layout(ViewGroup.java:5437) at androidx.drawerlayout.widget.DrawerLayout.onLayout(DrawerLayout.java:1231) at android.view.View.layout(View.java:16636) at android.view.ViewGroup.layout(ViewGroup.java:5437) at android.widget.FrameLayout.layoutChildren(FrameLayout.java:336) at android.widget.FrameLayout.onLayout(FrameLayout.java:273) at android.view.View.layout(View.java:16636) at android.view.ViewGroup.layout(ViewGroup.java:5437) at android.widget.FrameLayout.layoutChildren(FrameLayout.java:336) at android.widget.FrameLayout.onLayout(FrameLayout.java:273) at android.view.View.layout(View.java:16636) at android.view.ViewGroup.layout(ViewGroup.java:5437) at android.widget.FrameLayout.layoutChildren(FrameLayout.java:336) at android.widget.FrameLayout.onLayout(FrameLayout.java:273) at android.view.View.layout(View.java:16636) at android.view.ViewGroup.layout(ViewGroup.java:5437) at android.widget.LinearLayout.setChildFrame(LinearLayout.java:1743) at android.widget.LinearLayout.layoutVertical(LinearLayout.java:1586) at android.widget.LinearLayout.onLayout(LinearLayout.java:1495) at android.view.View.layout(View.java:16636) at android.view.ViewGroup.layout(ViewGroup.java:5437) at android.widget.FrameLayout.layoutChildren(FrameLayout.java:336) at android.widget.FrameLayout.onLayout(FrameLayout.java:273) at com.android.internal.policy.PhoneWindow$DecorView.onLayout(PhoneWindow.java:2678) at android.view.View.layout(View.java:16636) at android.view.ViewGroup.layout(ViewGroup.java:5437) at android.view.ViewRootImpl.performLayout(ViewRootImpl.java:2171) at android.view.ViewRootImpl.performTraversals(ViewRootImpl.java:1931) at android.view.ViewRootImpl.doTraversal(ViewRootImpl.java:1107) at android.view.ViewRootImpl$TraversalRunnable.run(ViewRootImpl.java:6013) at android.view.Choreographer$CallbackRecord.run(Choreographer.java:858) at android.view.Choreographer.doCallbacks(Choreographer.java:670) at android.view.Choreographer.doFrame(Choreographer.java:606) at android.view.Choreographer$FrameDisplayEventReceiver.run(Choreographer.java:844) at android.os.Handler.handleCallback(Handler.java:739) at android.os.Handler.dispatchMessage(Handler.java:95) at android.os.Looper.loop(Looper.java:148) at android.app.ActivityThread.main(ActivityThread.java:5417) at java.lang.reflect.Method.invoke(Native Method) at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:726) at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:616) ************ APP INFORMATION ************ ID: com.nextcloud.client Version: 30150090 Build flavor: generic ************ DEVICE INFORMATION ************ Brand: google Device: flo Model: Nexus 7 Id: MOB30X Product: razor ************ FIRMWARE ************ SDK: 23 Release: 6.0.1 Incremental: 3036618 ``` 
185853,206674,https://api.github.com/repos/mathjax/MathJax/issues/2457,question,2020-06-16T22:00:57Z,NONE,https://api.github.com/repos/mathjax/MathJax,"Expose latex to mathjax internal representation translation API The MathJax Web Demo tex-chtml.html (https://mathjax.github.io/MathJax-demos-web/tex-chtml.html) shows a configuration of MathJax that will process an entire webpage, find existing LaTeX source, extract and translate to MathJax's internal representation, and then render the equation in place. I would like to be able to just call the portion of MathJax such that I could pass a single string (or other object) containing the LaTeX source (for a single equation) and have MathJax return and instance of its internal representation. Is this functionality already available? If not, could it be exposed? "
542015,602432,https://api.github.com/repos/YTVanced/VancedManager/issues/416,bug,2021-02-14T05:30:44Z,NONE,https://api.github.com/repos/YTVanced/VancedManager,"Manager is bugged if device is rotated during installation **Please only report your issue here, if all points below are true** - I installed the App from [vancedapp.com](https://vancedapp.com), this github repository or the Vanced Discord server - I am using the latest version - This is an issue in the Vanced Manager app (NOT Youtube Vanced) - This issue keeps re-occurring every time I try - For MIUI users: I disabled MIUI optimisation **Phone Specifications:** - Brand: Redmi Note 7 Pro - Operating System: Resurrection Remix 8.6.7 - Android Version: 10 - Vanced Manager Version: 2.4.0 **Please describe the problem you are having in as much detail as possible:** Vanced manager gets bugged, if device is rotated during installation of YouTube or Music. Have video recorded here https://youtu.be/rEcIqgFH-1s **Steps to reproduce:** Install latest manager (2.4.0) Turn on auto rotation in device Opened manager in portrait, given magisk root permission Clicked install on YouTube or Music. During progress bar dialog, rotate device to landscape. **Further details:** Fresh installation after ROM installed on my device using nik gapps. Magisk root. Bug won't happen if device not rotated in entire process, installed YouTube without bug this way."
337642,375326,https://api.github.com/repos/Nordes/IdentityServer4.LdapExtension/issues/65,enhancement,2021-04-04T20:46:15Z,NONE,https://api.github.com/repos/Nordes/IdentityServer4.LdapExtension,"IdentityServer version 4.1.2 Hello! I tried to update your example to IdentityServer version 4.1.2 and it didn’t work for me, are you planning to update your IdentityServer.LdapExtension?"
124124,137936,https://api.github.com/repos/cameronRomo/my-strain-book/issues/8,enhancement,2021-01-17T20:10:43Z,OWNER,https://api.github.com/repos/cameronRomo/my-strain-book,"Add basic styling As a user, * I would like to interact with an aesthetically pleasing website that uses modern styling supplied by CSS."
545792,606621,https://api.github.com/repos/iotaledger/identity.rs/issues/204,question,2021-04-09T07:36:02Z,COLLABORATOR,https://api.github.com/repos/iotaledger/identity.rs,"[Task] Open Discussion Points for DID Comms Specification v0.3 This issue is a list of open discussion points for v0.3: - [x] In report/report: Define an actual error communication / information field that is parseable and includes error codes. See #209 - [x] In revocation: How do we deal with unauthorized revocations, i.e. invalid ones? - [x] Discuss field `id` optionality over whole specification. - [x] Create sequence diagrams / state machines for every interaction. - [x] Discuss constraints to fields such that large message or spam attacks aren't a thing. - [x] Work on supported signatures (signature types) and signature suites and communication about those (""... and I offer these types of signatures and signature suites ...""). - [x] Discuss who signs what, how exactly and why. - [x] Discuss list of VC requirements - [x] Discuss credential schemata for credentialSchemaResponse - [x] Discuss how to deal with lists - [x] Discover Features: Do we want versioning with regex? - [x] Do we have / need a way to ask others to start an interaction? Relevant for [request](https://github.com/hyperledger/aries-rfcs/blob/master/features/0028-introduce/README.md) - [x] DID Introduction: n parties or just 2? - [x] Shall we split up all interactions to seperate files for better overview? - [x] Formatting for all split interactions"
305063,339183,https://api.github.com/repos/USantaTecla-tool-ustUML/front-angular/issues/19,enhancement,2021-05-20T14:46:43Z,CONTRIBUTOR,https://api.github.com/repos/USantaTecla-tool-ustUML/front-angular,"Completar registro, log in y log out Acordarse de recoger token al registrarse"
603064,670205,https://api.github.com/repos/AppTelemetry/Viewer/issues/44,enhancement,2021-01-29T17:44:31Z,CONTRIBUTOR,https://api.github.com/repos/AppTelemetry/Viewer,Recent Signals Improvement - [x] Rename to Recent Signals - [x] Filter by signal type - [x] Filter by user (for development testing) - [x] Auto Reload ? - [x] Use Druid
17689,19697,https://api.github.com/repos/Pure-Storage-Ansible/FlashArray-Collection/issues/144,bug,2021-02-01T16:57:04Z,NONE,https://api.github.com/repos/Pure-Storage-Ansible/FlashArray-Collection,"Bug at purestorage.flasharray.purefa_volume (move volume) **Describe the bug** If you use ""ansible-galaxy collection install purestorage.flasharray (v. 1.5.1)"" there is a problem with ""purestorage.flasharray.purefa_volume (move volume)"" it returns a error message: ""InsecureRequestWarning: Unverified HTTPS request is being made"" At version 1.5.0 the error not exist. **To Reproduce** Steps to reproduce the behavior: 1. Run playbook 2. - name: Move volume purestorage.flasharray.purefa_volume: name: ""{{ vol_name }}"" move: ""{{ vol_to_pod }}"" fa_url: ""{{ fa_url }}"" api_token: ""{{ fa_token }}"" 4. Returns error message: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n InsecureRequestWarning)\n/var/lib/awx/venv/ansible/lib/python3.6/site-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n"
340602,378629,https://api.github.com/repos/coil-kt/coil/issues/706,question,2021-03-22T20:26:14Z,NONE,https://api.github.com/repos/coil-kt/coil,Reset single memory/disc cache entry Is there a way to remove all cache entries (memory + disc) for a given reqeust? E.g. I have following: ```kotlin val data = ... // data is a valid coil model that can be loaded via `ImageRequest.Builder.data` // remove all related cache entries from memory and disc cache // could look like following context.imageLoader.memoryCache.removeAll(data) val cache = CoilUtils.createDefaultCache(context) cache.removeAll(data) ``` Is that somehow possible?
214713,238758,https://api.github.com/repos/zero-to-mastery/breads-client/issues/54,bug,2020-12-11T06:44:11Z,COLLABORATOR,https://api.github.com/repos/zero-to-mastery/breads-client,Subscribe error: Cannot read property 'following' of undefined The error above is thrown whenever a user subscribes to another.
321269,357153,https://api.github.com/repos/Spessman-Incorporated/Spessman/issues/11,enhancement,2021-02-28T17:19:17Z,CONTRIBUTOR,https://api.github.com/repos/Spessman-Incorporated/Spessman,Create Error panel when connecting to server fails ### Description Simple error panel 
313626,348678,https://api.github.com/repos/robotframework/SSHLibrary/issues/45,bug,2014-08-14T09:13:22Z,CONTRIBUTOR,https://api.github.com/repos/robotframework/SSHLibrary,"keepalive ssh connect by sending null packets to server until timeout reach > _Originally submitted to [Google Code](http://code.google.com/p/robotframework-sshlibrary/issues/detail?id=45) by zhangjia... on 23 Apr 2012_ **What steps will reproduce the problem?** 1. Create ssh connect and set timeout as 10 min 2. But remote *nix server will disconnect any idle client and terminating the session if no data has been received from client longer than 5 min. But my script on remote server will take 10 min to finish. **What is the expected output? What do you see instead?** We are hoping that ssh lib can help us send null packets to the remote server so that the connection can keepalive before timeout value reached. **What version of the product are you using? On what operating system?** SSH 1.0. robot is running on Windows XP. **Please provide any additional information below.** putty can provide the similiar function by setting the interval seconds to the option ""Sending of null packets to keep session active"". "
646733,718854,https://api.github.com/repos/nomorenotes/nomorecdn/issues/1,bug,2021-03-08T13:03:45Z,CONTRIBUTOR,https://api.github.com/repos/nomorenotes/nomorecdn,"NoMoreNotes account creation requests When someone creates an account, a comment will be made on this issue."
386393,429526,https://api.github.com/repos/opensearch-project/opensearch-plugins/issues/37,enhancement,2021-05-26T16:25:57Z,CONTRIBUTOR,https://api.github.com/repos/opensearch-project/opensearch-plugins,Document RestAPI backward compatibility support for routes on 9600 port The RestAPIs design documented for backward compatibility takes care of routes in 9200. For other routes which run on 9600 we have a different design. 
673169,748162,https://api.github.com/repos/microsoft/azuredatastudio/issues/15191,bug,2021-04-19T23:37:51Z,CONTRIBUTOR,https://api.github.com/repos/microsoft/azuredatastudio,unnecessary horizontal scrollbar in the 'create project from database' dialog ![image](https://user-images.githubusercontent.com/13777222/115316063-7399ed80-a12d-11eb-92d7-6e5661b11ff7.png) 
714444,794033,https://api.github.com/repos/Metatavu/meta-proj-cli/issues/132,enhancement,2021-03-19T08:30:08Z,CONTRIBUTOR,https://api.github.com/repos/Metatavu/meta-proj-cli,"utilizing prompt-utils We have the prompt-utils utility, now it's time to utilize it."
560638,623061,https://api.github.com/repos/duch3201/LightFile/issues/15,bug,2021-02-04T13:54:14Z,OWNER,https://api.github.com/repos/duch3201/LightFile,"can't change laungage ``` Traceback (most recent call last): File ""Y:\LightFile\config.py"", line 35, in <module> if(exists == False): NameError: name 'exists' is not defined ``` after adding this: ![image](https://user-images.githubusercontent.com/56601374/106902177-cd774380-66f8-11eb-9b3e-105938a37690.png) to the config file"
357323,397231,https://api.github.com/repos/UMCP-CSA/Lunar-Banquet-2021/issues/20,enhancement,2021-01-05T02:59:07Z,CONTRIBUTOR,https://api.github.com/repos/UMCP-CSA/Lunar-Banquet-2021,"Shopping tile styling: Padding (a tad bit more) + square images Should match our color scheme currently by having a white background on the tile, and use regular <img> tags instead of avatars for the shopping tile - Add an add to cart button on hover (it doesn't have to actually add to cart until we built the shopping cart functionality) - Should have an in stock indicator (the stock status will be passed in via props to the component) - Make sure the typography looks nice like below, where the title is bigger (h4 or so in MUI typography) and the descrip is smaller font (body2 in MUI typography i think, but you can adjust accordingly) Here's a good design you can refer to: ![image](https://user-images.githubusercontent.com/52755821/103601481-b82faf00-4ed7-11eb-9302-5b3f65504a73.png) "
173634,193072,https://api.github.com/repos/Adyen/adyen-dotnet-api-library/issues/366,enhancement,2021-01-18T23:40:01Z,NONE,https://api.github.com/repos/Adyen/adyen-dotnet-api-library,Adyen.Model.Modification.CaptureRequest does not include Splits **Is your feature request related to a problem? Please describe.** I'm trying to do manual /capture with splits and I do not see a way to do it. **Describe the solution you'd like** Add 'Splits' to the Adyen.Model.Modification.CaptureRequest object **Describe alternatives you've considered** I tried inheriting from Adyen.Model.Modification.CaptureRequest and extending it but then the serializer won't get the property either. **Additional context** https://docs.adyen.com/api-explorer/#/Payment/v64/post/capture__reqParam_splits 
356564,396395,https://api.github.com/repos/ucfcs/Fall2020-Group44/issues/204,bug,2021-04-14T21:30:59Z,COLLABORATOR,https://api.github.com/repos/ucfcs/Fall2020-Group44,Add node fetch error handling node-fetch does not throw an error for request rejection
464158,515845,https://api.github.com/repos/Tanche-Z/Tanche-Z.github.io/issues/2,enhancement,2021-04-21T06:30:09Z,OWNER,https://api.github.com/repos/Tanche-Z/Tanche-Z.github.io,aaa aaa
661391,735153,https://api.github.com/repos/EtienneLamoureux/sc-trade-tools/issues/96,enhancement,2020-12-13T11:30:47Z,NONE,https://api.github.com/repos/EtienneLamoureux/sc-trade-tools,Display min/max prices and profits It would be really great to have the prices split into min and max buy and sell prices. Also the profit should display a range. To save some space the price could be displayed as the median and on mouseover the min and max values show up. This way the trader could make an even more informed trading decision. 
439808,488953,https://api.github.com/repos/Azure/azure-sdk-for-java/issues/19837,question,2021-03-14T00:17:46Z,NONE,https://api.github.com/repos/Azure/azure-sdk-for-java,"Application Freezes without error message Hi, when both dependencies are enabled, my application freezes without an error message: ``` <dependency> <groupId>com.azure.spring</groupId> <artifactId>azure-spring-boot-starter-keyvault-secrets</artifactId> <version>3.2.0</version> </dependency> <!--<dependency> <groupId>com.azure</groupId> <artifactId>azure-storage-blob</artifactId> <version>12.6.0</version> </dependency>-->` ``` --- #### Document Details ⚠ *Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.* * ID: fc84b055-7874-13cd-912c-7f8e37bbb880 * Version Independent ID: 3aa67db1-9d45-9486-f67d-4cd4e9784fb7 * Content: [Azure Key Vault Secrets Spring Boot starter client library for Java](https://docs.microsoft.com/en-us/java/api/overview/azure/spring-boot-starter-keyvault-secrets-readme?view=azure-java-stable) * Content Source: [docs-ref-services/latest/spring-boot-starter-keyvault-secrets-readme.md](https://github.com/Azure/azure-docs-sdk-java/blob/master/docs-ref-services/latest/spring-boot-starter-keyvault-secrets-readme.md) * Service: **springboot** * Product: **azure** * Technology: **azure** * GitHub Login: @maggiepint * Microsoft Alias: **magpint**"
365436,406237,https://api.github.com/repos/hass-emulated-hue/core/issues/67,bug,2021-01-10T11:41:10Z,CONTRIBUTOR,https://api.github.com/repos/hass-emulated-hue/core,"Invalid/unknown request: <Request PUT /api/c013fbe396b847f9a306/groups/ > --> {'stream': {'active': False}} <!-- !! DO NOT DELETE ANY TEXT FROM THIS TEMPLATE !! Thank you for taking the time to submit a BUG REPORT for this project. To ensure we have all the information necessary, please be sure to carefully read ALL the primers below. This will ensure that we have the necessary information to understand and reproduce the problem. 1. Please be sure to fill in the issue template completely and to the best of your ability so that we may reproduce the issue. Issues that are not reproducible CANNOT be fixed. 2. Support for installation methods other than Docker have been depreciated so ensure you are using Docker so that we may be able to best help you. 3. Do NOT use this template for user error/help/support questions. If this is for a help request, please go back and select the proper template. Basic GitHub Comment Tutorial: 1. Logs When pasting logs or code, type logs like so with ``` on either side. ``` Logs here. ``` 2. Checkboxes - [ ] This is a checkbox. To ""check"" the box put an x in the brackets like so - [x] This is a checked box. 3. Comments A block of text beginning with < !-- and ending with -- > is a comment. You will see these throughout the issue template. Make sure you do not type your comments between these characters or we will not be able to see what you wrote! 4. Links To create a hyperlink, type the [text you want to link](followed by the url in parenthesis) --> **Describe the bug** <!-- A clear and concise description of what the bug is. --> I'm getting warning in logs when I'm disabling Ambilight+Hue on non-Android Philips TV **Steps to Reproduce** <!-- Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error --> 1. Turn Ambilight+Hue on 2. Turn Ambilight+Hue off 3. Observer Warning in logs **Expected behavior** <!-- A clear and concise description of what you expected to happen. --> No warning on disabling Ambilight+Hue **Logs** <!-- If applicable, provide output logs. --> `2021-01-10 12:39:21,495 WARNING emulated_hue.api -- Invalid/unknown request: <Request PUT /api/c013fbe396b847f9a306/groups/ > --> {'stream': {'active': False}}` **Hardware Info:** - Architecture (Ex: x86, ARM): ARMv7 - Addon version (Ex: stable or dev): stable - Value of ""tag_commit_or_branch"" if using dev: - OS (Ex: Windows 10, Ubuntu Buster): HassOS - Hardware (Ex: PC, Raspberry Pi 1/2/3/Zero): RPI 3 **Additional context** <!-- Add any other context about the problem here. --> "
40709,45334,https://api.github.com/repos/shogo4405/SRTHaishinKit.swift/issues/11,enhancement,2021-04-20T18:08:09Z,NONE,https://api.github.com/repos/shogo4405/SRTHaishinKit.swift,"Adding Framework to project Hi, I'm wondering how I add the SRTHaishinKit framework to my current xcode project. I didn't see a cocoapods for it so I wasn't sure how I have to add it in. -Thanks"
287803,320056,https://api.github.com/repos/fwupd/fwupd/issues/2803,bug,2021-01-24T09:36:07Z,NONE,https://api.github.com/repos/fwupd/fwupd,"EFI partition not found fwupd 1.5.5 on a system without udisks EFI partition mounted as /boot before starting fwupd the first time OverrideESPMountPoint=/boot in /etc/fwupd/uefi.conf Each time I execute fwupdmgr, I get an error message UEFI ESP partition not detected or configured See https://github.com/fwupd/fwupd/wiki/PluginFlag:esp-not-found for more information. Why? If /boot is already mounted before the daemon is started, it should just work and not depend on udisks in any way?"
398741,443181,https://api.github.com/repos/ghga-de/datameta/issues/321,enhancement,2021-04-23T14:14:55Z,COLLABORATOR,https://api.github.com/repos/ghga-de/datameta,"Precise Error Handling for accepting requests Currently, when an error occurs during accepting account requests, an alert popup is opened. Change this to the type of error and maybe use danger alerts instead of a popup."
183782,204310,https://api.github.com/repos/alteryx/evalml/issues/1964,bug,2021-03-11T17:17:27Z,CONTRIBUTOR,https://api.github.com/repos/alteryx/evalml,"F1 objective causes a Runtime warning in AutoMLSearch Repro: ```python from evalml.demos import load_fraud from evalml import AutoMLSearch X, y = load_fraud(n_rows=50000) automl = AutoMLSearch(X_train=X, y_train=y, objective='f1', problem_type='binary') automl.search() ``` Results in: ![image](https://user-images.githubusercontent.com/22552445/110826915-8b936d00-8263-11eb-8f7b-29b50ddd7909.png) I don't observe this issue for `log loss binary` or `auc` metrics, so it might be something that's changed with how F1 is calculated in SKlearn. "
261540,290873,https://api.github.com/repos/Xandir150/montel_admin/issues/4,bug,2020-11-24T11:12:30Z,NONE,https://api.github.com/repos/Xandir150/montel_admin,Время Терминалов Время не совпадает. В развернутом виде время отображается на час раньше ![Screenshot_2020-11-24-10-51-39-792_com android chrome](https://user-images.githubusercontent.com/74590412/100086884-467f3280-2e4e-11eb-92de-daaabdf6f84e.jpg) 
428832,476711,https://api.github.com/repos/MozillaSecurity/FuzzManager/issues/572,bug,2019-08-09T17:03:29Z,CONTRIBUTOR,https://api.github.com/repos/MozillaSecurity/FuzzManager,"Bugzilla create bug is missing 'type' field. Reported by @nth10sd. Server log below. This results in a 500 error when submitting a bug to Bugzilla. ``` Aug 8 23:40:49 django: [ERROR] [django.request]: Internal Server Error: /crashmanager/crashes/3696328/createbug/ Traceback (most recent call last): File ""/usr/local/lib/python2.7/dist-packages/django/core/handlers/exception.py"", line 41, in inner response = get_response(request) File ""/usr/local/lib/python2.7/dist-packages/django/core/handlers/base.py"", line 249, in _legacy_get_response response = self._get_response(request) File ""/usr/local/lib/python2.7/dist-packages/django/core/handlers/base.py"", line 187, in _get_response response = self.process_exception_by_middleware(e, request) File ""/usr/local/lib/python2.7/dist-packages/django/core/handlers/base.py"", line 185, in _get_response response = wrapped_callback(request, *callback_args, **callback_kwargs) File ""/srv/FuzzManager/server/crashmanager/views.py"", line 962, in createExternalBug extBugId = provider.getInstance().handlePOSTCreate(request, entry) File ""/srv/FuzzManager/server/crashmanager/Bugtracker/BugzillaProvider.py"", line 305, in handlePOSTCreate raise RuntimeError(""Failed to create bug: %s"", ret) RuntimeError: ('Failed to create bug: %s', {u'code': 135, u'message': u'To file a new bug, you must first choose a type: --, defect, enhancement or task.', u'documentation': u'https://bmo.readthedocs.io/en/latest/api/', u'error': True}) ``` Solution: > @choller: we need to set type = ""defect"" when submitting"
406772,452139,https://api.github.com/repos/hashicorp/terraform-provider-helm/issues/445,question,2020-03-18T01:21:35Z,NONE,https://api.github.com/repos/hashicorp/terraform-provider-helm,"""heal_release"" work unstable with error ""Kubernetes cluster unreachable"" sometime Hello, my code most time work but some time will fail with this kind of error: ""helm_release.xxxxxx"": Kubernetes cluster unreachable Terraform: 0.11.14 `provider ""helm"" { version = ""1.0"" alias = ""default"" kubernetes { host = ""${aws_eks_cluster.eks-cluster.endpoint}"" cluster_ca_certificate = ""${base64decode(aws_eks_cluster.eks-cluster.certificate_authority.0.data)}"" token = ""${data.aws_eks_cluster_auth.eks-cluster.token}"" load_config_file = false } } resource ""helm_release"" ""nginx-controller"" { provider = ""helm.default"" name = ""nginx-controller"" chart = ""${path.module}/charts/nginx-controller"" force_update = true atomic = true timeout = 1200 ... depends_on = [""aws_eks_node_group.eks-node-group""] }` BTW: When this happens, a rerun will pass. Cannot find how to get debug logs and also curious if any retry logic in the helm provider? Or something wrong in my codes?"
230151,255949,https://api.github.com/repos/tjhamlet/tjhamlet.github.io/issues/3,enhancement,2021-01-25T02:52:44Z,OWNER,https://api.github.com/repos/tjhamlet/tjhamlet.github.io,"Add basic info Add information like name, address, contact information, etc."
237956,264688,https://api.github.com/repos/10up/safe-redirect-manager/issues/228,bug,2021-01-07T19:07:02Z,NONE,https://api.github.com/repos/10up/safe-redirect-manager,"srm_redirect_only_on_404 doesn't work for many 404s Filing a short bug report at @helen's request: When the functionality backed by the `srm_redirect_only_on_404` filter is enabled, `maybe_redirect` is hooked on `parse_request`. However, even on a page that ultimately 404's, `is_404()` is likely to return false at `WP::parse_request()` because it is before any lookups have been done in `WP::query_posts()`. There seems to be a scenario (where no rewrite rule is matched) where 404 _might_ be set early enough for this to work occasionally, but for the most part this functionality seems to fail. While I have not tested this, SRM should probably hook into `set_404` directly. It's more explicit and would catch precisely the scenarios where `WP` and `WP_Query` have decided a 404 will be sent."
299131,332602,https://api.github.com/repos/bentoml/BentoML/issues/1533,bug,2021-03-25T05:48:03Z,NONE,https://api.github.com/repos/bentoml/BentoML,"Confusing Docstring in lightgbm.py **Describe the bug** <!--- A clear and concise description of what the bug is. --> https://github.com/bentoml/BentoML/blob/master/bentoml/frameworks/lightgbm.py#L14 `model_extension (string): Extension name for saved xgboost model` Why do we need an extension name for saved `xgboost` model? **To Reproduce** <!-- Steps to reproduce the issue: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error --> **Expected behavior** <!--- A clear and concise description of what you expected to happen. --> **Screenshots/Logs** <!--- If applicable, add screenshots, logs or error outputs to help explain your problem. To give us more information for diagnosing the issue, make sure to enable debug logging: Enable via environment variable, e.g.: ``` $ git clone git@github.com:bentoml/BentoML.git && cd bentoml $ BENTOML__CORE__DEBUG=true python guides/quick-start/main.py ``` Or enable for all python sessions on current machine: ```bash $ bentoml config set core.debug=true $ python guides/quick-start/main.py ``` Or set debug logging in your Python code: ```python import bentoml import logging bentoml.config().set('core', 'debug', 'true') bentoml.configure_logging(logging.DEBUG) ``` For BentoML CLI commands, simply add the `--verbose` flag, e.g.: ```bash bentoml get IrisClassifier --verbose ``` --> **Environment:** - OS: [e.g. MacOS 10.14.3] - Python Version [e.g. Python 3.7.1] - BentoML Version [e.g. BentoML-0.8.6] **Additional context** <!-- Add any other context about the problem here. e.g. links to related discussion. --> "
195976,217906,https://api.github.com/repos/tracelabs/tlosint-live/issues/71,enhancement,2021-01-27T09:15:08Z,MEMBER,https://api.github.com/repos/tracelabs/tlosint-live,[Tool request] exiftool **Is your feature request related to a problem? Please describe.** A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] **Describe the tool you'd like** A clear and concise description of the tool you want added. **A link to the tool** A link to the tool code\repository. **Additional context** Add any other context or screenshots about the feature request here. 
482066,535764,https://api.github.com/repos/microsoft/vscode/issues/97323,bug,2020-05-09T04:59:57Z,NONE,https://api.github.com/repos/microsoft/vscode,"Folding Breaks <!-- ⚠️⚠️ Do Not Delete This! bug_report_template ⚠️⚠️ --> <!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ --> <!-- Please search existing issues to avoid creating duplicates. --> <!-- Also please test using the latest insiders build to make sure your issue has not already been fixed: https://code.visualstudio.com/insiders/ --> <!-- Use Help > Report Issue to prefill these. --> - VSCode Version: 1.45.0 - OS Version: Windows 10.0.18363.815 Don't know if it's a bug or if I mess up but... : Steps to Reproduce: 1. Add some comments folders. 2. Add another comments and a line of code then all folders dissapears. 3. I can't do any folder anymore. <a href=""https://gifyu.com/image/nLGl""><img src=""https://s6.gifyu.com/images/VsCodeBug.gif"" alt=""Vs-Code-Bug"" border=""0""></a> (Text that I type after the last comment seems to stay with the comments. I mean the little identation bar on the left) <!-- Launch with `code --disable-extensions` to check. --> Does this issue occur when all extensions are disabled?: Yes. With Insiders too. I tried to change the editor.foldingStrategy option. I disabled all extensions. "
276893,307941,https://api.github.com/repos/vazco/uniforms/issues/847,bug,2021-01-08T12:57:53Z,MEMBER,https://api.github.com/repos/vazco/uniforms,"Incosistent documentation of ""onValidate"" prop As per the [migration guide](https://uniforms.tools/docs/migrating-2-to-3#validation-flow-changes) `onValidate` should return a promise, however the examples still use callbacks: * https://uniforms.tools/docs/api-forms/#props-usage-1 * https://uniforms.tools/docs/api-forms/#asynchronous-validation * maybe more places, need to check the code Thanks!"
146272,162588,https://api.github.com/repos/facebookresearch/flashlight/issues/492,question,2021-03-10T16:35:07Z,NONE,https://api.github.com/repos/facebookresearch/flashlight,"After install can not run the test ### Question I follow the step to install this repo, and final show that i had install the flashlight==1.0.0. Then I run the two command below for testing. ``` python3 bindings/python/example/decoder_example.py flashlight/app/asr/test/decoder/data/ python bindings/python/example/feature_example.py flashlight/lib/test/audio/feature/data/ ``` and show the error for each cmd is ``` Loading the LM will be faster if you build a binary file. Reading flashlight/app/asr/test/decoder/data/lm.arpa ----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100 **************************************************************************************************** Segmentation fault (core dumped) # another cmd show this err Intel MKL FATAL ERROR: Cannot load libmkl_avx2.so or libmkl_def.so. ``` #### Additional Context here is my make output ``` running install running bdist_egg running egg_info writing flashlight.egg-info/PKG-INFO writing dependency_links to flashlight.egg-info/dependency_links.txt writing top-level names to flashlight.egg-info/top_level.txt package init file 'flashlight/__init__.py' not found (or not a regular file) package init file 'flashlight/lib/audio/__init__.py' not found (or not a regular file) package init file 'flashlight/lib/sequence/__init__.py' not found (or not a regular file) package init file 'flashlight/lib/text/__init__.py' not found (or not a regular file) reading manifest file 'flashlight.egg-info/SOURCES.txt' reading manifest template 'MANIFEST.in' writing manifest file 'flashlight.egg-info/SOURCES.txt' installing library code to build/bdist.linux-x86_64/egg running install_lib running build_py creating build creating build/lib.linux-x86_64-3.6 creating build/lib.linux-x86_64-3.6/flashlight creating build/lib.linux-x86_64-3.6/flashlight/lib copying flashlight/lib/__init__.py -> build/lib.linux-x86_64-3.6/flashlight/lib creating build/lib.linux-x86_64-3.6/flashlight/lib/audio copying flashlight/lib/audio/feature.py -> build/lib.linux-x86_64-3.6/flashlight/lib/audio creating build/lib.linux-x86_64-3.6/flashlight/lib/sequence copying flashlight/lib/sequence/criterion.py -> build/lib.linux-x86_64-3.6/flashlight/lib/sequence copying flashlight/lib/sequence/criterion_torch.py -> build/lib.linux-x86_64-3.6/flashlight/lib/sequence creating build/lib.linux-x86_64-3.6/flashlight/lib/text copying flashlight/lib/text/dictionary.py -> build/lib.linux-x86_64-3.6/flashlight/lib/text copying flashlight/lib/text/decoder.py -> build/lib.linux-x86_64-3.6/flashlight/lib/text running build_ext -- The CXX compiler identification is GNU 7.5.0 -- The C compiler identification is GNU 7.5.0 -- Check for working CXX compiler: /usr/bin/c++ -- Check for working CXX compiler: /usr/bin/c++ -- works -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Detecting CXX compile features -- Detecting CXX compile features - done -- Check for working C compiler: /usr/bin/cc -- Check for working C compiler: /usr/bin/cc -- works -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Detecting C compile features -- Detecting C compile features - done -- Performing Test COMPILER_SUPPORTS_RDYNAMIC -- Performing Test COMPILER_SUPPORTS_RDYNAMIC - Success -- -rdynamic supported. -- The CUDA compiler identification is NVIDIA 10.0.130 -- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc -- Check for working CUDA compiler: /usr/local/cuda/bin/nvcc -- works -- Detecting CUDA compiler ABI info -- Detecting CUDA compiler ABI info - done -- Looking for pthread.h -- Looking for pthread.h - found -- Looking for pthread_create -- Looking for pthread_create - not found -- Looking for pthread_create in pthreads -- Looking for pthread_create in pthreads - not found -- Looking for pthread_create in pthread -- Looking for pthread_create in pthread - found -- Found Threads: TRUE -- CUDA found (library: /usr/local/cuda/lib64/libcudart_static.a;-lpthread;dl;/usr/lib/x86_64-linux-gnu/librt.so include: /usr/local/cuda/include) -- CUDA architecture flags: -gencodearch=compute_30,code=sm_30-gencodearch=compute_35,code=sm_35-gencodearch=compute_50,code=sm_50-gencodearch=compute_52,code=sm_52-gencodearch=compute_60,code=sm_60-gencodearch=compute_61,code=sm_61-gencodearch=compute_70,code=sm_70-gencodearch=compute_75,code=sm_75-gencodearch=compute_75,code=compute_75 -- Will build flashlight libraries. -- MKL_THREADING = OMP -- Looking for sys/types.h -- Looking for sys/types.h - found -- Looking for stdint.h -- Looking for stdint.h - found -- Looking for stddef.h -- Looking for stddef.h - found -- Check size of void* -- Check size of void* - done -- Checking for [mkl_intel_lp64 - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl] -- Library mkl_intel_lp64: /opt/intel/mkl/lib/intel64/libmkl_intel_lp64.so -- Library mkl_gnu_thread: /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.so -- Library mkl_core: /opt/intel/mkl/lib/intel64/libmkl_core.so -- Library gomp: -fopenmp -- Library pthread: /usr/lib/x86_64-linux-gnu/libpthread.so -- Library m: /usr/lib/x86_64-linux-gnu/libm.so -- Library dl: /usr/lib/x86_64-linux-gnu/libdl.so -- Looking for cblas_sgemm -- Looking for cblas_sgemm - found -- MKL library found -- CBLAS found (include: /opt/intel/mkl/include, library: /opt/intel/mkl/lib/intel64/libmkl_intel_lp64.so;/opt/intel/mkl/lib/intel64/libmkl_gnu_thread.so;/opt/intel/mkl/lib/intel64/libmkl_core.so;-fopenmp;/usr/lib/x86_64-linux-gnu/libpthread.so;/usr/lib/x86_64-linux-gnu/libm.so;/usr/lib/x86_64-linux-gnu/libdl.so) -- Could NOT find FFTW3 (missing: FFTW3_DIR) -- Found PkgConfig: /usr/bin/pkg-config (found version ""0.29.1"") -- FindFFTW using pkgconfig: FOUND=1 LIBRARIES=fftw3 LIBRARY_DIRS= LIBDIR=/usr/lib/x86_64-linux-gnu LINK_LIBRARIES= -- FindFTTW using pkgconfig: INCLUDE_DIRS= INCLUDEDIR=/usr/include -- Found FFTW3: /usr/include -- FFTW found -- Found OpenMP_C: -fopenmp (found version ""4.5"") -- Found OpenMP_CXX: -fopenmp (found version ""4.5"") -- Found OpenMP: TRUE (found version ""4.5"") -- Looking for KenLM -- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so -- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found -- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so -- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found -- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so -- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so - found -- Found LibLZMA: /usr/include (found version ""5.2.2"") -- Found BZip2: /usr/lib/x86_64-linux-gnu/libbz2.so (found version ""1.0.6"") -- Looking for BZ2_bzCompressInit -- Looking for BZ2_bzCompressInit - found -- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version ""1.2.11"") -- Using kenlm library found in /root/kenlm/build/lib/libkenlm.a -- Using kenlm utils library found in /root/kenlm/build/lib/libkenlm_util.a -- kenlm model.hh found in /root/kenlm/lm -- Found kenlm: /root -- Found kenlm (include: /root, library: /root/kenlm/build/lib/libkenlm.a;/root/kenlm/build/lib/libkenlm_util.a;/usr/lib/x86_64-linux-gnu/liblzma.so;/usr/lib/x86_64-linux-gnu/libbz2.so;/usr/lib/x86_64-linux-gnu/libz.so) -- Could NOT find cub (missing: cub_INCLUDE_DIRS) -- Could not find cub - will download from source -- Found PythonInterp: /usr/local/bin/python (found version ""3.6.9"") -- Found PythonLibs: /usr/lib/x86_64-linux-gnu/libpython3.6m.so -- Performing Test HAS_FLTO -- Performing Test HAS_FLTO - Success -- LTO enabled -- Configuring done -- Generating done -- Build files have been written to: /root/flashlight/bindings/python/build/temp.linux-x86_64-3.6 Scanning dependencies of target pybind11 Scanning dependencies of target CUB [ 1%] Creating directories for 'CUB' [ 3%] Creating directories for 'pybind11' [ 4%] Performing download step (git clone) for 'CUB' [ 6%] Performing download step (git clone) for 'pybind11' Cloning into 'CUB'... Cloning into 'pybind11'... Note: checking out '9a19306fbf30642ca331d0ec88e7da54a96860f9'. You are in 'detached HEAD' state. You can look around, make experimental changes and commit them, and you can discard any commits you make in this state without impacting any branches by performing another checkout. If you want to create a new branch to retain commits you create, you may do so (now or later) by using -b with the checkout command again. Example: git checkout -b <new-branch-name> HEAD is now at 9a19306 bump version to 2.2.4 Submodule 'tools/clang' (https://github.com/wjakob/clang-cindex-python3) registered for path 'tools/clang' Cloning into '/root/flashlight/bindings/python/build/temp.linux-x86_64-3.6/pybind11/src/pybind11/tools/clang'... Submodule path 'tools/clang': checked out '6a00cbc4a9b8e68b71caf7f774b3f9c753ae84d5' [ 8%] No patch step for 'pybind11' [ 9%] Performing update step for 'pybind11' [ 11%] No configure step for 'pybind11' [ 13%] No build step for 'pybind11' [ 14%] No install step for 'pybind11' [ 16%] Completed 'pybind11' [ 16%] Built target pybind11 Note: checking out 'c3cceac115c072fb63df1836ff46d8c60d9eb304'. You are in 'detached HEAD' state. You can look around, make experimental changes and commit them, and you can discard any commits you make in this state without impacting any branches by performing another checkout. If you want to create a new branch to retain commits you create, you may do so (now or later) by using -b with the checkout command again. Example: git checkout -b <new-branch-name> HEAD is now at c3cceac1 update readme to 1.8.0 [ 19%] No patch step for 'CUB' [ 19%] Performing update step for 'CUB' [ 21%] No configure step for 'CUB' [ 22%] No build step for 'CUB' [ 24%] No install step for 'CUB' [ 26%] Completed 'CUB' [ 26%] Built target CUB Scanning dependencies of target fl-libraries [ 29%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/sequence/criterion/cpu/ForceAlignmentCriterion.cpp.o [ 29%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/sequence/criterion/cpu/CriterionUtils.cpp.o [ 32%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/sequence/criterion/cpu/FullConnectionCriterion.cpp.o [ 32%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/sequence/criterion/cpu/ConnectionistTemporalClassificationCriterion.cpp.o [ 34%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/sequence/criterion/cpu/ViterbiPath.cpp.o [ 36%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/audio/feature/Ceplifter.cpp.o [ 37%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/audio/feature/Dct.cpp.o [ 39%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/audio/feature/Derivatives.cpp.o [ 42%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/audio/feature/Mfcc.cpp.o [ 42%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/audio/feature/Dither.cpp.o [ 44%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/audio/feature/Mfsc.cpp.o [ 45%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/audio/feature/PowerSpectrum.cpp.o [ 47%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/audio/feature/PreEmphasis.cpp.o [ 49%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/audio/feature/SpeechUtils.cpp.o [ 50%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/audio/feature/Windowing.cpp.o [ 52%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/audio/feature/TriFilterbank.cpp.o [ 54%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/common/String.cpp.o [ 55%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/common/System.cpp.o [ 57%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/text/decoder/lm/ConvLM.cpp.o [ 59%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/text/decoder/lm/ZeroLM.cpp.o [ 60%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/text/decoder/lm/KenLM.cpp.o [ 62%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/text/decoder/LexiconDecoder.cpp.o [ 63%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/text/decoder/LexiconFreeDecoder.cpp.o [ 65%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/text/decoder/LexiconSeq2SeqDecoder.cpp.o [ 67%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/text/decoder/LexiconFreeSeq2SeqDecoder.cpp.o [ 68%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/text/decoder/Trie.cpp.o [ 70%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/text/decoder/Utils.cpp.o [ 72%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/text/dictionary/Dictionary.cpp.o [ 73%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/text/dictionary/Utils.cpp.o [ 75%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/text/tokenizer/PartialFileReader.cpp.o [ 77%] Building CXX object CMakeFiles/fl-libraries.dir/flashlight/lib/text/tokenizer/Tokenizer.cpp.o [ 78%] Building CUDA object CMakeFiles/fl-libraries.dir/flashlight/lib/sequence/criterion/cuda/CriterionUtils.cu.o [ 80%] Building CUDA object CMakeFiles/fl-libraries.dir/flashlight/lib/sequence/criterion/cuda/ForceAlignmentCriterion.cu.o [ 83%] Building CUDA object CMakeFiles/fl-libraries.dir/flashlight/lib/sequence/criterion/cuda/ViterbiPath.cu.o [ 83%] Building CUDA object CMakeFiles/fl-libraries.dir/flashlight/lib/sequence/criterion/cuda/FullConnectionCriterion.cu.o [ 85%] Linking CUDA device code CMakeFiles/fl-libraries.dir/cmake_device_link.o [ 86%] Linking CXX shared library ../lib.linux-x86_64-3.6/libfl-libraries.so [ 86%] Built target fl-libraries Scanning dependencies of target flashlight_lib_audio_feature Scanning dependencies of target flashlight_lib_sequence_criterion Scanning dependencies of target flashlight_lib_text_decoder Scanning dependencies of target flashlight_lib_text_dictionary [ 88%] Building CXX object CMakeFiles/flashlight_lib_text_decoder.dir/bindings/python/flashlight/lib/text/_decoder.cpp.o [ 90%] Building CXX object CMakeFiles/flashlight_lib_audio_feature.dir/bindings/python/flashlight/lib/audio/_feature.cpp.o [ 91%] Building CXX object CMakeFiles/flashlight_lib_sequence_criterion.dir/bindings/python/flashlight/lib/sequence/_criterion.cpp.o [ 93%] Building CXX object CMakeFiles/flashlight_lib_text_dictionary.dir/bindings/python/flashlight/lib/text/_dictionary.cpp.o [ 95%] Linking CXX shared module ../lib.linux-x86_64-3.6/flashlight/lib/text/flashlight_lib_text_dictionary.cpython-36m-x86_64-linux-gnu.so [ 96%] Linking CXX shared module ../lib.linux-x86_64-3.6/flashlight/lib/sequence/flashlight_lib_sequence_criterion.cpython-36m-x86_64-linux-gnu.so [ 96%] Built target flashlight_lib_text_dictionary [ 98%] Linking CXX shared module ../lib.linux-x86_64-3.6/flashlight/lib/audio/flashlight_lib_audio_feature.cpython-36m-x86_64-linux-gnu.so [ 98%] Built target flashlight_lib_sequence_criterion [100%] Linking CXX shared module ../lib.linux-x86_64-3.6/flashlight/lib/text/flashlight_lib_text_decoder.cpython-36m-x86_64-linux-gnu.so [100%] Built target flashlight_lib_audio_feature [100%] Built target flashlight_lib_text_decoder -- -rdynamic supported. -- CUDA found (library: /usr/local/cuda/lib64/libcudart_static.a;-lpthread;dl;/usr/lib/x86_64-linux-gnu/librt.so include: /usr/local/cuda/include) -- CUDA architecture flags: -gencodearch=compute_30,code=sm_30-gencodearch=compute_35,code=sm_35-gencodearch=compute_50,code=sm_50-gencodearch=compute_52,code=sm_52-gencodearch=compute_60,code=sm_60-gencodearch=compute_61,code=sm_61-gencodearch=compute_70,code=sm_70-gencodearch=compute_75,code=sm_75-gencodearch=compute_75,code=compute_75 -- Will build flashlight libraries. -- MKL_THREADING = OMP -- Checking for [mkl_intel_lp64 - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl] -- Library mkl_intel_lp64: /opt/intel/mkl/lib/intel64/libmkl_intel_lp64.so -- Library mkl_gnu_thread: /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.so -- Library mkl_core: /opt/intel/mkl/lib/intel64/libmkl_core.so -- Library gomp: -fopenmp -- Library pthread: /usr/lib/x86_64-linux-gnu/libpthread.so -- Library m: /usr/lib/x86_64-linux-gnu/libm.so -- Library dl: /usr/lib/x86_64-linux-gnu/libdl.so -- MKL library found -- CBLAS found (include: /opt/intel/mkl/include, library: /opt/intel/mkl/lib/intel64/libmkl_intel_lp64.so;/opt/intel/mkl/lib/intel64/libmkl_gnu_thread.so;/opt/intel/mkl/lib/intel64/libmkl_core.so;-fopenmp;/usr/lib/x86_64-linux-gnu/libpthread.so;/usr/lib/x86_64-linux-gnu/libm.so;/usr/lib/x86_64-linux-gnu/libdl.so) -- Could NOT find FFTW3 (missing: FFTW3_DIR) -- FindFFTW using pkgconfig: FOUND=1 LIBRARIES=fftw3 LIBRARY_DIRS= LIBDIR=/usr/lib/x86_64-linux-gnu LINK_LIBRARIES= -- FindFTTW using pkgconfig: INCLUDE_DIRS= INCLUDEDIR=/usr/include -- FFTW found -- Found OpenMP_C: -fopenmp -- Found OpenMP_CXX: -fopenmp -- Found OpenMP: TRUE -- Looking for KenLM -- Using kenlm library found in /root/kenlm/build/lib/libkenlm.a -- Using kenlm utils library found in /root/kenlm/build/lib/libkenlm_util.a -- kenlm model.hh found in /root/kenlm/lm -- Found kenlm (include: /root, library: /root/kenlm/build/lib/libkenlm.a;/root/kenlm/build/lib/libkenlm_util.a;/usr/lib/x86_64-linux-gnu/liblzma.so;/usr/lib/x86_64-linux-gnu/libbz2.so;/usr/lib/x86_64-linux-gnu/libz.so) -- Could NOT find cub (missing: cub_INCLUDE_DIRS) -- Could not find cub - will download from source -- Configuring done -- Generating done -- Build files have been written to: /root/flashlight/bindings/python/build/temp.linux-x86_64-3.6 [ 1%] Performing update step for 'pybind11' [ 3%] Performing update step for 'CUB' [ 6%] No configure step for 'CUB' [ 6%] No configure step for 'pybind11' [ 8%] No build step for 'pybind11' [ 9%] No build step for 'CUB' [ 11%] No install step for 'pybind11' [ 13%] No install step for 'CUB' [ 14%] Completed 'pybind11' [ 16%] Completed 'CUB' [ 21%] Built target pybind11 [ 26%] Built target CUB [ 86%] Built target fl-libraries [ 93%] Built target flashlight_lib_text_decoder [ 93%] Built target flashlight_lib_text_dictionary [ 96%] Built target flashlight_lib_audio_feature [100%] Built target flashlight_lib_sequence_criterion -- -rdynamic supported. -- CUDA found (library: /usr/local/cuda/lib64/libcudart_static.a;-lpthread;dl;/usr/lib/x86_64-linux-gnu/librt.so include: /usr/local/cuda/include) -- CUDA architecture flags: -gencodearch=compute_30,code=sm_30-gencodearch=compute_35,code=sm_35-gencodearch=compute_50,code=sm_50-gencodearch=compute_52,code=sm_52-gencodearch=compute_60,code=sm_60-gencodearch=compute_61,code=sm_61-gencodearch=compute_70,code=sm_70-gencodearch=compute_75,code=sm_75-gencodearch=compute_75,code=compute_75 -- Will build flashlight libraries. -- MKL_THREADING = OMP -- Checking for [mkl_intel_lp64 - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl] -- Library mkl_intel_lp64: /opt/intel/mkl/lib/intel64/libmkl_intel_lp64.so -- Library mkl_gnu_thread: /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.so -- Library mkl_core: /opt/intel/mkl/lib/intel64/libmkl_core.so -- Library gomp: -fopenmp -- Library pthread: /usr/lib/x86_64-linux-gnu/libpthread.so -- Library m: /usr/lib/x86_64-linux-gnu/libm.so -- Library dl: /usr/lib/x86_64-linux-gnu/libdl.so -- MKL library found -- CBLAS found (include: /opt/intel/mkl/include, library: /opt/intel/mkl/lib/intel64/libmkl_intel_lp64.so;/opt/intel/mkl/lib/intel64/libmkl_gnu_thread.so;/opt/intel/mkl/lib/intel64/libmkl_core.so;-fopenmp;/usr/lib/x86_64-linux-gnu/libpthread.so;/usr/lib/x86_64-linux-gnu/libm.so;/usr/lib/x86_64-linux-gnu/libdl.so) -- Could NOT find FFTW3 (missing: FFTW3_DIR) -- FindFFTW using pkgconfig: FOUND=1 LIBRARIES=fftw3 LIBRARY_DIRS= LIBDIR=/usr/lib/x86_64-linux-gnu LINK_LIBRARIES= -- FindFTTW using pkgconfig: INCLUDE_DIRS= INCLUDEDIR=/usr/include -- FFTW found -- Looking for KenLM -- Using kenlm library found in /root/kenlm/build/lib/libkenlm.a -- Using kenlm utils library found in /root/kenlm/build/lib/libkenlm_util.a -- kenlm model.hh found in /root/kenlm/lm -- Found kenlm (include: /root, library: /root/kenlm/build/lib/libkenlm.a;/root/kenlm/build/lib/libkenlm_util.a;/usr/lib/x86_64-linux-gnu/liblzma.so;/usr/lib/x86_64-linux-gnu/libbz2.so;/usr/lib/x86_64-linux-gnu/libz.so) -- Could NOT find cub (missing: cub_INCLUDE_DIRS) -- Could not find cub - will download from source -- Configuring done -- Generating done -- Build files have been written to: /root/flashlight/bindings/python/build/temp.linux-x86_64-3.6 [ 1%] Performing update step for 'CUB' [ 3%] Performing update step for 'pybind11' [ 4%] No configure step for 'pybind11' [ 6%] No configure step for 'CUB' [ 8%] No build step for 'CUB' [ 9%] No build step for 'pybind11' [ 11%] No install step for 'CUB' [ 13%] No install step for 'pybind11' [ 14%] Completed 'CUB' [ 16%] Completed 'pybind11' [ 21%] Built target CUB [ 26%] Built target pybind11 [ 86%] Built target fl-libraries [ 90%] Built target flashlight_lib_text_decoder [ 93%] Built target flashlight_lib_sequence_criterion [ 96%] Built target flashlight_lib_audio_feature [100%] Built target flashlight_lib_text_dictionary -- -rdynamic supported. -- CUDA found (library: /usr/local/cuda/lib64/libcudart_static.a;-lpthread;dl;/usr/lib/x86_64-linux-gnu/librt.so include: /usr/local/cuda/include) -- CUDA architecture flags: -gencodearch=compute_30,code=sm_30-gencodearch=compute_35,code=sm_35-gencodearch=compute_50,code=sm_50-gencodearch=compute_52,code=sm_52-gencodearch=compute_60,code=sm_60-gencodearch=compute_61,code=sm_61-gencodearch=compute_70,code=sm_70-gencodearch=compute_75,code=sm_75-gencodearch=compute_75,code=compute_75 -- Will build flashlight libraries. -- MKL_THREADING = OMP -- Checking for [mkl_intel_lp64 - mkl_gnu_thread - mkl_core - gomp - pthread - m - dl] -- Library mkl_intel_lp64: /opt/intel/mkl/lib/intel64/libmkl_intel_lp64.so -- Library mkl_gnu_thread: /opt/intel/mkl/lib/intel64/libmkl_gnu_thread.so -- Library mkl_core: /opt/intel/mkl/lib/intel64/libmkl_core.so -- Library gomp: -fopenmp -- Library pthread: /usr/lib/x86_64-linux-gnu/libpthread.so -- Library m: /usr/lib/x86_64-linux-gnu/libm.so -- Library dl: /usr/lib/x86_64-linux-gnu/libdl.so -- MKL library found -- CBLAS found (include: /opt/intel/mkl/include, library: /opt/intel/mkl/lib/intel64/libmkl_intel_lp64.so;/opt/intel/mkl/lib/intel64/libmkl_gnu_thread.so;/opt/intel/mkl/lib/intel64/libmkl_core.so;-fopenmp;/usr/lib/x86_64-linux-gnu/libpthread.so;/usr/lib/x86_64-linux-gnu/libm.so;/usr/lib/x86_64-linux-gnu/libdl.so) -- Could NOT find FFTW3 (missing: FFTW3_DIR) -- FindFFTW using pkgconfig: FOUND=1 LIBRARIES=fftw3 LIBRARY_DIRS= LIBDIR=/usr/lib/x86_64-linux-gnu LINK_LIBRARIES= -- FindFTTW using pkgconfig: INCLUDE_DIRS= INCLUDEDIR=/usr/include -- FFTW found -- Looking for KenLM -- Using kenlm library found in /root/kenlm/build/lib/libkenlm.a -- Using kenlm utils library found in /root/kenlm/build/lib/libkenlm_util.a -- kenlm model.hh found in /root/kenlm/lm -- Found kenlm (include: /root, library: /root/kenlm/build/lib/libkenlm.a;/root/kenlm/build/lib/libkenlm_util.a;/usr/lib/x86_64-linux-gnu/liblzma.so;/usr/lib/x86_64-linux-gnu/libbz2.so;/usr/lib/x86_64-linux-gnu/libz.so) -- Could NOT find cub (missing: cub_INCLUDE_DIRS) -- Could not find cub - will download from source -- Configuring done -- Generating done -- Build files have been written to: /root/flashlight/bindings/python/build/temp.linux-x86_64-3.6 [ 3%] Performing update step for 'pybind11' [ 3%] Performing update step for 'CUB' [ 4%] No configure step for 'CUB' [ 6%] No configure step for 'pybind11' [ 8%] No build step for 'CUB' [ 9%] No build step for 'pybind11' [ 11%] No install step for 'CUB' [ 13%] No install step for 'pybind11' [ 14%] Completed 'CUB' [ 16%] Completed 'pybind11' [ 21%] Built target CUB [ 26%] Built target pybind11 [ 86%] Built target fl-libraries [ 96%] Built target flashlight_lib_text_dictionary [ 96%] Built target flashlight_lib_audio_feature [ 96%] Built target flashlight_lib_text_decoder [100%] Built target flashlight_lib_sequence_criterion creating build/bdist.linux-x86_64 creating build/bdist.linux-x86_64/egg copying build/lib.linux-x86_64-3.6/libfl-libraries.so -> build/bdist.linux-x86_64/egg creating build/bdist.linux-x86_64/egg/flashlight creating build/bdist.linux-x86_64/egg/flashlight/lib copying build/lib.linux-x86_64-3.6/flashlight/lib/__init__.py -> build/bdist.linux-x86_64/egg/flashlight/lib creating build/bdist.linux-x86_64/egg/flashlight/lib/text copying build/lib.linux-x86_64-3.6/flashlight/lib/text/flashlight_lib_text_decoder.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/flashlight/lib/text copying build/lib.linux-x86_64-3.6/flashlight/lib/text/dictionary.py -> build/bdist.linux-x86_64/egg/flashlight/lib/text copying build/lib.linux-x86_64-3.6/flashlight/lib/text/decoder.py -> build/bdist.linux-x86_64/egg/flashlight/lib/text copying build/lib.linux-x86_64-3.6/flashlight/lib/text/flashlight_lib_text_dictionary.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/flashlight/lib/text creating build/bdist.linux-x86_64/egg/flashlight/lib/audio copying build/lib.linux-x86_64-3.6/flashlight/lib/audio/flashlight_lib_audio_feature.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/flashlight/lib/audio copying build/lib.linux-x86_64-3.6/flashlight/lib/audio/feature.py -> build/bdist.linux-x86_64/egg/flashlight/lib/audio creating build/bdist.linux-x86_64/egg/flashlight/lib/sequence copying build/lib.linux-x86_64-3.6/flashlight/lib/sequence/criterion.py -> build/bdist.linux-x86_64/egg/flashlight/lib/sequence copying build/lib.linux-x86_64-3.6/flashlight/lib/sequence/flashlight_lib_sequence_criterion.cpython-36m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/flashlight/lib/sequence copying build/lib.linux-x86_64-3.6/flashlight/lib/sequence/criterion_torch.py -> build/bdist.linux-x86_64/egg/flashlight/lib/sequence byte-compiling build/bdist.linux-x86_64/egg/flashlight/lib/__init__.py to __init__.cpython-36.pyc byte-compiling build/bdist.linux-x86_64/egg/flashlight/lib/text/dictionary.py to dictionary.cpython-36.pyc byte-compiling build/bdist.linux-x86_64/egg/flashlight/lib/text/decoder.py to decoder.cpython-36.pyc byte-compiling build/bdist.linux-x86_64/egg/flashlight/lib/audio/feature.py to feature.cpython-36.pyc byte-compiling build/bdist.linux-x86_64/egg/flashlight/lib/sequence/criterion.py to criterion.cpython-36.pyc byte-compiling build/bdist.linux-x86_64/egg/flashlight/lib/sequence/criterion_torch.py to criterion_torch.cpython-36.pyc creating build/bdist.linux-x86_64/egg/EGG-INFO copying flashlight.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO copying flashlight.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO copying flashlight.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO copying flashlight.egg-info/not-zip-safe -> build/bdist.linux-x86_64/egg/EGG-INFO copying flashlight.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt creating dist creating 'dist/flashlight-1.0.0-py3.6-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it removing 'build/bdist.linux-x86_64/egg' (and everything under it) Processing flashlight-1.0.0-py3.6-linux-x86_64.egg creating /usr/local/lib/python3.6/dist-packages/flashlight-1.0.0-py3.6-linux-x86_64.egg Extracting flashlight-1.0.0-py3.6-linux-x86_64.egg to /usr/local/lib/python3.6/dist-packages Removing flashlight 1.0.0 from easy-install.pth file Adding flashlight 1.0.0 to easy-install.pth file Installed /usr/local/lib/python3.6/dist-packages/flashlight-1.0.0-py3.6-linux-x86_64.egg Processing dependencies for flashlight==1.0.0 Finished processing dependencies for flashlight==1.0.0 ``` "
608137,675820,https://api.github.com/repos/LiHRaM/taint/issues/10,bug,2021-05-11T07:53:41Z,COLLABORATOR,https://api.github.com/repos/LiHRaM/taint,Binary Operands not working as expected The following program does not throw an error which would be the expected behavior: ``` // Test with with the assert instruction being used fn main() { let a = input(); let b = a + 3; output(b) //~ERROR function `output` received tainted input [T0001] } fn input() -> i32 { 4 } fn output(_: i32) { () } ```
646069,718108,https://api.github.com/repos/KrishnaswamyLab/phateR/issues/56,bug,2021-03-08T16:14:33Z,NONE,https://api.github.com/repos/KrishnaswamyLab/phateR,"ModuleNotFoundError: No module named 'pyparsing' **Describe the bug** Hello, I am trying to use Phate on my univeristy's HPC and have been unable to run phate to completion on any matrix due to an error with the associated pyparsing module. To address this I have tried to ```pip install --user pyparsing``` however I am informed that the requirement is already met: ``` [user@node ~]$ pip install --user pyparsing Requirement already satisfied: pyparsing in /sw/arcts/centos7/python3.8-anaconda/2020.07/lib/python3.8/site-packages (2.4.7) ``` **To Reproduce** phateR::check_pyphate_version() is sufficient to trigger the error - output can be seen below **Expected behavior** Phate to run to completion and return its output. **Actual behavior** following ``` counts_phate <- phate(counts_matrix)``` the following error returns: ``` Error in py_module_import(module, convert = convert) : ModuleNotFoundError: No module named 'pyparsing' Error in py_module_import(module, convert = convert) : ModuleNotFoundError: No module named 'pyparsing' Error: $ operator is invalid for atomic vectors ``` **System information:** Output of `phate.__version__`: ``` [usr@node ~]$ python -c 'import phate; print(phate.__version__)' 1.0.7 [usr@node ~]$ ``` Output of `pd.show_versions()`: <details> ``` INSTALLED VERSIONS ------------------ commit : f2c8480af2f25efdbd803218b9d87980f416563e python : 3.8.3.final.0 python-bits : 64 OS : Linux OS-release : 3.10.0-1160.6.1.el7.x86_64 Version : #1 SMP Tue Nov 17 13:59:11 UTC 2020 machine : x86_64 processor : x86_64 byteorder : little LC_ALL : None LANG : en_US.UTF-8 LOCALE : en_US.UTF-8 pandas : 1.2.3 numpy : 1.20.1 pytz : 2021.1 dateutil : 2.8.1 pip : 20.1.1 setuptools : 49.2.0.post20200714 Cython : 0.29.21 pytest : 5.4.3 hypothesis : None sphinx : 3.1.2 blosc : None feather : None xlsxwriter : 1.2.9 lxml.etree : 4.5.2 html5lib : 1.1 pymysql : None psycopg2 : None jinja2 : 2.11.2 IPython : 7.16.1 pandas_datareader: None bs4 : 4.9.1 bottleneck : 1.3.2 fsspec : 0.7.4 fastparquet : None gcsfs : None matplotlib : 3.3.4 numexpr : 2.7.1 odfpy : None openpyxl : 3.0.4 pandas_gbq : None pyarrow : None pyxlsb : None s3fs : None scipy : 1.6.1 sqlalchemy : 1.3.18 tables : 3.6.1 tabulate : None xarray : None xlrd : 1.2.0 xlwt : 1.3.0 numba : 0.50.1 ``` </details> Output of `sessionInfo()`: <details> ``` R version 4.0.3 (2020-10-10) -- ""Bunny-Wunnies Freak Out"" Copyright (C) 2020 The R Foundation for Statistical Computing Platform: x86_64-pc-linux-gnu (64-bit) R is free software and comes with ABSOLUTELY NO WARRANTY. You are welcome to redistribute it under certain conditions. Type 'license()' or 'licence()' for distribution details. Natural language support but running in an English locale R is a collaborative project with many contributors. Type 'contributors()' for more information and 'citation()' on how to cite R or R packages in publications. Type 'demo()' for some demos, 'help()' for on-line help, or 'help.start()' for an HTML browser interface to help. Type 'q()' to quit R. > library(phateR); sessionInfo() Loading required package: Matrix R version 4.0.3 (2020-10-10) Platform: x86_64-pc-linux-gnu (64-bit) Running under: CentOS Linux 7 (Core) Matrix products: default BLAS: /sw/arcts/centos7/stacks/gcc/8.2.0/R/4.0.3/lib64/R/lib/libRblas.so LAPACK: /sw/arcts/centos7/stacks/gcc/8.2.0/R/4.0.3/lib64/R/lib/libRlapack.so locale: [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 [7] LC_PAPER=en_US.UTF-8 LC_NAME=C [9] LC_ADDRESS=C LC_TELEPHONE=C [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C attached base packages: [1] stats graphics grDevices utils datasets methods base other attached packages: [1] phateR_1.0.7 Matrix_1.2-18 loaded via a namespace (and not attached): [1] Rcpp_1.0.6 magrittr_2.0.1 tidyselect_1.1.0 munsell_0.5.0 [5] colorspace_2.0-0 lattice_0.20-41 R6_2.5.0 rlang_0.4.10 [9] fastmap_1.1.0 fansi_0.4.2 dplyr_1.0.4 grid_4.0.3 [13] gtable_0.3.0 utf8_1.1.4 DBI_1.1.1 ellipsis_0.3.1 [17] assertthat_0.2.1 tibble_3.0.6 lifecycle_1.0.0 crayon_1.4.1 [21] purrr_0.3.4 ggplot2_3.3.3 vctrs_0.3.6 memoise_2.0.0 [25] glue_1.4.2 cachem_1.0.4 compiler_4.0.3 pillar_1.5.0 [29] generics_0.1.0 scales_1.1.1 jsonlite_1.7.2 reticulate_1.18 [33] pkgconfig_2.0.3 ``` </details> Output of `reticulate::py_discover_config(required_module = ""phate"")`: <details> ``` > reticulate::py_discover_config(required_module = ""phate"") python: /home/usr/miniconda3/envs/r-reticulate/bin/python libpython: /home/usr/miniconda3/envs/r-reticulate/lib/libpython3.8.so pythonhome: /home/usr/miniconda3/envs/r-reticulate:/home/usr/miniconda3/envs/r-reticulate version: 3.8.6 | packaged by conda-forge | (default, Jan 25 2021, 23:21:18) [GCC 9.3.0] numpy: /home/usr/.local/lib/python3.8/site-packages/numpy numpy_version: 1.20.1 phate: /home/usr/.local/lib/python3.8/site-packages/phate python versions found: /home/usr/miniconda3/envs/r-reticulate/bin/python /sw/arcts/centos7/python3.8-anaconda/2020.07/bin/python3 /usr/bin/python3 /usr/bin/python /home/usr/miniconda3/bin/python ``` </details> Output of `phateR::check_pyphate_version()`: <details> ``` Error loading Python module phate ModuleNotFoundError: No module named 'pyparsing' Detailed traceback: File ""/home/usr/R/x86_64-pc-linux-gnu-library/4.0/reticulate/python/rpytools/loader.py"", line 19, in _import_hook module = _import( File ""/home/usr/.local/lib/python3.8/site-packages/phate/__init__.py"", line 3, in <module> from .phate import PHATE File ""/home/usr/R/x86_64-pc-linux-gnu-library/4.0/reticulate/python/rpytools/loader.py"", line 19, in _import_hook module = _import( File ""/home/usr/.local/lib/python3.8/site-packages/phate/phate.py"", line 17, in <module> import matplotlib.pyplot as plt File ""/home/usr/R/x86_64-pc-linux-gnu-library/4.0/reticulate/python/rpytools/loader.py"", line 19, in _import_hook module = _import( File ""/home/usr/.local/lib/python3.8/site-packages/matplotlib/__init__.py"", line 107, in <module> from . import cbook, rcsetup File ""/home/usr/R/x86_64-pc-linux-gnu-library/4.0/reticulate/python/rpytools/loader.py"", line 19, in _import_hook module = _import( File ""/home/usr/.local/lib/python3.8/site-packages/matplotlib/rcsetup.py"", line 28, in <module> from matplotlib.fontconfig_pattern import parse_fontconfig_pattern File ""/home/usr/R/x86_64-pc-linux-gnu-library/4.0/reticulate/python/rpytools/loader.py"", line 19, in _import_hook module = _import( File ""/home/usr/.local/lib/python3.8/site-packages/matplotlib/fontconfig_pattern.py"", line 15, in <module> from pyparsing import (Literal, ZeroOrMore, Optional, Regex, StringEnd, File ""/home/usr/R/x86_64-pc-linux-gnu-library/4.0/reticulate/python/rpytools/loader.py"", line 19, in _import_hook module = _import( Consider removing the 'r-reticulate' environment by running: reticulate::conda_remove('r-reticulate') Error: Error loading Python module phate Execution halted ``` </details> Output of `reticulate::py_discover_config(required_module = ""phate"")`: <details> ``` > reticulate::py_discover_config(required_module = ""phate"") python: /home/usr/miniconda3/envs/r-reticulate/bin/python libpython: /home/usr/miniconda3/envs/r-reticulate/lib/libpython3.8.so pythonhome: /home/usr/miniconda3/envs/r-reticulate:/home/usr/miniconda3/envs/r-reticulate version: 3.8.6 | packaged by conda-forge | (default, Jan 25 2021, 23:21:18) [GCC 9.3.0] numpy: /home/usr/.local/lib/python3.8/site-packages/numpy numpy_version: 1.20.1 phate: /home/usr/.local/lib/python3.8/site-packages/phate python versions found: /home/usr/miniconda3/envs/r-reticulate/bin/python /sw/arcts/centos7/python3.8-anaconda/2020.07/bin/python3 /usr/bin/python3 /usr/bin/python /home/usr/miniconda3/bin/python ``` </details> Output of `reticulate::py_discover_config(required_module = ""pyparsing"")`: <details> ``` > reticulate::py_discover_config(required_module = ""pyparsing"") python: /sw/arcts/centos7/python3.8-anaconda/2020.07/bin/python3 libpython: /sw/arcts/centos7/python3.8-anaconda/2020.07/lib/libpython3.8.so pythonhome: /sw/arcts/centos7/python3.8-anaconda/2020.07:/sw/arcts/centos7/python3.8-anaconda/2020.07 version: 3.8.3 (default, Jul 2 2020, 16:21:59) [GCC 7.3.0] numpy: /home/rebernrj/.local/lib/python3.8/site-packages/numpy numpy_version: 1.20.1 pyparsing: /sw/arcts/centos7/python3.8-anaconda/2020.07/lib/python3.8/site-packages python versions found: /home/rebernrj/miniconda3/envs/r-reticulate/bin/python /sw/arcts/centos7/python3.8-anaconda/2020.07/bin/python3 /usr/bin/python3 /usr/bin/python /home/rebernrj/miniconda3/bin/python ``` </details> "
669426,744034,https://api.github.com/repos/zephyrproject-rtos/zephyr/issues/33009,bug,2021-03-06T11:00:23Z,COLLABORATOR,https://api.github.com/repos/zephyrproject-rtos/zephyr,"kernel: k_heap failures on small heaps **Describe the bug** `k_heap_alloc` fails when attempting to allocate memory from small heaps. The following code will fail: ``` K_HEAP_DEFINE(test_heap, 40); void main(void) { void * p = k_heap_alloc(&test_heap, 8, K_NO_WAIT); printk(""%p\n"", p); } ``` On a Cortex M4F board, this will just return NULL, but on `native_posix_64` a `K_ERR_KERNEL_PANIC` is triggered. Based on the documentation (https://docs.zephyrproject.org/latest/reference/kernel/memory/heap.html), it seems clear that there is simply not enough space at the start of the buffer to hold the bucket list for allocations. The bug is not that the k_heap cannot support tiny heaps, but that fatal errors can occur. It also not obvious from the documentation how large the heap needs to be before it will start working. 64 bytes is sufficient to allocate 8 bytes on a Cortex M4F , but not `native_posix_64`. **Expected behavior** Allocating from small heap should just return NULL, not hard fault. Ideally some form of validation would be done on the values provided to `K_HEAP_DEFINE` to ensure that it is large enough to return a valid 8 byte (smallest allocation unit) memory chunk at least once. Something similar to: ``` #define K_HEAP_DEFINE(name, bytes) \ BUILD_ASSERT((bytes) >= (MINIMUM_BUCKET_SIZE + 8), ""Heap too small to allocate memory from"");\ char __aligned(sizeof(void *)) kheap_##name[bytes]; \ Z_STRUCT_SECTION_ITERABLE(k_heap, name) = { \ .heap = { \ .init_mem = kheap_##name, \ .init_bytes = (bytes), \ }, \ } ``` **Environment (please complete the following information):** - Zephyr v2.5 "
451978,502332,https://api.github.com/repos/CaiJingLong/flutter_photo_manager/issues/484,bug,2021-04-25T21:00:04Z,NONE,https://api.github.com/repos/CaiJingLong/flutter_photo_manager,"[BUG] Cannot build for platform macos **Describe the bug** When trying to build an app that includes photo manager 1.1.4 for platform macos then the build fails. **To Reproduce** Steps to reproduce the behavior: 1. Build for platform macos. **Expected behavior** App builds. **Flutter version** 2.0.5 **Log** ```bash Command CompileSwift failed with a nonzero exit code Command CompileSwift failed with a nonzero exit code /Applications/flutter/.pub-cache/hosted/pub.dartlang.org/photo_manager-1.1.4/macos/Classes/core/PMManager.m:510:37: warning: more '%' conversions than data arguments [-Wformat] NSLog(@""Asset download fail: %@""); ~^ /Applications/flutter/.pub-cache/hosted/pub.dartlang.org/photo_manager-1.1.4/macos/Classes/core/PMManager.m:585:35: error: type-id cannot have a name resultHandler:^(UIImage *_Nullable image, ^~~~~~~ /Applications/flutter/.pub-cache/hosted/pub.dartlang.org/photo_manager-1.1.4/macos/Classes/core/PMManager.m:585:43: error: expected ')' resultHandler:^(UIImage *_Nullable image, ^ /Applications/flutter/.pub-cache/hosted/pub.dartlang.org/photo_manager-1.1.4/macos/Classes/core/PMManager.m:585:34: note: to match this '(' resultHandler:^(UIImage *_Nullable image, ^ /Applications/flutter/.pub-cache/hosted/pub.dartlang.org/photo_manager-1.1.4/macos/Classes/core/PMManager.m:585:33: warning: type specifier missing, defaults to 'int' [-Wimplicit-int] resultHandler:^(UIImage *_Nullable image, ^ /Applications/flutter/.pub-cache/hosted/pub.dartlang.org/photo_manager-1.1.4/macos/Classes/core/PMManager.m:588:7: error: non-void block should return a value return; ^ /Applications/flutter/.pub-cache/hosted/pub.dartlang.org/photo_manager-1.1.4/macos/Classes/core/PMManager.m:591:57: error: use of undeclared identifier 'info' BOOL downloadFinished = [PMManager isDownloadFinish:info]; ^ /Applications/flutter/.pub-cache/hosted/pub.dartlang.org/photo_manager-1.1.4/macos/Classes/core/PMManager.m:594:7: error: non-void block should return a value return; ^ /Applications/flutter/.pub-cache/hosted/pub.dartlang.org/photo_manager-1.1.4/macos/Classes/core/PMManager.m:597:69: error: implicit declaration of function 'UIImageJPEGRepresentation' is invalid in C99 [-Werror,-Wimplicit-function-declaration] NSString *path = [self writeFullFileWithAssetId:asset imageData:UIImageJPEGRepresentation(image, 1.0)]; ^ /Applications/flutter/.pub-cache/hosted/pub.dartlang.org/photo_manager-1.1.4/macos/Classes/core/PMManager.m:597:95: error: use of undeclared identifier 'image' NSString *path = [self writeFullFileWithAssetId:asset imageData:UIImageJPEGRepresentation(image, 1.0)]; ^ /Applications/flutter/.pub-cache/hosted/pub.dartlang.org/photo_manager-1.1.4/macos/Classes/core/PMManager.m:585:33: error: incompatible block pointer types sending 'int ((^)(void))' to parameter of type 'void (^ _Nonnull)(NSImage * _Nullable __strong, NSDictionary * _Nullable __strong)' resultHandler:^(UIImage *_Nullable image, ^~~~~~~~~~~~~~~~~~~~~~~~~~~ In module 'Photos' imported from /Applications/flutter/.pub-cache/hosted/pub.dartlang.org/photo_manager-1.1.4/macos/Classes/core/PMManager.h:7: /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX11.1.sdk/System/Library/Frameworks/Photos.framework/Headers/PHImageManager.h:160:264: note: passing argument to parameter 'resultHandler' here - (PHImageRequestID)requestImageForAsset:(PHAsset *)asset targetSize:(CGSize)targetSize contentMode:(PHImageContentMode)contentMode options:(nullable PHImageRequestOptions *)options resultHandler:(void (^)(NSImage *_Nullable result, NSDictionary *_Nullable info))resultHandler; ^ 2 warnings and 8 errors generated. ``` "
77382,86035,https://api.github.com/repos/bgauslin/moon/issues/23,enhancement,2021-03-16T01:36:14Z,OWNER,https://api.github.com/repos/bgauslin/moon,"Update prev-next states ``` .prev-next background var(--background-0) border-radius 50% transition background .3s, transform .3s &:focus [no-touch] &:hover background var(--background-1) &:active background var(--background-2) transform scale(.9) ```"
127969,142225,https://api.github.com/repos/sgratzl/lineup-lite/issues/5,enhancement,2021-02-01T10:29:36Z,NONE,https://api.github.com/repos/sgratzl/lineup-lite,Hardcoded min-width for the select column breaks the UI https://github.com/sgratzl/lineup-lite/blob/340dc558e79be22accb6e6f09a12a78888271d4b/packages/hooks/src/hooks/useRowSelectColumn.tsx#L89 Can we take the defaultColumn width and use it instead of the fixed width 20?
202557,225233,https://api.github.com/repos/APSIMInitiative/APSIMClassic/issues/1987,question,2021-02-15T06:08:36Z,NONE,https://api.github.com/repos/APSIMInitiative/APSIMClassic,"Issues associated with APSoil in APSIM V7.10 Dear Apsim Classic users Based on Dalgliesh et al (2016) I inserted sorghum soil parameters in the APSoil database for some profiles. I uploaded the modified APSOIl to the APSIM GUI through ""Option"". But the modified soil did not work. The error message is ""Can't find soil water info for sorghum"". I then examined the modified soil database and found there is a blank space after sorghum <SoilCrop name=""sorghum "">. I deleted the blank space and saved the changes and re-uploded it to the apsim GUI, but it still did not work. The problem is that once the edited soil database was uploaded to the GUI, the soil text file become to <SoilCrop name=""sorghum ""> again (not in the right format <SoilCrop name=""sorghum"">). The other problem is that I found two soil profiles (Dysart No1270, Baralaba No1265) have no info for Fbiom in the module of SoilOrganicMatter. Once again I inserted relevant info on FBiom in the APSoil database and saved the changes and uploaded it to the GUI and re-run the model, but it did not work. The problem is that even though I edited and saved the changes, once the modified soil database is uploaded to the GUI, the inserted section in the database disappeared. The error message from running the model is "" Object reference not set to an instance of an object"", ""Unable to read real value from string [Soil.SoilOrganicmatter.Fbiom]"". Just wondering how to fix these two problems. looking forward to your support!"
113755,126416,https://api.github.com/repos/VolmitSoftware/Iris/issues/348,enhancement,2021-05-03T03:10:50Z,NONE,https://api.github.com/repos/VolmitSoftware/Iris,"Potential fixes for disappearing entities I am writing in regards to the error i have seen discussed on the discord in which entities spawn using iris methods de spawn after leaving chunks. I have a few questions regarding what has been tried and and is believed to be the issue. as well as a few (hopefully temporary) suggestions to work around this issue. 1: Has entity tag ""persistent"" been considered? to my knowledge this ""disappearing"" behavior is what happens when this value is false https://hub.spigotmc.org/javadocs/spigot/org/bukkit/entity/Entity.html#setPersistent(boolean) I think(?) that for some reason entities are not receiving the persistent tag when spawned. - what led me onto the idea of persistence is how a mob spawned in via different methods (ie mythic mobs) may behave differently. due to different default values "
714028,793566,https://api.github.com/repos/lunapaint/vscode-luna-paint/issues/36,bug,2021-03-26T14:02:18Z,NONE,https://api.github.com/repos/lunapaint/vscode-luna-paint,Saving an unchanged file causes change on disk 1. Open an image in luna paint 2. Save it right after opening 3. 🐛 SCM view says the file has changed on disk What's expected is that nothing happens since the file is not dirty.
656341,729551,https://api.github.com/repos/philip-zakharov/homepage-bsa/issues/2,enhancement,2021-05-03T10:05:25Z,OWNER,https://api.github.com/repos/philip-zakharov/homepage-bsa,"Create index.html using GitHub online editor ``` <!DOCTYPE html> <html> <head> <meta charset=""UTF-8"" /> <title>Résumé</title> </head> <body> ― Hello World! &#x1F609; </body> </html> ```"
630374,700582,https://api.github.com/repos/ably/ably-js/issues/477,enhancement,2018-02-22T22:40:25Z,NONE,https://api.github.com/repos/ably/ably-js,"Convert library to ES6 modules; use webpack for creating bundles `import * as Ably from 'ably'` (I'm using TypeScript) yields the follow stats in my Webpack build: > Size: 369.66kb > Parsed size: 151.46kb > Gzipped size: 40.88kb This makes Ably the single largest dependency in our application. For comparison, the alternative I'm evaluating is roughly 35% of all those numbers. If Ably exported an ES2015 modules target using the `module` field in package.json, then modern tooling like Webpack could try to only bundle the minimum my application requires. I'm not sure how effective this might be, but those size stats could use some help. ┆Issue is synchronized with this [Jira Story](https://ably.atlassian.net/browse/SDK-296) by [Unito](https://www.unito.io/learn-more) "
456600,507491,https://api.github.com/repos/eclipse/deeplearning4j/issues/6764,enhancement,2018-11-25T22:55:00Z,NONE,https://api.github.com/repos/eclipse/deeplearning4j,"Support dpotrs, dgetrs, dormqr, dtrtrs, and eigen decomposition for asymmetric matrix They are needed to solve least square problems with the QR decomposition. ND4J supports QR decomposition already. Thanks. Aha! Link: https://skymindai.aha.io/features/ND4J-145"
430659,478754,https://api.github.com/repos/c2corg/v6_api/issues/736,bug,2019-03-15T13:52:37Z,MEMBER,https://api.github.com/repos/c2corg/v6_api,"Do not use referer to identify destination url on topic creation on discourse First of all, read this : https://blog.mozilla.org/security/2018/01/31/preventing-data-leaks-by-stripping-path-information-in-http-referrers/ Modern browsers offers an option on privacy settings that remove any url content in referer field, in order to prevent personal data leak. In consequence, this code does not contains the good URL, and then, the topic does not links to the good document : https://github.com/c2corg/v6_api/blob/3a5d5202da0ee49903b7ce495e141c41dce27892/c2corg_api/views/forum.py#L91-L94 We must change the way we get the destination url : * rebuild it from document_id, lang, and title (we have everything we need, except the disctinction between prod/demo domain. We could hard-write production domain * or send it in the body request "
44725,49785,https://api.github.com/repos/naman32/github-slideshow/issues/1,question,2021-03-17T08:31:10Z,NONE,https://api.github.com/repos/naman32/github-slideshow,"Getting Started with GitHub # :wave: Welcome to GitHub Learning Lab's ""Introduction to GitHub"" To get started, I’ll guide you through some important first steps in coding and collaborating on GitHub. :point_down: _This arrow means you can expand the window! Click on them throughout the course to find more information._ <details><summary>What is GitHub?</summary> <hr> ## What is GitHub? I'm glad you asked! Many people come to GitHub because they want to contribute to open source <sup>[:book:](https://help.github.com/articles/github-glossary/#open-source)</sup> projects, or they're invited by teammates or classmates who use it for their projects. Why do people use GitHub for these projects? **At its heart, GitHub is a collaboration platform.** From software to legal documents, you can count on GitHub to help you do your best work with the collaboration and security tools your team needs. With GitHub, you can keep projects completely private, invite the world to collaborate, and streamline every step of your project. **GitHub is also a powerful version control tool.** GitHub uses Git <sup>[:book:](https://help.github.com/articles/github-glossary/#git)</sup>, the most popular open source version control software, to track every contribution and contributor <sup>[:book:](https://help.github.com/articles/github-glossary/#contributor)</sup> to your project--so you know exactly where every line of code came from. **GitHub helps people do much more.** GitHub is used to build some of the most advanced technologies in the world. Whether you're visualizing data or building a new game, there's a whole community and set of tools on GitHub that can get you to the next step. This course starts with the basics, but we'll dig into the rest later! :tv: [Video: What is GitHub?](https://www.youtube.com/watch?v=w3jLJU7DT5E) <hr> </details><br> <details><summary>Exploring a GitHub repository</summary> <hr> ## Exploring a GitHub repository :tv: [Video: Exploring a repository](https://www.youtube.com/watch?v=R8OAwrcMlRw) ### More features The video covered some of the most commonly-used features. Here are a few other items you can find in GitHub repositories: - Project boards: Create Kanban-style task tracking board within GitHub - Wiki: Create and store relevant project documentation - Insights: View a drop-down menu that contains links to analytics tools for your repository including: - Pulse: Find information about the work that has been completed and the work that’s in-progress in this project dashboard - Graphs: Graphs provide a more granular view of the repository activity including who contributed to the repository, who forked it, and when they completed the work ### Special Files In the video you learned about a special file called the README.md. Here are a few other special files you can add to your repositories: - CONTRIBUTING.md: The `CONTRIBUTING.md` is used to describe the process for contributing to the repository. A link to the `CONTRIBUTING.md` file is shown anytime someone creates a new issue or pull request. - ISSUE_TEMPLATE.md: The `ISSUE_TEMPLATE.md` is another file you can use to pre-populate the body of an issue. For example, if you always need the same types of information for bug reports, include it in the issue template, and every new issue will be opened with your recommended starter text. <hr> </details> ### Using issues This is an issue <sup>[:book:](https://help.github.com/articles/github-glossary/#issue)</sup>: a place where you can have conversations about bugs in your code, code review, and just about anything else. Issue titles are like email subject lines. They tell your collaborators what the issue is about at a glance. For example, the title of this issue is Getting Started with GitHub. <details><summary>Using GitHub Issues</summary> ## Using GitHub issues Issues are used to discuss ideas, enhancements, tasks, and bugs. They make collaboration easier by: - Providing everyone (even future team members) with the complete story in one place - Allowing you to cross-link to other issues and pull requests <sup>[:book:](https://help.github.com/articles/github-glossary/#pull-request)</sup> - Creating a single, comprehensive record of how and why you made certain decisions - Allowing you to easily pull the right people and teams into a conversation with @-mentions :tv: [Video: Using issues](https://www.youtube.com/watch?v=Zhj46r5D0nQ) <hr> </details> <details><summary>Managing notifications</summary> <hr> ## Managing notifications :tv: [Video: Watching, notifications, stars, and explore](https://www.youtube.com/watch?v=ocQldxF7fMY) Once you've commented on an issue or pull request, you'll start receiving email notifications when there's activity in the thread. ### How to silence or unmute specific conversations 1. Go to the issue or pull request 2. Under _""Notifications""_, click the **Unsubscribe** button on the right to silence notifications or **Subscribe** to unmute them You'll see a short description that explains your current notification status. ### How to customize notifications in Settings 1. Click your profile icon 2. Click **Settings** 3. Click **Notifications** from the menu on the left and [adjust your notification preferences](https://help.github.com/articles/managing-notification-delivery-methods/) ### Repository notification options * **Watch**: You'll receive a notification when a new issue, pull request or comment is posted, and when an issue is closed or a pull request is merged * **Not watching**: You'll no longer receive notifications unless you're @-mentioned * **Ignore**: You'll no longer receive any notifications from the repository ### How to review notifications for the repositories you're watching 1. Click your profile icon 2. Click **Settings** 3. Click **Notification** from the menu on the left 4. Click on the [things you’re watching](https://github.com/watching) link 5. Select the **Watching** tab 6. Click the **Unwatch** button to disable notifications, or **Watch** to enable them <hr> </details> <hr> <h3 align=""center"">Keep reading below to find your first task</h3> "
2735,3065,https://api.github.com/repos/geoffreycrofte/juiz-social-post-sharer/issues/76,enhancement,2020-12-31T17:19:34Z,OWNER,https://api.github.com/repos/geoffreycrofte/juiz-social-post-sharer,"[Core] Add live click counter (more stable than Network API counters) This will be handle directly into post custom field. A way to makes graphs, stats, and make these field editable manually will be added later. (2.1.0)"
65254,72549,https://api.github.com/repos/fossasia/open-event-frontend/issues/6454,bug,2021-01-21T12:37:43Z,MEMBER,https://api.github.com/repos/fossasia/open-event-frontend,"Attendee Form: Simplify form, fix order, show helper text The attendee form in the wizard and public form are not ordered in the same way. Instead of alphabetical order they should be ordered according to content logic. Furthermore the implementation of address fields in Home Address, Billing Address, Shipping Address, Work Address is not complete as it is missing city, country etc. and it would be helpful if the helper text was visible in the wizard itself. Therefore please change the following: 1. Hide the following address options but keep the standard form field ""Address"". For now we will not use the address options such as: * Home Address * Billing Address * Shipping Address * Work Address 2. Change the field ""Address"" to ""Address (Street, Building, Number etc.)"" 3. Change the order of the fields to the following: - Job Title - Phone - Work Phone - Age Group - Gender - Organisation - Tax Business Info - Address (Street, Building, Number etc.) - City - State - Country - Website - Blog - LinkedIn - Twitter - GitHub - Facebook - Instagram - Email consent - Partner contact consent - Photo & video & text consent 4. Increase the width of the table and include the ""Helper Text"" below each option (in the same cell) 5. Ensure the order on the public form page of attendees is the same as in the wizard 6. Fix the display of the form type column - show ""switch"" for switches instead of ""checkbox"" ![Screenshot from 2021-01-21 12-01-19](https://user-images.githubusercontent.com/1583873/105352107-c6770e00-5bed-11eb-8157-63e89ae0228b.png) "
359831,400033,https://api.github.com/repos/GDQuest/godot-2d-tower-defense/issues/5,bug,2021-05-04T02:14:19Z,CONTRIBUTOR,https://api.github.com/repos/GDQuest/godot-2d-tower-defense,Clicking three times on a tower purchase icon causes an error Steps: 1. Click on a tower purchase icon 2. Click on the tower shop to cancel the purchase 3. Click on a tower purchase icon An error happens: `Attempt to call function 'queue_free' in base 'null instance' on a null instance.` It seems `_current_tower` is not properly unset in TowerPlacer.gd when canceling a purchase.
284263,316141,https://api.github.com/repos/owncloud/files_pdfviewer/issues/56,bug,2015-05-18T12:14:06Z,MEMBER,https://api.github.com/repos/owncloud/files_pdfviewer,"Public sharing view of a PDF: double scrollbar When sharing a PDF, the PDF.js container extends below the viewport which results in a double scrollbar. One from PDF.js and one from us: ![owncloud shared pdf double scrollbar](https://cloud.githubusercontent.com/assets/925062/7614243/d42133ca-f995-11e4-99b9-f58fba038523.png) We should make sure the PDF.js container is only as high as the viewport _minus_ the header height to remove our scrollbar. cc @tomneedham @owncloud/designers "
454585,505246,https://api.github.com/repos/google/sandboxed-api/issues/73,question,2021-01-05T10:18:40Z,NONE,https://api.github.com/repos/google/sandboxed-api,"Do the framework support long live child process? We want use the library to call third pary SDK, and the SDK process will live all the time when the task in on-going. and will will be multi instance process to do the task. can the sandbox SDK support this case ?"
280444,311896,https://api.github.com/repos/eclipse/capella-xhtml-docgen/issues/104,enhancement,2021-01-08T12:42:30Z,NONE,https://api.github.com/repos/eclipse/capella-xhtml-docgen,"HTMLdump generated Logical LF page has non-clickable [LFCD]s HTMLdump generates [LFCD] diagrams with an empty <map>, it has no hyperlinks. So, we can’t go to the involved Functions nor to the involved FunctionalExchanges. Reproduction procedure : - create a new model - in LogicalArchitecture, create a functional chain and it's [LFCD] diagram - generate the HTML dump of this model - The LFCD diagram of the HTML has no hyperlinks maped `🆔 ECLIPSE-554889 / POLARSYS-2172` `👷 faycal.abka` `📅 2018-09-06` `🔎 1.2.0`"
161258,179285,https://api.github.com/repos/rafamizes/flutter_brand_palettes/issues/8,enhancement,2021-04-07T18:52:28Z,OWNER,https://api.github.com/repos/rafamizes/flutter_brand_palettes,"Microsoft color palette Microsoft's brand color palette is a ""must-have"" for a package like this. Reference: https://usbrandcolors.com/microsoft-colors/"
560474,622878,https://api.github.com/repos/Spring-Framework-Java-Apps/simpleworklist/issues/318,bug,2020-12-30T00:28:06Z,COLLABORATOR,https://api.github.com/repos/Spring-Framework-Java-Apps/simpleworklist,Broken: http://localhost:8080/taskstate/task/1153/changeorderto/1051 http://localhost:8080/taskstate/task/1153/changeorderto/1051
338485,376272,https://api.github.com/repos/tomik23/webpack-boilerplate/issues/17,enhancement,2021-02-13T11:19:56Z,OWNER,https://api.github.com/repos/tomik23/webpack-boilerplate,Could use a more in-depth description of the code More description of the explanatory code in webpack
427064,474720,https://api.github.com/repos/LiBa001/MoonPrint-GUI/issues/1,bug,2021-01-28T00:32:45Z,OWNER,https://api.github.com/repos/LiBa001/MoonPrint-GUI,"negative values malformed in gcode When there are negative values (e.g. extruder coordinates), they might get malformed, due to the zeros that are added on the left. For example, an extruder value of `-42.0` might end up like this in the gcode: `E00-42.0`"
686145,762560,https://api.github.com/repos/NUWCDIVNPT/stig-manager/issues/240,enhancement,2021-04-07T16:18:51Z,CONTRIBUTOR,https://api.github.com/repos/NUWCDIVNPT/stig-manager,"Provide indicators for field mappings from various imports/export formats to UI labeling Could be tooltips that pop up in review UI, and/or some sort of rubric on the import/export panels that indicate mappings: ckl: Status -> Evaluation Status Finding Details -> Evaluation Comment Comment -> Recommendation Comment xccdf: rule-result -> Evaluation Status rule-result (comment tbd) - Evaluation Comment Other tools on gitHub using our api can submit PRs updating these fields: Native field 1 -> Eval Comment Native Filed 2 -> Rec. Comment STIGMan appdata: no mapping required "
438445,487445,https://api.github.com/repos/ericaltendorf/plotman/issues/451,enhancement,2021-05-14T20:57:03Z,NONE,https://api.github.com/repos/ericaltendorf/plotman,"plotman does not work I am a newbie to linux and plotman and chia. I did everything follow a youtuber but mine came out as this error. Can anyone help me please? please excuse my english. ```python-traceback $ plotman plot ...starting plot loop ...sleeping 20 s: (True, 'Starting plot job: chia plots create -k 32 -r 2 -u 128 -b 3389 -t /mnt/sieunhanh1 -d /mnt/sieunhanh2 ; logging to /home/lp1/chialogs/2021-05-14T20_46_04.267106+00_00.log') ...sleeping 20 s: (True, 'Starting plot job: chia plots create -k 32 -r 2 -u 128 -b 3389 -t /mnt/sieunhanh1 -d /mnt/sieunhanh2 ; logging to /home/lp1/chialogs/2021-05-14T20_46_24.291317+00_00.log') ^CTraceback (most recent call last): File ""/home/lp1/chia-blockchain/venv/bin/plotman"", line 8, in <module> sys.exit(main()) File ""/home/lp1/chia-blockchain/venv/lib/python3.8/site-packages/plotman/plotman.py"", line 151, in main time.sleep(cfg.scheduling.polling_time_s) KeyboardInterrupt ```"
212549,236343,https://api.github.com/repos/KadeDev/Kade-Engine/issues/585,bug,2021-05-26T00:31:12Z,NONE,https://api.github.com/repos/KadeDev/Kade-Engine,"Error while compiling the game (bug fixed, but not in the end) Well, when I was compiling the game, but I got an error: C:/Users/Usuario/haxelib/polymod/git/polymod/format/XMLMerge.hx:189: characters 10-23 : Warning : This typedef is deprecated in favor of haxe.xml.Access C:/Users/Usuario/haxelib/polymod/git/polymod/format/XMLMerge.hx:189: characters 30-43 : Warning : This typedef is deprecated in favor of haxe.xml.Access source/PlayState.hx:299: characters 3-39 : Warning : `FlxCamera.defaultCameras` is deprecated, use `FlxG.cameras.setDefaultDrawTarget` instead C:\Users\Usuario\Downloads\Kade-Engine-master\Kade-Engine-master\export\release\windows\obj>setlocal enabledelayedexpansion Error: 64bit is not automatically supported for this version of VC. Set HXCPP_MSVC_CUSTOM and manually configure the executable, library and include paths Error: Error: 64bit is not automatically supported for this version of VC. Set HXCPP_MSVC_CUSTOM and manually configure the executable, library and include paths I solved it, I had to go to PlayState.hx and in line 299, it said FlxCamera.defaultCameras, I had to change to FlxG.cameras.setDefaultDrawTarget, it was solved but it tells me this ANOTHER ERROR: source/PlayState.hx:299: characters 3-36 : Cannot rebind this method : please use 'dynamic' before method declaration C:/Users/Usuario/haxelib/polymod/git/polymod/format/XMLMerge.hx:189: characters 10-23 : Warning : This typedef is deprecated in favor of haxe.xml.Access C:/Users/Usuario/haxelib/polymod/git/polymod/format/XMLMerge.hx:189: characters 30-43 : Warning : This typedef is deprecated in favor of haxe.xml.Access I solved it, again, in line 299 it said: FlxG.cameras.setDefaultDrawTarget = [cameras]; then where it says cameras, change it to dynamic it was fixed! But it gave me another error: source/PlayState.hx:299: characters 40-47 : Expected expression I dont know this part. Can someone help me?"
575176,639174,https://api.github.com/repos/watermarkchurch/contentful-schema-diff/issues/127,bug,2020-11-03T18:30:19Z,CONTRIBUTOR,https://api.github.com/repos/watermarkchurch/contentful-schema-diff,"Bug: Content type argument doesn't work When including `--content-type MYCONTENTTYPE` in the command, the generated file still includes **every** file type from the export. Example: `contentful-schema-diff --from MY-EXPORT-1.json --to MY-EXPORT-2.json -c image --one-file --out diff-output/` I expect that the above command would generate a diff file that only contains changes to `image` content type, but instead, it includes changes from all content types in the export files."
427992,475766,https://api.github.com/repos/afinegan/DynamicDCS/issues/19,enhancement,2019-06-10T16:30:07Z,COLLABORATOR,https://api.github.com/repos/afinegan/DynamicDCS,Add more coordinate formats to JTAC messages Add more coordinate formats to JTAC messages - [ ] MGRS - [ ] Lat/Lon - [ ] Lat/Lon Decimal Source: #todo - Quaggles
261671,291019,https://api.github.com/repos/provenance-io/explorer-frontend/issues/40,enhancement,2021-03-29T18:27:41Z,COLLABORATOR,https://api.github.com/repos/provenance-io/explorer-frontend,"Nginx and server cache settings <!-- -------------------------------------------------------- Thank you for opening an issue. Before submitting this request please review this template. -------------------------------------------------------- --> ## Summary Currently we just have a super basic nginx and cache setup running for the app. We should implement more advanced features/settings to enable cache busting with each new update as well as gZipping our files to speed up load times <!-- Short, concise description of the proposed feature --> ## Problem Definition <!-- Why do we need this feature? What problems may be addressed by introducing this feature? What benefits are gained by including this feature? Are there any disadvantages of including this feature? --> ## Proposal <!-- Detailed description of requirements of implementation --> ____ #### For Admin Use - [x] Not duplicate issue - [x] Appropriate labels applied - [x] Appropriate contributors tagged - [x] Contributor assigned/self-assigned"
383945,426802,https://api.github.com/repos/tutao/tutanota/issues/2933,bug,2021-04-12T08:21:57Z,CONTRIBUTOR,https://api.github.com/repos/tutao/tutanota,"Creating search index might get stuck in a never ending loop I cannot create the search index for my mailbox. It starts indexing but then the ""Abort"" error message is shown for a second and indexing is started again from the beginning. I checked the console log and there is a NotAuthorizedError for a mailbody which cancels the indexing process. Mail indexing failed: a {name: ""NotAuthorizedError"", message: ""403: MY44oeK----2 | GET /rest/tutanota/mailbody"", stack: ""NotAuthorizedError: 403: MY44oeK----2 | GET /rest/…tanoEtPuTT/resources/app.asar/worker.js:1:103968)""} # Test notes - [ ] Make sure indexing fails in the middle (with e.g. network error). It shouldn't automatically restart. Retry button should still work. - [ ] Make sure that quick search bar is updated properly after search bar is invisible (e.g. after going to settings). - [ ] Check that search bar still works in mobile layout"
71012,78942,https://api.github.com/repos/Waiviogit/waivio/issues/2123,bug,2021-03-05T08:06:09Z,COLLABORATOR,https://api.github.com/repos/Waiviogit/waivio,[Posts / Share buttons] on mobile Facebook and Twitter share buttons are not active on posts. Everything works correctly on desktops yammer 1252 Posts / Share buttons on mobile Facebook and Twitter share buttons are not active on posts. Everything works correctly on desktops ![2021-03-05_10-05](https://user-images.githubusercontent.com/67378322/110085894-589c3580-7d9a-11eb-834b-30ebe917e5fb.png) 
513280,570415,https://api.github.com/repos/sysread/TOML-Tiny/issues/11,bug,2021-05-26T17:59:07Z,NONE,https://api.github.com/repos/sysread/TOML-Tiny,"\0 and \1 do not appear to work as booleans The documentation suggests that `\0` and `\1` will work as booleans. However, this: ``` to_toml({ test => \1}) ``` results in: ``` Can't use string (""SCALAR"") as a SCALAR ref while ""strict refs"" in use at TOML/Tiny/Writer.pm line 98. ``` Glancing at the code, it appears that the topic variable is not the expected value"
699988,777979,https://api.github.com/repos/jekyller/jasper2/issues/21,bug,2017-12-28T02:25:48Z,NONE,https://api.github.com/repos/jekyller/jasper2,Code block syntax highlighting is not working just like [demo](https://myjekyll.github.io/jasper2/a-full-and-comprehensive-style-test) show
710164,789281,https://api.github.com/repos/mindsdb/mindsdb/issues/1214,enhancement,2021-04-20T14:10:11Z,MEMBER,https://api.github.com/repos/mindsdb/mindsdb,Serve server timezone to the GUI As part of `/api/config/vars` we need to add a `timezone` variable that specifies the timezone of the server.
589202,654744,https://api.github.com/repos/wluc9875/iUFCExport-iPad/issues/40,bug,2021-02-14T11:38:22Z,NONE,https://api.github.com/repos/wluc9875/iUFCExport-iPad,"AV8B - When BCN is used, the text in the window is not displayed on the iPad The BCN button can be pressed either in the sim or the iPad. In the AV8B Ready on the Ramp Instant Mission, there result of pressing the button is that the window displays ""ON"", justified to the left. This is not shown in the app."
89869,99894,https://api.github.com/repos/PhlexPlexico/G5API/issues/72,question,2021-01-26T20:48:06Z,NONE,https://api.github.com/repos/PhlexPlexico/G5API,Question. Https connection How to use now to connect an https connection?
693883,771216,https://api.github.com/repos/shazaib491/clone_app/issues/1,bug,2020-11-01T02:52:42Z,OWNER,https://api.github.com/repos/shazaib491/clone_app,"how to fix nodejs not accept angualr10 file request. everytime gives Unexpected token - in JSON at position 0 add_product.html ******************************************** <div class=""container""> <form [formGroup]=""product"" class="" text-center shadow p-4"" enctype=""multipart/form-data""> <h1>Add Yor products</h1> <!-- ************************************************************** --> <div class=""custom-file mx-auto d-block""> <input type=""file"" (change)=""uploadFile($event)"" class=""custom-file-input "" > <label class=""custom-file-label"" for=""customFile"">Banner</label> </div> <!-- ********************************************************************** --> <br> <!-- <div class=""custom-file mx-auto d-block""> <input type=""file"" class=""custom-file-input"" id=""customFile""> <label class=""custom-file-label"" for=""customFile"">Prudct Images</label> </div> --> <br> <div class=""row""> <div class=""form-group col-md-6""> <label for="""">Product Name</label> <input type=""text"" class=""form-control rounded-0"" formControlName=""productName"" value=""""> </div> <div class=""form-group col-md-6""> <label for="""">Mrp</label> <input type=""number"" class=""form-control rounded-0"" formControlName=""mrp"" value=""""> </div> <div class=""form-group col-md-6""> <label for="""">Price</label> <input type=""number"" class=""form-control rounded-0"" formControlName=""price"" value=""""> </div> <div class=""form-group col-md-6""> <label for="""">Color</label> <input type=""text"" class=""form-control rounded-0"" formControlName=""color"" value=""""> </div> <div class=""form-group col-md-6""> <label for="""">Brand</label> <input type=""text"" class=""form-control rounded-0"" formControlName=""brand"" value=""""> </div> <div class=""form-group col-md-6""> <label for="""">Item Dimension</label> <input type=""text"" class=""form-control rounded-0"" name="""" formControlName=""itemDimension"" value=""""> </div> <div class=""form-group col-md-6""> <label for="""">Item Weight</label> <input type=""text"" class=""form-control rounded-0"" name="""" formControlName=""itemWeight"" value=""""> </div> <div class=""form-group col-md-6""> <label for="""">Voltage</label> <input type=""text"" class=""form-control rounded-0"" name="""" formControlName=""voltage"" value=""""> </div> <div class=""form-group col-md-12""> <label for="""">Capacity</label> <input type=""text"" class=""form-control rounded-0"" name="""" formControlName=""capacity"" value=""""> </div> <div class=""form-group col-md-12"" formArrayName=""features""> <div class="""" *ngFor=""let item of product.controls.features['controls']; let i=index"" [formGroupName]=""i""> <label for="""">Features</label> <input type=""text"" class=""form-control rounded-0"" name="""" formControlName=""item"" value=""""> <button type=""button"" (click)=""removeFeatures(i)"" *ngIf=""i>0"" class=""btn btn-danger border float-ri"" name=""button"">X</button> </div> <br> <button type=""button"" (click)=""addFeatures()"" class=""btn btn-white border float-left"" name=""button"">Add More (+)</button> </div> <div class=""form-group col-lg-12"" formArrayName=""label""> <div class="""" *ngFor=""let item of product.controls.label['controls']; let i=index;"" [formGroupName]=i> <label for="""">Add New Row *Optional</label> <div class="" form-group""> <input type=""text"" formControlName=""labelnm"" class=""form-control"" name="""" value="""" placeholder=""Label Name""> </div> <div class="" form-group""> <input type=""text"" formControlName=""labelValue"" class=""form-control"" name="""" value="""" placeholder=""Label Value""> </div> <button type=""button"" (click)=""removeLabels(i)"" *ngIf=""i>0"" class=""btn btn-danger border float-ri"" name=""button"">X</button> </div> <button type=""button"" (click)=""addLabels()"" class=""btn btn-white border float-left"" name=""button"">Add More (+)</button> </div> <div class=""col-md-12""> <button type=""submit"" class=""btn btn-primary btn-block w-50 mx-auto d-block rounded-0 shadow"" (click)=""AddData()"" name=""button"">Submit</button> </div> </div> </form> </div> ************************************************ add_product.ts ************************************************ import { Component, OnInit, ViewChild, ElementRef } from '@angular/core'; import { FormBuilder, FormControl, FormGroup, Validators, FormArray } from '@angular/forms'; import { ProductService } from '../services/product.service'; import { HttpEvent, HttpEventType } from '@angular/common/http'; @Component({ selector: 'app-add-product', templateUrl: './add-product.component.html', styleUrls: ['./add-product.component.css'] }) export class AddProductComponent implements OnInit { percentDone: any = 0; preview: string; // @ViewChild(""fileUpload"", {static: false}) fileUpload: ElementRef;files = []; constructor(private fb: FormBuilder, private proSend: ProductService) { } product: FormGroup; ngOnInit(): void { this.product = this.fb.group({ banner: [null], productName: [], mrp: [], price: [], color: [], brand: [], itemDimension: [], itemWeight: [], voltage: [], capacity: [], features: this.fb.array([ this.fb.group({ itemid: [1], item: ['ultra hd'], }) ]), label: this.fb.array([ this.fb.group({ labelId: [1], labelnm: [''], labelValue: [] }) ]) }) } // uploadFile(event) { // const file = (event.target as HTMLInputElement).files[0]; // this.product.patchValue({ // banner: file // }); // this.product.get('banner').updateValueAndValidity() // preview the image // const reader = new FileReader(); // reader.onload=()=> { // this.preview = reader.result as string; // } // reader.readAsDataURL(file) // } get features() { return this.product.get('features') as FormArray; } get labels(){ return this.product.get('label') as FormArray; } addFeatures() { let len = this.features.length; let newFeatures = this.fb.group({ itemid: [len + 1], item: [''], }) this.features.push(newFeatures) } removeFeatures(index: number) { this.features.removeAt(index); } addLabels(){ let len = this.labels.length; const newlabel = this.fb.group({ labelId: [len + 1], labelnm: [''], labelValue: [] }) this.labels.push(newlabel); } removeLabels(index: number){ this.labels.removeAt(index); } // ************************************************* uploadFile(event) { if(event.target.files.length>0){ const file=event.target.files[0]; this.product.get('banner').setValue(file); } } AddData() { console.log(this.product.controls) console.log(this.product.value.banner); this.proSend.addItem(this.product.value.banner).subscribe((res)=>{ console.log(res); }) } ******************************************************************** .product.service.ts } import { Injectable } from '@angular/core'; import { AdminFetchService } from './admin-fetch.service'; import { Observable, throwError } from 'rxjs'; import { HttpHeaders, HttpErrorResponse, HttpClient } from '@angular/common/http'; @Injectable({ providedIn: 'root' }) export class ProductService { constructor(private fetcher: AdminFetchService) { } addItem(banner){ let image = new FileReader(); const form_Data = new FormData(); // form_Data.append('productName', item.productName); // form_Data.append('mrp', item.mrp); // form_Data.append('price', item.price); // form_Data.append('color', item.color); // form_Data.append('brand', item.brand); // form_Data.append('itemDimension', item.itemDimension); // form_Data.append('itemWeight', item.itemWeight); // form_Data.append('voltage', item.voltage); // form_Data.append('capacity', item.capacity); form_Data.append('banner',banner,banner.name); // formData.append('label',item.label) // formData.append('Features',item.features) return this.fetcher.admin_post('addItem',form_Data); } errorMgmt(error: HttpErrorResponse) { let errorMessage = ''; if (error.error instanceof ErrorEvent) { errorMessage = error.error.message; } else { errorMessage = `Error Code ${error.status}\n Message:{error:message}` } console.log(errorMessage); return throwError(errorMessage); } } *********************************************** fetchservice.ts ******************************************** import { Injectable } from '@angular/core'; import { HttpClient,HttpHeaders } from '@angular/common/http'; import { Observable,BehaviorSubject } from 'rxjs'; import { map, tap } from ""rxjs/operators""; import {Admin} from './admin'; import { environment } from './../environments/environment'; @Injectable({ providedIn: 'root' }) export class FetchService { constructor(private http: HttpClient) { } car: []; headers = new HttpHeaders({'Content-Type':'application/json; charset=utf-8'}); posts(url: string, payload) { return this.http.post(`${environment.root_url}/${url}`,payload); } get(url): Observable<any> { return this.http.get<any>(`${environment.root_url}/${url}`); } } ***************************************************************** nodejs index.js var express = require('express'); var app = express(); var cors = require('cors'); var mongoose = require('mongoose'); const {env} = require('process'); app.use(cors()); app.use(express.json({limit: '50mb'})); app.use(express.urlencoded({limit: '50mb'})); //calling routes const route=require('./routes/routes'); const productRoutes=require('./routes/p_routes'); var passport = require(""passport"") app.use(passport.initialize()); app.use(passport.session()); const multer = require('multer'); // const multer = require('multer'); app.use('/api', route); app.use('/product',productRoutes); //calling routes // app.use(multer({storage:fileStorage}).fields([{name:'images',maxCount:1},{name:'images1',maxCount:1},{name:'images2',maxCount:1},{name:'images3',maxCount:1}])) // server const Port = process.env.PORT || 3000 app.listen(Port, () => { console.log(`Server is listening on port ${Port}`); }) // server app.use((req, res, next) => { // Error goes via `next()` method setImmediate(() => { next(new Error('Something went wrong')); }); }); app.use(function (err, req, res, next) { console.error(err.message); if (!err.statusCode) err.statusCode = 500; res.status(err.statusCode).send(err.message); }); // *********************************************************************** p_rouutes.js const mongoose = require('mongoose'), express = require('express'), router = express.Router(); const config = require('../database/mongoose'); const product = require('../database/model/product'); const multer = require('multer'); // const DIR = './uploads/'; // const storage = multer.diskStorage({ // destination: (req, file, cb) => { // console.log(file); // cb(null, DIR); // // }, // filename: (req, file, cb) => { // console.log(file); // const fileName = file.originalname.toLowerCase().split(' ').join('-'); // cb(null, fileName) // } // }); // var upload = multer({ // storage: storage, // limits: {fileSize: 1024 * 1024 * 5}, // fileFilter: (req, file, cb) => { // if (file.mimetype == ""image/png"" || file.mimetype == ""image/jpg"" || file.mimetype == ""image/jpeg"") { // cb(null, true); // } else { // cb(null, false); // return cb(new Error('Only .png, .jpg and .jpeg format allowed!')); // } // } // }); var upload = multer({ dest: './uploads/' }) router.post('/addItem', upload.single('banner'), (req, res) => { JSON.parse(req.file) console.log(req.file); const url = req.protocol + '://' + req.get('host'); // console.log(""INSIDE REQUEST"",req.body) console.log(""Files"", req.file) console.log(""**************************************************"") // console.log(req) let arrdata = []; // off karke on krbapas // for (let i in pro) { // arrdata.push(pro[i].filename); // } // let item = new product({ // productName: req.body.productName, // mrp: req.body.mrp, // price: req.body.price, // color: req.body.color, // brand: req.body.brand, // itemDimension: req.body.itemDimension, // itemWeight: req.body.itemWeight, // voltage: req.body.voltage, // capacity: req.body.capacity, // banner: url + '/uploads/' + req.file['banner'][0].filename, // productImg: arrdata, // Features:req.body.features, // label:req.body.label // }); // product.insertProduct(item, (err, product) => { // if (err) { // console.log(err); // console.log(err,'1'); // } else { // res.send('data'); // } // } // ) }) module.exports = router; "
37443,41737,https://api.github.com/repos/malliaridis/obssd/issues/5,enhancement,2021-01-17T00:15:50Z,OWNER,https://api.github.com/repos/malliaridis/obssd,Configuration of audio sync offset and stream delay ## Idea description While streaming audio might need synchronization or a stream delay needs to be set for various reasons. These kind of configurations can be included in OBS settings.
622476,691754,https://api.github.com/repos/gohugoio/hugo/issues/5906,bug,2019-04-28T04:40:25Z,NONE,https://api.github.com/repos/gohugoio/hugo,"panic: invalid taxonomy state for ... I just upgraded to the latest version of hugo: ```bash $ hugo version Hugo Static Site Generator v0.55.4-57900417 linux/amd64 BuildDate: 2019-04-25T07:38:50Z ``` And this is the error which I am getting while running the build: ```bash $ hugo panic: invalid taxonomy state for ""/tmp/site/content/predavane/_index.md"" with sections [predavane] goroutine 70 [running]: github.com/gohugoio/hugo/hugolib.(*HugoSites).createMissingPages(0xc0000b30a0, 0x0, 0x0) /root/project/hugo/hugolib/hugo_sites.go:663 +0x10f3 github.com/gohugoio/hugo/hugolib.(*HugoSites).assemble(0xc0000b30a0, 0xc0005a8200, 0xc00006fc70, 0x20) /root/project/hugo/hugolib/hugo_sites_build.go:245 +0x13a github.com/gohugoio/hugo/hugolib.(*HugoSites).Build.func2.2() /root/project/hugo/hugolib/hugo_sites_build.go:98 +0x3c runtime/trace.WithRegion(0x1243840, 0xc0005a6c90, 0xfec3da, 0x8, 0xc00006fd20) /usr/local/go/src/runtime/trace/annotation.go:137 +0xe9 github.com/gohugoio/hugo/hugolib.(*HugoSites).Build.func2(0xc0004525c0, 0x20) /root/project/hugo/hugolib/hugo_sites_build.go:100 +0x23d github.com/gohugoio/hugo/hugolib.(*HugoSites).Build.func3() /root/project/hugo/hugolib/hugo_sites_build.go:109 +0x2f runtime/trace.WithRegion(0x1243840, 0xc0005a6c90, 0xfe93f9, 0x7, 0xc0004526c8) /usr/local/go/src/runtime/trace/annotation.go:137 +0xe9 github.com/gohugoio/hugo/hugolib.(*HugoSites).Build(0xc0000b30a0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0, ...) /root/project/hugo/hugolib/hugo_sites_build.go:111 +0x7bd github.com/gohugoio/hugo/commands.(*commandeer).buildSites(...) /root/project/hugo/commands/hugo.go:763 github.com/gohugoio/hugo/commands.(*commandeer).fullBuild.func3(0x8, 0x1099548) /root/project/hugo/commands/hugo.go:313 +0x79 golang.org/x/sync/errgroup.(*Group).Go.func1(0xc0005a6c30, 0xc000549980) /go/pkg/mod/golang.org/x/sync@v0.0.0-20180314180146-1d60e4601c6f/errgroup/errgroup.go:58 +0x57 created by golang.org/x/sync/errgroup.(*Group).Go /go/pkg/mod/golang.org/x/sync@v0.0.0-20180314180146-1d60e4601c6f/errgroup/errgroup.go:55 +0x66 ``` `_index.md` contains only: ``` { ""title"": ""Predavane"" } ``` and in `config.toml` i have ``` [taxonomies] predavane = ""Predavane"" ```"
441338,490634,https://api.github.com/repos/RecordReplay/devtools/issues/2159,bug,2021-03-21T15:59:13Z,COLLABORATOR,https://api.github.com/repos/RecordReplay/devtools,The console should only scroll when the message is not visible https://replay.io/view?id=75a881e5-d810-4f6c-b1ae-b7f664104f1e
3400,3809,https://api.github.com/repos/donotturnoff/simpledoc/issues/2,bug,2020-12-03T12:35:01Z,OWNER,https://api.github.com/repos/donotturnoff/simpledoc,"Occasional ParseException when loading several stylesheets When loading several stylesheets, either internal or external, every so often a `ParseException` occurs, despite the grammar and tokens being correct. This doesn't seem to happen when loading one internal and one external stylesheet, or at least it is so rare that I couldn't produce such an error, but when there are two of the same type the error sometimes appears. This may cause pages to be rendered incorrectly, if the affected stylesheet contains some rules which have a higher priority than the same rule in other stylesheets. This does not seem to affect default styling. The `ParseException` very often indicates an unexpected token early on in the file, but also often indicates that the EOF token (`$`) is unexpected."
193384,215055,https://api.github.com/repos/wolfkidsounds/Universe-Modpack/issues/197,enhancement,2021-03-13T16:19:40Z,OWNER,https://api.github.com/repos/wolfkidsounds/Universe-Modpack,[Feature] - MobSpawns:Planets - [x] planet.Ceres #Ceres - [x] planet.Eris https://github.com/wolfkidsounds/Universe-Modpack/commit/00dc953cb0ab18607633ba7a9a2511f96fb82629 - [x] planet.Jupiter https://github.com/wolfkidsounds/Universe-Modpack/commit/6d1739d1cf0235573269a01186ce503344f6c5bd - [x] planet.Pluto #Pluto - [x] planet.Saturn https://github.com/wolfkidsounds/Universe-Modpack/commit/54e208c62e36c9571bd28c066833676de2106b8e - [x] planet.Uranus https://github.com/wolfkidsounds/Universe-Modpack/commit/63b6376aaae723f2eef1119f3047ac197e6c0cd4 - [x] planet.Mercury https://github.com/wolfkidsounds/Universe-Modpack/commit/08c00ef6a1613124ff7fe60c9043ec36f3e93fc4
279433,310778,https://api.github.com/repos/libsdl-org/SDL/issues/3288,bug,2021-02-11T01:32:56Z,COLLABORATOR,https://api.github.com/repos/libsdl-org/SDL,"Warnings in SDL_LogEvent() # This bug report was migrated from our old Bugzilla tracker. **Reported in version:** HG 2.0 **Reported for operating system, platform:** All, All # Comments on the original bug report: On 2019-06-18 15:05:34 +0000, Sam Lantinga wrote: > ../src/events/SDL_events.c: In function 'SDL_LogEvent': > ../src/events/SDL_events.c:281:53: warning: unknown conversion type character '' in format [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: note: in definition of macro 'PRINT_FINGER_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: warning: unknown conversion type character '' in format [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: note: in definition of macro 'PRINT_FINGER_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: warning: format '%f' expects argument of type 'double', but argument 5 has type 'long long int' [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > (uint) event->tfinger.timestamp, (long long) event->tfinger.touchId, \ > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: note: in definition of macro 'PRINT_FINGER_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: warning: format '%f' expects argument of type 'double', but argument 6 has type 'long long int' [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:283:17: > (long long) event->tfinger.fingerId, event->tfinger.x, event->tfinger.y, \ > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: note: in definition of macro 'PRINT_FINGER_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: warning: too many arguments for format [-Wformat-extra-args] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: note: in definition of macro 'PRINT_FINGER_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: warning: unknown conversion type character '' in format [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: note: in definition of macro 'PRINT_FINGER_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: warning: unknown conversion type character '' in format [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: note: in definition of macro 'PRINT_FINGER_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: warning: format '%f' expects argument of type 'double', but argument 5 has type 'long long int' [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > (uint) event->tfinger.timestamp, (long long) event->tfinger.touchId, \ > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: note: in definition of macro 'PRINT_FINGER_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: warning: format '%f' expects argument of type 'double', but argument 6 has type 'long long int' [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:283:17: > (long long) event->tfinger.fingerId, event->tfinger.x, event->tfinger.y, \ > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: note: in definition of macro 'PRINT_FINGER_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: warning: too many arguments for format [-Wformat-extra-args] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: note: in definition of macro 'PRINT_FINGER_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: warning: unknown conversion type character '' in format [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: note: in definition of macro 'PRINT_FINGER_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: warning: unknown conversion type character '' in format [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: note: in definition of macro 'PRINT_FINGER_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: warning: format '%f' expects argument of type 'double', but argument 5 has type 'long long int' [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > (uint) event->tfinger.timestamp, (long long) event->tfinger.touchId, \ > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: note: in definition of macro 'PRINT_FINGER_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: warning: format '%f' expects argument of type 'double', but argument 6 has type 'long long int' [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:283:17: > (long long) event->tfinger.fingerId, event->tfinger.x, event->tfinger.y, \ > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: note: in definition of macro 'PRINT_FINGER_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: warning: too many arguments for format [-Wformat-extra-args] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:281:53: note: in definition of macro 'PRINT_FINGER_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld fingerid=%lld x=%f y=%f dx=%f dy=%f pressure=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: warning: unknown conversion type character '' in format [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: note: in definition of macro 'PRINT_DOLLAR_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: warning: unknown conversion type character '' in format [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: note: in definition of macro 'PRINT_DOLLAR_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: warning: format '%u' expects argument of type 'unsigned int', but argument 5 has type 'long long int' [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > (uint) event->dgesture.timestamp, (long long) event->dgesture.touchId, \ > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: note: in definition of macro 'PRINT_DOLLAR_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: warning: format '%f' expects argument of type 'double', but argument 6 has type 'long long int' [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:293:17: > (long long) event->dgesture.gestureId, (uint) event->dgesture.numFingers, \ > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: note: in definition of macro 'PRINT_DOLLAR_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: warning: format '%f' expects argument of type 'double', but argument 7 has type 'unsigned int' [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:293:56: > (long long) event->dgesture.gestureId, (uint) event->dgesture.numFingers, \ > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: note: in definition of macro 'PRINT_DOLLAR_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: warning: too many arguments for format [-Wformat-extra-args] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: note: in definition of macro 'PRINT_DOLLAR_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: warning: unknown conversion type character '' in format [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: note: in definition of macro 'PRINT_DOLLAR_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: warning: unknown conversion type character '' in format [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: note: in definition of macro 'PRINT_DOLLAR_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: warning: format '%u' expects argument of type 'unsigned int', but argument 5 has type 'long long int' [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > (uint) event->dgesture.timestamp, (long long) event->dgesture.touchId, \ > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: note: in definition of macro 'PRINT_DOLLAR_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: warning: format '%f' expects argument of type 'double', but argument 6 has type 'long long int' [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:293:17: > (long long) event->dgesture.gestureId, (uint) event->dgesture.numFingers, \ > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: note: in definition of macro 'PRINT_DOLLAR_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: warning: format '%f' expects argument of type 'double', but argument 7 has type 'unsigned int' [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:293:56: > (long long) event->dgesture.gestureId, (uint) event->dgesture.numFingers, \ > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: note: in definition of macro 'PRINT_DOLLAR_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: warning: too many arguments for format [-Wformat-extra-args] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:291:53: note: in definition of macro 'PRINT_DOLLAR_EVENT' > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld gestureid=%lld numfingers=%u error=%f x=%f y=%f)"", \ > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:300:79: warning: unknown conversion type character '' in format [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%ld dtheta=%f ddist=%f x=%f y=%f numfingers=%u)"", > > ../src/events/SDL_events.c:300:90: warning: format '%f' expects argument of type 'double', but argument 5 has type 'long long int' [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld dtheta=%f ddist=%f x=%f y=%f numfingers=%u)"", > ~^ > %I64d > (uint) event->mgesture.timestamp, (long long) event->mgesture.touchId, > ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:300:123: warning: format '%u' expects argument of type 'unsigned int', but argument 9 has type 'double' [-Wformat=] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld dtheta=%f ddist=%f x=%f y=%f numfingers=%u)"", > ~^ > %f > ../src/events/SDL_events.c:303:36: > event->mgesture.x, event->mgesture.y, (uint) event->mgesture.numFingers); > ~~~~~~~~~~~~~~~~~ > ../src/events/SDL_events.c:300:53: warning: too many arguments for format [-Wformat-extra-args] > SDL_snprintf(details, sizeof (details), "" (timestamp=%u touchid=%lld dtheta=%f ddist=%f x=%f y=%f numfingers=%u)"", > ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ On 2019-06-18 20:17:33 +0000, Ryan C. Gordon wrote: > > Fixing these. > > --ryan. On 2019-06-18 20:23:32 +0000, Ryan C. Gordon wrote: > > Wait, what platform is triggering these? I thought it was MingW, but they don't seem to be...? > > --ryan. On 2019-06-18 21:13:27 +0000, Sam Lantinga wrote: > Steam Link SDK on armv7 On 2019-06-18 22:42:15 +0000, Ryan C. Gordon wrote: > (In reply to Sam Lantinga from comment # 3) > > Steam Link SDK on armv7 > > Ok, checking. > > --ryan. On 2019-06-20 00:12:20 +0000, Sam Lantinga wrote: > It was the long long format specifiers that were hosing things. We have an SDL macro for print formatting 64-bit values. > > Fixed! > https://hg.libsdl.org/SDL/rev/25998acc4810 "
602138,669175,https://api.github.com/repos/graasp/graasp-app-radiation-absorption/issues/26,bug,2021-04-09T10:50:40Z,NONE,https://api.github.com/repos/graasp/graasp-app-radiation-absorption,"when a molecule is oscillating and the spectrum is toggled, reset that molecule For example, observe the behavior of the leftmost molecule below: when the spectrum is toggled to Visible Light, the expectation is that the molecule resets to its original position. It's unclear why the current code is not generating this behavior. https://user-images.githubusercontent.com/19311953/114169628-17b3b580-9932-11eb-9be3-6051155fed85.mov "
14112,15716,https://api.github.com/repos/mwaskom/seaborn/issues/2441,bug,2021-01-19T12:34:33Z,OWNER,https://api.github.com/repos/mwaskom/seaborn,"lineplot ignoring ci=None ```python sns.lineplot(x=[1, 1, 2, 2], y=[1, 2, 3, 4], ci=None) ``` This should warn and then reformat the args to have `errorbar=None`"
618061,686846,https://api.github.com/repos/comses/comses.net/issues/549,enhancement,2020-12-10T17:08:26Z,MEMBER,https://api.github.com/repos/comses/comses.net,"under ""My Models"" show all models related to the user Currently models are listed by submitter, but we should list all models related to a user (via Contributors)"
339410,377297,https://api.github.com/repos/shaswa/consecutive_runs/issues/49,bug,2021-05-04T23:27:11Z,NONE,https://api.github.com/repos/shaswa/consecutive_runs,"Image pull policy should be ""Always"" **Description:** **Remediation:** "
480150,533643,https://api.github.com/repos/near-daos/near-sputnik-dao/issues/2,bug,2021-01-20T12:43:17Z,NONE,https://api.github.com/repos/near-daos/near-sputnik-dao,Unable to finalize proposal Non-Council member users of the DAO are unable to finalize proposals.
323138,359252,https://api.github.com/repos/serverlessworkflow/sdk-typescript/issues/89,bug,2021-05-15T12:25:24Z,MEMBER,https://api.github.com/repos/serverlessworkflow/sdk-typescript,Builder doesn't support union types well **What happened**: ```typescript startdefValidator().stateName('foo'); // Property 'stateName' does not exist on type 'Builder<Startdef>'. // Property 'stateName' does not exist on type '{ build: () => Startdef; } & string'. ``` **What you expected to happen**: To work without TS complaining. **How to reproduce it**: See **What happened** **Anything else we need to know?**: Will be fixed in an upcoming PR
392027,435737,https://api.github.com/repos/BrighterCommand/Brighter/issues/1486,bug,2021-04-13T13:45:56Z,MEMBER,https://api.github.com/repos/BrighterCommand/Brighter,"Validate infrastructure does not work cross account ### Describe the bug When we validate an SNS Topic exists for a publication and subscription we use List Topics. List Topics has two issues: (A) In environments with a lot of topics this is not performant. (B) This won't work if the topic is another account. Even if you have permissions to publish to that account, the List Topics call only returns results for topics in the caller's account ### To Reproduce Create a topic in Account A. Assign permissions to Publish to that Topic to Account B. Try to List Topics from Account B Result is that topics in Account A are not visible ### Fix Using a GetTopicAttributes call will return the attributes for a topic in another account, if you have the Arn and permissions to list the attributes of the topic from the other account. In this way we can validate the existence of a topic by looking for its attributes. What happens if we don't have the Arn? We can create an Arn from its parts as the format has remained constant to AWS, which would allow us to always use an Arn. As a side-effect this would be cheaper than using List Topics to iterate through the topics. "
580049,644567,https://api.github.com/repos/IgniteUI/igniteui-angular/issues/9320,bug,2021-04-14T06:42:08Z,NONE,https://api.github.com/repos/IgniteUI/igniteui-angular,"[IgxGrid] date and time pickers not fully stretched in cell editing mode ## Description [IgxGrid] date picker is not stretched in full width in cells when it is embedded in cell. * igniteui-angular version: 11.1.7 ## Steps to reproduce 1. npm install and npm start the attached sample. 2. Double click on a Birthday cell to enter edit mode. -> Observe the width of the text box of the date picker. ## Result date picker is not stretched in the cell. there is an empty area at the right. ![image](https://user-images.githubusercontent.com/33947244/114665098-9005e680-9d37-11eb-9ce8-289a086cc2ae.png) ## Expected result date picker is stretched in 100% width. ![image](https://user-images.githubusercontent.com/33947244/114665115-96945e00-9d37-11eb-89ce-5154fe7491ee.png) ## Attachments Attach a sample if available, and screenshots, if applicable. [cas34451-app1.zip](https://github.com/IgniteUI/igniteui-angular/files/6308690/cas34451-app1.zip) "
405712,450953,https://api.github.com/repos/parallaxinc/Propeller-Tool/issues/123,enhancement,2021-02-25T16:40:33Z,NONE,https://api.github.com/repos/parallaxinc/Propeller-Tool,"Make Enable Debug Status Persistent Between Sessions On restarting Propeller Tool, the Enable Debug state is set to ON by default; this gets in the way as soon as I try to download something that uses PST. Please make this state persistent between sessions so that I don't have to turn it off every time I restart Propeller Tool (which is frequent given crashes probably caused by memory leaks). The Enable Debug state should also be part of the toolbar which is right around the corner, right? :)"
549282,610477,https://api.github.com/repos/http4s/http4s/issues/4180,bug,2021-01-11T02:23:46Z,MEMBER,https://api.github.com/repos/http4s/http4s,"jetty-client callback methods should be synchronous ```java /** * Callback method invoked when the response content has been received, parsed and there is demand. * This method may be invoked multiple times, and the {@code content} buffer * must be consumed (or copied) before returning from this method. * * @param response the response containing the response line data and the headers * @param content the content bytes received */ void onContent(Response response, ByteBuffer content); ``` But we're running them asynchronously. We can address this for Cats-Effect 3 in #4165, but we need a fix on 0.21."
477432,530596,https://api.github.com/repos/KnuckleCracker/CW4-bug-tracker/issues/742,bug,2021-02-19T08:51:23Z,NONE,https://api.github.com/repos/KnuckleCracker/CW4-bug-tracker,"recorder does not export on certain maps, probably due to map name On map 801, named "":)"" (without the quotes), the recorder does not export any video. There is also no file in MyGames/creeperworld4/recordings "
250902,279079,https://api.github.com/repos/nav-gov-hu/Online-Invoice/issues/837,question,2021-03-28T17:23:01Z,NONE,https://api.github.com/repos/nav-gov-hu/Online-Invoice,"[Q&A] Óraátállítás - INVALID_REQUEST_SIGNATURE Sziasztok! Ma hajnalban - vélhetően az óraátállítással kapcsolatban - érdekes esemény történt az éles NAV Online Számla felé. A tesztben biztos nem fogjuk tudni reprodukálni, ezért csak gondolatébresztőnek írom fel a NAVos kollégának, hátha beugrik valami, illetve az érdekelne, hogy más is tapasztalt-e ilyet. Az érdekes az, hogy nem hajnali 2kor vagy (az ugrás miatt) 3kor kezdődött, hanem pontosan 4 órakor és pontosan 5 óráig tartott. INVALID_REQUEST_SIGNATURE : Érvénytelen kérés aláírás! Mind a saját üzemeltetésű felhős környezetünkből, mind az ügyfelek által üzemeltetett rendszerekből bejött a figyelmeztetés, függetlenül attól, hogy *nix vagy Windowsos környezetről van/volt-e szó. Az UTC időkezelés miatt nem gondoltuk, hogy ilyen probléma lehet, illetve eddig egyetlen óra átállításkor sem tapasztaltuk ilyet. Igaz, hogy tavaly ősszel még nem volt tömeges bejövő számla letöltés sem az ügyfeleknél, illetve azóta aktiváltuk azt a programrészt is, amely visszakérdez, hogy a NAV oldalán is be van-e jegyezve minden számlára, hogy lekértük a státuszát és hiába kértük le, ha a NAV ezt nem jegyezte be, akkor újra lekérjük (elkerülendő azt, hogy az ügyfelek levelet kapjanak a NAVtól, de ez a szál nagyot ment anno, nem magyarázom :))."
481186,534784,https://api.github.com/repos/connext/vector/issues/351,bug,2021-02-03T06:01:06Z,NONE,https://api.github.com/repos/connext/vector,getTransfers() is not exposed in Browser Node The new getTransfers() method is not actually available via BrowserNode; there is no RPC wrapper in there for the new method.
547046,608021,https://api.github.com/repos/bexis/Module_ResourceManagement/issues/129,bug,2021-01-05T12:30:54Z,MEMBER,https://api.github.com/repos/bexis/Module_ResourceManagement,Check availability - don't work if not available Hatten wir das mit Absicht ausgeschaltet? Erst mal ganz rausnehmen solange es nicht 100% funktioniert?
104833,116494,https://api.github.com/repos/nystudio107/craft-recipe/issues/34,bug,2021-03-16T14:34:11Z,NONE,https://api.github.com/repos/nystudio107/craft-recipe,"Can't generate Nutritional Analysis information ### Describe the bug `Error fetching nutritional information from API.` (I was looking at a programmatic solution to retrieving exactly this info also, so thank you!) ### To reproduce - Update **Recipe** to `1.3.0` for access to the Edamam API - Sign up for Nutritional Analysis developer account, generate ID & Key - Add key & ID to plugin settings - Run `./craft recipe/nutrition-api/generate --section=recipes --field=recipe` (failed for me) - Navigate to entry in CP, navigate to Nutrition tab, click ""Fetch Info"" (failed for me) ### Expected behaviour Receive nutritional analysis of recipes on [https://recipes.onemohrti.me/recipes](https://recipes.onemohrti.me/recipes) ### Screenshots ![Screen Shot 2021-03-16 at 10 22 16](https://user-images.githubusercontent.com/11075805/111325919-84dd6f00-8642-11eb-9b0a-03bb224e468a.png) ![Screen Shot 2021-03-16 at 10 31 11](https://user-images.githubusercontent.com/11075805/111326202-bce4b200-8642-11eb-8f59-0711a91e094d.png) (the executable on the server is actually located at (`./craft/operations/`) ### Logs ```bash 2021-03-15 22:07:56 - error - yii\console\UnknownCommandException yii\base\InvalidRouteException: Unable to resolve the request ""recipe/nutrition-api/generate"". in /srv/users/onemohrtime/apps/recipes-prod/releases/be02343c268f0e72f71d75fa274115e0d68b6399/vendor/yiisoft/yii2/base/Module.php:537 Stack trace: #0 /srv/users/onemohrtime/apps/recipes-prod/releases/be02343c268f0e72f71d75fa274115e0d68b6399/vendor/yiisoft/yii2/console/Application.php(180): yii\base\Module->runAction('recipe/nutritio...', Array) #1 /srv/users/onemohrtime/apps/recipes-prod/releases/be02343c268f0e72f71d75fa274115e0d68b6399/vendor/craftcms/cms/src/console/Application.php(88): yii\console\Application->runAction('recipe/nutritio...', Array) #2 /srv/users/onemohrtime/apps/recipes-prod/releases/be02343c268f0e72f71d75fa274115e0d68b6399/vendor/yiisoft/yii2/console/Application.php(147): craft\console\Application->runAction('recipe/nutritio...', Array) #3 /srv/users/onemohrtime/apps/recipes-prod/releases/be02343c268f0e72f71d75fa274115e0d68b6399/vendor/yiisoft/yii2/base/Application.php(386): yii\console\Application->handleRequest(Object(craft\console\Request)) #4 /srv/users/onemohrtime/apps/recipes-prod/releases/be02343c268f0e72f71d75fa274115e0d68b6399/operations/craft(23): yii\base\Application->run() #5 {main} Next yii\console\UnknownCommandException: Unknown command ""recipe/nutrition-api/generate"". in /srv/users/onemohrtime/apps/recipes-prod/releases/be02343c268f0e72f71d75fa274115e0d68b6399/vendor/yiisoft/yii2/console/Application.php:183 Stack trace: #0 /srv/users/onemohrtime/apps/recipes-prod/releases/be02343c268f0e72f71d75fa274115e0d68b6399/vendor/craftcms/cms/src/console/Application.php(88): yii\console\Application->runAction('recipe/nutritio...', Array) #1 /srv/users/onemohrtime/apps/recipes-prod/releases/be02343c268f0e72f71d75fa274115e0d68b6399/vendor/yiisoft/yii2/console/Application.php(147): craft\console\Application->runAction('recipe/nutritio...', Array) #2 /srv/users/onemohrtime/apps/recipes-prod/releases/be02343c268f0e72f71d75fa274115e0d68b6399/vendor/yiisoft/yii2/base/Application.php(386): yii\console\Application->handleRequest(Object(craft\console\Request)) #3 /srv/users/onemohrtime/apps/recipes-prod/releases/be02343c268f0e72f71d75fa274115e0d68b6399/operations/craft(23): yii\base\Application->run() #4 {main} ``` ### Versions - Plugin version: 1.3.0 - Craft version: 3.5.15.1 "
700895,778986,https://api.github.com/repos/MicrosoftEdge/WebView2Feedback/issues/1268,question,2021-05-10T04:27:31Z,NONE,https://api.github.com/repos/MicrosoftEdge/WebView2Feedback,"Strobe like effect on the webview2 control I use this on my mainform to speed up the graphics and remove nearly all flickering. protected override CreateParams CreateParams { get { var handleParam = base.CreateParams; handleParam.ExStyle |= 0x02000000; return handleParam; } Everything is good except the webview2 control flickers continuously to a degree that is looks like a strobe, this worked fine about 4 or 5 revisions ago. What is causing this? }"
510334,567158,https://api.github.com/repos/2021sp-475-TeamSpecter/SpecterAdvent/issues/4,enhancement,2021-03-17T12:25:51Z,CONTRIBUTOR,https://api.github.com/repos/2021sp-475-TeamSpecter/SpecterAdvent,Environment - [ ] simple level with a couple pitfalls 
25198,28074,https://api.github.com/repos/katharostech/bevy_ldtk/issues/2,enhancement,2021-01-28T01:02:43Z,MEMBER,https://api.github.com/repos/katharostech/bevy_ldtk,"Use Thiserror For Creating More Specific AssetLoader Error Type We should create a more specific error type with proper error formatting for the asset loader error, very similar to how it is done [here](https://docs.rs/bevy_gltf/0.4.0/src/bevy_gltf/loader.rs.html#34)."
484598,538571,https://api.github.com/repos/softbankrobotics-research/qibullet/issues/67,question,2021-04-04T20:58:05Z,NONE,https://api.github.com/repos/softbankrobotics-research/qibullet,"Adding a video Source in the simulation environment Hi, I am new to this. How can I use a video to feed into the Nao's Camera and its music in the microphone sensor? This might be a basic question. Sorry for that. Thanks, Suti"
257986,286939,https://api.github.com/repos/ultralytics/yolov3/issues/548,bug,2019-10-11T05:30:28Z,NONE,https://api.github.com/repos/ultralytics/yolov3," labels4.append(labels) UnboundLocalError: local variable 'labels' referenced before assignment I have replaced coco dataset with own datasets, which have only one class ('person'). While training, i got the following error. ` (base) C:\Users\samjith.cp\Desktop\yolov3>python train.py --data coco.data --cfg cfg/yolov3.cfg Namespace(accumulate=2, adam=False, arc='defaultpw', batch_size=32, bucket='', cache_images=False, cfg='cfg/yolov3.cfg', data='coco.data', device='', epochs=273, evolve=False, img_size=416, img_weights=False, multi_scale=False, name='', nosave=False, notest=False, prebias=False, rect=False, resume=False, transfer=False, var=None, weights='') Using CPU WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode. Reading labels (357 found, 0 missing, 4 empty for 361 images): 100%|███████████████| 361/361 [00:00<00:00, 6489.34it/s] Model Summary: 222 layers, 6.19491e+07 parameters, 6.19491e+07 gradients Starting training for 273 epochs... Epoch gpu_mem GIoU obj cls total targets img_size Corrupt JPEG data: 2 extraneous bytes before marker 0xd9 0%| | 0/12 [00:00<?, ?it/s]Corrupt JPEG data: 2 extraneous bytes before marker 0xd9 Corrupt JPEG data: 1 extraneous bytes before marker 0xd9 Corrupt JPEG data: 1 extraneous bytes before marker 0xd9 Corrupt JPEG data: 2 extraneous bytes before marker 0xd9 Corrupt JPEG data: 1 extraneous bytes before marker 0xd9 Corrupt JPEG data: 2 extraneous bytes before marker 0xd9 Corrupt JPEG data: 1 extraneous bytes before marker 0xd9 Corrupt JPEG data: 1 extraneous bytes before marker 0xd9 Corrupt JPEG data: 1 extraneous bytes before marker 0xd9 Corrupt JPEG data: 2 extraneous bytes before marker 0xd9 Corrupt JPEG data: 2 extraneous bytes before marker 0xd9 Corrupt JPEG data: 1 extraneous bytes before marker 0xd9 Corrupt JPEG data: 1 extraneous bytes before marker 0xd9 Corrupt JPEG data: 2 extraneous bytes before marker 0xd9 Traceback (most recent call last): File ""train.py"", line 426, in <module> train() # train normally File ""train.py"", line 235, in train for i, (imgs, targets, paths, _) in pbar: # batch ------------------------------------------------------------- File ""C:\Users\samjith.cp\AppData\Local\Continuum\anaconda3\lib\site-packages\tqdm\_tqdm.py"", line 1005, in __iter__ for obj in iterable: File ""C:\Users\samjith.cp\AppData\Local\Continuum\anaconda3\lib\site-packages\torch\utils\data\dataloader.py"", line 819, in __next__ return self._process_data(data) File ""C:\Users\samjith.cp\AppData\Local\Continuum\anaconda3\lib\site-packages\torch\utils\data\dataloader.py"", line 846, in _process_data data.reraise() File ""C:\Users\samjith.cp\AppData\Local\Continuum\anaconda3\lib\site-packages\torch\_utils.py"", line 369, in reraise raise self.exc_type(msg) UnboundLocalError: Caught UnboundLocalError in DataLoader worker process 0. Original Traceback (most recent call last): File ""C:\Users\samjith.cp\AppData\Local\Continuum\anaconda3\lib\site-packages\torch\utils\data\_utils\worker.py"", line 178, in _worker_loop data = fetcher.fetch(index) File ""C:\Users\samjith.cp\AppData\Local\Continuum\anaconda3\lib\site-packages\torch\utils\data\_utils\fetch.py"", line 44, in fetch data = [self.dataset[idx] for idx in possibly_batched_index] File ""C:\Users\samjith.cp\AppData\Local\Continuum\anaconda3\lib\site-packages\torch\utils\data\_utils\fetch.py"", line 44, in <listcomp> data = [self.dataset[idx] for idx in possibly_batched_index] File ""C:\Users\samjith.cp\Desktop\yolov3\utils\datasets.py"", line 416, in __getitem__ img, labels = load_mosaic(self, index) File ""C:\Users\samjith.cp\Desktop\yolov3\utils\datasets.py"", line 590, in load_mosaic labels4.append(labels) UnboundLocalError: local variable 'labels' referenced before assignment`"
471967,524542,https://api.github.com/repos/iobroker-community-adapters/ioBroker.sourceanalytix/issues/226,enhancement,2020-10-20T12:04:09Z,NONE,https://api.github.com/repos/iobroker-community-adapters/ioBroker.sourceanalytix,"Reset DP What do I have to do to reset a measured data point? One of my measurement points is unfortunately on a completely wrong value (much too high). i have already reset the meter reading. However, it remains high. ![image](https://user-images.githubusercontent.com/8565847/96583449-02dc5a80-12dd-11eb-949f-19b35cf65b55.png) ![image](https://user-images.githubusercontent.com/8565847/96583508-1daecf00-12dd-11eb-8e6c-fd5362d8e668.png) "
465832,517709,https://api.github.com/repos/CEHAT-Clinic/dashboard/issues/494,enhancement,2021-03-26T17:21:01Z,CONTRIBUTOR,https://api.github.com/repos/CEHAT-Clinic/dashboard,Add humidity sensor status One of the sensors is returning readings but not humidity values. Have this visible on the admin pane so admin users can better understand why a sensor is down
65356,72668,https://api.github.com/repos/jpdillingham/Soulseek.NET/issues/544,enhancement,2021-05-13T15:25:13Z,OWNER,https://api.github.com/repos/jpdillingham/Soulseek.NET,"Close transfer streams prior to raising the final state change event Working on a feature of slskd that moves completed files when they are finished, I'm unable to do so because the file is still in use when the final event fires (I've long lost the associated Task, which I _could_ use, and still might). Consumers should expect the stream to have been closed prior to this event being raised."
625208,694815,https://api.github.com/repos/pedro-hs/checkbox.sh/issues/6,bug,2020-11-19T05:12:30Z,NONE,https://api.github.com/repos/pedro-hs/checkbox.sh,Invalid option for mac os Looks like the script doesn't work on Mac OS I am receiving error -> ` ./scripts/utils/checkbox.sh: line 416: read: -N: invalid option read: usage: read [-ers] [-u fd] [-t timeout] [-p prompt] [-a array] [-n nchars] [-d delim] [name ...] `
483615,537476,https://api.github.com/repos/Thom440/LumberInventoryManager/issues/38,enhancement,2021-02-08T04:56:16Z,COLLABORATOR,https://api.github.com/repos/Thom440/LumberInventoryManager,"Show a message when ""empty"" Consume is clicked Under the ConsumeUnits form, pop up a message if consume is clicked with nothing to consume. Try/Catch or If/Else"
594618,660836,https://api.github.com/repos/migueldeicaza/gui.cs/issues/944,bug,2020-10-02T17:44:15Z,COLLABORATOR,https://api.github.com/repos/migueldeicaza/gui.cs,"StatusBar - SHIFT-CTRL-A shortcut not possible `new StatusItem(Key.ShiftMask | Key.CharMask | (Key)65, ""~SHIFT-^A~ Select None"", () => ...` This does not work. Neither does `Key.ShiftMask | Key.ControlA` which is what I tried first, Am I missing something or is this just broke?"
686206,762634,https://api.github.com/repos/linkedin/cruise-control/issues/1508,question,2021-03-30T13:28:50Z,NONE,https://api.github.com/repos/linkedin/cruise-control,cc can't auto rebalance disk we can rebalance disk within each broker by setting _rebalance?rebalance_disk=true_ does cc can **auto** balance disks utilization within each broker ?
336813,374400,https://api.github.com/repos/MetaCell/NetPyNE-UI/issues/197,bug,2021-02-08T17:51:38Z,NONE,https://api.github.com/repos/MetaCell/NetPyNE-UI,Connections plot and 2DNet plot not updated after creating network **Reproduction:** * Import Tutorial 1 * Create Network * Open Connections plot and 2D Net plot * Go back to Model > Edit * Change number of cells (e.g. from 40 to 200) * Create Network * Open Connections plot and 2D Net Plot **Actual:** * Shows me plot output of old version **Expected:** * Shows me plot output of new version with different number of cells **Suggested solution:** In plotMiddleware.js we only recreate plots for action SIMULATE_NETWORK or CREATE_SIMULATE_NETWORK. We can extend this middleware by recreating only the connection plots if action CREATE_NETWORK was triggered.
581506,646193,https://api.github.com/repos/ProjectStarlight/StarlightRiver/issues/56,bug,2020-08-01T00:55:05Z,NONE,https://api.github.com/repos/ProjectStarlight/StarlightRiver,"Crashlog: Voidsmith This test was done in a new small world, expert, and single player. During testing I checked out the void smith, I opened his tabs and clicked upgrade, the tab opened for a split second then the game proceeded to crash. VS: I expected that after opening the upgrade tab for the void smith I would see the UI with the two placeholder quests; Instead I opened the upgrade tab and then proceeded to crash. [client.log](https://github.com/ProjectStarlight/StarlightRiver/files/5009438/client.log) "
241205,268277,https://api.github.com/repos/hexlet-codebattle/codebattle/issues/742,enhancement,2020-05-03T18:40:08Z,CONTRIBUTOR,https://api.github.com/repos/hexlet-codebattle/codebattle,В профиле игрока вывести последние 10 игр взять компонент CompletedGAmes из главной страницы и вывести на странице грока последние игры
541365,601709,https://api.github.com/repos/obspy/obspy/issues/2007,bug,2017-11-17T09:59:32Z,MEMBER,https://api.github.com/repos/obspy/obspy,seishub: authentication check not working The authentication check `Client.test_auth()` seems broken and always returns `True`. Probably not worth fixing given that seishub kind of is replaced by [jane](http://github.com/krischer/jane). CC @trichter 
580477,645048,https://api.github.com/repos/dotnet/interactive/issues/58,bug,2019-10-27T15:50:18Z,NONE,https://api.github.com/repos/dotnet/interactive,"Unable to use System.Data.SqlClient in Jupyter C# Kernel #### Describe the bug I'm attempting to use the System.Data.SqlClient NuGet package in a C# Jupyter Notebook. The package will be used together with the DatabaseLoader in ML.NET. I'm successful in installing the NuGet package, but when I call SqlClientFactory.Instance, I'm getting a likely re-direct error. I want to mention that this work okay in Visual Studio 2019, so it seems to be related to Jupyter and the C# Kernel. #### Did this error occur while using `dotnet try` or online? - [X] `dotnet-try` - [ ] online #### What kind of error was it? - [ ] User Interface (UI): For example the output never displayed - [ ] Service Error: For example ""The service is temporarily unavailable. We are working on it"" - [X] Other: #### Screenshots ![image](https://user-images.githubusercontent.com/30201569/67637327-d18aa380-f8af-11e9-959a-8ae28f52200f.png) #### Please complete the following: - OS - [X] Windows 10 - [ ] macOS - [ ] Linux (Please specify distro) - [ ] iOS - [ ] Android - Browser - [X] Chrome - [ ] Edge - [ ] Safari "
82158,91340,https://api.github.com/repos/Dyalog/link/issues/221,bug,2021-02-15T10:59:07Z,NONE,https://api.github.com/repos/Dyalog/link,"Error ""Can't Edit: The value of the name has changed."" with ]LINKed files **Describe the bug** While working with ]LINKed files and editing suspended code, that ""old"" error sometimes still show up. **To Reproduce** Steps to reproduce the behaviour: 1. `)clear` 2. `]link.create # c:/temp/test` 3. `)ed ⍟test` ``` :Namespace test ∇ R←f1 R←sub1 ∘∘∘ ∇ ∇ R←sub1 ∘∘∘ ∇ :EndNamespace ``` fix that and repeat these step, but use the name test1. 4. `test.f1` when it crashes in sub1, do an edit and change sub1 (inserting/removing blank lines is sufficient). Make sure execution continues and you get out of sub1. When f1 crashes, try to edit it. You should now see the error-message: ![image](https://user-images.githubusercontent.com/5645494/107937849-ccf66c80-6f84-11eb-966d-79574d6fe780.png) **Expected behaviour** This problem does not show up when editing a class with suspended code in the workspace in unlinked state. I'd expected the same behavior when ]LINK is used. **Desktop (please complete the following information):** Dyalog 18.1.40004 64-bit Unicode, BuildID bf80af4f OS Windows 10 or Windows Server 2016 (10.0.19041) 64-bit SALT 2.808, Link: 2.1.0-beta41 UCMD 2.4 .NET .NET Core 3.1.12 WS 18.1 "
559448,621749,https://api.github.com/repos/vlang/ui/issues/265,enhancement,2021-01-07T09:31:02Z,CONTRIBUTOR,https://api.github.com/repos/vlang/ui,gg.clip_rect() function and clip_region()
210372,233914,https://api.github.com/repos/UMCUGenetics/DxNextflowWES/issues/25,bug,2020-11-30T07:33:05Z,MEMBER,https://api.github.com/repos/UMCUGenetics/DxNextflowWES,"PED file published failed Kinship + not overwritten after re-run PED file is published even if Kinship analysis failed (due to i.e. mistakes in PED file). After PED file correction and restart of NF workflow, the new PED file is not published (old remains in publish folder QC/Kinship/)"
396414,440595,https://api.github.com/repos/dirkwhoffmann/vAmiga/issues/429,enhancement,2020-10-29T10:44:03Z,NONE,https://api.github.com/repos/dirkwhoffmann/vAmiga,"Future: Add support for ipf images Hi, Title says it all really add support for ipf and zipped ipf images. Ben."
23687,26386,https://api.github.com/repos/RockBottomGame/RockBottom/issues/19,question,2019-08-11T13:11:22Z,MEMBER,https://api.github.com/repos/RockBottomGame/RockBottom,"Lighting I made some adjustments to the lighting propogation and I personally think it looks a lot better, but since Ellpeck disagrees I thought I'd make an issue about it. This is the new lighting ![Capture](https://user-images.githubusercontent.com/8121164/62834202-740d9000-bc8c-11e9-99e1-6bb2e50b3b25.PNG) And this is what it looks like without my changes ![Capture2](https://user-images.githubusercontent.com/8121164/62834205-766fea00-bc8c-11e9-84a1-c7b9ddac68da.PNG) What do you think? I've also been experimenting with an option that makes skylight come down but it has issues with chunk generation since it works bottom-up."
238782,265597,https://api.github.com/repos/trustedtomato/id3-rw/issues/2,enhancement,2021-01-10T20:21:46Z,OWNER,https://api.github.com/repos/trustedtomato/id3-rw,"Add feature detection to library analyser demo It doesn't work in latest Firefox, so support shouldn't be just assumed to exist."
258550,287542,https://api.github.com/repos/Chia-Network/chia-blockchain/issues/5928,bug,2021-05-24T08:54:06Z,NONE,https://api.github.com/repos/Chia-Network/chia-blockchain,"[BUG] keyring.errors.KeyringError: Can't get password from keychain: (-25308, 'Unknown Error') Several days before, my PC can plot normally. But when I try it again yesterday, run `chia init `or `chia plots create ...`, it always shows this error: > (venv) truxs-iMac-Pro:chia-blockchain haoye.tian$ chia init > Traceback (most recent call last): > File ""/Users/haoye.tian/Downloads/chia/chia-blockchain/venv/lib/python3.9/site-packages/keyring/backends/macOS/__init__.py"", line 49, in get_password > return api.find_generic_password(self.keychain, service, username) > File ""/Users/haoye.tian/Downloads/chia/chia-blockchain/venv/lib/python3.9/site-packages/keyring/backends/macOS/api.py"", line 101, in find_generic_password > Error.raise_for_status(status) > File ""/Users/haoye.tian/Downloads/chia/chia-blockchain/venv/lib/python3.9/site-packages/keyring/backends/macOS/api.py"", line 48, in raise_for_status > raise cls(status, ""Unknown Error"") > keyring.backends.macOS.api.Error: (-25308, 'Unknown Error') > > During handling of the above exception, another exception occurred: > > Traceback (most recent call last): > File ""/Users/haoye.tian/Downloads/chia/chia-blockchain/venv/bin/chia"", line 33, in <module> > sys.exit(load_entry_point('chia-blockchain', 'console_scripts', 'chia')()) > File ""/Users/haoye.tian/Downloads/chia/chia-blockchain/chia/cmds/chia.py"", line 77, in main > cli() # pylint: disable=no-value-for-parameter > File ""/Users/haoye.tian/Downloads/chia/chia-blockchain/venv/lib/python3.9/site-packages/click/core.py"", line 829, in __call__ > return self.main(*args, **kwargs) > File ""/Users/haoye.tian/Downloads/chia/chia-blockchain/venv/lib/python3.9/site-packages/click/core.py"", line 782, in main > rv = self.invoke(ctx) > File ""/Users/haoye.tian/Downloads/chia/chia-blockchain/venv/lib/python3.9/site-packages/click/core.py"", line 1259, in invoke > return _process_result(sub_ctx.command.invoke(sub_ctx)) > File ""/Users/haoye.tian/Downloads/chia/chia-blockchain/venv/lib/python3.9/site-packages/click/core.py"", line 1259, in invoke > return _process_result(sub_ctx.command.invoke(sub_ctx)) > File ""/Users/haoye.tian/Downloads/chia/chia-blockchain/venv/lib/python3.9/site-packages/click/core.py"", line 1066, in invoke > return ctx.invoke(self.callback, **ctx.params) > File ""/Users/haoye.tian/Downloads/chia/chia-blockchain/venv/lib/python3.9/site-packages/click/core.py"", line 610, in invoke > return callback(*args, **kwargs) > File ""/Users/haoye.tian/Downloads/chia/chia-blockchain/venv/lib/python3.9/site-packages/click/decorators.py"", line 21, in new_func > return f(get_current_context(), *args, **kwargs) > File ""/Users/haoye.tian/Downloads/chia/chia-blockchain/chia/cmds/keys.py"", line 53, in add_cmd > add_private_key_seed(mnemonic) > File ""/Users/haoye.tian/Downloads/chia/chia-blockchain/chia/cmds/keys_funcs.py"", line 50, in add_private_key_seed > sk = keychain.add_private_key(mnemonic, passphrase) > File ""/Users/haoye.tian/Downloads/chia/chia-blockchain/chia/util/keychain.py"", line 180, in add_private_key > index = self._get_free_private_key_index() > File ""/Users/haoye.tian/Downloads/chia/chia-blockchain/chia/util/keychain.py"", line 167, in _get_free_private_key_index > pkent = self._get_pk_and_entropy(pk) > File ""/Users/haoye.tian/Downloads/chia/chia-blockchain/chia/util/keychain.py"", line 142, in _get_pk_and_entropy > read_str = keyring.get_password(self._get_service(), user) > File ""/Users/haoye.tian/Downloads/chia/chia-blockchain/venv/lib/python3.9/site-packages/keyring/core.py"", line 55, in get_password > return get_keyring().get_password(service_name, username) > File ""/Users/haoye.tian/Downloads/chia/chia-blockchain/venv/lib/python3.9/site-packages/keyring/backends/macOS/__init__.py"", line 55, in get_password > raise KeyringError(""Can't get password from keychain: "" ""{}"".format(e)) > keyring.errors.KeyringError: Can't get password from keychain: (-25308, 'Unknown Error') OS: MacOS 11.3.1 CPU: Intel(R) Xeon(R) W-2140B CPU @ 3.20GHz Using the latest version 1.1.6. Although I reinstall the chia, the bug still exists. I have no idea what happened. "
567971,631182,https://api.github.com/repos/thesofproject/sof/issues/3880,bug,2021-03-01T05:20:25Z,COLLABORATOR,https://api.github.com/repos/thesofproject/sof,"[BUG] Build error with GCC10 in mux.c: missing memmove, memset and memcpy **Describe the bug** After https://github.com/thesofproject/sof/pull/3848 merged, when build SOF with latest GCC10 binary, got below error on all cavs platform ``` /home/sof/work/xtensa-apl-elf/lib/gcc/xtensa-apl-elf/10.2.0/../../../../xtensa-apl-elf/bin/ld: CMakeFiles/sof.dir/src/audio/mux/mux.c.o: in function `mux_prepare': /home/sof/work/sof.git/src/audio/mux/mux.c:657: undefined reference to `memmove' /home/sof/work/xtensa-apl-elf/lib/gcc/xtensa-apl-elf/10.2.0/../../../../xtensa-apl-elf/bin/ld: CMakeFiles/sof.dir/src/audio/mux/mux.c.o: in function `mux_mix_check': /home/sof/work/sof.git/src/audio/mux/mux.c:62: undefined reference to `memmove' ``` **To Reproduce** ``` # get the latest Docker image with GCC 10 docker pull thesofproject/sof:20210228 docker tag thesofproject/sof:20210228 sof # build with docker image in sof repo folder ./scripts/docker-run.sh ./scripts/xtensa-build-all.sh apl ``` **Reproduction Rate** 10/10 **Expected behavior** Build pass without error **Impact** GCC10 docker image could not be used in CI "
562767,625412,https://api.github.com/repos/ianrbaguio/xbank-angular/issues/5,enhancement,2020-06-25T20:05:15Z,OWNER,https://api.github.com/repos/ianrbaguio/xbank-angular,Register Component - Create Register component - Style Register page - Register component form: • Client Type (Personal/Business) • Username • Password • First Name • Last Name • Email • Savings Account balance • Chequing Account balance 
81199,90264,https://api.github.com/repos/imn00133/BeerNode/issues/61,enhancement,2021-02-13T12:36:02Z,OWNER,https://api.github.com/repos/imn00133/BeerNode,Scrap app: Delete View 만들기 pk를 통해 scrap을 삭제할 수 있도록 작성
92573,102879,https://api.github.com/repos/ivan0117/github-slideshow/issues/1,enhancement,2021-05-23T08:38:01Z,NONE,https://api.github.com/repos/ivan0117/github-slideshow,"Getting Started with GitHub # :wave: Welcome to GitHub Learning Lab's ""Introduction to GitHub"" To get started, I’ll guide you through some important first steps in coding and collaborating on GitHub. :point_down: _This arrow means you can expand the window! Click on them throughout the course to find more information._ <details><summary>What is GitHub?</summary> <hr> ## What is GitHub? I'm glad you asked! Many people come to GitHub because they want to contribute to open source <sup>[:book:](https://help.github.com/articles/github-glossary/#open-source)</sup> projects, or they're invited by teammates or classmates who use it for their projects. Why do people use GitHub for these projects? **At its heart, GitHub is a collaboration platform.** From software to legal documents, you can count on GitHub to help you do your best work with the collaboration and security tools your team needs. With GitHub, you can keep projects completely private, invite the world to collaborate, and streamline every step of your project. **GitHub is also a powerful version control tool.** GitHub uses Git <sup>[:book:](https://help.github.com/articles/github-glossary/#git)</sup>, the most popular open source version control software, to track every contribution and contributor <sup>[:book:](https://help.github.com/articles/github-glossary/#contributor)</sup> to your project--so you know exactly where every line of code came from. **GitHub helps people do much more.** GitHub is used to build some of the most advanced technologies in the world. Whether you're visualizing data or building a new game, there's a whole community and set of tools on GitHub that can get you to the next step. This course starts with the basics, but we'll dig into the rest later! :tv: [Video: What is GitHub?](https://www.youtube.com/watch?v=w3jLJU7DT5E) <hr> </details><br> <details><summary>Exploring a GitHub repository</summary> <hr> ## Exploring a GitHub repository :tv: [Video: Exploring a repository](https://www.youtube.com/watch?v=R8OAwrcMlRw) ### More features The video covered some of the most commonly-used features. Here are a few other items you can find in GitHub repositories: - Project boards: Create Kanban-style task tracking board within GitHub - Wiki: Create and store relevant project documentation - Insights: View a drop-down menu that contains links to analytics tools for your repository including: - Pulse: Find information about the work that has been completed and the work that’s in-progress in this project dashboard - Graphs: Graphs provide a more granular view of the repository activity including who contributed to the repository, who forked it, and when they completed the work ### Special Files In the video you learned about a special file called the README.md. Here are a few other special files you can add to your repositories: - CONTRIBUTING.md: The `CONTRIBUTING.md` is used to describe the process for contributing to the repository. A link to the `CONTRIBUTING.md` file is shown anytime someone creates a new issue or pull request. - ISSUE_TEMPLATE.md: The `ISSUE_TEMPLATE.md` is another file you can use to pre-populate the body of an issue. For example, if you always need the same types of information for bug reports, include it in the issue template, and every new issue will be opened with your recommended starter text. <hr> </details> ### Using issues This is an issue <sup>[:book:](https://help.github.com/articles/github-glossary/#issue)</sup>: a place where you can have conversations about bugs in your code, code review, and just about anything else. Issue titles are like email subject lines. They tell your collaborators what the issue is about at a glance. For example, the title of this issue is Getting Started with GitHub. <details><summary>Using GitHub Issues</summary> ## Using GitHub issues Issues are used to discuss ideas, enhancements, tasks, and bugs. They make collaboration easier by: - Providing everyone (even future team members) with the complete story in one place - Allowing you to cross-link to other issues and pull requests <sup>[:book:](https://help.github.com/articles/github-glossary/#pull-request)</sup> - Creating a single, comprehensive record of how and why you made certain decisions - Allowing you to easily pull the right people and teams into a conversation with @-mentions :tv: [Video: Using issues](https://www.youtube.com/watch?v=Zhj46r5D0nQ) <hr> </details> <details><summary>Managing notifications</summary> <hr> ## Managing notifications :tv: [Video: Watching, notifications, stars, and explore](https://www.youtube.com/watch?v=ocQldxF7fMY) Once you've commented on an issue or pull request, you'll start receiving email notifications when there's activity in the thread. ### How to silence or unmute specific conversations 1. Go to the issue or pull request 2. Under _""Notifications""_, click the **Unsubscribe** button on the right to silence notifications or **Subscribe** to unmute them You'll see a short description that explains your current notification status. ### How to customize notifications in Settings 1. Click your profile icon 2. Click **Settings** 3. Click **Notifications** from the menu on the left and [adjust your notification preferences](https://help.github.com/articles/managing-notification-delivery-methods/) ### Repository notification options * **Watch**: You'll receive a notification when a new issue, pull request or comment is posted, and when an issue is closed or a pull request is merged * **Not watching**: You'll no longer receive notifications unless you're @-mentioned * **Ignore**: You'll no longer receive any notifications from the repository ### How to review notifications for the repositories you're watching 1. Click your profile icon 2. Click **Settings** 3. Click **Notification** from the menu on the left 4. Click on the [things you’re watching](https://github.com/watching) link 5. Select the **Watching** tab 6. Click the **Unwatch** button to disable notifications, or **Watch** to enable them <hr> </details> <hr> <h3 align=""center"">Keep reading below to find your first task</h3> "
565612,628554,https://api.github.com/repos/nats-io/nats.rs/issues/147,bug,2021-02-03T14:49:27Z,NONE,https://api.github.com/repos/nats-io/nats.rs,"The `no_echo` option does not actually appear to prevent echoes Make sure that these boxes are checked before submitting your issue -- thank you! - [x] Included below version and environment information - [x] Included a [Minimal, Complete, and Verifiable example] (https://stackoverflow.com/help/mcve) #### NATS version `async-nats = ""0.9""` #### rustc version `rustc 1.49.0 (e1884a8e3 2020-12-29)` #### OS/Container environment: `Ubuntu 20.04, x86_64` #### Steps or code to reproduce the issue: ```rust use async_nats::Options; #[tokio::main] async fn main() { let connection = Options::new() .no_echo() .connect(""nats://127.0.0.1:4222"") .await .unwrap(); let subscription = connection.subscribe(""test"").await.unwrap(); connection.publish(""test"", ""no echo eh?"").await.unwrap(); assert_eq!( subscription.next().await.unwrap().data, b""no echo eh?"".to_vec() ); } ``` #### Expected result: With a nats bus running at `127.0.0.1:4222` this code should hang forever as with `no_echo` set no messages should be received. #### Actual result: This code does not crash demonstrating a message with the same payload as the outgoing message is received despite the presence of `no_echo`. "
640561,711954,https://api.github.com/repos/nextcloud/spreed/issues/5347,enhancement,2021-03-08T18:49:19Z,NONE,https://api.github.com/repos/nextcloud/spreed,Delete/edit messages **Delete/edit messages** A function to delete and at best also to edit already sent messages like in other modern messengers would be very helpful and a nice improvement. 
179198,199212,https://api.github.com/repos/primefaces/primereact/issues/1961,enhancement,2021-04-16T12:47:32Z,MEMBER,https://api.github.com/repos/primefaces/primereact,"Reimplement EventBus Current implementation uses an html comment element and causes conflicts, instead create a map based EventBus to avoid these cases."
576287,640415,https://api.github.com/repos/elastic/beats/issues/18069,enhancement,2020-04-28T21:24:34Z,CONTRIBUTOR,https://api.github.com/repos/elastic/beats,"[Heartbeat][libbeat] Use cloud metadata to autofill `observer.location` **Describe the enhancement:** Currently, one must manually fill the fields for `observer.location`, which is tedious. For hosts on cloud providers who could automatically fill this in based on cloud metadata. The idea for this came from [this forum post](https://discuss.elastic.co/t/aws-uptime-geo-information/230242). "
380894,423425,https://api.github.com/repos/fredericvl/py-agua-iot/issues/1,enhancement,2021-01-14T07:16:46Z,NONE,https://api.github.com/repos/fredericvl/py-agua-iot,"Homebridge Plugin Hello, Are you working on a hombridge pluging aqua-iot? Thanks"
169398,188358,https://api.github.com/repos/tatarize/vpype-gcode/issues/1,enhancement,2021-01-25T16:27:09Z,NONE,https://api.github.com/repos/tatarize/vpype-gcode,Instead of using `scale` allow providing the unit It would be nice if you could provide the unit in which you want the gcode/output to be in instead of the scale. vpype does this with its show command quite nicely: https://github.com/abey79/vpype/blob/7592bf47fd525ca58e09ee92ae8c05082e9257a0/vpype_cli/show.py#L145
700155,778162,https://api.github.com/repos/screwdriver-cd/screwdriver/issues/1829,question,2019-11-05T08:33:12Z,NONE,https://api.github.com/repos/screwdriver-cd/screwdriver,use SCM_USERNAME & SCM_ACCESS_TOKEN globally? We want to use screwdriver with a github team having only private repos. It would be a hassle to define the scm user and password values in each project's secrets separately. Is there an easy way to share those(would be from a github bot user)? 
85153,94671,https://api.github.com/repos/craftcms/nitro/issues/213,bug,2020-09-22T04:10:36Z,NONE,https://api.github.com/repos/craftcms/nitro,"Nitro unable to edit hosts file (requires elevated privileges) ### Description As the title describes, nitro is unable to edit the hosts file on a linux system without the use of elevated privileges. Nitro attempts to escalate the permissions by asking for sudo, however by escalating to sudo user nitro then attempts to read the nitro configuration from the wrong place (it does not exist in the sudo user, but under the current user) which returns the following error. ```bash nitro apply Applied changes from $HOME/.nitro/nitro-dev.yaml <attempts sudo here> There are no sites in the config file. ``` ### Steps to reproduce 1. Add a new site to the nitro config (either though `nitro add`or directly with the 2. Site is not added to /etc/hosts ### Additional info - Nitro version: 1.0.1 - Multipass version: 1.4.0 ### Possible solution Ensure that even in elevated user, that the config is read from the user that initially called the command. ### Workaround As a work around for now you can edit the /etc/hosts file directly with any text editor you like. ```bash sudo nano /etc/hosts ``` And add a new entry anywhere with the IP Address gathered with `nitro info` ``` # Nitro # IP HOST XX.57.78.XX craft.test ```"
482112,535811,https://api.github.com/repos/Ranchero-Software/NetNewsWire/issues/3046,bug,2021-04-24T04:13:00Z,COLLABORATOR,https://api.github.com/repos/Ranchero-Software/NetNewsWire,Share extension may be missing App Store Connect report: “The share extension for subscribing to feeds seems to be missing.”
420978,467952,https://api.github.com/repos/IceReaper/KKnD/issues/84,bug,2021-03-01T13:23:19Z,COLLABORATOR,https://api.github.com/repos/IceReaper/KKnD,Repairbay's repair arms do not move when an actor is being repaired This is an issue related to master branch.
593266,659326,https://api.github.com/repos/ansible-collections/amazon.aws/issues/317,bug,2021-04-06T07:16:10Z,NONE,https://api.github.com/repos/ansible-collections/amazon.aws,"rds tags not possible to configure on instance creation <!--- Verify first that your issue is not already reported on GitHub --> <!--- Also test if the latest release and devel branch are affected too --> <!--- Complete *all* sections as described, this form is processed automatically --> ##### SUMMARY <!--- Explain the problem briefly below --> On RDS instance creation, it's not possible to set the tags. It will give a type error (received dict but only accepts list) ##### ISSUE TYPE - Bug Report ##### COMPONENT NAME <!--- Write the short name of the module, plugin, task or feature below, use your best guess if unsure --> rds_instance ##### ANSIBLE VERSION <!--- Paste verbatim output from ""ansible --version"" between quotes --> ```paste below ansible 2.10.7 config file = /etc/ansible/ansible.cfg configured module search path = ['/home/ik/.ansible/plugins/modules', '/usr/share/ansible/plugins/modules'] ansible python module location = /usr/lib/python3.9/site-packages/ansible executable location = /usr/bin/ansible python version = 3.9.2 (default, Feb 20 2021, 18:40:11) [GCC 10.2.0] ``` ##### CONFIGURATION <!--- Paste verbatim output from ""ansible-config dump --only-changed"" between quotes --> ```paste below ``` ##### OS / ENVIRONMENT <!--- Provide all relevant information below, e.g. target OS versions, network device firmware, etc. --> Manjaro ##### STEPS TO REPRODUCE <!--- Describe exactly how to reproduce the problem, using a minimal test-case --> <!--- Paste example playbooks or commands between quotes below --> ```yaml - name: Create new RDS instance rds_instance: creation_source: snapshot backup_retention_period: 0 copy_tags_to_snapshot: yes db_snapshot_identifier: ""{{ rds_snapshot }}"" snapshot_identifier: ""{{ rds_snapshot }}"" id: ""{{ new_project_name }}"" storage_encrypted: ""{{ rdsdetails.storage_encrypted }}"" kms_key_id: ""{{ rdsdetails.kms_key_id }}"" storage_type: ""{{ rdsdetails.storage_type }}"" engine: ""{{ rdsdetails.engine }}"" engine_version: ""{{ rdsdetails.engine_version }}"" db_subnet_group_name: ""{{ rdsdetails.db_subnet_group.db_subnet_group_name }}"" vpc_security_group_ids: ""{{ rdsdetails.vpc_security_groups[0].vpc_security_group_id }}"" zone: ""{{ rdsdetails.availability_zone }}"" wait: no tags: mytag: somevalue ``` <!--- HINT: You can paste gist.github.com links for larger files --> ##### EXPECTED RESULTS <!--- Describe what you expected to happen when running the steps above --> Tags being set ##### ACTUAL RESULTS <!--- Describe what actually happened. If possible run with extra verbosity (-vvvv) --> Type error when setting tags when rds instance needs to be created. It is possible to modify the tags when the rds instance already exists <!--- Paste verbatim command output between quotes --> ```paste below ``` "
138688,154148,https://api.github.com/repos/CCExtractor/sample-platform/issues/507,bug,2021-03-06T21:46:22Z,MEMBER,https://api.github.com/repos/CCExtractor/sample-platform,"[BUG] Not all mediainfo is showing up on the site Sample platform commit (found at the bottom of each page) : 8a90a9cf92 **In raising this issue, I confirm the following (please check boxes, eg [X]):** - [x] I have read and understood the [contributors guide](https://github.com/CCExtractor/sample-platform/blob/master/.github/CONTRIBUTING.md). - [x] I have checked that the bug-fix I am reporting can be replicated, or that the feature I am suggesting isn't already present. - [x] I have checked that the issue I'm posting isn't already reported. - [x] I have checked that the issue I'm posting isn't already solved and no duplicates exist in [closed issues](https://github.com/CCExtractor/sample-platform/issues?q=is%3Aissue+is%3Aclosed) and in [opened issues](https://github.com/CCExtractor/sample-platform/issues) - [x] I have checked the pull requests tab for existing solutions/implementations to my issue/suggestion. **My familiarity with the project is as follows (check one, eg [X]):** - [] I have never visited/used the platform. - [] I have used the platform just a couple of times. - [] I have used the platform extensively, but have not contributed previously. - [x] I am an active contributor to the platform. --- Some recent samples (i.e. https://sampleplatform.ccextractor.org/sample/164) are not showing media info while the xml file is available on the repository. I suspect a parsing issue is at hand. The failing xml is attached: [failing.xml.zip](https://github.com/CCExtractor/sample-platform/files/6096148/failing.xml.zip) "
106387,118247,https://api.github.com/repos/barkingbunny/termostat_git/issues/3,enhancement,2018-07-31T15:51:44Z,OWNER,https://api.github.com/repos/barkingbunny/termostat_git,"Termostat - HREJ - instant action Pri mackani tlacitka, pro okamzite zapnuti - incrementuj cas pro dobu po kterou bude topeni topit."
705881,784530,https://api.github.com/repos/LukeChannings/moviematch/issues/77,bug,2021-05-06T17:33:42Z,NONE,https://api.github.com/repos/LukeChannings/moviematch,"[Bug] Reverse Proxy not working in v2.0.0-beta.1 in Docker - **MovieMatch version:** Version 2.0.0-beta.1 - **System:** Docker container of lukechannings/moviematch:develop running in Unraid OS - **Plex Version:** VERSION 1.23.0.4482 **Describe the bug** Following the upgrade to the 2.0 beta everything works fine when accessing MovieMatch from the local IP. However when accessing via moviematch.mydomain.com there is simply the MovieMatch logo at the top, a pulsing red circle in the middle, and a red bar with the word ""Disconnected"" at the bottom. Docker logs simply state ""[31mERROR Failed to upgrade to a WebSocket Error: request is not acceptable[39m"" No changes were made to the reverse proxy since it was previously working. Nginx subdomain.conf file can be seen below ``` server { listen 443 ssl; listen [::]:443 ssl; server_name moviematch.*; include /config/nginx/ssl.conf; client_max_body_size 0; # enable for ldap auth, fill in ldap details in ldap.conf #include /config/nginx/ldap.conf; location / { # enable the next two lines for http auth #auth_basic ""Restricted""; #auth_basic_user_file /config/nginx/.htpasswd; # enable the next two lines for ldap auth #auth_request /auth; #error_page 401 =200 /login; include /config/nginx/proxy.conf; resolver 127.0.0.11 valid=30s; set $upstream_moviematch MovieMatch; proxy_pass http://$upstream_moviematch:8000; } location /ws { include /config/nginx/proxy.conf; resolver 127.0.0.11 valid=30s; set $upstream_moviematch MovieMatch; proxy_pass http://$upstream_moviematch:8000; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection ""upgrade""; } } ``` **Screenshots** [https://imgur.com/a/HsF3lq0](url)"
599443,666164,https://api.github.com/repos/matiasvallejosdev/udemy-avengers/issues/7,enhancement,2021-01-29T18:20:42Z,OWNER,https://api.github.com/repos/matiasvallejosdev/udemy-avengers,Mala optimizacion de los archivos. # Atencion! Necesitamos resolver los problemas de la DB.
104671,116311,https://api.github.com/repos/WU-BIMAC/4DNMicroscopyMetadataToolReact/issues/164,bug,2021-01-05T22:18:50Z,MEMBER,https://api.github.com/repos/WU-BIMAC/4DNMicroscopyMetadataToolReact,Fixing old TESM file--> only a subset of LightSource positions are available when dragging and dropping Load TESM from Repo (old file) Saved new version Attempted to move Laser to correct position Only 4 positions available See the movie 
112456,124996,https://api.github.com/repos/rvanbekkum/vsc-xliff-sync/issues/57,bug,2020-10-28T12:53:18Z,NONE,https://api.github.com/repos/rvanbekkum/vsc-xliff-sync,"'State' attribute incorrectly added to XLIFF 2.0 files during syncing Hi! A minor issue found out during testing. --- **Version:** 0.5.1 **Steps to reproduce** 1. Add two new XLIFF files - one base file & one translation file 1. Update the base file with a new unit not present in the translation file 1. Run XLIFF sync **Expected result** New unit added to translation file, with target element set as an empty element ```xml <unit id=""sample_unit""> <segment state=""initial""> <source>Not assigned</source> <target/> </segment> </unit> ``` **Actual result** Unit added but with an additional incorrect state attribute added to target element. Unlike in version 1.2, state element can only be added segment elements as per [XLIFF 2.0 core specification](http://docs.oasis-open.org/xliff/xliff-core/v2.0/xliff-core-v2.0.html#state) ```xml <unit id=""sample_unit""> <segment state=""initial""> <source>Not assigned</source> <target state=""initial""/> </segment> </unit> ``` --- Once again, thanks for the great work on this extension! "
549360,610562,https://api.github.com/repos/EIDSS/EIDSS7/issues/65,bug,2019-07-09T16:16:57Z,NONE,https://api.github.com/repos/EIDSS/EIDSS7,"No results found with Advanced Search to select ""Species"" **Summary** No results found with Advanced Search to select ""Species"" **To Reproduce** Steps to reproduce the behavior: 1. Log in as troymcclure 2. Go to Laboratory>Testing Step 1. Select Laboratory>Testing Tab displayed Step 2. Select Advanced Search Step 3. Select Species Step 4. Select Search - no results were found ![image](https://user-images.githubusercontent.com/52667706/60904739-8c2f6100-a241-11e9-83c6-28529173f002.png) **Expected behavior** Selecting Search the Testing tab should display with tests records and match the search criteria. **Screenshots** Above. **Additional details:** - Build: 80 - Script title: LAB13. Create a BatchTest **Issue severity** Severity Major **Additional context** N/A "
503585,559735,https://api.github.com/repos/snikket-im/snikket-web-portal/issues/52,enhancement,2021-02-04T13:48:32Z,NONE,https://api.github.com/repos/snikket-im/snikket-web-portal,Add an F-Droid button on invite page Around here I guess: https://github.com/snikket-im/snikket-web-portal/blob/1c4fa92c974da1b50a781b1b04d7362612b2182b/snikket_web/templates/invite_view.html#L27
643826,715598,https://api.github.com/repos/eclipse/leshan/issues/979,question,2021-03-03T21:17:45Z,NONE,https://api.github.com/repos/eclipse/leshan,"Problems with ReadRequest (maybe a bug) Hello again, I'm not sure wether I'm doing something wrong or if it's a bug, but I have slight problems with ReadRequests. The Request itself gets through but the Type od the ReadRequest in the ReadRequest.success doesn't. It's a Opaque type and I have to convert this byte array I get into the type I want manually. My ReadResponse in the Server(in this example here I am using the RandomTemperatureSensor of the demo): ``` ReadResponse responseTemperatur = leshanServer.send(registration, new ReadRequest(OBJECT_ID_TEMPERATURE_SENSOR, 0, 5700)); if (responseTemperatur.isSuccess()) { System.out.println(""Temperature: "" + ((LwM2mResource)responseTemperatur.getContent()).getValue()); //Bug handling; double gets converted to byte array(in the sending process) //this converts a byte array to double Object test = ((LwM2mResource)responseTemperatur.getContent()).getValue(); byte[] test2 = (byte[]) test; System.out.println(""ByteArray = "" + Arrays.toString(test2)); System.out.println(""Actual value: "" + ByteBuffer.wrap(test2).getDouble()); }else { System.out.println(""Failed to read:"" + responseTemperatur.getCode() + "" "" + responseTemperatur.getErrorMessage()); } ``` The Terminal says: ``` ... Temperature: [B@47da8cdb ByteArray = [64, 51, -26, 102, 102, 96, 0, 0] Actual value: 19.899999998509884 ... ``` Best regards, Jonas "
382201,424867,https://api.github.com/repos/cseelhoff/RimThreaded/issues/237,bug,2020-11-19T02:05:28Z,NONE,https://api.github.com/repos/cseelhoff/RimThreaded,"Freeze upon making a room with smoothed stone floors I'm having a complete freeze upon making a room with smoothed stone floors. I.E as soon as the last bit of floor is smoothed and the game I assume updates the room information with that it locks up to not responding. Exception while rebuilding dirty regions: System.Threading.ThreadAbortException at (wrapper managed-to-native) System.Object.__icall_wrapper_mono_monitor_enter_v4_internal(object,intptr) at RimThreaded.Room_Patch.Notify_RoomShapeOrContainedBedsChanged (Verse.Room __instance) [0x00005] in <7baf655e5d854fddba41592b65d1a630>:0 at (wrapper dynamic-method) Verse.Room.Verse.Room.Notify_RoomShapeOrContainedBedsChanged_Patch2(Verse.Room) at RimThreaded.RegionAndRoomUpdater_Patch.NotifyAffectedRoomsAndRoomGroupsAndUpdateTemperature2 (Verse.RegionAndRoomUpdater __instance) [0x0001f] in <7baf655e5d854fddba41592b65d1a630>:0 at RimThreaded.RegionAndRoomUpdater_Patch.CreateOrUpdateRooms2 (Verse.RegionAndRoomUpdater __instance) [0x00067] in <7baf655e5d854fddba41592b65d1a630>:0 at RimThreaded.RegionAndRoomUpdater_Patch.TryRebuildDirtyRegionsAndRooms (Verse.RegionAndRoomUpdater __instance) [0x0008b] in <7baf655e5d854fddba41592b65d1a630>:0 This happens even if I were to split the room into two different sections, as soon as one has smoothed stone floor completely this freeze happens. This is my first time ever posting an issue so sorry if its not quite laid out in a great way."
15171,16912,https://api.github.com/repos/rcjsuen/dockerfile-utils/issues/94,enhancement,2021-04-10T14:43:07Z,OWNER,https://api.github.com/repos/rcjsuen/dockerfile-utils,"Ignore *.tgz files when publishing to npm When testing with `npm pack`, it is possible for extraneous `*.tgz` files to be included in the root folder. We should ensure that `*.tgz` files are not included when running `npm pack` so that extra files do not get published to npm by mistake."
212930,236775,https://api.github.com/repos/Sonarr/Sonarr/issues/4167,enhancement,2020-12-15T23:16:47Z,NONE,https://api.github.com/repos/Sonarr/Sonarr,Add Recommended to the List types for Trakt **Describe the problem** Add Recommended to the List types for Trakt **Describe any solutions you think might work** Obtain the recommended list similarly to how to other lists types are obtained **Additional context** https://trakt.tv/shows/recommended/monthly 
642726,714359,https://api.github.com/repos/bjucps/open-contest/issues/60,enhancement,2021-01-23T00:24:22Z,NONE,https://api.github.com/repos/bjucps/open-contest,"Submission detail dialog - Set default test case tab When a judge displays the details for a submission, currently the first tab showing the sample data results is displayed. Enhance the system so that the default tab is as follows: * If at least one test case is not ""Correct,"" display the first tab with a non-correct result. * If no tabs are in error, the default tab should be the first tab for a non-sample case. * If all cases are sample cases, the default tab should be the first tab."
606282,673780,https://api.github.com/repos/OctopusDeployLabs/terraform-provider-octopusdeploy/issues/151,bug,2021-04-01T10:10:38Z,NONE,https://api.github.com/repos/OctopusDeployLabs/terraform-provider-octopusdeploy,"create team not working inside space or similar **Describe the bug** While automating creation of teams- the spaceId is not working as expected. Scope of a team is for System however it should be confined within the given spaceID. **code:** **main.tf:** terraform { required_providers { octopusdeploy = { source = ""OctopusDeployLabs/octopusdeploy"" } } } provider ""octopusdeploy"" { address = var.address api_key = var.api_key space_id = var.space_id } resource ""octopusdeploy_team"" ""team-demo"" { name = var.name description = var.description users = data.octopusdeploy_users.example[*].users[0].id } **data.tf:** data ""octopusdeploy_users"" ""example"" { count = length(var.users) filter = var.users[count.index] skip = 0 take = 1 } **tfvars:** address = <URL> api_key = <API KEy> space_id = ""Spaces-90"" name = ""Test-team"" description = ""This is a test team"" #users = [""<emailID>""] "
674478,749618,https://api.github.com/repos/IkerGalardi/LMake/issues/87,bug,2021-04-06T22:04:52Z,OWNER,https://api.github.com/repos/IkerGalardi/LMake,Bug: compilation times Compilation times in recent commits are huge compared to before.
142243,158109,https://api.github.com/repos/pawelsalawa/sqlitestudio/issues/3452,bug,2018-11-05T00:01:24Z,NONE,https://api.github.com/repos/pawelsalawa/sqlitestudio,"escapeCdata: Additional split of substrings ""]]>"" in CDATA See [Plugins/XmlExport/xmlexport.cpp `escapeCdata`](https://github.com/pawelsalawa/sqlitestudio/blob/2b25508ad3d52248d5bd2dcdff1bd1d952577fec/Plugins/XmlExport/xmlexport.cpp#L446). CDATA ends with ""]]>"". The substring of `str` ""]]>"" requires splitting into different `CDATA` to prevent unexpected termination of CDATA. Thank you for your job!"
611872,679968,https://api.github.com/repos/discord/discord-api-docs/issues/2537,bug,2021-01-27T07:12:43Z,NONE,https://api.github.com/repos/discord/discord-api-docs,"Emojis in option names cause validation error **Description** Slash commands with a string/integer choices that contain an standard emoji in the name fail to pass the client validation. **Steps to Reproduce** Have a command with a choices option (string or integer, doesn't matter), and an emoji in the name. ```ts discord.interactions.commands.register( { name: 'roll', description: 'Rolls a die.', options: (opt) => ({ type: opt.integer({ description: 'The number of sides the die has.', choices: [ { name: '🎲 Standard (D6)', value: 6 }, { name: 'D4', value: 4 } // ... more choices ] }) }) }, async (interaction, { type }) => { const rnd = Math.ceil(Math.random() * type); await interaction.respond(`**You rolled:** \`${rnd}\`!`); } ); ``` **Expected Behavior** The client should not throw a validation error, and let you use the choice with a custom emoji. **Current Behavior** The behavior is best described visually: ![P2kdKvWFNn](https://user-images.githubusercontent.com/4871369/105955395-11988300-602b-11eb-8d6d-194d94955e9c.gif) **Client and System Information** 👎 Desktop/Web 👍 Mobile This doesn't appear to be a problem on at least the iOS client. The emoji appears in the name and I can select these choices there and invoke the command with no errors."
678787,754378,https://api.github.com/repos/kopkop123/homepage/issues/18,enhancement,2021-05-03T19:29:59Z,OWNER,https://api.github.com/repos/kopkop123/homepage,"Add stylesheet and other meta tags \<link rel=""stylesheet"" href=""https://binary-studio-academy.github.io/stage-2/assets/stylesheets/base.css"">"
708636,787588,https://api.github.com/repos/java-operator-sdk/java-operator-sdk/issues/337,enhancement,2021-02-11T12:45:14Z,NONE,https://api.github.com/repos/java-operator-sdk/java-operator-sdk,"namespaces configuration should not be fixed at build time for quarkus operator Hi, I have an issue where I want a quarkus native executable to watch different namespaces depending on its environment variable. The idea is to deploy a pod with env section something like ```yaml env: - name: quarkus_operator_sdk_controllers_foocontroller.namespaces valueFrom: fieldRef: fieldPath: metadata.namespace ``` or any other values. Is it possible ?"
142011,157853,https://api.github.com/repos/OpenSRP/web/issues/258,enhancement,2020-12-15T04:23:51Z,MEMBER,https://api.github.com/repos/OpenSRP/web,"Select the parent location automatically during location unit creation - [x] When creating location units, the parent field should automatically default to the location selected on the location tree. - [x] The user should still be allowed the ability to change the parent location by navigating location tree on the parent location field"
703964,782385,https://api.github.com/repos/gigioSouza/japigee-bundler/issues/32,enhancement,2021-04-14T03:24:37Z,OWNER,https://api.github.com/repos/gigioSouza/japigee-bundler,"Implement Bundler interfaces for APIDefinition Implement Bundler interfaces for APIDefinition to transform an APIDefinition into an APIBundle instance, and than be able to create a bundle.zip."
253207,281653,https://api.github.com/repos/eclipse/capella-basic-vp/issues/18,enhancement,2021-01-08T13:01:50Z,NONE,https://api.github.com/repos/eclipse/capella-basic-vp,Migration to Capella 1.0.x Merged to [master]. Commit: [471bff7be2d0d41c7e7b2a92ef98db31766477b9](https://github.com/search?q=471bff7be2d0d41c7e7b2a92ef98db31766477b9&type=Commits) `🆔 ECLIPSE-555063 / POLARSYS-649` `👷 anonymous` `📅 2015-11-27` `🔎 1.0.0`
634355,705031,https://api.github.com/repos/HimmelKreis4865/BetterSkulls/issues/5,bug,2021-03-31T08:21:23Z,NONE,https://api.github.com/repos/HimmelKreis4865/BetterSkulls,"Kopfentity Bug mit Worldedit Wenn man die Köpfe mit Worldedit entfernt, bleibt der Entity dort für immer. Kann man was dagegen tuen? 😅 "
706088,784760,https://api.github.com/repos/ArtResearch/pharos-dev/issues/6,enhancement,2021-02-03T13:45:57Z,CONTRIBUTOR,https://api.github.com/repos/ArtResearch/pharos-dev,Providers entities over time @statistics An additional tab should be added to present the change in number of entities over time for each provider.
281655,313228,https://api.github.com/repos/dealii/dealii/issues/11626,bug,2021-01-26T00:12:04Z,MEMBER,https://api.github.com/repos/dealii/dealii,"Broken python wrappers. The elimination of the enum `ReferenceCell::Type::CellKinds` broke our python wrappers: ``` /usr/bin/c++ -DBOOST_NO_AUTO_PTR -DPyDealII_release_EXPORTS -Iinclude -I../include -I../bundled/taskflow-2.5.0/include -I../contrib/python-bindings/include -isystem /usr/lib/x86_64-linux-gnu/openmpi/include/openmpi -isystem /usr/lib/x86_64-linux-gnu/openmpi/include -isystem /usr/include/trilinos -isystem /usr/include/hdf5/openmpi -isystem /usr/include/scotch -isystem /usr/include/suitesparse -isystem /usr/include/petsc -isystem /usr/lib/x86_64-linux-gnu/hdf5/openmpi/include -isystem /usr/include/opencascade -isystem /usr/include/slepc -isystem /usr/include/python3.8 -fPIC -pedantic -fPIC -Wall -Wextra -Wmissing-braces -Woverloaded-virtual -Wpointer-arith -Wsign-compare -Wsuggest-override -Wswitch -Wsynth -Wwrite-strings -Wno-placement-new -Wno-deprecated-declarations -Wno-literal-suffix -Wno-psabi -Wno-class-memaccess -fopenmp-simd -pthread -Wno-unused-local-typedefs -O2 -funroll-loops -funroll-all-loops -fstrict-aliasing -Wno-unused-local-typedefs -MD -MT contrib/python-bindings/source/CMakeFiles/PyDealII_release.dir/export_reference_cell.cc.o -MF contrib/python-bindings/source/CMakeFiles/PyDealII_release.dir/export_reference_cell.cc.o.d -o contrib/python-bindings/source/CMakeFiles/PyDealII_release.dir/export_reference_cell.cc.o -c ../contrib/python-bindings/source/export_reference_cell.cc #5 6892. ../contrib/python-bindings/source/export_reference_cell.cc: In function ‘void dealii::python::export_reference_cell()’: #5 6892. ../contrib/python-bindings/source/export_reference_cell.cc:31:47: error: ‘CellKinds’ is not a member of ‘dealii::ReferenceCell::Type’ #5 6892. 31 | boost::python::enum_<ReferenceCell::Type::CellKinds>(""CellKinds"") #5 6892. | ^~~~~~~~~ #5 6892. ../contrib/python-bindings/source/export_reference_cell.cc:31:47: error: ‘CellKinds’ is not a member of ‘dealii::ReferenceCell::Type’ #5 6892. ../contrib/python-bindings/source/export_reference_cell.cc:31:56: error: template argument 1 is invalid #5 6892. 31 | boost::python::enum_<ReferenceCell::Type::CellKinds>(""CellKinds"") #5 6892. | ^ #5 6892. ../contrib/python-bindings/source/export_reference_cell.cc:44:48: error: ‘CellKinds’ is not a member of ‘dealii::ReferenceCell::Type’ #5 6892. 44 | boost::python::init<ReferenceCell::Type::CellKinds>( #5 6892. | ^~~~~~~~~ #5 6892. ../contrib/python-bindings/source/export_reference_cell.cc:44:48: error: ‘CellKinds’ is not a member of ‘dealii::ReferenceCell::Type’ #5 6892. ../contrib/python-bindings/source/export_reference_cell.cc:44:57: error: template argument 1 is invalid #5 6892. 44 | boost::python::init<ReferenceCell::Type::CellKinds>( #5 6892. | ^ #5 6899. [937/966] Building CXX object contrib/python- :bindings/source/CMakeFiles/PyDealII_release.dir/cell_accessor_wrapper.cc.o #5 6990. [938/966] Linking CXX shared library lib/libdeal_II.g.so.9.3.0-pre #5 6990. ninja: build stopped: subcommand failed. ``` and with it our master docker images."
421509,468542,https://api.github.com/repos/lithops-cloud/lithops/issues/643,bug,2021-04-26T02:54:31Z,COLLABORATOR,https://api.github.com/repos/lithops-cloud/lithops,"[ bug] partitioner failed to list objects in nested directories When data source is ```iterdata = 'cos://mydata/allcollected/jpg/'``` , partitioner removes slash and list it wrong ``` 2021-04-26 05:50:08,570 [DEBUG] lithops.job.partitioner -- Parsing input data 2021-04-26 05:50:08,570 [DEBUG] lithops.job.partitioner -- Listing objects in 'ibm_cos://mydata/allcollectedjpg' 2021-04-26 05:50:09,909 [DEBUG] lithops.job.partitioner -- Total objects found: 0 ```"
717301,797209,https://api.github.com/repos/snekkylang/snekkyd/issues/4,bug,2021-04-21T22:13:28Z,MEMBER,https://api.github.com/repos/snekkylang/snekkyd,Precedence bug `5 / (2 / 2)` -> `5 / 2 / 2`
451042,501287,https://api.github.com/repos/Obsidion-dev/Obsidion/issues/176,bug,2021-05-05T09:44:29Z,COLLABORATOR,https://api.github.com/repos/Obsidion-dev/Obsidion,"Direct Message Server Server command sent in Direct Messages has no `guild` component. Traceback: Exception in command 'server' Traceback (most recent call last): File ""/opt/pysetup/.venv/lib/python3.8/site-packages/discord/ext/commands/core.py"", line 85, in wrapped ret = await coro(*args, **kwargs) File ""/app/obsidion/cogs/info/info.py"", line 159, in server address = await self.bot._guild_cache.get_server(ctx.guild) File ""/app/obsidion/core/settings_cache.py"", line 191, in get_server gid = guild.id AttributeError: 'NoneType' object has no attribute 'id' The above exception was the direct cause of the following exception: Traceback (most recent call last): File ""/opt/pysetup/.venv/lib/python3.8/site-packages/discord/ext/commands/bot.py"", line 939, in invoke await ctx.command.invoke(ctx) File ""/opt/pysetup/.venv/lib/python3.8/site-packages/discord/ext/commands/core.py"", line 863, in invoke await injected(*ctx.args, **ctx.kwargs) File ""/opt/pysetup/.venv/lib/python3.8/site-packages/discord/ext/commands/core.py"", line 94, in wrapped raise CommandInvokeError(exc) from exc discord.ext.commands.errors.CommandInvokeError: Command raised an exception: AttributeError: 'NoneType' object has no attribute 'id'"
705278,783860,https://api.github.com/repos/FBJ-TCD/O-LABIRINTO-DAS-ESCOLHAS/issues/38,question,2021-03-03T17:08:11Z,CONTRIBUTOR,https://api.github.com/repos/FBJ-TCD/O-LABIRINTO-DAS-ESCOLHAS,"(OPCIONAL) integrar jogo com a discord Integrar o jogo através de bot com o servidor da disciplina: administração do servidor, divulgação do placar etc. Esta tarefa é para aquele 10 no final da disciplina..."
368336,409461,https://api.github.com/repos/MUTUAL-DE-SERVICIOS-AL-POLICIA/PVT/issues/1734,enhancement,2021-04-07T23:51:26Z,CONTRIBUTOR,https://api.github.com/repos/MUTUAL-DE-SERVICIOS-AL-POLICIA/PVT,Crear método para obtener roles y permisos Crear método para el filtrado del historial de Pago
148643,165226,https://api.github.com/repos/cli/cli/issues/3509,bug,2021-04-25T11:57:11Z,NONE,https://api.github.com/repos/cli/cli,"gh repo clone requires me to enter username/password even for public repositories ### Describe the bug I'm trying to simply use GitHub CLI as 'clone and do pull later when there is new tags' tool for the public repositories. Those two features are the only ones which I want to use. Using custom tools is not an alternative, it has to be the one from GitHub. ### Steps to reproduce the behavior - Enter command gh repo create <repo name> - GH required me to enter username/password ### Expected vs actual behavior I should not be forced to enter a username/password at all. "
714424,794010,https://api.github.com/repos/tensorflow/datasets/issues/3110,bug,2021-03-17T06:17:42Z,COLLABORATOR,https://api.github.com/repos/tensorflow/datasets,"Multiple progress bars for single task On downloading a dataset via ``` tfds build mnist ``` or ```python tfds.load('mnist') ``` multiple progress bars are displayed for the same task ```python 2021-03-17 11:31:29.271974: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""Not found: Could not locate the credentials file."". Retrieving token from GCE failed with ""Failed precondition: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Couldn't resolve host 'metadata'"". Downloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /home/vijayphoenix/tensorflow_datasets/mnist/3.0.1... Dl Completed...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:07<00:00, 1.82s/ file] Dl Completed...: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:07<00:00, 1.87s/ file] Dataset mnist downloaded and prepared to /home/vijayphoenix/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data. 2021-03-17 11:32:13.220118: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations: SSE4.1 SSE4.2 AVX AVX2 FMA To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags. 2021-03-17 11:32:13.244796: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2699905000 Hz 2021-03-17 11:32:13.245497: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5652857e7bb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices: 2021-03-17 11:32:13.245566: I tensorflow/compiler/xla/service/service.cc:176] StreamExecutor device (0): Host, Default Version ``` **Expected:** Only one progress bar is displayed "
454996,505705,https://api.github.com/repos/s-yadav/react-number-format/issues/435,bug,2020-08-21T11:44:07Z,NONE,https://api.github.com/repos/s-yadav/react-number-format,"If value doesn't change because it doesn't pass isAllowed condition, onChange still fires when onValueChange doesn't. Since the event object isn't provided by the onValueChange handler, I need to use this in conjunction with onChange. Unfortunately one is firing when the other isn't which is causing issues. My thought was that as the value is not changing when not passing isAllowed, onChange shouldn't fire. What's the intended behaviour? "
366417,407327,https://api.github.com/repos/minio/operator/issues/638,bug,2021-05-12T15:41:42Z,NONE,https://api.github.com/repos/minio/operator,The cert issued should include sans for minio.<ns> and minio.<ns>.svc <!--- Provide a general summary of the issue in the Title above --> The cert issued should include sans for `minio.<ns>` and `minio.<ns>.svc` ## Expected Behavior I can connect to the service using the short-hand service names. ## Current Behavior I can't connect to the service using the short-hand service names due to ssl failures. 
256688,285499,https://api.github.com/repos/motdotla/node-lambda/issues/555,enhancement,2021-03-24T10:57:24Z,NONE,https://api.github.com/repos/motdotla/node-lambda,"Add --no-optional option to node-lambda zip Please add `--no-optional` flag to node-lambda zip. Motivation: in our project we have a dependency (pubnub) which pulls in react-native packages as optionalDependency, even though we are using it in backend. This could be avoided by passing `--no-optional` when building zipbundle, but it seems there is no way to pass it when callling `node-lambda zip ...`. Or is there? "
677526,752994,https://api.github.com/repos/MightyPirates/OpenComputers/issues/3391,bug,2020-12-22T07:56:52Z,NONE,https://api.github.com/repos/MightyPirates/OpenComputers,"Generator upgrade destroys fuel containers. OC 1.7.5.192 Minecraft version 1.12.2 OC version 1.7.5.192 Hi I was playing Project Ozone 3 and I noticed with the generator upgrade consumes the bucket along with the lava in it for fuel. Also after testing it with only OC installed it still displayed the same behavior. I know this has been brought up in #1779 however, its been 4 years >.> Attached is a screenshot showing that there is no bucket being returned. Thanks! <img width=""959"" alt=""Screenshot 2020-12-22 023722"" src=""https://user-images.githubusercontent.com/76469850/102863919-49dfec80-4401-11eb-90db-b43a9ad2efca.png""> "
96892,107676,https://api.github.com/repos/OpenWork-NZ/mdwg/issues/90,enhancement,2020-09-23T23:38:15Z,COLLABORATOR,https://api.github.com/repos/OpenWork-NZ/mdwg,"Service Type Should not use the suggested dropdown items for Service Type. Rather should use a different vocabulary. Enhancement: new options could be ""discovery"", ""view"", ""download"", ""transformation"", or ""invoke"". This is a somewhat confusion issue. The standard lacks clarity about how this element and related elements (ServiceType, ServicewVersion, profile and ServiceStandard). More firm agreement and guidance from MDWG would be helpful as these are likely xearch parameters. Computers need to know how to find and index these values ![image](https://user-images.githubusercontent.com/1085756/94625317-f59f0200-0314-11eb-8632-3dce4bd37778.png) "
270828,301187,https://api.github.com/repos/Informasjonsforvaltning/fdk-dataset-harvester/issues/8,bug,2020-01-21T11:03:17Z,CONTRIBUTOR,https://api.github.com/repos/Informasjonsforvaltning/fdk-dataset-harvester,NullPointerException Frå https://console.cloud.google.com/errors/CIfPuauXr6GEtwE?time=P1D&project=fdk-prod&authuser=2&organizationId=382284307604 ``` java.lang.NullPointerException at java.lang.String.contains(String.java:2133) at no.dcat.harvester.crawler.handlers.ElasticSearchResultHandler.lambda$filterValidationMessagesForDataset$8(ElasticSearchResultHandler.java:923) at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:174) at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382) at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566) at no.dcat.harvester.crawler.handlers.ElasticSearchResultHandler.filterValidationMessagesForDataset(ElasticSearchResultHandler.java:924) at no.dcat.harvester.crawler.handlers.ElasticSearchResultHandler.createDatasetHarvestRecord(ElasticSearchResultHandler.java:783) at no.dcat.harvester.crawler.handlers.ElasticSearchResultHandler.saveDatasetAndHarvestRecord(ElasticSearchResultHandler.java:730) at no.dcat.harvester.crawler.handlers.ElasticSearchResultHandler.updateDatasets(ElasticSearchResultHandler.java:366) at no.dcat.harvester.crawler.handlers.ElasticSearchResultHandler.indexWithElasticsearch(ElasticSearchResultHandler.java:201) at no.dcat.harvester.crawler.handlers.ElasticSearchResultHandler.process(ElasticSearchResultHandler.java:143) at no.dcat.harvester.crawler.CrawlerJob.run(CrawlerJob.java:171) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) ```
96208,106929,https://api.github.com/repos/theislab/scvelo/issues/433,enhancement,2021-04-23T19:15:59Z,NONE,https://api.github.com/repos/theislab/scvelo,"Goodness of fit for velocity based Markov Chain model <!-- What kind of feature would you like to request? --> Is there a suggested way to test the goodness of fit of the markov chain model (i.e. the transition matrix) that is derived from the velocity graph? Since single cell data can be very noisy, it would be nice to have some kind of measure to determine how confident we can be in the transition matrix, similar to the velocity confidence metric, that allows us to understand how much variability should be expected in the transition matrix probabilities fit to the data."
134158,149122,https://api.github.com/repos/thaomonster/rancid-tomatillos/issues/23,enhancement,2021-02-12T16:24:00Z,COLLABORATOR,https://api.github.com/repos/thaomonster/rancid-tomatillos,"Youtube embeds As a user, When I visit the movie detail page, I want to see embedded youtube videos relating to that movie, So that I can stream them in the same page, or click the titles to visit youtube. "
391036,434661,https://api.github.com/repos/milieuinfo/webcomponent-vl-ui-select/issues/157,bug,2021-05-03T10:59:32Z,CONTRIBUTOR,https://api.github.com/repos/milieuinfo/webcomponent-vl-ui-select,"[BUG] - Required validatie in combinatie met dynamische opties **Omschrijf het probleem** Form validatie zegt dat de form valid is wanneer er geen value gekozen is bij een 'required' select met dynamisch gegenereerde opties. **Hoe te reproduceren** `<select is=""vl-select"" data-vl-block data-vl-error-placeholder=""diersoort-error"" data-vl-required=""true"" data-vl-validation-type=""select""></select>` `select.dress({callbackFn: () => opties()});` **Gewenst gedrag** Form moet zeggen dat het invalid is wanneer geen waarde ingevuld bij required select. "
98616,109575,https://api.github.com/repos/gnosis/safe-ios/issues/929,enhancement,2021-02-15T02:04:20Z,COLLABORATOR,https://api.github.com/repos/gnosis/safe-ios,"[iOS] Submit rejection transaction We want to create rejection transaction and submit it. In order to submit any transaction to back end, a new [endpoint](https://github.com/gnosis/safe-client-gateway/wiki/transactions_proposal) already created. In order to submit a rejection transaction we have to use the previous endpoint with the flowing parameters: - **To:** safe address - **Nonce:** the nonce of tx to be canceled. - **Signature:** the hash of current tx signed by owner key - **Safe tx gas:** must be zero - **All other params:** zero values ### **Notes** - We can use same error codes and create signature method used for submit confirmation"
209810,233304,https://api.github.com/repos/SilentChaos512/ScalingHealth/issues/255,bug,2020-04-17T23:16:10Z,NONE,https://api.github.com/repos/SilentChaos512/ScalingHealth,"Compatibility issue with gokiStats mod ## Versions <!-- Include versions affected by the issue (actual version number, do not use ""latest""). Pasting the name of the JAR file is acceptable. --> - **Scaling Health**: 1.3.42+147 for 1.12.2 - **Silent Lib**: 3.0.14+168 - **Forge**: 1.12.2-14.23.5.2847 - **Optifine Installed**: Yes <!-- enter Yes or No --> ## Problem description <!-- What do you expect to happen in this case? --> As you may know, ""gokiStats"" mod increase player's stats trough upgradeable ""skills"" — damage, max health, run, mine, chop, swim, smelt speed, resistance to damage dealt by mobs, fire, explosion, fall and so on. And there is an issue — if you try to level up ""Health"" skill to increase player's MaxHealth with your ""Scalable health"" mod active, your mod just blocks any player's MaxHealth manipulation, so ""Health"" skill from ""gokiStats"" just become useless. And I think this problem also may appears with other mods that manipulates player's MaxHealth. So can you somehow allow other mods to modify player's MaxHealth?"
222419,247331,https://api.github.com/repos/Tel-Aviv/HavanaClients/issues/41,bug,2021-05-24T15:38:36Z,MEMBER,https://api.github.com/repos/Tel-Aviv/HavanaClients,"Date changed after record edited in AddNewRecord dialog When sucessful closing of the sub-dialog of the AddNewRecord, the first date of the current month appears on the main dialog. TODO: Don't touch the date displayed on the caption of the AddNew Dialog"
674358,749483,https://api.github.com/repos/Manuele99/reega/issues/4,enhancement,2021-01-24T16:16:49Z,OWNER,https://api.github.com/repos/Manuele99/reega,Upgrade DataController Add methods to: - add new contract - add new price model - remove contract - remove price model
16105,17958,https://api.github.com/repos/cgeo/cgeo/issues/10248,bug,2021-03-24T11:08:34Z,MEMBER,https://api.github.com/repos/cgeo/cgeo,"SAF folder cannot be accessed (IOException / NullPointerException) On support mail a beta user informed us, that we sees an error toast, that /cgeo/maps cannot be accessed: ![Screenshot_2021-03-23-22-45-48-431_cgeo geocaching](https://user-images.githubusercontent.com/949669/112300685-6823e580-8c99-11eb-99ad-a5cbce2b83cb.jpg) System information: ``` --- System information --- c:geo version: 2021.03.22-RC Device: ------- - Device type: Redmi Note 9 Pro (joyeuse_eea, Redmi) - Android version: 10 - Android build: QKQ1.191215.002 test-keys - Sailfish OS detected: false - Google Play services: enabled - 21.06.13 (120400-358943053) - HW acceleration: enabled (default state) Sensor and location: ------- - Low power mode: inactive - Compass capabilities: yes - Rotation vector sensor: present - Orientation sensor: present - Magnetometer & Accelerometer sensor: present - Direction sensor used: rotation vector Program settings: ------- - Hide caches: archived - Hide waypoints: - - Set language: en - System date format: M/d/yy - Debug mode active: no - Live map mode: true - Global filter: display all caches - Last backup: Oct 3, 2020, 12:43 AM - Routing mode: Car - Map: Google: Satellite - Id: cgeo.geocaching.maps.google.v2.GoogleMapProvider$GoogleSatelliteSource - Atts: none - Theme: Services: ------- - Geocaching sites enabled: geocaching.com: Logged in (Login OK) / PREMIUM - Geocaching.com date format: dd/MM/yyyy - BRouter installed: false / connection available: false - Installed c:geo plugins: none Permissions & paths: ------- - Fine location permission: granted - Write external storage permission: granted - System internal c:geo dir: /data/user/0/cgeo.geocaching (68.2 GB free) v2 internal isDir(7 entries) - Legacy User storage c:geo dir: /storage/emulated/0/cgeo (68.2 GB free) v2 external non-removable isDir(5 entries) - Geocache data: /storage/emulated/0/Android/data/cgeo.geocaching/files/GeocacheData (68.2 GB free) v2 external non-removable isDir(256 entries) - Internal theme sync (is turned off): /data/user/0/cgeo.geocaching/MapThemeData (68.2 GB free) v2 internal isDir(0 entries) - Public Folders: #9 - BASE: /cgeo (User-defined)[/cgeo[DOCUMENT#0:p-content://com.android.externalstorage.documents/tree/primary%3Acgeo::], default: /storage/emulated/0/cgeo[FILE#0:p-file:///storage/emulated/0/cgeo::]] (Uri: content://com.android.externalstorage.documents/tree/primary%3Acgeo/document/primary%3Acgeo, Av:true, Files:11, dirs:9, totalFileSize:126.5 MB, free space: 68.2 GB, files on device: 13511675) - OFFLINE_MAPS: /cgeo/maps (User-defined)[/cgeo/maps[DOCUMENT#0:p-content://com.android.externalstorage.documents/tree/primary%3Acgeo%2Fmaps::], default: /cgeo/maps[PERSISTABLE_FOLDER(BASE)#1:p-content://com.android.externalstorage.documents/tree/primary%3Acgeo::/maps]] (Uri: content://com.android.externalstorage.documents/tree/primary%3Acgeo%2Fmaps/document/primary%3Acgeo%2Fmaps, Av:false, Files:0, dirs:0, totalFileSize:0 B, free space: -1 B, files on device: -1) - OFFLINE_MAP_THEMES: /Download (User-defined)[/Download[DOCUMENT#0:p-content://com.android.externalstorage.documents/tree/primary%3ADownload::], default: /cgeo/maps/_themes[PERSISTABLE_FOLDER(OFFLINE_MAPS)#1:p-content://com.android.externalstorage.documents/tree/primary%3Acgeo%2Fmaps::/_themes]] (Uri: content://com.android.externalstorage.documents/tree/primary%3ADownload/document/primary%3ADownload, Av:true, Files:30, dirs:0, totalFileSize:768.5 MB, free space: 68.2 GB, files on device: 13511675) - LOGFILES: /cgeo/logfiles (Default)[/cgeo/logfiles[PERSISTABLE_FOLDER(BASE)#1:p-content://com.android.externalstorage.documents/tree/primary%3Acgeo::/logfiles], default: (same)] (Uri: content://com.android.externalstorage.documents/tree/primary%3Acgeo/document/primary%3Acgeo%2Flogfiles, Av:true, Files:10, dirs:0, totalFileSize:125.2 MB, free space: 68.2 GB, files on device: 13511675) - GPX: /cgeo/gpx (Default)[/cgeo/gpx[PERSISTABLE_FOLDER(BASE)#1:p-content://com.android.externalstorage.documents/tree/primary%3Acgeo::/gpx], default: (same)] (Uri: content://com.android.externalstorage.documents/tree/primary%3Acgeo/document/primary%3Acgeo%2Fgpx, Av:true, Files:0, dirs:0, totalFileSize:0 B, free space: 68.2 GB, files on device: 13511675) - BACKUP: /cgeo/backup (Default)[/cgeo/backup[PERSISTABLE_FOLDER(BASE)#1:p-content://com.android.externalstorage.documents/tree/primary%3Acgeo::/backup], default: (same)] (Uri: content://com.android.externalstorage.documents/tree/primary%3Acgeo/document/primary%3Acgeo%2Fbackup, Av:true, Files:1, dirs:1, totalFileSize:1.3 MB, free space: 68.2 GB, files on device: 13511675) - FIELD_NOTES: /cgeo/field-notes (Default)[/cgeo/field-notes[PERSISTABLE_FOLDER(BASE)#1:p-content://com.android.externalstorage.documents/tree/primary%3Acgeo::/field-notes], default: (same)] (Uri: content://com.android.externalstorage.documents/tree/primary%3Acgeo/document/primary%3Acgeo%2Ffield-notes, Av:true, Files:0, dirs:0, totalFileSize:0 B, free space: 68.2 GB, files on device: 13511675) - SPOILER_IMAGES: /cgeo/GeocachePhotos (Default)[/cgeo/GeocachePhotos[PERSISTABLE_FOLDER(BASE)#1:p-content://com.android.externalstorage.documents/tree/primary%3Acgeo::/GeocachePhotos], default: (same)] (Uri: content://com.android.externalstorage.documents/tree/primary%3Acgeo/document/primary%3Acgeo%2FGeocachePhotos, Av:true, Files:0, dirs:3, totalFileSize:0 B, free space: 68.2 GB, files on device: 13511675) - TEST_FOLDER: [Legacy]/data/user/0/cgeo.geocaching/files/unittest (Default)[/data/user/0/cgeo.geocaching/files/unittest[FILE#1:p-file:///data/user/0/cgeo.geocaching/files::/unittest], default: (same)] (Uri: file:///data/user/0/cgeo.geocaching/files/unittest, Av:true, Files:0, dirs:0, totalFileSize:0 B, free space: 68.2 GB, files on device: -1) - Map render theme path: - PersistedDocumentUris: #1 - TRACK: null - Persisted Uri Permissions: #3 - content://com.android.externalstorage.documents/tree/primary%3ADownload (Mar 22, 2:58 PM):RW - content://com.android.externalstorage.documents/tree/primary%3Acgeo (Mar 22, 2:58 PM):RW - content://com.android.externalstorage.documents/tree/primary%3Acgeo%2Fmaps (Mar 22, 2:58 PM):RW - Database: /data/user/0/cgeo.geocaching/databases/data (v94, Size:8.0 MB) on system internal storage -Settings: v5, Count:133 --- End of system information --- ``` Log file (Relevant part): ``` 03-23 22:46:21.167 24499 25110 W cgeo : [AsyncTask #1] ContentStorage: Folder 'content://com.android.externalstorage.documents/tree/primary%3Acgeo%2Fmaps/document/primary%3Acgeo%2Fmaps)' could not be accessed 03-23 22:46:21.168 24499 25110 W cgeo : [AsyncTask #1] Could not show toast 'Folder '/cgeo/maps (User-defined)' could not be accessed' to user: java.lang.RuntimeException: Can't toast on a thread that has not called Looper.prepare() 03-23 22:46:21.171 24499 25110 W cgeo : [AsyncTask #1] ContentStorage: Files in Folder 'content://com.android.externalstorage.documents/tree/primary%3Acgeo%2Fmaps/document/primary%3Acgeo%2Fmaps)' could not be listed 03-23 22:46:21.171 24499 25110 W cgeo : java.io.IOException: Failed dir query for 'content://com.android.externalstorage.documents/tree/primary%3Acgeo%2Fmaps/document/primary%3Acgeo%2Fmaps' cols [document_id,_display_name,mime_type,last_modified,_size] 03-23 22:46:21.171 24499 25110 W cgeo : at cgeo.geocaching.storage.DocumentContentAccessor.queryDir(DocumentContentAccessor.java:382) 03-23 22:46:21.171 24499 25110 W cgeo : at cgeo.geocaching.storage.DocumentContentAccessor.listInternal(DocumentContentAccessor.java:203) 03-23 22:46:21.171 24499 25110 W cgeo : at cgeo.geocaching.storage.DocumentContentAccessor.list(DocumentContentAccessor.java:185) 03-23 22:46:21.171 24499 25110 W cgeo : at cgeo.geocaching.storage.ContentStorage.list(ContentStorage.java:213) 03-23 22:46:21.171 24499 25110 W cgeo : at cgeo.geocaching.storage.ContentStorage.list(ContentStorage.java:203) 03-23 22:46:21.171 24499 25110 W cgeo : at cgeo.geocaching.storage.FolderUtils.treeWalk(FolderUtils.java:789) 03-23 22:46:21.171 24499 25110 W cgeo : at cgeo.geocaching.storage.FolderUtils.treeWalk(FolderUtils.java:785) 03-23 22:46:21.171 24499 25110 W cgeo : at cgeo.geocaching.storage.FolderUtils.getFolderInfo(FolderUtils.java:153) 03-23 22:46:21.171 24499 25110 W cgeo : at cgeo.geocaching.utils.SystemInformation.appendPublicFolders(SystemInformation.java:172) 03-23 22:46:21.171 24499 25110 W cgeo : at cgeo.geocaching.utils.SystemInformation.getSystemInformation(SystemInformation.java:120) 03-23 22:46:21.171 24499 25110 W cgeo : at cgeo.geocaching.AboutActivity$GatherSystemInformationTask.doInBackground(AboutActivity.java:342) 03-23 22:46:21.171 24499 25110 W cgeo : at cgeo.geocaching.AboutActivity$GatherSystemInformationTask.doInBackground(AboutActivity.java:316) 03-23 22:46:21.171 24499 25110 W cgeo : at android.os.AsyncTask$3.call(AsyncTask.java:378) 03-23 22:46:21.171 24499 25110 W cgeo : at java.util.concurrent.FutureTask.run(FutureTask.java:266) 03-23 22:46:21.171 24499 25110 W cgeo : at android.os.AsyncTask$SerialExecutor$1.run(AsyncTask.java:289) 03-23 22:46:21.171 24499 25110 W cgeo : at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1167) 03-23 22:46:21.171 24499 25110 W cgeo : at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:641) 03-23 22:46:21.171 24499 25110 W cgeo : at java.lang.Thread.run(Thread.java:919) 03-23 22:46:21.171 24499 25110 W cgeo : Caused by: java.lang.NullPointerException: Attempt to invoke interface method 'boolean android.database.Cursor.moveToNext()' on a null object reference 03-23 22:46:21.171 24499 25110 W cgeo : at cgeo.geocaching.storage.DocumentContentAccessor.queryDir(DocumentContentAccessor.java:371) 03-23 22:46:21.171 24499 25110 W cgeo : ... 17 more 03-23 22:46:21.171 24499 25110 W cgeo : [AsyncTask #1] Could not show toast 'Files in Folder '/cgeo/maps' could not be listed' to user: java.lang.RuntimeException: Can't toast on a thread that has not called Looper.prepare() 03-23 22:46:21.278 24499 24610 D OpenGLRenderer: endAllActiveAnimators on 0x713a66d600 (MenuPopupWindow$MenuDropDownListView) with handle 0x713a0f5b20 03-23 22:46:21.581 24499 25110 W BpBinder: Slow Binder: BpBinder transact took 359 ms, interface=android.content.IContentProvider, code=21 oneway=false 03-23 22:46:21.609 24499 24499 D ViewRootImpl: [TouchInput][ViewRootImpl] KeyEvent { action=ACTION_DOWN, keyCode=KEYCODE_BACK, scanCode=0, metaState=0, flags=0x48, repeatCount=0, eventTime=363070915, downTime=363070915, deviceId=-1, source=0x101, displayId=-1 } 03-23 22:46:21.696 24499 24499 D ViewRootImpl: [TouchInput][ViewRootImpl] KeyEvent { action=ACTION_UP, keyCode=KEYCODE_BACK, scanCode=0, metaState=0, flags=0x48, repeatCount=0, eventTime=363071005, downTime=363070915, deviceId=-1, source=0x101, displayId=-1 } 03-23 22:46:21.731 24499 24514 W System : A resource failed to call close. 03-23 22:46:21.732 24499 24514 I chatty : uid=10257(cgeo.geocaching) FinalizerDaemon identical 4 lines 03-23 22:46:21.732 24499 24514 W System : A resource failed to call close. 03-23 22:46:21.745 24499 24499 D ForceDarkHelper: updateByCheckExcludeList: pkg: cgeo.geocaching activity: cgeo.geocaching.MainActivity@67e8e7d 03-23 22:46:23.955 24499 24610 D OpenGLRenderer: endAllActiveAnimators on 0x713a492400 (MenuPopupWindow$MenuDropDownListView) with handle 0x71abe036e0 03-23 22:46:34.756 24499 24579 I cgeo : [RxCachedThreadScheduler-1] [LogCat]Issuing command: [logcat, -d, *:V, -f, /data/user/0/cgeo.geocaching/cache/cgeo_tempfile_1183711118194179075.tmp] 03-23 22:46:34.781 24499 24610 D OpenGLRenderer: endAllActiveAnimators on 0x71a7706500 (RippleDrawable) with handle 0x71ab20fec0 03-23 22:46:35.154 24499 24499 W cgeo : [main] ContentStorage: Folder 'content://com.android.externalstorage.documents/tree/primary%3Acgeo%2Fmaps/document/primary%3Acgeo%2Fmaps)' could not be accessed 03-23 22:46:35.172 24499 24499 W cgeo : [main] ContentStorage: Files in Folder 'content://com.android.externalstorage.documents/tree/primary%3Acgeo%2Fmaps/document/primary%3Acgeo%2Fmaps)' could not be listed 03-23 22:46:35.172 24499 24499 W cgeo : java.io.IOException: Failed dir query for 'content://com.android.externalstorage.documents/tree/primary%3Acgeo%2Fmaps/document/primary%3Acgeo%2Fmaps' cols [document_id,_display_name,mime_type,last_modified,_size] 03-23 22:46:35.172 24499 24499 W cgeo : at cgeo.geocaching.storage.DocumentContentAccessor.queryDir(DocumentContentAccessor.java:382) 03-23 22:46:35.172 24499 24499 W cgeo : at cgeo.geocaching.storage.DocumentContentAccessor.listInternal(DocumentContentAccessor.java:203) 03-23 22:46:35.172 24499 24499 W cgeo : at cgeo.geocaching.storage.DocumentContentAccessor.list(DocumentContentAccessor.java:185) 03-23 22:46:35.172 24499 24499 W cgeo : at cgeo.geocaching.storage.ContentStorage.list(ContentStorage.java:213) 03-23 22:46:35.172 24499 24499 W cgeo : at cgeo.geocaching.storage.ContentStorage.list(ContentStorage.java:203) 03-23 22:46:35.172 24499 24499 W cgeo : at cgeo.geocaching.storage.FolderUtils.treeWalk(FolderUtils.java:789) 03-23 22:46:35.172 24499 24499 W cgeo : at cgeo.geocaching.storage.FolderUtils.treeWalk(FolderUtils.java:785) 03-23 22:46:35.172 24499 24499 W cgeo : at cgeo.geocaching.storage.FolderUtils.getFolderInfo(FolderUtils.java:153) 03-23 22:46:35.172 24499 24499 W cgeo : at cgeo.geocaching.utils.SystemInformation.appendPublicFolders(SystemInformation.java:172) 03-23 22:46:35.172 24499 24499 W cgeo : at cgeo.geocaching.utils.SystemInformation.getSystemInformation(SystemInformation.java:120) 03-23 22:46:35.172 24499 24499 W cgeo : at cgeo.geocaching.utils.DebugUtils.shareLogfileAsEmail(DebugUtils.java:136) 03-23 22:46:35.172 24499 24499 W cgeo : at cgeo.geocaching.utils.DebugUtils.lambda$createLogcatHelper$6(DebugUtils.java:122) 03-23 22:46:35.172 24499 24499 W cgeo : at cgeo.geocaching.utils.-$$Lambda$DebugUtils$70tQoPSzV8SqzTPVUwruW9XuKL0.run(Unknown Source:8) 03-23 22:46:35.172 24499 24499 W cgeo : at io.reactivex.rxjava3.android.schedulers.HandlerScheduler$ScheduledRunnable.run(HandlerScheduler.java:123) 03-23 22:46:35.172 24499 24499 W cgeo : at android.os.Handler.handleCallback(Handler.java:883) 03-23 22:46:35.172 24499 24499 W cgeo : at android.os.Handler.dispatchMessage(Handler.java:100) 03-23 22:46:35.172 24499 24499 W cgeo : at android.os.Looper.loop(Looper.java:224) 03-23 22:46:35.172 24499 24499 W cgeo : at android.app.ActivityThread.main(ActivityThread.java:7562) 03-23 22:46:35.172 24499 24499 W cgeo : at java.lang.reflect.Method.invoke(Native Method) 03-23 22:46:35.172 24499 24499 W cgeo : at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:539) 03-23 22:46:35.172 24499 24499 W cgeo : at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:950) 03-23 22:46:35.172 24499 24499 W cgeo : Caused by: java.lang.NullPointerException: Attempt to invoke interface method 'boolean android.database.Cursor.moveToNext()' on a null object reference 03-23 22:46:35.172 24499 24499 W cgeo : at cgeo.geocaching.storage.DocumentContentAccessor.queryDir(DocumentContentAccessor.java:371) 03-23 22:46:35.172 24499 24499 W cgeo : ... 20 more 03-23 22:46:35.267 24499 24499 I Timeline: Timeline: Activity_launch_request time:363084578 ```"
475314,528251,https://api.github.com/repos/vorov2/dyalect/issues/430,bug,2021-04-27T08:47:52Z,OWNER,https://api.github.com/repos/vorov2/dyalect,"Crush when calling a function The following code causes Dy to crush: ```swift func pars(x, y) { print(""x=\(x),y=\(y)"") } pars(y: 2, 1) ```"
421521,468554,https://api.github.com/repos/CovidTrackerFr/vitemadose/issues/252,bug,2021-04-26T07:13:56Z,NONE,https://api.github.com/repos/CovidTrackerFr/vitemadose,"Centre de vaccination 75015 qui ne remonte pas Centre concerné : Centre de Vaccination Covid Paris 15 - 31 Rue Peclet, 75015 Paris Sur l'url (https://partners.doctolib.fr/centre-de-sante/paris/centre-de-vaccination-covid-paris-15e) dont nous disposons (partners) il n'y a pas de rendez-vous disponible : ![image](https://user-images.githubusercontent.com/82476476/116042961-599d6500-a66f-11eb-9d7b-ff6a229539ab.png) Pourtant, via l'url publique (https://www.doctolib.fr/centre-de-sante/paris/centre-de-vaccination-covid-ville-de-paris-mairie-du-15e-creneaux-dedies) il semble y avoir de nombreux rendez-vous disponibles dès aujourd'hui. ![image](https://user-images.githubusercontent.com/82476476/116043150-94070200-a66f-11eb-8e11-5dfada4739ea.png)"
183639,204155,https://api.github.com/repos/2-young-2-simple/VirtualApp/issues/14,bug,2021-03-22T10:00:59Z,NONE,https://api.github.com/repos/2-young-2-simple/VirtualApp,"Android 8/9 上运行部分 App 出现 JNI 返回类型错误 JNI DETECTED ERROR IN APPLICATION: the return type of CallVoidMethodA does not match void android.view.IWindowManager.getInitialDisplaySize(int, android.graphics.Point) native: #00 pc 002e0f83 /system/lib/libart.so (offset 1a6000) (art::DumpNativeStack(std::__1::basic_ostream<char, std::__1::char_traits<char>>&, int, BacktraceMap*, char const*, art::ArtMethod*, void*, bool)+134) 2021-03-22 17:29:50.213 10858-11112/com.carrot.iceworld A/.busniess.va:p: java_vm_ext.cc:542] native: #01 pc 00378ba3 /system/lib/libart.so (offset 1a6000) (art::Thread::DumpStack(std::__1::basic_ostream<char, std::__1::char_traits<char>>&, bool, BacktraceMap*, bool) const+210) 2021-03-22 17:29:50.213 10858-11112/com.carrot.iceworld A/.busniess.va:p: java_vm_ext.cc:542] native: #02 pc 003751bf /system/lib/libart.so (offset 1a6000) (art::Thread::Dump(std::__1::basic_ostream<char, std::__1::char_traits<char>>&, bool, BacktraceMap*, bool) const+34) 2021-03-22 17:29:50.213 10858-11112/com.carrot.iceworld A/.busniess.va:p: java_vm_ext.cc:542] native: #03 pc 00235da9 /system/lib/libart.so (offset 1a6000) (art::JavaVMExt::JniAbort(char const*, char const*)+720) 2021-03-22 17:29:50.213 10858-11112/com.carrot.iceworld A/.busniess.va:p: java_vm_ext.cc:542] native: #04 pc 0023610f /system/lib/libart.so (offset 1a6000) (art::JavaVMExt::JniAbortV(char const*, char const*, std::__va_list)+58) 2021-03-22 17:29:50.213 10858-11112/com.carrot.iceworld A/.busniess.va:p: java_vm_ext.cc:542] native: #05 pc 000c4e89 /system/lib/libart.so (art::(anonymous namespace)::ScopedCheck::AbortF(char const*, ...)+48) 2021-03-22 17:29:50.213 10858-11112/com.carrot.iceworld A/.busniess.va:p: java_vm_ext.cc:542] native: #06 pc 000c7c97 /system/lib/libart.so (art::(anonymous namespace)::ScopedCheck::CheckMethodAndSig(art::ScopedObjectAccess&, _jobject*, _jclass*, _jmethodID*, art::Primitive::Type, art::InvokeType)+514) 2021-03-22 17:29:50.213 10858-11112/com.carrot.iceworld A/.busniess.va:p: java_vm_ext.cc:542] native: #07 pc 000c82cf /system/lib/libart.so (art::(anonymous namespace)::CheckJNI::CallMethodA(char const*, _JNIEnv*, _jobject*, _jclass*, _jmethodID*, jvalue*, art::Primitive::Type, art::InvokeType)+566) 2021-03-22 17:29:50.213 10858-11112/com.carrot.iceworld A/.busniess.va:p: java_vm_ext.cc:542] native: #08 pc 000b8095 /system/lib/libart.so (art::(anonymous namespace)::CheckJNI::CallVoidMethodA(_JNIEnv*, _jobject*, _jmethodID*, jvalue*)+44)"
162523,180708,https://api.github.com/repos/espnet/espnet/issues/3097,question,2021-03-22T04:58:38Z,NONE,https://api.github.com/repos/espnet/espnet,"using arpabet during inference Hi I was wondering if it's possible to use arpabet or cmu symnols during inference so that we can control the pronunciations of different words? for example. Does the g2p_en model supports this I tried this in the inference notebook but the model still produce {HH AW1 S S T AH0 N} as individual letters ``` x= 'Turn left on {HH AW1 S S T AH0 N} Street.' # synthesis with torch.no_grad(): start = time.time() wav, c, *_ = text2speech(x) wav = vocoder.inference(c) rtf = (time.time() - start) / (len(wav) / fs) print(f""RTF = {rtf:5f}"") # let us listen to generated samples from IPython.display import display, Audio display(Audio(wav.view(-1).cpu().numpy(), rate=fs)) ```"
461488,512882,https://api.github.com/repos/Dzemoro/Project_PT/issues/9,bug,2021-05-06T18:00:25Z,OWNER,https://api.github.com/repos/Dzemoro/Project_PT,"Add the missing field to the ""Measurements"" table Add wireLenght field to the ""Measurements"" table."
417189,463730,https://api.github.com/repos/tachiyomiorg/tachiyomi-extensions/issues/5338,bug,2021-01-07T01:41:08Z,NONE,https://api.github.com/repos/tachiyomiorg/tachiyomi-extensions,"[Bug] MangaDex: ID lookup failing ## Device information - Tachiyomi version: 0.10.7 - Android version: 10 ## Source information - Name: MangaDex - Extension version: 1.2.98 ## Steps to reproduce 1. In Sources, enter the MangaDex source 2. (Might not actually be necessary) Open webview and ensure you are logged in to MangaDex to enable search 3. Search for ""id:<some_known_manga_id>"" (e.g. ""id:48045"") ### Expected behavior Search results should return only one entry. (In the above example, ""Sousou no Frieren"") ### Actual behavior Error message: 'manga' is not found"
592542,658524,https://api.github.com/repos/Clinical-Genomics/MIP/issues/1727,enhancement,2020-11-25T08:16:21Z,COLLABORATOR,https://api.github.com/repos/Clinical-Genomics/MIP,Log data from mip's gender check MIP does a gender check on wgs samples with unknown gender. Right now only the result of that check is logged (i.e. male/female). It would be useful to alos log the some of the data underlying that decision. 
254448,283015,https://api.github.com/repos/riogod/jintV2/issues/1,enhancement,2021-03-06T16:55:50Z,OWNER,https://api.github.com/repos/riogod/jintV2,Первоначальная настройка frontend части приложения - [x] создать структуру - [x] Добавить моки для фронта - [x] Установить Storybook
15002,16720,https://api.github.com/repos/karaoke-dev/karaoke/issues/396,bug,2021-01-10T09:23:58Z,MEMBER,https://api.github.com/repos/karaoke-dev/karaoke,"Cause error if move lyric time. ![image](https://user-images.githubusercontent.com/9100368/104119101-bdc24480-5370-11eb-88b5-a8f17f150462.png) Cause error if move lyric time in editor. Not really sure why but seems need to be fixed. Call sack : ``` at osu.Game.Rulesets.Karaoke.UI.Components.SaitenVisualization.Add(KaraokeReplayFrame frame) in F:\Github\osu-Karaoke\osu-Karaoke-release\osu.Game.Rulesets.Karaoke\UI\Components\SaitenVisualization.cs:line 108 at osu.Game.Rulesets.Karaoke.UI.NotePlayfield.AddReplay(KaraokeReplayFrame frame) in F:\Github\osu-Karaoke\osu-Karaoke-release\osu.Game.Rulesets.Karaoke\UI\NotePlayfield.cs:line 259 at osu.Game.Rulesets.Karaoke.Mods.KaraokeModAutoplay.ApplyToDrawableRuleset(DrawableRuleset`1 drawableRuleset) in F:\Github\osu-Karaoke\osu-Karaoke-release\osu.Game.Rulesets.Karaoke\Mods\KaraokeModAutoplay.cs:line 42 at osu.Game.Rulesets.UI.DrawableRuleset`1.applyRulesetMods(IReadOnlyList`1 mods, OsuConfigManager config) at osu.Game.Rulesets.UI.DrawableRuleset`1.RegenerateAutoplay() at osu.Game.Rulesets.Edit.DrawableEditRulesetWrapper`1.updateReplay() at osu.Game.Screens.Edit.EditorChangeHandler.UpdateState() at osu.Game.Screens.Edit.TransactionalCommitComponent.EndChange() at osu.Game.Screens.Edit.Compose.Components.BlueprintContainer.OnDragEnd(DragEndEvent e) at osu.Game.Screens.Edit.Compose.Components.Timeline.TimelineBlueprintContainer.OnDragEnd(DragEndEvent e) at osu.Framework.Graphics.Drawable.TriggerEvent(UIEvent e) at System.Linq.Enumerable.TryGetFirst[TSource](IEnumerable`1 source, Func`2 predicate, Boolean& found) at osu.Framework.Input.ButtonEventManager`1.PropagateButtonEvent(IEnumerable`1 drawables, UIEvent e) at osu.Framework.Input.MouseButtonEventManager.handleDragEnd(InputState state) at osu.Framework.Input.MouseButtonEventManager.HandleButtonUp(InputState state, List`1 targets) at osu.Framework.Input.ButtonEventManager`1.handleButtonUp(InputState state) at osu.Framework.Input.ButtonEventManager`1.HandleButtonStateChange(InputState state, ButtonStateChangeKind kind) at osu.Framework.Input.InputManager.HandleMouseButtonStateChange(ButtonStateChangeEvent`1 e) at osu.Framework.Input.StateChanges.ButtonInput`1.Apply(InputState state, IInputStateChangeHandler handler) at osu.Framework.Input.PassThroughInputManager.Handle(UIEvent e) at osu.Framework.Graphics.Drawable.OnMouseUp(MouseUpEvent e) at osu.Framework.Graphics.Drawable.TriggerEvent(UIEvent e) at System.Linq.Enumerable.TryGetFirst[TSource](IEnumerable`1 source, Func`2 predicate, Boolean& found) at osu.Framework.Input.ButtonEventManager`1.PropagateButtonEvent(IEnumerable`1 drawables, UIEvent e) at osu.Framework.Input.MouseButtonEventManager.HandleButtonUp(InputState state, List`1 targets) at osu.Framework.Input.ButtonEventManager`1.handleButtonUp(InputState state) at osu.Framework.Input.ButtonEventManager`1.HandleButtonStateChange(InputState state, ButtonStateChangeKind kind) at osu.Framework.Input.InputManager.HandleMouseButtonStateChange(ButtonStateChangeEvent`1 e) at osu.Framework.Input.UserInputManager.HandleInputStateChange(InputStateChangeEvent inputStateChange) at osu.Framework.Input.StateChanges.ButtonInput`1.Apply(InputState state, IInputStateChangeHandler handler) at osu.Framework.Input.InputManager.Update() at osu.Framework.Input.PassThroughInputManager.Update() at osu.Framework.Graphics.Drawable.UpdateSubTree() at osu.Framework.Graphics.Containers.CompositeDrawable.UpdateSubTree() at osu.Framework.Platform.GameHost.UpdateFrame() at osu.Framework.Threading.GameThread.ProcessFrame() ```"
24349,27116,https://api.github.com/repos/vtereshkov/umka-lang/issues/57,question,2021-04-02T22:15:09Z,CONTRIBUTOR,https://api.github.com/repos/vtereshkov/umka-lang,"Struct values corruption I'm passing 2 vector structs defined like this: ``` type ( vec3* = struct {x, y, z: real32} ) ``` In a function defined like this: ``` fn CreateSphere *(pos, clr: vec3, rv, rd: real): int32 ``` The call looks like this: ``` head := r8.CreateSphere(r8.vec3{0.1, 0.2, 0.3}, r8.vec3{0.4, 0.5, 0.6}, 0.7, 0.8) ``` The func bind in C: ```c void umCreateSphere(UmkaStackSlot* p, UmkaStackSlot* r) { vec3* pos = (vec3*)&p[3]; vec3* clr = (vec3*)&p[2]; float rv = (float) p[1].realVal; float rd = (float) p[0].realVal; printf(""%.1f, %.1f, %.1f, %.1f, %.1f, %.1f, %.1f, %.1f\n"", pos->x, pos->y, pos->z, clr->x, clr->y, clr->z, rv, rd); int i = createSphere(*pos, *clr, rv, rd); r[0].intVal = i; } ``` C vector struct definition: ```c typedef struct { float x, y, z; } vec3; ``` I would expect the printf to output to be `0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8` but the output is `0.6, 0.0, 0.1, 0.4, 0.5, 0.6, 0.7, 0.8` Only the position vector gets corrupted. The code is from [here](https://github.com/ProkopRandacek/r8/tree/9d87afbca6f71f6fc49c41f2b4359306bad27b76) `src/umka/bindings.c`, `src/vector.h`, `scripts/game.um`, `scripts/r8/r8.um`"
103151,114631,https://api.github.com/repos/APSIMInitiative/APSIMClassic/issues/2032,question,2021-04-09T02:16:57Z,MEMBER,https://api.github.com/repos/APSIMInitiative/APSIMClassic,"Invoking 'add_surfaceom' from Manager2 with AddSurfaceOMType Is there any way we can invoke **add_surfaceom** from a Manager2 using **SurfaceOrganicMatterType**? I wrote this and dont get an exception, but I am not sure: ``` AddSurfaceOMType SomType = new AddSurfaceOMType(); SomType.name = ""millmud""; SomType.type = ""millmud""; SomType.mass = (float)millmud_p; SomType.cnr = 22; MySimulation.Publish(""add_surfaceom"", SomType); ```"
88078,97897,https://api.github.com/repos/NVIDIA/spark-rapids/issues/1973,bug,2021-03-19T11:13:06Z,COLLABORATOR,https://api.github.com/repos/NVIDIA/spark-rapids,"[BUG] generate_expr_test FAILED on Dataproc Cluster 18:58:05 ----------------------------- Captured stdout call ----------------------------- 18:58:05 ### CPU RUN ### 18:58:05 ### GPU RUN ### 18:58:05 [31m[1m_______________ test_posexplode_nested_array_data[Decimal(12,2)] _______________[0m 18:58:05 18:58:05 spark_tmp_path = '/tmp/pyspark_tests//653163/' 18:58:05 data_gen = [Integer, Array(Array(Decimal(12,2)))] 18:58:05 18:58:05 [37m@ignore_order[39;49;00m(local=[94mTrue[39;49;00m) 18:58:05 [37m@pytest[39;49;00m.mark.parametrize([33m'[39;49;00m[33mdata_gen[39;49;00m[33m'[39;49;00m, all_gen, ids=idfn) 18:58:05 [94mdef[39;49;00m [92mtest_posexplode_nested_array_data[39;49;00m(spark_tmp_path, data_gen): 18:58:05 data_gen = [int_gen, ArrayGen(ArrayGen(data_gen))] 18:58:05 > assert_gpu_and_cpu_are_equal_collect( 18:58:05 [94mlambda[39;49;00m spark: two_col_df(spark, *data_gen).selectExpr( 18:58:05 [33m'[39;49;00m[33ma[39;49;00m[33m'[39;49;00m, [33m'[39;49;00m[33mposexplode(b) as (pos, c)[39;49;00m[33m'[39;49;00m).selectExpr([33m'[39;49;00m[33ma[39;49;00m[33m'[39;49;00m, [33m'[39;49;00m[33mpos[39;49;00m[33m'[39;49;00m, [33m'[39;49;00m[33mposexplode(c)[39;49;00m[33m'[39;49;00m), 18:58:05 conf=conf_to_enforce_split_input) 18:58:05 18:58:05 [1m[31m/home/root/integration_tests/src/main/python/generate_expr_test.py[0m:107: 18:58:05 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 18:58:05 [1m[31m/home/root/integration_tests/src/main/python/asserts.py[0m:341: in assert_gpu_and_cpu_are_equal_collect 18:58:05 _assert_gpu_and_cpu_are_equal(func, [33m'[39;49;00m[33mCOLLECT[39;49;00m[33m'[39;49;00m, conf=conf) 18:58:05 [1m[31m/home/root/integration_tests/src/main/python/asserts.py[0m:324: in _assert_gpu_and_cpu_are_equal 18:58:05 from_gpu = with_gpu_session(bring_back, 18:58:05 [1m[31m/home/root/integration_tests/src/main/python/spark_session.py[0m:95: in with_gpu_session 18:58:05 [94mreturn[39;49;00m with_spark_session(func, conf=copy) 18:58:05 [1m[31m/home/root/integration_tests/src/main/python/spark_session.py[0m:68: in with_spark_session 18:58:05 ret = func(_spark) 18:58:05 [1m[31m/home/root/integration_tests/src/main/python/asserts.py[0m:178: in <lambda> 18:58:05 bring_back = [94mlambda[39;49;00m spark: limit_func(spark).collect() 18:58:05 [1m[31m/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1616146249773_0001/container_e01_1616146249773_0001_01_000001/pyspark.zip/pyspark/sql/dataframe.py[0m:677: in collect 18:58:05 sock_info = [96mself[39;49;00m._jdf.collectToPython() 18:58:05 [1m[31m/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1616146249773_0001/container_e01_1616146249773_0001_01_000001/py4j-0.10.9-src.zip/py4j/java_gateway.py[0m:1304: in __call__ 18:58:05 return_value = get_return_value( 18:58:05 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 18:58:05 18:58:05 a = ('xro416609', <py4j.java_gateway.GatewayClient object at 0x7f229797c250>, 'o416608', 'collectToPython') 18:58:05 kw = {} 18:58:05 converted = IllegalArgumentException('Part of the plan is not columnar class org.apache.spark.sql.execution.FilterExec\nFilter ((s...:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n', None) 18:58:05 18:58:05 [94mdef[39;49;00m [92mdeco[39;49;00m(*a, **kw): 18:58:05 [94mtry[39;49;00m: 18:58:05 [94mreturn[39;49;00m f(*a, **kw) 18:58:05 [94mexcept[39;49;00m py4j.protocol.Py4JJavaError [94mas[39;49;00m e: 18:58:05 converted = convert_exception(e.java_exception) 18:58:05 [94mif[39;49;00m [95mnot[39;49;00m [96misinstance[39;49;00m(converted, UnknownException): 18:58:05 [90m# Hide where the exception came from that shows a non-Pythonic[39;49;00m 18:58:05 [90m# JVM exception message.[39;49;00m 18:58:05 > [94mraise[39;49;00m converted [94mfrom[39;49;00m [96mNone[39;49;00m 18:58:05 [1m[31mE pyspark.sql.utils.IllegalArgumentException: Part of the plan is not columnar class org.apache.spark.sql.execution.FilterExec[0m 18:58:05 [1m[31mE Filter ((size(c#219594, true) > 0) AND isnotnull(c#219594))[0m 18:58:05 [1m[31mE +- GpuColumnarToRow false[0m 18:58:05 [1m[31mE +- GpuGenerate gpuposexplode(b#219590), [a#219589], false, [pos#219593, c#219594][0m 18:58:05 [1m[31mE +- GpuRowToColumnar TargetSize(8192)[0m 18:58:05 [1m[31mE +- Filter ((size(b#219590, true) > 0) AND isnotnull(b#219590))[0m 18:58:05 [1m[31mE +- Scan ExistingRDD[a#219589,b#219590][0m 18:58:05 18:58:05 [1m[31m/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1616146249773_0001/container_e01_1616146249773_0001_01_000001/pyspark.zip/pyspark/sql/utils.py[0m:117: IllegalArgumentException 18:58:05 ----------------------------- Captured stdout call -----------------------------"
165236,183710,https://api.github.com/repos/yarnpkg/berry/issues/2839,bug,2021-05-04T08:40:37Z,NONE,https://api.github.com/repos/yarnpkg/berry,"[Bug] tsc can't find @types/... packages that are dependencies of the worktree root - [X] I'd be willing to implement a fix **Describe the bug** When compiling a workspace, typescript seems not to be able to find type definitions (i.e. @types/...) that are dependencies of the worktree root (i.e. that are declared in the `package.json` of the top-level package). I'm not sure if this behavior is intended or not but it is at least a breaking change from 2.0.0-rc1 (which is, of course, very many versions ago - I recently upgraded after fixing a long-lasting blocker). **To Reproduce** (would've used Sherlock but it doesn't look like the API exposes anything to do with workspaces) 1. clone repo [here](https://github.com/mprast/yarn-workspace-types-repro) and go to repo root 2. `yarn install` 3. `yarn run tsc -b packages/test` - should result in: ``` packages/test/src/index.ts:1:21 - error TS2307: Cannot find module 'fs' or its corresponding type declarations. 1 import * as fs from ""fs""; ~~~~ Found 1 error. ``` 4. `yarn remove @types/node` 5. `cd packages/test` 6. `yarn add @types/node` 7. `cd ../..` 8. `yarn run tsc -b packages/test` - should complete successfully, writing nothing to stdout 9. `ls packages/test/lib` - should return `index.d.ts` and `index.js` Expected behavior - I would expect `tsc` to run successfully both times. **Environment if relevant (please complete the following information):** - OS: Fedora - Node version: 10.19.0 - Yarn version 2.4.1 **Additional context** Again, not sure if this technically a bug or not, but I would expect all workspaces to be able to see types at the worktree root since that's how non-type dependencies behave (I think - I couldn't find anything in the docs that specified either how root package dependencies used to work or how they work now. I can verify that this was the behavior as of 2.0.0-rc of course). In any case, it would be really great to have a way for workspaces to inherit types, even if it's not via the workspace root anymore - we have many workspaces (> 50) and until now were using this mechanism to provide types most or all of them needed, e.g. `@types/jasmine` and `@types/node`. Thanks a ton for your help!"
332513,369667,https://api.github.com/repos/pgaudit/pgaudit/issues/128,enhancement,2020-11-27T09:25:52Z,NONE,https://api.github.com/repos/pgaudit/pgaudit,"The value in the COMMAND column of session audit log is not ""COPY"" after executed copy command. Hello, when I use pgaudit to output the session audit log, I encountered the following problem: step-1: set pgaudit.log='read, write'; step-2: set pgaudit.log_relation=on; step-3: copy tb01 to '/home/postgres/data.txt'; AUDIT: SESSION,1,1,READ,SELECT,TABLE,public.tb01,… step-4: copy tb01 from '/home/postgres/data.txt'; AUDIT: SESSION,2,1,WRITE,INSERT,TABLE,public.tb01,… I think the COMMAND column should be ""COPY"". In fact, step-3 is ""SELECT"", step-4 is ""INSERT"". But when pgaudit.log_relation is off, ""COPY"" is outputted. step-2: set pgaudit.log_relation=off; step-3: copy tb01 to '/home/postgres/data.txt'; AUDIT: SESSION,3,1,READ,COPY,… step-4: copy tb01 from '/home/postgres/data.txt'; AUDIT: SESSION,4,1,WRITE,COPY,… "
161229,179252,https://api.github.com/repos/fbergmann/libSEDML/issues/84,enhancement,2020-11-17T00:00:33Z,COLLABORATOR,https://api.github.com/repos/fbergmann/libSEDML,"Add 'name' to SedBase. Functions for metaid and id are present in SedBase, but not 'name'."
385369,428379,https://api.github.com/repos/TheSuperGamer20578/Sudan-bot/issues/114,enhancement,2021-01-30T04:26:00Z,NONE,https://api.github.com/repos/TheSuperGamer20578/Sudan-bot,allow anyone to use /close Imported from jira SDB-77 Created by: ogx In server: kraftier
463958,515615,https://api.github.com/repos/ossia/score/issues/540,enhancement,2017-06-22T08:48:56Z,MEMBER,https://api.github.com/repos/ossia/score,"color scheme issues this is to be discussed with @stirem we have to address: - [ ] progress ""bar"" (which is green on cyan, hence not so visible...) @blacksound was proposing using strong color contrasts - [ ] color-blindness please feel free to add, @jln- @lossius and others"
165898,184447,https://api.github.com/repos/ita-social-projects/what-front/issues/260,enhancement,2020-12-15T14:32:39Z,CONTRIBUTOR,https://api.github.com/repos/ita-social-projects/what-front,Validation refactoring Create unified validation helpers: - email; - first name; - last name; - group name; - course name; - date validation;
623307,692688,https://api.github.com/repos/dedica-team/nivio/issues/63,question,2019-11-28T05:28:14Z,COLLABORATOR,https://api.github.com/repos/dedica-team/nivio,Investigate graph DB inclusion * allows to use all graph db features on a landscape * https://neo4j.com/docs/java-reference/current/tutorials-java-embedded/include-neo4j/ * https://orientdb.com/docs/last/Memory-storage.html
226730,252154,https://api.github.com/repos/deislabs/akri/issues/199,enhancement,2021-01-12T18:55:05Z,CONTRIBUTOR,https://api.github.com/repos/deislabs/akri,Naming guidelines **Is your feature request related to a problem? Please describe.** Naming guidelines would be useful if documented if desired. For example: + `akri-agent-daemonset` + `akri-controller-deployment` Is this guidance `akri-[THING]-[TYPE]`? It is a common pattern with Kubernetes but I find it overwrought since these objects all have Kinds (and Labels) and e.g.: `kubectl get deployment/akri-controller-deployment` is redundant and leads to lengthy names **Is your feature request related to a way you would like Akri extended? Please describe.** **Describe the solution you'd like** Definitive naming guidelines **Describe alternatives you've considered** **Additional context** Add any other context or screenshots about the feature request here. 
682442,758467,https://api.github.com/repos/primefaces/primereact/issues/1817,enhancement,2021-02-16T13:31:09Z,MEMBER,https://api.github.com/repos/primefaces/primereact,Improve checkbox selection on DataTable Remove hidden input element as in primevue
372611,414215,https://api.github.com/repos/Qiskit/qiskit-metal/issues/439,bug,2021-03-24T18:35:40Z,COLLABORATOR,https://api.github.com/repos/Qiskit/qiskit-metal,"Renderer options (for 'path') being added to all renderers in qgeom table <!-- ⚠️ Please abide by this template, otherwise you run the risk of the issue being closed --> <!-- ⚠️ Make sure to browse the opened and closed issues --> ### Information - **Qiskit Metal version**: - **Python version**: - **Operating system**: ### What is the current behavior? Renderer option in Ansys is getting added as a GDS option in the qgeometry tables ``` element_table_data = dict(path=dict(wire_bonds=False), junction=dict( inductance=default_options['Lj'], capacitance=default_options['Cj'], resistance=default_options['_Rj'], mesh_kw_jj=parse_units( default_options['max_mesh_length_jj']))) ``` ### Steps to reproduce the problem Branch 224_wirebondAnsys Add any component with paths, then look at design.qgeometry.tables['paths'] ### What is the expected behavior? Should only be adding hfss_wire_bonds and q3d_wire_bonds to the table ![Capture](https://user-images.githubusercontent.com/53087709/112365340-ea1e0980-8cad-11eb-8539-32cc46e5b9d5.PNG) ### Suggested solutions Suspect it is in the qgeometries_handler, not differentiating the renderers when defining the keys for the tables"
85056,94566,https://api.github.com/repos/aws-samples/amazon-chime-react-native-demo/issues/50,enhancement,2021-02-02T15:41:57Z,NONE,https://api.github.com/repos/aws-samples/amazon-chime-react-native-demo,"Chat component Hi all, I didn't find, and I'd like to understand/know if there is the possibility to have a chat embedded in a component for React-Native, similar to the AttendeeList. How to implement a chat component? Does the SDK have a method to be used from a component? All the best and thank you for the example "
309412,344022,https://api.github.com/repos/geocollections/EMA/issues/151,enhancement,2021-03-04T07:09:10Z,MEMBER,https://api.github.com/repos/geocollections/EMA,"Map ideas We could activate geological map layer for drillcore and locality views by default (if locality country is Estonia). But since the bedrock geological map is of lower resolution we should zoom out initial map view by 2 steps. Blue marker is not always well visible - better to use red color and open label by default. In drillcore view, the label should show locality name (Orjaku borehole) rather than core name (Orjaku drillcore). For site, bedrock map is not relevant and should not be activated by default (in future higher resolution quaternary cover map could be used). "
210758,234347,https://api.github.com/repos/kaist-plrg/jiset/issues/131,bug,2021-01-20T07:18:00Z,CONTRIBUTOR,https://api.github.com/repos/kaist-plrg/jiset,"Wrong extraction of `this` object name for `ModuleNamespaceExoticObject.Set` ``` ModuleNamespaceExoticObject.Set (P, P, V, Receiver): ... ``` Use `this` instead of `P` because no name assignment in this case."
80530,89524,https://api.github.com/repos/chainapsis/keplr-extension/issues/60,bug,2021-02-23T22:40:31Z,NONE,https://api.github.com/repos/chainapsis/keplr-extension,"Error when trying to interact with an account via the extension When I try to make transactions on `cosmoshub-4` with `cosmos1lcsjy2d5s33h0sddd8lpuqvwyz5ruz7jsfj43h`, I get `read property 'length' of undefined` on trying to send or withdraw rewards. "
604531,671828,https://api.github.com/repos/Azure/Industrial-IoT/issues/626,bug,2020-07-21T06:44:16Z,NONE,https://api.github.com/repos/Azure/Industrial-IoT,"TSI: Mismatch of Time Series ID Case **Describe the bug** The Time Series ID Properties has a case mismatch with the data that is being sent from the publisher. This causes all data to appear under the 'null' entry in TSI. In TSI the property is defined as `publisherId, dataSetWriterId, nodeId` The data is arriving `PublisherId, DataSetWriterId, NodeId` Additionally the Timestamp added to the Event Source `TimeStamp` does not exist. `SourceTimestamp` would appear to be more appropriate. This is on a fresh install of 2.170 release. **To Reproduce** Steps to reproduce the behavior: 1. Deploy the 2.170 Release 1. Publish data 1. Go to TSI to look at data **Expected behavior** The attributes are recognised as the property ids **Screenshots** ![image](https://user-images.githubusercontent.com/6579068/88021716-4d0f3d80-cb2e-11ea-9bc1-585a4a71a808.png) **Additional context** Add any other context about the problem here. "
223758,248837,https://api.github.com/repos/IgniteUI/igniteui-angular/issues/7681,bug,2020-06-25T09:53:51Z,CONTRIBUTOR,https://api.github.com/repos/IgniteUI/igniteui-angular,When use grid.columns getter the error is thrown in the console ## Description * browser: all ## Steps to reproduce 1. Open the following [sample](https://stackblitz.com/edit/angular-pskbsu) 2. Open the browser console #### Note the error is also reproducible in [Grid Hiding samples](https://github.com/IgniteUI/igniteui-angular-samples/issues/1205) ## Result ![image](https://user-images.githubusercontent.com/34240583/85696990-163a3900-b6e2-11ea-9b75-26ebcffaae32.png) ## Expected result No errors should be thrown in the console 
418931,465690,https://api.github.com/repos/craftercms/craftercms/issues/4547,enhancement,2021-02-26T22:04:06Z,MEMBER,https://api.github.com/repos/craftercms/craftercms,"[studio] Remove refresh tokens actions from audit log. ## Describe the bug Each time a refresh token happens an audit log entry is added. ## Expected behavior * Refresh tokens actions should be removed from audit log. * Token management actions(create, remove, enable) should be meaningful to the user in the Audit page, adding a new `Operation` type? ## Screenshots ![image](https://user-images.githubusercontent.com/6722074/109359955-f8fad300-784b-11eb-95cc-e5c637aa63ab.png) ## Logs N/A ## Specs ### Version `4.0.0-SNAPSHOT` ### OS Any ### Browser Any ## Additional context https://github.com/craftercms/craftercms/issues/4429 "
206347,229441,https://api.github.com/repos/rero/rero-ils/issues/1697,bug,2021-02-12T10:43:52Z,MEMBER,https://api.github.com/repos/rero/rero-ils,"2nd-level values of hierarchical facets are not always sorted according to their parent value **Describe the bug** A document can have a repetitive document type (main type + subtype). In this case, if it has 2 different main types, this generates a problem in the facet (see screenshot). Example: a document has the following main types/subtypes: `a/1` + `b/2`. If the main type `a` is selected in the facet, `1` is then proposed as sub-facet, but `2` is also proposed. **To Reproduce** 1. Create a document with two different main type, and two different subtypes 2. Save it 3. Do a search using the document type facet, and selecting one of the main type of this document. 4. See the subtypes proposed **Expected behavior** `2` should not be proposed as subfacet of `a`. **Context** * server: [ils.test.rero.ch][1] * version: `v1.0.0` [1]: https://ils.test.rero.ch **Screenshots** ""CD-Rom, DVD-Rom"" belongs to the main type ""Support électronique"". ![image](https://user-images.githubusercontent.com/8154915/107758054-a3d8a080-6d26-11eb-9755-e0c1d2413396.png)"
18400,20486,https://api.github.com/repos/SyneRBI/SIRF/issues/858,question,2021-02-01T08:34:49Z,CONTRIBUTOR,https://api.github.com/repos/SyneRBI/SIRF,Tag new patch version SIRF 2.2.1? Unittests with [CIL](https://github.com/vais-ral/CCPi-Framework) will fail because of a bug in SIRF's algebra methods in version 2.2.0. This is fixed in current master and I would suggest to tag master as 2.2.1 so that builds will be green again.
585409,650537,https://api.github.com/repos/agrosner/DBFlow/issues/1540,enhancement,2018-02-21T00:07:23Z,NONE,https://api.github.com/repos/agrosner/DBFlow,"Determine Primary Key Field Hi, I would like to know if its possible to determine which field is the primary key at runtime without having to add a custom runtime annotation. "
678067,753592,https://api.github.com/repos/abpframework/abp/issues/7315,question,2021-01-18T14:48:54Z,CONTRIBUTOR,https://api.github.com/repos/abpframework/abp,"Is it possible to change the tenant after login? Used separate identityserver4 and angular. In one application have multiple tenants. There is two or more users. All of them have same username, mail address, other infos, but have different tenantId. Is it possible to change the tenant after login? if it is ok how can i do it, can you give me some hints please "
558409,620609,https://api.github.com/repos/microsoft/vscode-jupyter/issues/5789,bug,2021-05-06T13:00:13Z,NONE,https://api.github.com/repos/microsoft/vscode-jupyter,"Notebook loses keyboard focus after switching tabs Unclear if this is related to #3954. Couldn't find other relevant issues ## Environment data - VS Code version: Version: 1.56.0 Commit: cfa2e218100323074ac1948c885448fdf4de2a7f Date: 2021-05-04T22:06:21.189Z (1 day ago) Electron: 12.0.4 Chrome: 89.0.4389.114 Node.js: 14.16.0 V8: 8.9.255.24-electron.0 OS: Darwin x64 20.4.0 - Jupyter Extension version (available under the Extensions sidebar): v2021.6.811652604 - Python Extension version (available under the Extensions sidebar): v2021.4.765268190 - macOS version: 11.3 (20E232) - Python and/or Anaconda version: Python 3.9.4 - Type of virtual environment used (N/A | venv | virtualenv | conda | ...): venv - Jupyter server running: Local ## Expected behaviour Keyboard inputs like up/down arrows, <kbd>a</kbd> or <kbd>b</kbd> to add a new cell, enter to edit, etc. should continue to work after switching to a different tab in VS Code and then back to a Jupyter notebook. ## Actual behaviour After switching from a Jupyter notebook to a different tab in VS Code and then back, all keyboard input to the Jupyter notebook tab seems to stop working. Clicking on something in the notebook restores keyboard focus. ## Steps to reproduce: 1. Have latest VS Code installed 2. `mkdir project && cd project` 4. `python3 -m venv venv` 5. `source venv/bin/activate` 6. `pip install jupyter` 7. `code --user-data-dir ../temp-user-data-dir --extensions-dir ../temp-extensions-dir .` 3. Install python and jupyter extensions in VS Code 4. cmd-shift-p -> Python: Select Interpreter -> select the venv 5. cmd-shift-p -> Jupyter: Create New Blank Notebook 6. Add a couple of cells, run some code, etc. 7. cmd-n to create a new tab 9. Switch back to the jupyter tab 10. No keyboard input is possible <!-- Note: If you think a GIF of what is happening would be helpful, consider tools like https://www.cockos.com/licecap/, https://github.com/phw/peek or https://www.screentogif.com/ . --> ## Logs <details> <summary>Output for <code>Jupyter</code> in the <code>Output</code> panel (<code>View</code>→<code>Output</code>, change the drop-down the upper-right of the <code>Output</code> panel to <code>Jupyter</code>) </summary> https://gist.github.com/raiskila/a8f4ab7178d0dc6f3281ff874c62c840 </details> "
295685,328802,https://api.github.com/repos/morenoh149/react-native-contacts/issues/549,enhancement,2020-08-06T15:50:44Z,NONE,https://api.github.com/repos/morenoh149/react-native-contacts,"[ANDROID][addContact]: Crash if some of fields of postalAddresses are missed ``` const contact = { postalAddresses: [ { }] } PermissionsAndroid.request( PermissionsAndroid.PERMISSIONS.WRITE_CONTACTS, PermissionsAndroid.PERMISSIONS.READ_CONTACTS, { 'title': 'Contacts', 'message': 'This app would like to view your contacts.', 'buttonPositive': 'Please accept bare mortal' } ).then(() => { Contacts.addContact(contact, error => { console.log('error', error) }) }) ``` <img width=""475"" alt=""Снимок экрана 2020-08-06 в 18 49 34"" src=""https://user-images.githubusercontent.com/9610401/89553037-ab6a3a80-d815-11ea-9c11-aa058ea1070e.png""> Expected behavior: ability to process error in callback"
236518,263067,https://api.github.com/repos/nextcloud/server/issues/25782,bug,2021-02-24T12:40:46Z,NONE,https://api.github.com/repos/nextcloud/server,"Uploading large files fails with nextcloud 20.0.6 on raspberry pi 2 with 32bit cpu ### Steps to reproduce 1. install nextcloud with apache2 + mariadb on raspi II 2. upload large file (2.5GB+) via webgui 3. see error messages ### Expected behaviour Uploading large files via nextcloud-webgui should work. ### Actual behaviour Uploading a file of 5GB takes some time. When all data is transfered to the nextcloud server, the server obvioulsy starts assembling the file from chunks. Assembling fails and the following error is displayed in the browser: [webdav] Fatal: Sabre\DAV\Exception: Error while copying file to target location (copied bytes: -1, expected filesize: -1 ) at <<closure>> Messeges from protocol from Nextcloud admin-gui from 2021-02-17T22:58:25+0100: <details> [PHP] Error: Error: Cannot modify header information - headers already sent by (output started at /var/www/html/nextcloud/3rdparty/sabre/http/lib/Sapi.php:132) at /var/www/html/nextcloud/apps/dav/lib/Connector/Sabre/File.php#691 at <<closure>> 0. <<closure>> OC\Log\ErrorHandler::onError(2, ""Cannot modify h ... )"", ""/var/www/html/n ... p"", 691, {string: ""X-Hash ... ""}) 1. /var/www/html/nextcloud/apps/dav/lib/Connector/Sabre/File.php line 691 header(""X-Hash-SHA1: 29 ... b"") 2. /var/www/html/nextcloud/apps/dav/lib/Connector/Sabre/File.php line 192 OCA\DAV\Connector\Sabre\File->header(""X-Hash-SHA1: 29 ... b"") 3. <<closure>> OCA\DAV\Connector\Sabre\File->OCA\DAV\Connector\Sabre\{closure}(""*** sensitive parameters replaced ***"") 4. /var/www/html/nextcloud/lib/private/Files/Stream/HashWrapper.php line 71 call_user_func(Closure {}, ""*** sensitive parameter replaced ***"") 5. <<closure>> OC\Files\Stream\HashWrapper->stream_close() 6. /var/www/html/nextcloud/3rdparty/icewind/streams/src/Wrapper.php line 132 fclose(null) 7. /var/www/html/nextcloud/lib/private/Files/Stream/HashWrapper.php line 75 Icewind\Streams\Wrapper->stream_close() 8. /var/www/html/nextcloud/3rdparty/sabre/dav/lib/DAV/Server.php line 319 OC\Files\Stream\HashWrapper->stream_close() 9. /var/www/html/nextcloud/apps/dav/lib/Server.php line 332 Sabre\DAV\Server->exec() 10. /var/www/html/nextcloud/apps/dav/appinfo/v2/remote.php line 35 OCA\DAV\Server->exec() 11. /var/www/html/nextcloud/remote.php line 167 require_once(""/var/www/html/n ... p"") MOVE /nextcloud/remote.php/dav/uploads/walter/web-file-upload-ac54f9335b65f2f7cdefc613ad2a036a-1613594591360/.file from 192.168.178.38 by walter at 2021-02-17T21:58:25+00:00 [PHP] Error: Error: Cannot modify header information - headers already sent by (output started at /var/www/html/nextcloud/3rdparty/sabre/http/lib/Sapi.php:132) at /var/www/html/nextcloud/apps/dav/lib/Connector/Sabre/File.php#691 at <<closure>> 0. <<closure>> OC\Log\ErrorHandler::onError(2, ""Cannot modify h ... )"", ""/var/www/html/n ... p"", 691, {string: ""X-Hash ... ""}) 1. /var/www/html/nextcloud/apps/dav/lib/Connector/Sabre/File.php line 691 header(""X-Hash-SHA256: ... 3"") 2. /var/www/html/nextcloud/apps/dav/lib/Connector/Sabre/File.php line 195 OCA\DAV\Connector\Sabre\File->header(""X-Hash-SHA256: ... 3"") 3. <<closure>> OCA\DAV\Connector\Sabre\File->OCA\DAV\Connector\Sabre\{closure}(""*** sensitive parameters replaced ***"") 4. /var/www/html/nextcloud/lib/private/Files/Stream/HashWrapper.php line 71 call_user_func(Closure {}, ""*** sensitive parameter replaced ***"") 5. /var/www/html/nextcloud/3rdparty/sabre/dav/lib/DAV/Server.php line 319 OC\Files\Stream\HashWrapper->stream_close() 6. /var/www/html/nextcloud/apps/dav/lib/Server.php line 332 Sabre\DAV\Server->exec() 7. /var/www/html/nextcloud/apps/dav/appinfo/v2/remote.php line 35 OCA\DAV\Server->exec() 8. /var/www/html/nextcloud/remote.php line 167 require_once(""/var/www/html/n ... p"") MOVE /nextcloud/remote.php/dav/uploads/walter/web-file-upload-ac54f9335b65f2f7cdefc613ad2a036a-1613594591360/.file from 192.168.178.38 by walter at 2021-02-17T21:58:25+00:00 [no app in context] Error: Sabre\DAV\Exception: Error while copying file to target location (copied bytes: -1, expected filesize: -1 ) at <<closure>> 0. /var/www/html/nextcloud/apps/dav/lib/Connector/Sabre/Directory.php line 155 OCA\DAV\Connector\Sabre\File->put(null) 1. /var/www/html/nextcloud/3rdparty/sabre/dav/lib/DAV/Tree.php line 311 OCA\DAV\Connector\Sabre\Directory->createFile(""pso-niemals_web.720p.mkv"", null) 2. /var/www/html/nextcloud/3rdparty/sabre/dav/lib/DAV/Tree.php line 135 Sabre\DAV\Tree->copyNode(OCA\DAV\Upload\FutureFile {}, OCA\DAV\Connector\Sabre\Directory {}, ""pso-niemals_web.720p.mkv"") 3. /var/www/html/nextcloud/3rdparty/sabre/dav/lib/DAV/Tree.php line 167 Sabre\DAV\Tree->copy(""uploads/walter/ ... e"", ""files/walter/sh ... v"") 4. /var/www/html/nextcloud/apps/dav/lib/Upload/ChunkingPlugin.php line 95 Sabre\DAV\Tree->move(""uploads/walter/ ... e"", ""files/walter/sh ... v"") 5. /var/www/html/nextcloud/apps/dav/lib/Upload/ChunkingPlugin.php line 77 OCA\DAV\Upload\ChunkingPlugin->performMove(""uploads/walter/ ... e"", ""files/walter/sh ... v"") 6. /var/www/html/nextcloud/3rdparty/sabre/event/lib/WildcardEmitterTrait.php line 89 OCA\DAV\Upload\ChunkingPlugin->beforeMove(""uploads/walter/ ... e"", ""files/walter/sh ... v"") 7. /var/www/html/nextcloud/3rdparty/sabre/dav/lib/DAV/CorePlugin.php line 632 Sabre\DAV\Server->emit(""beforeMove"", [""uploads/walter ... ""]) 8. /var/www/html/nextcloud/3rdparty/sabre/event/lib/WildcardEmitterTrait.php line 89 Sabre\DAV\CorePlugin->httpMove(Sabre\HTTP\Request {}, Sabre\HTTP\Response {}) 9. /var/www/html/nextcloud/3rdparty/sabre/dav/lib/DAV/Server.php line 474 Sabre\DAV\Server->emit(""method:MOVE"", [Sabre\HTTP\Requ ... }]) 10. /var/www/html/nextcloud/3rdparty/sabre/dav/lib/DAV/Server.php line 251 Sabre\DAV\Server->invokeMethod(Sabre\HTTP\Request {}, Sabre\HTTP\Response {}) 11. /var/www/html/nextcloud/3rdparty/sabre/dav/lib/DAV/Server.php line 319 Sabre\DAV\Server->start() 12. /var/www/html/nextcloud/apps/dav/lib/Server.php line 332 Sabre\DAV\Server->exec() 13. /var/www/html/nextcloud/apps/dav/appinfo/v2/remote.php line 35 OCA\DAV\Server->exec() 14. /var/www/html/nextcloud/remote.php line 167 require_once(""/var/www/html/n ... p"") MOVE /nextcloud/remote.php/dav/uploads/walter/web-file-upload-ac54f9335b65f2f7cdefc613ad2a036a-1613594591360/.file from 192.168.178.38 by walter at 2021-02-17T21:58:23+00:00 Prior error-message, but file is ok: [PHP] Error: Error: file_put_contents(): content truncated from 2539095840 to 2147483647 bytes at /var/www/html/nextcloud/lib/private/Files/Storage/Local.php#559 at <<closure>> 0. <<closure>> OC\Log\ErrorHandler::onError(2, ""file_put_conten ... s"", ""/var/www/html/n ... p"", 559, {path: ""files/sh ... l}) 1. /var/www/html/nextcloud/lib/private/Files/Storage/Local.php line 559 file_put_contents(""/opt/externalhd ... t"", null) 2. /var/www/html/nextcloud/lib/private/Files/Storage/Wrapper/Wrapper.php line 631 OC\Files\Storage\Local->writeStream(""files/shared/Un ... t"", null, null) 3. /var/www/html/nextcloud/apps/dav/lib/Connector/Sabre/File.php line 207 OC\Files\Storage\Wrapper\Wrapper->writeStream(""files/shared/Un ... t"", null) 4. /var/www/html/nextcloud/apps/dav/lib/Connector/Sabre/Directory.php line 155 OCA\DAV\Connector\Sabre\File->put(null) 5. /var/www/html/nextcloud/3rdparty/sabre/dav/lib/DAV/Tree.php line 311 OCA\DAV\Connector\Sabre\Directory->createFile(""Unser Mann in Amerika 720p.mkv"", null) 6. /var/www/html/nextcloud/3rdparty/sabre/dav/lib/DAV/Tree.php line 135 Sabre\DAV\Tree->copyNode(OCA\DAV\Upload\FutureFile {}, OCA\DAV\Connector\Sabre\Directory {}, ""Unser Mann in Amerika 720p.mkv"") 7. /var/www/html/nextcloud/3rdparty/sabre/dav/lib/DAV/Tree.php line 167 Sabre\DAV\Tree->copy(""uploads/walter/ ... e"", ""files/walter/sh ... v"") 8. /var/www/html/nextcloud/apps/dav/lib/Upload/ChunkingPlugin.php line 95 Sabre\DAV\Tree->move(""uploads/walter/ ... e"", ""files/walter/sh ... v"") 9. /var/www/html/nextcloud/apps/dav/lib/Upload/ChunkingPlugin.php line 77 OCA\DAV\Upload\ChunkingPlugin->performMove(""uploads/walter/ ... e"", ""files/walter/sh ... v"") 10. /var/www/html/nextcloud/3rdparty/sabre/event/lib/WildcardEmitterTrait.php line 89 OCA\DAV\Upload\ChunkingPlugin->beforeMove(""uploads/walter/ ... e"", ""files/walter/sh ... v"") 11. /var/www/html/nextcloud/3rdparty/sabre/dav/lib/DAV/CorePlugin.php line 632 Sabre\DAV\Server->emit(""beforeMove"", [""uploads/walter ... ""]) 12. /var/www/html/nextcloud/3rdparty/sabre/event/lib/WildcardEmitterTrait.php line 89 Sabre\DAV\CorePlugin->httpMove(Sabre\HTTP\Request {}, Sabre\HTTP\Response {}) 13. /var/www/html/nextcloud/3rdparty/sabre/dav/lib/DAV/Server.php line 474 Sabre\DAV\Server->emit(""method:MOVE"", [Sabre\HTTP\Requ ... }]) 14. /var/www/html/nextcloud/3rdparty/sabre/dav/lib/DAV/Server.php line 251 Sabre\DAV\Server->invokeMethod(Sabre\HTTP\Request {}, Sabre\HTTP\Response {}) 15. /var/www/html/nextcloud/3rdparty/sabre/dav/lib/DAV/Server.php line 319 Sabre\DAV\Server->start() 16. /var/www/html/nextcloud/apps/dav/lib/Server.php line 332 Sabre\DAV\Server->exec() 17. /var/www/html/nextcloud/apps/dav/appinfo/v2/remote.php line 35 OCA\DAV\Server->exec() 18. /var/www/html/nextcloud/remote.php line 167 require_once(""/var/www/html/n ... p"") MOVE /nextcloud/remote.php/dav/uploads/walter/web-file-upload-797b68e2e43a4df1289f42da62e01670-1613592337334/.file from 192.168.178.38 by walter at 2021-02-17T20:41:46+00:00 </details> ### Server configuration **Operating system:** Raspbian GNU/Linux 10 (buster) **Web server:** apache2 2.4.38-3+deb10u4 armhf **Database:** mariadb-server-10.3 1:10.3.27-0+deb10u1 armhf **PHP version:** php7.3-common 7.3.19-1~deb10u1 armhf **Nextcloud version:** 20.0.6 **Updated from an older Nextcloud/ownCloud or fresh install:** fresh **Where did you install Nextcloud from:** from nextcloud-20.0.6.zip **Signing status:** don't know about that Login as admin user into your Nextcloud and access http://example.com/index.php/settings/integrity/failed paste the results here. No errors have been found. **List of activated apps:** <details> Mail 1.8.1 Accessibility 1.6.0 Activity 2.13.4 Brute-force settings 2.0.1 Calendar 2.1.3 Collabora Online 3.7.14 Collaborative tags 1.10.0 Comments 1.10.0 Contacts 3.4.3 Contacts Interaction 1.1.0 Dashboard 7.0.0 Deleted files 1.10.1 Federation 1.10.1 File sharing 1.12.2 First run wizard 2.9.0 Log Reader 2.5.0 Monitoring 1.10.0 Nextcloud announcements 1.9.0 Notifications 2.8.0 Password policy 1.10.1 PDF viewer 2.0.1 Photos 1.2.3 Privacy 1.4.0 Recommendations 0.8.0 Right click 0.17.0 Share by mail 1.10.0 Support 1.3.0 Talk 10.0.5 Text 3.1.0 Theming 1.11.0 Update notification 1.10.0 Usage survey 1.8.0 User status 1.0.1 Versions 1.13.0 Video player 1.9.0 Weather status 1.0.0 <summary>App list</summary> If you have access to your command line run e.g.: sudo -u www-data php occ app:list from within your Nextcloud installation folder Enabled: - accessibility: 1.6.0 - activity: 2.13.4 - bruteforcesettings: 2.0.1 - calendar: 2.1.3 - cloud_federation_api: 1.3.0 - comments: 1.10.0 - contacts: 3.4.3 - contactsinteraction: 1.1.0 - dashboard: 7.0.0 - dav: 1.16.2 - federatedfilesharing: 1.10.2 - federation: 1.10.1 - files: 1.15.0 - files_pdfviewer: 2.0.1 - files_rightclick: 0.17.0 - files_sharing: 1.12.2 - files_trashbin: 1.10.1 - files_versions: 1.13.0 - files_videoplayer: 1.9.0 - firstrunwizard: 2.9.0 - logreader: 2.5.0 - lookup_server_connector: 1.8.0 - mail: 1.8.1 - nextcloud_announcements: 1.9.0 - notifications: 2.8.0 - oauth2: 1.8.0 - password_policy: 1.10.1 - photos: 1.2.3 - privacy: 1.4.0 - provisioning_api: 1.10.0 - recommendations: 0.8.0 - richdocuments: 3.7.14 - serverinfo: 1.10.0 - settings: 1.2.0 - sharebymail: 1.10.0 - spreed: 10.0.5 - support: 1.3.0 - survey_client: 1.8.0 - systemtags: 1.10.0 - text: 3.1.0 - theming: 1.11.0 - twofactor_backupcodes: 1.9.0 - updatenotification: 1.10.0 - user_status: 1.0.1 - viewer: 1.4.0 - weather_status: 1.0.0 - workflowengine: 2.2.0 Disabled: - admin_audit - encryption - files_external - user_ldap </details> **Nextcloud configuration:** <details> <summary>Config report</summary> If you have access to your command line run e.g.: sudo -u www-data php occ config:list system from within your Nextcloud installation folder { ""system"": { ""instanceid"": ""***REMOVED SENSITIVE VALUE***"", ""passwordsalt"": ""***REMOVED SENSITIVE VALUE***"", ""secret"": ""***REMOVED SENSITIVE VALUE***"", ""trusted_domains"": [ ""my.host.net"" ], ""datadirectory"": ""***REMOVED SENSITIVE VALUE***"", ""dbtype"": ""mysql"", ""version"": ""20.0.6.1"", ""overwrite.cli.url"": ""https:\/\/my.host.net\/nextcloud"", ""dbname"": ""***REMOVED SENSITIVE VALUE***"", ""dbhost"": ""***REMOVED SENSITIVE VALUE***"", ""dbport"": """", ""dbtableprefix"": ""oc_"", ""mysql.utf8mb4"": true, ""dbuser"": ""***REMOVED SENSITIVE VALUE***"", ""dbpassword"": ""***REMOVED SENSITIVE VALUE***"", ""installed"": true } } or Insert your config.php content here. Make sure to remove all sensitive content such as passwords. (e.g. database password, passwordsalt, secret, smtp password, …) pi@homunculus:/var/www/html/nextcloud/config $ sudo cat config.php <?php $CONFIG = array ( 'instanceid' => '12345', 'passwordsalt' => 'blah', 'secret' => 'blahblah', 'trusted_domains' => array ( 0 => 'my.host.net', ), 'datadirectory' => '/opt/externalhd/nextclouddata', 'dbtype' => 'mysql', 'version' => '20.0.6.1', 'overwrite.cli.url' => 'https://my.host.net/nextcloud', 'dbname' => 'nextclouddb', 'dbhost' => 'localhost', 'dbport' => '', 'dbtableprefix' => 'oc_', 'mysql.utf8mb4' => true, 'dbuser' => 'nextclouduser', 'dbpassword' => '***************', 'installed' => true, ); pi@homunculus:/var/log/apache2 $ cat /etc/php/7.3/apache2/php.ini | grep ""^[^;[]"" engine = On short_open_tag = Off precision = 14 output_buffering = Off zlib.output_compression = Off implicit_flush = Off unserialize_callback_func = serialize_precision = -1 disable_functions = pcntl_alarm,pcntl_fork,pcntl_waitpid,pcntl_wait,pcntl_wifexited,pcntl_wifstopped,pcntl_wifsignaled,pcntl_wifcontinued,pcntl_wexitstatus,pcntl_wtermsig,pcntl_wstopsig,pcntl_signal,pcntl_signal_get_handler,pcntl_signal_dispatch,pcntl_get_last_error,pcntl_strerror,pcntl_sigprocmask,pcntl_sigwaitinfo,pcntl_sigtimedwait,pcntl_exec,pcntl_getpriority,pcntl_setpriority,pcntl_async_signals, disable_classes = zend.enable_gc = On expose_php = Off max_execution_time = 3600 max_input_time = 3600 memory_limit = 512M error_reporting = E_ALL display_errors = Off display_startup_errors = Off log_errors = On log_errors_max_len = 1024 ignore_repeated_errors = Off ignore_repeated_source = Off report_memleaks = On html_errors = On error_log = /var/log/php_errors.log variables_order = ""GPCS"" request_order = ""GP"" register_argc_argv = Off auto_globals_jit = On post_max_size = 8G auto_prepend_file = auto_append_file = default_mimetype = ""text/html"" default_charset = ""UTF-8"" doc_root = user_dir = enable_dl = Off file_uploads = On upload_tmp_dir = /opt/externalhd/tmp upload_max_filesize = 8G max_file_uploads = 20 allow_url_fopen = On allow_url_include = Off default_socket_timeout = 60 cli_server.color = On pdo_mysql.default_socket= SMTP = localhost smtp_port = 25 mail.add_x_header = Off odbc.allow_persistent = On odbc.check_persistent = On odbc.max_persistent = -1 odbc.max_links = -1 odbc.defaultlrl = 4096 odbc.defaultbinmode = 1 ibase.allow_persistent = 1 ibase.max_persistent = -1 ibase.max_links = -1 ibase.timestampformat = ""%Y-%m-%d %H:%M:%S"" ibase.dateformat = ""%Y-%m-%d"" ibase.timeformat = ""%H:%M:%S"" mysqli.max_persistent = -1 mysqli.allow_persistent = On mysqli.max_links = -1 mysqli.default_port = 3306 mysqli.default_socket = mysqli.default_host = mysqli.default_user = mysqli.default_pw = mysqli.reconnect = Off mysqlnd.collect_statistics = On mysqlnd.collect_memory_statistics = Off pgsql.allow_persistent = On pgsql.auto_reset_persistent = Off pgsql.max_persistent = -1 pgsql.max_links = -1 pgsql.ignore_notice = 0 pgsql.log_notice = 0 bcmath.scale = 0 session.save_handler = files session.use_strict_mode = 0 session.use_cookies = 1 session.use_only_cookies = 1 session.name = PHPSESSID session.auto_start = 0 session.cookie_lifetime = 0 session.cookie_path = / session.cookie_domain = session.cookie_httponly = session.cookie_samesite = session.serialize_handler = php session.gc_probability = 0 session.gc_divisor = 1000 session.gc_maxlifetime = 1440 session.referer_check = session.cache_limiter = nocache session.cache_expire = 180 session.use_trans_sid = 0 session.sid_length = 26 session.trans_sid_tags = ""a=href,area=href,frame=src,form="" session.sid_bits_per_character = 5 zend.assertions = -1 tidy.clean_output = Off soap.wsdl_cache_enabled=1 soap.wsdl_cache_dir=""/tmp"" soap.wsdl_cache_ttl=86400 soap.wsdl_cache_limit = 5 ldap.max_links = -1 </details> **Are you using external storage, if yes which one:** external ext4 harddisk /dev/sda1 for file storage and tmp **Are you using encryption:** don't think so **Are you using an external user-backend, if yes which one:** no ### Client configuration **Browser:** Firefox 85.0.1 (64-bit) **Operating system:** Ubuntu 20.04.2 LTS ### Logs <!--- Reports without logs might be closed as unqualified reports! --> #### Web server error log <details> pi@homunculus:/var/log/apache2 $ cat error.log.1 [Wed Feb 17 00:00:05.586786 2021] [ssl:warn] [pid 443] AH01906: 127.0.1.1:443:0 server certificate is a CA certificate (BasicConstraints: CA == TRUE !?) [Wed Feb 17 00:00:05.587050 2021] [ssl:warn] [pid 443] AH01909: 127.0.1.1:443:0 server certificate does NOT include an ID which matches the server name [Wed Feb 17 00:00:05.588040 2021] [mpm_prefork:notice] [pid 443] AH00163: Apache/2.4.38 (Raspbian) SVN/1.10.4 OpenSSL/1.1.1d configured -- resuming normal operations [Wed Feb 17 00:00:05.588104 2021] [core:notice] [pid 443] AH00094: Command line: '/usr/sbin/apache2' [Wed Feb 17 02:00:45.082766 2021] [php7:error] [pid 27115] [client 45.155.205.108:43842] script '/var/www/html/index.php' not found or unable to stat [Wed Feb 17 02:46:25.989123 2021] [php7:error] [pid 27115] [client 13.90.56.166:41106] script '/var/www/html/wp-login.php' not found or unable to stat [Wed Feb 17 05:57:53.486314 2021] [php7:error] [pid 27117] [client 45.155.205.108:37744] script '/var/www/html/index.php' not found or unable to stat [Wed Feb 17 18:51:56.275689 2021] [php7:error] [pid 951] [client 45.155.205.108:44766] script '/var/www/html/index.php' not found or unable to stat [Wed Feb 17 20:44:46.714097 2021] [php7:error] [pid 951] [client 192.241.219.147:38740] script '/var/www/html/search.php' not found or unable to stat [Wed Feb 17 20:56:01.312885 2021] [mpm_prefork:notice] [pid 443] AH00169: caught SIGTERM, shutting down [Wed Feb 17 20:56:17.146575 2021] [ssl:warn] [pid 388] AH01906: 127.0.0.1:443:0 server certificate is a CA certificate (BasicConstraints: CA == TRUE !?) [Wed Feb 17 20:56:17.153820 2021] [ssl:warn] [pid 388] AH01909: 127.0.0.1:443:0 server certificate does NOT include an ID which matches the server name [Wed Feb 17 20:56:17.342573 2021] [so:warn] [pid 388] AH01574: module dav_module is already loaded, skipping [Wed Feb 17 20:56:23.509566 2021] [ssl:warn] [pid 492] AH01906: 127.0.0.1:443:0 server certificate is a CA certificate (BasicConstraints: CA == TRUE !?) [Wed Feb 17 20:56:23.509792 2021] [ssl:warn] [pid 492] AH01909: 127.0.0.1:443:0 server certificate does NOT include an ID which matches the server name [Wed Feb 17 20:56:23.547542 2021] [mpm_prefork:notice] [pid 492] AH00163: Apache/2.4.38 (Raspbian) SVN/1.10.4 OpenSSL/1.1.1d configured -- resuming normal operations [Wed Feb 17 20:56:23.547790 2021] [core:notice] [pid 492] AH00094: Command line: '/usr/sbin/apache2' [Wed Feb 17 21:33:33.656530 2021] [php7:error] [pid 995] [client 157.245.120.130:34206] script '/var/www/html/wp-login.php' not found or unable to stat [Thu Feb 18 00:00:30.010481 2021] [mpm_prefork:notice] [pid 492] AH00171: Graceful restart requested, doing restart [Thu Feb 18 00:00:31.000732 2021] [so:warn] [pid 492] AH01574: module dav_module is already loaded, skipping AH00558: apache2: Could not reliably determine the server's fully qualified domain name, using 127.0.1.1. Set the 'ServerName' directive globally to suppress this message <summary>Web server error log</summary> ``` Insert your webserver log here ``` </details> #### Nextcloud log (data/nextcloud.log) <details> [nextcloud.log.txt](https://github.com/nextcloud/server/files/6035979/nextcloud.log.txt) </details> "
417786,464402,https://api.github.com/repos/informatics-isi-edu/ermrest/issues/234,enhancement,2020-12-17T19:11:15Z,CONTRIBUTOR,https://api.github.com/repos/informatics-isi-edu/ermrest,"add url, uri, curie domain types Purely for semantic labeling/hints, we could add `url`, `uri`, and `curie` domains over `text` type to the basic set of types we support in new catalogs. However, it is unclear how much we can constrain/validate values of these domains in their SQL definitions, since we would not want anything that cannot be expressed as easily maintained and `immutable` SQL or plpgsql code."
507233,563722,https://api.github.com/repos/davidedc/Algebrite/issues/75,enhancement,2019-01-03T22:31:37Z,NONE,https://api.github.com/repos/davidedc/Algebrite,More Unit Circle cases for arcsin/arccos? ``` simplify(arcsin(sqrt(2)/2)) > 1/4*pi simplify(arcsin(1/2)) > 1/6*pi simplify(arcsin(sqrt(3)/2)) > arcsin(1/2*3^(1/2)) ``` It seems like arcsin and arccos don't handle pi/3 during simplification. A cursory glance through `arcsin.coffee` suggests this is just a unit circle value that was overlooked. It would be nice to see that added.
300707,334326,https://api.github.com/repos/Kimyechan/DivingProject-BackEnd/issues/20,bug,2021-03-22T12:28:01Z,OWNER,https://api.github.com/repos/Kimyechan/DivingProject-BackEnd,"강의 예약 API 수정 - [x] : 요청에 scheduleDetailId, scheduleTimeId 추가 - [x] : ReservationDate에 ScheduleDetail ScheduleTime 관계 추가"
292895,325702,https://api.github.com/repos/flashbyte/chngLog/issues/3,enhancement,2021-05-02T15:08:03Z,OWNER,https://api.github.com/repos/flashbyte/chngLog,"Exclude for commit types Add option to exclude commit types. e.g. ugly, chore, test"
55928,62192,https://api.github.com/repos/dotnet/runtime/issues/49617,bug,2021-03-15T00:13:26Z,MEMBER,https://api.github.com/repos/dotnet/runtime,"HTTP/3: Hang after 100 requests on a connection HttpClient + HTTP/3 appears to consistently hang when making the 101st HTTP/3 requests to the server. I've looked at client and server logs and I believe the issue is HttpClient never sends the 101st request. The app calls `HttpClient.SendAsync`, nothing is received by the server, and the app hangs. I'm guessing there is a setting that limits the number of concurrent streams to the server and that number isn't being reset by the client when requests are complete. When the 101st request is made the client thinks it has 100 requests in progress and hangs forever."
588278,653739,https://api.github.com/repos/dascr/dascr-board/issues/5,bug,2021-01-26T19:12:30Z,CONTRIBUTOR,https://api.github.com/repos/dascr/dascr-board,Cricket broken When one player cannot win anymore cause he cannot score another player cause the other player has already closed everything an one player is left with something open then game is not shot automatically. Check winning condition against this test 
196808,218824,https://api.github.com/repos/WalkingMachine/sara_behaviors/issues/61,enhancement,2018-05-08T03:29:55Z,CONTRIBUTOR,https://api.github.com/repos/WalkingMachine/sara_behaviors,La doc est pas complète Il faudrait complete la documentation pour l'installation. C'est pas clair quand on l'utilise pour la premiere fois. Ou quand ca fait un an qu'on en a pas fait ! :p 
555016,616803,https://api.github.com/repos/TF2Autobot/tf2autobot/issues/286,bug,2021-01-23T16:01:48Z,NONE,https://api.github.com/repos/TF2Autobot/tf2autobot,"Wrong stock calculation **Describe the bug** Bot didn't like one of admins and decided not to share the items :) **To Reproduce** Steps to reproduce the behavior: No idea how to reproduce honestly. **Screenshots and logs** Pure stock was: `💰 I have 160.88 refs (153 ref, 18 rec, 17 scrap) in my inventory.` Chat with admin X: ``` 2021-01-22 09:48:56 ESC[32minfoESC[39m: Message from X (xxx): !withdraw name=Refined Metal&amount=150 2021-01-22 09:48:56 ESC[32minfoESC[39m: Message sent to X (xxx): ❌ I don't have any more Refined Metals. ``` Tried 2 or 3 times, didn't help. Tried to reduce the amount to 130, didn't help either. Chat with admin Y: ``` 2021-01-22 09:47:00 ESC[32minfoESC[39m: Message from Y (xxx): !withdraw name=Refined Metal&amount=150 2021-01-22 09:47:00 ESC[32minfoESC[39m: Message sent to Y (xxx): ✅ 150 Refined Metals has been added to your cart. Type ""!cart"" to view your cart summary or ""!checkout"" to checkout. 🛒 ``` **Additional context** Got fixed after a restart. Nothing suspicious in logs. Version: 2.3.5 "
8688,9690,https://api.github.com/repos/mozilla-services/absearch/issues/6,enhancement,2015-07-17T14:11:15Z,CONTRIBUTOR,https://api.github.com/repos/mozilla-services/absearch,cache results We can drastically improve performances by caching the results - one option is to use nginx for this see https://github.com/mozilla-services/cliquet/issues/401 - and add a few headers in the server. 
486379,540555,https://api.github.com/repos/rsksmart/rif-credential-verifier/issues/13,enhancement,2021-02-01T12:23:41Z,COLLABORATOR,https://api.github.com/repos/rsksmart/rif-credential-verifier,"Add raw view Similar to JWT.io, add a button on each presentation and credential panel to display the raw decoded JSON."
327443,364014,https://api.github.com/repos/How-Bout-No/Outvoted/issues/45,bug,2021-05-16T06:22:55Z,NONE,https://api.github.com/repos/How-Bout-No/Outvoted,"[BUG] Outvoted crashes with Fastsuite, fastworkbench without replacement, while opening up a crafting table on dedicated server /Before submitting, please ensure you've done the following, as these are fixes for some common bugs: [x ] Reset/delete config files [x ] Run with Java 8 **Describe the bug** title **To Reproduce** Steps to reproduce the behavior: 1.start up dedic server 2. join it 3. craft something or open up a table 4. crash **Expected behavior** to craft stuff **Screenshots/Logs** [crash-2021-05-16_01.15.42-server.txt](https://github.com/How-Bout-No/Outvoted/files/6488769/crash-2021-05-16_01.15.42-server.txt) **Version (please complete the following information):** - Minecraft Version: 1.16.5 - Mod Version: 2.0.0 alpha 3 **Additional context** Use it with 'fast suite' and 'fast workbench without replacement' "
344127,382547,https://api.github.com/repos/jmcerrejon/PiKISS/issues/74,bug,2021-01-07T08:37:22Z,NONE,https://api.github.com/repos/jmcerrejon/PiKISS,"AVP no sound Hello, i have installed avp from your script in my RPI 4 it runs fine but i dont have sound in the game? any suggestion on whats wrong ??"
482937,536722,https://api.github.com/repos/microsoft/vscode-azure-iot-edge/issues/351,bug,2019-01-24T00:50:24Z,MEMBER,https://api.github.com/repos/microsoft/vscode-azure-iot-edge,"Docker commands in PowerShell From David R. Williamson, I'm running into a new issue with ""Build and Push IoT Edge Solution"" command in VS Code It yields an error: At line:1 char:235 + ... ce\IoTEdgeAndMlSample\EdgeSolution\modules\turbofanRouter"" && docker ... The token '&&' is not a valid statement separator in this version. At line:1 char:308 + ... turbofanacrlihxmkbo.azurecr.io/turbofanrouter:0.0.1-amd64 && docker ... The token '&&' is not a valid statement separator in this version. At line:1 char:545 + ... ce\IoTEdgeAndMlSample\EdgeSolution\modules\avroFileWriter"" && docker ... The token '&&' is not a valid statement separator in this version. + CategoryInfo : ParserError: (:) [], ParentContainsErrorRecordException + FullyQualifiedErrorId : InvalidEndOfLine && isn't valid for separating commands in power shell. Instead it should be a semicolon."
219561,244147,https://api.github.com/repos/antvis/X6/issues/1015,bug,2021-05-26T04:01:04Z,NONE,https://api.github.com/repos/antvis/X6,同样的代码，在react中成功，vue中失败 继承Node，注册节点。 然后用注册的节点去创建节点，并修改属性。react成功，vue不成功 react https://codesandbox.io/s/flamboyant-glade-vljm4?file=/src/app.tsx vue https://codesandbox.io/s/wonderful-roentgen-19u6z?file=/src/App.vue
389755,433228,https://api.github.com/repos/3dgeo-heidelberg/helios/issues/23,bug,2021-03-25T06:58:40Z,COLLABORATOR,https://api.github.com/repos/3dgeo-heidelberg/helios,"scannerSettings template behavior - scan angle increasing for each leg using the template When defining the `scanAngle_deg` via a `scannerSettings` template in the beginning of the survey XML file, the scan angle is not inherited to each leg using the template. Instead the scan angle increases for each leg using the template, at least with the new `risley` scanner optics. The bug can be reproduced with [data/surveys/toyblocks/uls_toyblocks_livox.xml](https://github.com/3dgeo-heidelberg/helios/blob/main/data/surveys/toyblocks/uls_toyblocks_livox.xml). (Note: It seems like the issue occurs for all scanner optics, but for the existing scanners, the scan angle is always limited to the maximum possible value. For the new scanner optics (""risley""), part of the code is uncommented (see [src/scanner/beamDeflector/RisleyBeamDeflector.cpp](https://github.com/3dgeo-heidelberg/helios/blob/main/src/scanner/beamDeflector/RisleyBeamDeflector.cpp) line 64f.), so scan angle is not set to max scan angle.)"
202171,224791,https://api.github.com/repos/casbin/node-casbin/issues/245,bug,2021-03-14T05:16:24Z,NONE,https://api.github.com/repos/casbin/node-casbin,"Use require syntax for docs as an example instead of import I would like to point out that while following the examples I faced following error : - In server.js `import { newEnforcer } from 'casbin';` `const enforcer = await newEnforcer('basic_model.conf', 'basic_policy.csv');` ![image](https://user-images.githubusercontent.com/39632788/111057899-c9390580-84b0-11eb-82c8-4cd3dfff08c4.png) This is because nodejs natively supports `require syntax` and the index file of the librar is not in form of a module. Adding `""type"": ""module""` in package.json (which parses every js file as a module) solves the issue but then messes with other packages like express.js Additionally on declaring following `const enforcer = await newEnforcer('basic_model.conf', 'basic_policy.csv')` I got this error ; ![image](https://user-images.githubusercontent.com/39632788/111058129-5761bb80-84b2-11eb-9c72-bf2f3fa09577.png) Since this is casbin implementation for nodejs I would recommend to make example specific to node developers."
36612,40821,https://api.github.com/repos/Neos-Metaverse/NeosPublic/issues/2244,bug,2021-05-14T14:13:09Z,NONE,https://api.github.com/repos/Neos-Metaverse/NeosPublic,"LogiX interface cards spawn additional copies for every user in the session ## Describe the bug This is a long-standing bug that was mentioned a lot of times, but still there is no open issues on it that I can find. I propose this to be the issue to track this bug so it would be fixed. ## Relevant issues Issues on similar topic, but not exactly: #2066, #1128, #1491 ## To Reproduce 1. Be in a session with more than one user 2. Work with LogiX - create, use interfaces, pack, unpack 3. Observe additional interface cards being spawned. The exact number is usually equal to the user count in the session for each unique card. ## Expected behavior Additional cards won't spawn. ## Log Files ## Screenshots / Video ## Bug information (please complete the following information): - How often does it happen: Always - Does the bug persist after restarting Neos? Yes - Neos Version: 2021.5.13.433 - Neos Platform: Any - Link to reproduction World/Item: - Regression: No ## Additional context There is a button to clean all interfaces in the world, but it doesn't distinguish between working interfaces and extra copies. There was a community-made tool to only remove extra interfaces (Ukilop's), but it stopped working after the recent patch that removed one of the ""hacky"" ways to properly clean up interface cards. ## Reporters: Shadow Panther#5154 "
363498,404093,https://api.github.com/repos/AbsaOSS/k8gb/issues/323,enhancement,2021-02-26T18:29:10Z,COLLABORATOR,https://api.github.com/repos/AbsaOSS/k8gb,Move `expose53onWorkers` from `externaldns` to `k8gb` section Semantically it belongs to core k8gb functionality and not really related to external-dns
574647,638580,https://api.github.com/repos/postmanlabs/postman-app-support/issues/8876,bug,2020-08-03T10:03:15Z,NONE,https://api.github.com/repos/postmanlabs/postman-app-support,"Encoding `charset` from older response are getting persisted when new response have no `charset` defined in Content-Type **Describe the bug** In case of responses which use content-type encoding other than `utf-8`, * When the `charset` is missing in the Content-Type header is assumed to be `utf-8`. * If the `charset` is defined in the Content-Type header it takes precedence. This issue arises when a response containing an explicit charset defined is followed by a response containing no charset defined. The app uses the older charset and does not default to `utf-8` for the new response. **To Reproduce** Steps to reproduce the behaviour: 1. Restart or Open the postman app. (Quit and Restart is important) 2. Open a new tab 3. Make a request to `https://httpbin.org/get` (Do not use postman-echo) 4. Notice the response being rendered correctly 5. Now use this [Snippet](https://gist.github.com/saswatds/78e4b2c6b010db9d3a31539a2a893c95) to start the server 6. Make a request to `http://localhost:8080/utf16` 7. Notice the response is rendered correctly as the encoding is being handled 8. Now make a request again to `https://httpbin.org/get` 9. Notice that the response is now garbled because the encoding did not default to `utf-8` but used the previous `utf-16` encoding **Expected behaviour** The new response without having an explicit charset should default to `utf-8` decoding for the content. **App information (please complete the following information):** - App Type - Native App, Web - Postman Version - v7.29.1 - OS: macOS **Additional context** This seems to be a problem with the `postman-collection` ~ `Response.contentInfo()` implementation "
440162,489334,https://api.github.com/repos/adobe/himl/issues/20,bug,2020-06-30T20:05:31Z,NONE,https://api.github.com/repos/adobe/himl,cwd is not working as expected https://github.com/adobe/himl/blob/master/himl/config_generator.py#L204 os.chdir(self.cwd) should be used before the for loop where os.chdir(path) is used. I made this change in local and it works. 
279047,310343,https://api.github.com/repos/KIM6JIN/welcome/issues/1,bug,2021-05-26T07:21:47Z,OWNER,https://api.github.com/repos/KIM6JIN/welcome,버그나 나타났어요! 버그의 내용은...
706390,785102,https://api.github.com/repos/Pustur/whatsapp-chat-parser-website/issues/3,bug,2021-03-08T09:42:15Z,NONE,https://api.github.com/repos/Pustur/whatsapp-chat-parser-website,"Encryption message is not treated as a system message ![groupChat](https://user-images.githubusercontent.com/23440847/110303280-82539780-7ffa-11eb-8151-ccdbd0862675.png) Export Group is the name of the group. Guess this happens for ""recently created"" groups. first lines of txt: ``` [04.03.21, 10:18:18] ‎You created group “Export group” [04.03.21, 10:18:18] Export group: ‎Messages and calls are end-to-end encrypted. No one outside of this chat, not even WhatsApp, can read or listen to them. ‎[04.03.21, 10:18:30] Adrian: ‎<attached: 00000002-PHOTO-2021-03-04-10-18-29.jpg> ‎[04.03.21, 10:18:39] Adrian: ‎<attached: 00000003-VIDEO-2021-03-04-10-18-38.mp4> ```"
411980,457924,https://api.github.com/repos/opensearch-project/OpenSearch/issues/704,bug,2021-05-13T18:33:19Z,NONE,https://api.github.com/repos/opensearch-project/OpenSearch,"[BUG] **Describe the bug** A clear and concise description of what the bug is. **To Reproduce** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected behavior** A clear and concise description of what you expected to happen. **Plugins** Please list all plugins currently enabled. **Screenshots** If applicable, add screenshots to help explain your problem. **Host/Environment (please complete the following information):** - OS: [e.g. iOS] - Version [e.g. 22] **Additional context** Add any other context about the problem here. "
305952,340183,https://api.github.com/repos/firefly-iii/firefly-iii/issues/4246,question,2021-01-10T12:30:05Z,NONE,https://api.github.com/repos/firefly-iii/firefly-iii,"CSV Importer: Handle stray delimiters Reporting when Firefly III CSV Import Tool, v2.3.3 was latest My banks csv exports are pretty bad. My main issue is that they for some strange reason prepend a random `'` character to _some_ text fields. ``` Date, Type, Description, Value, Balance, Account Name, Account Number 08/01/2021,POS,""'Sid"",-10.00,1234.56,""'Joint Account"",""'112233-44556677"", 05/01/2021,POS,""'Nancy"",-10.00,1224.56,""'Joint Account"",""'112233-44556677"", 06/01/2021,POS,""'Jane"",-10.00,1234.56,""'Joint Account"",""'112233-44556677"", ``` This is a redacted real export with fake data but _real_ in all the ways that matter. Notice `'Sid` and not `Sid` and also `""'112233-44556677""` and not `""112233-44556677""`. Just to make it extra annoying notice `POS` is a value in the Type text filed but doesn't have this issue. This feels like quite an edge case but equally I have zero chance of the bank fixing this at my request. I can obviously do some sanitisation after export but before import but if there was any way to cater for this natively it would be well received. "
707186,785976,https://api.github.com/repos/BAndysc/WoWDatabaseEditor/issues/64,enhancement,2021-05-03T06:11:28Z,NONE,https://api.github.com/repos/BAndysc/WoWDatabaseEditor,[Feature] SAI - Show %-chances on Script overview **Is your feature request related to a problem? Please describe.** Currently no way to see %-Event chances beside opening each one and face-check them. **Describe the solution you'd like** Show % in the overview screen. **Additional context** ![image](https://user-images.githubusercontent.com/37972361/116845733-fbc8ca00-abe6-11eb-9ffa-ecf8b27f6d0e.png) 
323249,359369,https://api.github.com/repos/dbwebb-se/mvc/issues/27,question,2021-05-03T16:14:37Z,NONE,https://api.github.com/repos/dbwebb-se/mvc,"phpstan (Laravel Eloquent): ""access to an undefined property"" + ""call to an undefined static method"" Jag lyckas inte komma till rätta med dessa valideringsfel som genereras av phpstan. Är det i min PHPDoc som definitionen ska göras, och hur ska den i så fall se ut? Jag hittar tyvärr inget som fungerar i de resurser jag hittat på nätet. ``` ------ ------------------------------------------------------------------- Line app\Http\Controllers\YatzyController.php ------ ------------------------------------------------------------------- 85 Access to an undefined property App\Models\Highscore::$player. 85 Access to an undefined property Illuminate\Http\Request::$player. 86 Access to an undefined property App\Models\Highscore::$score. 86 Access to an undefined property Illuminate\Http\Request::$score. ------ ------------------------------------------------------------------- ------ -------------------------------------------------------------- Line app\Models\Book.php ------ -------------------------------------------------------------- 34 Access to an undefined property App\Models\Book::$isbn. 35 Access to an undefined property App\Models\Book::$title. 36 Access to an undefined property App\Models\Book::$author. 37 Access to an undefined property App\Models\Book::$image_url. ------ -------------------------------------------------------------- ------ ------------------------------------------------------------------------- Line app\Models\Highscore.php ------ ------------------------------------------------------------------------- 31 Call to an undefined static method App\Models\Highscore::orderByDesc(). ------ ------------------------------------------------------------------------- ``` Aktuell del ur YatzyController.php ``` /** * Save submitted score and call highScores() to present highscores * * @param Request $request * @property array $request * @property object $newScore * @return \Illuminate\Contracts\View\View */ public function submitHighScore(Request $request) { $newScore = new Highscore(); $newScore->player = $request->player; $newScore->score = $request->score; $newScore->save(); return $this->highScores(); } ``` Book.php: ``` namespace App\Models; use Illuminate\Database\Eloquent\Factories\HasFactory; use Illuminate\Database\Eloquent\Model; class Book extends Model { use HasFactory; /** * Indicates if the model should be timestamped. * * @var bool */ public $timestamps = false; /** * Get all books from books table in database. * * @property array $books * @property object $bookDBObject * @property object $book * @return array $books */ public function getAllBooks() { $bookDBObject = Book::all(); $books = []; foreach ($bookDBObject as $book) { array_push($books, [ 'isbn' => $book->isbn, 'title' => $book->title, 'author' => $book->author, 'image' => $book->image_url ]); } return $books; } } ``` Highscore.php ``` namespace App\Models; use Illuminate\Database\Eloquent\Factories\HasFactory; use Illuminate\Database\Eloquent\Model; class Highscore extends Model { use HasFactory; /** * Indicates if the model should be timestamped. * * @var bool */ public $timestamps = false; /** * Get all highscores from highscores table in database. * * @property object $highscoresDBObject * @property array $highscoresArray * @property int $rank * @property array $highscore * @return array $highscoresArray */ public function getAllHighscores() { $highscoresDBObject = Highscore::orderByDesc('score') ->limit(10) ->get(); $highscoresArray = []; $rank = 0; foreach ($highscoresDBObject as $highscore) { $rank += 1; array_push($highscoresArray, [ 'rank' => $rank, 'player' => $highscore->player, 'score' => $highscore->score, 'date_played' => substr($highscore->date_played, 0, 10) ]); } return $highscoresArray; } } ``` "
262447,291881,https://api.github.com/repos/John200410/rusherhack-issues/issues/360,enhancement,2021-01-17T06:09:27Z,NONE,https://api.github.com/repos/John200410/rusherhack-issues,[FEATURE] Targethud Create an additional square that contains viewmodel of targeted player health of targeted player totempop of targeted player armor durability of targeted player inventory of targeted player this will give alot of info to the user (rusherhack user) and possibly win fight because of this feature 
26812,29877,https://api.github.com/repos/fyne-io/fyne/issues/1884,question,2021-01-30T05:06:03Z,CONTRIBUTOR,https://api.github.com/repos/fyne-io/fyne,"README Images taken without focus? ### Describe the bug: It would appear the images within the README were screen shots taken without the window in focus. Among other slight differences in our Widgets (and how they might look with or without focus), the most jarring difference is that the Mac OS X stoplights which normally decorate the window title are grey circles, which simply looks out of place. <div align=""center""><table><tr><td><img src=""https://raw.githubusercontent.com/fyne-io/fyne/master/img/hello-light.png"" alt=""Fyne Hello Light Theme""/></td><td><img src=""https://raw.githubusercontent.com/fyne-io/fyne/master/img/hello-dark.png"" alt=""Fyne Hello Dark Theme""/></td></tr></table></div> "
506116,562503,https://api.github.com/repos/dapr/java-sdk/issues/399,question,2020-11-27T09:24:36Z,NONE,https://api.github.com/repos/dapr/java-sdk,"How to set timeout invoking service How to set a timeout per request when invokeService ? invokeService will return a Mono<T>, Mono.block(Duration.ofMills(3000)) and Mono.timeout(Duration.ofMills(3000)) seems not work as I expected. The default timeout of DaprHttp is 10s . How can I invoke different service with different timeout with only one daprClient instance?"
342544,380804,https://api.github.com/repos/circlesland/o-platform/issues/164,bug,2021-05-14T09:07:57Z,CONTRIBUTOR,https://api.github.com/repos/circlesland/o-platform,"The amount of tiny transactions, like 0.0000001 is not displayed properly on the transaction detail page ""1 e7 circles"" should be => ""0.0000001"" <img width=""948"" alt=""Bildschirmfoto 2021-05-14 um 11 07 17"" src=""https://user-images.githubusercontent.com/747161/118248411-8c838d80-b4a4-11eb-8cab-027afe64274b.png""> "
554234,615953,https://api.github.com/repos/akasatan/workbook_app/issues/11,bug,2021-04-20T07:00:33Z,OWNER,https://api.github.com/repos/akasatan/workbook_app,管理者のdeviseが本番環境で動くか deviseの導入順番を間違えたのかエラーになりまくってやり直したので、 動くか心配です。本番環境で動くか確認したらissue閉じます。
364423,405099,https://api.github.com/repos/shadowwalker/next-pwa/issues/131,bug,2020-12-12T22:57:00Z,NONE,https://api.github.com/repos/shadowwalker/next-pwa,"OAuth flow breaks on Safari (iOS and MacOS) in PWA # Summary When I try to use Google OAuth with [next-auth](https://github.com/vercel/next.js/tree/canary/examples/with-next-auth) and add next-pwa to my app, it doesn't work in Safari for Mac and iOS devices. The user is able to enter Google credentials, but when Google attempts to redirect back to the app next-auth returns an error. # How To Reproduce I am using [next-auth](https://github.com/vercel/next.js/tree/canary/examples/with-next-auth) with the [progressive-web-app](https://github.com/vercel/next.js/tree/canary/examples/progressive-web-app). I created a [repo](https://github.com/Ramos-Diego/pwa) which is the simplest combination of these two examples. 1. Visit [pwa-sage.vercel.app](https://pwa-sage.vercel.app/) from an iPhone or Mac 2. Click on the `Sign In` button in the top right corner 3. Enter Google credentials and try to login 4. See error # Expected Behaviors You will not be able to login from an iOS or Mac device # Screenshots next-auth generates this error ONLY when attempting to authenticate in a Mac or iOS device. ``` [GET] /api/auth/callback/google?state=a18d41d8...bd&code=4%2...lHx1JC-fg&scope=email+profile+openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.profile+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email&authuser=0&prompt=none 12:57:40:47 Status: 302 Duration: 3.58ms Memory Used: 108 MB ID: l...d-160...1-79c...4 User Agent: Mozilla/5.0 (iPhone; CPU iPhone OS 14_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.1 Mobile/15E148 Safari/604.1 2020-12-12T17:57:40.487Z a...c-690c-4ac7-b...7-f8...82 ERROR [next-auth][error][callback_oauth_error] Error: Invalid state returned from oAuth provider at /var/task/node_modules/next-auth/dist/server/lib/oauth/callback.js:46:27 at Generator.next (<anonymous>) at asyncGeneratorStep (/var/task/node_modules/next-auth/dist/server/lib/oauth/callback.js:26:103) at _next (/var/task/node_modules/next-auth/dist/server/lib/oauth/callback.js:28:194) at /var/task/node_modules/next-auth/dist/server/lib/oauth/callback.js:28:364 at new Promise (<anonymous>) at /var/task/node_modules/next-auth/dist/server/lib/oauth/callback.js:28:97 at /var/task/node_modules/next-auth/dist/server/lib/oauth/callback.js:143:17 at /var/task/node_modules/next-auth/dist/server/routes/callback.js:58:31 at Generator.next (<anonymous>) https://next-auth.js.org/errors#callback_oauth_error ``` ![photo_2020-12-12_17-55-22](https://user-images.githubusercontent.com/57334399/101998664-3c10c580-3ca3-11eb-81f7-2cf8b0138aa5.jpg) Everything that I've read points that the issue is caused by PWA and not the next-auth or my implementation of next-auth. # Additional Context I've already asked in other repos about this issue, [see here](https://github.com/vercel/next.js/discussions/20119), but I'm still looking for a solution. I don't mind completely disabling everything related to `next-pwa` in iOS and Mac devices if that means having my OAuth work and still have PWA for the other devices. "
490186,544803,https://api.github.com/repos/nixgates/plugin.video.seren/issues/421,bug,2021-01-15T21:11:02Z,NONE,https://api.github.com/repos/nixgates/plugin.video.seren,"[BUG] **Logs** Please provide debug logs to assist with your issue **Describe the bug** A clear and concise description of what the bug is. **To Reproduce** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected behavior** A clear and concise description of what you expected to happen. **Screenshots** If applicable, add screenshots to help explain your problem. **Kodi Version (please complete the following information):** - Kodi Version [e.g. 18.7, 19.0rc1] - Version [e.g. 22] **Additional context** Add any other context about the problem here. "
610896,678901,https://api.github.com/repos/jmwerner/recipes/issues/260,enhancement,2020-12-26T23:34:38Z,OWNER,https://api.github.com/repos/jmwerner/recipes,"Add defensive checks for glass types Right now it naively takes glass type and adds an extension, add some defensive checks (or maybe a dropdown in the input app?)"
269449,299650,https://api.github.com/repos/libsdl-org/SDL/issues/2212,bug,2021-02-11T00:23:47Z,COLLABORATOR,https://api.github.com/repos/libsdl-org/SDL,"Screen corruption after alt+tab # This bug report was migrated from our old Bugzilla tracker. These attachments are available in the static archive: * [screen capture (7b3af792-3ba1-11e6-98fd-7794cb04fa5f.png, image/png, 2016-07-03 05:36:33 +0000, 81640 bytes)](https://bugzilla.libsdl.org/attachment.cgi?id=2522) **Reported in version:** 2.0.1 **Reported for operating system, platform:** Windows 10, x86_64 # Comments on the original bug report: On 2016-07-03 05:36:33 +0000, DLaboratory wrote: > Created attachment 2522 > screen capture > > Alt+tabing works fine first 1-3 times, but then the issue begins to occur. After the user switches back, the screen is corrupted. On 2016-07-07 19:08:47 +0000, Philipp Wiesemann wrote: > Is this only with SDL 2.0.1 (as selected above) or still with SDL 2.0.4? On 2016-07-08 12:42:44 +0000, DLaboratory wrote: > (In reply to Philipp Wiesemann from comment # 1) > > Is this only with SDL 2.0.1 (as selected above) or still with SDL 2.0.4? > > Yes, still happening with SDL 2.0.4. On 2017-08-12 01:16:59 +0000, Sam Lantinga wrote: > Can you attach a test program or a link to the source for this program so we can reproduce it here? > > Thanks! On 2018-08-06 21:20:18 +0000, Ryan C. Gordon wrote: > > Hello, and sorry if you're getting dozens of copies of this message by email. > > We are closing out bugs that appear to be abandoned in some form. This can happen for lots of reasons: we couldn't reproduce it, conversation faded out, the bug was noted as fixed in a comment but we forgot to mark it resolved, the report is good but the fix is impractical, we fixed it a long time ago without realizing there was an associated report, etc. > > Individually, any of these bugs might have a better resolution (such as WONTFIX or WORKSFORME or INVALID) but we've added a new resolution of ABANDONED to make this easily searchable and make it clear that it's not necessarily unreasonable to revive a given bug report. > > So if this bug is still a going concern and you feel it should still be open: please feel free to reopen it! But unless you respond, we'd like to consider these bugs closed, as many of them are several years old and overwhelming our ability to prioritize recent issues. > > (please note that hundred of bug reports were sorted through here, so we apologize for any human error. Just reopen the bug in that case!) > > Thanks, > --ryan. "
420748,467700,https://api.github.com/repos/ntop/ntopng/issues/3974,enhancement,2020-05-22T10:36:04Z,MEMBER,https://api.github.com/repos/ntop/ntopng,"Implement alert filtering As of today alert filtering is implemented but a bit cumbersome. ![Screen Shot 2020-05-22 at 12 19 35](https://user-images.githubusercontent.com/4493366/82658126-c5d54480-9c26-11ea-8bd7-44a541fea0ea.png) As alerts are being reimplemented (see #3859) we also need to implement a criteria for filtering out in a single place, all ""potential"" alerts before they become ""confirmed"". In essence today when an alert is triggered, there is no simple way to discard it before it is generated. Examples - Fortinet firewalls do probing on home networks and thus they generate many ""suspicious tcp syn probing"" that should be ignored. - if device X use the DNS to verify the hash of downloaded files (Zeek does) queries like 3a34edefdd2c1ad4bb71214fcb9356e575a334234265e.malware.hash.cymru.com are issued and they generate many alerts So in essence it needs to be implemented a pre-filtering step when potential alerts can be filtered/silenced in a simple way before they become alert, or drop too many alerts produced by a single device... things like these that can help reducing noise in data analysis. Please see also #3859. "
502197,558189,https://api.github.com/repos/VGavara/ArduinoTB6612FNG/issues/10,enhancement,2021-01-27T19:39:43Z,OWNER,https://api.github.com/repos/VGavara/ArduinoTB6612FNG,Complete Spinner examples Complete the Spinner class with one more example aborting the spinning when the map reached a certain point. Don't base the example in callbacks but in checking the results returned by `spin()` function. Create a README.md file per example and add the required graphic documents (see Motor examples) Special care must be put in adding a subdirectory per example (as Spinner/SpinnerExample01) to be aligned with the directory structure expected by Arduino IDE.
294494,327475,https://api.github.com/repos/libsdl-org/SDL-1.2/issues/448,enhancement,2021-02-10T21:12:55Z,COLLABORATOR,https://api.github.com/repos/libsdl-org/SDL-1.2,"Ported sdl-config # This bug report was migrated from our old Bugzilla tracker. These attachments are available in the static archive: * [converted sdl-script (sdl-config.bat, text/plain, 2008-12-31 02:56:25 +0000, 1100 bytes)](https://bugzilla.libsdl.org/attachment.cgi?id=286) **Reported in version:** 1.2.13 **Reported for operating system, platform:** Windows (XP), x86 # Comments on the original bug report: On 2008-12-31 02:37:04 +0000, bauke wrote: > The sdl-config sh-script doesn't work that well under windows. Would it be an idea to include a cmd-script? > > If created a port of the script. Here's the source: > > @echo off > set VAR=before > if ""!VAR!"" == ""before"" ( > set VAR=after > if not ""!VAR!"" == ""after"" ( > cmd /V:ON /C %0 %1 %2 %3 %4 %5 %6 %7 %8 %9 > exit /B > ) > ) > > set prefix=c:/mingw/bin > set exec_prefix=%prefix% > set exec_prefix_set=no > > set usage=Usage: sdl-config [--prefix[=DIR]] [--exec-prefix[=DIR]] [--version] [--cflags] [--libs] [--static-libs] > > if ""%1""=="""" ( > echo !usage! 1>&2 > exit /B > ) > > set L=%1,%2,%3,%4,%5,%6,%7,%8,%9 > for %%f in (!L!) do ( > set G=%%f > set Q=!G:~0,9! > if ""!Q!""==""--prefix="" ( > set prefix=!G:~9! > if !exec_prefix_set!==no ( > set exec_prefix=!G:~9! > ) > ) > set Q=!F:~0,14! > if ""!Q!""==""--exec-prefix="" ( > set exec_prefix_set==yes > set exec_prefix=!G:~14! > ) > if ""!G!""==""--prefix"" ( > echo !prefix! > ) > if ""!G!""==""--exec-prefix"" ( > echo !exec_prefix! > ) > if ""!G!""==""--version"" ( > echo 1.2.13 > ) > if ""!G!""==""--cflags"" ( > echo -I!prefix!/include/SDL -D_GNU_SOURCE=1 -Dmain=SDL_main > ) > if ""!G!""==""--libs"" ( > echo -L!exec_prefix!/lib -lmingw32 -lSDLmain -lSDL -mwindows > ) > if ""!G!""==""--static-libs"" ( > echo -L!exec_prefix!/lib -lmingw32 -lSDLmain -lSDL -mwindows > ) > ) On 2008-12-31 02:56:25 +0000, bauke wrote: > Created attachment 286 > converted sdl-script > > The previous script didn't work correctly. This one is supposed to do so. On 2009-09-13 16:33:30 +0000, Ryan C. Gordon wrote: > > Tagging this bug with ""target-1.2.14"" so we can try to resolve it for SDL 1.2.14. > > Please note that we may choose to resolve it as WONTFIX. This tag is largely so we have a comprehensive wishlist of bugs to examine for 1.2.14 (and so we can close bugs that we'll never fix, rather than have them live forever in Bugzilla). > > --ryan. On 2009-09-21 03:58:13 +0000, Sam Lantinga wrote: > Thanks for the script! I won't include it because it won't work for people using MSys or Cygwin32, but I'm sure someone can use it! "
687561,764142,https://api.github.com/repos/Reiningecho90/S.A.N.E.-Repo/issues/3,enhancement,2021-04-13T20:44:55Z,OWNER,https://api.github.com/repos/Reiningecho90/S.A.N.E.-Repo,"No .txt files with the source code branch(es), or main branch Add source code to the PC Source code, and copy over with Beta v1.1 rollout."
438574,487588,https://api.github.com/repos/omen273/crosswordApp/issues/138,bug,2021-04-11T21:34:25Z,COLLABORATOR,https://api.github.com/repos/omen273/crosswordApp,Crossword data was damaged Steps to reproduce: 1. fill crossword 2. choose new 3. from main activity choose old crossword 4. choose new again 5. get an error message in main activity
535171,594807,https://api.github.com/repos/moq/moq4/issues/1143,question,2021-02-09T14:16:37Z,NONE,https://api.github.com/repos/moq/moq4,How to mock the this.context.Database.BeginTransaction() in Asp.net Core? How to mock the this.context.Database.BeginTransaction() in Asp.net Core? Unable to mock the Begin Transaction in EF.
662704,736622,https://api.github.com/repos/Shravan-1908/hydra/issues/3,bug,2021-05-12T14:45:16Z,NONE,https://api.github.com/repos/Shravan-1908/hydra,"Bash Script installation not working I have tried installing hydra via the bash script in the README on Ubuntu and Pop OS, but it is not getting installed with the script. "
277172,308257,https://api.github.com/repos/ghdl/ghdl/issues/566,question,2018-05-02T15:39:50Z,COLLABORATOR,https://api.github.com/repos/ghdl/ghdl,"Migration from travis-ci.org Travis is starting to merge travis-ci.org and travis-ci.com. GHDL is not affected, yet, but it will be in the following months: > However, open source repositories will be migrated to travis-ci.com gradually, beginning at the end of Q2 2018 https://docs.travis-ci.com/user/open-source-on-travis-ci-com/#Existing-Open-Source-Repositories-on-travis-ci.org @tgingold, do we want to keep the build history? If not, you can send an e-mail and have the migration done now. Apart from the domain, they are also going to change how authentication works. We should keep an eye on it: > This creates the foundation for us to remove the repo-scoped OAuth login token, which is a common request. https://blog.travis-ci.com/2018-05-02-open-source-projects-on-travis-ci-com-with-github-apps"
205236,228203,https://api.github.com/repos/rednir/wow2/issues/36,bug,2021-04-29T23:19:04Z,OWNER,https://api.github.com/repos/rednir/wow2,"Fix null reference when checking bot messages ``` System.NullReferenceException: Object reference not set to an instance of an object. at wow2.Modules.Moderator.ModeratorModule.GetUserRecord(ModeratorModuleConfig config, UInt64 id) in /home/pi/source/wow2/src/Modules/Moderator/ModeratorModule.cs:line 212 at wow2.Modules.Moderator.ModeratorModule.CheckMessageWithAutoMod(SocketMessage message) in /home/pi/source/wow2/src/Modules/Moderator/ModeratorModule.cs:line 31 at wow2.EventHandlers.MessageRecievedAsync(SocketMessage receivedMessage) in /home/pi/source/wow2/src/EventHandlers.cs:line 157 at Discord.EventExtensions.InvokeAsync[T](AsyncEvent`1 eventHandler, T arg) at Discord.WebSocket.DiscordSocketClient.TimeoutWrap(String name, Func`1 action) ```"
703548,781921,https://api.github.com/repos/digimezzo/knowte/issues/150,bug,2021-04-29T08:34:31Z,OWNER,https://api.github.com/repos/digimezzo/knowte,Note title font is too bold This is especially noticeable in Windows.
295672,328788,https://api.github.com/repos/mitchelloharawild/vitae/issues/59,enhancement,2019-05-14T10:43:46Z,OWNER,https://api.github.com/repos/mitchelloharawild/vitae,"Improve introduction vignette The document body section should be more detailed on how to input data without external sources (maybe direct from a tibble, keep it very simple!)"
315039,350248,https://api.github.com/repos/KWB-R/dwc.wells/issues/1,enhancement,2021-03-25T07:25:17Z,MEMBER,https://api.github.com/repos/KWB-R/dwc.wells,"feat: add renamings ""Parameterliste.xlsx"" table to inst/extdata/ but as `parameterliste.csv` https://github.com/KWB-R/dwc.wells/blob/dev/inst/scripts/prepare_data.R#L17 "
109856,122116,https://api.github.com/repos/hengband/hengband/issues/51,enhancement,2021-02-10T13:02:11Z,NONE,https://api.github.com/repos/hengband/hengband,AQUATICつきモンスターの陸上生成の可能性 OSDNより移行。[41437](https://osdn.net/projects/hengband/ticket/41437) ![lup13088](https://user-images.githubusercontent.com/78687408/107513457-94a10800-6beb-11eb-88cc-379a011599c7.png) 山の特殊地形にて遭遇。空を飛べはしますが水棲生物であるセイレーンが陸上に生成されています。
545720,606547,https://api.github.com/repos/grindsa/acme2certifier/issues/55,enhancement,2021-04-12T15:17:01Z,NONE,https://api.github.com/repos/grindsa/acme2certifier,"EAB registration - database trail Hi, first thanks for the amazing work on this project. With the recent introduction of EAB support I was wondering if new account requests could also leave a trail in the database to see which EAB_key_id was used to register an account? In this way we can ensure we know exactly which ACME account is associated with a specific EAB account. "
704878,783414,https://api.github.com/repos/IDAES/idaes-pse/issues/344,bug,2021-05-14T21:37:00Z,MEMBER,https://api.github.com/repos/IDAES/idaes-pse,"Fragile model tests In working on addressing #330 and #340, a few tests were discovered that fail under specific circumstances, suggesting an underlying issue that needs to be addressed. Know tests include: - PFR tests with saponification properties - outright solver failure. Occurs when running PFR tests in isolation. - Distiallation (reboiler?) - small deviation from expected value. Have not determined how to reliably reproduce yet. - Pressure changer - I recall seeing this turn up as well These failures maybe related to unexpected changes in default solver options during testing."
552019,613503,https://api.github.com/repos/LCailliot/EasySSL/issues/2,enhancement,2021-01-29T15:28:43Z,OWNER,https://api.github.com/repos/LCailliot/EasySSL,EasySSL python command CLI # Python command CLI : ## Requirements : * [x] move easyssl.sh to bin/cert.sh * [x] move bin/platform_certs.py to bin/platform_material.sh ## Features * [x] cert option : redirect all arguments to bin/cert.sh * [x] store option: redirect all arguments to bin/store.sh * [x] platform option : redirect all arguments to bin/platform_material.py
217826,242220,https://api.github.com/repos/HomeITAdmin/nextcloud_geoblocker/issues/53,enhancement,2021-01-03T10:19:22Z,OWNER,https://api.github.com/repos/HomeITAdmin/nextcloud_geoblocker,Add support for Nextcloud 21 Test and add at early stage this time.
143214,159189,https://api.github.com/repos/dotnet/roslyn-analyzers/issues/4630,enhancement,2020-12-22T17:18:26Z,NONE,https://api.github.com/repos/dotnet/roslyn-analyzers,"CA2225: named alternates, allow 'As' instead of 'To' ### Analyzer **Diagnostic ID**: [CA2225](https://docs.microsoft.com/en-us/dotnet/fundamentals/code-analysis/quality-rules/ca2225) ### Describe the improvement It appears that using `As` as prefix for methods that convert an object is used increasingly in .NET (AsSpan, AsMemory, AsReadOnlySpan, etc.). So, the rule should allow methods named ToObject and AsObject. ### Describe suggestions on how to achieve the rule Add `As` as a valid prefix to fulfill the rule ### Additional context None "
176893,196665,https://api.github.com/repos/lucene-cn/lxdb/issues/84,bug,2021-01-29T06:14:23Z,NONE,https://api.github.com/repos/lucene-cn/lxdb,"describe database FORMATTED 查看数据库属性失败 测试步骤： describe database FORMATTED djj; 结果： Error: extraneous input 'djj' expecting <EOF>; line 1 pos 28 (state=,code=0) 期望; 应展示数据库的属性信息 ![image](https://user-images.githubusercontent.com/76684843/106238534-fb154600-623b-11eb-9b61-7c58c809c02d.png) "
446469,496236,https://api.github.com/repos/microsoft/SCMScaleUnitDevTools/issues/27,enhancement,2021-02-04T13:53:21Z,CONTRIBUTOR,https://api.github.com/repos/microsoft/SCMScaleUnitDevTools,"Tool attempts to uninstall/stop scale unit Batch service if it does not exist This is minor; the tool currently shows an error while enabling the hybrid topology on a shared-box scale unit (when it creates the additional Batch service) - the error is benign as we ignore it, but we can avoid it completely if we just check if the Batch service is installed or not."
653238,726140,https://api.github.com/repos/DidierRLopes/GamestonkTerminal/issues/85,bug,2021-03-03T15:27:43Z,NONE,https://api.github.com/repos/DidierRLopes/GamestonkTerminal,"[Bug] Not being able to run from the docker image **Describe the bug** After building a docker image, the application crashes when I try to execute with `docker run`, with the following error: ``` 2021-03-03 15:16:41.157332: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory 2021-03-03 15:16:41.157405: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine. /home/python/.local/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:100.) return torch._C._cuda_getDeviceCount() > 0 Welcome to Didier's Gamestonk Terminal What do you want to do? help help to see this menu again quit to abandon the program clear clear a specific stock ticker from analysis load load a specific stock ticker for analysis view view and load a specific stock ticker for technical analysis Stock: ? Market OPEN. Menus: disc discover trending stocks, e.g. map, sectors, high short interest sen sentiment of the market, from: reddit, stocktwits, twitter > Traceback (most recent call last): File ""gamestonk_terminal.py"", line 328, in <module> main() File ""gamestonk_terminal.py"", line 213, in main as_input = input('> ') EOFError: EOF when reading a line ``` **To Reproduce** Either in Windows 10 or macOS Catalina: - `docker build -t gamestonkterminal` - `docker run gamestonkterminal` **Desktop (please complete the following information):** - OS: both macOS Catalina and Windows 10 1909 - Python version [e.g. 3.6.8] **Additional context** GPU: GeForce GTX 1060 with the last Game Ready drivers installed. "
153147,170257,https://api.github.com/repos/djkoloski/rkyv/issues/30,enhancement,2021-01-13T17:47:12Z,OWNER,https://api.github.com/repos/djkoloski/rkyv,Link book in README The crate READMEs link to the docs but don't link to the book. Getting this more visibility will help onboarding.
434876,483450,https://api.github.com/repos/root-project/root/issues/6881,bug,2020-11-25T18:10:58Z,MEMBER,https://api.github.com/repos/root-project/root,"[TTreeReader] Partial leaf/branch names not recognized in cases that TTree::Draw supports - [x] Checked for duplicates <!-- Please search in * [GitHub](https://github.com/root-project/root/issues?q=is%3Aissue) * AND [Jira](https://sft.its.cern.ch/jira/issues/?jql=project %3D ROOT) for existing reports of your issue. If you find one, you are very welcome to add to the existing report, for instance ""issue still exists in today's master"". --> ### Describe the bug <!-- A clear and concise description of what the wrong behavior is. --> First reported [here](https://root-forum.cern.ch/t/tchain-parallel-reading-more-than-1-branch/42348/13). For this TTree (the file is linked from the forum post): ``` root [12] DmpMCEvtNtup->Print(""NUD_total_ADC*"") ****************************************************************************** *Tree :DmpMCEvtNtup: DAMPE MC Event nTuple Tree * *Entries : 30000 : Total = 42024515 bytes File Size = 5331016 * * : : Tree compression factor = 7.90 * ****************************************************************************** *Br 0 :NUD_total_ADC : nud_total_adc/D * *Entries : 30000 : Total Size= 241261 bytes File Size = 7509 * *Baskets : 8 : Basket Size= 32000 bytes Compression= 32.06 * *............................................................................* ``` ``` DmpMCEvtNtup->Draw(""NUD_total_ADC"") ``` works, while ``` root [13] TTreeReader r(DmpMCEvtNtup); root [14] TTreeReaderValue<double> rv(r, ""NUD_total_ADC""); root [15] r.Next() Error in <TTreeReaderValueBase::GetBranchDataType()>: The branch NUD_total_ADC was created using a leaf list and cannot be represented as a C++ type. Please access one of its siblings using a TTreeReaderArray: Error in <TTreeReaderValueBase::GetBranchDataType()>: NUD_total_ADC.nud_total_adc Error in <TTreeReaderValueBase::CreateProxy()>: The branch NUD_total_ADC contains data of type {UNDETERMINED TYPE}, which does not have a dictionary. (bool) false ``` does not. `TTreeReader` instead requires the full leaf name: ``` root [1] TTreeReader r(DmpMCEvtNtup); root [2] TTreeReaderValue<double> rv(r, ""NUD_total_ADC.nud_total_adc""); root [3] r.Next() (bool) true root [4] *rv (double) -999.00000 ``` ### Expected behavior <!-- A clear and concise description of what you expected to happen. --> `TTreeReader` should support the same set of ""valid branch names"" that `TTree::Draw` supports. ### Setup <!-- 1. ROOT version 2. Operating system 3. How you obtained ROOT, such as `dnf install` / binary download / you built it yourself. --> Reproduced with 6.22/02 and master@4ea4d8943 . ### Additional context <!-- Add any other context about the problem here. --> This looks similar to https://sft.its.cern.ch/jira/browse/ROOT-7984 and it is (at least part of) the cause of https://sft.its.cern.ch/jira/browse/ROOT-9558 ."
345949,384592,https://api.github.com/repos/oizhaolei/spa-wiki/issues/53,bug,2020-11-03T09:06:59Z,COLLABORATOR,https://api.github.com/repos/oizhaolei/spa-wiki,53.用户view-->工作流一览-->状态一列的数据来自哪里 用户View里的工作流一览中，有 状态 一列，这一列的数据从哪里来的？都有哪些状态？ ![userViewFlowListStatus](https://user-images.githubusercontent.com/18024406/97966566-f4bb2d80-1df6-11eb-95c6-bf9f571f090d.jpg) 
158284,175978,https://api.github.com/repos/nextcloud/cookbook/issues/549,bug,2021-01-22T05:08:11Z,NONE,https://api.github.com/repos/nextcloud/cookbook,Internal Server Error Never mind - issue was a duplicate. https://github.com/nextcloud/cookbook/issues/527
143674,159708,https://api.github.com/repos/ausaf-a/life.cpp/issues/1,enhancement,2021-04-02T14:56:16Z,OWNER,https://api.github.com/repos/ausaf-a/life.cpp,"Add support for setting cells to dead Currently, dragging using the mouse is only able to turn dead cells to alive, not the other way around. When making more complex creatures, you have to start over completely to fix small mistakes. Adding a ""delete mode"" would be one way of doing this, or by intelligently checking whether a cell is alive or dead when the mouse starts dragging on it. "
392923,436740,https://api.github.com/repos/DavidAnson/vscode-markdownlint/issues/156,question,2021-03-24T09:03:42Z,NONE,https://api.github.com/repos/DavidAnson/vscode-markdownlint,[Question] How to make it consistent with CommonMark I was checking this file https://github.com/joelparkerhenderson/monorepo_vs_polyrepo/blob/master/README.md and vscode shows me 138 problems. I didn't know about CommonMark until this https://github.com/joelparkerhenderson/monorepo_vs_polyrepo/pull/5. Now I wanted to enable a set of rules or a mode that helps me to be consistent with CommonMark but couldn't find the way. Is there a way fo achieve this using this extension?
151482,168410,https://api.github.com/repos/numbersprotocol/capture-lite/issues/561,bug,2021-03-05T08:37:55Z,NONE,https://api.github.com/repos/numbersprotocol/capture-lite,capture 頁面日期格是不一樣 ## Description capture 頁面日期格是不一樣 目前 : 2021/03/05 修改為 : Mar. 2021 
61298,68128,https://api.github.com/repos/PyTorchLightning/pytorch-lightning/issues/5361,enhancement,2021-01-05T15:18:25Z,NONE,https://api.github.com/repos/PyTorchLightning/pytorch-lightning,"weights_save_path get overridden by modelcheckpoint but nothing indicate that. More like a ""bug prone"" feature IMHO. Searching for ""weights_save_path"" in the source yield no other use except for modelcheckpoint, so I think that in case where the model checkpoint ignores the weights_save_path variable, it's better let the user know that he is incorrectly using the API rather then letting him explore why the model does not appear where it wished it to be (or why I'm getting ""out of space"" error even though the external device I'm saving to is empty Haha). I don't mind PR-ing this, but let me know if this is acceptable by you. "
384136,427008,https://api.github.com/repos/fabric8io/kubernetes-client/issues/2768,question,2021-02-01T09:53:18Z,NONE,https://api.github.com/repos/fabric8io/kubernetes-client,"io.fabric8.kubernetes.client.KubernetesClientException: too old resource version Experiencing repeated ""too old resource version"" onClose() exceptions in a Watcher object. The resource being watched, a Job, runs for several hours but (typically) after 80-100 minutes I always encounter a ""too old resource version"" exception. I re-create the Watch object, but after another period (35 minutes in one case) I encounter another ""too old resource version"" exception. I keep re-creating the Watch object until the underlying Job completes. The exception stack is as follows: ``` 2021-01-26 06:28:17 ERROR EngineWatcher:87 - too old resource version: 51780364 (52677017) io.fabric8.kubernetes.client.KubernetesClientException: too old resource version: 51780364 (52677017) at io.fabric8.kubernetes.client.dsl.internal.WatchConnectionManager$1.onMessage(WatchConnectionManager.java:257) at okhttp3.internal.ws.RealWebSocket.onReadMessage(RealWebSocket.java:323) at okhttp3.internal.ws.WebSocketReader.readMessageFrame(WebSocketReader.java:219) at okhttp3.internal.ws.WebSocketReader.processNextFrame(WebSocketReader.java:105) at okhttp3.internal.ws.RealWebSocket.loopReader(RealWebSocket.java:274) at okhttp3.internal.ws.RealWebSocket$2.onResponse(RealWebSocket.java:214) at okhttp3.RealCall$AsyncCall.execute(RealCall.java:203) at okhttp3.internal.NamedRunnable.run(NamedRunnable.java:32) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) ``` What is the cause of this problem and how can I solve it"
302506,336337,https://api.github.com/repos/RayTakemura/jest-another-RPG/issues/1,enhancement,2021-04-13T06:06:18Z,OWNER,https://api.github.com/repos/RayTakemura/jest-another-RPG,"Create a Potion object Create tests for the Potion object. The Potion object will be used to give the player stat boosts. If no stat is provided, the stat should be randomly selected."
57557,63981,https://api.github.com/repos/jellyfin/jellyfin/issues/5204,bug,2021-02-10T12:27:08Z,NONE,https://api.github.com/repos/jellyfin/jellyfin,"non-RC jellyfin version shown in RC **Describe the bug** Hello, I'm currently running 10.7.0-RC3 I think, and it just shows version 10.7.0 on the dashboard instead of the RC. I initially downloaded this version just because I use the syncplay a lot, but now that I want to help find bugs again it's hard to remember what RC I'm on. I'm using the stable-RC docker release channel. **System (please complete the following information):** - OS: Unraid - Virtualization: Docker - Clients: Browser, Android - Browser: All - Jellyfin Version: 10.7.0 RC3 I think, i dont know I only know its the current stable-rc release - Reverse Proxy: nginx **To Reproduce** <!-- Steps to reproduce the behavior: --> 1. On the current RC version go to the dashboard 2. Notice that the version there doesn't specify the current RC **Expected behavior** I expected it to say 10.7.0-rc3 "
428243,476041,https://api.github.com/repos/Chatterino/chatterino2/issues/2562,bug,2021-03-24T16:08:05Z,NONE,https://api.github.com/repos/Chatterino/chatterino2,"Badges not showing (MacOS Big Sur) 2.2.3-beta2 Subscriber, VIP, Mod and Bit badges not showing up on MacOS Big Sur. Running version 2.2.3-beta2 "
635809,706652,https://api.github.com/repos/Twake/Twake/issues/828,bug,2021-01-28T03:36:45Z,MEMBER,https://api.github.com/repos/Twake/Twake,"Create Channel > Breaking ""Add members"" form when the channel name length is over 100 characters # Precondition Story: https://github.com/TwakeApp/Twake/issues/321 # Actual Result When inputting the channel name with the length is over 100 characters, the ""add members"" form is breaking ![Peek 2021-01-28 10-25.gif](https://images.zenhubusercontent.com/5f76a1e8a1698e3d1ae2d969/d2348bfa-f925-4c12-abea-a6a49bce182b) # Expected Result The channel name should have a length limitation The ""add members"" form should be responsive. # Environment Chrome Ubuntu "
135892,151051,https://api.github.com/repos/PHPfox-Official/phpfox-v4-issues/issues/2387,enhancement,2018-09-04T10:50:21Z,NONE,https://api.github.com/repos/PHPfox-Official/phpfox-v4-issues,"hastags in comments don't show up in feed when click on them ---------------------------------------- ## What happened? ... when add a hashtag in comment and it shows as a #hastag but that comment doesn't show up when we click on the hashtag says nothing there ?? ## Steps to reproduce: 1. go to a post and comment and add a hashtag in your comment 2. then click on the hashtag in your comment 3. it will go to feed and it shows nothing there ## What is expected? ... #hashtags should work in comments also, since we allow #hastags to show as #hastags in a comment ## Browsers and Devices tested (Example: Chrome on iPhone X, Safari on Macbook, Miscrosoft Edge on Windown 10, Firefox on Ubuntu 16.04, ...) ## Server information (Example: CentOS 7, php 7.1 apache) ... ## phpFox version (Example: phpFox 4.6.0) ... 4.6.1.b6 ## Screenshots ... ![capture](https://user-images.githubusercontent.com/17736688/45027183-4e9cee80-b006-11e8-96d2-181c9232922e.JPG) ![capture1](https://user-images.githubusercontent.com/17736688/45027184-4e9cee80-b006-11e8-82fc-d60ce3de434b.JPG) "
686979,763490,https://api.github.com/repos/nightwatchjs/nightwatch/issues/758,enhancement,2015-11-28T16:08:18Z,NONE,https://api.github.com/repos/nightwatchjs/nightwatch,"Don't print passwords: can I tell setValue() to be silent? Or add setPassword()? I'm filling in a password in an external service in an end-to-end test (a user logs in with OpenAuth in this external service). `browser.setValue()` prints the password on the console. Is there any way to tell it to not print the password? Alternatively, what about a function `setPassword(password)` that doesn't print the value to the console? Otherwise it could work exactly like `setValue()`. "
663300,737288,https://api.github.com/repos/badgateway/react-ketting/issues/43,bug,2021-03-27T12:06:56Z,NONE,https://api.github.com/repos/badgateway/react-ketting,"""Failed to resolve entry for package 'react-ketting'"" when using vite to build a react app I tried to add `react-ketting` to my react app which is build using [vite](https://vitejs.dev/). When running `yarn dev` on (Node 14.9.0), I get this error: ```text [vite:dep-scan] Failed to resolve entry for package ""react-ketting"". The package may have incorrect main/module/exports specified in its package.json. ``` I followed the instructions at https://github.com/badgateway/ketting/wiki/React. I've created a repro here: https://github.com/AlexZeitler/vite-react-ketting-repro I've [started a discussion about the issue](https://discord.com/channels/804011606160703521/814182556068085760/825203873177927680) on the vite Discord channel and I got [this answer](https://discord.com/channels/804011606160703521/814182556068085760/825320127682576414): > according to it's `package.json`, it should have a build version aimed at bundlers (""browser"" field) at `/browser/react-ketting.min.js`, but that folder/file doesn't exist in the bundle. the `""main""` field does point to a correct CJS module at `dist/index.js`, but I guess vite wants to prefer the entry defined in the `""browser""` field, and that one not existing throws it off. "
706670,785406,https://api.github.com/repos/applandinc/appmap-python/issues/94,enhancement,2021-04-29T11:00:04Z,CONTRIBUTOR,https://api.github.com/repos/applandinc/appmap-python,Drop support for Python 3.5 It's over five years old and seven months after its end of life: https://endoflife.date/python It breaks builds often and requires frequent special cases and special fixes.
271592,302041,https://api.github.com/repos/react-native-share/react-native-share/issues/798,question,2020-06-13T14:55:37Z,NONE,https://api.github.com/repos/react-native-share/react-native-share,"What is ""Share Single"" category ? Hello, when I go to the ""Share Single"" category in the documentation, I realize that there is a list of applications supported by the react-native-share package. So, to start with, I was already wondering what ""Share Single"" meant exactly. I didn't really understand the associated example gifs. Then, why are some applications, like FACEBOOK_STORIES, only supported on iOS and others only on Android? What's that due to ? Does this mean that I won't be able to share an image in a facebook storie from an android phone? Thanks for your answers Viktor"
262366,291789,https://api.github.com/repos/flybywiresim/a32nx/issues/3112,bug,2021-01-19T07:41:38Z,NONE,https://api.github.com/repos/flybywiresim/a32nx,"[BUG] Simbrief Payload won't be loaded <!-- ⚠⚠ Do not delete this issue template! ⚠⚠ --> <!-- Issues that do not use the issue template are likely to be ignored and closed. --> **Mod Version** <!-- Either a release version or ""master"" for the latest master branch. --> <!-- If you used the A32NX-master.zip, or the Dev version from the installer, paste the contents from the build_info.json here --> { ""built"": ""2021-01-19T01:05:05+00:00"", ""ref"": """", ""sha"": """", ""actor"": ""Matthew Sainsbury <matthew@sainsbury.io>"", ""event_name"": ""manual"" } **Describe the bug** <!-- A clear and concise description of what the bug is. --> When I load a flightplan from Simbrief it will pull the fuel but not the payload even though correctly displayed on page 2/2 of the PERF/W&B page. **To Reproduce** <!-- Steps to reproduce the behavior. --> <!-- We need to know how you encountered the bug to properly troubleshoot the issue. --> 1. Create a flightplan on Simbrief and load it into the aircraft. 2. Use the refuel softkey on the PERF/W&B page and note it works and changes the fuellevels. 3. Do the same for the payload and note it will always remain on what you set on the worldmap. **Expected behavior** <!-- A clear and concise description of what you expected to happen. --> It should enter the correctly displayed weights to reach a value above simbriefs expected TOW. **Actual behavior** <!-- A clear and concise description of what actually happened. --> Payload will not change. **References** <!-- If applicable, add screenshots or videos to help explain your problem. --> **Additional context** <!-- Add any other context about the problem here. --> Was this working before/when did the issue start occurring? Never. Is this a problem in the vanilla unmodded game? Doesnt support that feature. <!-- You may optionally provide your discord username, so that we may contact you directly about the issue. --> Discord username (if different from GitHub): Polacanthus#4729 ** as well as searched for other possible duplicate issues. I acknowledge if this line is not removed and/or the issue template is not respected, my issue will be closed without warning** "
71043,78976,https://api.github.com/repos/Catfriend1/syncthing-android/issues/586,enhancement,2019-12-20T11:21:28Z,OWNER,https://api.github.com/repos/Catfriend1/syncthing-android,"We need some in-app notification on the drawer FR. Then, we could also tutorial guide new users there, accept or deny connections..."
214407,238421,https://api.github.com/repos/Samerion/Isodi/issues/7,bug,2021-03-31T07:51:35Z,COLLABORATOR,https://api.github.com/repos/Samerion/Isodi,"The camera Y keyboard controls ocassionally cause a crash This is the error: ``` core.exception.AssertError@../isodi/source/isodi/camera.d(32): Camera angle Y must be at least 0°. ---------------- ??:? _d_assert_msg [0x563f50c2367e] ../isodi/source/isodi/camera.d:32 const void isodi.camera.Camera.Angle.__invariant4() [0x563f50c04212] ../isodi/source/isodi/camera.d:21 const void isodi.camera.Camera.Angle.__invariant() [0x563f50c043a7] ../isodi/source/isodi/camera.d:40 const @property float isodi.camera.Camera.Angle.x() [0x563f50c042d8] ../isodi/source/isodi/camera.d:77 void isodi.camera.Camera.offsetScreenX(float) [0x563f50c04485] ../isodi/source/isodi/raylib/camera.d:176 void isodi.raylib.camera.updateCamera(ref isodi.camera.Camera, isodi.raylib.camera.CameraKeybindings) [0x563f50beecf5] source/isodi.tools/main.d:79 _Dmain [0x563f50bc2c4f] Program exited with code 1 ``` This probably occurs in the isodi.raylib package."
477271,530420,https://api.github.com/repos/maralorn/nix-output-monitor/issues/14,enhancement,2020-11-09T08:07:18Z,CONTRIBUTOR,https://api.github.com/repos/maralorn/nix-output-monitor,Indication of failed packages It would be nice to keep track of this for when users are building with `-k` (staunch mode). Not sure what the UI should be exactly.
53795,59851,https://api.github.com/repos/darkshine0x/ExShift/issues/6,enhancement,2021-01-24T22:44:24Z,OWNER,https://api.github.com/repos/darkshine0x/ExShift,Create README The project misses a README. It should point for point explain the the different methods of the `ExcelObjectMapper` and the `Query` classes.
280595,312066,https://api.github.com/repos/Sunoo/homebridge-camera-ffmpeg/issues/957,enhancement,2020-12-24T15:33:16Z,NONE,https://api.github.com/repos/Sunoo/homebridge-camera-ffmpeg,"Add more automation/advanced Options <img width=""1149"" alt=""image"" src=""https://user-images.githubusercontent.com/60692414/103096847-9136ca80-4605-11eb-945d-d1dc1d833557.png""> "
261158,290447,https://api.github.com/repos/openremote/openremote/issues/362,bug,2021-03-03T17:45:23Z,MEMBER,https://api.github.com/repos/openremote/openremote,Consoles needs update Consoles still use /main which should be replaced by /manager: ![IMG_1315](https://user-images.githubusercontent.com/11444149/110011241-7c6e6580-7d1f-11eb-9742-ed225b081b87.png) 
690144,767035,https://api.github.com/repos/LuisPalacios/LuisPalacios.github.io/issues/4,enhancement,2021-05-02T04:37:06Z,OWNER,https://api.github.com/repos/LuisPalacios/LuisPalacios.github.io,Habilitar la posibilidad de dejar comentarios en el Blog Investigar si es posible implementar comentarios con Jekyll en GitHub pages y si es así implementar el mejor mecanismo. [Aquí](https://stackoverflow.com/questions/59096243/adding-comments-in-blog-posts-on-github-pages) vi un post al respecto... a estudiar... 
707110,785892,https://api.github.com/repos/sider/runners/issues/2034,enhancement,2021-02-08T08:27:54Z,MEMBER,https://api.github.com/repos/sider/runners,[PHPCS] Add `target` option I propose to add a new option `target` to the PHP_CodeSniffer runner. The reason is that users don't need to remember less about `sider.yml` because many other runners support the `target` option. The new option `target` will be an alias of the `dir` option at first. See also: https://github.com/sider/runners/blob/5c97f2c2208895c7d3fd331f85e07268ec3e3661/lib/runners/processor/code_sniffer.rb#L11
265979,295797,https://api.github.com/repos/Ubunfu/mc-log-bot/issues/19,bug,2021-03-31T02:56:02Z,OWNER,https://api.github.com/repos/Ubunfu/mc-log-bot,"Player joins aren't parsed correctly in non-vanilla servers Modpacks like the Forge-based Enigmatica 6 pack may alter the server log format slightly such that player joins are no longer parsed correctly. This results in non-sensical player names being posted to Discord via the web-hook. <img width=""371"" alt=""image"" src=""https://user-images.githubusercontent.com/4256242/113083715-a8f49080-91aa-11eb-9775-52e8a0e234a6.png""> Below is a sample log which breaks the current parsing ``` [29Mar2021 11:20:12.946] [Server thread/INFO] [net.minecraft.server.dedicated.DedicatedServer/]: pimpdaddysanta98 joined the game ```"
511829,568818,https://api.github.com/repos/hound-search/hound/issues/382,enhancement,2021-02-19T23:04:17Z,CONTRIBUTOR,https://api.github.com/repos/hound-search/hound,"Compile and bundle JavaScript using esbuild https://esbuild.github.io/ – esbuild is > An extremely fast JavaScript bundler It provides a CLI and a Go API, see https://esbuild.github.io/api/ It might be used to streamline the bundling and replace the webpack config."
518630,576371,https://api.github.com/repos/ustaxes/UsTaxes/issues/246,enhancement,2021-04-20T23:43:25Z,COLLABORATOR,https://api.github.com/repos/ustaxes/UsTaxes,Create 404 page Create 404 page that shows up when a user navigates to a page that is not defined in Urls const
476703,529785,https://api.github.com/repos/CraveFood/farmblocks/issues/1041,enhancement,2021-04-12T15:16:30Z,MEMBER,https://api.github.com/repos/CraveFood/farmblocks,[Icon] Add link to download the SVG files in the All Icons story This will be very helpful for the mobile team. We'll be able to look for the icons we need and download them directly from the list.
110378,122692,https://api.github.com/repos/SwissDataScienceCenter/renku/issues/532,enhancement,2019-03-20T15:29:20Z,NONE,https://api.github.com/repos/SwissDataScienceCenter/renku,"Enable ""pages"" in Gitlab https://gitlab.com/ allows for creating pages ![image](https://user-images.githubusercontent.com/4173925/54696873-e5597480-4b2c-11e9-8c2c-0aa349d123a9.png) Is it possible to have the same service on the Renku side? ![image](https://user-images.githubusercontent.com/4173925/54696895-f3a79080-4b2c-11e9-8cc7-7866a37e24cb.png) [It would be nice to be able to use Renku to write an e-book about Renku, not unlike https://gitlab.com/cchoirat/renku, https://cchoirat.gitlab.io/renku/]."
23760,26465,https://api.github.com/repos/syssi/xiaomi_airpurifier/issues/160,bug,2021-04-03T13:57:22Z,NONE,https://api.github.com/repos/syssi/xiaomi_airpurifier,"Speed field was change for zhimi.airfresh.va4. Hi. UI of zhimi.airfresh.va4 had change. VA4 model have 5 modes for fan speed. It's interval, silent, low, middle, strong. Now i have other interface for manage it. It's not correct. ![изображение](https://user-images.githubusercontent.com/48487551/113480508-341ca180-949d-11eb-839e-e8b036774c59.png) Early i had 5 modes in speed field."
42735,47586,https://api.github.com/repos/Bierinformatik/MIRfix/issues/5,enhancement,2019-08-01T12:01:10Z,COLLABORATOR,https://api.github.com/repos/Bierinformatik/MIRfix,"clustalw to clustalw2? Maybe is better in terms of speed, as referred on [this reference](https://academic.oup.com/bioinformatics/article/23/21/2947/371686): >The Clustal W and Clustal X multiple sequence alignment programs have been completely rewritten in C++. >Two new options have been included in Clustal W 2.0, to allow faster alignment of very large data sets and to increase alignment accuracy. > We have reimplemented a very efficient algorithm for UPGMA which can be called by using the command line option ‘-clustering=UPGMA’. It is marginally less accurate on the Balibase benchmark, but on large alignments (e.g. 10 000 globin sequences) this is offset by the savings in processing time (2 h versus 12 h). https://github.com/Bierinformatik/MIRfix/blob/d7d5138811a66dd17dca9450cfbb439a6f185578/scripts/MIRfix.py#L3495"
98710,109675,https://api.github.com/repos/nclskfm/dhbw-studienarbeit-muehle/issues/71,bug,2021-01-14T19:01:21Z,COLLABORATOR,https://api.github.com/repos/nclskfm/dhbw-studienarbeit-muehle,"Project: Feedback check 2021-01-13 Checken ob das Feedback vom 2021-01-13 eingearbeitet wurde. Also bitte die *Commented*-Dateien nocheinmal herunterladen und durchlesen,"
525964,584570,https://api.github.com/repos/flexion/ef-cms/issues/7264,bug,2020-12-07T21:34:53Z,NONE,https://api.github.com/repos/flexion/ef-cms,"BUG: Respondent counsel not displaying on New trial session eligible table **Describe the Bug** Respondent counsel is not displaying on the eligible case table for New trial session. **Business Impact/Reason for Severity** **In which environment did you see this bug?** flexon prod **Who were you logged in as?** docket clerk **What were you doing when you discovered this bug? (Using the application, demoing, smoke tests, testing other functionality, etc.)** manual testing **To Reproduce** Steps to reproduce the behavior: 1. Go to trial sessions 2. Go to Mobile, Alabama session for 12/30/20 **Expected Behavior** Respondent counsel on case should display in table. **Actual Behavior** Respondent counsel does not display in table. **Screenshots** If applicable, add screenshots to help explain your problem. ![Screen Shot 2020-12-07 at 4.33.04 PM.png](https://images.zenhubusercontent.com/5bd7271508843955cc24d3d0/dcaa7d22-edb4-4871-afc3-f5703c777454) ![Screen Shot 2020-12-07 at 4.33.54 PM.png](https://images.zenhubusercontent.com/5bd7271508843955cc24d3d0/385ae240-41b5-4f00-bd87-c114f0c72ef9) **Desktop (please complete the following information):** - OS: [e.g. iOS] - Browser [e.g. chrome, safari] - Version [e.g. 22] **Smartphone (please complete the following information):** - Device: [e.g. iPhone6] - OS: [e.g. iOS8.1] - Browser [e.g. stock browser, safari] - Version [e.g. 22] **Cause of Bug, If Known** **Process for Logging a Bug:** * Complete the above information * Add a severity tag (Critical, High Severity, Medium Severity or Low Severity). See below for priority definition. **Severity Definition:** * Critical Defect Blocks entire system's or module’s functionality No workarounds available Testing cannot proceed further without bug being fixed. * High-severity Defect Affects key functionality of an application There's a workaround, but not obvious or easy App behaves in a way that is strongly different from the one stated in the requirements * Medium-severity Defect A minor function does not behave in a way stated in the requirements. Workaround is available and easy * Low-severity Defect Mostly related to an application’s UI Doesn't need a workaround, because it doesn't impact functionality **FOR ENGINEERING TEAM ONLY** Bug Resolution Steps: - [x] Determine why the bug wasn't caught by a test. - [x] Determine if an automated test needs to fixed, expanded or created. If unsure, bring in others to discuss. - [x] Determine if a manual test needs to be fixed, expanded or created. If unsure, bring in others to discuss. - [x] If needed, automated test is created. - [x] If needed, manual test is created. - [x] Reason for bug has been documented. - [x] Fix has been deployed to dev environment. - [ ] Fix has been deployed to the stage environment. - [x] Bug has been tested in staging (UX or Engineering). "
570041,633475,https://api.github.com/repos/ucfopen/UDOIT/issues/447,enhancement,2019-08-23T20:02:22Z,MEMBER,https://api.github.com/repos/ucfopen/UDOIT,Admin panel: Job queue statistics The job queue contains a lot of useful information for determining server load and whether adding another worker is necessary. Here is some data I think would be useful: - Current queue length (with auto update) - Live view of job queue - Average wait time per job (`date_created` vs `date_completed`) - Expired jobs
144980,161161,https://api.github.com/repos/hchiam/html-template-generator/issues/2,enhancement,2021-05-08T01:48:51Z,OWNER,https://api.github.com/repos/hchiam/html-template-generator,"automated reminder to update codepen demo + surge site # Problem/Need: So I don't forget to keep the editable demo in sync. Having a surge site isn't as customizable, but is more friendly non-devs. # Suggested actions: - [x] publish to surge for sharing with non-devs - [x] add husky reminder to update codepen - [x] add husky reminder to update surge"
554633,616378,https://api.github.com/repos/ZoneMinder/zoneminder/issues/181,bug,2013-09-29T15:41:59Z,CONTRIBUTOR,https://api.github.com/repos/ZoneMinder/zoneminder,"Bootstrap tooltip and jQueryUI tooltip collision error The following error is on every page in the console: Uncaught TypeError: Cannot call method 'createDocumentFragment' of null This is caused by Bootstrap's tooltip and jQueryUI's tooltip colliding. The tooltip functionality needs to be removed from one or the other and the error will go away. I was going to do this myself, but I'm not sure how either package was built. StackOverflow thread for reference: http://stackoverflow.com/questions/15790568/jquery-1-9-1-unable-to-get-property-createdocumentfragment-of-undefined-or-nul ## <bountysource-plugin> Want to back this issue? **[Post a bounty on it!](https://www.bountysource.com/issues/998623-bootstrap-tooltip-and-jqueryui-tooltip-collision-error?utm_campaign=plugin&utm_content=tracker%2F188329&utm_medium=issues&utm_source=github)** We accept bounties via [Bountysource](https://www.bountysource.com/?utm_campaign=plugin&utm_content=tracker%2F188329&utm_medium=issues&utm_source=github). </bountysource-plugin> "
12120,13517,https://api.github.com/repos/PatternAtlas/pattern-atlas-ui/issues/37,bug,2020-05-06T16:40:02Z,CONTRIBUTOR,https://api.github.com/repos/PatternAtlas/pattern-atlas-ui,"Icon URL of Pattern View is not stored and used **Describe the bug** Icon URL from creation dialog for a Pattern View is not stored or used **Expected behavior** Remove input element or implement storage and usage, [actually the code handles only the name](https://github.com/PatternPedia/pattern-pedia-views-ui/blob/c5a926d4d2d23acfc347e9d14ae2c2362283245a/src/app/core/component/create-edit-pattern-language/create-edit-pattern-language.component.ts#L83). **Screenshots** ![Screenshot from 2020-05-06 18-32-02](https://user-images.githubusercontent.com/13757952/81203928-cf28a500-8fc8-11ea-9feb-962365ae1f47.png) "
694212,771597,https://api.github.com/repos/IQTLabs/SkyScan/issues/8,bug,2021-03-01T15:50:59Z,CONTRIBUTOR,https://api.github.com/repos/IQTLabs/SkyScan,"Calc 3D distance between positions Currently, the distance of different planes from the camera is calculated based solely on their 2d positions. The Altitude of the planes should also be taken into consideration. An additional function should be added, based on [coordinate_distance()](https://github.com/IQTLabs/SkyScan/blob/main/tracker/utils.py#L52) that also takes in altitude and calculates the relative distance in 3 dimensional space between them. The calls will need to be updated to use this new function: https://github.com/IQTLabs/SkyScan/blob/main/tracker/flighttracker.py#L156 https://github.com/IQTLabs/SkyScan/blob/main/tracker/flighttracker.py#L352 https://github.com/IQTLabs/SkyScan/blob/main/tracker/flighttracker.py#L374 https://github.com/IQTLabs/SkyScan/blob/main/tracker/flighttracker.py#L413 https://github.com/IQTLabs/SkyScan/blob/main/tracker/flighttracker.py#L430"
366839,407792,https://api.github.com/repos/darrenswhite/pokedot/issues/21,bug,2021-04-14T23:16:31Z,OWNER,https://api.github.com/repos/darrenswhite/pokedot,"Prevent in-battle and purely cosmetic forms in team generator Examples of Pokémon with forms only available in-battle: Wishiwashi, Darmanitan, and Morpeko. These should not be eligible to be picked in a pool."
625228,694835,https://api.github.com/repos/SushiBtw/discord-music-player/issues/80,bug,2021-03-13T05:56:57Z,NONE,https://api.github.com/repos/SushiBtw/discord-music-player,"[BUG] Live video plays then stops **Bug Description** If a live video link is played, the music plays for about 5 seconds then it stops. There are no errors thrown. The bot still functions as normal as adding tracks to queue and skipping tracks function normally. **Reproduction Steps** Steps to reproduce the behavior: 1. Play a live video link from YouTube with either the play() or addToQueue() function. 2. The song plays momentarily. 3. The song stops **Expected Result** The music continues to play **Versioning:** - Module Version : 7.0.0 **Additional Comments** No other error is thrown. If other functions like skip() are used, it skips the current song and continues to play the next song in the queue. "
50144,55794,https://api.github.com/repos/CaffeineMC/sodium-fabric/issues/524,bug,2021-02-12T06:59:13Z,NONE,https://api.github.com/repos/CaffeineMC/sodium-fabric,"Between Blocks (Visual Bug) ### Expected Behavior That was compatible the sodium ### Actual Behavior When entering the world, a visual bug appears which makes me see as if I were between blocks but it is only visual because I can dare them ### Reproduction Steps What I did was that I downloaded everything necessary to be able to play with the lithium-phosphor-sodium (I attach images from the mods folder) but when I entered I am between blocks, but I could dare them, I thought they were the texture pack, and when I removed it It was still the same, I tried to remove the phospor and the lithium but it remained the same, I also removed the API from the fabric, but neither, so what I did was remove the sodium and the bug was removed, so I knew it was because of the sodium . Sorry about the English, I speak Spanish, you do what you can :( 1. Place a Redstone Lamp beside a Redstone Repeater 2. Use a Lever to activate the Redstone Repeater 3. Nothing happens ### Attachments https://imgur.com/a/E4hyAtH [latest.log](https://github.com/CaffeineMC/sodium-fabric/files/5970067/latest.log) ### System Information [DxDiag.txt](https://github.com/CaffeineMC/sodium-fabric/files/5970061/DxDiag.txt) - Java Version: [1.8.0_281-b09] - CPU: [Intel Celeron n2830] - GPU: [INTEL HD GRAPHICS] "
207103,230290,https://api.github.com/repos/abapinho/abapBlame/issues/38,bug,2020-12-18T20:05:37Z,COLLABORATOR,https://api.github.com/repos/abapinho/abapBlame,HTML is wrongly rendered in some circumstances I still didn't understand what are the circumstances but I have a test variant called `HTML_LINE_9`.
190468,211816,https://api.github.com/repos/nolanlawson/pinafore/issues/1909,enhancement,2020-12-13T23:51:36Z,OWNER,https://api.github.com/repos/nolanlawson/pinafore,"Internationalize the OCR This is technically not the same thing as internationalizing the UI, because the UI and an image that you're uploading may be in different languages. So it needs to be independently selectable. #1693 "
365237,406006,https://api.github.com/repos/daohoangson/flutter_widget_from_html/issues/437,question,2021-02-18T14:43:28Z,NONE,https://api.github.com/repos/daohoangson/flutter_widget_from_html,[web] ul html element is not rendering correctly with canvaskit in web Simple `ul `tag is not rendering correctly in web. And I am using below command `flutter run -d chrome --release --dart-define=FLUTTER_WEB_USE_SKIA=true` ``` <ul> <li>Coffee</li> <li>Tea</li> <li>Milk</li> </ul> ``` 
343240,381561,https://api.github.com/repos/Raptor430/MSG_Windowed/issues/1,bug,2021-05-02T14:01:30Z,OWNER,https://api.github.com/repos/Raptor430/MSG_Windowed,The whole thing The whole thing is the issue
310614,345371,https://api.github.com/repos/analogdevicesinc/libiio/issues/646,enhancement,2021-01-21T09:41:00Z,CONTRIBUTOR,https://api.github.com/repos/analogdevicesinc/libiio,Do a review of the libserial timeouts Verify which libserialport calls might timeout and handle the return value in case timeout occurs. Some works has been done in #645 but only for call: sp_blocking_read_next().
391864,435563,https://api.github.com/repos/Azure/autorest/issues/4061,question,2021-04-13T15:56:27Z,NONE,https://api.github.com/repos/Azure/autorest,"Maintaining default property values or matching enum values with discriminator We have an inheritance structure where the subtypes have ""Type"" properties that are initialized as enum values. We're attempting to use SwaggerSubType and Discriminator to translate those into the generated client. ### Code ``` using System.ComponentModel; using Swashbuckle.AspNetCore.Annotations; namespace ApiTest { [SwaggerDiscriminator(""type"")] [SwaggerSubType(typeof(Square), DiscriminatorValue = nameof(ShapeType.Square))] [SwaggerSubType(typeof(Circle), DiscriminatorValue = nameof(ShapeType.Circle))] public abstract class Shape { public abstract ShapeType Type { get; } } public class Square : Shape { public override ShapeType Type { get; } = ShapeType.Circle; } public class Circle : Shape { public override ShapeType Type { get; } = ShapeType.Circle; } public enum ShapeType { [Description(nameof(Square))] Square = 1, [Description(nameof(Circle))] Circle = 2 } } ``` ### Swagger ``` ""components"": { ""schemas"": { ""Circle"": { ""type"": ""object"", ""allOf"": [ { ""$ref"": ""#/components/schemas/Shape"" } ], ""properties"": { ""type"": { ""$ref"": ""#/components/schemas/ShapeType"" } }, ""additionalProperties"": false }, ""Shape"": { ""required"": [ ""type"" ], ""type"": ""object"", ""properties"": { ""type"": { ""$ref"": ""#/components/schemas/ShapeType"" } }, ""additionalProperties"": false, ""discriminator"": { ""propertyName"": ""type"", ""mapping"": { ""Square"": ""#/components/schemas/Square"", ""Circle"": ""#/components/schemas/Circle"" } } }, ""ShapeType"": { ""enum"": [ 1, 2 ], ""type"": ""integer"", ""format"": ""int32"" }, ""Square"": { ""type"": ""object"", ""allOf"": [ { ""$ref"": ""#/components/schemas/Shape"" } ], ""properties"": { ""type"": { ""$ref"": ""#/components/schemas/ShapeType"" } }, ""additionalProperties"": false } } } ``` ### AutoRest Client Models: ``` // Copyright (c) Microsoft Corporation. All rights reserved. // Licensed under the MIT License. // <auto-generated/> #nullable disable namespace Client.Models { /// <summary> The Circle. </summary> internal partial class Circle : Shape { /// <summary> Initializes a new instance of Circle. </summary> internal Circle() { Type = new ShapeType(""Circle""); } } } ``` So what we're seeing is the client attempts to new up a field that is an enum value. "
452988,503455,https://api.github.com/repos/microting/eform-angular-basecustomer-plugin/issues/64,enhancement,2021-03-05T17:42:39Z,MEMBER,https://api.github.com/repos/microting/eform-angular-basecustomer-plugin,Bump Microting.eFormBaseCustomerBase from 2.0.97 to 2.0.98 TBD
619175,688090,https://api.github.com/repos/intellij-rust/intellij-rust/issues/5067,bug,2020-03-09T11:48:19Z,NONE,https://api.github.com/repos/intellij-rust/intellij-rust,"A second item with name '_' imported ## Environment * **IntelliJ Rust plugin version:** 0.2.117.2170-193 * **Rust toolchain version:** 1.41.1 (f3e1a954d 2020-02-24) x86_64-apple-darwin * **IDE name and version:** CLion 2019.3.4 (CL-193.6494.38) * **Operating system:** macOS 10.12.6 ## Problem description Two `as _` imports show the error: <img width=""747"" alt=""scc1"" src=""https://user-images.githubusercontent.com/7114909/76210162-35cd5480-620c-11ea-9325-1863659487f4.png""> ## Steps to reproduce 1. VCS > Get from version control... > https://github.com/instrumentisto/medea 2. Let the project being indexed. 3. Open `src/api/control/mod.rs` file and see 14 line."
457030,507958,https://api.github.com/repos/pereiren/dotnet-template-onion/issues/1,bug,2021-03-01T21:03:13Z,NONE,https://api.github.com/repos/pereiren/dotnet-template-onion,"docker build fails Upon run ```docker build -f Dockerfile ..``` process fails because wrong .csproj file is referenced. ```Sending build context to Docker daemon 27.85MB Step 1/17 : FROM mcr.microsoft.com/dotnet/aspnet:5.0-buster-slim AS base ---> c3a51e51a0f9 Step 2/17 : WORKDIR /app ---> Using cache ---> 9790ebeae196 Step 3/17 : EXPOSE 80 ---> Using cache ---> 1f4abed4e62f Step 4/17 : EXPOSE 443 ---> Using cache ---> 6cc799c8153d Step 5/17 : FROM mcr.microsoft.com/dotnet/sdk:5.0-buster-slim AS build ---> dd6f8be8f903 Step 6/17 : WORKDIR /src ---> Using cache ---> bf4d464ea7f1 Step 7/17 : COPY [""Onion/Onion.csproj"", ""Onion/""] COPY failed: file not found in build context or excluded by .dockerignore: stat Onion/Onion.csproj: file does not exist```"
614680,683089,https://api.github.com/repos/NightAngel47/Space-Uber/issues/406,enhancement,2021-03-22T21:04:14Z,COLLABORATOR,https://api.github.com/repos/NightAngel47/Space-Uber,"Tutorial Text Only Leaves if you click through it. **Is your feedback related to a problem? Please describe.** The text boxes for the tutorial do not leave the screen until you click through all of them. If a player begins the job, they'll still be on screen until clicked-through. This includes saving/quitting and continuing the run. **Describe an idea solution (if you have one)** Hide/delete the element that brings up the tutorial text box when a player begins the first job. **Additional context** ![Screenshot (193)](https://user-images.githubusercontent.com/16767247/112058009-055f0c80-8b28-11eb-885a-bd3fc4af6fed.png) **Related Discipline(s)** Programming & Design "
659850,733436,https://api.github.com/repos/sairish2001/makesmatheasy/issues/886,bug,2021-04-08T12:38:53Z,CONTRIBUTOR,https://api.github.com/repos/sairish2001/makesmatheasy,"Wrong position of tetrahedron calculator Right now the tetrahedron is placed in shapes calculator, but it should be placed in 3-D shapes calculator. Please assign this to me. "
52328,58209,https://api.github.com/repos/elastic/beats/issues/11519,enhancement,2019-03-28T18:20:53Z,MEMBER,https://api.github.com/repos/elastic/beats,"Metricbeat elasticsearch module when output is Kafka I am linking this to one of the items on the main issue on monitoring ES via metricbeat (https://github.com/elastic/beats/issues/7035). One aspect we haven't talked about much (or documented) is what happens when the user's metricbeat is configured to route all events through Kafka (using output.kafka). Per our guidelines today (https://www.elastic.co/guide/en/elasticsearch/reference/current/configuring-metricbeat.html), the configuration of the Elasticsearch module requires the output to be output.elasticsearch. What is the recommended set up here for output.kafka users? 1. Will they send everything through output.kafka, and have separate Logstash ES outputs downstream, 1 for regular events to the production cluster, and 1 for routing metricbeat ES stack module events to .monitoring-es* indices on the remote monitoring cluster? 2. Or is there a way to reuse Logstash's xpack.monitoring.elasticsearch.hosts for the connection to route the metricbeat ES stack module events to the remote monitoring cluster? 3. Will they have to set up a 2nd metricbeat (with output.elasticsearch just for the ES stack modules) to route events directly to the remote monitoring cluster, while the original metricbeat instance will continue to send other events through Kafka. Until we figure out our story on this, it will be helpful to update https://www.elastic.co/guide/en/elasticsearch/reference/current/configuring-metricbeat.html with some information on our current guidelines when metricbeat does not have an output.elasticsearch (or maybe it's simply a not-currently-supported statement, etc..). Thx!"
557925,620076,https://api.github.com/repos/gatewayapps/ims-feedback/issues/488,bug,2021-04-19T15:54:14Z,NONE,https://api.github.com/repos/gatewayapps/ims-feedback,"On the list page, all filters appear to work, except location. Unless, if I pick 'Rollmill 1' when entering and choosing a filter one up from that ""Rollmill"" does get the nodes below it. Version: 0.6.0 User: Jim Byrd(jim.byrd@nucor-yamato.com)"
696378,773982,https://api.github.com/repos/CDCgov/prime-simplereport/issues/1689,bug,2021-05-25T14:42:17Z,COLLABORATOR,https://api.github.com/repos/CDCgov/prime-simplereport,"`check-terraform-validity` check failing in deployment workflows ### Description This particular issue is a known one: https://github.com/okta/terraform-provider-okta/issues/480 The upstream Okta Terraform provider released a new version on Friday that's causing our deployment workflows to fail. Right now it's only affecting `check-terraform-validity`, but it will also break any Terraform command that requires downloading of the Okta plugin. Example job: https://github.com/CDCgov/prime-simplereport/runs/2642467674 We're not doing much dependency pinning, and so the long-term solution likely revolves around doing so. ### Steps to reproduce Run any workflow that includes a `check-terraform-validity` check. You should see the same output as in the example job above. ### Expected behavior The plugin should download without issue and this check should not fail. "
149426,166104,https://api.github.com/repos/adamhassel/bender/issues/16,bug,2021-01-17T12:49:53Z,OWNER,https://api.github.com/repos/adamhassel/bender,Log actions in channel logger plugin The channel logger doesn't log actions. Fix that.
538084,598050,https://api.github.com/repos/AugurProject/turbo/issues/657,bug,2021-05-27T18:45:59Z,CONTRIBUTOR,https://api.github.com/repos/AugurProject/turbo,"Figure out why three markets did not resolve when they were postponed The games for these markets rained out, postponed until some future date. They should have been marked No Contest but are unresolved. market?id=0x6b53958e2961a30e3ebbdb6ad03aa7ae88a3c79d-46 market?id=0x6b53958e2961a30e3ebbdb6ad03aa7ae88a3c79d-45 market?id=0x6b53958e2961a30e3ebbdb6ad03aa7ae88a3c79d-48 My guess is they changed the event date so the #656 will fix this. But need to investigate to be sure."
715849,795616,https://api.github.com/repos/ognomdb/OgnomDB/issues/40,enhancement,2021-05-24T20:17:36Z,MEMBER,https://api.github.com/repos/ognomdb/OgnomDB,"AddFrom() method ### Adding nodes to the Tree from existing Collection To add several nodes at once instead of iterating through collection by loops use `addFrom()` ```js const tree = new BinarySearchTree({ fieldKey: 'city' }); // object of objects const collection1 = { name0: { name: 'name0', city: 0 }, name1: { name: 'name1', city: 1 }, name2: { name: 'name2', city: 2 }, name3: { name: 'name3', city: 3 }, }; // array of objects const collection2 = [ { name: 'name0', city: 0 }, { name: 'name1', city: 1 }, { name: 'name2', city: 2 }, { name: 'name3', city: 3 }, ]; // usage tree.addFrom(collection1); // fine tree.addFrom(collection2); // fine ```"
412877,458918,https://api.github.com/repos/ez-connect/cocos-html-pack/issues/1,bug,2021-01-08T04:53:39Z,CONTRIBUTOR,https://api.github.com/repos/ez-connect/cocos-html-pack,"Particle doesn't work Error while running ``` index.html:190 download failed: resources/native/d7/d70b0e32-8371-41c4-9334-1e4be560bc1b.plist, status: 0(error) Error: download failed: resources/native/d7/d70b0e32-8371-41c4-9334-1e4be560bc1b.plist ``` because it's incorrect ``` ""resources/native/d7/d70b0e32-8371-41c4-9334-1e4be560bc1b.plist"":""data:text/plist;base64,PD94bWwgdmVyc2lvbj0iMS4wIiBlbmNvZGluZz0iVVRGLT... ``` "
343730,382111,https://api.github.com/repos/quinn-rs/quinn/issues/747,enhancement,2020-05-04T20:07:36Z,COLLABORATOR,https://api.github.com/repos/quinn-rs/quinn,Coarsen flow control updates We currently issue flow control credit immediately upon application-layer consumption of data. This is excessive; we could slightly reduce overhead by instead issuing flow control credit when the amount that would be issued is at least a certain proportion of the entire window.
653193,726087,https://api.github.com/repos/twinstae/tripReviewAnalysisSystem/issues/15,enhancement,2020-03-24T04:49:28Z,OWNER,https://api.github.com/repos/twinstae/tripReviewAnalysisSystem,"for문을 행렬 연산으로 바꿉시다다. 효율적인 알고리즘 ## 문제 설명 제가 지금까지 짠 코드들을 보면 중복 for문이나 dictionary를 자주 사용합니다. 알고리즘을 배우셨다면 아시겠지만 중복 for문은 알고리즘 속도를 느리게 만드는 O^n의 대표적인 형태입니다. 예를 들어 100 번 반복하는 for 문 안에 또 100번 반복하는 for 문이 있으면... 1만 번 연산을 해야 하는 거죠. 또 같은 양의 계산이라도 for문 호출 자체가 속도를 느리게 만듭니다. 그래서 이를 모두 데이터 프레임이나, 넘파이 행렬 연산으로 바꿔서 O의 차수를 낮추고 싶습니다. 또 파이썬 자체 라이브러리를 사용할 수 있는 (예를 들어 join으로 텍스트 합치기) 연산을 찾아서 변환하는 것도 중요합니다. 물론 테스트를 통해서 시간 차이도 비교하고요. 코드를 수정하여 올릴 테니 참고해주시기 바랍니다. ## 사용자 스토리 대용량의 계산을 빠르게 처리할 수 있습니다. 사용자가 로딩을 하염없이 기다리지 않아도 됩니다. 서버와 컴퓨터에 부하가 적어져, 각종 비용이 줄어듭니다."
235754,262209,https://api.github.com/repos/freqtrade/freqtrade/issues/5023,question,2021-05-25T17:11:55Z,NONE,https://api.github.com/repos/freqtrade/freqtrade,"fees in database during dry run Hi, I just realized that the fees during the dry run are not reported correctly. Since it writes a open/close fee of 0.001 for binance but calculates the profit_ratio with 0.002 e.g. I have close_rate= 2121,23 amount= 0,01256 the tool calculates a profit ratio of 0,0747111266750577 with a fee of 0.001 you will get 0,07578799. Do I miss something? In addition to that I would like to ask if it is possible to use early stopping during the training? Thanks for this nice framework. Best, Sebastian "
578378,642731,https://api.github.com/repos/laurent22/joplin/issues/2821,bug,2020-03-20T17:58:08Z,NONE,https://api.github.com/repos/laurent22/joplin,"Laggy preview scrolling ## Environment Joplin version: 1.0.94 Platform: Windows OS specifics: win10 ## Steps to reproduce 1. create a new note 2. Insert Lorem Ipsum 3. while the preview is selected, scroll with the mouse wheel, arrow or page keys. ## Describe what you expected to happen I experience very laggy scrolling with all methods except the scroll bars in the preview. Sometimes it scrolls normally, then only one or two pixels, sometimes (with the mouse wheel, not at all), then again somewhat normal. In the editor, it works fine, though. "
255247,283903,https://api.github.com/repos/phpmyadmin/phpmyadmin/issues/16721,question,2021-03-08T21:58:46Z,NONE,https://api.github.com/repos/phpmyadmin/phpmyadmin,My database Hello I have a problem when I change the password in me databasy I set my new password and the next time it threw me out and the new password does not want to give it to me but even then I do not know why so I want to ask if there is any way to change the password in my databases.
106520,118398,https://api.github.com/repos/lloesche/valheim-server-docker/issues/304,question,2021-04-08T00:34:48Z,NONE,https://api.github.com/repos/lloesche/valheim-server-docker,"Server always seems to restart at 1am EST First, thank you for setting up the nice docker. Working pretty well so far. I've noticed that the server at 1am EST will restart every day, even when players are logged in. When I set up the server, I only specified the ports, volumes for config and data, server and world name, and password. My understanding is that the server should only perform an update by default when no one is logged in. I've tried figuring out where the server log files should be, to confirm what is happening at 1am, but I'd guess it is always updating at that time? Ultimately I'd like to figure out what is happening at 1am, and change the time at least to a better time, since I've had players on a few hours after 1am, and it's annoying getting booted in the middle of things. Thanks!"
360812,401103,https://api.github.com/repos/CSCfi/metadata-submitter-frontend/issues/248,bug,2021-04-14T05:31:01Z,MEMBER,https://api.github.com/repos/CSCfi/metadata-submitter-frontend,"clear form and new form buttoms fill in inputs with description for some objects #### Describe the bug <!-- A clear and concise description of what the bug is. --> #### To Reproduce Steps to reproduce the behaviour: 1. Go to Create submission 2. Click on New folder and fill in details 3. go to any of Analysis, Dataset, Run, Experiment, Dataset, Sample 4. Click on `New Form` of `Clear form` without filling in anything 5. see how either `title`, `description` or both get filled with information #### Expected behavior <!-- A clear and concise description of what you expected to happen. --> all inputs are empty when clicking on `New Form` of `Clear form` #### Screenshots <!-- If applicable, add screenshots to help explain your problem. --> Analysis ![Peek 2021-04-14 08-26](https://user-images.githubusercontent.com/47524/114658850-31bb1280-9cfb-11eb-9787-ac99cac90d6d.gif) --- Dataset ![Peek 2021-04-14 08-25](https://user-images.githubusercontent.com/47524/114658852-3253a900-9cfb-11eb-9c43-cf9468eee7ac.gif) #### Additional context <!-- Add any other context about the problem here. --> "
498838,554441,https://api.github.com/repos/AvaloniaUI/Avalonia/issues/5419,bug,2021-02-03T11:33:24Z,CONTRIBUTOR,https://api.github.com/repos/AvaloniaUI/Avalonia,"Massive perfomance regression from 0.10.0-rc1 to 0.10.0-rc2 **Describe the bug** For 0.10.0-rc1 it takes about 61mb for ""hello world"" avalonia application. ![image](https://user-images.githubusercontent.com/53405089/106740710-705d8e00-6623-11eb-921b-77729e8c7956.png) For 0.10.0-rc2 and above it takes about 123mb for ""hello world"" avalonia application. ![image](https://user-images.githubusercontent.com/53405089/106740984-ca5e5380-6623-11eb-9ec9-4f4369baa06b.png) RAM memory usage for every template is the same, but GPU memory usage has increased a lot **To Reproduce** Just run the usual Avalonia template **Desktop (please complete the following information):** - OS: Windows 10 Pro "
408053,453555,https://api.github.com/repos/RoinujNosde/SimpleClans/issues/18,enhancement,2020-07-28T15:07:59Z,OWNER,https://api.github.com/repos/RoinujNosde/SimpleClans,Player's leaderboard position placeholder ```%simpleclans_leaderboard_<position>_playername%``` 
571150,634718,https://api.github.com/repos/gulrak/filesystem/issues/87,enhancement,2021-01-17T12:27:16Z,NONE,https://api.github.com/repos/gulrak/filesystem,It would be great to offer this in vcpkg.... Would need a portfile submitting.
312922,347903,https://api.github.com/repos/NosWings/bug-reports/issues/904,bug,2021-01-05T12:13:38Z,NONE,https://api.github.com/repos/NosWings/bug-reports,"[BUG]NosBasar shows 0 days, although it only expired today ## **Title of bug** NosBasar shows 0 days, although it only expired today ## **To Reproduce** **Description**: After I put items in the bazaar without a medal and 1 day has passed, the bazaar shows that the item has expired but shows 0 days. It should show the days how long I have to take the item out before it is deleted.( Normally 7 Days after the sale time has expires) ## Screenshots ![image](https://user-images.githubusercontent.com/26258408/103644754-2a93a400-4f57-11eb-8e13-4e1041708e15.png) "
396933,441181,https://api.github.com/repos/SmallDreams/youtube_plyr_iframe/issues/30,bug,2021-05-20T19:04:36Z,NONE,https://api.github.com/repos/SmallDreams/youtube_plyr_iframe,"setVolume not working **Describe the bug** setVolume not working **To Reproduce:** Can be reproduced in example project by calling setVolume while a video is paused. **Expected behavior:** Video volume to change in response to setVolume **Flutter Doctor:** [✓] Flutter (Channel beta, 2.2.0-10.3.pre, on macOS 11.3.1 20E241 darwin-arm, locale en-US) [✓] Android toolchain - develop for Android devices (Android SDK version 30.0.3) [✓] Xcode - develop for iOS and macOS [✓] Chrome - develop for the web [✓] Android Studio (version 4.1) [✓] VS Code (version 1.53.1) [✓] Connected device (2 available) **Additional context** N/A"
267051,296997,https://api.github.com/repos/ulab-committee/ulab-website/issues/707,bug,2021-04-14T20:00:30Z,MEMBER,https://api.github.com/repos/ulab-committee/ulab-website,Sprockets::FileNotFound in assets:precompile ## Error in ULAB Website **Sprockets::FileNotFound** in **assets:precompile** couldn't find file '@github/tab-container-element/dist/index.js' Checked in these paths: /tmp/build_08d4cb01/app/assets/config /tmp/build_08d4cb01/app/assets/fonts /tmp/build_08d4cb01/app/assets/images /tmp/build_08d4cb01/app/assets/stylesheets /tmp/build_08d4cb01/vendor/bundle/ruby/2.7.0/gems/primer_view_components-0.0.31/app/assets/javascripts /tmp/build_08d4cb01/vendor/bundle/ruby/2.7.0/gems/turbo-rails-0.5.9/app/assets/javascripts /tmp/build_08d4cb01/vendor/bundle/ruby/2.7.0/gems/stimulus-rails-0.2.3/app/assets/javascripts /tmp/build_08d4cb01/vendor/bundle/ruby/2.7.0/gems/spina-admin-conferences-1.3.10/app/assets/config /tmp/build_08d4cb01/vendor/bundle/ruby/2.7.0/gems/spina-admin-conferences-1.3.10/app/assets/javascripts /tmp/build_08d4cb01/vendor/bundle/ruby/2.7.0/gems/spina-admin-conferences-1.3.10/app/assets/stylesheets /tmp/build_08d4cb01/vendor/bundle/ruby/2.7.0/gems/spina-conferences-primer_theme-0.1.17/app/assets/config /tmp/build_08d4cb01/vendor... [View on Bugsnag](https://app.bugsnag.com/ulab/ulab-website/errors/607749deb07ef20007768608?event_id=607749de00776adbd3570000&i=gh&m=ci) ## Stacktrace vendor/bundle/ruby/2.7.0/gems/spina-conferences-primer_theme-0.1.17/app/assets/config/spina_conferences_primer_theme_manifest.js:7 - [View full stacktrace](https://app.bugsnag.com/ulab/ulab-website/errors/607749deb07ef20007768608?event_id=607749de00776adbd3570000&i=gh&m=ci) *Created automatically via Bugsnag*
81501,90593,https://api.github.com/repos/stackblitz/core/issues/597,bug,2018-07-10T13:50:17Z,NONE,https://api.github.com/repos/stackblitz/core,Format code dose not work for .scss files :( Format code dose not work for .scss files :( I would love to use this feature . 
244451,271879,https://api.github.com/repos/danielaparker/jsoncons/issues/296,bug,2020-12-25T08:02:42Z,NONE,https://api.github.com/repos/danielaparker/jsoncons,"jsoncons build with GCC 10.2.0 fails without -Wno-deprecated-declarations compiler option Hello Daniel, jsoncons build fails for us with GCC 10.2.0 if **-Wno-deprecated-declarations** compiler option is not added. ``` include/jsoncons/basic_json.hpp:4696:64: note: declared here 4696 | std::basic_string<char_type, char_traits_type, SAllocator> to_string(const basic_json_encode_options<char_type>& options, | ^~~~~~~~~ /export/home/scratch/ven_angritsiuk/plasma/build/Release/tools/TxnLogDump/jsoncons/src/JSONCONS_LIB/include/jsoncons/basic_json.hpp:4701:69: error: ‘std::__cxx11::basic_string<CharT, std::char_traits<_CharT>, SAllocator> jsoncons::basic_json<CharT, ImplementationPolicy, Allocator>::to_string(const jsoncons::basic_json_encode_options<CharT>&, const SAllocator&) const’ is deprecated: Instead, use dump(std::basic_ostream<char_type>&, const basic_json_encode_options<char_type>&) [-Werror=deprecated-declarations] 4701 | basic_compact_json_encoder<char_type, jsoncons::string_sink<string_type>> encoder(s, options); ``` Kind regards, Andrei."
286986,319152,https://api.github.com/repos/LSSTDESC/SN-PWV/issues/157,enhancement,2021-03-16T15:31:15Z,COLLABORATOR,https://api.github.com/repos/LSSTDESC/SN-PWV,"Add error values to apparent magnitude estimates **Issue:** The pipeline output file includes fitted values for the apparent B-band magnitude but does not include an associated error estimate or the relevant covariance values. **Thoughts:** 1. @rubind was kind enough to point out the covariance in `mu` should be calculated from full `[mB, x1, c]` covariance matrix as`Cov_mu = [1, alpha, -beta].C.[1, alpha, -beta]`. 1. @rbiswas4 has written some extremely useful code for doing just this sort of thing in [rbiswas4/AnalyzeSN](https://github.com/rbiswas4/AnalyzeSN). With some minor updates in the source (e.g., the `pandas` dependency has a new API), I was able to get it running successfully on NERSC. **Proposed Solution:** Use the code from @rbiswas4 to calculate the covariance matrix from each fit result and add the elements to the output file. - [x] Extend the `PipelineResult` class to include covariance values (See #162) - [x] Add new fields to the dataclass` constructor - [x] Modify `PipelineResult.to_csv` to reflect the new output columns. Covariance values should be masked if not provided (to match existing behavior). - [x] Port an updated copy of the relevant code from [rbiswas4/AnalyzeSN](https://github.com/rbiswas4/AnalyzeSN) (See #158) - [x] Update docs to reflect provenance (See #168) "
465795,517667,https://api.github.com/repos/baidu/amis/issues/1727,enhancement,2021-03-31T02:24:14Z,NONE,https://api.github.com/repos/baidu/amis,代码编辑器增强 #### 是否关联于某个问题吗： 无 #### 预期的解决方案： 代码编辑器editor： 1. 支持tpl表达式 2. 高亮语法支持shell脚本 #### 其他可接受方案： 请简单描述其他你可以接受的效果... #### 任何附加信息： 请添加任何可以补充说明上述问题的材料，例如图片或视频等... 
577838,642121,https://api.github.com/repos/multitheftauto/mtasa-blue/issues/2099,bug,2021-02-26T11:30:07Z,NONE,https://api.github.com/repos/multitheftauto/mtasa-blue,"Grenade bug which is here for 5 years and it's still not fixed and by day to day it's ruining atmosphere Grenade bug* As the bug that is here with us for a long time - like 5 years and it's still not fixed and it's ruining atmosphere of clanwars and arenas on all Shooter/Hunter servers (topic from 2019 https://github.com/multitheftauto/mtasa-blue/issues/1123) As there it was explained ^^ but I'll explain it once more again: How can you trigger Grenade bug?* - You'll go to some Freeroam server (any, also you can use Host Game) and will take Grenade/Satchel. If grenade, you'll start throwing grenades under you and die by it. Then you'll join some server and you have triggered grenade bug. Same it's working with Satchel. What's grenade?* https://youtu.be/RraAIjzOet0 - A lot of times it's exploding over they player, so he die instantly instead of burning. I'll add few videos of explanation: 00:00 - 00:10 | You can see, that he has grenade and I don't, so his shoot disappeared for me, because I don't have grenade and it sticked with mine and exploded. It wouldn't happened, if he wouldn't use grenade bug. 00:11 - 00:23 | Clearly you can see, that he hit him, but he didn't die, because Hardy was using grenade. If he wouldn't, he would die. This can happen only with grenade. 00:24 - 00:30 | You can see, that the player hit Chiki, but he started burning, because the player who hit him was using grenade. 00:31 - 00:35 | Same situation as last one. 00:36 - 00:46 | Same situation as in 00:11 - 00:23. Zeroxy hit Vndtt, but he didn't die because he was using grenade. He got just -40hp. This can happen only with this bug. 00:47 - 00:53 | He shooted corner and it teleported to Lonnex because of grenade. - You should fix this bug because it's ruining atmosphere of fun and it's hard to fix it by normal script. FFS made some script, but it's not working well. You can still trigger grenade and it's also kicking players who aren't using it or who came from PTP - mode which can trigger grenade bug, because there you can use 'Grenade' Please take care of it.. "
499648,555344,https://api.github.com/repos/flickchicks/flick-ios/issues/60,bug,2020-08-09T02:07:26Z,COLLABORATOR,https://api.github.com/repos/flickchicks/flick-ios,Refactor how tags are handled in list the `+# more` and `show less` not working properly anymore. Prob have to do with excessive `reloadData`
373314,414988,https://api.github.com/repos/huawei-noah/SMARTS/issues/847,enhancement,2021-05-12T15:20:10Z,CONTRIBUTOR,https://api.github.com/repos/huawei-noah/SMARTS,"genhistories.py should rescale history data to match SMARTS' scale **Is your feature request related to a problem? Please describe.** History datasets (like NGSIM) that use a different scale than SMARTS cause some problems (see Issue #742). **Describe the solution you'd like** The average lane width on the map (`map.net.xml`) should be computed such that this can be used to rescale the data in `genhistories.py` while creating the `.shf` file to match SMARTS' (and SUMO's) default scale (average lane width of 3.2m). This will alleviate the need for `lane_width` in the `.yaml` file. **Describe alternatives you've considered** With a proper solution to Issue #742, this wouldn't be needed. But it looks like that is some ways off, so we need to do something like this in the meantime. **Additional context** The Yaml file is described in Issue #732."
248993,276952,https://api.github.com/repos/songliao/qdp-python/issues/3,enhancement,2021-02-24T14:41:36Z,OWNER,https://api.github.com/repos/songliao/qdp-python,"make the parameters' order more consistent within the package the Barrier class and the Payoff class both have method that takes asset price and time as arguments, please make the arguments' order more consistent"
252112,280426,https://api.github.com/repos/ivoa-std/ADQL/issues/16,enhancement,2019-10-30T14:22:01Z,COLLABORATOR,https://api.github.com/repos/ivoa-std/ADQL,"Add reference to the Endorsed Note about a UDF catalog Jon Juaristi Campillo and Markus Demleitner have published an Endorsed Note (currently in PR) describing an IVOA consensus on some User Defined Functions: [Endorsed Note ""Catalogue of ADQL User Defined Functions "" - PR-1.0, Jon Juaristi Campillo, et.al.](http://www.ivoa.net/documents/udf-catalogue/20190925) There is no obligation to implement them. They are just recommandations for function names (all prefixed with `ivo_`) and signatures."
647206,719377,https://api.github.com/repos/fosscord/fosscord-css/issues/11,enhancement,2021-01-05T02:24:19Z,MEMBER,https://api.github.com/repos/fosscord/fosscord-css,[Feature] Checkbox - [x] empty ![image](https://user-images.githubusercontent.com/34555296/103599434-6a31a000-4f05-11eb-8ed5-f6983ed35278.png) - [ ] empty inverted ![image](https://user-images.githubusercontent.com/34555296/103599445-70c01780-4f05-11eb-845c-674345d5715f.png) - [x] toggled ![image](https://user-images.githubusercontent.com/34555296/103599455-74539e80-4f05-11eb-8965-44b3dcaaf0c8.png) - [ ] toggled inverted ![image](https://user-images.githubusercontent.com/34555296/103599468-7c134300-4f05-11eb-9035-67293b2f885a.png) 
673569,748605,https://api.github.com/repos/MRtrix3/mrtrix3/issues/2268,bug,2021-01-21T15:09:23Z,NONE,https://api.github.com/repos/MRtrix3/mrtrix3,"dwibiascorrect: error when using the `-debug` flag **The bug** Running `dwibiascorrect` with option flag `-debug` raises error. **To Reproduce** Command: ```sh /home/localadmin/Softwares/miniconda3/bin/dwibiascorrect ants -mask /home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/flirt_dwimask/dwi_brain_mask.nii.gz -bias diffusion_denoised_biasfield.mif -debug -force /home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/dwi_denoise/diffusion_denoised.mif /home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/dwi_biascorrect/diffusion_denoised_biascorr.mif ``` Terminal output: ```output dwibiascorrect: dwibiascorrect: Note that this script makes use of commands / algorithms that have relevant articles for citation; INCLUDING FROM EXTERNAL SOFTWARE PACKAGES. Please consult the help page (-help option) for more information. dwibiascorrect: dwibiascorrect: [DEBUG] path.script_subdir_name() (from algorithm.py:69): dwibiascorrect dwibiascorrect: [WARNING] Output file 'diffusion_denoised_biasfield.mif' already exists; will be overwritten at script completion dwibiascorrect: Generated scratch directory: /home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/ dwibiascorrect: [DEBUG] path.from_user() (from dwibiascorrect:50): /home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/dwi_denoise/diffusion_denoised.mif -> /home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/dwi_denoise/diffusion_denoised.mif dwibiascorrect: [DEBUG] path.to_scratch() (from dwibiascorrect:50): in.mif -> /home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/in.mif dwibiascorrect: [DEBUG] run.exe_name() (from run.py:546): mrconvert -> mrconvert dwibiascorrect: [DEBUG] run.version_match() (from run.py:330): Version-matched executable for mrconvert: /home/localadmin/Softwares/miniconda3/bin/mrconvert dwibiascorrect: [DEBUG] run._shebang() (from run.py:340): File ""/home/localadmin/Softwares/miniconda3/bin/mrconvert"": Not a text file dwibiascorrect: [DEBUG] run.command() (from dwibiascorrect:50): To execute: [['/home/localadmin/Softwares/miniconda3/bin/mrconvert', '/home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/dwi_denoise/diffusion_denoised.mif', '/home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/in.mif', '-info']] Command: mrconvert /home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/dwi_denoise/diffusion_denoised.mif /home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/in.mif mrconvert: [INFO] opening image ""/home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/dwi_denoise/diffusion_denoised.mif""... mrconvert: [INFO] image ""/home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/dwi_denoise/diffusion_denoised.mif"" opened with dimensions 96x96x38x129, voxel spacing 2.2083300000000001x2.2083300000000001x3x5.9000000000000004, datatype Float32LE mrconvert: [INFO] found 129x4 diffusion gradient table mrconvert: [INFO] creating image ""/home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/in.mif""... mrconvert: [INFO] image ""/home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/in.mif"" created with dimensions 96x96x38x129, voxel spacing 2.2083300000000001x2.2083300000000001x3x5.9000000000000004, datatype Float32LE mrconvert: [100%] copying from ""/home/loca...oise/diffusion_denoised.mif"" to ""/home/loca...ascorrect-tmp-XEGOZD/in.mif"" dwibiascorrect: [DEBUG] path.from_user() (from dwibiascorrect:52): /home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/flirt_dwimask/dwi_brain_mask.nii.gz -> /home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/flirt_dwimask/dwi_brain_mask.nii.gz dwibiascorrect: [DEBUG] path.to_scratch() (from dwibiascorrect:52): mask.mif -> /home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/mask.mif dwibiascorrect: [DEBUG] run.exe_name() (from run.py:546): mrconvert -> mrconvert dwibiascorrect: [DEBUG] run.version_match() (from run.py:330): Version-matched executable for mrconvert: /home/localadmin/Softwares/miniconda3/bin/mrconvert dwibiascorrect: [DEBUG] run._shebang() (from run.py:340): File ""/home/localadmin/Softwares/miniconda3/bin/mrconvert"": Not a text file dwibiascorrect: [DEBUG] run.command() (from dwibiascorrect:52): To execute: [['/home/localadmin/Softwares/miniconda3/bin/mrconvert', '/home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/flirt_dwimask/dwi_brain_mask.nii.gz', '/home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/mask.mif', '-datatype', 'bit', '-info']] Command: mrconvert /home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/flirt_dwimask/dwi_brain_mask.nii.gz /home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/mask.mif -datatype bit mrconvert: [INFO] opening image ""/home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/flirt_dwimask/dwi_brain_mask.nii.gz""... mrconvert: [INFO] image ""/home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/flirt_dwimask/dwi_brain_mask.nii.gz"" opened with dimensions 96x96x38, voxel spacing 2.2083332538604736x2.2083332538604736x3, datatype Float32LE mrconvert: [INFO] no valid diffusion gradient table found mrconvert: [INFO] error importing diffusion gradient table for image ""/home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/flirt_dwimask/dwi_brain_mask.nii.gz"" mrconvert: [100%] uncompressing image ""/home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/flirt_dwimask/dwi_brain_mask.nii.gz"" mrconvert: [INFO] creating image ""/home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/mask.mif""... mrconvert: [INFO] image ""/home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/mask.mif"" created with dimensions 96x96x38, voxel spacing 2.2083332538604736x2.2083332538604736x3, datatype Bit mrconvert: [100%] copying from ""/home/loca...imask/dwi_brain_mask.nii.gz"" to ""/home/loca...correct-tmp-XEGOZD/mask.mif"" dwibiascorrect: Changing to scratch directory (/home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/) dwibiascorrect: [DEBUG] path.name_temporary() (from image.py:33): /home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/mrtrix-tmp-ti2iWL.json dwibiascorrect: [DEBUG] run.exe_name() (from run.py:546): mrinfo -> mrinfo dwibiascorrect: [DEBUG] run.version_match() (from image.py:34): Version-matched executable for mrinfo: /home/localadmin/Softwares/miniconda3/bin/mrinfo dwibiascorrect: [DEBUG] run.exe_name() (from image.py:34): /home/localadmin/Softwares/miniconda3/bin/mrinfo -> /home/localadmin/Softwares/miniconda3/bin/mrinfo dwibiascorrect: Loading header for image file 'in.mif' dwibiascorrect: [DEBUG] image.__init__() (from dwibiascorrect:59): ['/home/localadmin/Softwares/miniconda3/bin/mrinfo', 'in.mif', '-json_all', '/home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/mrtrix-tmp-ti2iWL.json'] dwibiascorrect: [DEBUG] image.__init__() (from dwibiascorrect:59): {'_name': 'in.mif', '_size': [96, 96, 38, 129], '_spacing': [2.20833, 2.20833, 3.0, 5.9], '_strides': [1, 2, 3, 4], '_format': 'MRtrix', '_datatype': 'Float32LE', '_intensity_offset': 0.0, '_intensity_scale': 1.0, '_transform': [[0.999999943880058, 5.33884694434427e-08, 0.000335022184972424, -102.900541691394], [1.57276657824972e-05, 0.998889975305693, -0.0471043187585057, -93.3131521331962], [-0.000334652837870155, 0.0471043228779298, 0.998889919317656, -23.3364965748897], [0.0, 0.0, 0.0, 1.0]], '_keyval': {'command_history': [""mrconvert -stride '1,2,3,4' -force -fslgrad /output_dir/cmp/sub-01/ses-01/dwi/sub-01_ses-01_desc-cmp_dwi.bvec /output_dir/cmp/sub-01/ses-01/dwi/sub-01_ses-01_desc-cmp_dwi.bval -quiet /output_dir/cmp/sub-01/ses-01/dwi/sub-01_ses-01_desc-cmp_dwi.nii.gz diffusion.mif (version=3.0.2)"", 'dwidenoise -mask /output_dir/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/flirt_dwimask/dwi_brain_mask.nii.gz -noise diffusion_noisemap.mif -force -debug /output_dir/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/mr_convert/diffusion.mif diffusion_denoised.mif (version=3.0.2)', '/home/localadmin/Softwares/miniconda3/bin/mrconvert /home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/dwi_denoise/diffusion_denoised.mif /home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/in.mif -info (version=3.0.2)'], 'comments': 'TE=1e+02;Time=160316.967;phase=1', 'dw_scheme': [[0.0, 0.0, 0.0, 0.0], [4.604794858e-11, -0.9999980001, -0.001999937115, 500.0], [1.455731894e-10, 2.590861083e-08, -1.0, 500.0], [-0.999998, -9.949299793e-11, -0.001999989269, 500.0], [0.7071057544, -0.7071063938, -0.00141422849, 1000.0], [0.7067542777, -5.561829258e-08, -0.707459109, 1000.0], [2.6698783e-10, -0.7067539959, -0.7074593906, 1000.0], [1.98246735e-10, 0.7067540551, -0.7074593314, 1000.0], [-0.7071061444, -0.7071060037, -0.001414231861, 1000.0], [-0.7067538111, 4.064903066e-08, -0.7074595752, 1000.0], [0.5770938972, -0.5770939732, -0.577862596, 1500.0], [0.5770936909, 0.5770944823, -0.5778622937, 1500.0], [-0.5770942262, -0.5770936115, -0.5778626287, 1500.0], [-0.5770938222, 0.5770937722, -0.5778628717, 1500.0], [4.701760879e-11, -0.999999875, -0.0004999499268, 2000.0], [1.455731894e-10, 2.590861083e-08, -1.0, 2000.0], [-0.999999875, -6.189255252e-11, -0.0004999995985, 2000.0], [0.8944271678, -0.44721332, -0.0005366216217, 2500.0], [0.8942481999, 1.233911471e-09, -0.4475713987, 2500.0], [0.4472140294, -0.894426813, -0.0005366778619, 2500.0], [0.447141854, -6.331739179e-08, -0.8944630581, 2500.0], [6.047983974e-10, -0.8942484278, -0.4475709434, 2500.0], [-1.547638207e-10, -0.4471420937, -0.8944629383, 2500.0], [6.038469206e-11, 0.4471424734, -0.8944627485, 2500.0], [-2.987575823e-10, 0.8942483962, -0.4475710065, 2500.0], [-0.4472142273, -0.8944267141, -0.0005366223904, 2500.0], [-0.4471422325, 2.979426711e-09, -0.894462869, 2500.0], [-0.8944272642, -0.4472131271, -0.0005366111842, 2500.0], [-0.8942481864, -1.203342597e-08, -0.4475714257, 2500.0], [0.8163150495, -0.4082259566, -0.4086334645, 3000.0], [0.8163149864, 0.4082255761, -0.4086339707, 3000.0], [0.4082262058, -0.816314944, -0.4086334263, 3000.0], [0.4081581457, -0.408157277, -0.816587145, 3000.0], [0.408157348, 0.4081578487, -0.8165872579, 3000.0], [0.4082253801, 0.8163154, -0.4086333403, 3000.0], [-0.4082260024, -0.8163148249, -0.4086338675, 3000.0], [-0.4081577425, -0.408157098, -0.816587436, 3000.0], [-0.4081578271, 0.4081579636, -0.816586961, 3000.0], [-0.4082254286, 0.8163152063, -0.4086336787, 3000.0], [-0.8163152896, -0.4082256582, -0.408633283, 3000.0], [-0.8163150614, 0.4082255313, -0.4086338657, 3000.0], [0.7071071135, -0.7071063605, -0.0003535496407, 4000.0], [0.7069299418, -5.319339341e-09, -0.7072835764, 4000.0], [-9.789377913e-11, -0.7069302433, -0.707283275, 4000.0], [1.567798364e-10, 0.7069298265, -0.7072836916, 4000.0], [-0.7071066491, -0.7071068248, -0.0003535998457, 4000.0], [-0.7069299747, 3.830753602e-08, -0.7072835434, 4000.0], [0.6665928365, -0.6665925637, -0.3336290519, 4500.0], [0.6664856674, -0.3333169916, -0.6668557852, 4500.0], [0.6664856527, 0.3333167604, -0.6668559155, 4500.0], [0.6665929437, 0.6665923207, -0.3336293233, 4500.0], [0.333317104, -0.6664855564, -0.66685584, 4500.0], [0.3333173941, 0.6664856233, -0.6668556281, 4500.0], [4.085725123e-11, -0.9999999012, -0.0004444170368, 4500.0], [1.455731894e-10, 2.590861083e-08, -1.0, 4500.0], [-0.3333166201, -0.6664858367, -0.6668558017, 4500.0], [-0.3333166057, 0.6664855235, -0.6668561219, 4500.0], [-0.6665924266, -0.666592734, -0.3336295307, 4500.0], [-0.6664858483, -0.3333171152, -0.6668555426, 4500.0], [-0.6664853425, 0.3333167888, -0.6668562113, 4500.0], [-0.6665924202, 0.666592617, -0.3336297773, 4500.0], [-0.9999999012, 3.742696584e-11, -0.0004444399636, 4500.0], [0.9486830278, -0.3162282667, -0.0004427363325, 5000.0], [0.9485630721, 2.321566786e-08, -0.3165882157, 5000.0], [0.3162277787, -0.9486831905, -0.0004427124981, 5000.0], [0.3162084303, -1.470391669e-08, -0.9486897431, 5000.0], [6.094271403e-11, -0.9485631972, -0.3165878406, 5000.0], [3.727802446e-10, -0.3160571874, -0.9487401406, 5000.0], [2.102303804e-10, 0.3162084941, -0.9486897218, 5000.0], [2.418275742e-10, 0.9485631902, -0.3165878617, 5000.0], [-0.3162281986, -0.9486830505, -0.0004427240341, 5000.0], [-0.3162086596, -2.213515469e-08, -0.9486896667, 5000.0], [-0.9486830937, -0.3162280692, -0.0004427716254, 5000.0], [-0.9485632352, -2.792397978e-09, -0.3165877268, 5000.0], [0.9044196305, -0.3014910643, -0.3018745932, 5500.0], [0.9044195348, 0.3014912943, -0.3018746504, 5500.0], [0.3014912367, -0.9044193748, -0.3018751873, 5500.0], [0.3015110819, -0.3013465199, -0.9045890462, 5500.0], [0.3014815607, 0.3014810386, -0.9045540625, 5500.0], [0.301491691, 0.9044192968, -0.3018749673, 5500.0], [-0.3014917901, -0.9044192099, -0.3018751286, 5500.0], [-0.3015110626, -0.3013465021, -0.9045890585, 5500.0], [-0.3014814747, 0.3014810781, -0.904554078, 5500.0], [-0.301491225, 0.904419444, -0.3018749917, 5500.0], [-0.9044195788, -0.3014910964, -0.301874716, 5500.0], [-0.9044196065, 0.3014912379, -0.3018744917, 5500.0], [0.5772539059, -0.577254112, -0.5775427416, 6000.0], [0.5772537687, 0.5772545673, -0.5775424235, 6000.0], [-0.5772541227, -0.5772538622, -0.5775427744, 6000.0], [-0.577254148, 0.5772543081, -0.5775423035, 6000.0], [0.8320501259, -0.5547003438, -0.0003413330173, 6500.0], [0.8319060448, 3.098869511e-08, -0.5549165096, 6500.0], [0.5546999144, -0.8320504122, -0.0003413904583, 6500.0], [0.554572481, -4.940954412e-08, -0.8321354236, 6500.0], [6.072960914e-10, -0.8319059468, -0.5549166565, 6500.0], [-3.666727552e-10, -0.5545724001, -0.8321354776, 6500.0], [2.11767819e-10, 0.5545717321, -0.8321359228, 6500.0], [-3.600334341e-10, 0.831906107, -0.5549164164, 6500.0], [-0.5546999789, -0.8320503692, -0.0003413141108, 6500.0], [-0.5545722601, 2.913643411e-08, -0.8321355709, 6500.0], [-0.832050099, -0.5547003842, -0.0003413181217, 6500.0], [-0.8319060534, 3.281216423e-10, -0.5549164967, 6500.0], [0.8017208664, -0.53446813, -0.2675583495, 7000.0], [0.8016418421, -0.2672396717, -0.5347460283, 7000.0], [0.8016418981, 0.2672394531, -0.5347460537, 7000.0], [0.8017207264, 0.534468159, -0.267558711, 7000.0], [0.5344681068, -0.8017208029, -0.2675585861, 7000.0], [0.53442475, -0.2671552934, -0.8018841786, 7000.0], [0.5343916032, 0.2672533946, -0.8018735795, 7000.0], [0.5344678393, 0.8017210021, -0.2675585238, 7000.0], [0.2672396447, -0.8016419395, -0.5347458958, 7000.0], [0.2672530582, -0.5343914545, -0.8018737907, 7000.0], [0.2672532447, 0.5343918496, -0.8018734652, 7000.0], [0.2672394535, 0.8016416949, -0.534746358, 7000.0], [-0.2672393738, -0.8016420235, -0.5347459053, 7000.0], [-0.2672529745, -0.5343914835, -0.8018737993, 7000.0], [-0.2672527998, 0.534391969, -0.801873534, 7000.0], [-0.2672395729, 0.8016417046, -0.5347462838, 7000.0], [-0.534468046, -0.8017208702, -0.2675585059, 7000.0], [-0.534424298, -0.2671553634, -0.8018844565, 7000.0], [-0.5343916999, 0.2672534444, -0.8018734985, 7000.0], [-0.5344680464, 0.801720919, -0.267558359, 7000.0], [-0.8017210357, -0.5344679886, -0.2675581246, 7000.0], [-0.8016417412, -0.2672397248, -0.5347461531, 7000.0], [-0.8016420535, 0.2672394791, -0.5347458078, 7000.0], [-0.8017211137, 0.5344675679, -0.2675587314, 7000.0], [2.651765635e-12, -0.9999999687, -0.0002500086681, 8000.0], [1.455731894e-10, 2.590861083e-08, -1.0, 8000.0], [-0.9999999687, -1.852948745e-11, -0.0002500002363, 8000.0]], 'mrtrix_version': '3.0.2'}} dwibiascorrect: [DEBUG] path.name_temporary() (from image.py:33): /home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/mrtrix-tmp-njtCya.json dwibiascorrect: [DEBUG] run.exe_name() (from run.py:546): mrinfo -> mrinfo dwibiascorrect: [DEBUG] run.version_match() (from image.py:34): Version-matched executable for mrinfo: /home/localadmin/Softwares/miniconda3/bin/mrinfo dwibiascorrect: [DEBUG] run.exe_name() (from image.py:34): /home/localadmin/Softwares/miniconda3/bin/mrinfo -> /home/localadmin/Softwares/miniconda3/bin/mrinfo dwibiascorrect: Loading header for image file 'in.mif' dwibiascorrect: [DEBUG] image.__init__() (from image.py:175): ['/home/localadmin/Softwares/miniconda3/bin/mrinfo', 'in.mif', '-json_all', '/home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/mrtrix-tmp-njtCya.json'] dwibiascorrect: [DEBUG] image.__init__() (from image.py:175): {'_name': 'in.mif', '_size': [96, 96, 38, 129], '_spacing': [2.20833, 2.20833, 3.0, 5.9], '_strides': [1, 2, 3, 4], '_format': 'MRtrix', '_datatype': 'Float32LE', '_intensity_offset': 0.0, '_intensity_scale': 1.0, '_transform': [[0.999999943880058, 5.33884694434427e-08, 0.000335022184972424, -102.900541691394], [1.57276657824972e-05, 0.998889975305693, -0.0471043187585057, -93.3131521331962], [-0.000334652837870155, 0.0471043228779298, 0.998889919317656, -23.3364965748897], [0.0, 0.0, 0.0, 1.0]], '_keyval': {'command_history': [""mrconvert -stride '1,2,3,4' -force -fslgrad /output_dir/cmp/sub-01/ses-01/dwi/sub-01_ses-01_desc-cmp_dwi.bvec /output_dir/cmp/sub-01/ses-01/dwi/sub-01_ses-01_desc-cmp_dwi.bval -quiet /output_dir/cmp/sub-01/ses-01/dwi/sub-01_ses-01_desc-cmp_dwi.nii.gz diffusion.mif (version=3.0.2)"", 'dwidenoise -mask /output_dir/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/flirt_dwimask/dwi_brain_mask.nii.gz -noise diffusion_noisemap.mif -force -debug /output_dir/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/mr_convert/diffusion.mif diffusion_denoised.mif (version=3.0.2)', '/home/localadmin/Softwares/miniconda3/bin/mrconvert /home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/dwi_denoise/diffusion_denoised.mif /home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/in.mif -info (version=3.0.2)'], 'comments': 'TE=1e+02;Time=160316.967;phase=1', 'dw_scheme': [[0.0, 0.0, 0.0, 0.0], [4.604794858e-11, -0.9999980001, -0.001999937115, 500.0], [1.455731894e-10, 2.590861083e-08, -1.0, 500.0], [-0.999998, -9.949299793e-11, -0.001999989269, 500.0], [0.7071057544, -0.7071063938, -0.00141422849, 1000.0], [0.7067542777, -5.561829258e-08, -0.707459109, 1000.0], [2.6698783e-10, -0.7067539959, -0.7074593906, 1000.0], [1.98246735e-10, 0.7067540551, -0.7074593314, 1000.0], [-0.7071061444, -0.7071060037, -0.001414231861, 1000.0], [-0.7067538111, 4.064903066e-08, -0.7074595752, 1000.0], [0.5770938972, -0.5770939732, -0.577862596, 1500.0], [0.5770936909, 0.5770944823, -0.5778622937, 1500.0], [-0.5770942262, -0.5770936115, -0.5778626287, 1500.0], [-0.5770938222, 0.5770937722, -0.5778628717, 1500.0], [4.701760879e-11, -0.999999875, -0.0004999499268, 2000.0], [1.455731894e-10, 2.590861083e-08, -1.0, 2000.0], [-0.999999875, -6.189255252e-11, -0.0004999995985, 2000.0], [0.8944271678, -0.44721332, -0.0005366216217, 2500.0], [0.8942481999, 1.233911471e-09, -0.4475713987, 2500.0], [0.4472140294, -0.894426813, -0.0005366778619, 2500.0], [0.447141854, -6.331739179e-08, -0.8944630581, 2500.0], [6.047983974e-10, -0.8942484278, -0.4475709434, 2500.0], [-1.547638207e-10, -0.4471420937, -0.8944629383, 2500.0], [6.038469206e-11, 0.4471424734, -0.8944627485, 2500.0], [-2.987575823e-10, 0.8942483962, -0.4475710065, 2500.0], [-0.4472142273, -0.8944267141, -0.0005366223904, 2500.0], [-0.4471422325, 2.979426711e-09, -0.894462869, 2500.0], [-0.8944272642, -0.4472131271, -0.0005366111842, 2500.0], [-0.8942481864, -1.203342597e-08, -0.4475714257, 2500.0], [0.8163150495, -0.4082259566, -0.4086334645, 3000.0], [0.8163149864, 0.4082255761, -0.4086339707, 3000.0], [0.4082262058, -0.816314944, -0.4086334263, 3000.0], [0.4081581457, -0.408157277, -0.816587145, 3000.0], [0.408157348, 0.4081578487, -0.8165872579, 3000.0], [0.4082253801, 0.8163154, -0.4086333403, 3000.0], [-0.4082260024, -0.8163148249, -0.4086338675, 3000.0], [-0.4081577425, -0.408157098, -0.816587436, 3000.0], [-0.4081578271, 0.4081579636, -0.816586961, 3000.0], [-0.4082254286, 0.8163152063, -0.4086336787, 3000.0], [-0.8163152896, -0.4082256582, -0.408633283, 3000.0], [-0.8163150614, 0.4082255313, -0.4086338657, 3000.0], [0.7071071135, -0.7071063605, -0.0003535496407, 4000.0], [0.7069299418, -5.319339341e-09, -0.7072835764, 4000.0], [-9.789377913e-11, -0.7069302433, -0.707283275, 4000.0], [1.567798364e-10, 0.7069298265, -0.7072836916, 4000.0], [-0.7071066491, -0.7071068248, -0.0003535998457, 4000.0], [-0.7069299747, 3.830753602e-08, -0.7072835434, 4000.0], [0.6665928365, -0.6665925637, -0.3336290519, 4500.0], [0.6664856674, -0.3333169916, -0.6668557852, 4500.0], [0.6664856527, 0.3333167604, -0.6668559155, 4500.0], [0.6665929437, 0.6665923207, -0.3336293233, 4500.0], [0.333317104, -0.6664855564, -0.66685584, 4500.0], [0.3333173941, 0.6664856233, -0.6668556281, 4500.0], [4.085725123e-11, -0.9999999012, -0.0004444170368, 4500.0], [1.455731894e-10, 2.590861083e-08, -1.0, 4500.0], [-0.3333166201, -0.6664858367, -0.6668558017, 4500.0], [-0.3333166057, 0.6664855235, -0.6668561219, 4500.0], [-0.6665924266, -0.666592734, -0.3336295307, 4500.0], [-0.6664858483, -0.3333171152, -0.6668555426, 4500.0], [-0.6664853425, 0.3333167888, -0.6668562113, 4500.0], [-0.6665924202, 0.666592617, -0.3336297773, 4500.0], [-0.9999999012, 3.742696584e-11, -0.0004444399636, 4500.0], [0.9486830278, -0.3162282667, -0.0004427363325, 5000.0], [0.9485630721, 2.321566786e-08, -0.3165882157, 5000.0], [0.3162277787, -0.9486831905, -0.0004427124981, 5000.0], [0.3162084303, -1.470391669e-08, -0.9486897431, 5000.0], [6.094271403e-11, -0.9485631972, -0.3165878406, 5000.0], [3.727802446e-10, -0.3160571874, -0.9487401406, 5000.0], [2.102303804e-10, 0.3162084941, -0.9486897218, 5000.0], [2.418275742e-10, 0.9485631902, -0.3165878617, 5000.0], [-0.3162281986, -0.9486830505, -0.0004427240341, 5000.0], [-0.3162086596, -2.213515469e-08, -0.9486896667, 5000.0], [-0.9486830937, -0.3162280692, -0.0004427716254, 5000.0], [-0.9485632352, -2.792397978e-09, -0.3165877268, 5000.0], [0.9044196305, -0.3014910643, -0.3018745932, 5500.0], [0.9044195348, 0.3014912943, -0.3018746504, 5500.0], [0.3014912367, -0.9044193748, -0.3018751873, 5500.0], [0.3015110819, -0.3013465199, -0.9045890462, 5500.0], [0.3014815607, 0.3014810386, -0.9045540625, 5500.0], [0.301491691, 0.9044192968, -0.3018749673, 5500.0], [-0.3014917901, -0.9044192099, -0.3018751286, 5500.0], [-0.3015110626, -0.3013465021, -0.9045890585, 5500.0], [-0.3014814747, 0.3014810781, -0.904554078, 5500.0], [-0.301491225, 0.904419444, -0.3018749917, 5500.0], [-0.9044195788, -0.3014910964, -0.301874716, 5500.0], [-0.9044196065, 0.3014912379, -0.3018744917, 5500.0], [0.5772539059, -0.577254112, -0.5775427416, 6000.0], [0.5772537687, 0.5772545673, -0.5775424235, 6000.0], [-0.5772541227, -0.5772538622, -0.5775427744, 6000.0], [-0.577254148, 0.5772543081, -0.5775423035, 6000.0], [0.8320501259, -0.5547003438, -0.0003413330173, 6500.0], [0.8319060448, 3.098869511e-08, -0.5549165096, 6500.0], [0.5546999144, -0.8320504122, -0.0003413904583, 6500.0], [0.554572481, -4.940954412e-08, -0.8321354236, 6500.0], [6.072960914e-10, -0.8319059468, -0.5549166565, 6500.0], [-3.666727552e-10, -0.5545724001, -0.8321354776, 6500.0], [2.11767819e-10, 0.5545717321, -0.8321359228, 6500.0], [-3.600334341e-10, 0.831906107, -0.5549164164, 6500.0], [-0.5546999789, -0.8320503692, -0.0003413141108, 6500.0], [-0.5545722601, 2.913643411e-08, -0.8321355709, 6500.0], [-0.832050099, -0.5547003842, -0.0003413181217, 6500.0], [-0.8319060534, 3.281216423e-10, -0.5549164967, 6500.0], [0.8017208664, -0.53446813, -0.2675583495, 7000.0], [0.8016418421, -0.2672396717, -0.5347460283, 7000.0], [0.8016418981, 0.2672394531, -0.5347460537, 7000.0], [0.8017207264, 0.534468159, -0.267558711, 7000.0], [0.5344681068, -0.8017208029, -0.2675585861, 7000.0], [0.53442475, -0.2671552934, -0.8018841786, 7000.0], [0.5343916032, 0.2672533946, -0.8018735795, 7000.0], [0.5344678393, 0.8017210021, -0.2675585238, 7000.0], [0.2672396447, -0.8016419395, -0.5347458958, 7000.0], [0.2672530582, -0.5343914545, -0.8018737907, 7000.0], [0.2672532447, 0.5343918496, -0.8018734652, 7000.0], [0.2672394535, 0.8016416949, -0.534746358, 7000.0], [-0.2672393738, -0.8016420235, -0.5347459053, 7000.0], [-0.2672529745, -0.5343914835, -0.8018737993, 7000.0], [-0.2672527998, 0.534391969, -0.801873534, 7000.0], [-0.2672395729, 0.8016417046, -0.5347462838, 7000.0], [-0.534468046, -0.8017208702, -0.2675585059, 7000.0], [-0.534424298, -0.2671553634, -0.8018844565, 7000.0], [-0.5343916999, 0.2672534444, -0.8018734985, 7000.0], [-0.5344680464, 0.801720919, -0.267558359, 7000.0], [-0.8017210357, -0.5344679886, -0.2675581246, 7000.0], [-0.8016417412, -0.2672397248, -0.5347461531, 7000.0], [-0.8016420535, 0.2672394791, -0.5347458078, 7000.0], [-0.8017211137, 0.5344675679, -0.2675587314, 7000.0], [2.651765635e-12, -0.9999999687, -0.0002500086681, 8000.0], [1.455731894e-10, 2.590861083e-08, -1.0, 8000.0], [-0.9999999687, -1.852948745e-11, -0.0002500002363, 8000.0]], 'mrtrix_version': '3.0.2'}} dwibiascorrect: [DEBUG] path.name_temporary() (from image.py:33): /home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/mrtrix-tmp-6azLV9.json dwibiascorrect: [DEBUG] run.exe_name() (from run.py:546): mrinfo -> mrinfo dwibiascorrect: [DEBUG] run.version_match() (from image.py:34): Version-matched executable for mrinfo: /home/localadmin/Softwares/miniconda3/bin/mrinfo dwibiascorrect: [DEBUG] run.exe_name() (from image.py:34): /home/localadmin/Softwares/miniconda3/bin/mrinfo -> /home/localadmin/Softwares/miniconda3/bin/mrinfo dwibiascorrect: Loading header for image file 'mask.mif' dwibiascorrect: [DEBUG] image.__init__() (from image.py:179): ['/home/localadmin/Softwares/miniconda3/bin/mrinfo', 'mask.mif', '-json_all', '/home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/mrtrix-tmp-6azLV9.json'] dwibiascorrect: [DEBUG] image.__init__() (from image.py:179): {'_name': 'mask.mif', '_size': [96, 96, 38], '_spacing': [2.20833, 2.20833, 3.0], '_strides': [1, 2, 3], '_format': 'MRtrix', '_datatype': 'Bit', '_intensity_offset': 0.0, '_intensity_scale': 1.0, '_transform': [[0.999999943880049, 5.33884719919637e-08, 0.000335022184972424, -102.900543212891], [1.57276657824971e-05, 0.998889975224889, -0.0471043187585057, -93.3131484985352], [-0.00033465286422834, 0.0471043245914531, 0.998889919317656, -23.3364963531494], [0.0, 0.0, 0.0, 1.0]], '_keyval': {'command_history': '/home/localadmin/Softwares/miniconda3/bin/mrconvert /home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/flirt_dwimask/dwi_brain_mask.nii.gz /home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/mask.mif -datatype bit -info (version=3.0.2)', 'comments': 'FSL5.0', 'mrtrix_version': '3.0.2'}} dwibiascorrect: [DEBUG] image.match() (from dwibiascorrect:69): 'in.mif' 'mask.mif' image match dwibiascorrect: [DEBUG] run.exe_name() (from run.py:546): dwiextract -> dwiextract dwibiascorrect: [DEBUG] run.version_match() (from run.py:330): Version-matched executable for dwiextract: /home/localadmin/Softwares/miniconda3/bin/dwiextract dwibiascorrect: [DEBUG] run._shebang() (from run.py:340): File ""/home/localadmin/Softwares/miniconda3/bin/dwiextract"": Not a text file dwibiascorrect: [DEBUG] run.exe_name() (from run.py:546): mrmath -> mrmath dwibiascorrect: [DEBUG] run.version_match() (from run.py:330): Version-matched executable for mrmath: /home/localadmin/Softwares/miniconda3/bin/mrmath dwibiascorrect: [DEBUG] run._shebang() (from run.py:340): File ""/home/localadmin/Softwares/miniconda3/bin/mrmath"": Not a text file dwibiascorrect: [DEBUG] run.command() (from ants.py:64): To execute: [['/home/localadmin/Softwares/miniconda3/bin/dwiextract', 'in.mif', '-', '-bzero', '-info'], ['/home/localadmin/Softwares/miniconda3/bin/mrmath', '-', 'mean', 'mean_bzero.mif', '-axis', '3', '-info']] Command: dwiextract in.mif - -bzero | mrmath - mean mean_bzero.mif -axis 3 dwiextract: [INFO] opening image ""in.mif""... dwiextract: [INFO] image ""in.mif"" opened with dimensions 96x96x38x129, voxel spacing 2.2083300000000001x2.2083300000000001x3x5.9000000000000004, datatype Float32LE dwiextract: [INFO] found 129x4 diffusion gradient table dwiextract: [INFO] creating image ""-""... dwiextract: [INFO] image ""/home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/mrtrix-tmp-sK5XHm.mif"" created with dimensions 96x96x38x1, voxel spacing 2.2083300000000001x2.2083300000000001x3x5.9000000000000004, datatype Float32LE dwiextract: [100%] extracting volumes mrmath: [INFO] opening image ""-""... mrmath: [INFO] image ""/home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/mrtrix-tmp-sK5XHm.mif"" opened with dimensions 96x96x38x1, voxel spacing 2.2083300000000001x2.2083300000000001x3x5.9000000000000004, datatype Float32LE mrmath: [INFO] creating image ""mean_bzero.mif""... mrmath: [INFO] image ""mean_bzero.mif"" created with dimensions 96x96x38, voxel spacing 2.2083300000000001x2.2083300000000001x3, datatype Float32LE mrmath: [100%] computing mean along axis 3... dwibiascorrect: [DEBUG] run.exe_name() (from run.py:546): mrconvert -> mrconvert dwibiascorrect: [DEBUG] run.version_match() (from run.py:330): Version-matched executable for mrconvert: /home/localadmin/Softwares/miniconda3/bin/mrconvert dwibiascorrect: [DEBUG] run._shebang() (from run.py:340): File ""/home/localadmin/Softwares/miniconda3/bin/mrconvert"": Not a text file dwibiascorrect: [DEBUG] run.command() (from ants.py:68): To execute: [['/home/localadmin/Softwares/miniconda3/bin/mrconvert', 'mean_bzero.mif', 'mean_bzero.nii', '-strides', '+1,+2,+3', '-info']] Command: mrconvert mean_bzero.mif mean_bzero.nii -strides +1,+2,+3 mrconvert: [INFO] opening image ""mean_bzero.mif""... mrconvert: [INFO] image ""mean_bzero.mif"" opened with dimensions 96x96x38, voxel spacing 2.2083300000000001x2.2083300000000001x3, datatype Float32LE mrconvert: [INFO] no valid diffusion gradient table found mrconvert: [INFO] error importing diffusion gradient table for image ""mean_bzero.mif"" mrconvert: [INFO] opening image ""+1,+2,+3""... mrconvert: [INFO] creating image ""mean_bzero.nii""... mrconvert: [INFO] image ""mean_bzero.nii"" created with dimensions 96x96x38, voxel spacing 2.2083300000000001x2.2083300000000001x3, datatype Float32LE mrconvert: [100%] copying from ""mean_bzero.mif"" to ""mean_bzero.nii"" dwibiascorrect: [DEBUG] run.exe_name() (from run.py:546): mrconvert -> mrconvert dwibiascorrect: [DEBUG] run.version_match() (from run.py:330): Version-matched executable for mrconvert: /home/localadmin/Softwares/miniconda3/bin/mrconvert dwibiascorrect: [DEBUG] run._shebang() (from run.py:340): File ""/home/localadmin/Softwares/miniconda3/bin/mrconvert"": Not a text file dwibiascorrect: [DEBUG] run.command() (from ants.py:69): To execute: [['/home/localadmin/Softwares/miniconda3/bin/mrconvert', 'mask.mif', 'mask.nii', '-strides', '+1,+2,+3', '-info']] Command: mrconvert mask.mif mask.nii -strides +1,+2,+3 mrconvert: [INFO] opening image ""mask.mif""... mrconvert: [INFO] image ""mask.mif"" opened with dimensions 96x96x38, voxel spacing 2.2083300000000001x2.2083300000000001x3, datatype Bit mrconvert: [INFO] no valid diffusion gradient table found mrconvert: [INFO] error importing diffusion gradient table for image ""mask.mif"" mrconvert: [INFO] opening image ""+1,+2,+3""... mrconvert: [INFO] creating image ""mask.nii""... mrconvert: [WARNING] requested datatype (Bit) not supported - substituting with UInt8 mrconvert: [INFO] image ""mask.nii"" created with dimensions 96x96x38, voxel spacing 2.2083300000000001x2.2083300000000001x3, datatype UInt8 mrconvert: [100%] copying from ""mask.mif"" to ""mask.nii"" dwibiascorrect: [DEBUG] run.exe_name() (from run.py:546): N4BiasFieldCorrection -> N4BiasFieldCorrection dwibiascorrect: [DEBUG] run.version_match() (from run.py:330): Version-matched executable for N4BiasFieldCorrection: /home/localadmin/Softwares/miniconda3/bin/N4BiasFieldCorrection dwibiascorrect: [DEBUG] run._shebang() (from run.py:340): File ""/home/localadmin/Softwares/miniconda3/bin/N4BiasFieldCorrection"": Not a text file dwibiascorrect: [DEBUG] run.command() (from ants.py:72): To execute: [['/home/localadmin/Softwares/miniconda3/bin/N4BiasFieldCorrection', '-d', '3', '-i', 'mean_bzero.nii', '-w', 'mask.nii', '-o', '[corrected.nii,init_bias.nii]', '-s', '4', '-b', '[100,3]', '-c', '[1000,0.0]', '-info']] Command: N4BiasFieldCorrection -d 3 -i mean_bzero.nii -w mask.nii -o [corrected.nii,init_bias.nii] -s 4 -b [100,3] -c [1000,0.0] ERROR: Invalid command line flags found! Aborting execution. dwibiascorrect: [ERROR] N4BiasFieldCorrection -d 3 -i mean_bzero.nii -w mask.nii -o [corrected.nii,init_bias.nii] -s 4 -b [100,3] -c [1000,0.0] (ants.py:72) dwibiascorrect: [ERROR] Information from failed command: dwibiascorrect: ERROR: Invalid flag provided in ERROR: Invalid command line flags found! Aborting execution. dwibiascorrect: dwibiascorrect: [ERROR] For debugging, inspect contents of scratch directory: /home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/ dwibiascorrect: Scratch directory retained; location: /home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-XEGOZD/ ``` Looking at the line: ``` dwibiascorrect: [DEBUG] run.command() (from ants.py:72): To execute: [['/home/localadmin/Softwares/miniconda3/bin/N4BiasFieldCorrection', '-d', '3', '-i', 'mean_bzero.nii', '-w', 'mask.nii', '-o', '[corrected.nii,init_bias.nii]', '-s', '4', '-b', '[100,3]', '-c', '[1000,0.0]', '-info']] ``` It seems an extra option flag `-info` is added to the N4BiasFieldCorrection. Running `dwibiascorrect` without the flag `-debug` succeeds, see below. Command: ```bash /home/localadmin/Softwares/miniconda3/bin/dwibiascorrect ants -mask /home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/flirt_dwimask/dwi_brain_mask.nii.gz -bias diffusion_denoised_biasfield.mif -force /home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/dwi_denoise/diffusion_denoised.mif /home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/dwi_biascorrect/diffusion_denoised_biascorr.mif dwibiascorrect: dwibiascorrect: Note that this script makes use of commands / algorithms that have relevant articles for citation; INCLUDING FROM EXTERNAL SOFTWARE PACKAGES. Please consult the help page (-help option) for more information. dwibiascorrect: dwibiascorrect: [WARNING] Output file 'diffusion_denoised_biasfield.mif' already exists; will be overwritten at script completion dwibiascorrect: Generated scratch directory: /home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-683WFE/ Command: mrconvert /home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/dwi_denoise/diffusion_denoised.mif /home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-683WFE/in.mif Command: mrconvert /home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/flirt_dwimask/dwi_brain_mask.nii.gz /home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-683WFE/mask.mif -datatype bit dwibiascorrect: Changing to scratch directory (/home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-683WFE/) Command: dwiextract in.mif - -bzero | mrmath - mean mean_bzero.mif -axis 3 Command: mrconvert mean_bzero.mif mean_bzero.nii -strides +1,+2,+3 Command: mrconvert mask.mif mask.nii -strides +1,+2,+3 Command: N4BiasFieldCorrection -d 3 -i mean_bzero.nii -w mask.nii -o [corrected.nii,init_bias.nii] -s 4 -b [100,3] -c [1000,0.0] Command: mrcalc mean_bzero.mif mask.mif -mult - | mrmath - sum - -axis 0 | mrmath - sum - -axis 1 | mrmath - sum - -axis 2 | mrdump - Command: mrcalc corrected.nii mask.mif -mult - | mrmath - sum - -axis 0 | mrmath - sum - -axis 1 | mrmath - sum - -axis 2 | mrdump - Command: mrcalc init_bias.nii 0.9515317417482443 -mult bias.mif Command: mrcalc in.mif bias.mif -div result.mif Command: mrconvert result.mif /home/localadmin/Desktop/HagmannTest/BIDS_out/ds-DSI/derivatives/nipype/sub-01/ses-01/diffusion_pipeline/preprocessing_stage/dwi_biascorrect/diffusion_denoised_biascorr.mif Command: mrconvert bias.mif /home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/diffusion_denoised_biasfield.mif dwibiascorrect: Changing back to original directory (/home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88) dwibiascorrect: Deleting scratch directory (/home/localadmin/.local/share/Trash/files/dwibiascorrect-tmp-I6CQ88/dwibiascorrect-tmp-683WFE/) ``` **Platform/Environment/Version** Please provide the following information: - OS: Distributor ID: Ubuntu Description: Ubuntu 16.04.6 LTS Release: 16.04 Codename: xenial - *MRtrix3* version: == mrinfo 3.0.2 == 64 bit release version, built Sep 30 2020, using Eigen 3.3.7 Author(s): J-Donald Tournier (d.tournier@brain.org.au) and Robert E. Smith (robert.smith@florey.edu.au) Copyright (c) 2008-2020 the MRtrix3 contributors. --- "
391353,435007,https://api.github.com/repos/codepunkt/webpack-license-plugin/issues/460,question,2020-12-10T07:14:51Z,NONE,https://api.github.com/repos/codepunkt/webpack-license-plugin,"Handle custom license with no valid SPDX identifier According https://github.com/codepunkt/webpack-license-plugin/issues/443#issuecomment-742060966 > As of now, this plugin requires valid SPDX identifiers in the license field and checks for the license text in a licen[cs]e file. There are use cases where there is no valid SPDX identifiers in `package.json` but something like `SEE LICENSE IN LICENSE.txt`. Here is an example (which was also valid before the recent license change when BSD-3-Clause used to be the license): https://github.com/mapbox/mapbox-gl-js/blob/20b953937ac54e3743aed06066b0bbe0092f5c9a/package.json#L7 What about a `licenseOverrides` option: ``` ""license"": ""see licenseText"" ``` which takes the license text of a licen[cs]e file for `licenseText`? "
26958,30044,https://api.github.com/repos/vendia/serverless-express/issues/214,bug,2019-02-26T08:24:23Z,NONE,https://api.github.com/repos/vendia/serverless-express,"Does not support array query string parameters aws-serverless-express cannot parse array query string parameters For example `?a=1&a=2` exposes only `{a: 1}` to express. Normally this would result in `{a: [1, 2]}` API Gateway supports array query string parameters using `multiValueQueryStringParameters` instead of `queryStringParameters`. https://docs.aws.amazon.com/apigateway/latest/developerguide/set-up-lambda-proxy-integrations.html#apigateway-multivalue-headers-and-parameters"
566887,629975,https://api.github.com/repos/appsmithorg/appsmith/issues/2897,enhancement,2021-02-08T02:54:25Z,CONTRIBUTOR,https://api.github.com/repos/appsmithorg/appsmith,[Feature] Users would like to enable optional encoding of URI for APIs A default true option for encoding allows users to skip a forced decoding step in case their URI components are already encoded.
659792,733373,https://api.github.com/repos/WC-Local-Pickup/woocommerce-local-pickup-time/issues/96,enhancement,2020-10-05T21:40:29Z,NONE,https://api.github.com/repos/WC-Local-Pickup/woocommerce-local-pickup-time,"checkout page time slot re-arrange needed sometime customer stay at check out page for like 30 mins or a hour before submitting the order. by that time , current time already passed first available time slot. I am not sure if i made this clearly. eg. customer at check out page @ 2:25 .dealy was set 15mins. so first available time slot will be 2:45pm. but customer submited the order at 4pm and the pick time was still set at 2:45. is there anyway to make them re selected for new time slot or make a page expire countdown to let them finish check out in 5 mins. "
159471,177291,https://api.github.com/repos/Polidea/RxAndroidBle/issues/738,bug,2021-03-04T01:35:15Z,NONE,https://api.github.com/repos/Polidea/RxAndroidBle,"Duplicate READY state when using RxBleClientMock ## Description The doc comment for `RxBleClient#observeStateChanges` states: >Returns an observable emitting state _changes_ of the RxBleClient environment... and > To get the initial State and then observe changes you can use: `observeStateChanges().startWith(getState())`. As such, my code does: ```kotlin client.observeStateChanges() .startWith(client.state) .switchMap { state -> etc() } ``` However, it appears that when using the `RxBleClientMock`, `observeStateChanges()` returns `Observable.just(State.READY)`. As a result, my switch map receives **two** READY state changes. Clearly the mock is violating the specification that it is intended to mock. ## Reproduction ```kotlin var calls = 0 val client = RxBleClientMock.Builder().build() client .observeStateChanges() .startWith(client.state) .switchMap { state -> if (state == RxBleClient.State.READY) { calls++ println(""I've been called $calls times!"") } } ``` ``` I've been called 1 times! I've been called 2 times! ``` ## Expected Behavior The `Observable` returned by `observeStateChanges` should yield _nothing_ by default, as described by the specification of `RxBleClient#observeStateChanges` ## Proposed Solution The mock's implementation should return an empty `Observable` and/or allow the client to specify an observable, similar to `RxBleClientMock.Builder.setDeviceDiscoveryObservable`"
285665,317689,https://api.github.com/repos/NVIDIA/spark-rapids/issues/575,bug,2020-08-18T14:33:32Z,COLLABORATOR,https://api.github.com/repos/NVIDIA/spark-rapids,"[BUG] Spark 3.1 FAILED join_test.py::test_broadcast_join_mixed[FullOuter][IGNORE_ORDER] failed **Describe the bug** Run the integration tests against Spark 3.1 and the following test fails, need to investigate FAILED integration_tests/src/main/python/join_test.py::test_broadcast_join_mixed[FullOuter][IGNORE_ORDER] "
189468,210702,https://api.github.com/repos/OriginProtocol/ousd-analytics/issues/39,enhancement,2021-01-12T22:34:46Z,CONTRIBUTOR,https://api.github.com/repos/OriginProtocol/ousd-analytics,"Trigger event ordering The way the triggers are fired and events are ordered means that the events tend to be ordered by [trigger execution order], then [block number]. This causes events to be grouped by the trigger, which is generally not the same as execution on the blockchain. While this generally doesn't cause confusion since triggers are mostly separate concerns, sometimes they can describe contract interacting in a way that can be confusing. For instance, if a governor contract accepts a proposal then executes a timelock transaction. Events could be reversed showing the execution first. Not a huge deal but giving events ordering data(block number and transaction index maybe) would help clarify these edge cases."
4510,5021,https://api.github.com/repos/AlexxIT/WebRTC/issues/18,enhancement,2021-04-16T11:29:23Z,NONE,https://api.github.com/repos/AlexxIT/WebRTC,error installing integration GUI. Configuration > Integration > Add Integration > WebRTC Camera. ![rtc](https://user-images.githubusercontent.com/64173457/115017790-b8205180-9ebf-11eb-9a65-9d3dcacc9036.PNG) mouse click end ![rtc2](https://user-images.githubusercontent.com/64173457/115017955-edc53a80-9ebf-11eb-9a44-fbe7d5c2fce2.PNG) core-2021.4.4 What is missing?
636787,707723,https://api.github.com/repos/primefaces/primevue/issues/1209,bug,2021-04-25T20:58:36Z,NONE,https://api.github.com/repos/primefaces/primevue,"Multiple Form Components Break Inside TabView **I'm submitting a ...** (check one with ""x"") ``` [x] bug report => Search github for a similar issue or PR before submitting [ ] feature request => Please check if request is not on the roadmap already https://github.com/primefaces/primevue/wiki/Roadmap [ ] support request => Please do not submit support request here, instead see http://forum.primefaces.org/viewforum.php?f=110 ``` **Current behavior** When using form components (InputText, Autocomplete) inside a TabView/TabPanel, the form components do not properly work. The value being passed along to the v-model gets corrupted and does not reflect what the user is typing. This works fine under Primevue v2.3.0 but breaks in v2.4.1. **Expected behavior** <!-- Describe what the behavior would be without the bug. --> InputText v-model updates with correct user input. **Minimal reproduction of the problem with instructions** <!-- If the current behavior is a bug or you can illustrate your feature request better with an example, please provide the *STEPS TO REPRODUCE* and if possible a *MINIMAL DEMO* of the problem via codesandbox or similar (you can use this template as a starting point: https://codesandbox.io/s/primevue-issue-template-forked-vgbzf). --> https://jsfiddle.net/3rx91v8y/2/ **What is the motivation / use case for changing the behavior?** <!-- Describe the motivation or the concrete use case --> Multi-part form using tab to group sections. **Please tell us about your environment:** <!-- Operating system, IDE, package manager, HTTP server, ... --> * **Vue version:** 3.X <!-- Check whether this is still an issue in the most recent Vue version --> Vue 2.6.12 * **PrimeVue version:** 5.X <!-- Check whether this is still an issue in the most recent PrimeVue version --> PrimeVue 2.4.1 * **Browser:** [all | Chrome XX | Firefox XX | IE XX | Safari XX | Mobile Chrome XX | Android X.X Web Browser | iOS XX Safari | iOS XX UIWebView | iOS XX WKWebView ] <!-- All browsers where this could be reproduced --> Chrome 89, Firefox 88.1.1"
62416,69389,https://api.github.com/repos/visualboyadvance-m/visualboyadvance-m/issues/804,bug,2021-01-25T06:26:38Z,CONTRIBUTOR,https://api.github.com/repos/visualboyadvance-m/visualboyadvance-m,"(Post r1229 regression)Croket 2 slowdown going left of the snowman at start of game. It looks like when Normmatt resolved the hang issue in this specific location, he broke 8bit memory loads causing them all to be 32bit, going by the change set here https://sourceforge.net/p/vbam/code/1205/tree//trunk/src/gba/GBAinline.h?diff=51a5080727184674d4b548ec:1204 MGBA does not choke in this location whilst encountering ""bad"" memory load8 and 32's at this location."
218755,243243,https://api.github.com/repos/bradyhouse/house/issues/190,enhancement,2017-08-03T22:51:29Z,OWNER,https://api.github.com/repos/bradyhouse/house,"fiddle.sh - ""poll"" command It seems like every time I visit [bradyhouse.github.io](bradyhouse.github.io) it ends in the frustration of finding yet another non-working fiddle. And so (dear backlog), I need way to ping (or rather test) each of my published fiddles. I am thinking this would be a useful function for fiddle.sh. If after running fiddle.sh ""publish"", I could then kickoff fiddle.sh ""poll"" to find anything that's broken, I would be like camper happy. In use case workflow speak -- 1. loop through the fiddles types 2. loop through the fiddles 3. open published page 4. on error, record the target URL And then (dear backlog) perhaps this function can be folded into publish process."
212565,236361,https://api.github.com/repos/rafaelsetragni/awesome_notifications/issues/98,bug,2021-01-28T13:14:29Z,NONE,https://api.github.com/repos/rafaelsetragni/awesome_notifications,Notification not display 1) Notification doesn't show when app is on Foreground state (in both Android & iOS). it shows only when app is in Background/Killed. It works with action buttons. without action buttons it's not working on Foreground state. 2) Action button not working in iOS. change `JsonUtils.fromJson` to `JsonUtils.fromJsonArr` line no. 45 `mapData[Definitions.PUSH_NOTIFICATION_BUTTONS] = JsonUtils.fromJson(buttonsJsonData)` to `mapData[Definitions.PUSH_NOTIFICATION_BUTTONS] = JsonUtils.fromJsonArr(buttonsJsonData)` 
393906,437822,https://api.github.com/repos/AdoptOpenJDK/openjdk-support/issues/279,bug,2021-03-11T20:56:38Z,NONE,https://api.github.com/repos/AdoptOpenJDK/openjdk-support,"AIX crashes 8u282 but not 8u265 <!-- Have you tested with the latest version? Yes both 8u282 and 8u265 with very different results --> ## Summary We have seen many crashes in a number of locations. We first thought it was JIT related so we disabled JIT and we see the same crashes, This is definitely a regression from 8u265 that is present in 8u282. [stacks.txt](https://github.com/AdoptOpenJDK/openjdk-support/files/6125902/stacks.txt) [javacore.20210302.071234.25625076.0002.txt](https://github.com/AdoptOpenJDK/openjdk-support/files/6125905/javacore.20210302.071234.25625076.0002.txt) ## Steps to reproduce Here is where the problem is. There are no steps that you can duplicate we found it during automated testing and can reproduce with a subset of the test. The people who sign my pay check require I write this report sending a javacore and stacks. We have many stacks that indicate the same thing, <!-- All bug reports must have steps to reproduce. Otherwise, we cannot work on it! A crash dump is not sufficient! I understand but this is a severe regression that is causing us to stop release of our V11 fix pack product and our new V12 Please provide a minimal, reproducible example that we can run locally. See https://stackoverflow.com/help/minimal-reproducible-example for what that means. A public GitHub repository works best. See https://github.com/aahlenst/datetimeformatter-parse-bug for a live example. --> ## Expected results Test runs correctly ## Actual results Crashes is many places ## Triaging info <!-- Paste the entire output of java -version. --> Java version: This is the release that is causing issues [root@pautoaixnext:/opt/ibm/domino/notes/latest/ibmpow/jvm/bin]#./java -version openjdk version ""1.8.0_282"" OpenJDK Runtime Environment (build 1.8.0_282-b08) Eclipse OpenJ9 VM (build openj9-0.24.0, JRE 1.8.0 AIX ppc64-64-Bit Compressed References 20210120_953 (JIT enabled, AOT enabled) OpenJ9 - 345e1b09e OMR - 741e94ea8 JCL - ab07c6a8fd based on jdk8u282-b08) This release works fine [root@pautoaixnext:/opt/ibm/domino/notes/latest/ibmpow/jvm/bin]#cd ../../jvmback/bin [root@pautoaixnext:/opt/ibm/domino/notes/latest/ibmpow/jvmback/bin]#./java -version openjdk version ""1.8.0_265"" OpenJDK Runtime Environment (build 1.8.0_265-b01) Eclipse OpenJ9 VM (build openj9-0.21.0, JRE 1.8.0 AIX ppc64-64-Bit Compressed References 20200728_769 (JIT enabled, AOT enabled) OpenJ9 - 34cf4c075 OMR - 113e54219 JCL - c82ff0c20f based on jdk8u265-b01) What is your operating system and platform? OS Level : AIX 7.2 2XHCPUS Processors - 3XHCPUARCH Architecture : ppc64 3XHNUMCPUS How Many : 8 3XHNUMASUP NUMA is either not supported or has been disabled by user How did you install Java? We install the entire JRE within a JVM directory in our product. <!-- Whether you used a binary archive (zip, tar.gz), an installer package (MSI, rpm, etc.), a version manager (jabba, jenv, etc.). --> Did it work before? Works with 8u265 and fails with 8u272. We can take 8u272 and place it in a previous version of our product and it will fail the same way <!-- If so, please specify what changed. --> The Java version Did you test with other Java versions? Yes see above <!-- Please specify exactly what Java versions you tested with, for example by pasting the output of java -version. see above If available, test with an upstream build: * https://adoptopenjdk.net/upstream.html (8, 11) * http://jdk.java.net/ (anything newer than 8, 11) --> "
251616,279880,https://api.github.com/repos/gloriaJun/gloria-tilog/issues/142,enhancement,2020-09-18T17:14:34Z,OWNER,https://api.github.com/repos/gloriaJun/gloria-tilog,svg icon component ## Description :memo: ## To Do :mag: 
690479,767396,https://api.github.com/repos/GEOLYTIX/xyz/issues/390,bug,2021-03-31T19:10:21Z,MEMBER,https://api.github.com/repos/GEOLYTIX/xyz,_workspace module code review and roles method Negated only roles do not work for layers in locales. The _workspace module is a bit of a mess with repeated definitions of the legacy role check method.
649094,721503,https://api.github.com/repos/concourse/concourse/issues/6512,bug,2021-02-04T22:47:05Z,CONTRIBUTOR,https://api.github.com/repos/concourse/concourse,"testflight failing to create container with memory limit ## Summary <!-- A brief summary of the problem. --> The testflight [test](https://github.com/concourse/concourse/blob/368451a95f6d4dcc6e6903e5b83934c47914e898/testflight/container_limits_test.go#L13) for container limits is failing with `containerd` with the following error: ``` find or create container on worker a967c5450087: starting task: new task: OCI runtime create failed: container_linux.go:367: starting container process caused: process_linux.go:495: container init caused: process_linux.go:458: setting cgroup config for procHooks process caused: open /sys/fs/cgroup/memory/garden/a6de8b89-bce8-4fba-58a7-4aff260615ec/memory.memsw.limit_in_bytes: no such file or directory: unknown ``` This error is from `runc` and started showing up after runc v1.0.0-rc-93 (https://github.com/opencontainers/runc/releases/tag/v1.0.0-rc93) began being bundled in the `concourse/dev` image. ## Steps to reproduce <!-- All bug reports must have steps to reproduce, starting from the instructions in CONTRIBUTING.md for running Concourse locally: https://github.com/concourse/concourse/blob/master/CONTRIBUTING.md#running-concourse Starting from `docker-compose up`, what steps can be followed to reproduce the problem? Please use https://gist.github.com for large snippets! --> So far this wasn't reproducible using Docker compose. ## Additional context Failed build - https://ci.concourse-ci.org/teams/main/pipelines/concourse/jobs/testflight/builds/580 ## Triaging info * Runc version: v1.0.0-rc-93 - [Release Notes](https://github.com/opencontainers/runc/releases/tag/v1.0.0-rc93) * Concourse version: circa v7.0.0 - https://github.com/concourse/concourse/commit/368451a95f6d4dcc6e6903e5b83934c47914e898 * Did this used to work? - Yes "
691513,768543,https://api.github.com/repos/intel/mptcpd/issues/134,question,2021-05-08T00:14:25Z,NONE,https://api.github.com/repos/intel/mptcpd,"optional values for MPTCP_CMD_SUB_CREATE in netlink_pm_mptcp_org.c Hi, It looks like the comment https://github.com/intel/mptcpd/blob/master/src/netlink_pm_mptcp_org.c#L317-L321 are not correct. **Local address**, **remote address** and **remote port** are not optional for `MPTCP_CMD_SUB_CREATE` command. Only **source port**, **backup flag** and **if_idx** are optional. Please check the **out of tree mptcp Netlink path manager** implementation at kernel side https://github.com/multipath-tcp/mptcp/blob/mptcp_v0.95/net/mptcp/mptcp_netlink.c#L862-L872 Also, why we are not adding `MPTCP_ATTR_FAMILY` for subflow create command? I see the bug comment https://github.com/intel/mptcpd/blob/v0.7/src/netlink_pm_mptcp_org.c#L333 but I don't understand it. Am I missing something here? "
61103,67916,https://api.github.com/repos/lovell/sharp/issues/2723,question,2021-05-18T07:05:11Z,NONE,https://api.github.com/repos/lovell/sharp,version 0.28.0 and later is not compatible with Intel Wolfdale E5xxx CPU **Are you using the latest version?** yes **What are the steps to reproduce?** I just installed the latest version using npm. after adding this line of code: ```await sharp(req.file.path)``` I get this error: ```Illegal instruction (core dumped)``` **What is the output of running `npx envinfo --binaries --system`?** ``` System: OS: Linux 5.4 Linux Mint 20 (Ulyana) CPU: (2) x64 Pentium(R) Dual-Core CPU E5300 @ 2.60GHz Memory: 172.51 MB / 3.84 GB Container: Yes Shell: 3.2.2 - /usr/bin/fish Binaries: Node: 10.19.0 - /usr/bin/node npm: 7.6.1 - /usr/local/bin/npm ``` after trying a couple of older versions I found that the latest version that works for me is ```0.27.2```. I don't have any problem with this version yet.
342647,380914,https://api.github.com/repos/massenergize/frontend-portal/issues/513,bug,2021-02-06T11:51:19Z,CONTRIBUTOR,https://api.github.com/repos/massenergize/frontend-portal,"Unapproved team shows up on teams page for anonymous user On Dev in Nowhere site, on the [all teams page](https://community-dev.massenergize.org/nowhere/teams) I can see the team Sore Losers. When I click on it, I get to the error page with the message: Error: Unable to load this team - Cannot access team until it is approved. It shouldn't show up on the list unless I am signed in and was the admin who created the team"
251243,279460,https://api.github.com/repos/marlomgirardi/vscode-keep-context/issues/4,enhancement,2020-09-22T06:04:03Z,NONE,https://api.github.com/repos/marlomgirardi/vscode-keep-context,Hotkey to switch between tasks Could you please add a hotkey to switch between tasks ? ex: <kbd>alt+s</kbd> -> switch to next task from the list <kbd>alt + p</kbd> -> switch to previous task from the list And thank you for this plugin :)
59866,66552,https://api.github.com/repos/appsmithorg/appsmith/issues/2822,bug,2021-02-02T10:15:13Z,CONTRIBUTOR,https://api.github.com/repos/appsmithorg/appsmith,"[Bug] Unable to change the tab name from the Entity explorer Steps to reproduce : 1) Add Tab Widget into the canvas 2) Add other widget into the Tab widget 3) Now navigate to Entity explorer 4) Change the name of the ""Tab"" from the Entity explorer and observer Observation: It is observed that the user Name of the tab does not get updated when changed from the entity explorer Expectation: It is expected that the entity explorer name must get updated to the widget ![Screenshot 2021-02-02 at 3 39 30 PM](https://user-images.githubusercontent.com/71753653/106585620-86a91280-656d-11eb-83f4-bb429a79b5bf.png) "
342770,381048,https://api.github.com/repos/Naamloos/FeestSpel/issues/19,bug,2021-05-05T22:36:21Z,OWNER,https://api.github.com/repos/Naamloos/FeestSpel,"room code rendert raar op mobile schermen. voorbeeld: <img height=""350"" src=""https://user-images.githubusercontent.com/12187179/117218167-ee882700-ae02-11eb-95ae-520f254aa03e.png"">"
254496,283066,https://api.github.com/repos/legoboyvdlp/A320-family/issues/212,bug,2021-03-03T21:26:41Z,COLLABORATOR,https://api.github.com/repos/legoboyvdlp/A320-family,Bug - VHF3 data mode got broken on next due to core changes previously setting `/instrumentation/comm[2]/frequencies/selected-mhz` to 0 switched the VHF3 into data mode. This is no longer possible as it gets reset to a valid frequency. We need another property for it now..... any proposals?
528130,586991,https://api.github.com/repos/jacobweinstock/tinklet/issues/4,enhancement,2021-04-22T00:20:40Z,OWNER,https://api.github.com/repos/jacobweinstock/tinklet,add kubernetes backend add the ability to run containers using Kubernetes. WIP here: https://github.com/jacobweinstock/tinklet/tree/kube-implementation
192746,214351,https://api.github.com/repos/microsoft/vscode-jupyter/issues/5280,bug,2021-03-24T23:23:34Z,NONE,https://api.github.com/repos/microsoft/vscode-jupyter,".ipynb Open Changes in Source Control not working Version: 1.54.3 Commit: 2b9aebd5354a3629c3aba0a5f5df49f43d6689f8 Date: 2021-03-15T10:55:24.277Z Electron: 11.3.0 Chrome: 87.0.4280.141 Node.js: 12.18.3 V8: 8.7.220.31-electron.0 OS: Linux x64 5.8.0-45-generic snap ## Expected behaviour 1. Source control upon clicking on a staged on .ipyn (or right click Open Changes): side by side staged and last commit with red and green area for the diff. 2. Sorce control upon clicking on commit in the timeline: same as above. ## Actual behaviour 1. The file opens, shows (index) in the title for a second, then turn into (git) and display the actual file: no diff, no comparison with the previous commit, just one column. 2.When clicking on a commit in the timeline, SOMETIMES It opens two files side by side with the title ""xxxx.ipynb contrast yyyyy.ipynb"", but they neither scroll async nor the differences are shown. SOMETIMES shows just one file with title (git). ## Steps to reproduce: 0. [With a the jupyter strip installed and configured](https://github.com/kynan/nbstripout#apply-retroactively). 1.Go to SCM (ctrl+shoft+G) 2. Stage a .ipynb. 3. click on the stage file (or right click Open Changes) 4. as comparison (and to prove git is working fine) open a new terminal in vs code 5. type git diff --cahced NOTE: everything works fine for .py scripts. This problem persists for 2 months."
653325,726240,https://api.github.com/repos/wazuh/wazuh-kibana-app/issues/3006,bug,2021-02-24T05:37:13Z,NONE,https://api.github.com/repos/wazuh/wazuh-kibana-app,"No matching indices found | Wazuh | Elastic | Rev | | ----- | ------- | --- | | 4.1.0-1 | 7.10 | --- | **Description** Wazuh don't create monitoring-* indice. I get error: `No matching indices found: No indices match pattern ""wazuh-monitoring-*""` Also I have such logs: ``` error: 2021/02/24 3:15:1: monitoring:insertMonitoringDataElasticsearch: Response Error error: 2021/02/24 3:15:1: monitoring:insertMonitoringDataElasticsearch: index_not_found_exception error: 2021/02/24 3:30:2: monitoring:insertMonitoringDataElasticsearch: Response Error error: 2021/02/24 3:30:2: monitoring:insertMonitoringDataElasticsearch: index_not_found_exception error: 2021/02/24 3:45:1: monitoring:insertMonitoringDataElasticsearch: Response Error error: 2021/02/24 3:45:1: monitoring:insertMonitoringDataElasticsearch: index_not_found_exception error: 2021/02/24 4:0:1: monitoring:insertMonitoringDataElasticsearch: Response Error error: 2021/02/24 4:0:1: monitoring:insertMonitoringDataElasticsearch: index_not_found_exception error: 2021/02/24 4:15:1: monitoring:insertMonitoringDataElasticsearch: Response Error error: 2021/02/24 4:15:1: monitoring:insertMonitoringDataElasticsearch: index_not_found_exception error: 2021/02/24 4:30:2: monitoring:insertMonitoringDataElasticsearch: Response Error error: 2021/02/24 4:30:2: monitoring:insertMonitoringDataElasticsearch: index_not_found_exception error: 2021/02/24 4:45:1: monitoring:insertMonitoringDataElasticsearch: Response Error error: 2021/02/24 4:45:1: monitoring:insertMonitoringDataElasticsearch: index_not_found_exception error: 2021/02/24 5:0:1: monitoring:insertMonitoringDataElasticsearch: Response Error error: 2021/02/24 5:0:1: monitoring:insertMonitoringDataElasticsearch: index_not_found_exception error: 2021/02/24 5:15:2: monitoring:insertMonitoringDataElasticsearch: Response Error error: 2021/02/24 5:15:2: monitoring:insertMonitoringDataElasticsearch: index_not_found_exception error: 2021/02/24 5:30:1: monitoring:insertMonitoringDataElasticsearch: Response Error error: 2021/02/24 5:30:1: monitoring:insertMonitoringDataElasticsearch: index_not_found_exception error: 2021/02/24 5:45:1: monitoring:insertMonitoringDataElasticsearch: Response Error error: 2021/02/24 5:45:1: monitoring:insertMonitoringDataElasticsearch: index_not_found_exception error: 2021/02/24 6:0:2: monitoring:insertMonitoringDataElasticsearch: Response Error error: 2021/02/24 6:0:2: monitoring:insertMonitoringDataElasticsearch: index_not_found_exception error: 2021/02/24 6:15:1: monitoring:insertMonitoringDataElasticsearch: Response Error error: 2021/02/24 6:15:1: monitoring:insertMonitoringDataElasticsearch: index_not_found_exception error: 2021/02/24 6:30:1: monitoring:insertMonitoringDataElasticsearch: Response Error error: 2021/02/24 6:30:1: monitoring:insertMonitoringDataElasticsearch: index_not_found_exception error: 2021/02/24 6:45:2: monitoring:insertMonitoringDataElasticsearch: Response Error error: 2021/02/24 6:45:2: monitoring:insertMonitoringDataElasticsearch: index_not_found_exception error: 2021/02/24 7:0:1: monitoring:insertMonitoringDataElasticsearch: Response Error error: 2021/02/24 7:0:1: monitoring:insertMonitoringDataElasticsearch: index_not_found_exception error: 2021/02/24 7:15:1: monitoring:insertMonitoringDataElasticsearch: Response Error error: 2021/02/24 7:15:1: monitoring:insertMonitoringDataElasticsearch: index_not_found_exception error: 2021/02/24 7:30:2: monitoring:insertMonitoringDataElasticsearch: Response Error error: 2021/02/24 7:30:2: monitoring:insertMonitoringDataElasticsearch: index_not_found_exception error: 2021/02/24 7:45:1: monitoring:insertMonitoringDataElasticsearch: Response Error error: 2021/02/24 7:45:1: monitoring:insertMonitoringDataElasticsearch: index_not_found_exception error: 2021/02/24 8:0:1: monitoring:insertMonitoringDataElasticsearch: Response Error error: 2021/02/24 8:0:1: monitoring:insertMonitoringDataElasticsearch: index_not_found_exception error: 2021/02/24 8:15:0: monitoring:insertMonitoringDataElasticsearch: Response Error error: 2021/02/24 8:15:0: monitoring:insertMonitoringDataElasticsearch: index_not_found_exception error: 2021/02/24 8:30:2: monitoring:insertMonitoringDataElasticsearch: Response Error error: 2021/02/24 8:30:2: monitoring:insertMonitoringDataElasticsearch: index_not_found_exception error: 2021/02/24 8:31:6: wazuh-elastic:getFieldTop: index_not_found_exception ``` "
638293,709391,https://api.github.com/repos/greenbone/ospd-openvas/issues/284,bug,2020-07-10T10:00:03Z,NONE,https://api.github.com/repos/greenbone/ospd-openvas,"Resumed tasks may generate invalid target value error on ospd-openvas side **Environment:** ``` Ubuntu 18.04 Greenbone Vulnerability Manager 9.0.1~git-e250176b-gvmd-9.0 GIT revision e250176b-gvmd-9.0 Manager DB revision 221 gvm@ov-master-eqi:~$ gsad --version Greenbone Security Assistant 9.0.1~git-9fb2e63cd-gsa-9.0 gvm@ov-master-eqi:~$ openvas --version OpenVAS 7.0.1 gvm-libs 11.0.1 ``` **Expected behaviour:** Tasks resumed shouldn't produce any target errors on ospd-openvas side. **Actual behaviour:** If a task stop while running for whatever reason; resuming it may generated continuous Invalid target value errors on ospd-openvas side. Target has not been changed, and starting the task again (without resuming it) will not produce those errors: ``` 2020-07-10 11:58:10,604 OSPD - openvas: INFO: (ospd.network) : Invalid target value 2020-07-10 11:58:10,772 OSPD - openvas: INFO: (ospd.network) : Invalid target value 2020-07-10 11:58:11,618 OSPD - openvas: INFO: (ospd.network) : Invalid target value 2020-07-10 11:58:11,779 OSPD - openvas: INFO: (ospd.network) : Invalid target value 2020-07-10 11:58:12,628 OSPD - openvas: INFO: (ospd.network) : Invalid target value .... ``` It is not clear if this bug has any effect on scans results, since openvas logs doesn't show any errors and resume the scans without problem; while no error is reported on gsad / gvmd side. **How To reproduce:** - Start a task - After at least 50-60% achieved; stop the task. - Once stopped; resume the task. - Look at ospd-openvas logs for the upon errors. **Note:** The issue do not always occurs; but is likely to occurs on big tasks (/22 or higher)"
276220,307181,https://api.github.com/repos/SadracTijerina/robot-gladiators/issues/6,bug,2021-04-02T01:36:50Z,OWNER,https://api.github.com/repos/SadracTijerina/robot-gladiators,"Mixed-case response and blank/null handling for the fight-or-skip prompt # Expected Behavior - Accepts mixed case response for skip and fight. - Re-prompts for blank and null responses # Current Behavior - If responses is mixed case like ""Skip"", the fighting progresses, not skipping. - if the response is blank or null, the fighting progresses. # Possible Solution - Change case using string method. - Add conditionals to handle the blanks and null responses."
227604,253131,https://api.github.com/repos/apache/superset/issues/11859,bug,2020-11-30T21:30:43Z,CONTRIBUTOR,https://api.github.com/repos/apache/superset,"[bar chart] Chart cannot scroll horizontally #### How to reproduce the bug 1. create a time-series bar chart that can be wider than browser view area. ### Actual results <img width=""1584"" alt=""Screen Shot 2020-11-30 at 1 24 01 PM"" src=""https://user-images.githubusercontent.com/27990562/100667935-00bfdf80-3310-11eb-9ea8-db6fb1cb838a.png""> ### Expected results User should be able to scroll horizontally to see the right end. ### Environment latest master ### Checklist Make sure to follow these steps before submitting your issue - thank you! - [x] I have checked the superset logs for python stacktraces and included it here as text if there are any. - [x] I have reproduced the issue with at least the latest released version of superset. - [x] I have checked the issue tracker for the same issue and I haven't found one similar. ### Additional context Add any other context about the problem here. "
45135,50246,https://api.github.com/repos/CastosHQ/Seriously-Simple-Podcasting/issues/629,bug,2021-03-02T16:44:19Z,COLLABORATOR,https://api.github.com/repos/CastosHQ/Seriously-Simple-Podcasting,"Castos player doesn't play in v2.5.3+ release **Describe the bug** In some sites, the ""castos"" player doesn't play audio in the latest versions. "
85995,95600,https://api.github.com/repos/crc-32/libpebblecommon/issues/4,bug,2020-09-30T19:23:59Z,OWNER,https://api.github.com/repos/crc-32/libpebblecommon,Android release package empty https://github.com/pebble-dev/mobile-app/issues/10
678412,753972,https://api.github.com/repos/Biebertal-mach-mit-TV/Data-Analytics/issues/14,enhancement,2021-05-10T19:07:59Z,COLLABORATOR,https://api.github.com/repos/Biebertal-mach-mit-TV/Data-Analytics,"[Implementierung] Erstellung des Dashboards # Implementierung * Erstellen des Dashboards (mind. Komponente Infoprovider-Übersicht) * Aufbau der grundlegenden Struktur (bestenfalls mit Tabs wie in den Mock-Ups) Auflisten aller Infoprovider, die durch das Backend bereitgestellt werden (Anfrage beim Laden der Seite, solange Ladeanimation) - siehe Datenformat von Sören in allgemein. * Nachbesserung Formeleditor: Bei einer Formel muss für alle enthaltenen Variablen/Daten der Datentyp mit gesendet werden, ggf. Absprache mit Backend wegen Format * Anfangen mit Bearbeiten Infoprovider "
566018,629007,https://api.github.com/repos/davestephens/ansible-nas/issues/334,bug,2020-05-24T19:51:06Z,NONE,https://api.github.com/repos/davestephens/ansible-nas,"Gitea: fail to create database **Describe the bug** I tried to install ansible-nas multiple times and use gitea service, I always get an error in the first registry of `The database settings are invalid: Error 1005: Can't create table 'user' (errno: 13)`. I didn't touch the db configuration of the default gitea installation. ![Screenshot](https://user-images.githubusercontent.com/497246/82763521-be589b80-9dde-11ea-8a60-2cd07dbd6969.png) **Environment** - Ansible-NAS revision (`git rev-parse --short HEAD`): `a61ecb9` - Ansible version (paste the entire output of `ansible --version` on the machine you run the playbook from): `2.9.9` - Ansib..le-NAS operating system (`cat /etc/lsb-release` on the Ansible-NAS box) - _If this is anything other than Ubuntu 18.04 help will be limited_: `Ubuntu 20.04` - Ansible-NAS kernel (`uname -a` on the Ansible-NAS box): `Linux nas 5.4.0-31-generic` - Ansible-NAS Python version (`python --version` on the Ansible-NAS box): `3.8.2` - Ansible-NAS Docker version (`docker --version` on the Ansible-NAS box): `19.03.9` - Latest Docker logs (`journalctl -u docker.service` on the Ansible-NAS box): `` - Are you running the playbook from a remote box or the Ansible-NAS box itself? `remote` - Vagrant version, if testing (`vagrant --version`): `` - Ansible-NAS filesystems (`df -hT` on the Ansible-NAS box): `` - Mounted filesystems (`mount` on the Ansible-NAS box) `` **Expected behavior** The error shouldn't appear. **Actual behavior** Error reported. **Steps to reproduce** Install gitea via ansible-nas and try to access gitea service. "
304279,338296,https://api.github.com/repos/magey/tbc-warrior/issues/57,bug,2021-04-23T20:58:29Z,OWNER,https://api.github.com/repos/magey/tbc-warrior,"Glancing damage reduction is inconsistent with TBC-era logs Research done by vigo2 [over here](https://github.com/magey/tbc-warrior/issues/1#issuecomment-825579288) revealed that glancing blow damage reduction vs. boss mobs in an [extensive collection of WWS parses](http://sisuguild.fi/~juha/wws/) from that era does not match the known/accepted value of 35% that we currently measured on beta, but instead is around **25%**. The glancing blow damage reduction formula for vanilla indeed calculated 35% reduction against boss mobs without any bonus weapon skill, but it's possible that when the glancing blow chance formula was changed in patch 2.1, the damage reduction formula changed as well. Here's a direct link to his [spreadsheet aggregating the glance damage reduction from various fights](https://docs.google.com/spreadsheets/d/e/2PACX-1vSwB4EZdWkCjm2gVuufyTCtIc6T3e7VZ7p57Ex4GCkQuSHq766Kh-MeHItMvtpUdP4_3jWpNlhTxD7M/pubhtml)."
231306,257229,https://api.github.com/repos/Fammeo/Fammeo/issues/398,enhancement,2021-02-26T07:05:38Z,NONE,https://api.github.com/repos/Fammeo/Fammeo,issue in removing industry and software experience ### When user click on the remove button in industry and software experience it should ask for confirmation just like the award ### same thing also happened in industry in about tab 
487758,542081,https://api.github.com/repos/qtile/qtile/issues/1275,enhancement,2019-01-31T19:18:35Z,NONE,https://api.github.com/repos/qtile/qtile,"How to make sure no windows start as floating? Pretty self explanatory. I tried setting `float_rules=[]`, `float_rules=None`, and removing `layout.Floating()` from my `config.py` altogether. I just don't want to have to keep running `lazy.window.toggle_floating()` all the time because I really dislike handling floating windows, even if they are dialog boxes."
331958,369043,https://api.github.com/repos/AllTheMods/ATM-6/issues/901,question,2021-01-20T18:10:08Z,NONE,https://api.github.com/repos/AllTheMods/ATM-6,"Jumping from singleplayer to multiplayer after leaving a SP world <!-- Type your question below. Questions without a pack version will be closed without comment. --> Version: 1.4.1 (current) I don't rly know if this is a pack, forge or mc related issue but when I leave a singleplayer world it automatically jumps to multiplayer. During the ""Exiting world and loading menu""-time I don't press or click anything. I just wanted to ask if this is sth. pack related?"
718168,798173,https://api.github.com/repos/home-assistant/android/issues/1523,enhancement,2021-04-22T14:00:15Z,NONE,https://api.github.com/repos/home-assistant/android,"Samsung Gear S3 / Health Integration <!-- READ THIS FIRST: - Make sure you've checked existing feature requests to make sure you aren't opening a duplicate. If you do open a duplicate issue because you didn't check existing requests, we will have some work for nothing. Putting this work into more features (maybe even yours!) just feels better. DO NOT DELETE ANY TEXT from this template! All requested information is important. --> **Is your feature request related to a problem? Please describe.** <!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] --> Not related to a problem, a helpful idea **Describe the solution you'd like** <!-- A clear and concise description of what you want to happen. --> An option in the companion app to read the state of Tizen OS Devices (Battery State, Is_charging) and Samsung Health Statistics (similar the Fitbit Integration: Weight (int), Steps (int), Active Time (Int), Last Exercise (String), Last Exercise Time (Datetime object?), Last Exercise Calories Burned (Int), Food Calories (Int), Food Last Meal Type (String), Food Last Meal (String), Sleep Time Elapsed (Int or Datetime Object), Heart Rate (Int), Water (In Glasses, Int), Blood Glucose (Int), Blood Pressure (String, maybe an Int Concatenation), and a lot more available. Also, maybe services through home assistant to update sensors from other sources, if applicable (such as Fitbit, Withings Sleep Sensor, etc.) to update to Samsung Health as a ""sub hub"" of sorts. **Describe alternatives you've considered, if any** <!-- A clear and concise description of any alternative solutions or features you've considered. --> I have considered using a service called FitnessSyncer, because it uses a REST API and Updates through multiple areas, including Samsung Health, but also Google Fit and Fitbit, and synchronizes the other connections to the app, but it is a paid service. **Additional context** <!-- Add any other context or screenshots about the feature request here. --> Samsung does have a REST API endpoint, but it is locked town to ONLY corporate customers, and not to 3rd party integrations. The only feasible way would be the Companion App, since it has the structure to do so. Reference here (for Health): https://developer.samsung.com/onlinedocs/health/overview-summary.html "
78238,86990,https://api.github.com/repos/libvips/libvips/issues/1731,enhancement,2020-07-20T13:50:47Z,MEMBER,https://api.github.com/repos/libvips/libvips,reconsider use of `__builtin` Look at `__builtin_fmax()` and fmin() again. They seem to be slower than a simpler ternary. See https://github.com/libvips/libvips/pull/1729 
572072,635747,https://api.github.com/repos/habetuz/me/issues/11,bug,2021-02-08T20:19:34Z,OWNER,https://api.github.com/repos/habetuz/me,"Scrollen wird nicht deaktiviert **Describe the bug** Scrollen wird nicht deaktiviert, wenn man zu früh scrollt **To Reproduce** 1. Öffne Youtube 2. Click auf das Logo 3. Scrolle bevor die Animation beendet ist **Expected behavior** Das scrollen sollte trotzdem deaktiviert werden "
291995,324697,https://api.github.com/repos/ProfileCreator/ProfileCreator/issues/239,question,2021-01-27T16:44:07Z,NONE,https://api.github.com/repos/ProfileCreator/ProfileCreator,"VPN Payload? It looks like it was requested in issue #54, but was closed without being added. I manually added our VPN payload to a network profile, and imported it to PC, but after signing and uploading it to Jamf and installing the profile, the VPN connection doesn't exist on the device. The other payloads such as AD certificate, WiFi, Ethernet, etc that were created in PC work fine."
445745,495436,https://api.github.com/repos/nonlinear-labs-dev/C15/issues/2421,bug,2021-01-06T19:56:34Z,MEMBER,https://api.github.com/repos/nonlinear-labs-dev/C15,"BOLED: Preset-Screen: das Part-Icon folgt machmal nicht mehr der Part-Selektion (repro s.u.) - Im Preset-Screen ein Layer-Preset laden - Über ""Sound"" und ""Voices"" den Mono- oder Unison-Parameter-Screen öffnen - Wieder zurück auf den Preset-Screen: Mit dem ""I / II""-Button kann man beide Parts auswählen, aber das Part-Icon springt höchstens einmal auf Part I und bleibt dann dort hängen. Wenn man im Parameter-Screen den ""I / II""-Button betätigt, ist danach das Verhalten des Icons im Preset-Screen wieder ok."
390964,434578,https://api.github.com/repos/signal-csharp/libsignal-service-dotnet/issues/39,enhancement,2020-12-18T16:30:03Z,NONE,https://api.github.com/repos/signal-csharp/libsignal-service-dotnet,"Missing attachment id I can't donwload attachents which are send from the offical iOS and android app because the attachment id of the message is missing (value is 0), but attachments which are send from signal-widows have an id. Message from iOS: ![Screenshot 2020-12-18 170722](https://user-images.githubusercontent.com/42971547/102635573-d06fa200-4153-11eb-9e37-3ca5c310e980.jpg) Message from signal-windows: ![Screenshot 2020-12-18 170717](https://user-images.githubusercontent.com/42971547/102635569-cfd70b80-4153-11eb-8e52-a148df3892e7.jpg) Any idea what is causing this?"
639307,710543,https://api.github.com/repos/DLR-RM/stable-baselines3/issues/402,enhancement,2021-04-19T13:03:34Z,CONTRIBUTOR,https://api.github.com/repos/DLR-RM/stable-baselines3,"[Feature Request] support vec env evaluation with n_envs >1 Description Issue for #398 Right now, policy evaluation can only happen on vector environments with n=1 copies of the env. This is a small change to expand this. Motivation and Context -When doing hyperparameter tuning on certain environments, large numbers of evaluations are required to get accurate performance metrics. This lets that happen much faster. -This is required for all the wrappers to work when PettingZoo environments are used Both of these have been problems for be recently. This change is so small that I don't know what tests if any would be sensible to add. ### Alternatives Having to manage my own fork with this functionality ### Additional context Similar libraries do this: https://github.com/cpnota/autonomous-learning-library/blob/develop/all/experiments/parallel_env_experiment.py#L90 ### Checklist - [x] I have checked that there is no similar [issue](https://github.com/DLR-RM/stable-baselines3/issues) in the repo (**required**) <!--- This Template is an edited version of the one from https://github.com/pytorch/pytorch -->"
628397,698351,https://api.github.com/repos/SaiintBrisson/inventory-framework/issues/6,bug,2021-03-15T19:21:24Z,NONE,https://api.github.com/repos/SaiintBrisson/inventory-framework,Individual click cancellation being set prematurely https://github.com/SaiintBrisson/inventory-framework/blob/368ed07a75d1e3f3b51ce28e3b9806c818927a5d/src/main/java/me/saiintbrisson/minecraft/PaginatedView.java#L277
201103,223606,https://api.github.com/repos/axetroy/anti-redirect/issues/366,bug,2021-01-14T15:46:56Z,NONE,https://api.github.com/repos/axetroy/anti-redirect,简书偶尔失效 ### BUG 描述 简书跳转偶尔失效 > 请对这个 BUG 进行描述 ### 相关的连接 > 请输入出现这个 BUG 的相关网页地址 `https://www.jianshu.com/go-wild?ac=2&url=https%3A%2F%2Ftic.gal%2Fen%2Fjava-security-cert-certpathvalidatorexception-trust-anchor-for-certification-path-not-found%2F` `https://www.jianshu.com/go-wild?ac=2&url=https%3A%2F%2Fletsencrypt.org%2Fzh-cn%2Fdocs%2Frate-limits%2F` 截图如下: ![photo_2021-01-14_21-10-38](https://user-images.githubusercontent.com/44364154/104613939-b2e61780-56c2-11eb-9ad7-503f5c592d64.jpg) 
460198,511457,https://api.github.com/repos/wso2/product-is/issues/11075,bug,2021-01-25T07:53:34Z,MEMBER,https://api.github.com/repos/wso2/product-is,"Creating two OAuth apps with the same name returns 500 **Describe the issue:** Create an application with below payload ``` { ""name"": ""aaaaaa"", ""inboundProtocolConfiguration"": { ""oidc"": { ""allowedOrigins"": [""https://localhost""], ""callbackURLs"": [ ""http://localhost:8080/playground2/oauth2client"" ], ""grantTypes"": [ ""refresh_token"", ""authorization_code"" ] } } } ``` - Try to create an application with the same name (same payload) again - Observed error, Status Code: 500 ``` { ""code"": ""APP-65001"", ""message"": ""Server error while performing the attempted operation."", ""description"": ""Error while Creating/Updating OAuth2/OpenIDConnect configuration. Error when adding the application. An application with the same name already exists."", ""traceId"": ""44cd850a-497b-443f-bc66-d244b641cf7b"" } ``` **How to reproduce:** As given above **Expected behavior:** Status code should be 409 (Conflict) A proper error code indicating the error needs to be returned instead of APP-65001"
376722,418787,https://api.github.com/repos/frappe/erpnext/issues/22846,bug,2020-07-29T10:34:12Z,NONE,https://api.github.com/repos/frappe/erpnext,"Accounts Receivable Summary mismatch with General ledger and Customer Ledger Summary-v13 - General Ledger Debit Amount and Customer Ledger Summary Invoiced Amount agree. - General Ledger Credit Amount and Customer Ledger Summary Paid Amount do not agree, because Paid Amount in CLS includes cancelled entries. - - Invoiced Amount and Paid Amount in Accounts Receivable Summary, do not agree with what's on the GL and Customer Ledger Summary. Could be a reason for this, but it's not clear where the figures in the Accounts Receivable Summary come from. "
291177,323784,https://api.github.com/repos/Elysiayn/just-tech-news/issues/8,enhancement,2021-02-02T07:16:19Z,OWNER,https://api.github.com/repos/Elysiayn/just-tech-news,"Create a login and signup page * As a user, I can visit a login page to create a new account or log into an existing account. * As a user, I want to stay logged in even if I refresh the page or close the browser tab. * As a user, I can click a ""logout"" button for the app to forget me."
195578,217466,https://api.github.com/repos/MicrosoftDocs/navdevitpro-content-pr/issues/2174,question,2021-01-13T21:28:18Z,NONE,https://api.github.com/repos/MicrosoftDocs/navdevitpro-content-pr,"More Clarification Needed I am wondering if there needs to be some further clarification. The doc instructs to export the language file, then ""open the file with a text editor or in Microsoft Office Excel."" Then the picture illustrates a file that has been parsed into two Excel columns--something that takes some artful Excel importing, not just ""open"". Then in the Import section, we get only ""Select the file, and then choose Open."" It does not describe how or if the parsed Excel file needs to be re-assembled before importing. A little documentation on the identity/role of each of the elements on the language line would also be helpful. [Enter feedback here] --- #### Document Details ⚠ *Do not edit this section. It is required for docs.microsoft.com ➟ GitHub issue linking.* * ID: bde3484d-cec0-101f-c0c4-09f8b0fa7500 * Version Independent ID: bd4ff161-3dbc-892b-a188-35350db0882c * Content: [Importing and Exporting Multilanguage Files - Dynamics NAV](https://docs.microsoft.com/en-us/dynamics-nav/how-to--add-translated-strings-by-importing-and-exporting-multilanguage-files) * Content Source: [dynamics-nav/How-to--Add-Translated-Strings-By-Importing-and-Exporting-Multilanguage-Files.md](https://github.com/MicrosoftDocs/navdevitpro-content-pr/blob/live/dynamics-nav/How-to--Add-Translated-Strings-By-Importing-and-Exporting-Multilanguage-Files.md) * Product: **dynamics-nav-2018** * GitHub Login: @jswymer * Microsoft Alias: **jswymer**"
593161,659212,https://api.github.com/repos/KadeDev/Kade-Engine/issues/155,enhancement,2021-04-06T17:46:42Z,NONE,https://api.github.com/repos/KadeDev/Kade-Engine,"Enhancement: Readd Old Input. Basically, i want the old input option back. this is all ill say. "
520264,578204,https://api.github.com/repos/directus/directus/issues/3988,bug,2021-02-09T19:54:17Z,MEMBER,https://api.github.com/repos/directus/directus,Remove Overview from Docs This page should be deleted. It is not part of our docs and has all broken links. **Getting Started > Intro** should be the initial page of the Docs module. ![Screen Shot 2021-02-09 at 2 52 47 PM](https://user-images.githubusercontent.com/522079/107420159-97660500-6ae6-11eb-9699-ab9cb99e80f3.png) 
318144,353676,https://api.github.com/repos/djkoloski/rust_serialization_benchmark/issues/1,enhancement,2021-03-10T21:25:03Z,OWNER,https://api.github.com/repos/djkoloski/rust_serialization_benchmark,CBOR benchmarks CBOR is supported through serde so it shouldn't be too hard to get this up and running. Crate is `serde_cbor`.
705302,783885,https://api.github.com/repos/Arquisoft/radarin_es1b/issues/41,enhancement,2021-03-02T10:10:46Z,CONTRIBUTOR,https://api.github.com/repos/Arquisoft/radarin_es1b,Implementar la lógica de acceso a datos para el mapa A realizar con @manuel-arroyo 
126356,140407,https://api.github.com/repos/informalsystems/apalache/issues/197,enhancement,2020-08-05T11:45:38Z,MEMBER,https://api.github.com/repos/informalsystems/apalache,"[FEATURE] Better constant propagation The current optimizer propagates constants, but fails to do so in some cases. For example: ```tla ---------------------------- MODULE Opt1 ------------------------------------- VARIABLES S A == ""Foo"" Init == S = 0 Next == IF A = ""Foo"" THEN S' = 1 ELSE S' = 2 ============================================================================== ``` The output after the optimization step (as can be seen in `out-opt.tla`), is like this: ```tla ----- MODULE Opt1 ----- VARIABLE S Init$0 == S' := 0 Next$0 == ""Foo"" = ""Foo"" /\ S' := 1 Next$1 == ~(""Foo"" = ""Foo"") /\ S' := 2 =============== ``` It is not clear, why the optimizer did not rewrite `""Foo"" = ""Foo""` into `TRUE`. The optimizer can be found in [`at.forsyte.apalache.tla.pp.passes.OptPassImpl`](https://github.com/informalsystems/apalache/blob/unstable/tla-pp/src/main/scala/at/forsyte/apalache/tla/pp/passes/OptPassImpl.scala)."
461727,513153,https://api.github.com/repos/defold/defold/issues/5542,bug,2021-02-08T15:15:17Z,CONTRIBUTOR,https://api.github.com/repos/defold/defold,"Vulkan builds are broken on Windows **Describe the bug (REQUIRED)** I get `lld-link: error: could not open 'libgraphics_vulkan.lib': No such file or directory` when I try to build for x86_64-win32 with extension-vulkan with bob.jar (and the Editor). **To Reproduce (REQUIRED)** Steps to reproduce the behavior: 1. Add extension-vulkan to a new project 2. Enable SPIR-V in game.project 3. Try to build for WIndows 4. See error **Expected behavior (REQUIRED)** It should build. **Defold version (REQUIRED):** - Version 1.2.179, 5209b50cf4bf8e925cb4c32fd0bde6c53fc85a66 **Platforms (REQUIRED):** - Platforms: macOS, Windows - OS: Big Sur, Win 10 **Logs (OPTIONAL):** ``` clang++ -target x86_64-pc-win32-msvc -m64 -g -gcodeview -DDLIB_LOG_DOMAIN=""ENGINE_MAIN"" -DDM_PLATFORM_WINDOWS -DLUA_BYTECODE_ENABLE_64 -D_CRT_SECURE_NO_WARNINGS -D_WINSOCK_DEPRECATED_NO_WARNINGS -D__STDC_LIMIT_MACROS -DWINVER=0x0600 -DWIN32 -DDM_RELEASE -O2 -Wall -Werror=format -fvisibility=hidden -isystem /opt/platformsdk/Win32/MicrosoftVisualStudio2019/VC/Tools/MSVC/14.25.28610//atlmfc/include -isystem /opt/platformsdk/Win32/WindowsKits/10//Include/10.0.18362.0/ucrt -isystem /opt/platformsdk/Win32/WindowsKits/10//Include/10.0.18362.0/winrt -isystem /opt/platformsdk/Win32/WindowsKits/10//Include/10.0.18362.0/um -isystem /opt/platformsdk/Win32/WindowsKits/10//Include/10.0.18362.0/shared -I/var/extender/sdk/5209b50cf4bf8e925cb4c32fd0bde6c53fc85a66/defoldsdk//include -I/var/extender/sdk/5209b50cf4bf8e925cb4c32fd0bde6c53fc85a66/defoldsdk//sdk/include build/main.cpp -c -o build/main_tmp6.o clang++ -target x86_64-pc-win32-msvc -m64 -g -o build/dmengine.exe -O2 -fuse-ld=lld -Wl,/entry:mainCRTStartup -Wl,/safeseh:no -Wl,/subsystem:windows -L/tmp/job3173375792939348246/build -lOpenGL32 -ldelayimp -lUser32 -lshell32 -lXinput9_1_0 -lOpenAL32 -lWS2_32 -liphlpapi -lDbgHelp -lAdvAPI32 -lPsapi -llibgraphics_vulkan.lib -lvulkan-1.lib -llibengine_release.lib -llibengine_service_null.lib -llibprofilerext_null.lib -llibrecord_null.lib -llibphysics_2d.lib -llibrecord_null.lib -lsafearea_5 -ldefos_3 -lVulkan_1 -L/var/extender/sdk/5209b50cf4bf8e925cb4c32fd0bde6c53fc85a66/defoldsdk//lib/x86_64-win32 -L/var/extender/sdk/5209b50cf4bf8e925cb4c32fd0bde6c53fc85a66/defoldsdk//ext/lib/x86_64-win32 -L/opt/platformsdk/Win32/MicrosoftVisualStudio2019/VC/Tools/MSVC/14.25.28610//lib/x64 -L/opt/platformsdk/Win32/MicrosoftVisualStudio2019/VC/Tools/MSVC/14.25.28610//atlmfc/lib/x64 -L/opt/platformsdk/Win32/WindowsKits/10//Lib/10.0.18362.0/ucrt/x64 -L/opt/platformsdk/Win32/WindowsKits/10//Lib/10.0.18362.0/um/x64 -llibmbedtls -llibzip -llibwebviewext -llibfacebookext -llibiapext -llibpushext -llibiacext -llibgameobject -llibddf -llibresource -llibgamesys -llibgraphics -llibBox2D -llibrender -llibscript -llibluajit-5.1 -llibextension -llibhid -llibinput -llibparticle -llibrig -llibdlib -llibdmglfw -llibgui -llibcrashext -llibliveupdate -llibsound -llibcares build/main_tmp6.o build/dmengine.res lld-link: error: could not open 'libgraphics_vulkan.lib': No such file or directory clang-10: error: linker command failed with exit code 1 (use -v to see invocation) ```"
76483,85033,https://api.github.com/repos/ITEAD-Thierry/NextionX/issues/1,enhancement,2021-02-08T21:22:19Z,NONE,https://api.github.com/repos/ITEAD-Thierry/NextionX,Nextion HMI read longed I can't wait to read the next part to this library. Then hopefully with the longed for Read function. So please excuse me for using this issue to send this wish. I very much appreciate your experience and implementation. Regards Fii
536814,596631,https://api.github.com/repos/Uniswap/uniswap-interface/issues/1283,bug,2021-01-24T04:11:10Z,NONE,https://api.github.com/repos/Uniswap/uniswap-interface,No chain id defined **Bug Description** When I confirm a swap an error message pops up stating no chainid defined. **Steps to Reproduce** 1. Go to ...swap token 2. Click on ...enter eth amount click confirm ... **Expected Behavior** Won’t allow swapping of tokens **Additional Context** Happens every time every token 
577955,642249,https://api.github.com/repos/primefaces/primevue/issues/1020,bug,2021-02-24T17:30:47Z,NONE,https://api.github.com/repos/primefaces/primevue,"DataTable error while using stateStorage with date filter First, thank you for the great library. I have a DataTable column with `dataType=""date""` and using default date filter modes. When enabling `stateStorage` on the DataTable I got the following error: ``` Uncaught (in promise) TypeError: filter.getTime is not a function ``` After some digging, I have found that in ""src > components > DataTable.vue"" the `saveState()` is using `JSON.stringify(state)` which will convert date objects to ISO8601 string, Then the `restoreState()` is using `JSON.parse(stateString)` which will keep the date as string and causes error when calling date methods e.g. `getTime()` on it to filter. I made a PR to fix this and will submit it soon."
638103,709175,https://api.github.com/repos/raphaelquintao/QRedshift/issues/32,bug,2021-03-19T13:30:47Z,NONE,https://api.github.com/repos/raphaelquintao/QRedshift,"Fails to start with ""setTimeout is not defined"" Cinnamon 3.8.8 Applet version 1.5.5 Debian 10 ``` QRedshift: Created error t=2021-03-19T15:30:01Z [qredshift@quintao]: setTimeout is not defined [qredshift@quintao]: Failed to evaluate 'main' function on applet: qredshift@quintao/91 trace t=2021-03-19T15:30:01Z <---------------- anonymous/QRedshift/<@/home/yrtimid/.local/share/cinnamon/applets/qredshift@quintao/applet.js:214:13 verifyVersion@/home/yrtimid/.local/share/cinnamon/applets/qredshift@quintao/applet.js:259:21 QRedshift@/home/yrtimid/.local/share/cinnamon/applets/qredshift@quintao/applet.js:212:9 main@/home/yrtimid/.local/share/cinnamon/applets/qredshift@quintao/applet.js:787:12 createApplet@/usr/share/cinnamon/js/ui/appletManager.js:573:18 addAppletToPanels@/usr/share/cinnamon/js/ui/appletManager.js:347:22 onEnabledAppletsChanged@/usr/share/cinnamon/js/ui/appletManager.js:290:9 ----------------> ```"
336593,374157,https://api.github.com/repos/crypto-org-chain/chainlibpy/issues/10,enhancement,2021-04-06T16:36:56Z,NONE,https://api.github.com/repos/crypto-org-chain/chainlibpy,Problem: out of date library Please update the library since the used endpoints are deprecated and some features like staking are missing. 
49814,55429,https://api.github.com/repos/TXST-CS5346-AI/project-one/issues/22,enhancement,2021-02-27T20:08:46Z,CONTRIBUTOR,https://api.github.com/repos/TXST-CS5346-AI/project-one,"Remove IDE specific code https://hownot2code.com/2016/06/04/do-not-use-pragma-warningdefaultx/ Removing `#pragma warning(disable : 4996)` unless it is needed and can be refactored to something like in the above article. Ex: `#pragma warning(push)` `#pragma warning(disable:4996)` `LONG result = regKey.QueryValue(buf, _T(""""), &buf_size);` `#pragma warning(pop)`"
254367,282925,https://api.github.com/repos/goenning/webping.cloud/issues/3,enhancement,2020-11-12T20:31:35Z,OWNER,https://api.github.com/repos/goenning/webping.cloud,Tweet Button add a Tweet Button so people can share what's the region with lowest latency to where they are
492337,547214,https://api.github.com/repos/qupath/qupath/issues/662,bug,2021-01-21T11:02:25Z,CONTRIBUTOR,https://api.github.com/repos/qupath/qupath,"showConfirmDialog method never uses its title parameter ## Bug report **Describe the bug** `showConfirmDialog()` in the `Dialogs` class never uses the `title` parameter, and uses the `text` as a title instead. This results in confirm dialogs showing their `text` in the main content pane as well as in their title. **Expected behavior** The title is used as title and text as main text. **Desktop (please complete the following information):** - OS: All - QuPath Version 0.2.3 **Additional context** The issue is located [here](https://github.com/qupath/qupath/blob/main/qupath-gui-fx/src/main/java/qupath/lib/gui/dialogs/Dialogs.java#L100). There are around 30 calls to this method in other parts of the code. "
562903,625567,https://api.github.com/repos/Pr47/T10/issues/9,bug,2021-01-03T07:42:45Z,MEMBER,https://api.github.com/repos/Pr47/T10,"GcInfo consistency issue The current overall `GcInfo` check looks like: ```rust unsafe fn lifetime_check_l1(value: &'a Value<'a>) -> Result<GcInfoGuard<'a>, TError> { debug_assert!(!value.is_null()); let actual = value.gc_info(); if actual == GcInfo::Owned || actual == GcInfo::SharedWithHost { value.set_gc_info(SharedWithHost); Ok(GcInfoGuard::new(value, actual, actual)) } else { Err(LifetimeError::new(&INTO_REF_LIFETIMES, FFIAction::Share, actual).into()) } } ``` Here the check for `GcInfo` and updating `GcInfo` are separated into two steps, which can be vulnerable. We should eliminate TOCTTOU issue."
360862,401158,https://api.github.com/repos/hicetnunc2000/hicetnunc/issues/265,bug,2021-03-26T13:35:30Z,NONE,https://api.github.com/repos/hicetnunc2000/hicetnunc,"Burned OBJKTs are still listed in profile page I know that this is probably already on the to-do list, but I just wanted to add this as an official issue. It would really be nice if NFTs owned by tz1burnburnburnburnburnburnburjAYjjX would not show up in public views anymore."
22114,24609,https://api.github.com/repos/MarcusUniversee/paperbot/issues/24,bug,2021-01-27T07:32:18Z,OWNER,https://api.github.com/repos/MarcusUniversee/paperbot,add all error messages add error messages to all commands if there are incorrect parameters
289937,322415,https://api.github.com/repos/rovergulf/ngx-slice-kit/issues/151,bug,2021-04-06T22:14:26Z,MEMBER,https://api.github.com/repos/rovergulf/ngx-slice-kit,"nav tabs not working with ngFor directive error: ```console ERROR Error: NG0100: ExpressionChangedAfterItHasBeenCheckedError: Expression has changed after it was checked. Previous value: 'false'. Current value: 'true'.. Find more at https://angular.io/errors/NG0100 at throwErrorIfNoChangesMode (core.js:6744) at bindingUpdated (core.js:12881) at Module.ɵɵproperty (core.js:14681) at TabComponent_Template (tab.component.ts:5) at executeTemplate (core.js:9549) at refreshView (core.js:9418) at refreshComponent (core.js:10584) at refreshChildComponents (core.js:9215) at refreshView (core.js:9468) at refreshEmbeddedViews (core.js:10538) ``` rendered as: <img width=""448"" alt=""Screenshot 2021-04-07 at 01 13 27"" src=""https://user-images.githubusercontent.com/13754654/113784668-7ca6ba00-973e-11eb-8e56-135feba9a417.png""> component.html: ```html <sdk-tab-group> <ng-container *ngFor=""let v of getValues(d)""> <sdk-tab label=""{{getValueTabName(v)}}""> <pre class=""example""> <code [highlight]=""d.values[v]""></code> </pre> </sdk-tab> </ng-container> </sdk-tab-group> ``` "
74018,82306,https://api.github.com/repos/JayCeeCreates/earlygame/issues/11,enhancement,2021-02-28T04:36:09Z,NONE,https://api.github.com/repos/JayCeeCreates/earlygame,"EarlyGameConfig defined in EarlyGameClient, not EarlyGame # help https://pastebin.com/1PaqfhEj [***bruh***](https://github.com/JayCeeCreates/earlygame/blob/6a0a0034df5c5bce23cfd14f1f5dba96038fc891/src/main/java/jayceecreates/earlygame/world/StickTwigGen.java#L26) # Description StickTwigGen.generate reads client-side field EarlyGameClient.CONFIG on Dedicated Server"
442876,492310,https://api.github.com/repos/buddyboss/buddyboss-platform/issues/1078,bug,2020-06-23T11:00:35Z,NONE,https://api.github.com/repos/buddyboss/buddyboss-platform,Sharing Instagram post on activity page throws an error. **Describe the bug** Sharing an Instagram post on the activity page throws an error. I could replicate the issue on our demo site. **To Reproduce** Steps to reproduce the behavior: 1. Go to activity page 2. Share the URL of an Instagram post 3. See error **Expected behavior** It should work without issues. **Screenshots** - https://i.imgur.com/8lRhPbH.jpg **Support ticket links** - https://secure.helpscout.net/conversation/1200460489/78715?folderId=3701247
260359,289564,https://api.github.com/repos/zowe/api-layer/issues/1460,bug,2021-05-14T09:03:44Z,COLLABORATOR,https://api.github.com/repos/zowe/api-layer,"Gateway produces invalid registration **Describe the bug** With Internal port disabled: Gateway service id contains internal port Both secured and unsecured ports are disabled Both secured and unsecured ports do contain default internal port ```json { ""application"": { ""name"": ""GATEWAY"", ""instance"": [ { ""instanceId"": ""localhost:gateway:10017"", ""hostName"": ""localhost"", ""app"": ""GATEWAY"", ""ipAddr"": ""127.0.0.1"", ""status"": ""UP"", ""overriddenStatus"": ""UNKNOWN"", ""port"": { ""$"": 10017, ""@enabled"": ""false"" }, ""securePort"": { ""$"": 10017, ""@enabled"": ""false"" }, ""countryId"": 1, ""dataCenterInfo"": { ""@class"": ""com.netflix.appinfo.InstanceInfo$DefaultDataCenterInfo"", ""name"": ""MyOwn"" }, ""leaseInfo"": { ""renewalIntervalInSecs"": 30, ""durationInSecs"": 90, ""registrationTimestamp"": 1620982823790, ""lastRenewalTimestamp"": 1620982823790, ""evictionTimestamp"": 0, ""serviceUpTimestamp"": 1620982659731 }, ""metadata"": { ""apiml.service.description"": ""API Gateway service to route requests to services registered in the API Mediation Layer and provides an API for mainframe security."", ""apiml.routes.api_v1.gatewayUrl"": ""/api/v1"", ""apiml.catalog.tile.version"": ""1.0.0"", ""management.port"": ""10017"", ""apiml.catalog.tile.description"": ""The API Mediation Layer for z/OS internal API services. The API Mediation Layer provides a single point of access to mainframe REST APIs and offers enterprise cloud-like features such as high-availability, scalability, dynamic API discovery, and documentation."", ""apiml.service.title"": ""API Gateway"", ""apiml.apiInfo.0.apiId"": ""zowe.apiml.gateway"", ""apiml.authentication.sso"": ""true"", ""apiml.apiInfo.0.gatewayUrl"": ""api/v1"", ""apiml.apiInfo.0.documentationUrl"": ""https://zowe.github.io/docs-site/"", ""apiml.catalog.tile.id"": ""apimediationlayer"", ""apiml.routes.api_v1.serviceUrl"": ""/gateway"", ""apiml.apiInfo.0.swaggerUrl"": ""https://localhost:10010/api-doc"", ""apiml.catalog.tile.title"": ""API Mediation Layer API"" }, ""homePageUrl"": ""https://localhost:10010/"", ""statusPageUrl"": ""https://localhost:10010/application/info"", ""healthCheckUrl"": ""https://localhost:10010/application/health"", ""secureHealthCheckUrl"": ""https://localhost:10010/application/health"", ""vipAddress"": ""gateway"", ""secureVipAddress"": ""gateway"", ""isCoordinatingDiscoveryServer"": ""false"", ""lastUpdatedTimestamp"": ""1620982823790"", ""lastDirtyTimestamp"": ""1620982823744"", ""actionType"": ""ADDED"" } ] } } ```"
571754,635384,https://api.github.com/repos/wellenvogel/avnav-ocharts-provider/issues/1,bug,2020-09-10T17:58:35Z,OWNER,https://api.github.com/repos/wellenvogel/avnav-ocharts-provider,Caches are recreated on every start With some chart sets the loading of an existing cache file files with an error like: `INFO-invalid data len 111168 in /home/pi/avnav/data/ocharts/CS_home_pi_avnav_data_ocharts_charts_XXXX-BE_DE_NL-2020-36.avcache at 2825132` A check shows that the PNG at this position really is that long and is correct. Internally there is a limit of 100000 bytes for the len of a png in the cache when reading. This must be enlarged to 256x256x4 Bytes + PNG overhead.
268404,298488,https://api.github.com/repos/bsassoli/milan_culture_map/issues/10,enhancement,2021-04-08T11:36:56Z,COLLABORATOR,https://api.github.com/repos/bsassoli/milan_culture_map,"Centralised constants In this file: https://github.com/bsassoli/milan_culture_map/blob/main/venues/views.py You have a data structure within a view: ``` icons = { 'Museo': { 'icon': 'university', 'prefix': 'fa', 'color': 'cadetblue' }, } ``` It's not common to store structure like this, but rather within a separate, centralised files like `constants.py` or `const.py`. This means you can then do: `from .constants import ICONS ` Then you can use just ICONS in your view. This keeps your view logic cleaner and your data structures easier to reason within. From a personal project: ![Screenshot 2021-04-08 at 12 36 41](https://user-images.githubusercontent.com/3659224/114020081-18334a00-9867-11eb-84cd-7d06f84fa7d2.png) I just import these wherever I need them - a single source of truth and clean view layers. "
13411,14935,https://api.github.com/repos/derekleerock/Succinct/issues/73,enhancement,2021-02-03T08:43:00Z,COLLABORATOR,https://api.github.com/repos/derekleerock/Succinct,"Support finding labels in table view section headers Given a table view `subject` has a section with a header `Section Title`, this returns false. ``` // in table view public func tableView(_ tableView: UITableView, titleForHeaderInSection section: Int) -> String? { return ""Section Title"" } // in test expect(subject.hasLabel(withExactText: ""Section Title"")).toEventually(beTrue()) ``` Although the code does appear to look in the table section header https://github.com/derekleerock/Succinct/blob/master/Succinct/UITableView/UITableView+Evaluations.swift Not sure I'm looking in the right place but couldn't find a check for looking the the table view section headers for a label though https://github.com/derekleerock/Succinct/blob/master/SuccinctTests/UITableViewController/UITableViewController+UILabelSpec.swift Just adding but if it's already supported feel free to close."
65150,72435,https://api.github.com/repos/vanjarosoftware/Vanjaro.Platform/issues/566,bug,2021-01-20T15:47:42Z,COLLABORATOR,https://api.github.com/repos/vanjarosoftware/Vanjaro.Platform,Cookies name issue and add prefix ![image](https://user-images.githubusercontent.com/13765669/105199531-dd255280-5b64-11eb-95df-d619919c8892.png) 
405490,450697,https://api.github.com/repos/Phantom-test/do_not_delete_repo/issues/49,bug,2021-04-12T07:21:12Z,MEMBER,https://api.github.com/repos/Phantom-test/do_not_delete_repo,Test playbook issue Updated body
78032,86763,https://api.github.com/repos/IBM-Blockchain/blockchain-vscode-extension/issues/720,bug,2019-03-14T11:10:41Z,CONTRIBUTOR,https://api.github.com/repos/IBM-Blockchain/blockchain-vscode-extension,"Evaluate Transaction Clears the log panel ## Description When using `Submit Transaction` I see the logs scroll and the result of the transaction at the bottom of the output. However, when I `Evaluate` the same transaction the log panel clears. I can restore the log panel by switching to Blockchain log, then back to Local Fabric log. ## Repeatable Package/Install/Instantiate Fabcar - Evaluate queryCar - log good - Submit queryCar - log good - Evaluate queryCar - **log clears** Same behaviour using the supplied Admin identity, or a newly created Identity ## Your Environment * IBM Blockchain Platform Extension Version: 0.3.2 * Visual Studio Code version: 1.31.0 * Environment name and version (e.g. Node.js v8.12.0, npm v6.4.1): Node v8.12 * Operating System and version: Ubuntu 18.04 "
426613,474215,https://api.github.com/repos/ZbayApp/zbay/issues/128,bug,2020-06-18T20:42:47Z,NONE,https://api.github.com/repos/ZbayApp/zbay,Channel content shakes when there is no scrollbar Version: 1.0.68-dev-test-windows-2 Platform: Windows 10 x64 zcashd: v2.1.2 Steps to reproduce: 1. Set app to window view. It should take full height of the screen. 2. Open existing channel with not enough messages to display scrollbar (or just create new channel and add few messages messages). 3. Shrink the app window by few pixels from the bottom. Content of the channel will start to shake until scrollbar appears or window height resize happens. 
243931,271311,https://api.github.com/repos/microsoft/TypeScript/issues/42923,bug,2021-02-23T09:02:13Z,MEMBER,https://api.github.com/repos/microsoft/TypeScript,"Provide go-to-definition on unresolved shorthand properties ```ts interface Foo { /** * Hallo this is docs */ yadda(): void } let x: Foo = { yadda/**/ }; ``` Imagine that I am typing some code. I realize I don't remember what `yadda` is supposed to look like, so I run go-to-definition on `yadda`. ## Problem Go-to-definition doesn't work, because at this point `yadda` is a shorthand property, so go-to-definition tries to look for a local named `yadda` that doesn't exist. As a workaround, I often end up writing ```ts interface Foo { /** * Hallo this is docs */ yadda(): void } let x: Foo = { yadda: undefined! }; ``` just so I can go-to-definiiton on `yadda`, which really sucks. ## Expected Behavior We should resiliently try to pick up on the original definition and jump there."
163886,182216,https://api.github.com/repos/ACMILabs/media-player/issues/42,bug,2019-10-01T02:19:37Z,CONTRIBUTOR,https://api.github.com/repos/ACMILabs/media-player,Hide taskbar panel on x86 devices - [ ] Remove the small grey panel that appears on the top left when the x86 device boots (on the ACMI logo screen)
93303,103687,https://api.github.com/repos/GraxCode/threadtear/issues/51,bug,2020-11-07T19:45:52Z,NONE,https://api.github.com/repos/GraxCode/threadtear,"cn.name.hashCode() is prone to collisions between obfuscated names **Describe what's not working** The Stringer access deobfuscation code doesn't work properly because of class proxy collisions. I added some debug prints below to find the problem. As you can see `fuck_the_regulations_v320/dC` and `fuck_the_regulations_v320/cb` has the same hashCode() Here's the offending line in the executor: ClassNode proxy = Sandbox.createClassProxy(String.valueOf(cn.name.hashCode())); // can't use real // class name here **Java archive** The java archive I'm trying to deobfuscate is malware hiding as a crack for Jetbrains products. I don't want to attach it, but the sample is: SHA256: e3055d5b636b39d5609b8cfa28da2d8955615985fad53a5c27baac51cadbc698 name: jetbrains-agent.jar **Log / Screenshots** ``` 20:32:29.312 ERROR: !!! fuck_the_regulations_v320/dC cn.name.hashCode(): -1516023385 20:32:29.312 WARN : cn.name: fuck_the_regulations_v320/dC 20:32:29.312 ERROR: !!! fuck_the_regulations_v320/cb cn.name.hashCode(): -1516023385 20:32:29.312 ERROR: Failed load proxy for fuck_the_regulations_v320.cb, java.lang.RuntimeException: class -1516023385 is already defined ``` **Please complete the following information:** - OS: Mac OS X 10.14.6 - Java version: 13.0.1 (Eclipse) "
134569,149588,https://api.github.com/repos/paulevsGitch/BetterEnd/issues/74,bug,2021-01-26T15:02:18Z,NONE,https://api.github.com/repos/paulevsGitch/BetterEnd,"Crash upon clicking in the anvil screen with an item when there are no anvil recipes present Crash log here: https://paste.gg/p/anonymous/f7556b6a1024492b886fabc3898d69d5 Upon examining `AnvilScreenHandlerExtended#be_previousRecipe` ([here](https://github.com/paulevsGitch/BetterEnd/blob/8d56a7ec7efc6432b684f6fbe24b64124bdb6e95/src/main/java/ru/betterend/interfaces/AnvilScreenHandlerExtended.java#L22)), it seems like the method does not check whether the list of recipes (`recipes`) is empty, causing the index value to be erroneously set to -1 and an `ArrayIndexOutOfBoundsException` occurs when trying to use that index to access the recipe list."
629479,699578,https://api.github.com/repos/SanderMertens/flecs/issues/362,bug,2021-03-28T12:10:14Z,CONTRIBUTOR,https://api.github.com/repos/SanderMertens/flecs,"Deleting an entity involved in a pair causes flecs to leave the related entity broken **Describe the bug** Deleting an entity involved in a pair causes flecs to leave the related entity broken **To Reproduce** This is adapted from the manual - ```c++ auto world = flecs::world(); auto HasSibling = flecs::entity(world); auto Jane = flecs::entity(world, ""Jane""); auto Jeff = flecs::entity(world, ""Jeff""); Jane.add(HasSibling, Jeff); Jeff.add(HasSibling, Jane); Jane.each(HasSibling.id(), [](flecs::entity e) { printf(""Jane has a sibling named %s\n"", e.name().c_str()); }); Jeff.destruct(); Jane.each(HasSibling.id(), [](flecs::entity e) { printf(""Jane has a sibling named %s\n"", e.name().c_str()); }); ``` **Expected behavior** This should print `Jane has a sibling named Jeff` once. Instead it prints it once and asserts on the second print `err : assert(ecs_is_valid(world, entity)) ..\..\..\extern\flecs\src\entity.c:2074: invalid parameters` Also once Jeff has been deleted, it is also impossible to remove the HasSibling from Jane as the pair id is invalid and asserts if you try to. "
476316,529355,https://api.github.com/repos/timothycrosley/streamdeck-ui/issues/85,bug,2020-12-27T01:32:09Z,NONE,https://api.github.com/repos/timothycrosley/streamdeck-ui,Unicode not rendering I think this would be a valuable feature. Still new to this application.
141238,156990,https://api.github.com/repos/NCEAS/metacat/issues/1281,bug,2018-09-12T03:37:13Z,MEMBER,https://api.github.com/repos/NCEAS/metacat,"Investigate incorrect byte-for-byte storage of content After doing some work on the CN replication subsystem, I noticed that there are a number of replicas on Metacat-based Member Nodes in DataONE that have been audited and the status has been set to `INVALIDATED`: ```sql SELECT sys.guid, sys.authoritive_member_node AS source_node, sms.member_node as target_node, sms.status FROM systemmetadata sys INNER JOIN smreplicationstatus sms ON sys.guid = sms.guid WHERE sms.status = 'INVALIDATED' AND sms.member_node != sys.authoritive_member_node AND sms.member_node != 'urn:node:CN' ORDER BY sys.authoritive_member_node; ``` Results: [invalidated-pids.txt](https://github.com/NCEAS/metacat/files/2373447/invalidated-pids.txt) A quick `diff` of one of these [EML](https://knb.ecoinformatics.org/knb/d1/mn/v2/object/doi:10.5063/AA/knb.231.1) objects shows that there is an extra line end character on a single line compared to the source original: ```diff --- knb.xml 2018-09-11 21:01:58.000000000 -0600 +++ mn-ucsb-1.xml 2018-09-11 21:01:09.000000000 -0600 @@ -132,7 +132,7 @@ <para>Any bird species seen on, or flying over, KUFS areas has been included in this list</para> </section></description></methodStep> <sampling><studyExtent><description> -<para>The avifauna of KUFS is composed of species typical of the eastern deciduous forest and the prairie-forest ecotone, including early-successional shrublands and open lands in former agricultural areas. Several Great Plains specialties such as Harris’s Sparrow, Dickcissel, and Bell’s Vireo are commonly found on the northern tracts of KUFS (Nelson Environmental Study Area, Rockefeller Experimental Tract, and Fitch Natural History Reservation). KUFS tracts in the Baldwin Woods have essentially one habitat type (mature eastern deciduous forest) and this single habitat produces a specialized avifauna with several species that have a limited range in Kansas (e.g., Pileated Woodpecker, Acadian Flycatcher, Cerulean Warbler, and Worm-eating Warbler). The area’s birdlife represents primarily an eastern fauna, but is situated at or near the western range limit for many species. This geographic position affords many interesting opportunities for ecological research. +<para>The avifauna of KUFS is composed of species typical of the eastern deciduous forest and the prairie-forest ecotone, including early-successional shrublands and open lands in former agricultural areas. Several Great Plains specialties such as Harris?s Sparrow, Dickcissel, and Bell?s Vireo are commonly found on the northern tracts of KUFS (Nelson Environmental Study Area, Rockefeller Experimental Tract, and Fitch Natural History Reservation). KUFS tracts in the Baldwin Woods have essentially one habitat type (mature eastern deciduous forest) and this single habitat produces a specialized avifauna with several species that have a limited range in Kansas (e.g., Pileated Woodpecker, Acadian Flycatcher, Cerulean Warbler, and Worm-eating Warbler). The area?s birdlife represents primarily an eastern fauna, but is situated at or near the western range limit for many species. This geographic position affords many interesting opportunities for ecological research. </para> </description></studyExtent> ``` If this is caused by bytes being transferred during `MNRead.getReplica()` from the source node, then our subsequent logic for comparing checksums is broken. But note that the CN copy of this same file also different (with the same single line ending character difference). So, is Metacat injecting a line ending in certain circumstances when it shouldn't? We need to track this down since it may affect more than just XML content, but I haven't looked closely enough."
720625,800891,https://api.github.com/repos/ossia/score-docs/issues/4,enhancement,2021-02-26T11:56:36Z,MEMBER,https://api.github.com/repos/ossia/score-docs,"Indicate keyboard shortcut for putting things in parallel / in series If dropping multiple sound files, midi files, etc... it's possible to chose whether they will be played in parallel or in series, by pressing shift key: ![shift](https://user-images.githubusercontent.com/2772730/109297270-073bf580-7832-11eb-9710-83072c9da5f8.gif) "
700212,778225,https://api.github.com/repos/odin-lang/Odin/issues/689,enhancement,2020-07-08T22:27:07Z,CONTRIBUTOR,https://api.github.com/repos/odin-lang/Odin,"comma-ok for pointer-to-union-value Currently when pulling out a union value you can do: ``` val := u.(int); val, ok := u.(int); ``` but for pointers you can only do: ``` val := &u.(int); ``` which results in a lot of code that looks like this: ``` if _, ok := u.(int) { val := &u.(int); } ``` It would be nice if we could do: ``` val, ok := &u.(int); ``` I believe the same is true for getting map pointers as well but I am not certain."
718858,798938,https://api.github.com/repos/hpc/charliecloud/issues/442,question,2019-05-10T16:08:57Z,NONE,https://api.github.com/repos/hpc/charliecloud,"How to use docker environment variables? I see from #224 that the `ch-docker2tar` command will now save the environment information into /etc/environment. However, I don't see how to properly use it. If I do an `ch-run --unset-env=""*"" --set-env=""/var/tmp/$image/etc/environment"" ... /var/tmp/$image -- bash` then my PATH has quotes around it, eg: > ""/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games"" Instead of: > /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games If I don't do anything my outside environment variables are still set. How am I supposed to invoke this?"
524776,583244,https://api.github.com/repos/dsc-nsut/DSC-NSUT-App/issues/1,enhancement,2021-03-08T11:56:26Z,COLLABORATOR,https://api.github.com/repos/dsc-nsut/DSC-NSUT-App,"MVVM setup for blogs Tasks: 1. Create a model data class for blogs. 2. Create a blog repository class for fetching and sending data to Firebase. Use pagination for fetching blogs. The content of a blog will be in HTML, so that styling can be applied. 3. Create a ViewModel class which will act data source for the UI. _Note: Work only on the data source in this issue. Extracting data into UI will be handled in a different issue._"
593793,659926,https://api.github.com/repos/CarnegieLearningWeb/educational-experiment-service/issues/135,bug,2021-04-07T18:24:12Z,CONTRIBUTOR,https://api.github.com/repos/CarnegieLearningWeb/educational-experiment-service,"Experiment with group consistency rule cannot be set to enrolling The experiment defined below cannot transition into the enrolling state. Using the console, it looks as if the call to /api/experiments/state never responds the POST request. The key difference between this and other working experiments is the consistencyRule being group rather than individual. ```{ ""createdAt"": ""2021-02-03T15:06:19.455Z"", ""updatedAt"": ""2021-02-04T14:15:03.614Z"", ""versionNumber"": 7, ""id"": ""06386eea-cce8-4694-a8c7-a88e630b4643"", ""name"": ""AA3 - Geometry"", ""description"": ""Module: Connecting Geometric and Algebraic Descriptions Unit: Volume"", ""context"": [ ""assign-prog"" ], ""state"": ""inactive"", ""startDate"": null, ""startOn"": null, ""endDate"": null, ""consistencyRule"": ""group"", ""assignmentUnit"": ""group"", ""postExperimentRule"": ""assign"", ""enrollmentCompleteCondition"": { ""userCount"": 10, ""groupCount"": 100 }, ""endOn"": null, ""revertTo"": null, ""tags"": [ ""aa"" ], ""group"": ""class"", ""conditions"": [ { ""createdAt"": ""2021-02-03T15:06:19.455Z"", ""updatedAt"": ""2021-02-03T15:06:19.455Z"", ""versionNumber"": 1, ""id"": ""7199d993-c018-4437-9c86-c65f11aed8b5"", ""twoCharacterId"": ""QQ"", ""name"": """", ""description"": ""Second Condition"", ""conditionCode"": ""variant"", ""assignmentWeight"": 50 }, { ""createdAt"": ""2021-02-03T15:06:19.455Z"", ""updatedAt"": ""2021-02-03T15:06:19.455Z"", ""versionNumber"": 1, ""id"": ""e8545d7f-cb8c-48de-8e72-8867b5226781"", ""twoCharacterId"": ""1R"", ""name"": """", ""description"": ""First Condition"", ""conditionCode"": ""control"", ""assignmentWeight"": 50 } ], ""partitions"": [ { ""createdAt"": ""2021-02-04T14:15:03.614Z"", ""updatedAt"": ""2021-02-04T14:15:03.614Z"", ""versionNumber"": 1, ""id"": ""volume_surface_area_cone_vol_SelectSection"", ""twoCharacterId"": ""IP"", ""expPoint"": ""SelectSection"", ""expId"": ""volume_surface_area_cone_vol"", ""description"": """" }, { ""createdAt"": ""2021-02-04T14:15:03.614Z"", ""updatedAt"": ""2021-02-04T14:15:03.614Z"", ""versionNumber"": 1, ""id"": ""volume_surface_area_sphere_vol_SelectSection"", ""twoCharacterId"": ""0H"", ""expPoint"": ""SelectSection"", ""expId"": ""volume_surface_area_sphere_vol"", ""description"": """" }```"
554431,616164,https://api.github.com/repos/amplitude/unity-plugin/issues/65,question,2021-03-22T12:26:43Z,NONE,https://api.github.com/repos/amplitude/unity-plugin,"IDFA is null despite accepting prompt Unity: 2018.4.16 - 2019.4.16 Amplitude SDK: 2.1.0 Platform: Android & iOS Hi! I'm testing idfa behaviour, to receive or not receive it in amplitude events based on user answer in the Tracking prompt. Despite of allowing trackign amplitude is sending null as idfa value ![image](https://user-images.githubusercontent.com/4130008/111989525-a7fb9900-8af0-11eb-989f-de3c2051d11e.png) Is there any consideration to have? Am I missing something? Thanks EDIT: We are not using Amplitude custom solution from [this page](https://developers.amplitude.com/docs/unity-ios-idfa-and-gps-setup). We have our own implementation to prompt the tracking permission I leave some other questions Why there is no method like setIdfa(string) How should I call it if I have another implementation of how I use the prompt? What is the instance name I should pass to setIdfaBlock? And seems not to work the CUstomIDFA.m ![image](https://user-images.githubusercontent.com/4130008/111996209-89010500-8af8-11eb-999a-9bba34fd5d97.png) "
678988,754609,https://api.github.com/repos/Nexus-Mods/web-issues/issues/1306,bug,2021-02-21T17:39:10Z,NONE,https://api.github.com/repos/Nexus-Mods/web-issues,"Mod Page Tabs - Mobile site Mobile site, can't load images/posts/files tabs on mod pages. Can only access description"
416550,463016,https://api.github.com/repos/vigneshshettyin/Flask-Generate-Certificate/issues/105,enhancement,2021-03-26T04:10:37Z,OWNER,https://api.github.com/repos/vigneshshettyin/Flask-Generate-Certificate,Reset Password ### Is your feature request related to a problem? Please describe. The present reset password system is not effective it would directly send a newly generated password to the user via email. ### Describe the solution you'd like Generate a link and email it to the user such that using it user can enter his new password. That link will only be valid for some minutes or hours for security purposes. ### Describe alternatives you've considered A clear and concise description of any alternative solutions or features you've considered. ### Describe how this feature will be useful to our readers. A clear and concise description of how this feature will be useful for our other readers. ### Which Program are you part of? <!-- Example how to mark a checkbox:- - [x] Part of this program. --> - [x] GSSOC21 - [] Any other ### Additional context ![Screenshot 2021-03-26 093617](https://user-images.githubusercontent.com/77713888/112575672-c32f1700-8e16-11eb-843d-e49819c6b4c6.png) 
453706,504248,https://api.github.com/repos/OpenSlides/openslides-autoupdate-service/issues/211,bug,2021-05-17T09:36:11Z,MEMBER,https://api.github.com/repos/OpenSlides/openslides-autoupdate-service,"Projection error, maybe related to CLOS When I project a user on both projectors of the example data, I get ``` Internal Error: get first time restricted data: get values for keys `[meeting/1/name meeting/1/start_time meeting/1/end_time meeting/1/id meeting/1/projector_ids meeting/1/description projector/2/header_background_color projector/2/scroll projector/1/current_projection_ids projector/2/current_projection_ids projector/2/show_title projector/2/name projector/1/used_as_reference_projector_meeting_id projector/2/used_as_reference_projector_meeting_id projector/2/show_clock projector/1/header_font_color projector/2/background_color projector/1/aspect_ratio_numerator projector/1/show_logo projector/1/header_h1_color projector/1/chyron_font_color projector/1/show_header_footer projector/2/color projector/1/width projector/1/scale projector/1/name projector/1/aspect_ratio_denominator projector/1/id projector/2/id projector/2/scale projector/2/aspect_ratio_numerator projector/2/header_h1_color projector/2/header_font_color projector/1/background_color projector/1/scroll projector/1/chyron_background_color projector/2/show_logo projector/2/aspect_ratio_denominator projector/2/chyron_background_color projector/1/color projector/1/show_title projector/2/chyron_font_color projector/2/show_header_footer projector/2/width projector/1/show_clock projector/1/header_background_color projection/3/id projection/5/weight projection/6/content projection/6/id projection/6/stable projection/6/content_object_id projection/3/content projection/3/stable projection/5/content projection/6/type projection/6/weight projection/3/content_object_id projection/5/content_object_id projection/5/type projection/3/type projection/5/id projection/5/stable projection/3/options projection/3/weight projection/6/options projection/5/options meeting/1/is_hidden meeting/1/running user/2/voted_ids user/2/id meeting/1/weight meeting/1/default_password user/2/comment user/2/running user/2/tag_ids meeting/1/recommendation_id meeting/1/is_physical_person user/2/is_physical_person user/2/votesvalid meeting/1/default_poll_description meeting/1/global_abstain meeting/1/is_present_in_meeting_ids user/2/global_yes user/2/entitled_group_ids user/2/pollmethod meeting/1/votesinvalid meeting/1/username meeting/1/comment_ids meeting/1/content_object_id meeting/1/level user/2/global_abstain user/2/default_number user/2/number user/2/is_present_in_meeting_ids user/2/countdown_time user/2/item_number meeting/1/structure_level_$ meeting/1/agenda_item_id user/2/comment_ids user/2/duration user/2/default_password meeting/1/poll_ids meeting/1/votesvalid meeting/1/category_id meeting/1/global_no meeting/1/email meeting/1/message user/2/filesize user/2/last_name user/2/child_ids meeting/1/about_me meeting/1/open_posts meeting/1/majority_method user/2/phase meeting/1/child_ids meeting/1/voted_ids user/2/vote_weight_$ user/2/sequential_number meeting/1/comment meeting/1/speaker_ids meeting/1/min_votes_amount user/2/is_hidden meeting/1/phase meeting/1/default_structure_level user/2/max_votes_amount meeting/1/mimetype user/2/default_structure_level user/2/majority_method user/2/candidate_ids meeting/1/state_extension meeting/1/global_option_id meeting/1/entitled_group_ids meeting/1/tag_ids meeting/1/parent_id meeting/1/description meeting/1/block_id user/2/title user/2/modified_final_version meeting/1/text meeting/1/option_ids meeting/1/recommendation_extension meeting/1/duration user/2/message user/2/internal meeting/1/closed meeting/1/is_directory user/2/speaker_ids user/2/global_option_id meeting/1/title meeting/1/max_votes_amount user/2/votesinvalid user/2/amendment_paragraph_$ meeting/1/state user/2/meeting_id meeting/1/filesize meeting/1/is_internal user/2/default_time user/2/first_name user/2/category_id user/2/is_directory user/2/closed user/2/text user/2/lead_motion_id user/2/structure_level_$ user/2/default_poll_description user/2/recommendation_id user/2/is_internal meeting/1/lead_motion_id user/2/description user/2/number_poll_candidates user/2/level user/2/global_no user/2/recommendation_extension meeting/1/item_number meeting/1/votescast meeting/1/number_poll_candidates meeting/1/global_yes user/2/reason user/2/number_$ user/2/weight meeting/1/personal_note_ids meeting/1/create_timestamp user/2/last_email_send user/2/gender meeting/1/default_vote_weight user/2/email user/2/default_vote_weight user/2/create_timestamp user/2/comment_$ meeting/1/amendment_paragraph_$ meeting/1/internal meeting/1/last_email_send meeting/1/default_number user/2/min_votes_amount user/2/poll_ids user/2/state meeting/1/pollmethod meeting/1/gender meeting/1/reason meeting/1/sequential_number meeting/1/meeting_id meeting/1/onehundred_percent_base user/2/parent_id meeting/1/candidate_ids meeting/1/number_$ meeting/1/countdown_time meeting/1/modified_final_version user/2/is_active user/2/personal_note_ids user/2/option_ids user/2/block_id user/2/onehundred_percent_base meeting/1/vote_weight_$ meeting/1/default_time user/2/mimetype meeting/1/id meeting/1/is_active meeting/1/number user/2/type meeting/1/type meeting/1/has_inherited_access_groups user/2/open_posts meeting/1/first_name meeting/1/comment_$ meeting/1/last_name user/2/votescast user/2/has_inherited_access_groups user/2/content_object_id user/2/about_me user/2/username user/2/state_extension user/2/agenda_item_id user/2/number_$1 user/2/structure_level_$1 user/2/comment_$1 user/2/vote_weight_$1]` from datastore: getOrSet for keys `[meeting/1/name meeting/1/start_time meeting/1/end_time meeting/1/id meeting/1/projector_ids meeting/1/description projector/2/header_background_color projector/2/scroll projector/1/current_projection_ids projector/2/current_projection_ids projector/2/show_title projector/2/name projector/1/used_as_reference_projector_meeting_id projector/2/used_as_reference_projector_meeting_id projector/2/show_clock projector/1/header_font_color projector/2/background_color projector/1/aspect_ratio_numerator projector/1/show_logo projector/1/header_h1_color projector/1/chyron_font_color projector/1/show_header_footer projector/2/color projector/1/width projector/1/scale projector/1/name projector/1/aspect_ratio_denominator projector/1/id projector/2/id projector/2/scale projector/2/aspect_ratio_numerator projector/2/header_h1_color projector/2/header_font_color projector/1/background_color projector/1/scroll projector/1/chyron_background_color projector/2/show_logo projector/2/aspect_ratio_denominator projector/2/chyron_background_color projector/1/color projector/1/show_title projector/2/chyron_font_color projector/2/show_header_footer projector/2/width projector/1/show_clock projector/1/header_background_color projection/3/id projection/5/weight projection/6/content projection/6/id projection/6/stable projection/6/content_object_id projection/3/content projection/3/stable projection/5/content projection/6/type projection/6/weight projection/3/content_object_id projection/5/content_object_id projection/5/type projection/3/type projection/5/id projection/5/stable projection/3/options projection/3/weight projection/6/options projection/5/options meeting/1/is_hidden meeting/1/running user/2/voted_ids user/2/id meeting/1/weight meeting/1/default_password user/2/comment user/2/running user/2/tag_ids meeting/1/recommendation_id meeting/1/is_physical_person user/2/is_physical_person user/2/votesvalid meeting/1/default_poll_description meeting/1/global_abstain meeting/1/is_present_in_meeting_ids user/2/global_yes user/2/entitled_group_ids user/2/pollmethod meeting/1/votesinvalid meeting/1/username meeting/1/comment_ids meeting/1/content_object_id meeting/1/level user/2/global_abstain user/2/default_number user/2/number user/2/is_present_in_meeting_ids user/2/countdown_time user/2/item_number meeting/1/structure_level_$ meeting/1/agenda_item_id user/2/comment_ids user/2/duration user/2/default_password meeting/1/poll_ids meeting/1/votesvalid meeting/1/category_id meeting/1/global_no meeting/1/email meeting/1/message user/2/filesize user/2/last_name user/2/child_ids meeting/1/about_me meeting/1/open_posts meeting/1/majority_method user/2/phase meeting/1/child_ids meeting/1/voted_ids user/2/vote_weight_$ user/2/sequential_number meeting/1/comment meeting/1/speaker_ids meeting/1/min_votes_amount user/2/is_hidden meeting/1/phase meeting/1/default_structure_level user/2/max_votes_amount meeting/1/mimetype user/2/default_structure_level user/2/majority_method user/2/candidate_ids meeting/1/state_extension meeting/1/global_option_id meeting/1/entitled_group_ids meeting/1/tag_ids meeting/1/parent_id meeting/1/description meeting/1/block_id user/2/title user/2/modified_final_version meeting/1/text meeting/1/option_ids meeting/1/recommendation_extension meeting/1/duration user/2/message user/2/internal meeting/1/closed meeting/1/is_directory user/2/speaker_ids user/2/global_option_id meeting/1/title meeting/1/max_votes_amount user/2/votesinvalid user/2/amendment_paragraph_$ meeting/1/state user/2/meeting_id meeting/1/filesize meeting/1/is_internal user/2/default_time user/2/first_name user/2/category_id user/2/is_directory user/2/closed user/2/text user/2/lead_motion_id user/2/structure_level_$ user/2/default_poll_description user/2/recommendation_id user/2/is_internal meeting/1/lead_motion_id user/2/description user/2/number_poll_candidates user/2/level user/2/global_no user/2/recommendation_extension meeting/1/item_number meeting/1/votescast meeting/1/number_poll_candidates meeting/1/global_yes user/2/reason user/2/number_$ user/2/weight meeting/1/personal_note_ids meeting/1/create_timestamp user/2/last_email_send user/2/gender meeting/1/default_vote_weight user/2/email user/2/default_vote_weight user/2/create_timestamp user/2/comment_$ meeting/1/amendment_paragraph_$ meeting/1/internal meeting/1/last_email_send meeting/1/default_number user/2/min_votes_amount user/2/poll_ids user/2/state meeting/1/pollmethod meeting/1/gender meeting/1/reason meeting/1/sequential_number meeting/1/meeting_id meeting/1/onehundred_percent_base user/2/parent_id meeting/1/candidate_ids meeting/1/number_$ meeting/1/countdown_time meeting/1/modified_final_version user/2/is_active user/2/personal_note_ids user/2/option_ids user/2/block_id user/2/onehundred_percent_base meeting/1/vote_weight_$ meeting/1/default_time user/2/mimetype meeting/1/id meeting/1/is_active meeting/1/number user/2/type meeting/1/type meeting/1/has_inherited_access_groups user/2/open_posts meeting/1/first_name meeting/1/comment_$ meeting/1/last_name user/2/votescast user/2/has_inherited_access_groups user/2/content_object_id user/2/about_me user/2/username user/2/state_extension user/2/agenda_item_id user/2/number_$1 user/2/structure_level_$1 user/2/comment_$1 user/2/vote_weight_$1]`: fetching key: fetching missing keys: calculating key projection/3/content: calculating slide: fetching user/2/list_of_speakers_id: user/2/list_of_speakers_id does not exist. ``` I suspect the CLOS slide to see an update of the first projector, where a user is projected, but a user does not have a `list_of_speakers_id`. This must be catched."
161652,179727,https://api.github.com/repos/RehanSaeed/Serilog.Exceptions/issues/300,enhancement,2021-02-28T14:01:03Z,NONE,https://api.github.com/repos/RehanSaeed/Serilog.Exceptions,"[Docs] Destructurer via json I have all my config in json. Does anyone know how to use the destructurer via json? For example, for [`Serilog.Exceptions.EntityFrameworkCore`](https://github.com/RehanSaeed/Serilog.Exceptions#serilogexceptionsentityframeworkcore): ````cs .Enrich.WithExceptionDetails( new DestructuringOptionsBuilder() .WithDefaultDestructurers() .WithDestructurers(new[] { new DbUpdateExceptionDestructurer() }) ) ```` How is that represented in the `appsettings.json`? It would also be useful to add that to the docs in the corresponding section."
74936,83318,https://api.github.com/repos/PaulHancock/Aegean/issues/139,bug,2020-12-08T12:54:41Z,NONE,https://api.github.com/repos/PaulHancock/Aegean,"Ubuntu 18.04 anaconda python 3.7.3 issues ? I have created a virtual environment using anaconda python 3.7.3 on a system running Ubuntu 18.04. I have installed the stable aegeantools using ""pip install AegeanTools"" which seems to complete sucessfully. A colleague then attempts to use the installation with MEERKAT-GPS data and encounters problems (below). It has been suggested that the problem lies with aegean version issues and that reverting to aegeantools 2.0.2 might work 2) For AEGEAN, the problem seems to be to do with the WCS - the program starts but then quickly fails with a message: ""WCS does not have longitude type of 'RA', therefore (ra, dec) data can not be returned"" Have you any thoughts on this ? Thanks and Best Wishes David"
529835,588892,https://api.github.com/repos/pxblue/angular-component-library/issues/203,bug,2021-01-07T15:10:10Z,CONTRIBUTOR,https://api.github.com/repos/pxblue/angular-component-library,DrawerSubheader api hideContentOnCollapse description is wrong #### Describe the bug The description in the docs api table for DrawerSubheader says 'Hide footer content when closed'. #### What is the expected behavior? The description in the docs api table for DrawerSubheader should say 'Hide subheader content when closed'. #### What are the steps to reproduce? 1. Go to docs and look at the api table for DrawerSubheader 2. Observe description for hideContentOnCollapse #### Screenshots or links to minimum reproduction example ![Screen Shot 2021-01-07 at 7 20 43 AM](https://user-images.githubusercontent.com/13989985/103908167-3060c500-50d0-11eb-81c4-44bb0832d08d.png) 
457635,508627,https://api.github.com/repos/openzim/zim-tools/issues/226,question,2021-02-23T15:12:06Z,CONTRIBUTOR,https://api.github.com/repos/openzim/zim-tools,"zimdump: proper handling of _exceptions When it is not possible to dump article to `A/Foo`, zimdump outputs file to `_exceptions/A%2fFoo` instead. This makes dump directory partially broken, as one can't expose it over HTTP due to errors described in https://github.com/ipfs/distributed-wikipedia-mirror/issues/61#issuecomment-784213485 I believe zimdump could handle exceptions like this more gracefully by implementing additional error handling, making the output directory useful without the need for additional processing. ## Proposed exception handling The idea here is to resolve conflict between File and Directory having the same name by leveraging the fact that the directory will load article from `index.html` when present. ### When exception is for name without `/` like `A/Foo` Only one article can exist under `A/Foo`, so if we are unable to write it, `A/Foo` is a directory created by dumping `A/Foo/Bar`. Resolving exception for `A/Foo` is easy: - When exception occurs for a file without `/` in name, simply output the content of `Foo` article to `A/Foo/index.html` ### When exception is for name with `/` like `A/Foo/Bar` Dumping article with one or more `/` in name means a directory structure needs to be created. In this case, an exception occurs when the target name is already taken by either a file or a directory, so we have two ways of resolving this. In broad strokes, resolving exception for `A/Foo/Bar` could work like this (each level needs to be checked, from left to right): 1. When exception occurs, check if `A/Foo` is a directory or a file (or missing, if checking deeper levels) - IF `A/Foo` is a directory, then nothing to fix at this level, repeat (1) with next level (`A/Foo/Bar`) - IF `A/Foo` is a file, then we need to replace it with `A/File/index.html` to enable creation of subarticles - rename it to `A/Foo.tmp` - create directory `A/Foo` - move `A/Foo.tmp` to `A/Foo/index.html` - continue from (1) with next level (`A/Foo/Bar`) - IF `A/Foo` is missing, just write it ----- I believe this should be fixed in `zimdump`, because right now a lot of articles fail to load due to being in `_exceptions` instead of the correct path. Hopefully this does not add too much overhead to `zimdump` – it for sure is way easier to fix it here than in userland scripts later, especially for English wikipedia with tens of milions of articles. "
169646,188640,https://api.github.com/repos/vanjarosoftware/Vanjaro.Platform/issues/647,bug,2021-02-01T05:31:44Z,COLLABORATOR,https://api.github.com/repos/vanjarosoftware/Vanjaro.Platform,Size and text both open in styling ![image (35)](https://user-images.githubusercontent.com/62750280/106418647-dbb92b80-647c-11eb-83a2-56e08b22700e.png) 
561124,623593,https://api.github.com/repos/aecreations/panicbutton/issues/60,bug,2020-09-23T04:42:34Z,OWNER,https://api.github.com/repos/aecreations/panicbutton,"Pinned tabs no longer pinned after restoring browser session Panic Button 4.3 As reported in an Mozilla Add-on review: > After new update it's worse, than before... Now after unhide, addon unpin all pined pages..."
8523,9505,https://api.github.com/repos/purnima143/Kurakoo/issues/219,bug,2021-04-18T15:15:17Z,COLLABORATOR,https://api.github.com/repos/purnima143/Kurakoo,"testing bot ## **Describe the bug** - A clear and concise description of what the bug is. ## **Possible solution** - Describe the solution you thought of. ## **Screenshots** - If applicable, add screenshots to help explain your problem. ###### Do you want to work on this issue - [Yes/No] "
75032,83426,https://api.github.com/repos/stancl/tenancy/issues/613,bug,2021-03-10T09:29:14Z,NONE,https://api.github.com/repos/stancl/tenancy,"Tenant migrations are applied on central DB #### Describe the bug I have a multi-database tenancy installation, but when executing a `php artisan tenants:migrate` command, all migrations are being applied on central DB instead. This unexpected behaviour started happening after I transferred (copy-pasted) my code to another physical machine. I didn't do any changes in my code after that. On an old machine, all migrations were being applied on proper databases. I cleared all app caches, but it did no impact on the situation. I suppose this may not be a bug, but rather an issue in a configuration. Where should I look to fix that? #### Steps to reproduce - Set up a new project; - Install `stancl/tenancy` package; - Set up a multi-database tenancy app; - Move code to another machine by `ctrl+c`-ing source to another computer; - Run app and tenant migrations; #### Expected behavior Tenant migrations should apply on tenant databases, not central one. #### Your setup - Laravel version: 8.26.1 - stancl/tenancy version: 3.4.1 "
690545,767466,https://api.github.com/repos/hukaixuan19970627/YOLOv5_DOTA_OBB/issues/1,question,2021-03-18T09:09:51Z,NONE,https://api.github.com/repos/hukaixuan19970627/YOLOv5_DOTA_OBB,请问你的标签格式是什么样的？可否给截图出来 ## ❔Question ## Additional context 
85224,94748,https://api.github.com/repos/JuriBurakov/TrafoMultiBank/issues/28,bug,2021-01-16T19:12:20Z,OWNER,https://api.github.com/repos/JuriBurakov/TrafoMultiBank,":sparkles: **Welcome to GitHub Projects** :sparkles: We're so excited that you've decided to create a new project! Now that you're here, let's make sure you know how to get the most out of GitHub Projects. - [x] Create a new project - [x] Give your project a name - [x] Press the <kbd>?</kbd> key to see available keyboard shortcuts - [x] Add a new column - [x] Drag and drop this card to the new column - [x] Search for and add issues or PRs to your project - [x] Manage automation on columns - [x] [Archive a card](https://docs.github.com/articles/archiving-cards-on-a-project-board/) or archive all cards in a column"
302184,335986,https://api.github.com/repos/sdslabs/Rootex/issues/66,enhancement,2020-02-26T21:40:20Z,MEMBER,https://api.github.com/repos/sdslabs/Rootex,Add support for rendering animated models Our designers are going to provide us with animated models and we should be ready to deploy them directly into the game when we get them
306995,341336,https://api.github.com/repos/exelban/stats/issues/191,enhancement,2020-11-25T10:34:27Z,NONE,https://api.github.com/repos/exelban/stats,"More GPU info THANK YOU for making this wonderfull app! this is the only app that show my gpu (rx560) temp on my hackintosh (even istat cant) 1) i ussually monitor gpu stats with terminal. i wonder if you planning to add this to the app ![Screen Shot 2020-11-25 at 5 25 57 PM](https://user-images.githubusercontent.com/7521167/100215226-54fb4600-2f43-11eb-8b67-9de9d77e5697.png) `while sleep 1; do clear;ioreg -l |grep \""PerformanceStatistics\"" | cut -d '{' -f 2 | tr '|' ',' | tr -d '}' | tr ',' '\n'|grep 'Temp\|Fan\|Clock'; done` 2) sensors popup is too big, and cant fully visible with my 720 pixel height tv. maybe temp and power should be separated ? thanks again!"
365915,406769,https://api.github.com/repos/scp-fs2open/fs2open.github.com/issues/2920,bug,2020-11-22T21:50:10Z,CONTRIBUTOR,https://api.github.com/repos/scp-fs2open/fs2open.github.com,"Beam lighting not rendering correctly upon penetrating target When a beam hits a target and starts penetrating it, it stops casting light on the target ship. Tested only with direct-fire beams, in the Icarus cutscene on 2020-10-01 nightly build. Here's a couple screenshots of this happening: Before penetrating: https://cdn.discordapp.com/attachments/255067124836335616/780163673611436092/screen0005.png After penetrating: https://cdn.discordapp.com/attachments/255067124836335616/780163703113777222/screen0006.png This might be not only related to penetrating the target but to the target becoming destroyed and entering its deathroll during the salvo."
459975,511206,https://api.github.com/repos/Unbabel/OpenKiwi/issues/95,bug,2021-03-16T14:30:10Z,NONE,https://api.github.com/repos/Unbabel/OpenKiwi,"some problems about data without alignments i chage the data.yaml, just delete the alignments of it. and i get the following error. KeyError: 'alignments' anyone can tell me if i dont have alignments, how to train it? thank you. "
599501,666229,https://api.github.com/repos/mat1jaczyyy/apollo-studio/issues/422,bug,2021-01-26T13:28:53Z,NONE,https://api.github.com/repos/mat1jaczyyy/apollo-studio,Duplicating a Track doesn't properly initialize Fade device ### Description duplicating a track and changing the input to apollo connector crashes the application ### To Reproduce change the input to apollo connector after duplicating the track ### Your setup Apollo Version: Version 1.8.3 Operating System: Microsoft Windows 10 ### Additional context [Crash-1611664668.zip](https://github.com/mat1jaczyyy/apollo-studio/files/5873503/Crash-1611664668.zip) [Crash-1611664800.zip](https://github.com/mat1jaczyyy/apollo-studio/files/5873505/Crash-1611664800.zip) 
297616,330937,https://api.github.com/repos/department-of-veterans-affairs/va.gov-team/issues/21554,bug,2021-03-15T22:12:48Z,CONTRIBUTOR,https://api.github.com/repos/department-of-veterans-affairs/va.gov-team,"Folder system_folder attribute incorrectly shows as false when getting an individual folder I noticed that when listing folders, `system_folder` is correctly set to true for any of the inbox/sent/deleted/etc folders. `http://localhost:3000/mobile/v0/messaging/health/folders` But when getting an indidivual folder resource, `system_folder` is always false for those folders. `http://localhost:3000/mobile/v0/messaging/health/folders/0` This may be low priority because I don't even know that the mobile app has any use case for getting an individual folder vs. the list, but I would like to understand why that is happening so that it's not a lingering bug that we run across later."
559908,622251,https://api.github.com/repos/microting/eform-eform-dashboard-base/issues/51,enhancement,2021-04-04T16:11:40Z,MEMBER,https://api.github.com/repos/microting/eform-eform-dashboard-base,Bump Microting.eForm from 4.4.16 to 4.4.17 TBD
56273,62566,https://api.github.com/repos/RTXteam/RTX/issues/815,enhancement,2020-06-11T21:05:05Z,COLLABORATOR,https://api.github.com/repos/RTXteam/RTX,"Make BTE Expand work with general qnodes (no type or curie) BTE's `SingleEdgeQueryDispatcher` requires all qnodes to have a type (e.g., 'protein'), so a query like `(n00: DOID:14330)-->(n01)`, where n01 is general (no type), isn't currently possible with `kp=BTE` (Expand logs an error explaining that's not allowed). But we could get around this limitation by doing multiple BTE queries behind the scenes for such a query - one for each possible node type. Meaning, if the query was like this: ``` (n00: DOID:14330)-->(n01) ``` Behind the scenes, Expand could query BTE for: ``` (n00: DOID:14330)-->(n01: protein) (n00: DOID:14330)-->(n01: chemical_substance) (n00: DOID:14330)-->(n01: disease) etc... ``` and aggregate the results."
10524,11740,https://api.github.com/repos/nelsongoh/project-dopamine/issues/14,enhancement,2021-01-31T05:39:02Z,OWNER,https://api.github.com/repos/nelsongoh/project-dopamine,"Update the validation logic for content access Currently the DashboardContentAuth component relies on matching the permissions set out in the database, against the suffix of the URL that the user is visiting. This is hardcoded logic, and needs to be changed. A possible way of doing this is to have each page component (e.g. dashboard/calendar, dashboard/ig, dashboard/profile) hold a unique code which identifies this page. Pages that require the PageAuth component as a wrapper, will pass this unique identifier to the PageAuth component. Eventually this will be passed on to the DashboardContentAuth component, that will check this code against the list of permissions which they have (retrieved via API). This is a slightly more robust manner instead of relying on the check between the permissions in the DB and the URL. Future problems include: DB permission changes if the URLs change."
95101,105704,https://api.github.com/repos/CrunchyData/postgres-operator/issues/2314,question,2021-03-03T15:13:18Z,NONE,https://api.github.com/repos/CrunchyData/postgres-operator,"postgres-exporter - pgBackRest query fails in untrusted TLS environment **Describe the bug** I have a postgres cluster is working on Azure with metrics enabled. Everything worked fine except for postgres-exporter, it only worked on `replicas deployment` **To Reproduce** Steps to reproduce the behavior: 1. My own cluster is deployed with this command(*be noticed that all requirements are prepared already: s3, tls, prometheus,..*): ``` pgo create cluster infra \ --pgbouncer \ --service-type=LoadBalancer \ --server-ca-secret=postgresql-ca \ --server-tls-secret=infra-tls-keypair \ --pgbouncer-tls-secret=infra-tls-keypair \ --replication-tls-secret=infra-rep-tls-keypair \ --pgbouncer-replicas=2 \ --replica-count=1 \ --pvc-size=10Gi \ --pgbackrest-storage-type=s3 \ --pgbackrest-s3-bucket=<S3-BUCKET> \ --pgbackrest-s3-endpoint=<S3-ENDPOINT> \ --pgbackrest-s3-key=<S3-REGION> \ --pgbackrest-s3-key-secret=<S3-PROJECT> \ --pgbackrest-s3-region=eu-cenral-1 \ --pgbackrest-s3-uri-style=path \ --pgbackrest-s3-verify-tls=false \ --metrics ``` 2. I haved added 2 service monitors from my prometheus operator, they are: leader-postgres-exporter: ``` apiVersion: monitoring.coreos.com/v1 kind: ServiceMonitor metadata: annotations: meta.helm.sh/release-name: prometheus meta.helm.sh/release-namespace: cicd labels: app: prometheus-operator-prometheus app.kubernetes.io/managed-by: Helm chart: prometheus-operator-8.13.8 heritage: Helm pg-cluster-role: master release: prometheus name: psql-infra-master namespace: cicd spec: endpoints: - port: postgres-exporter jobLabel: psql-infra-master namespaceSelector: matchNames: - pgo selector: matchLabels: name: infra pg-cluster: infra ``` replica-postgres-exporter: ``` apiVersion: monitoring.coreos.com/v1 kind: ServiceMonitor metadata: annotations: meta.helm.sh/release-name: prometheus meta.helm.sh/release-namespace: cicd labels: app: prometheus-operator-prometheus app.kubernetes.io/managed-by: Helm chart: prometheus-operator-8.13.8 heritage: Helm pg-cluster-role: replica release: prometheus name: psql-infra-replica namespace: cicd spec: endpoints: - port: postgres-exporter jobLabel: psql-infra-replica namespaceSelector: matchNames: - pgo selector: matchLabels: name: infra-replica pg-cluster: infra ``` 3. From my prometheus, I see leader-postgres-exporter is always unaccessible. Even if I switched role between them, it is always unaccessible. ![image](https://user-images.githubusercontent.com/67224217/109824913-df062980-7c6b-11eb-83f7-9c576c3e900c.png) 4. Finally I looked at how differences between theirs k8s manifests. I see `database` sidecar from leader pod missed these configurations, `exporter` pods are same: ![image](https://user-images.githubusercontent.com/67224217/109825606-91d68780-7c6c-11eb-8cb4-b40f20f7ce6c.png) I have also tried to run curl inside leader exporter pod, and the result is failed: ![image](https://user-images.githubusercontent.com/67224217/109829435-1a0a5c00-7c70-11eb-8775-428ad2cc6bba.png) **Expected behavior** I am not sure it's feature or bug, I just want to have 2 dedicated metrics for both of them. **Screenshots** *(Included already)* **Please tell us about your environment:** * Operating System: Linux * Where is this running ( Local, Cloud Provider): Azure * Storage being used (NFS, Hostpath, Gluster, etc): Azure persistent volumes * Container Image Tag: registry.developers.crunchydata.com/crunchydata/crunchy-postgres-exporter:centos8-4.6.0 * PostgreSQL Version: registry.developers.crunchydata.com/crunchydata/crunchy-postgres-ha:centos8-13.1-4.6.0 * Platform (Docker, Kubernetes, OpenShift): Kubernetes * Platform Version: 1.17 **Additional context** Add any other context about the problem here. "
138841,154318,https://api.github.com/repos/zentnerlab/TSRexploreR/issues/35,enhancement,2020-11-20T16:30:47Z,OWNER,https://api.github.com/repos/zentnerlab/TSRexploreR,"Sample ordering for plots Would be good to be able to specify a sample order for plotting functions. One could generate a vector of sample names in the desired order and this could be fed to an option like ""sample_order""."
641022,712458,https://api.github.com/repos/AllTheMods/ATM-6/issues/1374,bug,2021-04-08T13:54:38Z,NONE,https://api.github.com/repos/AllTheMods/ATM-6,"[1.5.9b]Pulverizer can't accept osmium ingot <!--- Issues without a pack version will be closed without comment. --> **Describe the bug** Can't put osmium ingot into the pulverizer from thermal,even with pipes. **To Reproduce** Steps to reproduce the behavior: 1. Open the pulverizer's gui 2. try to put osmium ingot into the slot **Additional context** the jei's recipes still shows i can crush the osmium ingot into dust by pulverizer"
230477,256303,https://api.github.com/repos/Blockception/VSCode-Bedrock-Development-Extension/issues/21,enhancement,2020-11-12T13:33:29Z,CONTRIBUTOR,https://api.github.com/repos/Blockception/VSCode-Bedrock-Development-Extension,Implementation of all item components of the new beta **Describe the solution you'd like** To add all the other item components implementation in the JSON validation schemas 
332088,369191,https://api.github.com/repos/scikit-hep/scikit-hep.github.io/issues/109,enhancement,2021-01-15T10:03:52Z,MEMBER,https://api.github.com/repos/scikit-hep/scikit-hep.github.io,"Mention our Scikit-HEP tutorials somewhere on the website Indeed the tutorials available as a Jupyter notebook at https://scikit-hep.org/scikit-hep-tutorials are not mentioned anywhere, and they should. (See discussion at https://github.com/scikit-hep/scikit-hep.github.io/issues/108.) A possible place to mention the tutorials is the https://scikit-hep.org/resources page."
502193,558185,https://api.github.com/repos/artipie/artipie/issues/842,enhancement,2021-01-22T08:45:42Z,MEMBER,https://api.github.com/repos/artipie/artipie,"Re-enable binary proof After unrelated changes in https://github.com/artipie/artipie/pull/841 binary proof started to fail. It seems to be some issue with GitHub actions, as the same action with same code changes successfully runs in other repository: https://github.com/olegmoz/artipie/actions/runs/501064796 Seems that there is some issues with actions isolation, such as cache sharing. It needs to be investigated. "
461598,513007,https://api.github.com/repos/microsoft/EconML/issues/371,bug,2021-01-14T16:53:16Z,COLLABORATOR,https://api.github.com/repos/microsoft/EconML,Bug in automated_ml integration There seems to be a bug here: https://github.com/microsoft/EconML/blob/35c5418618d4ca9828f5465c090dd17e5e9a263c/econml/automated_ml.py#L292 Maybe also need to add a test where an `automl_config` is passed as positional argument so as to capture this path. Currently this seems to be the reason why this bug is not captured by tests.
235803,262264,https://api.github.com/repos/fleetdm/fleet/issues/555,bug,2021-03-30T01:48:59Z,NONE,https://api.github.com/repos/fleetdm/fleet,"Endpoint platform labels are not showing up in a pack's query list after migrating from Kolide Fleet to FleetDM 3.8.0 **Fleet version** (`fleetctl version`): fleetctl - version 3.8.0 branch: master revision: 499cd1d7dc5b418f4962d06c0bd490ce62597bbf build date: 2021-02-25T17:26:59Z build user: noahtalerman go version: go1.15.7 **Operating system** _(e.g. macOS 11.2.3)_: NAME=""Red Hat Enterprise Linux Server"" VERSION=""7.6 (Maipo)"" **Web browser** _(e.g. Chrome 88.0.4324)_: <hr/> Google Chrome Google Chrome is up to date Version 89.0.4389.90 (Official Build) (x86_64) ### 🧑‍💻  Expected behavior <!-- What did you do? What did you expect to see? --> I went to the web console and selected one of the packs; In the query list of the pack, I see the query name, Interval(s), ver., and Logging, but not the Platform icon. The platform filed is empty for all of the queries of the selected pack. Trying to update the platform of the query in the console did not help. I am seeing the same issue for all the queries in any pack regardless of the platform (macOS, Linux, and Windows) selected. ### 💥  Actual behavior <!-- What did you see instead? --> The platform field is empty. ![Screen Shot 2021-03-29 at 6 22 54 PM](https://user-images.githubusercontent.com/17017568/112919345-cbf44700-90bb-11eb-8c64-d8ce2b9e5661.png) ### More info <!-- Any ideas? --> <!-- If this is a performance issue: Please [follow these steps](https://github.com/fleetdm/fleet/blob/master/docs/1-Using-Fleet/5-Monitoring-Fleet.md#debugging-performance-issues) to generate and attach a debug archive. --> "
237324,263974,https://api.github.com/repos/NicolasConstant/BirdsiteLive/issues/56,enhancement,2021-01-16T07:45:31Z,OWNER,https://api.github.com/repos/NicolasConstant/BirdsiteLive,"Keep a ""last sync"" status in Twitter Users Db and be resilient to a saturated instance situation * Pull only the oldest synchronized users with a limit (defined by the API) * Update them after synchronizing (independently of synchronization success)"
392794,436589,https://api.github.com/repos/willmcpherson2/notcord/issues/25,enhancement,2021-05-13T01:24:56Z,COLLABORATOR,https://api.github.com/repos/willmcpherson2/notcord,"Groups cannot be deleted A route and the ability to delete groups should be implemented, so that if the admin leaves, the group is deleted, as well as if the group is specifically deleted."
616130,684704,https://api.github.com/repos/hellodword/wechat-feeds/issues/895,enhancement,2021-01-25T10:58:18Z,OWNER,https://api.github.com/repos/hellodword/wechat-feeds,关于图标 一直以来阅读器们不是很配合 RSS 的标准读取指定的图标，而是去获取 link 的 favicon，导致所有 feeds 的图标都是同一个，这样体验很不好，我也一直在思考解决方案。 今天在路上想到一个方案：既然它们会读取 favicon，那么就提供给它们 favicon，例如 `Mzg2ODAyNTgyMQ.favicon.privacyhide.com/favicon.ico` 就会返回 `Mzg2ODAyNTgyMQ==` 对应的图标。 于是需要泛解析，对此支持的方式很多，例如 [sslip.io](https://sslip.io/) ，或者一些 DNS 服务商。但是如果希望指向免费的服务却没有找到方案，总有各种各样的限制，例如 Cloudflare 的泛解析如果不想指向 ip，则需要企业版。 总的来说不是太希望依赖自己的服务器，并且希望能走 CDN，欢迎有思路或者有资源（例如 Cloudflare Enterprise 便可以泛解析指向一个 Cloudflare workers ）的朋友一起讨论。
126276,140316,https://api.github.com/repos/iains/gcc-darwin-arm64/issues/36,enhancement,2020-12-28T10:24:49Z,OWNER,https://api.github.com/repos/iains/gcc-darwin-arm64,"configuring with arm64-apple-darwin20 doesn't work yet I'm not sure if this is a major objective (perhaps a 'nice to have') but it also means that the sub-directories have to understand arm64-apple-darwin (which would mean updating GMP/MPFR/MPC/ISL and libcody, at minimum to config.sub/guess that understand arm64-apple-darwin). "
77385,86038,https://api.github.com/repos/Rapptz/discord.py/issues/6543,bug,2021-03-19T15:29:04Z,NONE,https://api.github.com/repos/Rapptz/discord.py,"Bug report ### Summary A case where Message.reactions gives incorrect return ### Reproduction Steps if we have a message created with resending content of replied message (message.reference) like msg = await ctx.send(replied_message.content) the msg.reactions returns an empty list easily reproduced with short code: @bot.command() async def reactions_test(ctx): old_message = await ctx.channel.fetch_message(ctx.message.reference.message_id) msg = await ctx.send(old_message.content) await msg.add_reaction('👍') await msg.add_reaction('👎') await ctx.send(f'list of reactions provided by message.reactions method: {msg.reactions}') ### Expected Results a list of Reaction type objects ### Actual Results empty list ### Intents all intents. ### System Information - Python v3.7.1-final - discord.py v1.6.0-final - aiohttp v3.7.3 - system info: Windows 10 10.0.19041 ### Checklist - [X] I have searched the open issues for duplicates. - [X] I have shown the entire traceback, if possible. - [X] I have removed my token from display, if visible. Was trying to make a command that makes a poll from replied message and encountered this bug."
259847,288997,https://api.github.com/repos/CrowdStrike/psfalcon/issues/32,question,2021-03-09T22:45:46Z,NONE,https://api.github.com/repos/CrowdStrike/psfalcon,Custom Cloud Parameter? Before chasing my tail I wanted to throw out this question. We leverage an API proxy. My understanding with how the API proxy works is that is just injects itself as the parent domain and keeps all the URL paths from the original API call. Could I add a new line(s) under the `$PSBoundParameters.Cloud` variable switch in the `oath2.ps1` script to account for that proxy? 
456963,507881,https://api.github.com/repos/rapidsai/cudf/issues/7638,bug,2021-03-18T16:17:09Z,CONTRIBUTOR,https://api.github.com/repos/rapidsai/cudf,"[BUG] cudf::partition causing data corruption on structs **Describe the bug** We recently switched over to try and use cudf::partition (0.19) as a way to partition shuffle data in some cases for Spark. Instantly a test started to fail that partitioning a column with a struct in it. **Steps/Code to reproduce bug** ```diff diff --git a/cpp/tests/partitioning/partition_test.cpp b/cpp/tests/partitioning/partition_test.cpp index a6838112a5..e15d57fc67 100644 --- a/cpp/tests/partitioning/partition_test.cpp +++ b/cpp/tests/partitioning/partition_test.cpp @@ -141,6 +141,35 @@ TYPED_TEST(PartitionTest, Identity) run_partition_test(table_to_partition, map, 6, table_to_partition, expected_offsets); } +TYPED_TEST(PartitionTest, Struct) +{ + using value_type = cudf::test::GetType<TypeParam, 0>; + using map_type = cudf::test::GetType<TypeParam, 1>; + + fixed_width_column_wrapper<value_type, int32_t> A({1, 2}, {0, 1}); + auto struct_col = cudf::test::structs_column_wrapper({A}, {0, 1}).release(); + auto table_to_partition = cudf::table_view{{*struct_col}}; + + fixed_width_column_wrapper<map_type> map{9, 2}; + + fixed_width_column_wrapper<value_type, int32_t> A_expected({2, 1}, {1, 0}); + auto struct_expected = cudf::test::structs_column_wrapper({A_expected}, {1, 0}).release(); + auto expected = cudf::table_view{{*struct_expected}}; + + std::vector<cudf::size_type> expected_offsets{0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2}; + + // This does not work because we cannot sort a struct right now... + // run_partition_test(table_to_partition, map, 12, expected, expected_offsets); + // But there is no ambiguity in the ordering so I'll just copy it all here for now. + auto num_partitions = 12; + auto result = cudf::partition(table_to_partition, map, num_partitions); + auto const& actual_partitioned_table = result.first; + auto const& actual_offsets = result.second; + EXPECT_EQ(actual_offsets, expected_offsets); + + CUDF_TEST_EXPECT_TABLES_EQUAL(expected, *actual_partitioned_table); +} + TYPED_TEST(PartitionTest, Reverse) { using value_type = cudf::test::GetType<TypeParam, 0>; ``` This test definitely fails and I think it is reproducing the error. Essentially what I see is that the child of the struct is not being changed despite the parent column being reordered. I think this is a scatter issue, but I am not 100% sure. **Expected behavior** The child of the struct should be reordered just like the struct was. **Additional context** Please verify that lists are working correctly too. "
557150,619196,https://api.github.com/repos/adiwajshing/Baileys/issues/461,bug,2021-04-22T21:04:58Z,NONE,https://api.github.com/repos/adiwajshing/Baileys,[BUG] baileys error: close
577051,641267,https://api.github.com/repos/DSnod93/portfolio-generator/issues/3,enhancement,2021-02-02T02:17:45Z,OWNER,https://api.github.com/repos/DSnod93/portfolio-generator,Prompt user for more input **Description** _Profile questions_ - Name - GitHub account name - About me _Project questions_ - Project name - Project description - Programming Languages - Project link
611216,679248,https://api.github.com/repos/SAP/spartacus/issues/8948,bug,2020-09-18T07:24:05Z,CONTRIBUTOR,https://api.github.com/repos/SAP/spartacus,"Group Menu gone after configure from cart and overview navigation Configure from cart. Navigate to OV Navigate back -> Group menu not displayed Happens only once, when navigation in config has taken place, it works fine after navigation to OV and back"
328081,364712,https://api.github.com/repos/xdefilab/xhalflife-base/issues/206,bug,2021-02-21T03:29:46Z,COLLABORATOR,https://api.github.com/repos/xdefilab/xhalflife-base,halflife的bug，已经结束的streem，显示状态为loading ![image](https://user-images.githubusercontent.com/23711319/108614718-f8230500-7437-11eb-8064-614aca7bfb5d.png) 
356249,396054,https://api.github.com/repos/swaponline/MultiCurrencyWallet/issues/4251,question,2021-04-19T21:42:20Z,NONE,https://api.github.com/repos/swaponline/MultiCurrencyWallet,"Question about phone and address Hi guys! Please tell us, how you have done the generation and access to wallets linked to my phone number. Thanks."
77976,86701,https://api.github.com/repos/HSLdevcom/bultti/issues/62,enhancement,2020-10-19T05:51:53Z,CONTRIBUTOR,https://api.github.com/repos/HSLdevcom/bultti,"Combine planned departures with observed events When the HFP events are fetched, they need to be combined with planned departures."
126419,140479,https://api.github.com/repos/MMetze/DMHelper-Tracker/issues/70,bug,2020-02-25T18:14:44Z,COLLABORATOR,https://api.github.com/repos/MMetze/DMHelper-Tracker,"Imported Dnd Beyond Spell slots start at Level 0 instead of 1 **Discord User:** dm-helper **Describe the bug:** In the DnD Beyond import, the spell level for spell slots start at 0 instead of 1 **DMHelper version:** v1.6 **To Reproduce:** 1. Import a spellcaster from Dnd Beyond 2. Go to the character view 3. Change to the Spells tab, check the spell slots **Expected behavior:** Spell slots start with Level 1 **Desktop (please complete the following information):** OS: Any "
716473,796303,https://api.github.com/repos/AADV-PUC/aadv-puc.github.io/issues/3,enhancement,2021-05-28T15:34:47Z,MEMBER,https://api.github.com/repos/AADV-PUC/aadv-puc.github.io,"Colocar link que leve para o site oficial da AADV Deverá ser adicionado um link que leva ao [site oficial da AADV](https://aadv.com.br/) no rodapé da página. A princípio, a atividade deverá ser entregue até 03/06."
315770,351057,https://api.github.com/repos/MeteorDevelopment/meteor-client/issues/481,enhancement,2021-04-12T13:05:40Z,NONE,https://api.github.com/repos/MeteorDevelopment/meteor-client,auto highway builder and schematic hi if u see sal hack there is some thing call auto highway builder.i know i can do it with baritone but with this is so much faster and ofc easier. i want ask meteor developers to add this to client that will be awesome. this client is one of the best client. second is schematic. using it is a bit hard and bugy if developers can add some thing to help players use it that would be so much good
328173,364812,https://api.github.com/repos/encode/httpx/issues/1488,question,2021-02-25T11:07:17Z,NONE,https://api.github.com/repos/encode/httpx,"Memory leak in any previous version? I was using httpx for a project, i let the project some time ago and get it back to then now i have time. I figure out that with version 0.13.1 that is what i had before, i have a insane memory leak, i think it was from my own code but i didnt figure out where it was. If i let the code run for multiple days got up to 12/13GB of ram just with postgresql and httpx Now i with lastest version i have 0 memory leaks, so 100% needs to be from this library the memory leak, but dosnt happen anymore, just curius cause in the past i have big troubles trying to find this memory leak. My client class is this, i didnt change since then, if someone knows any memory leak in any previous version would aprecciate. ``` import json import ssl import collections import traceback import httpx class http_Client(): def __init__(self): self.proxy = None self.headers = None self.body = None self.params = None self.url = None self.method = None self.cookies = None self.response = None self.remove = None def reset(self): self.headers = None self.body = None self.params = None self.url = None self.method = None self.cookies = None self.response = None self.remove = None async def run(self): if self.headers == None: raise Exception('Headers cant be empty') if self.method == 'POST' and self.body == None: raise Exception('HTTP body cant be empty') if self.url == None: raise Exception('URL Cant be empty') # todo aun falta configurar las cookies en las llamadas que faltan ya que no tengo claro que llamadas meten cookies y cuales no, la mayoria de gets llevan cookies ssl_config = httpx._config.SSLConfig() ssl_context = ssl_config.load_ssl_context() ssl_context.options |= getattr(ssl, ""OP_NO_TLSv1_3"", 0) ssl_context.load_verify_locations(r'C:\Users\qwert\Downloads\charlesproxy.pem') #ssl_config = client_httpx.SSLConfig(verify=r'C:\Users\localhost\Documents\Enrique\charlesproxy.pem') try: self.headers = collections.OrderedDict(self.headers) if self.proxy != None: client = httpx.AsyncClient(proxies={ ""http"": 'http://' + self.proxy, ""https"": 'http://' + self.proxy # configuramos ssl en el cliente }, verify=ssl_context, http2=True) else: client = httpx.AsyncClient(verify=False,http2=True) if self.method == 'get': request = client.build_request('get', self.url, headers=collections.OrderedDict(self.headers), params=self.params) # eliminamos de los headers el header accept # if self.remove != None: # print(2) # request.headers.pop(self.remove) self.response = await client.send(request,allow_redirects=True) await client.aclose() return self.response.text elif self.method == 'post': # pasamos a texto cualquier cosa dentro de el body body = str(self.body) # mandamos a el cliente ha hacer el post # self.response = await client.post(self.url, headers=collections.OrderedDict(self.headers), params=self.params, data=body) request = client.build_request('post', self.url, headers=collections.OrderedDict(self.headers), params=self.params, data=body) # eliminamos de los headers el header accept request.headers.pop(self.remove) self.response = await client.send(request) await client.aclose() return json.load(self.response) except Exception as e: print(e.args) print(traceback.print_exc()) finally: self.reset() ``` To be clear, in last version there is no memory leak, in someone of the previous ones should be one and i just want to find out what it causes :) thanks guys "
283879,315705,https://api.github.com/repos/oukone/aiobaro/issues/8,enhancement,2021-03-14T15:39:49Z,COLLABORATOR,https://api.github.com/repos/oukone/aiobaro,"Matrix client implementation: Set a user display name - [Matrix Spec reference](https://matrix.org/docs/spec/client_server/latest#put-matrix-client-r0-profile-userid-displayname) Parameter | Type | Description -- | -- | -- Path Parameters userId | string | Required. The user whose display name to set. JSON Body Parameters displayname | string | The new display name for this user. PUT /_matrix/client/r0/profile/{userId}/displayname HTTP/1.1 Content-Type: application/json ```json { ""displayname"": ""Alice Margatroid"" } ``` Rate-limited: Yes. Requires auth: Yes. "
25785,28724,https://api.github.com/repos/osome-iu/osometweet/issues/1,enhancement,2020-12-18T14:09:58Z,COLLABORATOR,https://api.github.com/repos/osome-iu/osometweet,"Handle rate limits The headers returned by each API call contain the following fields: > - x-rate-limit-limit: the rate limit ceiling for that given endpoint > - x-rate-limit-remaining: the number of requests left for the 15-minute window > - x-rate-limit-reset: the remaining window before the rate limit resets, in UTC epoch seconds These fields are documented [here](https://developer.twitter.com/en/docs/twitter-api/rate-limits). Method calls should parse these fields to determine when to sleep the process and for how long. Performing additional requests when the limit has been reached risks account suspension."
55832,62083,https://api.github.com/repos/shopsys/shopsys/issues/2098,bug,2020-11-03T13:05:44Z,CONTRIBUTOR,https://api.github.com/repos/shopsys/shopsys,"Passing nullable value to required argument in ListedProductViewFactory.php <!--- Title should contain short general summary what is the issue about --> Found in https://github.com/shopsys/shopsys/pull/2090#discussion_r512077387 ### What is happening <!--- What are preconditions and your setting e.g. Shopsys version or in case of Docker issues your operating system --> <!--- Best is to include steps to reproduce this issue if relevant--> <!--- Tell us what happens --> When creating `ListedProductView` there may be passed `null` (actually it cannot, because of our recalculations and so on) to argument requiring `ProductPrice`. https://github.com/shopsys/shopsys/blob/0d77eb9c5e6309df3e91eeaacf60b3c20419e784/packages/read-model/src/Product/Listed/ListedProductViewFactory.php#L127 ### Expected result <!--- Tell us what should happen instead --> The edgecase without found price is handled properly. _E.g.: There could be raised and hadled exception when the `ProductPrice` is not available instead of returning null._"
218631,243108,https://api.github.com/repos/iDigitalFlame/Scorebot-Scoreboard/issues/2,bug,2021-04-13T05:05:02Z,NONE,https://api.github.com/repos/iDigitalFlame/Scorebot-Scoreboard,"Request = Ability to hide a game/only show 1 gave on the Scoreboard So. I have 2 games on the scorebot itself. 1 for the live game, the other as ""staging"" which holds hosts that have been setup in the scorebot system. So when i want to add these to the live game i can just easily re-assign them, and they move from 1 scoreboard to the other (Just quicker than manually adding hosts/services) e.g http://<IP>:8080/game/1 = Staging Game http://<IP>:8080/game/2 = Live Game I'd like to be able to hide the ""Staging Game"" from players, so they can't get a sneak peak at new servers i'm gonna add. This might be hard within Scorebot, but even if you can specify the game number in scoreboard.config, so that it will then only show that 1 scoreboard e.g http://<IP>:8080 (When scoreboard.config has game = 3) will only display http://<IP>:8080/game/3 (and nothing else) Make sense? Cheers"
412216,458186,https://api.github.com/repos/konveyor/tackle-controls/issues/91,enhancement,2021-04-13T13:49:55Z,MEMBER,https://api.github.com/repos/konveyor/tackle-controls,Change default tag types' color codes The proposed set of colors are: - `#2b9af3` as blue - `#6ec664` as green - `#009596` as cyan - `#a18fff` as purple - `#35caed` as lightBlue - `#f4c145` as gold - `#ace12e` as lightGreen - `#ec7a08` as orange - `#7d1007` as red
486342,540512,https://api.github.com/repos/BSData/adeptus-titanicus/issues/94,bug,2021-02-03T03:40:49Z,COLLABORATOR,https://api.github.com/repos/BSData/adeptus-titanicus,"High Scion is required, one per Lance Banner. This is not yet enforced. High Scion is required, one per Lance. This is not yet enforced."
100896,112116,https://api.github.com/repos/davyzhang3/volto/issues/1,enhancement,2021-04-18T01:04:07Z,OWNER,https://api.github.com/repos/davyzhang3/volto,Set up a Amazon Scraper things to scrape: - target: waist extender - features: image link # contact info: business name and business address item names price
444564,494147,https://api.github.com/repos/jracker/testePSF/issues/1,bug,2021-04-09T20:29:58Z,OWNER,https://api.github.com/repos/jracker/testePSF,"Erro ao usar a função `plot()` do pacote PSF O erro ocorre ao usar a função `plot()` com os argumentos conforme mostrado no código a seguir ``` qnat_posto74<- qnat_posto74[10:length(qnat_posto74$qnat),] modelo_munhoz = psf(qnat_posto74, cycle = 12) (pred_munhoz = predict(modelo_munhoz, n.ahead = 12)) (obs <- qnat_posto74$qnat[580:591]) # Valores de vazão dos últimos 12 meses plot(modelo_munhoz, pred_munhoz) ``` Após executar a função `plot()` ocorre o seguinte erro: ` Error in xy.coords(x, NULL, log = log, setLab = FALSE) : 'list' object cannot be coerced to type 'double' ` Será que é necessário transformar os dados do tipo `dataframe` para séries temporais, como é feito nos exemplos do pacote PSF?"
642315,713904,https://api.github.com/repos/admob-plus/admob-plus/issues/46,enhancement,2018-11-28T16:13:01Z,NONE,https://api.github.com/repos/admob-plus/admob-plus,"Support mediation? Unity ads, adcolony ... Support mediation? Unity ads, adcolony ..."
346137,384808,https://api.github.com/repos/BME-MIT-IET/iet-hf2021-elia/issues/5,enhancement,2021-05-09T20:51:15Z,CONTRIBUTOR,https://api.github.com/repos/BME-MIT-IET/iet-hf2021-elia,"Bdd tesztelés Bdd tesztek készítése és a tesztekkel felmérni, hogy kielégíti a felhasználók igényeit. Javaslat a használt eszközökre: - Corde: javascript alapú teszt framework, amelyet Discord botok tesztelésére készítettek."
325371,361700,https://api.github.com/repos/uvdesk/community-skeleton/issues/368,enhancement,2021-03-06T11:09:47Z,CONTRIBUTOR,https://api.github.com/repos/uvdesk/community-skeleton,"Add options for ReCaptcha Actually for be able to add reCaptcha you need edit the code and I was able to insert reCaptcha only on the ticket creation. Please add in the admin back end the possibility to enable the reCaptcha in: - ticket creation - reset password - user login - operator login I'm thinking at section in branding or else where where user can insert the reCaptcha API than use checkboxes for activate the reCaptcha on desired pages. Hope this can be implemented so I can improve security. I was unable to implement reCaptcha on login pages. https://forums.uvdesk.com/topic/1840/add-google-recaptcha/6 I use other application different from uvdesk, for example a live chat system. I know is possibile add an option in the admin side where user can activate reCaptcha. ![SharedScreenshot](https://user-images.githubusercontent.com/5006150/110207136-d25b1e80-7e81-11eb-9597-e6c1fde5eb11.jpg) "
242842,270088,https://api.github.com/repos/edgedb/edgedb/issues/1381,bug,2020-05-06T21:01:36Z,MEMBER,https://api.github.com/repos/edgedb/edgedb,"Incorrect result for a value computed in WITH block Run the following in the existing scope tests dataset (from `test_edgeql_scope.py`): ``` WITH MODULE test, avg := math::mean({len(Card.name)}) SELECT Card {name, a := avg}; ``` Instead of being the same value across all results `a` is different for each as if the function call was inlined."
205415,228399,https://api.github.com/repos/neopragma/cobol-check/issues/98,bug,2021-02-11T18:43:46Z,OWNER,https://api.github.com/repos/neopragma/cobol-check,Reinstate jacoco support in build.gradle after downgrade to JDK 8 Forgot to put jacoco code back into build.gradle. 
151360,168276,https://api.github.com/repos/tamu-datathon-org/mercury/issues/3,enhancement,2021-03-27T17:14:02Z,MEMBER,https://api.github.com/repos/tamu-datathon-org/mercury,"Design for Mercury that includes needed features Use the Geist UI to come up with a some what thorough design for the page that has the following functionality: - Ability to choose any number of mailing lists. A custom option would be nice but doesn't have to be implemented right away - Fields for Email subject, body (html), and anything else that might be important based on the Mailgun Api - Preview functionality for the email through an iframe - Summary of the sent email (Geist UI guide) [https://react.geist-ui.dev/en-us/guide/introduction] (Mailgun API documentation)[https://documentation.mailgun.com/en/latest/user_manual.html#sending-via-api]"
158624,176355,https://api.github.com/repos/johnsonandjohnson/Bodiless-JS/issues/762,bug,2020-12-16T14:15:08Z,COLLABORATOR,https://api.github.com/repos/johnsonandjohnson/Bodiless-JS,"Menu item overlap after mouseover to next item <!-- Before submitting an issue: - Please read our contribution guidelines (https://github.com/johnsonandjohnson/Bodiless-JS/blob/master/packages/bodiless-documentation/doc/Development/Contributing.md). - Please search existing issues (https://github.com/johnsonandjohnson/Bodiless-JS/issues) to see if something similar has already been reported. Please fill out each section below; otherwise, your issue will be closed. --> ### Steps to reproduce - open static site or edit UI **preview mode** - click on menu item on top (not submenu) - mouseover to next menu item with submenu ### Expected result - Submenu drop opened - Preview menu item dropdown closed ### Actual result Both opened <img width=""787"" alt=""Screen Shot 2020-12-15 08-08-03"" src=""https://user-images.githubusercontent.com/1812250/102359754-30611f80-3f7f-11eb-828b-cbf03382c3d7.png""> What happened. ### Environment Run `gatsby info --clipboard` in your project directory and paste the output here. ### Affected Version - If the issue was encountered on a site, please attach your `package.json` - If the issue was encountered in the Bodiless-JS repo, please link to a commit or branch on which the issue occurs. "
251519,279768,https://api.github.com/repos/ARPA-SIMC/cosudo/issues/86,bug,2021-01-20T11:18:39Z,CONTRIBUTOR,https://api.github.com/repos/ARPA-SIMC/cosudo,"dati su mappa visualizzati come NaN molti dati su mappa vengono rappresentati come NaN. pare corrisponda a valori non rappresentabili nel formato prestabilito ad esempio: selezionare rete ""fidu"" e var ""Pressure"""
322880,358957,https://api.github.com/repos/aserowy/docker2mqtt/issues/17,bug,2021-03-10T06:45:15Z,OWNER,https://api.github.com/repos/aserowy/docker2mqtt,stream of events stopped working ## Describe the bug With while lets streams stop working unnoticed when they receive e.g. None values. ## Expected behavior Streams should recover easily. ## Additional context while lets to loops :) 
701484,779640,https://api.github.com/repos/tmdgusya/roach-web-server/issues/21,enhancement,2021-04-01T11:40:44Z,OWNER,https://api.github.com/repos/tmdgusya/roach-web-server,BeanFactory Test Code 를 작성한다. BeanFactory Test Code 를 작성한다. getBean 메소드 밑 시작할때 Bean 을 잘 등록하는지 확인한다.
633940,704567,https://api.github.com/repos/flexion/ef-cms/issues/7910,bug,2021-03-02T20:33:17Z,NONE,https://api.github.com/repos/flexion/ef-cms,"BUG: Logged out when trying to view document QC processed tab **Describe the Bug** Docket clerk is logged out of the app when trying to view Section Document QC Processed tab **Business Impact/Reason for Severity** **In which environment did you see this bug?** migration **Who were you logged in as?** docket clerk **What were you doing when you discovered this bug? (Using the application, demoing, smoke tests, testing other functionality, etc.)** Manual testing **To Reproduce** Steps to reproduce the behavior: 1. Log in as docket clerk 2. Navigate to Section Document QC > Processed tab **Expected Behavior** User should be able to view documents in Processed tab **Actual Behavior** User is logged out of app, network tab shows error on /served endpoint call but no error or response printed NOTE - looking at Kibana logs, the request to `/served` seems to have returned a 200 status. **Screenshots** ![image.png](https://images.zenhubusercontent.com/5e5e93c9fa78057303bcc6ac/abe9ee10-a712-41c0-ac01-5df0d2e43835) **Desktop (please complete the following information):** - OS: [e.g. iOS] - Browser [e.g. chrome, safari] - Chrome - Version [e.g. 22] **Smartphone (please complete the following information):** - Device: [e.g. iPhone6] - OS: [e.g. iOS8.1] - Browser [e.g. stock browser, safari] - Version [e.g. 22] **Cause of Bug, If Known** **Process for Logging a Bug:** * Complete the above information * Add a severity tag (Critical, High Severity, Medium Severity or Low Severity). See below for priority definition. **Severity Definition:** * Critical Defect Blocks entire system's or module’s functionality No workarounds available Testing cannot proceed further without bug being fixed. * High-severity Defect Affects key functionality of an application There's a workaround, but not obvious or easy App behaves in a way that is strongly different from the one stated in the requirements * Medium-severity Defect A minor function does not behave in a way stated in the requirements. Workaround is available and easy * Low-severity Defect Mostly related to an application’s UI Doesn't need a workaround, because it doesn't impact functionality ## Definition of Done (Updated 2-23-21) **Product Owner** - [x] Acceptance criteria have been met and validated on the Flexion Prod env **UX** - [ ] Business test scenarios to meet all acceptance criteria have been written - [x] Usability has been validated - [ ] Wiki has been updated (if applicable) - [ ] Story has been tested on a mobile device (for external users only) - [ ] Add scenario to testing document, if applicable (https://docs.google.com/spreadsheets/d/1FUHKC_YrT-PosaWD5gRVmsDzI1HS_U-8CyMIb-qX9EA/edit?usp=sharing) **Engineering** - [x] Automated test scripts have been written - [x] Field level and page level validation errors (front-end and server-side) integrated and functioning - [x] Verify that language for docket record for internal users and external users is identical - [x] New screens have been added to pa11y scripts - [x] All new functionality verified to work with keyboard and macOS voiceover https://www.apple.com/voiceover/info/guide/_1124.html - [x] READMEs, other appropriate docs, JSDocs and swagger/APIs fully updated - [x] UI should be touch optimized and responsive for external only (functions on supported mobile devices and optimized for screen sizes as required) - [ ] Module dependencies are up-to-date and are at the latest resolvable version (npm update) - [x] Errors in Sonarcloud are fixed https://sonarcloud.io/organizations/flexion-github/projects - [x] Lambdas include CloudWatch logging of users, inputs and outputs - [x] Interactors should validate entities before calling persistence methods - [x] Code refactored for clarity and to remove any known technical debt - [ ] Rebuild entity documentation - [x] Acceptance criteria for the story has been met - [x] Deployed to the dev environment - [x] Deployed to the Court's migration environment **Review Steps** 1. Finish all other DOD 2. Deploy to the dev environment 3. Engineers add `Needs UX Review` label 4. UX Review on dev environment (if feedback, implement and go back to step 2) 5. UX add `Needs Migration Deploy` label 6. Deploy to the Court's migration environment 7. Engineers go through test scenarios on Court's migration environment 8. Engineers add `Needs PO Review` label and move to Review/QA column 9. PO review (if feedback, implement and go back to step 2)"
213704,237639,https://api.github.com/repos/rednblackgames/HyperLap2D/issues/27,enhancement,2021-03-03T13:20:18Z,NONE,https://api.github.com/repos/rednblackgames/HyperLap2D,"Images are not sorted by name in the image panel Images are not sorted in the images panel, but seemingly coincidental: ![image](https://user-images.githubusercontent.com/73443724/109811775-8878fb00-7c2b-11eb-8569-b3feb79fa5d1.png) "
259250,288336,https://api.github.com/repos/cp-api/basic4/issues/7,enhancement,2021-01-04T12:25:59Z,NONE,https://api.github.com/repos/cp-api/basic4,Updating colors should not be applied when maxValue is 0 Merged to [master]. Commit: [1decee3cf0e84720b189a9e331d69311354262c3](https://github.com/search?q=1decee3cf0e84720b189a9e331d69311354262c3&type=Commits) `ECLIPSE-555067` `POLARSYS-865` `anonymous` `2016-04-07` `1.1.0`
112865,125433,https://api.github.com/repos/plum-umd/the-838e-compiler/issues/37,enhancement,2021-02-16T18:02:44Z,MEMBER,https://api.github.com/repos/plum-umd/the-838e-compiler,n-ary let Currently `let` expressions have to be of the form `(let ((x e)) e)`; it should be easy to generalize to any fixed number of variables.
11845,13202,https://api.github.com/repos/FuzzyStatic/blizzard/issues/34,question,2021-04-03T20:58:07Z,NONE,https://api.github.com/repos/FuzzyStatic/blizzard,"Wrong time format used for date parsing for header.LastModified / Date Hi again Been having weird issues today, and I think I found the cause: in `header.go`: ```go if httpHeader.Get(HeaderKeyLastModified) != """" { header.LastModified, err = time.Parse(time.RFC1123, httpHeader.Get(HeaderKeyLastModified)) if err != nil { header.LastModified = time.Time{} } } ``` If httpHeader.Get(HeaderKeyLastModified) returns this string: ""Sat, 3 Apr 2021 20:06:56 GMT"" time.Parse() gives this error: `parsing time ""Sat, 3 Apr 2021 20:06:56 GMT"" as ""Mon, 02 Jan 2006 15:04:05 MST"": cannot parse ""3 Apr 2021 20:06:56 GMT"" as ""02""` If instead of using `time.RFC1123` I try with a custom format `""Mon, _2 Jan 2006 15:04:05 MST""` then it works! Not sure if this still works if the day is > 9. I think so as it's how they handle it in Go's format.go "
565330,628252,https://api.github.com/repos/tk-codes/uno/issues/2,bug,2018-02-03T03:41:40Z,NONE,https://api.github.com/repos/tk-codes/uno,"Discovered A Bug If the play chooses the wild card but cancels when asked to pick the color, player then will be not able to choose other cards or draw. Working to find the solution. <img width=""960"" alt=""qq20180203-114104 2x"" src=""https://user-images.githubusercontent.com/30316509/35762742-2a550e12-08d7-11e8-9934-960e57adef21.png""> "
342967,381258,https://api.github.com/repos/timmo001/streamdeck-homeassistant/issues/70,enhancement,2021-02-06T14:24:32Z,OWNER,https://api.github.com/repos/timmo001/streamdeck-homeassistant,Automated Release Pipeline **Feature** <!-- A clear and concise description of the request. --> Automated release and ci pipeline using GitHub Actions 
536840,596661,https://api.github.com/repos/SWTCG/SWTCG-LACKEY/issues/40,bug,2021-01-01T00:03:48Z,CONTRIBUTOR,https://api.github.com/repos/SWTCG/SWTCG-LACKEY,"SAV031 and SAV032 Numbers Swapped SAV031 Boba Fett's Armor is listed as number 32, while SAV032 Blown Cover is listed as number 31."
718469,798511,https://api.github.com/repos/weirongxu/coc-kotlin/issues/3,bug,2021-02-19T19:20:13Z,NONE,https://api.github.com/repos/weirongxu/coc-kotlin,Kotlin script template class missing from classpath ### Result from CocInfo > vim version: VIM - Vi IMproved 8.2 8022164 node version: v15.9.0 coc.nvim version: 0.0.80-6e5a2aaeb5 coc.nvim directory: /Users/me/.vim/plugged/coc.nvim term: iTerm.app platform: darwin ### Description Open a kotlin script file e.g. `test.kts` and it shows an error missing script classes from the classpath. `[kotlin MISSING_SCRIPT_STANDARD_TEMPLATE] [E] No script runtime was found in the classpath: class 'kotlin.script.templates.standard.ScriptTemplateWithArgs' not found. Please add kotlin-script-runtime.jar to` ### Extension version 0.0.5 
635178,705960,https://api.github.com/repos/NOAA-EMC/NCEPLIBS/issues/122,enhancement,2020-09-29T20:44:48Z,COLLABORATOR,https://api.github.com/repos/NOAA-EMC/NCEPLIBS,Should ip and ip2 libraries be combined? There has been talk of combining the ip (https://github.com/NOAA-EMC/NCEPLIBS-ip) and ip2 (https://github.com/NOAA-EMC/NCEPLIBS-ip2) libraries. How would this happen? @GeorgeGayno-NOAA what do you think?
492436,547324,https://api.github.com/repos/hbattu73/wi21-cse110-lab3/issues/4,enhancement,2021-01-23T05:11:29Z,OWNER,https://api.github.com/repos/hbattu73/wi21-cse110-lab3,Align query box The search query box does not align with nav bar
722061,802476,https://api.github.com/repos/Guardsquare/proguard/issues/144,bug,2021-04-08T15:57:43Z,NONE,https://api.github.com/repos/Guardsquare/proguard,"Internal problem starting the ProGuard GUI Hello, When I run `bin/proguardgui.sh` I obtain the following error ` Internal problem starting the ProGuard GUI (Can't find resource for bundle java.util.PropertyResourceBundle, key field_generalization_classTip) java.util.MissingResourceException: Can't find resource for bundle java.util.PropertyResourceBundle, key field_generalization_classTip at java.base/java.util.ResourceBundle.getObject(ResourceBundle.java:564) at java.base/java.util.ResourceBundle.getString(ResourceBundle.java:521) at proguard.gui.GUIResources.getMessage(GUIResources.java:43) at proguard.gui.OptimizationsDialog.msg(OptimizationsDialog.java:249) at proguard.gui.OptimizationsDialog.tip(OptimizationsDialog.java:237) at proguard.gui.OptimizationsDialog.<init>(OptimizationsDialog.java:126) at proguard.gui.ProGuardGUI.createOptimizationsButton(ProGuardGUI.java:984) at proguard.gui.ProGuardGUI.<init>(ProGuardGUI.java:444) at proguard.gui.ProGuardGUI$6.run(ProGuardGUI.java:1909) at java.desktop/java.awt.event.InvocationEvent.dispatch(InvocationEvent.java:306) at java.desktop/java.awt.EventQueue.dispatchEventImpl(EventQueue.java:770) at java.desktop/java.awt.EventQueue$4.run(EventQueue.java:721) at java.desktop/java.awt.EventQueue$4.run(EventQueue.java:715) at java.base/java.security.AccessController.doPrivileged(AccessController.java:391) at java.base/java.security.ProtectionDomain$JavaSecurityAccessImpl.doIntersectionPrivilege(ProtectionDomain.java:85) at java.desktop/java.awt.EventQueue.dispatchEvent(EventQueue.java:740) at java.desktop/java.awt.EventDispatchThread.pumpOneEventForFilters(EventDispatchThread.java:203) at java.desktop/java.awt.EventDispatchThread.pumpEventsForFilter(EventDispatchThread.java:124) at java.desktop/java.awt.EventDispatchThread.pumpEventsForHierarchy(EventDispatchThread.java:113) at java.desktop/java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:109) at java.desktop/java.awt.EventDispatchThread.pumpEvents(EventDispatchThread.java:101) at java.desktop/java.awt.EventDispatchThread.run(EventDispatchThread.java:90) ` I have 1. Downloaded ProGuard-Core and I have built it with `gradle clean assemble` 2. Dowloaded Proguard and I have built libs with `./gradlew --include-build=../proguard-core assemble` 3. I'm suing macOSX 4. Java virtual machine is java 15.0.1 2020-10-20"
504353,560579,https://api.github.com/repos/awslabs/fhir-works-on-aws-deployment/issues/301,bug,2021-04-27T04:08:22Z,NONE,https://api.github.com/repos/awslabs/fhir-works-on-aws-deployment,"Not able to search resource identifier exactly. Hi FHIR Works Team, I tried to: `GET /Patient?identifier=testuser01@gmail.com` and there is only one patient with `identifier = testuser01@gmail.com`. I expect it to return one result, but it returns many more. Is this a bug? Deployed fhir-works-on-aws-deployment version: v2.6.0 "
642017,713575,https://api.github.com/repos/STMicroelectronics/cmsis_device_f4/issues/2,bug,2021-01-25T20:47:37Z,NONE,https://api.github.com/repos/STMicroelectronics/cmsis_device_f4,Wrong value for FLASH_ACR_LATENCY_Msk in stm32f407xx.h **Describe the bug** `#define FLASH_ACR_LATENCY_Msk (0xFUL << FLASH_ACR_LATENCY_Pos) /*!< 0x0000000F */` there are only 3 bits `#define FLASH_ACR_LATENCY_Msk (0x7UL << FLASH_ACR_LATENCY_Pos) /*!< 0x00000007 */` maybe it's not critical but misleading
193951,215685,https://api.github.com/repos/panjf2000/gnet/issues/179,question,2021-01-29T15:41:34Z,NONE,https://api.github.com/repos/panjf2000/gnet,v1.3.2版本发现连接建立后偶发没有触发OnOpened方法 潘神，你好。 我们使用了gnet的1.3.2版本做IM的服务器，上线一段时候后，我们发现一个非常诡异的现象。 当我们的服务运行一段时间后，会莫名其妙的造成系统内存一直增加，而且用netstat命令查看，发现很多连接的Recv-Q有大量的堆积。然后通过查询日志发现这一类有Recv-Q堆积的连接都没有触发onOpend方法，也就是说我的程序根本就没有感知到这个连接的建立（是不是因此这个连接的接收数据会一直得不到接收，一直堆在接收缓冲区上？） 附上recv-q的图 ![image](https://user-images.githubusercontent.com/16128584/106295364-4f93e200-628b-11eb-9f57-6cdf0b3007e6.png) 期待得到你的回复。十分感谢。
515052,572385,https://api.github.com/repos/CombatExtended-Continued/CombatExtended/issues/524,bug,2021-02-06T19:54:59Z,NONE,https://api.github.com/repos/CombatExtended-Continued/CombatExtended,"[Bug]: [HLX] ReGrowth - Mutated Animals Pack error on load **Specifications** Rimworld version: 1.2.2753 (64-bit) Combat Extended version: GitHub Dev build (41a3123) Combat Extended source (Steam, GitHub, etc.): GitHub Your operating system: Windows 10 Your mod list: - Harmony - Core - HugsLib - Combat Extended - [HLX] ReGrowth - Core - [HLX] ReGrowth - Wasteland - [HLX] ReGrowth - Mutated Animals Pack **Description** When I load the game with the mentioned modlist, the errors are thrown on game loading. **Expected behavior** No red error? **To reproduce** Load the mentioned mods. Launch RimWorld. **Screenshots & log dumps** Here's the link to the log : https://gist.github.com/e06c76cbcb66b16eebeab7d5fc056c85 Relevant part : ``` Failed to find any textures at Things/Pawn/Animal/WastelandDeer/WastelandDeer while constructing Multi(initPath=Things/Pawn/Animal/WastelandDeer/WastelandDeer, color=RGBA(1.000, 1.000, 1.000, 1.000), colorTwo=RGBA(1.000, 1.000, 1.000, 1.000)) (Filename: C:\buildslave\unity\build\Runtime/Export/Debug/Debug.bindings.h Line: 35) Exception from long event: System.Exception: RG-WF_WastelandDeer.lifeStages[0].bodyGraphicData ---> System.Exception: BoundMap(,) ---> System.Exception: Combat Extended :: CropVertical error while cropping Textures/Things/Pawn/Animal/WastelandDeer/WastelandDeer_side ---> System.NullReferenceException: Object reference not set to an instance of an object at CombatExtended.BoundsInjector.ExtractBounds (Verse.Graphic graphic, CombatExtended.BoundsInjector+GraphicType type) [0x00006] in <818ae093499a4140b0159bf9e706c495>:0 --- End of inner exception stack trace --- at CombatExtended.BoundsInjector.ExtractBounds (Verse.Graphic graphic, CombatExtended.BoundsInjector+GraphicType type) [0x00042] in <818ae093499a4140b0159bf9e706c495>:0 at CombatExtended.BoundsInjector.BoundMap (Verse.Graphic graphic, CombatExtended.BoundsInjector+GraphicType type) [0x00015] in <818ae093499a4140b0159bf9e706c495>:0 --- End of inner exception stack trace --- at CombatExtended.BoundsInjector.BoundMap (Verse.Graphic graphic, CombatExtended.BoundsInjector+GraphicType type) [0x0003d] in <818ae093499a4140b0159bf9e706c495>:0 at CombatExtended.BoundsInjector.Inject () [0x00073] in <818ae093499a4140b0159bf9e706c495>:0 --- End of inner exception stack trace --- at CombatExtended.BoundsInjector.Inject () [0x000b0] in <818ae093499a4140b0159bf9e706c495>:0 at Verse.LongEventHandler.UpdateCurrentSynchronousEvent (System.Boolean& sceneChanged) [0x0001d] in <d72310b4d8f64d25aee502792b58549f>:0 (Filename: C:\buildslave\unity\build\Runtime/Export/Debug/Debug.bindings.h Line: 35) ``` **Complete the following checklist** I hereby verify that I have done the following: - [x] Confirmed that my game version and load order are correct. - [x] Confirmed that I am running the appropriate and most updated version of Combat Extended and required compatibility patches. - [x] Confirmed I am not running any mods with known incompatibilities with Combat Extended. - [x] Disabled Combat Extended and attempted to reproduce the behavior without success. "
70507,78376,https://api.github.com/repos/RockinChaos/ItemJoin/issues/375,question,2021-03-11T18:25:07Z,NONE,https://api.github.com/repos/RockinChaos/ItemJoin,[Question] Stop moving of certain items in inventory? Hey! Is it at all possible to stop the movement of certain items within an inventory? Such as a star but they can move anything else. Many thanks.
179936,200036,https://api.github.com/repos/nextcloud/desktop/issues/264,bug,2018-04-24T09:06:45Z,NONE,https://api.github.com/repos/nextcloud/desktop,"Sync files problem Hi everybody, I use the version 13.0.1 of Nextcloud server & Nextcloud client for MacOSX 10.13.3 and I have a slight issue : this morning, a wonderful popup message appears to me ![capture d ecran 2018-04-24 a 10 19 19](https://user-images.githubusercontent.com/38652001/39176109-41dba6d6-47ac-11e8-949a-7dc4735cd17c.png) I think in English, it would says something like this : ![](https://help.nextcloud.com/uploads/default/original/2X/c/c28a31a2bfebb502becc4af4a334998a0d3686e9.png) I have deleted no folders on Nextcloud, so I don't get the message clearly. I am understanding it as in ""All the files contained in Nextcloud folder (which is the root folder) will be deleted"" but as I said before, I didn't do any big actions on the server. Thanks "
704662,783165,https://api.github.com/repos/LemmyNet/lemmy-ui/issues/290,bug,2021-05-05T14:15:42Z,NONE,https://api.github.com/repos/LemmyNet/lemmy-ui,"Community link on federated community post generates invalid URL I am using lemmy.ml, but viewing a community federated from lemmy.ca. For example: https://lemmy.ml/post/62739 The link `!canada@lemmy.ca` in the top right box, below the community name/logo and above the ""create a post"" button has an `href=""https://lemmy.ca/c/canada""` (which would be correct). However when I click on it the following URL is generated: https://lemmy.ml/post/https://lemmy.ca/c/canada Which eventually emits a 504 Gateway Time-out. This only happens when viewing federated, non-local, posts. "
450978,501215,https://api.github.com/repos/humhub/tasks/issues/153,bug,2021-05-05T13:12:35Z,CONTRIBUTOR,https://api.github.com/repos/humhub/tasks,Tests broken https://github.com/humhub/tasks/runs/2509286350?check_suite_focus=true#step:25:34 
399621,444157,https://api.github.com/repos/6bee/Remote.Linq/issues/76,enhancement,2020-10-09T16:06:20Z,NONE,https://api.github.com/repos/6bee/Remote.Linq,Missing ThenInclude for EF? Looks like there is no implementation for Then Include. I assume there is no work around and this is just a missing feature ?
428591,476435,https://api.github.com/repos/caprover/caprover/issues/1054,question,2021-03-18T21:19:05Z,NONE,https://api.github.com/repos/caprover/caprover,"How exactly should I configure the persistent storage for my node js app? I have my nodejs app running a database that uses `/store` folder to store data. How do I configure persistent storage in it? I've set 'Path in app' to `/store` and 'Path to host' to `/usr/store`. But after that the directory `usr/store` is still empty. In the docs example shows that the 'path in app' may be like `container/path` so I thought that some prefix like `container/` should be added. Or should I use the labeled option? I still need to figure out the right 'path in app' for that. Please, get me through )"
235312,261706,https://api.github.com/repos/eth-cscs/reframe/issues/1733,bug,2021-02-01T20:54:46Z,CONTRIBUTOR,https://api.github.com/repos/eth-cscs/reframe,"self.build_locally = False doesn't get a --time specification with Slurm based launching. using this config: ``` site_configuration = { 'systems': [ { 'name': 'kebnekaise', 'descr': 'Kebnekaise cluster', 'hostnames': ['b-'], 'modules_system': 'lmod', 'partitions': [ { 'name': 'bdw', 'descr': 'Broadwell compute nodes', 'scheduler': 'slurm', 'launcher': 'srun', 'access': ['-C broadwell', '-A sysop'], 'environs': ['gnu', 'intel'], 'resources': [ { 'name': 'tasks', 'options': ['-n {cores}'] }, ], }, ... } ``` And a test that does ``` self.build_locally = False ``` The build phase created slurm batch file lacks a --time specification, causing it to fail on our system since we require it to be specified."
717227,797128,https://api.github.com/repos/department-of-veterans-affairs/va.gov-team/issues/23630,bug,2021-04-22T14:48:33Z,MEMBER,https://api.github.com/repos/department-of-veterans-affairs/va.gov-team,"Bug roundup from staging and Sentry pass 1. Not falling back to clinic name if friendly name is missing 2. Back button on the clinic choice page in the primary/speciality appointment flow doesn’t work 3. The facility page shows an error if you choose a sleep or eye care option, have a single facility available for scheduling, and then change your type of sleep/eye care to the other option. Sentry error for last one: http://sentry.vfs.va.gov/organizations/vsp/issues/33895/events/6fd2fe00c4bc49388eb3c00743e56bca/?environment=production&project=4&query=is%3Aunresolved+vaos&statsPeriod=14d"
429733,477712,https://api.github.com/repos/rstudio/rstudio/issues/7988,bug,2020-10-07T09:03:53Z,NONE,https://api.github.com/repos/rstudio/rstudio,"Clearing Recent Project List <!-- IMPORTANT: Please fill out this template fully! Failure to do so will result in the issue being closed automatically. This issue tracker is for bugs and feature requests in the RStudio IDE. If you're having trouble with R itself or an R package, see https://www.r-project.org/help.html, and if you want to ask a question rather than report a bug, go to https://community.rstudio.com/. Finally, if you use RStudio Server Pro, get in touch with our Pro support team at support@rstudio.com. --> I do not know if this is a bug or an improvement but the problem is anoying. ### System details RStudio Edition : Desktop RStudio Version : 1.2.5019 OS Version : Windows 10 R Version : 3.6.0 ### Steps to reproduce the problem Open a Project in a Google File Stream Drive. -> Project is in the Recent Project List Close rstudio Close Google File Stream ->(Access to files is now impossible) Open rstudio -> Project is in the Recent Project List, but is not opened. Try to open the projet -> rstudio warnings you and deletes project from Recent Projet List (this is the problem) Open Google File Stream The recent project is no longer available. ### Describe the problem in detail The problem is that rstudio deletes automatically the project from list if the unit in which resides is not available. And this situation is very frequent when uses cloud filesystems. ### Describe the behavior you expected Maintain the recent project list even if the project is not available. <!-- Please keep the below portion in your issue, and check `[x]` the applicable boxes. --> - [x] I have read the guide for [submitting good bug reports](https://github.com/rstudio/rstudio/wiki/Writing-Good-Bug-Reports). - [x] I have installed the latest version of RStudio, and confirmed that the issue still persists. - [ ] If I am reporting a RStudio crash, I have included a [diagnostics report](https://support.rstudio.com/hc/en-us/articles/200321257-Running-a-Diagnostics-Report). - [x] I have done my best to include a minimal, self-contained set of instructions for consistently reproducing the issue. "
553223,614831,https://api.github.com/repos/fawohlsc/azure-policy-testing/issues/18,enhancement,2021-02-18T11:59:30Z,OWNER,https://api.github.com/repos/fawohlsc/azure-policy-testing,Improve test isolation Eliminate the problem of layering policies and parallel test runs by: - Defining the policies at a subscription with a unique name - Assigning policy to the dedicated resource group created per test 
215349,239460,https://api.github.com/repos/TerraFirmaCraft/TerraFirmaCraft/issues/1331,enhancement,2020-05-25T23:16:37Z,CONTRIBUTOR,https://api.github.com/repos/TerraFirmaCraft/TerraFirmaCraft,"TFCT: Metal items should heat faster in a hot crucible with enough liquid If an item is completely surrounded with hot metal, it will heat faster. I think this would be believable and useful. - TFC Version: build 140"
96355,107086,https://api.github.com/repos/NCEAS/metacat/issues/1280,bug,2018-09-10T21:58:57Z,CONTRIBUTOR,https://api.github.com/repos/NCEAS/metacat,"StackOverflow in Xerces on MNStorage.create() and then the calls hangs For some EML records with long geographicCoverage `geographicDescription` (see [gist](https://gist.github.com/amoeba/f250d1bc04ce82fb4fc68b4b32ec8528)), a POST to /object (MNStorage.create) never succeeds. catalina.out reports a StackOverflow in Xerces: ``` Exception in thread ""ajp-bio-8009-exec-37"" java.lang.StackOverflowError at org.apache.xerces.impl.xpath.regex.RegularExpression.matchString(Unknown Source) ...continues infinitely ``` It appears that a 7000 character description is fine but a 7499 character one doesn't. I suspect that's diagnostically helpful. A gist'ed a portion of catalina.out along with the offending EML record: https://gist.github.com/amoeba/f250d1bc04ce82fb4fc68b4b32ec8528 A 7499-character `geographicDescription` is long, but I think not entirely unreasonable so it'd be nice to see the behavior here be that the call either succeed or fail, rather than hangs seemingly indefinitely. I saw this behavior on dev.nceas if that's helpful in debugging and did the `MNStorage.create` from R with `arcticdatautils::publish_object(...)`."
639906,711213,https://api.github.com/repos/truecharts/apps/issues/507,bug,2021-05-24T17:41:51Z,MEMBER,https://api.github.com/repos/truecharts/apps,[All] Persitence GUI using the wrong storageClass All Recent versions use a wrong storageClass in the persistence GUI
235951,262431,https://api.github.com/repos/cloud-barista/cb-tumblebug/issues/538,bug,2021-05-24T08:39:28Z,MEMBER,https://api.github.com/repos/cloud-barista/cb-tumblebug,"Restriction on TB objects' `name` vs. AWS flavors <!-- Thanks for filing an issue! Before submitting, please fill in the following information. --> **What happened** : AWS flavor 의 이름이 `m6g.medium` 와 같은 형식을 갖고 있음. 이 flavor들을 TB에서 fetch 하니 에러가 발생함. (관련: https://github.com/cloud-barista/cb-tumblebug/pull/527#issuecomment-844724821) `❯ ./fetch-specs.sh aws 1 jhseo` ``` [CLOUD-BARISTA].[ERROR]: 2021-05-24 17:25:41 common.go:1205, github.com/cloud-barista/cb-tumblebug/src/core/mcir.CheckResource() - aws-ap-southeast-1-m6g.medium: The first character of name must be a lowercase letter, and all following characters must be a dash, lowercase letter, or digit, except the last character, which cannot be a dash. ``` **What you expected to happen** : **How to reproduce it (as minimally and precisely as possible)** : **Anything else we need to know?** : **Environment** - Source version or branch: - OS: - Others: **Proposed solution** : 1. Restriction 을 약간 느슨하게 하여, 마침표도 허용한다. (=> not recommended) 1. 전체적으로 2. TB Spec name 에 대해서만 2. 마침표를 다른 문자 (예: 하이픈) 로 변환하는 로직을 넣는다. 1. 전체적으로 (=> not recommended) 2. TB Spec name 에 대해서만 (예: `func ConvertSpiderSpecToTumblebugSpec`) **Any other context** : Image 에 대해서도 비슷한 현상이 발생할 가능성이 있음 "
31812,35435,https://api.github.com/repos/Bridgeconn/VachanAppReact/issues/52,bug,2020-12-29T14:49:57Z,COLLABORATOR,https://api.github.com/repos/Bridgeconn/VachanAppReact,"Parallel Bible :The color tray that displays for highlighting in the first pane is still visible upon selecting another book in the parallel Bible view Issue description: The color tray that displayed for highlighting in the single pane , is still visible, upon selecting a new book in the parallel Bible view Steps: From the App, select a verse from a Bible passage Now the color tray displays for the purpose of highlighting. Select the parallel Bible option, choose another book in the second pane. Observation : The color tray that displayed for highlighting in the first pane is still visible upon selecting another book in the parallel Bible view Expected result: Since the highlight option is not functional in the parallel view, t ![VG-The color tray should not be visible in the parallel Bible view](https://user-images.githubusercontent.com/74647279/103292080-24f80480-4a13-11eb-97d7-f1de08394a52.jpg) he color tray should not be visible in the parallel Bible view"
80976,90020,https://api.github.com/repos/jblancov7764/git_web_practice/issues/1,bug,2021-02-12T01:59:14Z,NONE,https://api.github.com/repos/jblancov7764/git_web_practice,"ISSUE 1: Corrección de páginas 5 y 3 ### Identificador de corrección: `FIX1` ### Errores a corregir: - En `pagina5.html`. La imagen y el título de la página no corresponden. - En `pagina3.html`. El link a la página siguiente apunta a una dirección equivocada. ### Soluciones: - En `pagina5.html`, cambiar la ruta de la imagen con id `imagen5` por `../imagenes/BD5.gif` y el texto del título con id `titulo5` por `Mi quinta página HTML`. - En `pagina3.html`, cambiar el link de navegación con id `enlace3` por `pagina4.html` y colocarle el nombre correcto `Mi cuarta página HTML`."
475181,528103,https://api.github.com/repos/compiler-explorer/compiler-explorer/issues/2611,bug,2021-04-18T07:34:45Z,MEMBER,https://api.github.com/repos/compiler-explorer/compiler-explorer,"[BUG] When linking with clang and libc++ under nsjail -pthread is required https://godbolt.org/z/snn7GT39Y The above code should work, but does not. When running CE locally using firejail or no sandboxing it does work, which indicates something is going on with the environment inside nsjail that causes `-pthread` to be required."
499494,555170,https://api.github.com/repos/rowanmanning/audrey/issues/36,bug,2021-01-09T13:22:58Z,OWNER,https://api.github.com/repos/rowanmanning/audrey,Missing Images There's a formatting issue for the entry [Sick Note](https://leemoody.co.uk/blog/weeknotes/16/): the two images on this entry don’t display in Audrey. Looking at the HTML vs XML the images have different URLs. ## Debugging information **Audrey version:** `2.0.0-beta.9` **Feed URL:** <https://leemoody.co.uk/blog/feed.xml>
694676,772113,https://api.github.com/repos/PREreview/prereview/issues/325,bug,2021-04-20T18:30:22Z,MEMBER,https://api.github.com/repos/PREreview/prereview,The notification and email display toggle still doesn't work properly @rudietuesdays @harumhelmy I'm still having issues with the toggles on the profile settings. When I activate/deactivate one it triggers the other.
699753,777717,https://api.github.com/repos/mvisonneau/gitlab-ci-pipelines-exporter/issues/219,bug,2021-01-22T02:54:57Z,NONE,https://api.github.com/repos/mvisonneau/gitlab-ci-pipelines-exporter,"json: cannot unmarshal array into Go value of type gitlab.Project I am getting error when trying to see pod logs and metrics are not coming Note: have added all projects and using wild card, would you ``` # projects: # - name: foo/project # - name: bar/project # wildcards: # - owner: # name: foo # kind: group ``` Error: {""error"":""json: cannot unmarshal array into Go value of type gitlab.Project"",""level"":""warning"",""msg"":""pulling refs from project"",""project-name"":"""",""time"":""2021-01-22T02:49:01Z""}"
359584,399769,https://api.github.com/repos/alltheplaces/alltheplaces/issues/1796,bug,2021-05-21T20:25:21Z,COLLABORATOR,https://api.github.com/repos/alltheplaces/alltheplaces,Spider ${spider} is broken ${issue_body}
214294,238299,https://api.github.com/repos/facebookresearch/faiss/issues/1741,enhancement,2021-03-05T22:25:19Z,CONTRIBUTOR,https://api.github.com/repos/facebookresearch/faiss,"RFC: replace {Long,LongLong,...}Vector with {Int32,Int64,...}Vector (with deprecation) In trying to get `faiss-gpu` to work with windows (cf. #1586), I'm hitting a couple of points where the different architectures collide. One of the main points about this revolves about what types `int`, `long` and `long long` actually correspond to on the respective platforms. Since these types are - sadly - fundamentally not cross-platform compatible, it is a bit unfortunate that the SWIG interface currently defines `IntVector`, `LongVector`, `LongLongVector`. For reasons of portability, I therefore wanted to suggest to deprecate these names and replace them with something unambiguous, e.g: * `CharVector` -> `Int8Vector` * `IntVector` -> `Int32Vector` * `LongVector` -> `Int32Vector if sizeof_long == 4 else Int64Vector` * `LongLongVector` -> `Int64Vector` * `ByteVector` -> `UInt8Vector` * `FloatVector` -> `Float32Vector` * `DoubleVector` -> `Float64Vector` This is the maximal reasonable set of renames/deprecations (`Int16Vector`, `UInt16Vector`, `UInt32Vector`, `UInt64Vector` exist already), and arguably not all of the names on the left _need_ to be deprecated. However, the uniform naming structure and intrinsic match with the underlying bit-width (as well as the numpy-types) is something that would IMO also substantially reduce the cognitive burden of figuring out what object one is working with (""what was `long` again on this system?""; or not knowing that `char` or `byte` correspond to integer types). I have a solution for doing exactly that which I believe is fairly elegant and unobtrusive - essentially generating wrapper classes around the equivalent non-deprecated versions in `__init__.py`, with the only difference that they raise a `DeprecationWarning` _once_ per session (if called). The advantage of this is that this can be done in pure python, and doesn't need any surgery on the SWIG interface. If desired, I can post the patches directly, but wanted to first get a feel if this would be welcome. WDYT @wickedfoo @beauby @mdouze?"
564302,627116,https://api.github.com/repos/PodcastGenerator/PodcastGenerator/issues/383,bug,2020-12-20T17:49:43Z,NONE,https://api.github.com/repos/PodcastGenerator/PodcastGenerator,Wrong bootstrap URL in default theme IS - https://getbootstrap.org/ SHOULD - https://getbootstrap.com/
551677,613133,https://api.github.com/repos/test-it-edu/notebook/issues/9,bug,2020-10-09T15:44:59Z,CONTRIBUTOR,https://api.github.com/repos/test-it-edu/notebook,"Sometimes `Backspace` won't remove characters Not able to use the `Backspace` key when a Notebook is loaded and the cursor is set. If you type a letter first, and then try to use the `Backspace` key characters will be removed correctly."
654903,727971,https://api.github.com/repos/the-parkers/playGround/issues/44,enhancement,2021-05-17T16:01:28Z,CONTRIBUTOR,https://api.github.com/repos/the-parkers/playGround,Features of user profile page - [x] Can Edit profile attributes - [x] Shows users favorited parks - [x] Shows Events made by that user 
670403,745132,https://api.github.com/repos/Tedeapolis/development/issues/443,enhancement,2021-03-03T16:51:10Z,NONE,https://api.github.com/repos/Tedeapolis/development,"Vliegtuig dodo **Beschrijf zo duidelijk mogelijk de feature** Ik ben er zojuist achter gekomen dat er 400kg in een dodo kan **Wat lost deze feature op?** het is niet echt realistisch vergeleken met het duurste vliegtuig (miljet) waar 300kg in kan en 10 keer zo duur is heb het vergeleken met een hoop anderen vliegtuigen en deze kwam bovenaan, mij lijkt 150kg beter."
118815,132020,https://api.github.com/repos/GeoStat-Framework/GSTools/issues/99,enhancement,2020-08-07T15:30:22Z,NONE,https://api.github.com/repos/GeoStat-Framework/GSTools,"Perform Local Kriging by specifying maximum number of nearest observations I am searching for a way in GSTools to perform local kriging. Basically, I want to specify the maximum number of nearest observations used for the kriging estimation at any point. Similar to `nmax` in gstat R package: https://www.rdocumentation.org/packages/gstat/versions/2.0-6/topics/krige Is this possible? When searching the thread, I saw issue #50 which is sort of related, but not exactly. Thanks in advance! "
705524,784133,https://api.github.com/repos/nextcloud/android/issues/7792,bug,2021-01-07T22:06:50Z,NONE,https://api.github.com/repos/nextcloud/android,"timestamps aren't preserved when uploading (in 2020/21) Basically the same as in ""timestamps aren't preserved when uploading #1433 "" ### Steps to reproduce 1. Upload file via Android-app (I used the automatic-upload option and synced a whole folder) 2. Upload the same file via browser (I used Chrome, for the record) 3. Compare modified date. ### Expected behavior The modified date should be the same - the actual modified date. ### Actual behavior The file uploaded via the app shows the upload date. The file uploaded via the browser shows the actual modified date (mtime afaik). ### Environment data Android version: 9 Device model: H3113 Stock or customized system: stock Nextcloud app version: 3.14.1 (from F-Droid) Nextcloud server version: 20.0.4 (docker:fpm) ### Logs Needed? "
470414,522823,https://api.github.com/repos/opentelekomcloud/terraform-provider-opentelekomcloud/issues/940,enhancement,2021-03-26T21:18:32Z,CONTRIBUTOR,https://api.github.com/repos/opentelekomcloud/terraform-provider-opentelekomcloud,"[CCE] Increase Timeout (or decrease deployment time) <!-- Hi there, thank you for opening an issue. --> # Terraform Version <!-- Run `terraform -v` to show the version. If you are not running the latest version of Terraform, please upgrade because your issue may have already been fixed. --> Terraform v0.14.7 - Using previously-installed opentelekomcloud/opentelekomcloud v1.23.4 # Affected Resource(s) - opentelekomcloud_cce_cluster_v3 # Terraform Configuration Files ```hcl # Set required Provider (source and version) terraform { required_providers { opentelekomcloud = { source = ""opentelekomcloud/opentelekomcloud"" version = "">= 1.23.4"" } } } # Configure OpenTelekomCloud VPC subnet resource ""opentelekomcloud_vpc_subnet_v1"" ""cce_cluster_subnet"" { name = ""indicarus-cce-cluster-subnet"" vpc_id = var.indicarus_vpc_id cidr = var.cce_cluster_subnet_cidr gateway_ip = var.cce_cluster_subnet_gateway_ip tags = { terraform = ""true"" } } # Configure OpenTelekomCloud network security group resource ""opentelekomcloud_networking_secgroup_v2"" ""cce_cluster_sg"" { name = ""indicarus-cce-cluster-sg"" description = ""Security group for a CCE cluster."" } # Configure OpenTelekomCloud network security group rule resource ""opentelekomcloud_networking_secgroup_rule_v2"" ""cce_cluster_sg_rule"" { direction = ""ingress"" ethertype = ""IPv4"" protocol = ""tcp"" port_range_min = 9998 port_range_max = 9998 remote_ip_prefix = ""0.0.0.0/0"" security_group_id = opentelekomcloud_networking_secgroup_v2.cce_cluster_sg.id } # Configure OpenTelekomCloud EIP resource ""opentelekomcloud_vpc_eip_v1"" ""cce_cluster_eip"" { publicip { type = ""5_bgp"" } bandwidth { name = ""indicarus-cce-cluster-bandwidth"" size = var.cce_cluster_eip_bandwidth_size share_type = ""PER"" charge_mode = ""traffic"" } } # Configure OpenTelekomCloud CCE cluster resource ""opentelekomcloud_cce_cluster_v3"" ""cce_cluster"" { name = ""indicarus-cce-cluster"" description = ""Kubernetes cluster to run Tika Server."" cluster_type = ""VirtualMachine"" flavor_id = var.cce_cluster_flavor cluster_version = var.cce_cluster_version vpc_id = var.indicarus_vpc_id subnet_id = opentelekomcloud_vpc_subnet_v1.cce_cluster_subnet.id container_network_type = ""overlay_l2"" authentication_mode = var.cce_cluster_authentication_mode eip = opentelekomcloud_vpc_eip_v1.cce_cluster_eip.publicip[0].ip_address } # Configure OpenTelekomCloud compute keypair resource ""opentelekomcloud_compute_keypair_v2"" ""cce_node_pool_keypair"" { name = ""indicarus-cce-node-pool-keypair"" public_key = var.cce_node_pool_keypair_public_key } # Configure OpenTelekomCloud CCE node pool resource ""opentelekomcloud_cce_node_pool_v3"" ""cce_node_pool"" { cluster_id = opentelekomcloud_cce_cluster_v3.cce_cluster.id name = ""indicarus-cce-node-pool"" os = var.cce_node_pool_os flavor = var.cce_node_pool_flavor initial_node_count = var.cce_node_pool_initial_node_count subnet_id = opentelekomcloud_vpc_subnet_v1.cce_cluster_subnet.id availability_zone = var.cce_node_pool_availability_zone key_pair = opentelekomcloud_compute_keypair_v2.cce_node_pool_keypair.name scale_enable = true min_node_count = var.cce_node_pool_min_node_count max_node_count = var.cce_node_pool_max_node_count scale_down_cooldown_time = var.cce_node_pool_scale_down_cooldown_time priority = 1 root_volume { size = var.cce_node_pool_root_volume_size volumetype = var.cce_node_pool_root_volumetype } data_volumes { size = var.cce_node_pool_data_volumes_size volumetype = var.cce_node_pool_data_volumetype } } ``` # Debug Output/Panic Output ![image](https://user-images.githubusercontent.com/13590797/112692925-04a7dc80-8e80-11eb-9a91-7576c2fe43bd.png) # Steps to Reproduce 1. `terraform apply` // any cce cluster # Expected Behavior Should be successful on first try. # Actual Behavior Fails. # Important Factoids <!-- Are there anything atypical about your accounts that we should know? For example: Which version of OpenTelekomCloud? Tight ACLs. --> # References <!-- Are there any other GitHub issues (open or closed) or Pull Requests that should be linked here? For example: - GH-1234 - #2546 --> "
487061,541306,https://api.github.com/repos/vapor/leaf-kit/issues/89,enhancement,2021-02-15T20:14:23Z,NONE,https://api.github.com/repos/vapor/leaf-kit,"Hashtag character is not allowed to start the value of a data attribute The `#` character is not allowed to start the value of a `data-*` attribute. For instance `data-foo=""#bar""` renders as `data-foo=""""`. ### To Reproduce Simply add a `data-*` attribute that has the `#` as the first character. ### Expected behavior If I add `data-foo=""#bar""` I expect `data-foo=""#bar""` to be rendered in the final HTML. ### Environment * Vapor Framework version: 4.39.2 * Vapor Toolbox version: 18.3.0 * OS version: Big Sur 11.2.1"
325376,361705,https://api.github.com/repos/VolmitSoftware/React/issues/592,bug,2021-03-13T11:48:05Z,NONE,https://api.github.com/repos/VolmitSoftware/React,"repo.volmit.com is down **Describe the bug** A clear and concise description of what the bug is. no dependencies can be retrieved with gradle. errors indicate that it cannot contact repo.volmit.com **To Reproduce** Steps to reproduce the behavior: 1. run 'gradle build' at the root folder 2. wait about half a minute 3. look at something similar to [this](https://pastebin.com/ifs9PjUE) **Expected behavior** A clear and concise description of what you expected to happen. for the project to successfully compile. **Screenshots or Video Recordings** If applicable, add screenshots or video recordings to help explain your problem. **Server and Plugin Informations** - Installed plugins: N/A - React Version: latest available from this repo - Server Platform and Version [eg: PaperSpigot 1.14.4]: N/A - Operating System (if applicable): Windows 10 **Additional context** Add any other context about the problem here, server timings reports, React dump information, complete console log etc. Please do not make Pastebin dumps or screenshot expire. "
226551,251946,https://api.github.com/repos/rl-institut/multi-vector-simulator/issues/687,bug,2020-12-07T14:42:11Z,MEMBER,https://api.github.com/repos/rl-institut/multi-vector-simulator,"[Bug] Error log message when running a simulation (""*_pdp_bus has too few assets connected to it"") `ERROR-Energy system bus Electricity (DSO)_pdp_bus has too few assets connected to it. The minimal number of assets that need to be connected so that the bus is not a dead end should be two, excluding the excess sink. These are the connected assets: Electricity_grid_DSO_consumption` I receive the above log message when I run a simulation with the Norway harbor inputs. The simulation is running successfully. Checklist to make sure that the bug report ist complete: - [x] OS: Xubuntu 18.4 - [x] Branch: fix/storage_in_autoreport, updated now - [ ] If applicable: Attach full error message - [ ] If applicable: Share screenshots/images of your problem - [ ] If applicable: Share used input data "
288842,321207,https://api.github.com/repos/AY2021S2-CS2103T-T12-1/tp/issues/94,enhancement,2021-03-29T16:01:30Z,NONE,https://api.github.com/repos/AY2021S2-CS2103T-T12-1/tp,Adding Select Command Added Select Command
88753,98654,https://api.github.com/repos/whimsicalraps/wslash/issues/58,bug,2021-02-04T16:31:50Z,MEMBER,https://api.github.com/repos/whimsicalraps/wslash,"clicks in tape/delay loops 1) get the wphase update working identically to write_ix style. regression test against previous released beta 2) print wphase & rphase upon `jumpto`, and print continuing vals for the remainder of the frame (both wphase & wphase_1) 3) refactor to track wphase.i attached to out_buf (make it a composite type) -> don't use wphase.i (or a history), but rather the attached timestamp directly -> confirm this works identically 4) remove REC_OFFSET and instead delay out_buf access by 2 & round-robin through"
541657,602032,https://api.github.com/repos/facebookresearch/fairscale/issues/655,question,2021-05-05T14:42:52Z,NONE,https://api.github.com/repos/facebookresearch/fairscale,Controlling tiling/parallelism of individual layers ## ❓ Questions and Help How does one control tiling/parallelism of individual layers? 
441169,490455,https://api.github.com/repos/gavinIRL/DCW/issues/38,bug,2021-03-22T13:53:48Z,OWNER,https://api.github.com/repos/gavinIRL/DCW,Fix concat and volume calc bugs in csv logger Fix concat and volume calc bugs in csv logger
158294,175989,https://api.github.com/repos/dinerojs/dinero.js/issues/202,bug,2021-01-21T17:52:01Z,NONE,https://api.github.com/repos/dinerojs/dinero.js,"using toFormat correctly (question) This is a question rather than a bug. I'm currently successfully using the lib for USD like so: ``` const Dinero = require('dinero.js') const amount = 100 // representing smallest minor units i.e cents const currency = 'USD' const standardUnitAmount = Dinero({ amount, currency }).toFormat('0,0.00') console.log(standardUnitAmount) ``` However, I want to be able to format the amount value to the standard unit of the any currency. Example when the top code doesn't work: ``` const Dinero = require('dinero.js') const amount = 100 // representing smallesr minor units i.e yen const currency = 'JPY' const standardUnitAmount = Dinero({ amount, currency }).toFormat('0,0.00') console.log(standardUnitAmount) ``` for Japanese yen that doesn't have sub-units the top code will incorrectly return 1.00 My main question thus is how can i always format the smallest minor units currency amount to the standard units of that currency. is is possible to detect minor units of currency and format it using that value? My current solution is using list of minor units from iso 4217 list and setting precision for each dinero object like so: `Dinero({ amount, currency, precision: iso_4217_minor_unit })` "
1330,1474,https://api.github.com/repos/AnthorNet/SC-InteractiveMap/issues/15,bug,2021-01-02T10:32:19Z,OWNER,https://api.github.com/repos/AnthorNet/SC-InteractiveMap,"Unlocking MAM schematics should unlock the corresponding research tree Persistent_Level:PersistentLevel.ResearchManager > Properties: ```js name: ""mUnlockedResearchTrees"" type: ""ArrayProperty"" value: type: ""ObjectProperty"" values: Array(10) 0: {levelName: """", pathName: ""/Game/FactoryGame/Schematics/Research/BPD_ResearchTree_Nutrients.BPD_ResearchTree_Nutrients_C""} 1: {levelName: """", pathName: ""/Game/FactoryGame/Schematics/Research/BPD_ResearchTree_AlienOrganisms.BPD_ResearchTree_AlienOrganisms_C""} 2: {levelName: """", pathName: ""/Game/FactoryGame/Schematics/Research/BPD_ResearchTree_PowerSlugs.BPD_ResearchTree_PowerSlugs_C""} 3: {levelName: """", pathName: ""/Game/FactoryGame/Schematics/Research/BPD_ResearchTree_FlowerPetals.BPD_ResearchTree_FlowerPetals_C""} 4: {levelName: """", pathName: ""/Game/FactoryGame/Schematics/Research/BPD_ResearchTree_Sulfur.BPD_ResearchTree_Sulfur_C""} 5: {levelName: """", pathName: ""/Game/FactoryGame/Schematics/Research/BPD_ResearchTree_Quartz.BPD_ResearchTree_Quartz_C""} 6: {levelName: """", pathName: ""/Game/FactoryGame/Schematics/Research/BPD_ResearchTree_Caterium.BPD_ResearchTree_Caterium_C""} 7: {levelName: """", pathName: ""/Game/FactoryGame/Schematics/Research/BPD_ResearchTree_HardDrive.BPD_ResearchTree_HardDrive_C""} 8: {levelName: """", pathName: ""/Game/FactoryGame/Schematics/Research/BPD_ResearchTree_Mycelia.BPD_ResearchTree_Mycelia_C""} 9: {levelName: """", pathName: ""/Game/FactoryGame/Schematics/Research/BPD_ResearchTree_XMas.BPD_ResearchTree_XMas_C""} ``` "
648922,721309,https://api.github.com/repos/odamex/odamex/issues/346,bug,2021-05-10T14:35:56Z,MEMBER,https://api.github.com/repos/odamex/odamex,"Remove vanilla demo recording support **Describe the bug** Odamex supports demoplayback in a very good way, as 9 demos out of 10 can be playbacked without any major issues or desynchronization. However, recording a vanilla demo gives way more problems than imagined, with many possible cases of desyncs due to how Odamex handles a few commands/physics/CVARs. Since it's definitely not 100% vanilla-capable and definitely unusable by speedrunners, I don't see why we should keep it any longer. **Build that the bug occurred in** Any since vanilla demorecording was introduced. "
375305,417206,https://api.github.com/repos/vdesabou/kafka-docker-playground/issues/331,bug,2021-03-18T16:10:06Z,OWNER,https://api.github.com/repos/vdesabou/kafka-docker-playground,🐛❌ connect-connect-salesforce-sobject-sink Version: 1.7.16 🔗 Link to test: //actions/runs/
517580,575193,https://api.github.com/repos/nextcloud/cookbook/issues/481,bug,2021-01-08T12:37:27Z,NONE,https://api.github.com/repos/nextcloud/cookbook,"Cannot create new recipe since the last update **Description** Cannot create a new recipe (won't save) since the last update. Also cannot add Tools, Ingredients and instructions when is push add new it does not provide a new field (only with new recipes). I can import a new recipe and adjust it completely through the URL add option. **Reproduction** Steps to reproduce the behavior: 1. new recipe 2. populate recipe 3. no Tools, ingredients or Instructions can be added (no field appears when pushing add) 4. New recipe will not save **Expected behavior** Saving the new recipe **Browser** In Chrome, IE and Firefox "
566659,629716,https://api.github.com/repos/solec0der/iact-check/issues/7,enhancement,2020-12-30T18:00:59Z,OWNER,https://api.github.com/repos/solec0der/iact-check,"Add separate branding page per customer it should be possible to configure, how the initial customer page looks like. Maybe prepare 3 different layouts. also the whole branding (colours, logo, font) should be in this branding page. "
371191,412633,https://api.github.com/repos/OpenSID/OpenSID/issues/4165,bug,2021-04-30T12:47:51Z,NONE,https://api.github.com/repos/OpenSID/OpenSID,"Cetak Buku Administrasi Umum - Buku Agenda - Surat Masuk [BUG] **Jelaskan error yg dialami** <!-- Pada saat mencetak Laporan Buku Agenda - Surat Masuk pada tempat tanda tangan kepala desa yg muncul bukan nama kepala desa yang dipilih yg terdapat dalam system ini. ![image](https://user-images.githubusercontent.com/64481641/116696912-b04acc00-a9ec-11eb-8006-0876f71e407e.png) Harap tidak melaporkan masalah instal OpenSID. Masalah pada waktu install harap ditanyakan di https://www.facebook.com/groups/OpenSID atau di https://t.me/joinchat/SI0GWHeqKT39Gxhh, karena terkait sistem masing2 pengguna. Berikan keterangan yg jelas dan singkat mengenai error yg dialami. Pastikan error ini juga ditemukan di https://demo.opensid.or.id (untuk RIlis Umum) atau di https://berputar.opensid.or.id (untuk RIlis Premium). --> V21.04 Premium-Pasca **Cara untuk mereplikasi errornya** <!-- Agar sesuai dengan yg diinginkan atau yg menanda tangan kepala desa yg di pilih Langkah untuk mereplikasi error yg dialami, misalnya: 1. Pergi ke halaman '...' 2. Klik tombol '....' 3. Gulir ke bawah sampai '....' 4. Lihat error --> **Hasil yg diharapkan** <!-- Agar dalam laporan buku Agenda Surat Masuk sesuai dengan yg diinginkan Berikan keterangan yg jelas dan singkat apa hasil yg diharapkan. --> **Tampakan layar dan log error** <!-- Lampirkan tampakan layar yg menjelaskan permasalahan. Lampirkan isi file di folder `logs` atau tampakan error di console inspector browser. --> **Versi OpenSID** <!-- Error ini terjadi di rilis/versi berapa: Rilis umum (mis. v21.03) atau premium (v21.03-premium)? --> **Tema Yg Digunakan** <!-- Sebutkan tema dan versinya yg digunakan --> **Informasi tambahan** <!-- Penjelasan lain yg dapat membantu. --> "
420865,467829,https://api.github.com/repos/firefly-iii/firefly-iii/issues/4199,bug,2020-12-30T09:32:00Z,CONTRIBUTOR,https://api.github.com/repos/firefly-iii/firefly-iii,"Unable to update tags using API **Bug description** I am running Firefly III version 5.4.6, and my problem is: I am unable to update tags from the API. Updating tags via the web interface works though. **Steps to reproduce** 1. Create tag ``` curl -X POST ""https://demo.firefly-iii.org/api/v1/tags"" -H ""accept: application/json"" -H ""Authorization: Bearer xxxx"" -H ""Content-Type: application/json"" -d ""{\""tag\"":\""some tag\"",\""date\"":\""2018-09-17\"",\""description\"":\""Some description\"",\""latitude\"":37.276675,\""longitude\"":-115.798936,\""zoom_level\"":6}"" ``` 2. Update tag ``` curl -X PUT ""https://demo.firefly-iii.org/api/v1/tags/2"" -H ""accept: application/json"" -H ""Authorization: Bearer xxxxx"" -H ""Content-Type: application/json"" -d ""{\""tag\"":\""some tag\"",\""date\"":\""2018-09-17\"",\""description\"":\""Some description\"",\""latitude\"":38.8977,\""longitude\"":77.0365,\""zoom_level\"":6}"" ``` This is tested on my personal instance since the API playground isn't working for me. "
658407,731844,https://api.github.com/repos/sbb-design-systems/sbb-angular/issues/798,bug,2021-04-28T20:48:13Z,NONE,https://api.github.com/repos/sbb-design-systems/sbb-angular,Bug: business stackblitz examples throw error https://stackblitz.com/angular/nndgexjynej?file=src%2Fapp%2Fforms-chip-input-example.ts throws Error Error in /turbo_modules/@sbb-esta/angular-business@11.1.3/bundles/angular-business-header.umd.js (1018:17) SbbHeader is not defined
481102,534691,https://api.github.com/repos/ryanheise/just_audio/issues/296,enhancement,2021-02-03T10:38:37Z,NONE,https://api.github.com/repos/ryanheise/just_audio,"Show Online Radio Stream's Now Playing Info at Notification <!-- PLEASE READ CAREFULLY! FOR YOUR FEATURE REQUEST TO BE PROCESSED, YOU WILL NEED TO FILL IN ALL SECTIONS BELOW. DON'T DELETE THE HEADINGS. THANK YOU :-D --> **Is your feature request related to a problem? Please describe.** Is there a way to show now playing info at notification area when palying an online radio stream by getting info from seperate online radio api. **Describe the solution you'd like** N/A **Describe alternatives you've considered** N/A **Additional context** N/A "
568522,631807,https://api.github.com/repos/express-validator/express-validator/issues/866,question,2020-05-01T18:09:36Z,NONE,https://api.github.com/repos/express-validator/express-validator,"How can I terminate all validation chains in case of error I have some validation chains as such; ``` body('firstName') .notEmpty() .withMessage('first name is required') .trim() .isLength({ min: 2, max: 25 }) .withMessage('first name must be between 2 to 25 characters'), body('lastName') .notEmpty() .withMessage('last name is required') .trim() .isLength({ min: 2, max: 25 }) .withMessage('last name must be between 2 to 25 characters') and so on... ``` How do I (probably using a custom validation) terminate the check for `body('lastName')` and the following chains if there are any errors? "
507947,564520,https://api.github.com/repos/geocollections/geokirjandus/issues/119,enhancement,2021-04-18T16:54:21Z,MEMBER,https://api.github.com/repos/geocollections/geokirjandus,"Add citation style Add Harvard citation style for users to select, after APA style."
593899,660041,https://api.github.com/repos/anhdtqwerty/thpt/issues/106,bug,2021-04-23T03:28:37Z,COLLABORATOR,https://api.github.com/repos/anhdtqwerty/thpt,"Danger | Danh sách hs | Bộ lọc | Lọc theo ""Ngày sinh"" Lọc theo """"Ngày sinh"""" 1. Điền định dạng ngày/tháng sinh hoặc chỉ nhập ngày sinh vào trường ""Ngày sinh"" (ví dụ: 29/12 hoặc ngày 29) 2. Bấm ""Tìm kiếm"" Actual: Không hiển thị kết quả tìm kiếm Expect: Hiển thị danh sách học sinh có trùng ngày sinh hoặc ngày/ tháng sinh muốn tìm kiếm <img width=""1019"" alt=""Lọc ngày sinh 1"" src=""https://user-images.githubusercontent.com/82717419/115813986-6c6d2b00-a41e-11eb-9db1-186b7cb2b581.png""> <img width=""1009"" alt=""Lọc ngày sinh 2"" src=""https://user-images.githubusercontent.com/82717419/115813995-71ca7580-a41e-11eb-9241-48afff00df6b.png""> "
290009,322490,https://api.github.com/repos/leoelias023/client-ifoodapi/issues/11,enhancement,2021-03-13T04:38:00Z,OWNER,https://api.github.com/repos/leoelias023/client-ifoodapi,"Configurar logs da aplicacao ### Tipo <!-- Obrigatório - (Problema, Melhoria, Nova funcionalidade) --> Nova funcionalidade ### Porque dessa ISSUE? <!-- Obrigatório - Exemplo: precisamos de logs para validar problemas --> Necessaria pois a aplicacao precisará de uma biblioteca padrão para adicionar logs em situações especificas. "
441282,490575,https://api.github.com/repos/airyhq/airy/issues/1323,bug,2021-03-22T14:15:12Z,CONTRIBUTOR,https://api.github.com/repos/airyhq/airy,minikube -p airy-core destroy doesn't exist it's `delete`
511795,568781,https://api.github.com/repos/TriageCapacityPlanning/Triage-Testable-Artifact/issues/38,enhancement,2021-03-08T03:01:03Z,NONE,https://api.github.com/repos/TriageCapacityPlanning/Triage-Testable-Artifact,"Date picker on Interval Prediction page allows infinitely distant dates **Description:** The **Prediction Intervals** date picker on the **Interval Prediction** page allows the user to scroll infinitely far forwards or backwards. Once you reach the year 0, the years begin counting back up, despite not denoting *B.C.E.* in the field when selected: ![image](https://user-images.githubusercontent.com/32877366/110268211-4df6c180-7f8f-11eb-87b7-97edcd72185b.png) ![image](https://user-images.githubusercontent.com/32877366/110268219-53540c00-7f8f-11eb-807b-d5372e9b7b1c.png) ![image](https://user-images.githubusercontent.com/32877366/110268239-58b15680-7f8f-11eb-9bbf-aa767adff4f6.png) However, scrolling forward does not appear to have a limit: ![image](https://user-images.githubusercontent.com/32877366/110268457-a9c14a80-7f8f-11eb-9187-ee07f499889a.png) Furthermore, this allows the user to select an infinitely large interval: ![image](https://user-images.githubusercontent.com/32877366/110268676-13415900-7f90-11eb-9d36-a1171fdd001e.png) ![image](https://user-images.githubusercontent.com/32877366/110268690-1a686700-7f90-11eb-96e7-c5be8384b29c.png) Submitting such an interval does product **Prediction Results**, but the results seem to have dates unrelated to the selected interval: ![image](https://user-images.githubusercontent.com/32877366/110268885-7632f000-7f90-11eb-8e62-a506a04c3951.png) And this submission is accompanied by two console errors: ![image](https://user-images.githubusercontent.com/32877366/110268785-471c7e80-7f90-11eb-9a4e-d65eadbb8fa0.png) ![image](https://user-images.githubusercontent.com/32877366/110268807-500d5000-7f90-11eb-9def-f96af14af05a.png) **Severity:** Low **OS:** Windows 10 Enterprise **Browser:** Chrome 89.0.4389.82 **Steps to Replicate:** - Launch the webapp - Navigate to **Interval Prediction** - Open the **Prediction Intervals** date picker - Scroll infinitely far forward or backward"
662170,736024,https://api.github.com/repos/corona-warn-app/cwa-app-android/issues/2857,bug,2021-04-17T17:45:05Z,CONTRIBUTOR,https://api.github.com/repos/corona-warn-app/cwa-app-android,"Create QR code card's image not clipped to padding ### Describe the bug The button's location in the QR code card does not depend on the image. This means that depending on screen width and font size, the background image can appear behind the button (in contrast to all other cards). ![image](https://user-images.githubusercontent.com/16943720/115121672-4a098680-9fb4-11eb-8e36-7d66d5794547.png) ### Steps to reproduce the issue Set Font Size to small in the settings. ### Expected behaviour There card should behave like the card that opens the dispatcher screen. --- Internal Tracking ID: [EXPOSUREAPP-6544](https://jira-ibs.wbs.net.sap/browse/EXPOSUREAPP-6544) "
434394,482918,https://api.github.com/repos/kokkos/kokkos-kernels/issues/974,bug,2021-05-12T21:44:24Z,CONTRIBUTOR,https://api.github.com/repos/kokkos/kokkos-kernels,"Fix invalid mem accesses in gemv cuBlas specializations for LayoutRight Many of the cuBlas specializations in kokkos-kernels are not currently being tested with layout right. While testing the changes in #965, I found that the gemv cuBlas specializations do not handle LayoutRight views correctly."
537692,597615,https://api.github.com/repos/AdoptOpenJDK/openjdk-systemtest/issues/379,bug,2020-11-24T15:49:21Z,CONTRIBUTOR,https://api.github.com/repos/AdoptOpenJDK/openjdk-systemtest,"LambdaLoadTests not executing correctly https://github.com/AdoptOpenJDK/openjdk-systemtest/pull/216 added `setInactivityLimit` as a parameter to the LambdaLoadTest. However, a bug in STF means that this has a side effect of preventing most of the tests in the test suite from running. A typical test output is currently: ``` 17:50:15 STF 17:50:14.928 - +------ Step 1 - Run lambda and stream load test 17:50:15 STF 17:50:14.928 - | Run foreground process 17:50:15 STF 17:50:14.928 - | Program: /home/jenkins/workspace/Test_openjdk8_j9_sanity.system_s390x_linux/openjdkbinary/j2sdk-image/bin/java 17:50:15 STF 17:50:14.928 - | Mnemonic: LT 17:50:15 STF 17:50:14.928 - | Echo: ECHO_ON 17:50:15 STF 17:50:14.928 - | Expectation: CLEAN_RUN within 1h 17:50:15 STF 17:50:14.928 - | 17:50:15 STF 17:50:14.928 - Running command: /home/jenkins/workspace/Test_openjdk8_j9_sanity.system_s390x_linux/openjdkbinary/j2sdk-image/bin/java -Xgcpolicy:gencon -Xgc:concurrentScavenge -classpath /home/jenkins/workspace/Test_openjdk8_j9_sanity.system_s390x_linux/jvmtest/system/stf/stf.load/bin:/home/jenkins/workspace/Test_openjdk8_j9_sanity.system_s390x_linux/jvmtest/system/stf/stf.core/bin:/home/jenkins/workspace/Test_openjdk8_j9_sanity.system_s390x_linux/jvmtest/system/systemtest_prereqs/log4j-2.13.3/log4j-api-2.13.3.jar:/home/jenkins/workspace/Test_openjdk8_j9_sanity.system_s390x_linux/jvmtest/system/systemtest_prereqs/log4j-2.13.3/log4j-core-2.13.3.jar:/home/jenkins/workspace/Test_openjdk8_j9_sanity.system_s390x_linux/jvmtest/system/systemtest_prereqs/junit-4.12/junit-4.12.jar:/home/jenkins/workspace/Test_openjdk8_j9_sanity.system_s390x_linux/jvmtest/system/systemtest_prereqs/junit-4.12/hamcrest-core-1.3.jar:/home/jenkins/workspace/Test_openjdk8_j9_sanity.system_s390x_linux/jvmtest/system/openjdk-systemtest/openjdk.test.lambdasAndStreams/bin net.adoptopenjdk.loadTest.LoadTest -resultsDir /home/jenkins/workspace/Test_openjdk8_j9_sanity.system_s390x_linux/openjdk-tests/TKG/test_output_16058941429755/LambdaLoadTest_ConcurrentScavenge_0/20201120-175013-LambdaLoadTest/results -resultsPrefix 1.LT. -inactivityLimit 60m -reportFailureLimit 1 -abortAtFailureLimit 10 -maxTotalLogFileSpace 200M -maxSingleLogSize 1/25 -suite.lambda.threadCount 2 -suite.lambda.inventoryFile /home/jenkins/workspace/Test_openjdk8_j9_sanity.system_s390x_linux/openjdk-tests/TKG/test_output_16058941429755/LambdaLoadTest_ConcurrentScavenge_0/20201120-175013-LambdaLoadTest/results/1.LT.inventory/openjdk.test.load/config/inventories/lambdasAndStreams/lambda.xml -suite.lambda.inventoryExcludeFile none -suite.lambda.totalNumberTests 200 -suite.lambda.selection random -suite.lambda.seed -1 -suite.lambda.repeatCount 1 -suite.lambda.thinkingTime 0ms..0ms 17:50:15 STF 17:50:14.928 - Redirecting stderr to /home/jenkins/workspace/Test_openjdk8_j9_sanity.system_s390x_linux/openjdk-tests/TKG/test_output_16058941429755/LambdaLoadTest_ConcurrentScavenge_0/20201120-175013-LambdaLoadTest/results/1.LT.stderr 17:50:15 STF 17:50:14.928 - Redirecting stdout to /home/jenkins/workspace/Test_openjdk8_j9_sanity.system_s390x_linux/openjdk-tests/TKG/test_output_16058941429755/LambdaLoadTest_ConcurrentScavenge_0/20201120-175013-LambdaLoadTest/results/1.LT.stdout 17:50:15 STF 17:50:14.933 - Monitoring processes: LT 17:50:15 LT 17:50:15.548 - Load test parameters 17:50:15 LT 17:50:15.552 - Time limited = true 17:50:15 LT 17:50:15.552 - Time limit = null 17:50:15 LT 17:50:15.552 - abortIfOutOfMemory = true 17:50:15 LT 17:50:15.552 - reportFailureLimit = 1 17:50:15 LT 17:50:15.552 - abortAtFailureLimit = 10 17:50:15 LT 17:50:15.552 - maxTotalLogFileSpace = 209715200 17:50:15 LT 17:50:15.552 - maxSingleLogSize = 8388608 17:50:15 LT 17:50:15.552 - Parameters for suite 0 17:50:15 LT 17:50:15.552 - Suite name = lambda 17:50:15 LT 17:50:15.552 - Number threads = 2 17:50:15 LT 17:50:15.552 - Supplied seed = -1 17:50:15 LT 17:50:15.553 - Inventory file = /home/jenkins/workspace/Test_openjdk8_j9_sanity.system_s390x_linux/openjdk-tests/TKG/test_output_16058941429755/LambdaLoadTest_ConcurrentScavenge_0/20201120-175013-LambdaLoadTest/results/1.LT.inventory/openjdk.test.load/config/inventories/lambdasAndStreams/lambda.xml 17:50:15 LT 17:50:15.553 - Exclude file = none 17:50:15 LT 17:50:15.553 - Number tests = 200 17:50:15 LT 17:50:15.553 - Repeat count = 1 17:50:15 LT 17:50:15.553 - Thinking time = 0ms..0ms 17:50:15 LT 17:50:15.553 - Selection mode = random 17:50:15 LT 17:50:15.553 - Actual seed = 1605434495915 17:50:15 LT 17:50:15.557 - Parsing inventory file. Root=/home/jenkins/workspace/Test_openjdk8_j9_sanity.system_s390x_linux/openjdk-tests/TKG/test_output_16058941429755/LambdaLoadTest_ConcurrentScavenge_0/20201120-175013-LambdaLoadTest/results/1.LT.inventory File=openjdk.test.load/config/inventories/lambdasAndStreams/lambda.xml 17:50:15 LT 17:50:15.570 - Final test list: 17:50:15 LT 17:50:15.570 - 0 JUnit[net.adoptopenjdk.test.lambda.ClassLibraryLambdaTests] Weighting=1 17:50:15 LT 17:50:15.570 - 1 JUnit[net.adoptopenjdk.test.lambda.TestLambdaCapture] Weighting=1 17:50:15 LT 17:50:15.570 - 2 JUnit[net.adoptopenjdk.test.lambda.TestLambdaContexts] Weighting=1 17:50:15 LT 17:50:15.570 - 3 JUnit[net.adoptopenjdk.test.lambda.TestLambdaDefaultsAndStatics] Weighting=1 17:50:15 LT 17:50:15.570 - 4 JUnit[net.adoptopenjdk.test.lambda.TestLambdaInferredTyping] Weighting=1 17:50:15 LT 17:50:15.570 - 5 JUnit[net.adoptopenjdk.test.lambda.TestLambdaJavaInterfaces] Weighting=1 17:50:15 LT 17:50:15.571 - 6 JUnit[net.adoptopenjdk.test.lambda.TestLambdaLexicalScoping] Weighting=1 17:50:15 LT 17:50:15.571 - 7 JUnit[net.adoptopenjdk.test.lambda.TestLambdaMethodReferences] Weighting=1 17:50:15 LT 17:50:15.571 - 8 JUnit[net.adoptopenjdk.test.lambda.TestLambdaMultithreaded] Weighting=1 17:50:15 LT 17:50:15.571 - 9 JUnit[net.adoptopenjdk.test.lambda.TestLambdaNested] Weighting=1 17:50:15 LT 17:50:15.571 - 10 JUnit[net.adoptopenjdk.test.lambda.TestLambdaRecursive] Weighting=1 17:50:15 LT 17:50:15.571 - 11 JUnit[net.adoptopenjdk.test.lambda.TestLambdasUserDefinedInterface] Weighting=1 17:50:15 LT 17:50:15.571 - 12 JUnit[net.adoptopenjdk.test.streams.TestParallelStreamOperations] Weighting=1 17:50:15 LT 17:50:15.571 - 13 JUnit[net.adoptopenjdk.test.streams.TestStreamOperations] Weighting=1 17:50:15 LT 17:50:15.609 - Starting thread. Suite=0 thread=0 17:50:15 LT 17:50:15.610 - Starting thread. Suite=0 thread=1 17:50:16 LT 17:50:15.768 - Thread completed. Suite=0 thread=1 17:50:16 LT 17:50:15.781 - Thread completed. Suite=0 thread=0 17:50:16 LT 17:50:15.810 - Test stopped due to reaching runtime limit 17:50:16 LT 17:50:15.810 - Load test completed 17:50:16 LT 17:50:15.811 - Ran : 2 17:50:16 LT 17:50:15.811 - Passed : 2 17:50:16 LT 17:50:15.811 - Failed : 0 17:50:16 LT 17:50:15.811 - Result : PASSED 17:50:16 STF 17:50:15.826 - Monitoring Report Summary: 17:50:16 STF 17:50:15.826 - o Process LT ended with the expected exit code (0) 17:50:16 STF 17:50:15.826 - EXECUTE stage completed 17:50:16 STF 17:50:15.832 - 17:50:16 STF 17:50:15.832 - ==================== T E A R D O W N ==================== 17:50:16 STF 17:50:15.832 - Running teardown: perl /home/jenkins/workspace/Test_openjdk8_j9_sanity.system_s390x_linux/openjdk-tests/TKG/../TKG/test_output_16058941429755/LambdaLoadTest_ConcurrentScavenge_0/20201120-175013-LambdaLoadTest/tearDown.pl 17:50:16 STF 17:50:15.864 - TEARDOWN stage completed 17:50:16 STF 17:50:15.870 - 17:50:16 STF 17:50:15.870 - ===================== R E S U L T S ===================== 17:50:16 STF 17:50:15.870 - Stage results: 17:50:16 STF 17:50:15.870 - setUp: pass 17:50:16 STF 17:50:15.870 - execute: pass 17:50:16 STF 17:50:15.870 - teardown: pass 17:50:16 STF 17:50:15.870 - 17:50:16 STF 17:50:15.870 - Overall result: PASSED 17:50:16 17:50:16 LambdaLoadTest_ConcurrentScavenge_0_PASSED ``` Note the following lines in the output: ``` 17:50:15 LT 17:50:15.552 - Time limited = true 17:50:15 LT 17:50:15.552 - Time limit = null ...... 17:50:16 LT 17:50:15.810 - Test stopped due to reaching runtime limit ``` When `inactivityLimit` is specified, STF is incorrectly setting `timeLimitedTest` to `true`. This in turn means that once the test starts its elapsed time is compared with the `timeLimit` of `null` which is interpreted as being exceeded and the test in terminated. The test output should really look something like: ``` LT 15:26:34.103 - Starting thread. Suite=0 thread=0 LT 15:26:34.104 - Starting thread. Suite=0 thread=1 LT 15:26:54.154 - Completed 3.5%. Number of tests started=7 LT 15:27:14.183 - Completed 3.5%. Number of tests started=7 (+0) LT 15:27:34.187 - Completed 3.5%. Number of tests started=7 (+0) LT 15:27:54.151 - Completed 30.0%. Number of tests started=60 (+53) LT 15:28:14.102 - Completed 30.0%. Number of tests started=60 (+0) LT 15:28:34.106 - Completed 30.0%. Number of tests started=60 (+0) LT 15:28:54.125 - Completed 54.5%. Number of tests started=109 (+49) LT 15:29:14.190 - Completed 54.5%. Number of tests started=109 (+0) LT 15:29:34.142 - Completed 54.5%. Number of tests started=109 (+0) LT 15:29:54.099 - Completed 67.5%. Number of tests started=135 (+26) LT 15:30:14.122 - Completed 67.5%. Number of tests started=135 (+0) LT 15:30:34.097 - Completed 67.5%. Number of tests started=135 (+0) LT 15:30:54.165 - Completed 78.0%. Number of tests started=156 (+21) LT 15:31:14.100 - Completed 78.0%. Number of tests started=156 (+0) STF 15:31:32.135 - Heartbeat: Process LT is still running LT 15:31:34.095 - Completed 78.0%. Number of tests started=156 (+0) LT 15:31:54.128 - Completed 84.0%. Number of tests started=168 (+12) LT 15:32:14.188 - Completed 84.0%. Number of tests started=168 (+0) LT 15:32:31.557 - Thread completed. Suite=0 thread=0 LT 15:32:34.098 - Completed 100.0%. Number of tests started=200 (+32) LT 15:32:54.189 - Completed 100.0%. Number of tests started=200 (+0) LT 15:32:56.642 - Thread completed. Suite=0 thread=1 LT 15:32:56.699 - Load test completed LT 15:32:56.699 - Ran : 200 LT 15:32:56.699 - Passed : 200 LT 15:32:56.699 - Failed : 0 LT 15:32:56.699 - Result : PASSED STF 15:32:56.762 - Monitoring Report Summary: STF 15:32:56.762 - o Process LT ended with the expected exit code (0) STF 15:32:56.762 - EXECUTE stage completed STF 15:32:57.190 - ```"
232671,258748,https://api.github.com/repos/altangent/node-lightning/issues/36,enhancement,2020-02-13T03:16:48Z,MEMBER,https://api.github.com/repos/altangent/node-lightning,gossip: implement gossip_query_ex querying Some thoughts things that * Provide gossip configuration capability > prereq is #97 * `PeerGossipReceiver` should choose the gossip_query_ex strategies if the remote peer supports the capability and we are configured to use it * Need a way to lookup channels by timestamps and checksums * possibly just iterate through all channels and construct an update struct? * probably don't want to do one-off lookups * in theory could store a last rescan time and anything that was updated prior to the last rescan can be ignored? * QueryChannelRange should ask for timestamps and checksums (make this configurable) for full range of channels available * Must check / validate the timestamps/checksums for received channels before we enqueue them for processing?? * QueryShortChannelIds should ask for the specific messages that are related to the message (using TLV options) 
515795,573213,https://api.github.com/repos/DevSolutionsLtd/Weekly-Training-Calls/issues/1,enhancement,2021-04-04T19:17:29Z,COLLABORATOR,https://api.github.com/repos/DevSolutionsLtd/Weekly-Training-Calls,"Change axis labels Please, the axis labels are not clear. Make them more informative."
621917,691137,https://api.github.com/repos/turbot/steampipe-plugin-gcp/issues/194,enhancement,2021-05-07T15:29:35Z,NONE,https://api.github.com/repos/turbot/steampipe-plugin-gcp,"Add self_link for gcp_dns_managed_zone table. **Is your feature request related to a problem? Please describe.** GET https://www.googleapis.com/dns/v1beta2/projects/parker-aaa/managedZones/cistest2 { ""creationTime"": ""2021-05-07T15:12:47.085Z"", ""description"": """", ""dnsName"": ""cistest2.com."", ""fingerprint"": ""sdfdsfdsfdsfdsfdsf"", ""id"": ""2dsfdsfdsfdsfdsf"", ""name"": ""cistest2"", ""nameServers"": [ ""ns-cloud-b1.googledomains.com."", ""ns-cloud-b2.googledomains.com."", ""ns-cloud-b3.googledomains.com."", ""ns-cloud-b4.googledomains.com."" ], ""rrsetCount"": 2.0, ""visibility"": ""PUBLIC"" } **Describe the solution you'd like** A clear and concise description of what you want to happen. **Describe alternatives you've considered** A clear and concise description of any alternative solutions or features you've considered. **Additional context** Add any other context or screenshots about the feature request here. "
40487,45085,https://api.github.com/repos/JasonBock/WSharp/issues/31,enhancement,2021-01-11T18:03:30Z,OWNER,https://api.github.com/repos/JasonBock/WSharp,Rename master to main Self-explanatory. See [this](https://github.com/github/renaming).
15251,17007,https://api.github.com/repos/rspamd/rspamd/issues/3683,bug,2021-03-21T17:58:40Z,NONE,https://api.github.com/repos/rspamd/rspamd,"[BUG] Rspamd proxy/logger removes dot in user's part of address <!-- Do you want to ask a question? Are you looking for support? Here are the places where you can get what you need: https://rspamd.com/support.html --> ### Prerequisites * [X ] Put an X between the brackets on this line if you have done all of the following: * Read about bug reporting in general: https://rspamd.com/doc/faq.html#how-to-report-bugs-found-in-rspamd * Enabled relevant debugging logs: https://rspamd.com/doc/faq.html#how-to-debug-some-module-in-rspamd * Checked the FAQs about Core files in case of fatal crash: https://rspamd.com/doc/faq.html#how-to-figure-out-why-rspamd-process-crashed * Tried ASAN package and obtained the ASAN report (if possible): https://rspamd.com/doc/faq.html#asan-builds * Checked that your issue isn't already filed: https://github.com/issues?utf8=%E2%9C%93&q=is%3Aissue+user%3Arspamd * Checked that there is not already an experimental package or master branch **Describe the bug** A clear and concise description of what the bug is. Dear Support Team, I struggle with the issue that in rspamd logs particular email addresses are presented without character dot ""."" in user part. For instance when user name is xx.yyyyyy@dom.com or yyyyyy.xx@dom.com the addresses are presented as xxyyyyyy@dom.com or yyyyyyxx@dom.com. Rules implemented on such addresses are work as expected. It is only a matter of presentation and reporting. Can you please advise if this is some configuration issue or a bug in the code? Please find the details below. Best regards, Marcin ### Steps to Reproduce 1. [First Step] receive or send email from / to xx.yyyyyyyy@dom.com 2. [Second Step] Check logs or WebUI 3. [and so on...] **Expected behavior** A clear and concise description of what you expected to happen. Email addresses to be presented without modification in log file. ### Versions You can get this information from copy and pasting the output of `rspamd --version` from the command line. Also, please include the **OS** and what version and architecture including the generation of CPU model (e.g. Haswell) where applicable, of the OS you're running. ### Additional Information Any additional information, configuration or data that might be necessary to reproduce the issue. 2021-03-21 18:39:51 #52118(rspamd_proxy) <c5355d>; proxy; rspamd_task_write_log: id: <C1C1A056-9444-4751-A10C-645FBCD985BF@gmail.com>, qid: <71A3916598F1>, ip: 209.85.208.182, from: <szczesnyit@gmail.com>, (default: F (no action): [-1.16/12.50] [R_DKIM_ALLOW(-1.00){gmail.com:s=20161025;},DMARC_POLICY_ALLOW(-0.50){gmail.com;none;},MV_CASE(0.50){},R_SPF_ALLOW(-0.50){+ip4:209.85.128.0/17:c;},SUBJ_ALL_CAPS(0.45){6;},MIME_GOOD(-0.10){text/plain;},MX_GOOD(-0.01){},ARC_NA(0.00){},ASN(0.00){asn:15169, ipnet:209.85.128.0/17, country:US;},DKIM_TRACE(0.00){gmail.com:+;},DWL_DNSWL_NONE(0.00){gmail.com:dkim;},FREEMAIL_ENVFROM(0.00){gmail.com;},FREEMAIL_FROM(0.00){gmail.com;},FROM_EQ_ENVFROM(0.00){},MID_RHS_MATCH_FROM(0.00){},MIME_TRACE(0.00){0:+;},PREVIOUSLY_DELIVERED(0.00){marcin@xxx.pl;},RCPT_COUNT_ONE(0.00){1;},RCVD_COUNT_THREE(0.00){3;},RCVD_IN_DNSWL_NONE(0.00){209.85.208.182:from;},RCVD_TLS_ALL(0.00){},RCVD_VIA_SMTP_AUTH(0.00){},RWL_MAILSPIKE_POSSIBLE(0.00){209.85.208.182:from;},TAGGED_FROM(0.00){},TO_DN_ALL(0.00){},BAYES_HAM(-0.00){21.62%;},FROM_HAS_DN(0.00){},TO_MATCH_ENVRCPT_ALL(0.00){}]), len: 2479, time: 264.770ms, dns req: 18, digest: <8c61609be8489e11f8b4da5706100599>, rcpts: <marcin@xxx.pl>, mime_rcpts: <marcin@xxx.pl> 2021-03-21 18:39:22 #52118(rspamd_proxy) <f7b94d>; proxy; rspamd_task_write_log: id: <827525AE-0DBA-43A7-B0C6-897657A6E645@gmail.com>, qid: <9F02416598F7>, ip: 209.85.167.44, from: <mnszczesny@gmail.com>, (default: F (no action): [-4.99/12.50] [BAYES_HAM(-3.68){92.30%;},R_DKIM_ALLOW(-1.00){gmail.com:s=20161025;},DMARC_POLICY_ALLOW(-0.50){gmail.com;none;},MV_CASE(0.50){},R_SPF_ALLOW(-0.50){+ip4:209.85.128.0/17;},SUBJ_ALL_CAPS(0.30){4;},MIME_GOOD(-0.10){text/plain;},MX_GOOD(-0.01){},ARC_NA(0.00){},ASN(0.00){asn:15169, ipnet:209.85.128.0/17, country:US;},DKIM_TRACE(0.00){gmail.com:+;},DWL_DNSWL_NONE(0.00){gmail.com:dkim;},FREEMAIL_ENVFROM(0.00){gmail.com;},FREEMAIL_FROM(0.00){gmail.com;},FROM_EQ_ENVFROM(0.00){},FROM_HAS_DN(0.00){},MID_RHS_MATCH_FROM(0.00){},MIME_TRACE(0.00){0:+;},PREVIOUSLY_DELIVERED(0.00){marcin@xxx.pl;},RCPT_COUNT_ONE(0.00){1;},RCVD_COUNT_THREE(0.00){3;},RCVD_IN_DNSWL_NONE(0.00){209.85.167.44:from;},RCVD_TLS_ALL(0.00){},RCVD_VIA_SMTP_AUTH(0.00){},RWL_MAILSPIKE_POSSIBLE(0.00){209.85.167.44:from;},TAGGED_FROM(0.00){},TO_DN_ALL(0.00){},TO_MATCH_ENVRCPT_ALL(0.00){}]), len: 2475, time: 1236.672ms, dns req: 30, digest: <f7322917d6c9fc4d74a00cb42a23804b>, rcpts: <marcin@xxx.pl>, mime_rcpts: <marcin@xxx.pl> Mar 21 18:39:51 goniec postfix/qmgr[38341]: 71A3916598F1: from=<szczesny.it@gmail.com>, size=2942, nrcpt=1 (queue active) Mar 21 18:39:22 goniec postfix/qmgr[38341]: 9F02416598F7: from=<mn.szczesny@gmail.com>, size=2938, nrcpt=1 (queue active) "
33224,37028,https://api.github.com/repos/auth0/auth0-cli/issues/157,enhancement,2021-03-12T22:42:56Z,MEMBER,https://api.github.com/repos/auth0/auth0-cli,"actions create should create an action file by default The default experience on `auth0 actions create` should be to create a ""noop"" action, write it to the file system and upload it. Specifying an action file should be a special case (`--file myaction.js`) After creating and upload the action we should tell the user > Edit the action code by opening `action-name.js` and deploy it using `auth0 actions deploy {new-action-id}` "
212472,236259,https://api.github.com/repos/home-assistant/android/issues/1188,bug,2020-11-12T10:52:11Z,NONE,https://api.github.com/repos/home-assistant/android,"Notification actions stopped working when image also defined <!-- READ THIS FIRST: - Make sure you run the latest version of the Android app - Make sure you run the latest version of Home Assistant - Make sure to check the Companion docs for troubleshooting and configuration: https://companion.home-assistant.io/ DO NOT DELETE ANY TEXT from this template! All requested information is important. --> ``` service: notify.myself data: message: Someone at the door data: image: ""http://..../cameraimage.jpg"" actions: - action: ""sayhi"" title: ""Say hi"" ``` If I have an image, the image shows but no actions. If I remove the image the actions show. **Home Assistant Android version:** 3.0.1-full **Android version:** 10 QKQ1.190828.002 (MIUI 12.0.2) **Phone model:** Pocophone f1 **Home Assistant version:** 0.117.6 **Last working Home Assistant release (if known):** **Description of problem:** **Traceback (if applicable):** ``` ``` **Screenshot of problem:** **Additional information:** "
226281,251648,https://api.github.com/repos/ultralytics/yolov5/issues/2343,bug,2021-03-02T22:30:18Z,NONE,https://api.github.com/repos/ultralytics/yolov5,"Something wrong with fixing ema Before submitting a bug report, please be aware that your issue **must be reproducible** with all of the following, otherwise it is non-actionable, and we can not help you: - **Current repo**: run `git fetch && git status -uno` to check and `git pull` to update repo - **Common dataset**: coco.yaml or coco128.yaml - **Common environment**: Colab, Google Cloud, or Docker image. See https://github.com/ultralytics/yolov5#environments If this is a custom dataset/training question you **must include** your `train*.jpg`, `test*.jpg` and `results.png` figures, or we can not help you. You can generate these with `utils.plot_results()`. ## 🐛 Bug A clear and concise description of what the bug is. I get an error while trying to resume a training ## To Reproduce (REQUIRED) Input: `` !python /content/yolov5/train.py --resume /content/drive/MyDrive/XRay/202102283/weights/last.pt ``` Output: wandb: Run `wandb offline` to turn off syncing. Traceback (most recent call last): File ""train.py"", line 532, in <module> train(hyp, opt, device, tb_writer, wandb) File ""train.py"", line 154, in train ema.ema.load_state_dict(ckpt['ema'].float().state_dict()) AttributeError: 'tuple' object has no attribute 'float' wandb: Waiting for W&B process to finish, PID 8842 ## Expected behavior Resuming of training ## Environment Google Colab - OS: [e.g. Ubuntu] - GPU [e.g. 2080 Ti] ## Additional context Removing float() fixes the bug. "
336562,374124,https://api.github.com/repos/DeepBlueRobotics/RobotCode2021/issues/8,enhancement,2021-03-09T00:00:11Z,CONTRIBUTOR,https://api.github.com/repos/DeepBlueRobotics/RobotCode2021,Only use the absolute encoder from the CANCoder for turning We can remove all references to the incremental encoder and use the absolute encoder instead.
38679,43095,https://api.github.com/repos/KnpLabs/php-github-api/issues/430,enhancement,2016-08-08T14:39:31Z,CONTRIBUTOR,https://api.github.com/repos/KnpLabs/php-github-api,"Support per_page param on paginated resources Per the Github API docs on [pagination](https://developer.github.com/guides/traversing-with-pagination/) > By passing the per_page parameter, you can specify how many items you want each page to return, up to 100 items. Is this currently possible? I didn't see it within the `Result Pager` docs. I could probably create a PR for this if no one else wants to tackle it. **Edit:** I didn't check every resource, but I noticed `starring()->all()` only supports a page param. It's actually a little odd that a function called `all()` only returns one page, not all stars. However, since it's common practice to use the `Result Pager` for this, it seems like that function could use a rename. ¯\_(ツ)_/¯ **Edit 2:**: I see `per_page` is actually implemented in the `AbstractAPI.php` class, but not all functions accept `per_page` as a param. "
701964,780163,https://api.github.com/repos/WeblateOrg/weblate/issues/5981,question,2021-05-10T10:19:02Z,NONE,https://api.github.com/repos/WeblateOrg/weblate,"Plurals are not included in a custom download for various formats (base format is i18next JSON) <!-- Thank you for reporting an issue on Weblate! Here are a few things to note: * This template will guide you to create a useful issue report, so please do NOT delete it. * The description blocks like this one are comments and won't be shown in the issue once it’s created. * Please write your text outside them or replace them. * In case you are pasting logs, please place them inside tripple backticks: ``` log content ``` --> I have a project of which the base language files are JSON (i18next). Plurals are configured with either a `_plural` or `_{count}` suffix. When attempting to create a custom download, plurals are not included in various formats. Changing the filters does not appear to have an effect. The translation status of the individual strings (""not translated"" or ""translated"") also does not appear to make a difference. In one case I'm also getting a ""Page not found"" error (gettext MO). Plurals **are** included in the following formats: - gettext PO - XLIFF with gettext extensions - Android String Resource Plurals **are not** included in the following formats: - XLIFF 1.1 - CSV - XLSX - JSON (even if the source is JSON) - iOS strings Not applicable: - TBX - TMX Gives a ""Page not found"": - gettext MO **I already tried** - [x] I've read and searched [the docs](https://docs.weblate.org/) and did not find the answer there. - [x] Tried with both translated and untranslated plurals. - [x] Tried exporting a custom download in the original base language, plurals are also not present here. - [x] Tried changing the filters. **To Reproduce the issue** Steps to reproduce the behavior: 1. Set up a project with one or more JSON plural strings (`_plural` or `_{count}`). 2. Navigate to an individual component language. 3. Click ""Files"" -> ""Customize download"". 4. Select one of the formats outlined above. 5. Open up the downloaded file, search for the expected plural key. There's an additional minor issue I noticed here: when you want to download multiple formats, the ""Download"" button stops working after the first download. You have to refresh the page to get it to work again. Happy to open up a new issue for this one. **Expected behavior** - I would expect consistent export behavior for all formats, and all strings, including plural forms, to be included by default. **Screenshots** - N/A **Exception traceback** - N/A **Server configuration and status** Weblate installation: Docker (4.6.0) ``` * Weblate: 4.6 * Django: 3.2 * siphashc: 2.1 * translate-toolkit: 3.3.4 * lxml: 4.6.3 * Pillow: 8.2.0 * bleach: 3.3.0 * python-dateutil: 2.8.1 * social-auth-core: 4.1.0 * social-auth-app-django: 4.0.0 * django-crispy-forms: 1.11.2 * oauthlib: 3.1.0 * django-compressor: 2.4.1 * djangorestframework: 3.12.4 * django-filter: 2.4.0 * django-appconf: 1.0.4 * user-agents: 2.2.0 * filelock: 3.0.12 * setuptools: 40.8.0 * jellyfish: 0.8.2 * openpyxl: 3.0.7 * celery: 5.0.5 * kombu: 5.0.2 * translation-finder: 2.9 * weblate-language-data: 2021.4 * html2text: 2020.1.16 * pycairo: 1.16.2 * pygobject: 3.30.4 * diff-match-patch: 20200713 * requests: 2.25.1 * django-redis: 4.12.1 * hiredis: 2.0.0 * sentry_sdk: 1.0.0 * Cython: 0.29.23 * misaka: 2.1.1 * GitPython: 3.1.14 * borgbackup: 1.1.16 * pyparsing: 2.4.7 * pyahocorasick: 1.4.2 * Python: 3.7.3 * Git: 2.20.1 * psycopg2: 2.8.6 * psycopg2-binary: 2.8.6 * phply: 1.2.5 * chardet: 4.0.0 * ruamel.yaml: 0.17.4 * tesserocr: 2.5.1 * akismet: 1.1 * boto3: 1.17.53 * zeep: 4.0.0 * aeidon: 1.9 * iniparse: 0.5 * mysqlclient: 2.0.3 * Mercurial: 5.7.1 * git-svn: 2.20.1 * git-review: 2.0.0 * Redis server: 6.2.1 * PostgreSQL server: 13.2 * Database backends: django.db.backends.postgresql * Cache backends: default:RedisCache, avatar:FileBasedCache * Email setup: django.core.mail.backends.smtp.EmailBackend: smtp.mandrillapp.com * OS encoding: filesystem=utf-8, default=utf-8 * Celery: redis://cache:6379/1, redis://cache:6379/1, regular * Platform: Linux 5.4.0-1046-azure (x86_64) ``` **Weblate deploy checks** ``` System check identified some issues: INFOS: ?: (weblate.I021) Error collection is not set up, it is highly recommended for production use HINT: https://docs.weblate.org/en/weblate-4.6/admin/install.html#collecting-errors ?: (weblate.I028) Backups are not configured, it is highly recommended for production use HINT: https://docs.weblate.org/en/weblate-4.6/admin/backup.html ?: (weblate.I031) New Weblate version is available, please upgrade to 4.6.2. HINT: https://docs.weblate.org/en/weblate-4.6/admin/upgrade.html ``` **Additional context** - N/A "
188445,209559,https://api.github.com/repos/bryntum/support/issues/2545,bug,2021-03-23T09:53:01Z,CONTRIBUTOR,https://api.github.com/repos/bryntum/support,"Resource histogram bars not redrawn on zoom in Angular/React/Vue Works on vanilla demo, not in angulars resource-histogram demo <img width=""1300"" alt=""Screenshot 2021-03-23 at 10 51 56"" src=""https://user-images.githubusercontent.com/5415653/112127487-c7b0c100-8bc5-11eb-812a-52cb6428ae6b.png""> "
521729,579852,https://api.github.com/repos/openvinotoolkit/training_extensions/issues/481,bug,2021-03-14T23:53:05Z,MEMBER,https://api.github.com/repos/openvinotoolkit/training_extensions,"CUDA + mmdetection = Error I believe we are missing a step (i.e., the pre-req for CUDA), as I'm getting this in the init_venv.sh step. @Ilya-Krylov ? on Ubuntu 18.04 with RTX 2060 mobile graphics card. `Obtaining file:///home/raymondlo84/Documents/training_extensions/external/mmdetection ERROR: Command errored out with exit status 1: command: /home/raymondlo84/Documents/training_extensions/models/text_spotting/venv/bin/python3 -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/home/raymondlo84/Documents/training_extensions/external/mmdetection/setup.py'""'""'; __file__='""'""'/home/raymondlo84/Documents/training_extensions/external/mmdetection/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info --egg-base /tmp/pip-pip-egg-info-ozcnvh3m cwd: /home/raymondlo84/Documents/training_extensions/external/mmdetection/ Complete output (13 lines): Traceback (most recent call last): File ""<string>"", line 1, in <module> File ""/home/raymondlo84/Documents/training_extensions/external/mmdetection/setup.py"", line 229, in <module> sources=['src/compiling_info.cpp']), File ""/home/raymondlo84/Documents/training_extensions/external/mmdetection/setup.py"", line 111, in make_cuda_ext extra_compile_args=extra_compile_args) File ""/home/raymondlo84/Documents/training_extensions/models/text_spotting/venv/lib/python3.6/site-packages/torch/utils/cpp_extension.py"", line 728, in CUDAExtension library_dirs += library_paths(cuda=True) File ""/home/raymondlo84/Documents/training_extensions/models/text_spotting/venv/lib/python3.6/site-packages/torch/utils/cpp_extension.py"", line 818, in library_paths if (not os.path.exists(_join_cuda_home(lib_dir)) and File ""/home/raymondlo84/Documents/training_extensions/models/text_spotting/venv/lib/python3.6/site-packages/torch/utils/cpp_extension.py"", line 1676, in _join_cuda_home raise EnvironmentError('CUDA_HOME environment variable is not set. ' OSError: CUDA_HOME environment variable is not set. Please set it to your CUDA install root. ---------------------------------------- WARNING: Discarding file:///home/raymondlo84/Documents/training_extensions/external/mmdetection. Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output. ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output. `"
9384,10468,https://api.github.com/repos/capnkirok/animaniamod/issues/518,bug,2021-04-09T14:49:58Z,NONE,https://api.github.com/repos/capnkirok/animaniamod,"[Bug] Most spawneggs dont work Hello, a lot of spawneggs in the creative menue show up but without name or only ""Spawn""and I cant spawn the ""Spawn"" called eggs. Animals dont spawn naturally. I am using a minecraft Server with Forge 1.12.2."
548718,609868,https://api.github.com/repos/JohnSnowLabs/spark-nlp/issues/2295,bug,2021-02-16T09:41:52Z,MEMBER,https://api.github.com/repos/JohnSnowLabs/spark-nlp,"DateMatcherUtils scala.MatchError in DateMatcher and MultiDateMatcher A bug that has been reported on Slack: ```scala case class PosToken2DateFeatures() extends GenericPipeline { ​ val f = ""date"" private val dateAnnotator:DateMatcher = new DateMatcher() .setInputCols(""sentence"") .setOutputCol(f) ​ private val featureCounter:AnnotationCounter = new AnnotationCounter() .setInputCol(f) .setOutputCol(f+""_count"") ​ ​ private val featureRatio:RatioCalculator = new RatioCalculator() .setInputCol(f+""_count"") .setOutputCol(f+""_ratio"") ​ ​ private val featureVector:VectorAssembler = new VectorAssembler() .setInputCols(Array(f+""_ratio"")) .setOutputCol(f+""_vec"") ​ override val stages:Array[PipelineStage] = Array(dateAnnotator,featureCounter,featureRatio,featureVector) ​ } ​ case class TemporalFeatureModel(dataFrame:DataFrame,modelPath:String,posPatterns:Map[String,String] = TemporalFeatures.posPatterns) extends GenericFeatureModel { ​ private val baseModel = BaseFeatureModel(dataFrame,modelPath) private val stages:Array[PipelineStage] = Array( baseModel.getPipeline, //PosToken2PatternFeatures(parameters.posFeatures.posPatterns).getPipeline, PosToken2DateFeatures().getPipeline ) private val pipeline = new Pipeline().setStages(stages) private val model = pipeline.fit(dataFrame) private val annotated = model.transform(dataFrame) ​ def getModel: PipelineModel = model ​ def getDataFrame: DataFrame = annotated ​ def getCachedDataFrame: DataFrame = annotated.cache() ​ } ``` Full error stack: ``` Uncaught exception: Job aborted due to stage failure: Task 0 in stage 45.0 failed 1 times, most recent failure: Lost task 0.0 in stage 45.0 (TID 129, localhost, executor driver): org.apache.spark.SparkException: Failed to execute user defined function($anonfun$dfAnnotate$1: (array<array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>>>>) => array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>>>) at org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source) at org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43) at org.apache.spark.sql.execution.WholeStageCodegenExec$$anonfun$13$$anon$1.hasNext(WholeStageCodegenExec.scala:636) at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:255) at org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247) at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858) at org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$24.apply(RDD.scala:858) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.iterator(RDD.scala:310) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.iterator(RDD.scala:310) at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) at org.apache.spark.scheduler.Task.run(Task.scala:123) at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408) at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Caused by: scala.MatchError: Fri (of class java.lang.String) at com.johnsnowlabs.nlp.annotators.DateMatcherUtils$class.relativeExactContentParse(DateMatcherUtils.scala:282) at com.johnsnowlabs.nlp.annotators.DateMatcher.relativeExactContentParse(DateMatcher.scala:35) at com.johnsnowlabs.nlp.annotators.DateMatcher$$anonfun$com$johnsnowlabs$nlp$annotators$DateMatcher$$extractRelativeExactDay$1.apply(DateMatcher.scala:129) at com.johnsnowlabs.nlp.annotators.DateMatcher$$anonfun$com$johnsnowlabs$nlp$annotators$DateMatcher$$extractRelativeExactDay$1.apply(DateMatcher.scala:128) at scala.Option.map(Option.scala:146) at com.johnsnowlabs.nlp.annotators.DateMatcher.com$johnsnowlabs$nlp$annotators$DateMatcher$$extractRelativeExactDay(DateMatcher.scala:128) at com.johnsnowlabs.nlp.annotators.DateMatcher$$anonfun$4.apply(DateMatcher.scala:65) at com.johnsnowlabs.nlp.annotators.DateMatcher$$anonfun$4.apply(DateMatcher.scala:65) at scala.Option.orElse(Option.scala:289) at com.johnsnowlabs.nlp.annotators.DateMatcher.extractDate(DateMatcher.scala:65) at com.johnsnowlabs.nlp.annotators.DateMatcher$$anonfun$annotate$1.apply(DateMatcher.scala:174) at com.johnsnowlabs.nlp.annotators.DateMatcher$$anonfun$annotate$1.apply(DateMatcher.scala:173) at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241) at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241) at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59) at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48) at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241) at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104) at com.johnsnowlabs.nlp.annotators.DateMatcher.annotate(DateMatcher.scala:173) at com.johnsnowlabs.nlp.AnnotatorModel$$anonfun$dfAnnotate$1.apply(AnnotatorModel.scala:35) at com.johnsnowlabs.nlp.AnnotatorModel$$anonfun$dfAnnotate$1.apply(AnnotatorModel.scala:34) ... 21 more Driver stacktrace: (org.apache.spark.SparkException) ``` Observations: - Most match cases in DateMatcherUtils don't have `case _` which might have resulted in MatchError. `MatchError occurs whenever an object doesn't match any pattern of a pattern-matching expression.` "
552706,614261,https://api.github.com/repos/parti-coop/parti-mx-spa/issues/156,bug,2021-02-25T07:05:12Z,NONE,https://api.github.com/repos/parti-coop/parti-mx-spa,"[믹스] 중복투표 글의 댓글에 투표내용 표시 관련 (스탠드업 등 세션에서도 이야기 나누었고, 파악하고 계신다고 하셨지만 깃헙에 없는 것 같아 적어봅니다!) 투표글에 투표한 후 댓글을 달면 이름 옆에 투표한 사항이 뜨지요. 그에 관련된 내용입니다. - [x] 중복투표에서 여러 개 선택한 사람도 댓글에 투표한 항목은 1개만 표시되고 있습니다. 여러 개 선택했을 경우 여러 개가 뜨도록 해야겠습니다. - [x] 중복투표 시 선택한 항목이 줄글로 뜨면 너무 길어 가독성이 떨어지기 때문에 이모티콘 1️⃣2️⃣3️⃣4️⃣5️⃣6️⃣7️⃣8️⃣9️⃣🔟 으로 띄우도록 개선 (1.0 로드맵 내용) "
190066,211368,https://api.github.com/repos/Icinga/icinga-powershell-framework/issues/183,bug,2021-01-08T19:56:54Z,NONE,https://api.github.com/repos/Icinga/icinga-powershell-framework,"PS-Error if in the local source directory are also other files then the msi-packes <!--- Provide a general summary of the issue in the Title above --> We have to download & install Icinga from a local directory. But if there also other files, the Cmdlet ""Start-IcingaAgentInstallWizard"" throws some errors: ![image](https://user-images.githubusercontent.com/38723488/104057802-09e77a80-51f3-11eb-8061-e9ff488e0ee6.png) For this we use the parameter ""-PackageSource 'C:\Icinga'"" The directory with the msi files ![image](https://user-images.githubusercontent.com/38723488/104057770-f6d4aa80-51f2-11eb-8868-2728f62914f4.png) This happens only, if you set the parameter -AgentVersion with the value 'release'. If you set a specific version, everything is fine. ## Expected Behavior Other files shouldn't confuse the Cmdlet ## Possible Solution - other files should not a problem - if there are other files which could be a problem for the framework, there should be a warning - when it cannot be prevented, there should be a hint in the doc ## Your Environment Tested with W2012R2, W2016 and W2019 PS: 4.6 and 4.7 Icinga-PowerShell-Framework 1.3.0 "
204217,227063,https://api.github.com/repos/saihaj/saihaj.github.io/issues/48,enhancement,2021-01-06T05:30:11Z,OWNER,https://api.github.com/repos/saihaj/saihaj.github.io,ci: setup incremental builds https://raulmelo.dev/blog/cache-gatsby-github-actions
645220,717155,https://api.github.com/repos/iaebots/iae/issues/285,enhancement,2021-05-20T22:38:21Z,COLLABORATOR,https://api.github.com/repos/iaebots/iae,"Improve password strength check. Check password entropy and validate it against password dictionaries. Currently, we use a regex to make users enter a ""strong"" password. But it's not the best way to do so. "
449665,499765,https://api.github.com/repos/tetratelabs/getenvoy/issues/162,bug,2021-04-05T09:15:51Z,MEMBER,https://api.github.com/repos/tetratelabs/getenvoy,datarace in exec_test.go I see that there's data race in https://github.com/tetratelabs/getenvoy/blob/master/pkg/util/exec/exec_test.go which can be verified with `-race` option in test.
186195,207054,https://api.github.com/repos/uniba-swt/swtbahn-cli/issues/13,bug,2021-01-21T17:10:02Z,COLLABORATOR,https://api.github.com/repos/uniba-swt/swtbahn-cli,"SWTbahn Standard layout mistake? The track layout for SWTbahn Standard as defined in the config.bahn with an anti-clockwise reading. This means that point1.straight should be connected to buffer3.up, rather than the following: https://github.com/uniba-swt/swtbahn-cli/blob/aee7b3cf99adc8e6820fb031022c19498bcbf295/configurations/swtbahn-standard/config.bahn#L164"
265610,295387,https://api.github.com/repos/thenewboston-developers/Account-Manager/issues/363,bug,2020-10-03T03:12:38Z,MEMBER,https://api.github.com/repos/thenewboston-developers/Account-Manager,"Account Number Link Issue When you: 1. go to a friends page 2. view their transactions 3. click on their account number it takes you to the overview page, but instead of displaying their nickname it displays the full account number. <img width=""551"" alt=""Screen Shot 2020-10-02 at 8 10 03 PM"" src=""https://user-images.githubusercontent.com/8547538/94981956-86c7d180-04eb-11eb-8199-56b8e7961236.png""> <img width=""755"" alt=""Screen Shot 2020-10-02 at 8 10 11 PM"" src=""https://user-images.githubusercontent.com/8547538/94981957-88919500-04eb-11eb-84e9-d0a719bfdad9.png""> <img width=""980"" alt=""Screen Shot 2020-10-02 at 8 10 19 PM"" src=""https://user-images.githubusercontent.com/8547538/94981959-892a2b80-04eb-11eb-8481-a3041708ef8e.png""> "
322790,358857,https://api.github.com/repos/B-G-Y/Team_Project_OPSW/issues/10,bug,2021-05-21T07:47:49Z,COLLABORATOR,https://api.github.com/repos/B-G-Y/Team_Project_OPSW,'음악 서비스'에 대하여 825dbb0935833f92215a9dad119274032a72894e ![image](https://user-images.githubusercontent.com/83295412/119101408-eca1a300-ba53-11eb-9b12-7e069af92b30.png) 음악 서비스를 이용 할려고 하였는데 작동이 되지않습니다. 확인하여 수정바랍니다.
210078,233594,https://api.github.com/repos/visit-dav/visit/issues/2519,enhancement,2019-02-27T01:00:00Z,CONTRIBUTOR,https://api.github.com/repos/visit-dav/visit,"Support 2 and 4 sided curve plots Currently, our curve plots support a single horizontal axis (at the bottom) and a single verticle axis (on the left). However, a lot of comparative scientific results involve plotting two curves relative to each other. However, those two curves often require different y axes (one on the left and a different one on the right) and in rare cases two different X axes (one on the bottom and one on the top). I think this is just a swizzle on our current curve plot and does not require a new plot. -----------------------REDMINE MIGRATION----------------------- This ticket was migrated from Redmine. As such, not all information was able to be captured in the transition. Below is a complete record of the original redmine ticket. Ticket number: 2515 Status: New Project: VisIt Tracker: Feature Priority: High Subject: Support 2 and 4 sided curve plots Assigned to: - Category: - Target version: - Author: Mark Miller Start: 01/25/2016 Due date: % Done: 0% Estimated time: Created: 01/25/2016 06:46 pm Updated: 05/08/2018 02:12 am Likelihood: Severity: Found in version: 2.12.3 Impact: 3 - Medium Expected Use: 3 - Occasional OS: All Support Group: Any Description: Currently, our curve plots support a single horizontal axis (at the bottom) and a single verticle axis (at the top). However, a lot of comparative scientific results involve plotting two curves relative to each other. However, those two curves often require different y axes (one on the left and a different one on the right) and in rare cases two different X axes (one on the bottom and one on the top). I think this is just a swizzle on our current curve plot and does not require a new plot. Comments: Another user has requested this. "
655937,729105,https://api.github.com/repos/KubeJS-Mods/KubeJS/issues/76,enhancement,2021-02-03T01:24:31Z,NONE,https://api.github.com/repos/KubeJS-Mods/KubeJS,Burntimes for ItemBuilder I want my tiny coal without a separate mod for it
4353,4846,https://api.github.com/repos/unixporn/trup-rs/issues/75,enhancement,2021-04-06T09:50:09Z,CONTRIBUTOR,https://api.github.com/repos/unixporn/trup-rs,"[FEATURE] include link to mental health thingy in ice bans When we ban an ice account (-> ban message contains ""ice""), robbb should include links to mental health stuff in the DM! https://www.nimh.nih.gov/health/find-help/index.shtml for example"
537750,597676,https://api.github.com/repos/kata-containers/kata-containers/issues/1372,enhancement,2021-02-08T00:36:44Z,CONTRIBUTOR,https://api.github.com/repos/kata-containers/kata-containers,"rustjail: use rlimit crate for maintainability **Which feature do you think can be improved?** The current implementation of rustjail uses the specific _setrlimit_. It's better remove our own function as much as possible by using crate. applicable parts: https://github.com/kata-containers/kata-containers/blob/main/src/agent/rustjail/src/container.rs#L1463 **How can it be improved?** We use rlimit crate. If we use the crate, we do not need to maintain our own setrlimit and RLIMITMAPS. crate: https://docs.rs/rlimit/0.5.3/rlimit/index.html#constants **Additional Information** Nothing "
111322,123741,https://api.github.com/repos/kami-blue/client/issues/1842,bug,2021-01-12T05:36:09Z,MEMBER,https://api.github.com/repos/kami-blue/client,"BooleanButton clicking is insensitive / sometimes missed Occasionally BooleanButton clicks won't register, which I assume is due to it waiting for a drag event. My proposed solution is to toggle the button on drag, which makes more sense intuitively with the animation. "
3146,3525,https://api.github.com/repos/mattjwarren/wavegan_latent_space_explorer/issues/27,enhancement,2020-12-30T20:34:07Z,OWNER,https://api.github.com/repos/mattjwarren/wavegan_latent_space_explorer,"Enable single-step ADD and SUB updates as title ... add single step updates , finer control than basic dragging and sensitivty based add/sub drag, "
415165,461471,https://api.github.com/repos/tonesto7/echo-speaks/issues/508,bug,2021-01-11T20:22:36Z,NONE,https://api.github.com/repos/tonesto7/echo-speaks,"Echo dot says ""I'm having difficulty accessing your ee simon says skill right now"" instead of my message ## Verify the following before opening an trouble issue **Go over all the following points, and put an `x` in all the boxes that apply. If you're unsure about any of these, don't hesitate to ask. We're here to help!** - [x ] That _OAuth_ is Enabled for the SmartApp under the IDE. - [ x] The App/SmartApp and Device Handler/Driver are using the latest code available. - [x ] You have reviewed the [Echo Speaks Documentation](https://tonesto7.github.io/echo-speaks-docs) for potential fixes. - [ x] That Both the Apps/SmartApps and Device Handlers/Drivers have been _Published for You_ in the IDE. --- ## About Your Setup - Hub Platform (SmartThings or Hubitat): Hubitat - How many devices are detected?: 3 - iOS or Android?: - Mobile App Version(Not required): - App/SmartApp Version: v3.6.4.4 - Device Handler/Driver Version: 3.6.4.1 - Heroku Server Version: 2.7.0 ## Expected Behavior Echo dot should speak my message ## Current Behavior **What happens instead of the expected behavior?** ## Steps to Reproduce (for bugs) **Provide a link to a live example, or an unambiguous set of steps to reproduce this bug. Include code to reproduce, if relevant** 1. 2. 3. 4. ## Context Trying to get dot to speak a message as part of good night routine confirming all doors closed, mode set night & HSM set to arm night. --- Please include a copy of any relevant log output to assist in tracking down the bug Only log entry for Echo dot is 2021-01-11 19:48:54.515 info Echo (v3.6.4.1) | SpeakCommand Sent | (All Doors closed, changing mode to Night & setting HSM to Armed Night.) | Runtime: (7 sec) | QueueItems: (0) --- Live Log Started, waiting for events --- Other messages do work & are spoken successfully on both of my 2 echo dots. One is 3rd gen & other is 2nd Gen which is the one that is giving me this message. "
602782,669891,https://api.github.com/repos/vivinano/MudaeAutoBot/issues/7,question,2021-04-26T17:07:13Z,NONE,https://api.github.com/repos/vivinano/MudaeAutoBot,"Disable claiming in specific servers. I think this should be a feature, maybe the channels you choose can be made the only places you want to claim."
251283,279503,https://api.github.com/repos/openzim/zimfarm/issues/621,enhancement,2021-05-20T10:22:16Z,NONE,https://api.github.com/repos/openzim/zimfarm,"Mirror stackexchange repo *@rgaudin commented on May 20, 2021, 9:38 AM UTC:* For sotoki scraper, we need to download dumps from StackExchange. The [server](https://archive.org/download/stackexchange/) is backed by a few mirrors but all of them are very slow. The torrent included in this folder just refers those mirrors as webseed so it's equally slow. Using this will greatly slow down our sotoki scraping while those files only changes twice a year (as per @kelson42 saying) and those are _only_ 78GB as of this writing. We should thus add a lightweight container to our infrastructure that would periodically (daily?) check whether the source repo had been updated and download each file. Those new files would then be served to our scraper, using a `--mirror` param or something. @kelson42 should we upload those to S3? As there is no versioning, we'd just be overwriting them each time. *This issue was moved by [kelson42](https://github.com/kelson42) from [kiwix/maintenance#182](https://github.com/kiwix/maintenance/issues/182).*"
702678,780953,https://api.github.com/repos/BlakeBr0/MysticalAgriculture/issues/398,bug,2021-03-23T17:09:42Z,NONE,https://api.github.com/repos/BlakeBr0/MysticalAgriculture,"red stone seed bug **Describe the bug** A clear and concise description of what the bug is. this does not only seem to be red seeds but all seeds, for some reason the red stone seed just could not be infused so i reinstalled the mod and it seemed to brought it back but long story short, please fix the interaction between hoppers and the alter, when a hopper is connected to the alter and after a seed is created, the hopper spits the next prosperity seed and it destroys the seed that was infused. Update***any block that involves transferring causes the seed to not be created please fix **To Reproduce** Steps to reproduce the behavior: i do the usual set up of Redstone seed. I place 4 red stone and 4 of the orange essence and a prosperity seed **Expected behavior** A clear and concise description of what you expected to happen. i expected it to produce a red stone seed but it the seed just has a shatter effect after the infusion is done. **Screenshots / Scripts / Logs** Please add your logs and scripts (if applicable). **Versions (please complete the following information):** - Minecraft:1.16.5 - Forge: 1.16.5 - Cucumber: 1.16.4-4.1.8 - Mystical Agriculture: 16.4-4.1.5 "
252159,280477,https://api.github.com/repos/JasonChhim/Kinoko/issues/10,bug,2021-04-15T04:22:40Z,OWNER,https://api.github.com/repos/JasonChhim/Kinoko,Hover State for clickable elements There is no hover styling for the buttons and other clickable links. Please decrease the opacity by 30% for these elements.
516775,574302,https://api.github.com/repos/Informasjonsforvaltning/fdk-organization-bff/issues/48,bug,2021-03-25T10:05:02Z,CONTRIBUTOR,https://api.github.com/repos/Informasjonsforvaltning/fdk-organization-bff,"Telling av datatjenester er feil Digdir har egentlig 11 API i prod, men viser 126 ![Screenshot from 2021-03-25 08-28-23](https://user-images.githubusercontent.com/50194012/112454976-8bae6500-8d59-11eb-9bfb-518c8b06cdd9.png) "
358601,398661,https://api.github.com/repos/perfsonar/bwctl/issues/20,enhancement,2015-08-31T20:52:03Z,NONE,https://api.github.com/repos/perfsonar/bwctl,"enhancement request: more controls on testing Ability to add restrictions such as: ""no more than N tests"" in a 24 hour window Only tests between 10pm and 6am With exceptions for lists of allowed subnets, etc. "
416296,462735,https://api.github.com/repos/10up/action-wordpress-plugin-deploy/issues/62,question,2021-01-14T09:43:25Z,NONE,https://api.github.com/repos/10up/action-wordpress-plugin-deploy,"Specify scope for GITHUB_TOKEN **Is your enhancement related to a problem? Please describe.** To improve the docs, it would be nice which scopes the token is required to have **Describe the solution you'd like** A list of scopes required for the personal access token. **Context** Available options: <img width=""769"" alt=""Screenshot 2021-01-14 at 10 43 32"" src=""https://user-images.githubusercontent.com/11903095/104573618-61537380-5655-11eb-8564-f89b3d7cd65e.png"">"
121699,135231,https://api.github.com/repos/enesbcs/rpieasy/issues/208,enhancement,2021-02-26T11:13:37Z,NONE,https://api.github.com/repos/enesbcs/rpieasy,"P502_PyGameSnd disable loop Hi, I need to run preset voice commands the plugins in question would be fine but they run continuously ... Is it possible to disable the loop or are there any other plugins that I can integrate for this purpose? Thanks for the support "
44883,49967,https://api.github.com/repos/kjappelbaum/pyepal/issues/167,enhancement,2021-01-18T15:22:39Z,OWNER,https://api.github.com/repos/kjappelbaum/pyepal,Better defaults ## Feature description - From our SI it appears that the Frobenius aggregation is not necessarily the best. - From our SI it appears that k-means init is better in terms of the final error 
380645,423151,https://api.github.com/repos/syncthing/syncthing/issues/7691,bug,2021-05-17T17:46:04Z,NONE,https://api.github.com/repos/syncthing/syncthing,"Not sending symlinks to old client (...) - please upgrade to v0.14.14 or newer I've installed on several machines with LinuxMint Linux Mint 20.1 Ulyssa and Ubuntu 20.04.2 LTS all with latest update. One system is a brand new setup. `$ apt show syncthing Package: syncthing Version: 1.1.4~ds1-4ubuntu1 ` Browser: Vivaldi 3.8.2259.40 (Stable channel) (64-Bit) or Opera latest stable **Issue**: Upon sync all systems report several times `Not sending symlinks to old client (client id) - please upgrade to v0.14.14 or newer` Frankly, I'm lost a bit."
69550,77309,https://api.github.com/repos/epistemonikos/isoq/issues/76,bug,2021-01-22T16:33:22Z,COLLABORATOR,https://api.github.com/repos/epistemonikos/isoq,"Login password not working and recover password not working @damian-garrido I user reached out to me this morning saying she could not get into her account (being told either the password or user was not right). I tried using her credentials and could login so I asked her to check that she did not accidentally include any spaces when she copied and pasted. But now I am unable to login. It is not accepting my password. AND I am clicking ""recover"" in the reset your password box and nothing is happening. "
47165,52498,https://api.github.com/repos/rclone/rclone/issues/4985,question,2021-02-01T11:09:49Z,NONE,https://api.github.com/repos/rclone/rclone,"Copy of single file from local to remote fails in 1.53.4, works in 1.51.0 #### What is the problem you are having with rclone? A copy from a local file to a remote (S3 in our case, but I guess this won't matter) results in an ""AccessDenied"" error reading the local file. When switching to v1.51.0 this works as expected. #### What is your rclone version (output from `rclone version`) - Failure: 1.53.4 - Correct: 1.51.0 #### Which OS you are using and how many bits (e.g. Windows 7, 64 bit) Linux, Official Docker Hub Image, 64bit #### Which cloud storage system are you using? (e.g. Google Drive) From: local file in /tmp To: S3 #### The command you were trying to run (e.g. `rclone copy /tmp remote:tmp`) rclone: Version ""v1.51.0"" starting with parameters [""/usr/local/bin/rclone"" ""copy"" ""-vv"" ""--config"" ""/root/.config/rclone/rclone.conf"" ""/tmp/rclone-redacted-2021-02-01-10-52-21.log"" ""backup:/redacted/logs/eu2-production/redacted""] #### A log from the command with the `-vv` flag (e.g. output from `rclone -vv copy /tmp remote:tmp`) ##### V1.53.4 (failure) ``` rclone-redacted-bucket-backup-manual-4-l266t rclone 2021/02/01 10:51:11 DEBUG : rclone: Version ""v1.53.4"" starting with parameters [""/usr/local/bin/rclone"" ""copy"" ""-vv"" ""--config"" ""/root/.config/rclone/rclone.conf"" ""/tmp/rclone-redacted-2021-02-01-10-51-11.log"" ""backup:/redacted-bucket/logs/eu2-production/redacted""] rclone-redacted-bucket-backup-manual-4-l266t rclone 2021/02/01 10:51:11 DEBUG : Creating backend with remote ""/tmp/rclone-redacted-2021-02-01-10-51-11.log"" rclone-redacted-bucket-backup-manual-4-l266t rclone 2021/02/01 10:51:11 DEBUG : Using config file from ""/root/.config/rclone/rclone.conf"" rclone-redacted-bucket-backup-manual-4-l266t rclone 2021/02/01 10:51:11 DEBUG : fs cache: adding new entry for parent of ""/tmp/rclone-redacted-2021-02-01-10-51-11.log"", ""/tmp"" rclone-redacted-bucket-backup-manual-4-l266t rclone 2021/02/01 10:51:11 DEBUG : Creating backend with remote ""backup:/redacted-bucket/logs/eu2-production/redacted"" rclone-redacted-bucket-backup-manual-4-l266t rclone 2021/02/01 10:51:12 DEBUG : fs cache: renaming cache item ""backup:/redacted-bucket/logs/eu2-production/redacted"" to be canonical ""backup:redacted-bucket/logs/eu2-production/redacted"" rclone-redacted-bucket-backup-manual-4-l266t rclone 2021/02/01 10:51:12 DEBUG : rclone-redacted-2021-02-01-10-51-11.log: Need to transfer - File not found at Destination rclone-redacted-bucket-backup-manual-4-l266t rclone 2021/02/01 10:51:12 ERROR : rclone-redacted-2021-02-01-10-51-11.log: Failed to copy: AccessDenied: Access Denied rclone-redacted-bucket-backup-manual-4-l266t rclone status code: 403, request id: B01776F275237C68, host id: Tz0wG1PhQSQUhkaAPIIXg2rg9+5/s55mSo/3C58ih4TB+oRoDv3B2T38+cY0JNf4bEaA11n/y9c= rclone-redacted-bucket-backup-manual-4-l266t rclone 2021/02/01 10:51:12 ERROR : Attempt 1/3 failed with 1 errors and: AccessDenied: Access Denied rclone-redacted-bucket-backup-manual-4-l266t rclone status code: 403, request id: B01776F275237C68, host id: Tz0wG1PhQSQUhkaAPIIXg2rg9+5/s55mSo/3C58ih4TB+oRoDv3B2T38+cY0JNf4bEaA11n/y9c= rclone-redacted-bucket-backup-manual-4-l266t rclone 2021/02/01 10:51:12 DEBUG : rclone-redacted-2021-02-01-10-51-11.log: Need to transfer - File not found at Destination rclone-redacted-bucket-backup-manual-4-l266t rclone 2021/02/01 10:51:12 ERROR : rclone-redacted-2021-02-01-10-51-11.log: Failed to copy: AccessDenied: Access Denied rclone-redacted-bucket-backup-manual-4-l266t rclone status code: 403, request id: AFBEF7ACA70C1D71, host id: llzIdT6JYlyzt4Ev7pLwFhH7DYPZ4ZgrADV4GJjpOP9J4wbFu6zt7SZGDBF5vNYLBcThBIVgVIc= rclone-redacted-bucket-backup-manual-4-l266t rclone 2021/02/01 10:51:12 ERROR : Attempt 2/3 failed with 1 errors and: AccessDenied: Access Denied rclone-redacted-bucket-backup-manual-4-l266t rclone status code: 403, request id: AFBEF7ACA70C1D71, host id: llzIdT6JYlyzt4Ev7pLwFhH7DYPZ4ZgrADV4GJjpOP9J4wbFu6zt7SZGDBF5vNYLBcThBIVgVIc= rclone-redacted-bucket-backup-manual-4-l266t rclone 2021/02/01 10:51:12 DEBUG : rclone-redacted-2021-02-01-10-51-11.log: Need to transfer - File not found at Destination rclone-redacted-bucket-backup-manual-4-l266t rclone 2021/02/01 10:51:12 ERROR : rclone-redacted-2021-02-01-10-51-11.log: Failed to copy: AccessDenied: Access Denied rclone-redacted-bucket-backup-manual-4-l266t rclone status code: 403, request id: 7522E76D24FBD8B8, host id: R4m7rt2EMdqBnl7VrJUvHpLX1PyUEt7b2NRQMNEcE6u6OHCZ5tgyszj1oYVHvZSUfcYjbbeztGc= rclone-redacted-bucket-backup-manual-4-l266t rclone 2021/02/01 10:51:12 ERROR : Attempt 3/3 failed with 1 errors and: AccessDenied: Access Denied rclone-redacted-bucket-backup-manual-4-l266t rclone status code: 403, request id: 7522E76D24FBD8B8, host id: R4m7rt2EMdqBnl7VrJUvHpLX1PyUEt7b2NRQMNEcE6u6OHCZ5tgyszj1oYVHvZSUfcYjbbeztGc= rclone-redacted-bucket-backup-manual-4-l266t rclone 2021/02/01 10:51:12 INFO : rclone-redacted-bucket-backup-manual-4-l266t rclone Transferred: 0 / 0 Bytes, -, 0 Bytes/s, ETA - rclone-redacted-bucket-backup-manual-4-l266t rclone Errors: 1 (retrying may help) rclone-redacted-bucket-backup-manual-4-l266t rclone Elapsed time: 0.3s rclone-redacted-bucket-backup-manual-4-l266t rclone rclone-redacted-bucket-backup-manual-4-l266t rclone 2021/02/01 10:51:12 DEBUG : 5 go routines active rclone-redacted-bucket-backup-manual-4-l266t rclone 2021/02/01 10:51:12 Failed to copy: AccessDenied: Access Denied rclone-redacted-bucket-backup-manual-4-l266t rclone status code: 403, request id: 7522E76D24FBD8B8, host id: R4m7rt2EMdqBnl7VrJUvHpLX1PyUEt7b2NRQMNEcE6u6OHCZ5tgyszj1oYVHvZSUfcYjbbeztGc= ``` ##### V1.51.0 (success) ``` rclone-redacted-bucket-backup-manual-5-dvjw7 rclone 2021/02/01 10:52:21 DEBUG : rclone: Version ""v1.51.0"" starting with parameters [""/usr/local/bin/rclone"" ""copy"" ""-vv"" ""--config"" ""/root/.config/rclone/rclone.conf"" ""/tmp/rclone-redacted-2021-02-01-10-52-21.log"" ""backup:/redacted-bucket/logs/eu2-production/redacted""] rclone-redacted-bucket-backup-manual-5-dvjw7 rclone 2021/02/01 10:52:21 DEBUG : Using config file from ""/root/.config/rclone/rclone.conf"" rclone-redacted-bucket-backup-manual-5-dvjw7 rclone 2021/02/01 10:52:21 DEBUG : rclone-redacted-2021-02-01-10-52-21.log: Need to transfer - File not found at Destination rclone-redacted-bucket-backup-manual-5-dvjw7 rclone 2021/02/01 10:52:22 DEBUG : rclone-redacted-2021-02-01-10-52-21.log: MD5 = 3a8a0c118074bf7956b7f904b6b59795 OK rclone-redacted-bucket-backup-manual-5-dvjw7 rclone 2021/02/01 10:52:22 INFO : rclone-redacted-2021-02-01-10-52-21.log: Copied (new) rclone-redacted-bucket-backup-manual-5-dvjw7 rclone 2021/02/01 10:52:22 INFO : rclone-redacted-bucket-backup-manual-5-dvjw7 rclone Transferred: 238.030k / 238.030 kBytes, 100%, 1019.855 kBytes/s, ETA 0s rclone-redacted-bucket-backup-manual-5-dvjw7 rclone Transferred: 1 / 1, 100% rclone-redacted-bucket-backup-manual-5-dvjw7 rclone Elapsed time: 0.2s rclone-redacted-bucket-backup-manual-5-dvjw7 rclone rclone-redacted-bucket-backup-manual-5-dvjw7 rclone 2021/02/01 10:52:22 DEBUG : 5 go routines active rclone-redacted-bucket-backup-manual-5-dvjw7 rclone 2021/02/01 10:52:22 DEBUG : rclone: Version ""v1.51.0"" finishing with parameters [""/usr/local/bin/rclone"" ""copy"" ""-vv"" ""--config"" ""/root/.config/rclone/rclone.conf"" ""/tmp/rclone-redacted-2021-02-01-10-52-21.log"" ""backup:/redacted-bucket/logs/eu2-production/redacted""] ``` "
663837,737863,https://api.github.com/repos/DrGFreeman/dynamo-pandas/issues/4,enhancement,2021-03-07T18:40:46Z,OWNER,https://api.github.com/repos/DrGFreeman/dynamo-pandas,"Add functions to convert DataFrame and Series to items dict and vice-versa Add functions to convert pandas DataFrame and Series to items dict and vice-versa. Examples (subject to modification): - `to_items(df)` to convert a dataframe to a list of dictionaries. - `to_item(obj)` to convert a single row dataframe or a series to a dictionary. - `to_df(items, dtype=None)` to convert a single or multiple items to a dataframe with optional data types."
93748,104197,https://api.github.com/repos/SirUbu/team-profile-generator/issues/1,enhancement,2021-05-18T21:38:14Z,OWNER,https://api.github.com/repos/SirUbu/team-profile-generator,Initial Setup ### Description *MVP Feature* - Add project Directories and Files - Add Dependencies: - npm init - install inquirer - install jest
143882,159932,https://api.github.com/repos/dlwlsdn201/basketball-game/issues/9,enhancement,2021-03-18T13:48:45Z,OWNER,https://api.github.com/repos/dlwlsdn201/basketball-game,"[enhancement] 리덕스 상태관리를 위한 dispatch 함수 생성 및 적용 [Required] 1. 각 버튼의 이벤트로 인해 게임 카운트, 점수, 메세지 등의 상태를 업데이트시킬 dispatch 생성 "
378034,420233,https://api.github.com/repos/bassmaster187/TeslaLogger/issues/551,bug,2021-04-03T19:12:52Z,CONTRIBUTOR,https://api.github.com/repos/bassmaster187/TeslaLogger,"memory leak in TL 1.47.5.0 03.04.2021 20:00:16 : TeslaLogger process statistics WorkingSet64: 89059328 PeakWorkingSet64: 96555008 PrivateMemorySize64: 97837056 VirtualMemorySize64: 148824064 HandleCount: 0 StartTime: 4/3/2021 7:52:26 PM 03.04.2021 20:00:18 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:00:17 03.04.2021 20:00:49 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:00:41 03.04.2021 20:01:14 : #1: Waiting for car to go to sleep 3 03.04.2021 20:01:37 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:01:35 03.04.2021 20:02:14 : #1: Waiting for car to go to sleep 4 03.04.2021 20:02:34 : #1: Stream: Timeout 03.04.2021 20:02:56 : #1: Stream: Timeout 03.04.2021 20:03:14 : #1: Waiting for car to go to sleep 5 03.04.2021 20:03:17 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:03:16 03.04.2021 20:03:27 : #1: Stream Data Error: vehicle_disconnected 10 03.04.2021 20:04:10 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:04:09 03.04.2021 20:04:15 : #1: Waiting for car to go to sleep 6 03.04.2021 20:05:11 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:05:05 03.04.2021 20:05:15 : #1: Waiting for car to go to sleep 7 03.04.2021 20:05:57 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:05:55 03.04.2021 20:06:15 : #1: Waiting for car to go to sleep 8 03.04.2021 20:06:35 : #1: Stream: Timeout 03.04.2021 20:06:50 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:06:48 03.04.2021 20:07:15 : #1: Waiting for car to go to sleep 9 03.04.2021 20:07:47 : #1: Stream: Timeout 03.04.2021 20:08:08 : #1: Stream: Timeout 03.04.2021 20:08:15 : #1: Waiting for car to go to sleep 10 03.04.2021 20:08:31 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:08:27 03.04.2021 20:09:06 : #1: Stream Data Error: vehicle_disconnected 20 03.04.2021 20:09:15 : #1: Waiting for car to go to sleep 11 03.04.2021 20:09:18 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:09:17 03.04.2021 20:09:49 : #1: Stream: Timeout 03.04.2021 20:10:05 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:10:05 03.04.2021 20:10:16 : #1: Waiting for car to go to sleep 12 03.04.2021 20:11:03 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:10:55 03.04.2021 20:11:16 : #1: Waiting for car to go to sleep 13 03.04.2021 20:11:54 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:11:53 03.04.2021 20:12:16 : #1: Waiting for car to go to sleep 14 03.04.2021 20:12:32 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:12:27 03.04.2021 20:13:04 : #1: Stream: Timeout 03.04.2021 20:13:16 : #1: Waiting for car to go to sleep 15 03.04.2021 20:13:25 : #1: Stream: Timeout 03.04.2021 20:13:46 : #1: Stream: Timeout 03.04.2021 20:14:03 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:14:00 03.04.2021 20:14:16 : #1: Waiting for car to go to sleep 16 03.04.2021 20:14:47 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:14:46 03.04.2021 20:14:57 : #1: Stream Data Error: vehicle_disconnected 30 03.04.2021 20:15:16 : #1: Waiting for car to go to sleep 17 03.04.2021 20:15:41 : #1: Stream: Timeout 03.04.2021 20:15:57 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:15:55 03.04.2021 20:16:07 : #1: Stream: Timeout 03.04.2021 20:16:16 : #1: Waiting for car to go to sleep 18 03.04.2021 20:16:53 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:16:53 03.04.2021 20:17:16 : #1: Waiting for car to go to sleep 19 03.04.2021 20:17:26 : #1: Stream: Timeout 03.04.2021 20:17:41 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:17:39 03.04.2021 20:18:12 : #1: Stream: Timeout 03.04.2021 20:18:16 : #1: Waiting for car to go to sleep 20 03.04.2021 20:18:34 : #1: Stream: Timeout 03.04.2021 20:18:49 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:18:47 03.04.2021 20:19:16 : #1: Waiting for car to go to sleep 21 03.04.2021 20:19:36 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:19:34 03.04.2021 20:20:16 : #1: Waiting for car to go to sleep 22 03.04.2021 20:20:21 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:20:20 03.04.2021 20:20:54 : #1: Stream Data Error: vehicle_disconnected 40 03.04.2021 20:21:12 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:21:06 03.04.2021 20:21:16 : #1: Waiting for car to go to sleep 23 03.04.2021 20:22:07 : #1: Stream: Timeout 03.04.2021 20:22:17 : #1: Waiting for car to go to sleep 24 03.04.2021 20:22:30 : #1: Stream: Timeout 03.04.2021 20:22:47 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:22:41 03.04.2021 20:23:17 : #1: Waiting for car to go to sleep 25 03.04.2021 20:23:20 : #1: Stream: Timeout 03.04.2021 20:23:41 : #1: Stream: Timeout 03.04.2021 20:23:55 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:23:52 03.04.2021 20:24:17 : #1: Waiting for car to go to sleep 26 03.04.2021 20:24:47 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:24:40 03.04.2021 20:25:17 : #1: Waiting for car to go to sleep 27 03.04.2021 20:25:25 : #1: Stream: Timeout 03.04.2021 20:25:45 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:25:37 03.04.2021 20:26:17 : #1: Waiting for car to go to sleep 28 03.04.2021 20:26:31 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:26:30 03.04.2021 20:27:04 : #1: Stream Data Error: vehicle_disconnected 50 03.04.2021 20:27:17 : #1: Waiting for car to go to sleep 29 03.04.2021 20:27:17 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:27:16 03.04.2021 20:28:12 : #1: Stream: Timeout 03.04.2021 20:28:17 : #1: Restart communication with Tesla Server! 2 03.04.2021 20:28:22 : #1: ScanMyTesla FastMode: False 03.04.2021 20:28:22 : DEBUG : FindOpenChargingStates: SQL SELECT id FROM chargingstate WHERE CarID=1 AND EndDate IS NULL ORDER BY StartDate ASC (C:\dev\TeslaLogger\TeslaLogger\DBHelper.cs:1422) 03.04.2021 20:28:22 : DEBUG : CloseChargingStates took 186.76ms (C:\dev\TeslaLogger\TeslaLogger\DBHelper.cs:840) 03.04.2021 20:28:22 : Distance: 34.8337920381218 - Radius: 95 - 🏠 E22 03.04.2021 20:28:22 : Reverse geocoding by Geofence 03.04.2021 20:28:23 : #1: change TeslaLogger state: Start -> Online 03.04.2021 20:28:33 : #1: Result.Statuscode: 408 (RequestTimeout) cmd: vehicle_state 03.04.2021 20:28:33 : #1: Result.Statuscode: 408 (RequestTimeout) cmd: drive_state 03.04.2021 20:28:53 : DEBUG : SuC: <Berlin, Germany - EUREF-Campus> <11> <12> (C:\dev\TeslaLogger\TeslaLogger\NearbySuCService.cs:172) 03.04.2021 20:28:53 : DEBUG : SuC: <Beelitz, Germany> <13> <14> (C:\dev\TeslaLogger\TeslaLogger\NearbySuCService.cs:172) 03.04.2021 20:28:53 : DEBUG : SuC: <Herzsprung, Germany> <9> <10> (C:\dev\TeslaLogger\TeslaLogger\NearbySuCService.cs:172) 03.04.2021 20:28:53 : DEBUG : SuC: <Uckerfelde, Germany> <4> <4> (C:\dev\TeslaLogger\TeslaLogger\NearbySuCService.cs:172) 03.04.2021 20:28:53 : DEBUG : ShareSuc: Insert superchargerstate: Berlin, Germany - EUREF-Campus Available: 11 Insert superchargerstate: Beelitz, Germany Available: 13 Insert superchargerstate: Herzsprung, Germany Available: 9 already have it: Uckerfelde, Germany (C:\dev\TeslaLogger\TeslaLogger\NearbySuCService.cs:140) 03.04.2021 20:29:03 : #1: IsDriving = NULL! 03.04.2021 20:31:36 : #1: GetOutsideTempAsync: NULL 03.04.2021 20:33:24 : #1: change TeslaLogger state: Online -> Start 03.04.2021 20:33:25 : #1: STOP communication with Tesla Server to enter sleep Mode! https://teslalogger.de/faq-1.php 03.04.2021 20:33:26 : #1: Waiting for car to go to sleep 0 03.04.2021 20:33:37 : #1: Stream: Timeout 03.04.2021 20:33:50 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:33:49 03.04.2021 20:34:26 : #1: Waiting for car to go to sleep 1 03.04.2021 20:34:36 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:34:35 03.04.2021 20:35:20 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:35:19 03.04.2021 20:35:26 : #1: Waiting for car to go to sleep 2 03.04.2021 20:36:07 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:36:06 03.04.2021 20:36:26 : #1: Waiting for car to go to sleep 3 03.04.2021 20:36:39 : #1: Stream Data Error: vehicle_disconnected 60 03.04.2021 20:36:51 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:36:50 03.04.2021 20:37:23 : #1: Stream: Timeout 03.04.2021 20:37:26 : #1: Waiting for car to go to sleep 4 03.04.2021 20:37:44 : #1: Stream: Timeout 03.04.2021 20:38:05 : #1: Stream: Timeout 03.04.2021 20:38:26 : #1: Waiting for car to go to sleep 5 03.04.2021 20:38:26 : #1: Stream: Timeout 03.04.2021 20:38:41 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:38:38 03.04.2021 20:39:27 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:39:26 03.04.2021 20:39:27 : #1: Waiting for car to go to sleep 6 03.04.2021 20:40:17 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:40:16 03.04.2021 20:40:27 : #1: Waiting for car to go to sleep 7 03.04.2021 20:41:13 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:41:06 03.04.2021 20:41:27 : #1: Waiting for car to go to sleep 8 03.04.2021 20:42:00 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:41:58 03.04.2021 20:42:22 : #1: Stream Data Error: vehicle_disconnected 70 03.04.2021 20:42:27 : #1: Waiting for car to go to sleep 9 03.04.2021 20:42:34 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:42:33 03.04.2021 20:43:21 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:43:19 03.04.2021 20:43:27 : #1: Waiting for car to go to sleep 10 03.04.2021 20:44:10 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:44:09 03.04.2021 20:44:27 : #1: Waiting for car to go to sleep 11 03.04.2021 20:45:04 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:44:59 03.04.2021 20:45:27 : #1: Waiting for car to go to sleep 12 03.04.2021 20:45:50 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:45:49 03.04.2021 20:46:23 : #1: Stream Data Error: vehicle_disconnected 80 03.04.2021 20:46:27 : #1: Waiting for car to go to sleep 13 03.04.2021 20:46:36 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:46:35 03.04.2021 20:47:22 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:47:21 03.04.2021 20:47:27 : #1: Waiting for car to go to sleep 14 03.04.2021 20:48:06 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:48:05 03.04.2021 20:48:27 : #1: Waiting for car to go to sleep 15 03.04.2021 20:49:02 : #1: Stream: Timeout 03.04.2021 20:49:23 : #1: Stream: Timeout 03.04.2021 20:49:27 : #1: Waiting for car to go to sleep 16 03.04.2021 20:49:44 : #1: Stream: Timeout 03.04.2021 20:49:59 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:49:59 03.04.2021 20:50:27 : #1: Waiting for car to go to sleep 17 03.04.2021 20:50:50 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:50:50 03.04.2021 20:51:23 : #1: Stream Data Error: vehicle_disconnected 90 03.04.2021 20:51:28 : #1: Waiting for car to go to sleep 18 03.04.2021 20:51:36 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:51:35 03.04.2021 20:52:23 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:52:21 03.04.2021 20:52:28 : #1: Waiting for car to go to sleep 19 03.04.2021 20:53:14 : #1: shift_state: Power: 0 Datetime: 03.04.2021 20:53:08 03.04.2021 20:53:28 : #1: Waiting for car to go to sleep 20 03.04.2021 20:53:45 : #1: Stream: Timeout 03.04.2021 20:54:07 : #1: Stream: Timeout 03.04.2021 20:54:28 : #1: Waiting for car to go to sleep 21 03.04.2021 20:54:28 : #1: Stream: Timeout 03.04.2021 20:54:49 : #1: Stream: Timeout 03.04.2021 20:55:10 : #1: Stream: Timeout 03.04.2021 20:55:28 : #1: Waiting for car to go to sleep 22 03.04.2021 20:55:32 : #1: Stream: Timeout 03.04.2021 20:56:28 : #1: Waiting for car to go to sleep 23 03.04.2021 20:56:58 : #1: Stream: Timeout 03.04.2021 20:57:19 : #1: Stream: Timeout 03.04.2021 20:57:28 : #1: Waiting for car to go to sleep 24 03.04.2021 20:57:40 : #1: Stream: Timeout 03.04.2021 20:58:01 : #1: Stream: Timeout 03.04.2021 20:58:24 : #1: Stream: Timeout 03.04.2021 20:58:28 : #1: Waiting for car to go to sleep 25 03.04.2021 20:58:45 : #1: Stream: Timeout 03.04.2021 20:59:06 : #1: Stream: Timeout 03.04.2021 20:59:27 : #1: Stream: Timeout 03.04.2021 20:59:28 : #1: Waiting for car to go to sleep 26 03.04.2021 20:59:49 : #1: Stream: Timeout 03.04.2021 21:00:10 : #1: Stream: Timeout 03.04.2021 21:00:16 : TeslaLogger process statistics WorkingSet64: 98013184 PeakWorkingSet64: 114556928 PrivateMemorySize64: 107409408 VirtualMemorySize64: 159211520 HandleCount: 0 StartTime: 4/3/2021 7:52:26 PM"
484699,538683,https://api.github.com/repos/Flying-Octopus-Team/octopus-services/issues/10,enhancement,2021-02-19T10:29:12Z,MEMBER,https://api.github.com/repos/Flying-Octopus-Team/octopus-services,Implement !fo member add -h option Add help option to member add action explaining how to use it. Might want to create some generic mechanism for all commands and actions.
98147,109050,https://api.github.com/repos/grf-labs/policytree/issues/87,question,2021-04-21T13:59:45Z,NONE,https://api.github.com/repos/grf-labs/policytree,"Measure of optimal policy ""stability"" Hi team, thank you for developing this tool. It is super useful. I noticed in my setting that the optimal policy changes slightly as I change the fraction of the sample I use to find the optimal policy and if change my see. It is of course not surprising that things change if we have different data points, but is there any way of assessing how ""stable"" an optimal policy is? I didn't see any discussion of this in Athey and Wager's Econometrica paper, but I might have missed it. Currently I am thinking of drawing X samples of size N of my data and compare the optimal policy across these X samples, but that seems a bit ad hoc (and it difficult to compare the optimal policies across samples). Thanks again for developing this! Hans"
452239,502620,https://api.github.com/repos/kyma-project/console/issues/2125,enhancement,2021-02-15T06:50:30Z,MEMBER,https://api.github.com/repos/kyma-project/console,"Remove Console Backing Services **Description** Remove completely Console Backing services and all GraphQL related calls from all our code. **AC** - [ ] console-backend is removed from all our Charts - [ ] ApiServer Proxy is removed from all our Charts - [ ] Console Functions as before, but using K8s APi instead of Console Backing Service - [ ] All tests and pipeline are adjusted **Non Functional Requirements** **Kyma Goals we are achieving with this ** - Slimmer / faster Kyma "
162837,181050,https://api.github.com/repos/Mato098/Bomberman/issues/1,enhancement,2021-01-31T15:47:11Z,OWNER,https://api.github.com/repos/Mato098/Bomberman,"features to be implemented AI hostility(search, and placement of bombs near other players, making its way through crates) "
322237,358229,https://api.github.com/repos/acquia/blt/issues/4225,enhancement,2020-08-12T14:42:01Z,COLLABORATOR,https://api.github.com/repos/acquia/blt,"Create ""BLT Launcher"" package to replace alias Currently BLT has an `alias` command that you can run manually, and that also runs automatically at various points such as Composer installs and during `setup` commands. This causes problems when people don't want a global alias for whatever reason (usually in CI), _can't_ install a global alias (due to file permissions or oddball directory structures), or are using a non-standard shell preference file. I propose creating a BLT Launcher package, modeled on the [Drush Launcher](https://github.com/drush-ops/drush-launcher), that acts as a shim/wrapper for local BLT installs, and removing the alias functionality from BLT core."
555956,617860,https://api.github.com/repos/lorenzo-rovigatti/oxDNA/issues/5,enhancement,2020-10-19T07:57:40Z,OWNER,https://api.github.com/repos/lorenzo-rovigatti/oxDNA,Add Continous Integration to oxDNA Use github actions to add CI to oxDNA. 
157789,175434,https://api.github.com/repos/rapid7/metasploit-framework/issues/14948,bug,2021-03-25T19:51:37Z,CONTRIBUTOR,https://api.github.com/repos/rapid7/metasploit-framework,"Switching Between Pry and IRB in a single session causes IRB to cease operating due to stack traces ## Steps to reproduce How'd you do it? ``` =[ metasploit v6.0.38-dev-9033dd19bc ] + -- --=[ 2111 exploits - 1135 auxiliary - 357 post ] + -- --=[ 592 payloads - 45 encoders - 10 nops ] + -- --=[ 8 evasion ] Metasploit tip: Use the resource command to run commands from a file msf6 > irb [*] Starting IRB shell... [*] You are in the ""framework"" object irb: warn: can't alias jobs from irb_jobs. >> exit msf6 > pry /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/irb-1.3.4/lib/irb.rb:425: warning: already initialized constant IRB::Irb::ASSIGNMENT_NODE_TYPES /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/irb-1.3.4/lib/irb.rb:425: warning: previous definition of ASSIGNMENT_NODE_TYPES was here /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/irb-1.3.4/lib/irb.rb:851: warning: already initialized constant IRB::Irb::ATTR_TTY /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/irb-1.3.4/lib/irb.rb:851: warning: previous definition of ATTR_TTY was here /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/irb-1.3.4/lib/irb.rb:853: warning: already initialized constant IRB::Irb::ATTR_PLAIN /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/irb-1.3.4/lib/irb.rb:853: warning: previous definition of ATTR_PLAIN was here [*] Starting Pry shell... [*] You are in the ""framework"" object [1] pry(#<Msf::Framework>)> exit msf6 > ir [-] Unknown command: ir. msf6 > irb [*] Starting IRB shell... [*] You are in the ""framework"" object Can't switch inspect mode. [-] Error during IRB: undefined method `[]' for nil:NilClass /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/irb-1.3.4/lib/irb/context.rb:363:in `prompt_mode=' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/irb-1.3.4/lib/irb/context.rb:70:in `initialize' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/irb-1.3.4/lib/irb.rb:456:in `new' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/irb-1.3.4/lib/irb.rb:456:in `initialize' /home/gwillcox/git/metasploit-framework/lib/rex/ui/text/irb_shell.rb:36:in `new' /home/gwillcox/git/metasploit-framework/lib/rex/ui/text/irb_shell.rb:36:in `run' /home/gwillcox/git/metasploit-framework/lib/msf/ui/console/command_dispatcher/developer.rb:119:in `cmd_irb' /home/gwillcox/git/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:542:in `run_command' /home/gwillcox/git/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:491:in `block in run_single' /home/gwillcox/git/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:485:in `each' /home/gwillcox/git/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:485:in `run_single' /home/gwillcox/git/metasploit-framework/lib/rex/ui/text/shell.rb:157:in `run' /home/gwillcox/git/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start' /home/gwillcox/git/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start' ./msfconsole:23:in `<main>' msf6 > ``` ## Were you following a specific guide/tutorial or reading documentation? Testing some stuff out whilst helping a community member with one of their questions. ## Expected behavior One should be able to switch freely between using IRB and using Pry ## Current behavior IRB will throw a stack trace after one uses `pry` thereby making it impossible to use `irb` again until after `msfconsole` is closed. ### Metasploit version v6.0.38-dev-9033dd19bc ## Module/Datastore The following global/module datastore, and database setup was configured before the issue occurred: <details> <summary>Collapse</summary> ``` [framework/core] LogLevel=3 [framework/database] default_db=local-https-data-service [framework/database/local-https-data-service] url=[Filtered] cert=[Filtered] skip_verify=[Filtered] api_token=[Filtered] ``` </details> ## History The following commands were ran during the session and before this issue occurred: <details> <summary>Collapse</summary> ``` 488 cert 489 next 490 exit 491 next 492 sslSocket.sslsock.hostname 493 next 494 cert 495 next 496 exit 497 next 498 sslSocket.sslsock.hostname 499 next 500 cert 501 exit 502 irb 503 exit 504 msf6 > irb 505 [*] Starting IRB shell... 506 [*] You are in the ""framework"" object 507 Can't switch inspect mode. 508 [-] Error during IRB: undefined method `[]' for nil:NilClass 509 /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/irb-1.3.4/lib/irb/context.rb:363:in `prompt_mode=' 510 /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/irb-1.3.4/lib/irb/context.rb:70:in `initialize' 511 /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/irb-1.3.4/lib/irb.rb:456:in `new' 512 /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/irb-1.3.4/lib/irb.rb:456:in `initialize' 513 /home/gwillcox/git/metasploit-framework/lib/rex/ui/text/irb_shell.rb:36:in `new' 514 /home/gwillcox/git/metasploit-framework/lib/rex/ui/text/irb_shell.rb:36:in `run' 515 /home/gwillcox/git/metasploit-framework/lib/msf/ui/console/command_dispatcher/developer.rb:119:in `cmd_irb' 516 /home/gwillcox/git/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:542:in `run_command' 517 /home/gwillcox/git/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:491:in `block in run_single' 518 /home/gwillcox/git/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:485:in `each' 519 /home/gwillcox/git/metasploit-framework/lib/rex/ui/text/dispatcher_shell.rb:485:in `run_single' 520 /home/gwillcox/git/metasploit-framework/lib/rex/ui/text/shell.rb:157:in `run' 521 /home/gwillcox/git/metasploit-framework/lib/metasploit/framework/command/console.rb:48:in `start' 522 /home/gwillcox/git/metasploit-framework/lib/metasploit/framework/command/base.rb:82:in `start' 523 ./msfconsole:23:in `<main>' 524 msf6 > 525 Msf 526 Msf::Config 527 Msf::Config.history_file 528 Msf::Config.history_file = 529 Msf::Config.history_file = ""/home/gwillcox/.msf4/fakeness"" 530 exit 531 Msf::Config.history_file 532 continue 533 exit 534 exit 535 exit 536 irb 537 debug ``` </details> ## Framework Errors The following framework errors occurred before the issue occurred: <details> <summary>Collapse</summary> ``` [03/25/2021 14:48:59] [e(0)] core: Dependency for windows/x64/encrypted_shell_reverse_tcp is not supported [03/25/2021 14:48:59] [e(0)] core: Dependency for windows/encrypted_shell_reverse_tcp is not supported [03/25/2021 14:48:59] [e(0)] core: Dependency for windows/x64/encrypted_reverse_tcp is not supported [03/25/2021 14:48:59] [e(0)] core: Dependency for windows/encrypted_reverse_tcp is not supported [03/25/2021 14:48:59] [e(0)] core: /home/gwillcox/git/metasploit-framework/modules/auxiliary/gather/office365userenum.py failed to load - LoadError Try running file manually to check for errors or dependency issues. [03/25/2021 14:49:33] [e(0)] core: Dependency for windows/x64/encrypted_shell_reverse_tcp is not supported [03/25/2021 14:49:33] [e(0)] core: Dependency for windows/encrypted_shell_reverse_tcp is not supported [03/25/2021 14:49:33] [e(0)] core: Dependency for windows/x64/encrypted_reverse_tcp is not supported [03/25/2021 14:49:33] [e(0)] core: Dependency for windows/encrypted_reverse_tcp is not supported [03/25/2021 14:49:34] [e(0)] core: /home/gwillcox/git/metasploit-framework/modules/auxiliary/gather/office365userenum.py failed to load - LoadError Try running file manually to check for errors or dependency issues. ``` </details> ## Web Service Errors The following web service errors occurred before the issue occurred: <details> <summary>Collapse</summary> ``` [-] Error handling request: Validation failed: Data is not in the NTLMHash data format of <LAN Manager hex digest>:<NT LAN Manager hex digest>, where each hex digest is 32 lowercase hexadecimal characters.. Call Stack: /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/validations.rb:80:in `raise_validation_error' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/validations.rb:52:in `save!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/transactions.rb:315:in `block in save!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/transactions.rb:387:in `block in with_transaction_returning_status' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/database_statements.rb:267:in `block in transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/transaction.rb:239:in `block in within_new_transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/transaction.rb:236:in `synchronize' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/transaction.rb:236:in `within_new_transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/database_statements.rb:267:in `transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/transactions.rb:212:in `transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/transactions.rb:385:in `with_transaction_returning_status' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/transactions.rb:315:in `save!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/suppressor.rb:48:in `save!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/metasploit-credential-4.0.2/lib/metasploit/credential/creation.rb:496:in `block in create_credential_private' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/metasploit-credential-4.0.2/lib/metasploit/credential/creation.rb:623:in `retry_transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/metasploit-credential-4.0.2/lib/metasploit/credential/creation.rb:472:in `create_credential_private' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/metasploit-credential-4.0.2/lib/metasploit/credential/creation.rb:133:in `create_credential' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet/credential_servlet.rb:52:in `block (2 levels) in create_credential' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet_helper.rb:78:in `exec_report_job' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet/credential_servlet.rb:54:in `block in create_credential' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `block in compile!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (3 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1032:in `route_eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (2 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1061:in `block in process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1011:in `block in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `each' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1129:in `block in dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1124:in `dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `block in call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:929:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:36:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/xss_header.rb:18:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/path_traversal.rb:16:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/json_csrf.rb:26:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/frame_options.rb:31:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:266:in `context' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:260:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/null_logger.rb:11:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/head.rb:12:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:216:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1991:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1769:in `synchronize' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:86:in `block in pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:53:in `process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:39:in `receive_data' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run_machine' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/backends/base.rb:75:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/server.rb:162:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/controllers/controller.rb:87:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:203:in `run_command' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:159:in `run!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/bin/thin:6:in `<top (required)>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `load' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `<main>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `<main>' [-] Error handling request: Validation failed: Data is not in the NTLMHash data format of <LAN Manager hex digest>:<NT LAN Manager hex digest>, where each hex digest is 32 lowercase hexadecimal characters.. Call Stack: /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/validations.rb:80:in `raise_validation_error' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/validations.rb:52:in `save!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/transactions.rb:315:in `block in save!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/transactions.rb:387:in `block in with_transaction_returning_status' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/database_statements.rb:267:in `block in transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/transaction.rb:239:in `block in within_new_transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/transaction.rb:236:in `synchronize' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/transaction.rb:236:in `within_new_transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/database_statements.rb:267:in `transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/transactions.rb:212:in `transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/transactions.rb:385:in `with_transaction_returning_status' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/transactions.rb:315:in `save!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/suppressor.rb:48:in `save!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/metasploit-credential-4.0.2/lib/metasploit/credential/creation.rb:496:in `block in create_credential_private' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/metasploit-credential-4.0.2/lib/metasploit/credential/creation.rb:623:in `retry_transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/metasploit-credential-4.0.2/lib/metasploit/credential/creation.rb:472:in `create_credential_private' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/metasploit-credential-4.0.2/lib/metasploit/credential/creation.rb:133:in `create_credential' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet/credential_servlet.rb:52:in `block (2 levels) in create_credential' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet_helper.rb:78:in `exec_report_job' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet/credential_servlet.rb:54:in `block in create_credential' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `block in compile!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (3 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1032:in `route_eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (2 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1061:in `block in process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1011:in `block in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `each' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1129:in `block in dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1124:in `dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `block in call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:929:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:36:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/xss_header.rb:18:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/path_traversal.rb:16:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/json_csrf.rb:26:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/frame_options.rb:31:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:266:in `context' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:260:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/null_logger.rb:11:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/head.rb:12:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:216:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1991:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1769:in `synchronize' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:86:in `block in pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:53:in `process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:39:in `receive_data' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run_machine' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/backends/base.rb:75:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/server.rb:162:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/controllers/controller.rb:87:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:203:in `run_command' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:159:in `run!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/bin/thin:6:in `<top (required)>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `load' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `<main>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `<main>' [-] Error handling request: Validation failed: Data is not in the NTLMHash data format of <LAN Manager hex digest>:<NT LAN Manager hex digest>, where each hex digest is 32 lowercase hexadecimal characters.. Call Stack: /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/validations.rb:80:in `raise_validation_error' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/validations.rb:52:in `save!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/transactions.rb:315:in `block in save!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/transactions.rb:387:in `block in with_transaction_returning_status' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/database_statements.rb:267:in `block in transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/transaction.rb:239:in `block in within_new_transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/transaction.rb:236:in `synchronize' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/transaction.rb:236:in `within_new_transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/connection_adapters/abstract/database_statements.rb:267:in `transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/transactions.rb:212:in `transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/transactions.rb:385:in `with_transaction_returning_status' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/transactions.rb:315:in `save!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.4/lib/active_record/suppressor.rb:48:in `save!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/metasploit-credential-4.0.2/lib/metasploit/credential/creation.rb:496:in `block in create_credential_private' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/metasploit-credential-4.0.2/lib/metasploit/credential/creation.rb:623:in `retry_transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/metasploit-credential-4.0.2/lib/metasploit/credential/creation.rb:472:in `create_credential_private' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/metasploit-credential-4.0.2/lib/metasploit/credential/creation.rb:133:in `create_credential' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet/credential_servlet.rb:52:in `block (2 levels) in create_credential' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet_helper.rb:78:in `exec_report_job' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet/credential_servlet.rb:54:in `block in create_credential' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `block in compile!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (3 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1032:in `route_eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (2 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1061:in `block in process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1011:in `block in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `each' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1129:in `block in dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1124:in `dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `block in call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:929:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:36:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/xss_header.rb:18:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/path_traversal.rb:16:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/json_csrf.rb:26:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/frame_options.rb:31:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:266:in `context' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:260:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/null_logger.rb:11:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/head.rb:12:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:216:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1991:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1769:in `synchronize' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:86:in `block in pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:53:in `process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:39:in `receive_data' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run_machine' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/backends/base.rb:75:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/server.rb:162:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/controllers/controller.rb:87:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:203:in `run_command' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:159:in `run!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/bin/thin:6:in `<top (required)>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `load' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `<main>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `<main>' [-] Error handling request: Couldn't find Metasploit::Credential::Core with 'id'=71. Call Stack: /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.5/lib/active_record/core.rb:177:in `find' /home/gwillcox/git/metasploit-framework/lib/msf/core/db_manager/cred.rb:277:in `block (2 levels) in delete_credentials' /home/gwillcox/git/metasploit-framework/lib/msf/core/db_manager/cred.rb:276:in `each' /home/gwillcox/git/metasploit-framework/lib/msf/core/db_manager/cred.rb:276:in `block in delete_credentials' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.5/lib/active_record/connection_adapters/abstract/connection_pool.rb:416:in `with_connection' /home/gwillcox/git/metasploit-framework/lib/msf/core/db_manager/cred.rb:274:in `delete_credentials' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet/credential_servlet.rb:77:in `block in delete_credentials' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `block in compile!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (3 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1032:in `route_eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (2 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1061:in `block in process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1011:in `block in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `each' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1129:in `block in dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1124:in `dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `block in call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:929:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:36:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/xss_header.rb:18:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/path_traversal.rb:16:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/json_csrf.rb:26:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/frame_options.rb:31:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:266:in `context' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:260:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/null_logger.rb:11:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/head.rb:12:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:216:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1991:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1769:in `synchronize' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:86:in `block in pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:53:in `process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:39:in `receive_data' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run_machine' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/backends/base.rb:75:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/server.rb:162:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/controllers/controller.rb:87:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:203:in `run_command' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:159:in `run!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/bin/thin:6:in `<top (required)>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `load' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `<main>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `<main>' [-] Error handling request: Validation failed: can't have private and public blank - at least one must be present.. Call Stack: /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.5/lib/active_record/validations.rb:80:in `raise_validation_error' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.5/lib/active_record/validations.rb:52:in `save!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.5/lib/active_record/transactions.rb:315:in `block in save!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.5/lib/active_record/transactions.rb:387:in `block in with_transaction_returning_status' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.5/lib/active_record/connection_adapters/abstract/database_statements.rb:267:in `block in transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.5/lib/active_record/connection_adapters/abstract/transaction.rb:239:in `block in within_new_transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.5/lib/active_record/connection_adapters/abstract/transaction.rb:236:in `synchronize' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.5/lib/active_record/connection_adapters/abstract/transaction.rb:236:in `within_new_transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.5/lib/active_record/connection_adapters/abstract/database_statements.rb:267:in `transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.5/lib/active_record/transactions.rb:212:in `transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.5/lib/active_record/transactions.rb:385:in `with_transaction_returning_status' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.5/lib/active_record/transactions.rb:315:in `save!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activerecord-5.2.4.5/lib/active_record/suppressor.rb:48:in `save!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/metasploit-credential-4.0.3/lib/metasploit/credential/creation.rb:264:in `block in create_credential_core' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/metasploit-credential-4.0.3/lib/metasploit/credential/creation.rb:623:in `retry_transaction' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/metasploit-credential-4.0.3/lib/metasploit/credential/creation.rb:256:in `create_credential_core' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/metasploit-credential-4.0.3/lib/metasploit/credential/creation.rb:144:in `create_credential' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet/credential_servlet.rb:52:in `block (2 levels) in create_credential' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet_helper.rb:75:in `exec_report_job' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet/credential_servlet.rb:54:in `block in create_credential' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `block in compile!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (3 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1032:in `route_eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (2 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1061:in `block in process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1011:in `block in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `each' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1129:in `block in dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1124:in `dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `block in call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:929:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:36:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/xss_header.rb:18:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/path_traversal.rb:16:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/json_csrf.rb:26:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/frame_options.rb:31:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:266:in `context' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:260:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/null_logger.rb:11:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/head.rb:12:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:216:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1991:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1769:in `synchronize' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:86:in `block in pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:53:in `process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:39:in `receive_data' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run_machine' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/backends/base.rb:75:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/server.rb:162:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/controllers/controller.rb:87:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:203:in `run_command' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:159:in `run!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/bin/thin:6:in `<top (required)>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `load' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `<main>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `<main>' [-] Error handling request: ""\xF0"" from ASCII-8BIT to UTF-8. Call Stack: /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/core_ext/object/json.rb:38:in `to_json' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/core_ext/object/json.rb:38:in `to_json' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:57:in `to_json' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/json-2.5.1/lib/json/common.rb:312:in `generate' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/json-2.5.1/lib/json/common.rb:312:in `generate' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:102:in `stringify' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:35:in `encode' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:22:in `encode' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/core_ext/object/json.rb:41:in `to_json' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet_helper.rb:181:in `to_json' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet_helper.rb:26:in `set_json_response' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet_helper.rb:31:in `set_json_data_response' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet/credential_servlet.rb:39:in `block in get_credentials' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `block in compile!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (3 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1032:in `route_eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (2 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1061:in `block in process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1011:in `block in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `each' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1129:in `block in dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1124:in `dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `block in call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:929:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:36:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/xss_header.rb:18:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/path_traversal.rb:16:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/json_csrf.rb:26:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/frame_options.rb:31:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:266:in `context' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:260:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/null_logger.rb:11:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/head.rb:12:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:216:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1991:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1769:in `synchronize' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:86:in `block in pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:53:in `process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:39:in `receive_data' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run_machine' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/backends/base.rb:75:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/server.rb:162:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/controllers/controller.rb:87:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:203:in `run_command' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:159:in `run!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/bin/thin:6:in `<top (required)>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `load' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `<main>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `<main>' [-] Error handling request: ""\xF0"" from ASCII-8BIT to UTF-8. Call Stack: /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/core_ext/object/json.rb:38:in `to_json' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/core_ext/object/json.rb:38:in `to_json' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:57:in `to_json' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/json-2.5.1/lib/json/common.rb:312:in `generate' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/json-2.5.1/lib/json/common.rb:312:in `generate' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:102:in `stringify' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:35:in `encode' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:22:in `encode' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/core_ext/object/json.rb:41:in `to_json' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet_helper.rb:181:in `to_json' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet_helper.rb:26:in `set_json_response' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet_helper.rb:31:in `set_json_data_response' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet/credential_servlet.rb:39:in `block in get_credentials' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `block in compile!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (3 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1032:in `route_eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (2 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1061:in `block in process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1011:in `block in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `each' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1129:in `block in dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1124:in `dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `block in call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:929:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:36:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/xss_header.rb:18:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/path_traversal.rb:16:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/json_csrf.rb:26:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/frame_options.rb:31:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:266:in `context' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:260:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/null_logger.rb:11:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/head.rb:12:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:216:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1991:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1769:in `synchronize' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:86:in `block in pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:53:in `process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:39:in `receive_data' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run_machine' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/backends/base.rb:75:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/server.rb:162:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/controllers/controller.rb:87:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:203:in `run_command' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:159:in `run!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/bin/thin:6:in `<top (required)>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `load' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `<main>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `<main>' [-] Error handling request: ""\xF0"" from ASCII-8BIT to UTF-8. Call Stack: /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/core_ext/object/json.rb:38:in `to_json' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/core_ext/object/json.rb:38:in `to_json' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:57:in `to_json' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/json-2.5.1/lib/json/common.rb:312:in `generate' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/json-2.5.1/lib/json/common.rb:312:in `generate' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:102:in `stringify' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:35:in `encode' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:22:in `encode' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/core_ext/object/json.rb:41:in `to_json' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet_helper.rb:181:in `to_json' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet_helper.rb:26:in `set_json_response' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet_helper.rb:31:in `set_json_data_response' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet/credential_servlet.rb:39:in `block in get_credentials' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `block in compile!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (3 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1032:in `route_eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (2 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1061:in `block in process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1011:in `block in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `each' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1129:in `block in dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1124:in `dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `block in call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:929:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:36:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/xss_header.rb:18:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/path_traversal.rb:16:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/json_csrf.rb:26:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/frame_options.rb:31:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:266:in `context' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:260:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/null_logger.rb:11:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/head.rb:12:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:216:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1991:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1769:in `synchronize' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:86:in `block in pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:53:in `process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:39:in `receive_data' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run_machine' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/backends/base.rb:75:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/server.rb:162:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/controllers/controller.rb:87:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:203:in `run_command' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:159:in `run!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/bin/thin:6:in `<top (required)>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `load' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `<main>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `<main>' [-] Error handling request: ""\xF0"" from ASCII-8BIT to UTF-8. Call Stack: /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/core_ext/object/json.rb:38:in `to_json' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/core_ext/object/json.rb:38:in `to_json' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:57:in `to_json' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/json-2.5.1/lib/json/common.rb:312:in `generate' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/json-2.5.1/lib/json/common.rb:312:in `generate' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:102:in `stringify' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:35:in `encode' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:22:in `encode' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/core_ext/object/json.rb:41:in `to_json' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet_helper.rb:181:in `to_json' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet_helper.rb:26:in `set_json_response' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet_helper.rb:31:in `set_json_data_response' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet/credential_servlet.rb:39:in `block in get_credentials' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `block in compile!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (3 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1032:in `route_eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (2 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1061:in `block in process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1011:in `block in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `each' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1129:in `block in dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1124:in `dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `block in call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:929:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:36:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/xss_header.rb:18:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/path_traversal.rb:16:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/json_csrf.rb:26:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/frame_options.rb:31:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:266:in `context' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:260:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/null_logger.rb:11:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/head.rb:12:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:216:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1991:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1769:in `synchronize' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:86:in `block in pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:53:in `process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:39:in `receive_data' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run_machine' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/backends/base.rb:75:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/server.rb:162:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/controllers/controller.rb:87:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:203:in `run_command' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:159:in `run!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/bin/thin:6:in `<top (required)>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `load' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `<main>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `<main>' [-] Error handling request: ""\xF0"" from ASCII-8BIT to UTF-8. Call Stack: /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/core_ext/object/json.rb:38:in `to_json' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/core_ext/object/json.rb:38:in `to_json' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:57:in `to_json' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/json-2.5.1/lib/json/common.rb:312:in `generate' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/json-2.5.1/lib/json/common.rb:312:in `generate' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:102:in `stringify' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:35:in `encode' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:22:in `encode' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/core_ext/object/json.rb:41:in `to_json' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet_helper.rb:181:in `to_json' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet_helper.rb:26:in `set_json_response' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet_helper.rb:31:in `set_json_data_response' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet/credential_servlet.rb:39:in `block in get_credentials' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `block in compile!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (3 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1032:in `route_eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (2 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1061:in `block in process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1011:in `block in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `each' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1129:in `block in dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1124:in `dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `block in call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:929:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:36:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/xss_header.rb:18:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/path_traversal.rb:16:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/json_csrf.rb:26:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/frame_options.rb:31:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:266:in `context' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:260:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/null_logger.rb:11:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/head.rb:12:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:216:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1991:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1769:in `synchronize' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:86:in `block in pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:53:in `process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:39:in `receive_data' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run_machine' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/backends/base.rb:75:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/server.rb:162:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/controllers/controller.rb:87:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:203:in `run_command' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:159:in `run!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/bin/thin:6:in `<top (required)>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `load' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `<main>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `<main>' ``` </details> ## Framework Logs The following framework logs were recorded before the issue occurred: <details> <summary>Collapse</summary> ``` [03/24/2021 16:52:29] [d(0)] core: Updated user based module store [03/24/2021 16:52:32] [e(0)] core: Dependency for windows/x64/encrypted_shell_reverse_tcp is not supported [03/24/2021 16:52:32] [e(0)] core: Dependency for windows/encrypted_shell_reverse_tcp is not supported [03/24/2021 16:52:32] [e(0)] core: Dependency for windows/x64/encrypted_reverse_tcp is not supported [03/24/2021 16:52:32] [e(0)] core: Dependency for windows/encrypted_reverse_tcp is not supported [03/24/2021 16:52:33] [e(0)] core: /home/gwillcox/git/metasploit-framework/modules/auxiliary/gather/office365userenum.py failed to load - LoadError Try running file manually to check for errors or dependency issues. [03/25/2021 13:54:37] [i(0)] core: Default data service found. Attempting to connect... [03/25/2021 13:54:37] [d(0)] core: Updated user based module store [03/25/2021 13:54:38] [e(0)] core: Dependency for windows/x64/encrypted_shell_reverse_tcp is not supported [03/25/2021 13:54:38] [e(0)] core: Dependency for windows/encrypted_shell_reverse_tcp is not supported [03/25/2021 13:54:38] [e(0)] core: Dependency for windows/x64/encrypted_reverse_tcp is not supported [03/25/2021 13:54:38] [e(0)] core: Dependency for windows/encrypted_reverse_tcp is not supported [03/25/2021 13:54:39] [e(0)] core: /home/gwillcox/git/metasploit-framework/modules/auxiliary/gather/office365userenum.py failed to load - LoadError Try running file manually to check for errors or dependency issues. [03/25/2021 13:54:58] [e(0)] core: Dependency for windows/x64/encrypted_shell_reverse_tcp is not supported [03/25/2021 13:54:58] [e(0)] core: Dependency for windows/encrypted_shell_reverse_tcp is not supported [03/25/2021 13:54:59] [e(0)] core: Dependency for windows/x64/encrypted_reverse_tcp is not supported [03/25/2021 13:54:59] [e(0)] core: Dependency for windows/encrypted_reverse_tcp is not supported [03/25/2021 13:58:23] [e(0)] core: Dependency for windows/x64/encrypted_shell_reverse_tcp is not supported [03/25/2021 13:58:23] [e(0)] core: Dependency for windows/encrypted_shell_reverse_tcp is not supported [03/25/2021 13:58:23] [e(0)] core: Dependency for windows/x64/encrypted_reverse_tcp is not supported [03/25/2021 13:58:23] [e(0)] core: Dependency for windows/encrypted_reverse_tcp is not supported [03/25/2021 14:24:00] [i(0)] core: Default data service found. Attempting to connect... [03/25/2021 14:24:01] [d(0)] core: Updated user based module store [03/25/2021 14:24:02] [e(0)] core: Dependency for windows/x64/encrypted_shell_reverse_tcp is not supported [03/25/2021 14:24:02] [e(0)] core: Dependency for windows/encrypted_shell_reverse_tcp is not supported [03/25/2021 14:24:02] [e(0)] core: Dependency for windows/x64/encrypted_reverse_tcp is not supported [03/25/2021 14:24:02] [e(0)] core: Dependency for windows/encrypted_reverse_tcp is not supported [03/25/2021 14:24:02] [e(0)] core: /home/gwillcox/git/metasploit-framework/modules/auxiliary/gather/office365userenum.py failed to load - LoadError Try running file manually to check for errors or dependency issues. [03/25/2021 14:31:54] [i(0)] core: Default data service found. Attempting to connect... [03/25/2021 14:31:56] [e(0)] core: Dependency for windows/x64/encrypted_shell_reverse_tcp is not supported [03/25/2021 14:31:56] [e(0)] core: Dependency for windows/encrypted_shell_reverse_tcp is not supported [03/25/2021 14:31:56] [e(0)] core: Dependency for windows/x64/encrypted_reverse_tcp is not supported [03/25/2021 14:31:56] [e(0)] core: Dependency for windows/encrypted_reverse_tcp is not supported [03/25/2021 14:31:56] [e(0)] core: /home/gwillcox/git/metasploit-framework/modules/auxiliary/gather/office365userenum.py failed to load - LoadError Try running file manually to check for errors or dependency issues. [03/25/2021 14:32:04] [e(0)] core: Dependency for windows/x64/encrypted_shell_reverse_tcp is not supported [03/25/2021 14:32:04] [e(0)] core: Dependency for windows/encrypted_shell_reverse_tcp is not supported [03/25/2021 14:32:04] [e(0)] core: Dependency for windows/x64/encrypted_reverse_tcp is not supported [03/25/2021 14:32:04] [e(0)] core: Dependency for windows/encrypted_reverse_tcp is not supported [03/25/2021 14:48:57] [i(0)] core: Default data service found. Attempting to connect... [03/25/2021 14:48:59] [e(0)] core: Dependency for windows/x64/encrypted_shell_reverse_tcp is not supported [03/25/2021 14:48:59] [e(0)] core: Dependency for windows/encrypted_shell_reverse_tcp is not supported [03/25/2021 14:48:59] [e(0)] core: Dependency for windows/x64/encrypted_reverse_tcp is not supported [03/25/2021 14:48:59] [e(0)] core: Dependency for windows/encrypted_reverse_tcp is not supported [03/25/2021 14:48:59] [e(0)] core: /home/gwillcox/git/metasploit-framework/modules/auxiliary/gather/office365userenum.py failed to load - LoadError Try running file manually to check for errors or dependency issues. [03/25/2021 14:49:32] [i(0)] core: Default data service found. Attempting to connect... [03/25/2021 14:49:33] [e(0)] core: Dependency for windows/x64/encrypted_shell_reverse_tcp is not supported [03/25/2021 14:49:33] [e(0)] core: Dependency for windows/encrypted_shell_reverse_tcp is not supported [03/25/2021 14:49:33] [e(0)] core: Dependency for windows/x64/encrypted_reverse_tcp is not supported [03/25/2021 14:49:33] [e(0)] core: Dependency for windows/encrypted_reverse_tcp is not supported [03/25/2021 14:49:34] [e(0)] core: /home/gwillcox/git/metasploit-framework/modules/auxiliary/gather/office365userenum.py failed to load - LoadError Try running file manually to check for errors or dependency issues. ``` </details> ## Web Service Logs The following web service logs were recorded before the issue occurred: <details> <summary>Collapse</summary> ``` /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet_helper.rb:31:in `set_json_data_response' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet/credential_servlet.rb:39:in `block in get_credentials' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `block in compile!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (3 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1032:in `route_eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (2 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1061:in `block in process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1011:in `block in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `each' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1129:in `block in dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1124:in `dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `block in call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:929:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:36:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/xss_header.rb:18:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/path_traversal.rb:16:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/json_csrf.rb:26:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/frame_options.rb:31:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:266:in `context' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:260:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/null_logger.rb:11:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/head.rb:12:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:216:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1991:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1769:in `synchronize' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:86:in `block in pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:53:in `process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:39:in `receive_data' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run_machine' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/backends/base.rb:75:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/server.rb:162:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/controllers/controller.rb:87:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:203:in `run_command' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:159:in `run!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/bin/thin:6:in `<top (required)>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `load' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `<main>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `<main>' [-] Error handling request: ""\xF0"" from ASCII-8BIT to UTF-8. Call Stack: /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/core_ext/object/json.rb:38:in `to_json' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/core_ext/object/json.rb:38:in `to_json' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:57:in `to_json' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/json-2.5.1/lib/json/common.rb:312:in `generate' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/json-2.5.1/lib/json/common.rb:312:in `generate' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:102:in `stringify' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:35:in `encode' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/json/encoding.rb:22:in `encode' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/activesupport-5.2.4.5/lib/active_support/core_ext/object/json.rb:41:in `to_json' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet_helper.rb:181:in `to_json' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet_helper.rb:26:in `set_json_response' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet_helper.rb:31:in `set_json_data_response' /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet/credential_servlet.rb:39:in `block in get_credentials' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1675:in `block in compile!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (3 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1032:in `route_eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1013:in `block (2 levels) in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1061:in `block in process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1059:in `process_route' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1011:in `block in route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `each' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1008:in `route!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1129:in `block in dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1124:in `dispatch!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `block in call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `block in invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1101:in `invoke' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:939:in `call!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:929:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:36:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/warden-1.2.9/lib/warden/manager.rb:34:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/xss_header.rb:18:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/path_traversal.rb:16:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/json_csrf.rb:26:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/base.rb:50:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-protection-2.1.0/lib/rack/protection/frame_options.rb:31:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:266:in `context' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/session/abstract/id.rb:260:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/null_logger.rb:11:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/rack-2.2.3/lib/rack/head.rb:12:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:216:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1991:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `block in call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1769:in `synchronize' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/sinatra-2.1.0/lib/sinatra/base.rb:1542:in `call' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:86:in `block in pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `catch' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:84:in `pre_process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:53:in `process' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/connection.rb:39:in `receive_data' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run_machine' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/eventmachine-1.2.7/lib/eventmachine.rb:195:in `run' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/backends/base.rb:75:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/server.rb:162:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/controllers/controller.rb:87:in `start' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:203:in `run_command' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/lib/thin/runner.rb:159:in `run!' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/gems/thin-1.8.0/bin/thin:6:in `<top (required)>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `load' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/thin:23:in `<main>' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `eval' /home/gwillcox/.rvm/gems/ruby-2.7.2@metasploit-framework/bin/ruby_executable_hooks:24:in `<main>' 2021-03-22 14:54:20 -0500 Exiting! 2021-03-22 15:00:27 -0500 Writing PID to /home/gwillcox/.msf4/msf-ws.pid 2021-03-22 15:00:28 -0500 Thin web server (v1.8.0 codename Possessed Pickle) 2021-03-22 15:00:28 -0500 Maximum connections set to 1024 2021-03-22 15:00:28 -0500 Listening on localhost:5443, CTRL+C to stop #<Thread:0x000055849858fc10 /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/job_processor.rb:18 run> terminated with exception (report_on_exception is true): /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/job_processor.rb:24:in `rescue in block (2 levels) in start_processor_thread': undefined method `print_error' for #<Msf::WebServices::JobProcessor:0x000055849858fcb0> (NoMethodError) from /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/job_processor.rb:21:in `block (2 levels) in start_processor_thread' from /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/job_processor.rb:19:in `loop' from /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/job_processor.rb:19:in `block in start_processor_thread' /home/gwillcox/git/metasploit-framework/lib/msf/core/db_manager/session_event.rb:65:in `report_session_event': Missing required option :session (ArgumentError) from /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/servlet/session_event_servlet.rb:39:in `block (2 levels) in report_session_event' from /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/job_processor.rb:22:in `block (2 levels) in start_processor_thread' from /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/job_processor.rb:19:in `loop' from /home/gwillcox/git/metasploit-framework/lib/msf/core/web_services/job_processor.rb:19:in `block in start_processor_thread' ``` </details> ## Version/Install The versions and install method of your Metasploit setup: <details> <summary>Collapse</summary> ``` Framework: 6.0.38-dev-9033dd19bc Ruby: ruby 2.7.2p137 (2020-10-01 revision 5445e04352) [x86_64-linux] Install Root: /home/gwillcox/git/metasploit-framework Session Type: Connected to remote_data_service: (https://localhost:5443). Connection type: http. Install Method: Git Clone ``` </details> "
438498,487505,https://api.github.com/repos/ioBroker/ioBroker.hm-rega/issues/155,question,2021-05-14T14:01:43Z,NONE,https://api.github.com/repos/ioBroker/ioBroker.hm-rega,"Do not set 'state', because non-existing in corresponding adapter Habe ein frisches docker (buanet/iobroker:latest-v5) erstellt und hm-rpc sowie hm-rega installiert. Die wenigen Geräte in meiner CCU werden anscheinend auch gefunden und device sowie channel angelegt in der Objekt Übersicht, leider keine states der Geräte. Bisher nur states von den Allgemeinen Meldungen sowie Programmen. Mit aktivierten DEBUG log der beiden Adapter tauchen dann bei ""datapoints.fn 1.9"" einige Einträge folgender Art im Log auf: ``` ... hm-rega.0 (1586) Do not set ""{""val"":true,""ack"":true}"" to ""hm-rpc.0.000C1BE9A24C47.1.PRESENCE_DETECTION_STATE"", because non-existing in corresponding adapter ... ``` Bis auf die 'states' wie in diesem Beispiel 'PRESENCE_DETECTION_STATE' sind die Objekte genau so in dem Objekt Browser vorhanden. Wie könnte ich dem adapter mitteilen das er die states auch auflisten/anlegen soll? Fehlt mir eventuell noch eine weitere/andere Einstellung? **Screenshots & Logfiles** - [docker-compose.yml.txt](https://github.com/ioBroker/ioBroker.hm-rega/files/6479167/docker-compose.yml.txt) - [iobroker.2021-05-14.log](https://github.com/ioBroker/ioBroker.hm-rega/files/6479169/iobroker.2021-05-14.log) - ![object_browser](https://user-images.githubusercontent.com/84186603/118282243-5fe46b80-b4ce-11eb-8dad-5a206f41052b.PNG) **Versions:** - hm-rpc version: 1.14.37 - hm-rega version: 3.0.16 - JS-Controller version: 3.2.16 - Node version: 12.22.1 - Operating system: Docker buanet/iobroker:latest-v5 (host: Debian buster Kernel-release 5.8.0-50-generic x64) - CCU model: raspberrymatic - CCU firmware: 3.57.5.20210424 Gruß svelys"
562272,624865,https://api.github.com/repos/microsoft/vscode-docker/issues/2838,bug,2021-04-04T06:49:28Z,NONE,https://api.github.com/repos/microsoft/vscode-docker,"Files from readme (gif, png) not loading in VSCODE's extensions tab For some reason none of the files are showing up in Vscode's extensions. I thought of using the files' relative paths instead, or even adding ?raw=true at the end of the urls, but I'm not sure either one is going to work. I also tried refreshing Vscode, so I don't think the issue is on my end. I included a screenshot, hopefully this helps. ![dockerscreenshot](https://user-images.githubusercontent.com/77614258/113500954-4ab90c00-9522-11eb-80eb-e12d84d34918.png) "
624071,693553,https://api.github.com/repos/dominikh/go-tools/issues/699,enhancement,2020-02-17T11:46:02Z,NONE,https://api.github.com/repos/dominikh/go-tools,"staticcheck verbose mode Hey, It would be nice if staticcheck had a `-verbose` flag that would show all files that are scanned, similarly e.g. to `gosec`. This might be helpful when checking out a repository with a complex build system (e.g. conditional compilation of files based on architecture or some tags)."
191962,213473,https://api.github.com/repos/awebre/la-historical-markers/issues/25,bug,2021-04-15T16:40:37Z,OWNER,https://api.github.com/repos/awebre/la-historical-markers,"""Go Button"" - Always include Google Maps Currently, I have no idea what happens if you hit the Go button without having at least one of the following app installed: Google Maps Apple Maps Waze Since we aren't explicitly using the `alwaysIncludeGoogle` option, something probably breaks (or nothing happens, which is also bad™️). TLDR; we should pass the `alwaysIncludeGoogle` option with value `true` to `showLocation`"
332705,369881,https://api.github.com/repos/CelestiaProject/Celestia/issues/833,enhancement,2020-08-28T16:37:34Z,COLLABORATOR,https://api.github.com/repos/CelestiaProject/Celestia,"(One more) way to improve albedo Albedo-related improvement was first raised by the Celestia Origin team, then on Discord and here (#624). Last time (on Discord) I wrote that it would be nice to connect `Albedo` to `BondAlbedo` too, but… `BondAlbedo` is limited to 1, while `GeomAlbedo` is unlimited. This can create problems with calculating temperatures for bodies with strongly directional reflectivity. So I propose to discuss adding four albedo parameters: 1. `Albedo` (from 0 to ∞) For backward compatibility only. It isn't possible to cover all use cases with one parameter. _If specified, interpreted as `GeomAlbedo` as the most likely option._ 2. `GeomAlbedo` (from 0 to ∞) The geometric albedo is the most common parameter and the most useless for us 😕 If simplified, it is the brightness of the full disk (in zero phase angle). However, just in this case, the reflectivity of many bodies increases significantly (due to the [opposition surge](https://en.wikipedia.org/wiki/Opposition_surge)). For this reason, it will be much more accurate to use `Reflectivity` instead. _Sets the `BondAlbedo` and `Reflectivity` values if it is <1, otherwise as 1._ Because imprecise values are better than no values. 3. `BondAlbedo` (from 0 to 1) Nothing changes here. Still used for reliable temperature calculations. 4. `Reflectivity` (from 0 to 1) This albedo has no generally accepted name (for example, ""Normal albedo"" is used [here](https://www.researchgate.net/figure/LORRI-albedos-on-Pluto-Panel-A-shows-normal-albedo-across-Pluto-from-LORRI-panchromatic_fig12_298918241)). It can probably be called ""visual spherical albedo"" or ""visual Bond albedo"". Without going into detail, this is the visible average global reflectivity, just what is needed for points' brightness if phase curves are unknown. Here is an illustration of the light curves from [this](https://arxiv.org/abs/1511.04415) paper: ![light_curves](https://user-images.githubusercontent.com/44873271/91576226-54591080-e950-11ea-9d8e-85192c7cfbc7.png) You can see the brightness peak at zero phase angle (corresponding to the geometric albedo). Table with parameters from the same paper, except for the Bond albedo: Celestial body | `GeomAlbedo` | `BondAlbedo` | `Reflectivity` -- | -- | -- | -- Enceladus | 1.362 | [0.81](https://www.sciencedirect.com/science/article/abs/pii/S001910350900308X) | 1.0 Callisto | 0.235 | [0.05](https://www.sciencedirect.com/science/article/abs/pii/0019103580902183) | 0.09 What do you think about this? I tried to take into account all previous opinions. _UPD: new albedo parameter renamed to `Reflectivity`_"
185175,205893,https://api.github.com/repos/hawkmoth-studio/perforce-docker/issues/25,bug,2020-12-30T22:10:54Z,CONTRIBUTOR,https://api.github.com/repos/hawkmoth-studio/perforce-docker,"Random errors 'Worker 1 initial preflight failure. Aborting.' in Swarm log ``` Fail create ctx on the connecting client. Failed to initialize SSL library. NetSslTransport::SslClientInit SSL_load_error_strings: error:0909006C:PEM routines:get_name:no start line: Success in /opt/perforce/swarm/library/P4/Connection/Extension.php:477 Stack trace: #0 /opt/perforce/swarm/library/P4/Connection/AbstractConnection.php(1010): P4\Connection\Extension->doConnect() #1 /opt/perforce/swarm/library/P4/Connection/AbstractConnection.php(710): P4\Connection\AbstractConnection->connect() #2 /opt/perforce/swarm/library/P4/Connection/AbstractConnection.php(403): P4\Connection\AbstractConnection->run('info') #3 /opt/perforce/swarm/module/Queue/src/Controller/IndexController.php(343): P4\Connection\AbstractConnection->getInfo() #4 /opt/perforce/swarm/module/Queue/src/Controller/IndexController.php(115): Queue\Controller\IndexController->preflight() #5 /opt/perforce/swarm/vendor/laminas/laminas-mvc/src/Controller/AbstractActionController.php(77): Queue\Controller\IndexController->workerAction() #6 /opt/perforce/swarm/vendor/laminas/laminas-eventmanager/src/EventManager.php(321): Laminas\Mvc\Controller\AbstractActionController->onDispatch(Object(Laminas\Mvc\MvcEvent)) #7 /opt/perforce/swarm/vendor/laminas/laminas-eventmanager/src/EventManager.php(178): Laminas\EventManager\EventManager->triggerListeners(Object(Laminas\Mvc\MvcEvent), Object(Closure)) #8 /opt/perforce/swarm/vendor/laminas/laminas-mvc/src/Controller/AbstractController.php(105): Laminas\EventManager\EventManager->triggerEventUntil(Object(Closure), Object(Laminas\Mvc\MvcEvent)) #9 /opt/perforce/swarm/vendor/laminas/laminas-mvc/src/DispatchListener.php(139): Laminas\Mvc\Controller\AbstractController->dispatch(Object(Laminas\Http\PhpEnvironment\Request), Object(Laminas\Http\PhpEnvironment\Response)) #10 /opt/perforce/swarm/vendor/laminas/laminas-eventmanager/src/EventManager.php(321): Laminas\Mvc\DispatchListener->onDispatch(Object(Laminas\Mvc\MvcEvent)) #11 /opt/perforce/swarm/vendor/laminas/laminas-eventmanager/src/EventManager.php(178): Laminas\EventManager\EventManager->triggerListeners(Object(Laminas\Mvc\MvcEvent), Object(Closure)) #12 /opt/perforce/swarm/vendor/laminas/laminas-mvc/src/Application.php(331): Laminas\EventManager\EventManager->triggerEventUntil(Object(Closure), Object(Laminas\Mvc\MvcEvent)) #13 /opt/perforce/swarm/public/index.php(65): Laminas\Mvc\Application->run() #14 {main} ```"
286054,318112,https://api.github.com/repos/digitalbazaar/bedrock-authn-token-http/issues/6,enhancement,2020-03-05T02:55:13Z,CONTRIBUTOR,https://api.github.com/repos/digitalbazaar/bedrock-authn-token-http,"Implement a `clientId` cookie. Yes, there should be an issue to implement an actual cookie for that. _Originally posted by @dlongley in https://github.com/digitalbazaar/bedrock-authn-token-http/pull/5_"
196722,218726,https://api.github.com/repos/metersphere/metersphere/issues/383,enhancement,2020-09-09T03:08:52Z,NONE,https://api.github.com/repos/metersphere/metersphere,[FEATURE]测试用例支持添加自定义字段，备注里支持上传截图 **请描述您的需求或者改进建议.** 1、测试用例支持扩展添加自定义字段配置， 2、测试用例备注里支持上传截图 **请描述你建议的实现方案** 
645318,717268,https://api.github.com/repos/YTVanced/Vanced/issues/148,bug,2020-11-04T03:55:15Z,NONE,https://api.github.com/repos/YTVanced/Vanced,"[Bug] Dark mode miui 12.0.2. notification bar **Bug description** When you turn on dark mode in miui 12.0.2.0 the notification bar on YouTube Vanced turns black with opacity and black text making it not clear. Would have wanted to optimise the app for dark mode to display white font like in the portrait mode. Phone: Xiaomi Redmi Note 8 Pro, android 10, miui 12.0.2. Disabling dark mode solves the issue. Neither setting dark mode at Vanced settings nor YouTube settings in YouTube Vanced app solves the issue. Also disabling/enabling miui enhancements doesn't solve the issue. Setting ""disable dark mode for specific app"" for YouTube Vanced to turn off dark mode doesn't work. You could just fix this to let disable dark mode from miui for that specific app or somewhat trick the font. **Variant** NonRoot: Yes Root: No **Vanced version** 15.43.32 - Build - 01.47.00 **Android version** Android 10 **Device** Xiaomi Redmi Note 8 Pro **Steps to Reproduce** Steps to reproduce the error: 1. Have Xiaomi phone with miui 2. Enable dark mode 3. Open app 4. Turn on video 5. Make it full screen (landscape) 6. Show notification bar - text is black, bar is black 7. In portrait mode notification bar is black text is white. **Expected behavior** Make text in the notification bar white when in landscape mode using miui dark mode. _Attach images/videos if possible. These can be helpful in solving the issue._ ![Screenshot_2020-11-04-03-29-46-995_com vanced android youtube](https://user-images.githubusercontent.com/27486533/98067447-d76b7b00-1e59-11eb-89b1-395af6fa6361.jpg) ![Screenshot_2020-11-04-03-29-52-107_com vanced android youtube](https://user-images.githubusercontent.com/27486533/98067469-e4886a00-1e59-11eb-80ef-3ee9c38775d0.jpg) "
531379,590599,https://api.github.com/repos/opendata-mvcr/sgov/issues/84,enhancement,2021-01-14T09:27:13Z,CONTRIBUTOR,https://api.github.com/repos/opendata-mvcr/sgov,"Integration with Keycloak authorization service. As a user, I want to be able to use the production line tools with only one account. To simplify matters, we will use a Keycloak server as an authentication/authorization service. The SGoV server should be able to verify provided token against a Keycloak service to see whether the user is authenticated and get their basic data for internal purposes (email for logging, etc.). No other authentication/authorization mechanism should be possible. See https://github.com/opendata-mvcr/termit/tree/enhancement/52-keycloak-auth for example configuration."
36694,40910,https://api.github.com/repos/eclipse/sumo/issues/8497,bug,2021-04-16T05:19:54Z,CONTRIBUTOR,https://api.github.com/repos/eclipse/sumo,proj.db error on windows release 1.9.0 prints ``` pj_obj_create: Cannot find proj.db ``` as error output on the console multiple times when loading a geo-referenced network with sumo or netconvert. Functionality doesn't seem to be affected
720262,800487,https://api.github.com/repos/RainbowMiner/RainbowMiner/issues/1451,bug,2021-02-27T17:35:09Z,NONE,https://api.github.com/repos/RainbowMiner/RainbowMiner,"GPU Device Order issue On one of my devices, at some point, I moved around some connections and where the device order was something like: ""card type 1, card type 2, card type 1, card type 2"" it is now ""card type 1, card type 1, card type 2, card type 2"" If I use them in legacy mode, it doesn't matter for the most part. If I change the mode, or if I use an algorithm that isn't compatible with all cards it can crash or not use all of them. The question I have is how do I force RBMiner to rescan/rebuild its GPU config for this machine?"
479875,533350,https://api.github.com/repos/bpatrik/pigallery2/issues/142,enhancement,2020-03-24T12:59:15Z,NONE,https://api.github.com/repos/bpatrik/pigallery2,"Auto-start pigallery2 on raspberrypi start-up This is not a feature request, is a instalation help request, sorry about that but I can't find support anywhere. I'm linux newbye, I instaled pigallery2 on my pi with the ""Getting Started"" guide, I can start it manually but I'm unable to make it auto-start when I reboot my pi, a guide to auto-start pigallery2 on raspberrypi start-up would be nice for newbyes. "
590453,656167,https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity/issues/8686,bug,2020-09-26T02:55:52Z,CONTRIBUTOR,https://api.github.com/repos/microsoft/MixedRealityToolkit-Unity,Switching from Standalone to UWP with Hand Physics Examples scene open in the editor throws a null exception ## Describe the bug When switching from Standalone to UWP with the Hand Physics Examples scene open in the editor throws a null exception. This happen only happens in Unity 2019. ## To reproduce Steps to reproduce the behavior: 1. Import all MRTK .unitypackages 2. Double click Assets/MRTK/Extensions/HandPhysicsService/Examples/HandPhysicsServiceExample.unity to open the scene with the viewport 3. Switch from Standalone to UWP 4. See error in Unity console ## Expected behavior A null exception will not be thrown when switching platforms. ## Screenshots ![switchtouwphandphysnullexception](https://user-images.githubusercontent.com/65038391/94328636-fcbabe80-ff68-11ea-9155-501e914b955c.png) ## Your setup (please complete the following information) - Unity Version 2019.4.10f1 - MRTK Version 20200925.7 ## Target platform (please complete the following information) - Standalone - UWP 
374531,416344,https://api.github.com/repos/nav-gov-hu/Online-Invoice/issues/377,question,2020-09-23T08:32:59Z,NONE,https://api.github.com/repos/nav-gov-hu/Online-Invoice,"Email üzeneteik intelligenssé tétele Megoldható lenne, hogy az automata e-mail küldözgetőjük ne jelezzen a felhasználó felé, amikor a szerverük rosszul működik (mint ma is) és vagy befogad egy számlát vagy nem, de nem ad vissza ID-t timeouton belül? Emiatt nem lehet biztosra tudni, hogy a számla felment-e. Ilyenkor a program újraküldi és ha a rendszerük mégis befogadta csak nem adott választ időben, akkor a rendszerük később küld egy e-mailt a felhasználónak hogy kétszer szolgáltatta ugyanazt a számlát. Jó lenne, ha az automata levelező figyelné, hogy mikor van ez a NAV szerverének hibája miatt és olyan időszakra eső esetekre nem küldözgetne leveleket. "
158503,176220,https://api.github.com/repos/knative-sandbox/eventing-kafka-broker/issues/707,bug,2021-03-06T17:49:50Z,MEMBER,https://api.github.com/repos/knative-sandbox/eventing-kafka-broker,"[flaky] TestBrokerAuthSslSaslScram512 - secrets ""broker-auth"" not found ## Expected Behavior No errors. ## Actual Behavior ``` failed to create security (auth) option: failed to get secret test-broker-auth-ssl-sasl-scram512-0-ttjlf/broker-auth: secrets ""broker-auth"" not found ``` ## Steps to Reproduce the Problem :shrug: ## Additional Info - https://github.com/knative-sandbox/eventing-kafka-broker/runs/2045098160?check_suite_focus=true "
62063,68995,https://api.github.com/repos/davidnguyen179/spotify-extension/issues/76,enhancement,2021-01-26T13:33:40Z,OWNER,https://api.github.com/repos/davidnguyen179/spotify-extension,Add repeat API https://developer.spotify.com/console/put-repeat/
317486,352959,https://api.github.com/repos/sqlalchemy/sqlalchemy/issues/6060,bug,2021-03-16T12:11:18Z,NONE,https://api.github.com/repos/sqlalchemy/sqlalchemy,"correlate_except does not seem to correlate from a CTE or subquery, possibly local to column_property() w aliased() Hello, Firstly, thank you very much for this library, we really appreciate this powerful tool. **Describe the bug** In legacy version 1.3, correlate_except is wrong with deferred loading column after CTE expression. In new version 1.4, defer doesn't work as previous version 1.3 so it isn't possible to test if the bug exists. **Expected behavior** FROM clause in subquery should take the correct table (correlated subquery) and `defer` in 1.4 should work as intended as previous version 1.3 **To Reproduce** Firstly, I created a full test script: ```python from sqlalchemy import Column, ForeignKey, Integer, Text from sqlalchemy import func, select from sqlalchemy.ext.declarative import declarative_base from sqlalchemy.orm import aliased, column_property, defer, sessionmaker Base = declarative_base() class Address(Base): __tablename__ = ""addresses"" id = Column(Integer, primary_key=True) user_id = Column(Integer, ForeignKey(""users.id""), nullable=False) city = Column(Text) class User(Base): __tablename__ = ""users"" id = Column(Integer, primary_key=True) name = Column(Text) total_addresses = column_property( select([func.count(Address.id)]) .where(Address.user_id == id) .correlate_except(Address) # .scalar_subquery() # SQLAlchemy 1.4 ) session = sessionmaker()() filtered_users = ( session.query(User) .join(Address) .filter(Address.city == ""somewhere"") .options(defer(User.total_addresses)) .cte(""filtered_users"") ) filtered_users_alias: User = aliased(User, filtered_users) paginated_users = ( session.query(filtered_users_alias) .order_by(func.lower(filtered_users_alias.name).asc()) .limit(25) .options(defer(""total_addresses"")) .cte(""paginated_users"") ) paginated_users_alias: User = aliased(User, paginated_users) print(session.query(paginated_users_alias)) ``` with legacy 1.3, this script gives: ```sql WITH filtered_users AS (SELECT users.id AS id, users.name AS name FROM users JOIN addresses ON users.id = addresses.user_id WHERE addresses.city = :city_1), paginated_users AS (SELECT filtered_users.id AS id, filtered_users.name AS name FROM filtered_users ORDER BY lower(filtered_users.name) ASC LIMIT :param_1) SELECT (SELECT count(addresses.id) AS count_1 FROM paginated_users WHERE addresses.user_id = paginated_users.id) AS anon_1, paginated_users.id AS paginated_users_id, paginated_users.name AS paginated_users_name FROM paginated_users ``` This is wrong in subquery: ```sql SELECT count(addresses.id) AS count_1 FROM paginated_users WHERE addresses.user_id = paginated_users.id) AS anon_1 ``` which should be (noted the different FROM clause): ```sql SELECT count(addresses.id) AS count_1 FROM addresses WHERE addresses.user_id = paginated_users.id) AS anon_1 ``` This isn't producible in version 1.4, because defer doesn't work as intended, SQLAlchemy 1.4 gives: ```sql WITH filtered_users AS (SELECT (SELECT count(addresses.id) AS count_1 FROM addresses WHERE addresses.user_id = users.id) AS anon_1, users.id AS id, users.name AS name FROM users JOIN addresses ON users.id = addresses.user_id WHERE addresses.city = :city_1), paginated_users AS (SELECT filtered_users.anon_1 AS anon_1, filtered_users.id AS id, filtered_users.name AS name FROM filtered_users ORDER BY lower(filtered_users.name) ASC LIMIT :param_1) SELECT paginated_users.anon_1 AS paginated_users_anon_1, paginated_users.id AS paginated_users_id, paginated_users.name AS paginated_users_name FROM paginated_users ``` The column_property is loaded in the very first CTE despite the `defer`. This is the same result as 1.3 if I omit the defer option. If I don't filter Address in CTE, the subquery is correlated correctly: ```python filtered_users = ( session.query(User) .options(defer(User.total_addresses)) .cte(""filtered_users"") ) filtered_users_alias: User = aliased(User, filtered_users) paginated_users = ( session.query(filtered_users_alias) .order_by(func.lower(filtered_users_alias.name).asc()) .limit(25) .options(defer(""total_addresses"")) .cte(""paginated_users"") ) paginated_users_alias: User = aliased(User, paginated_users) print(session.query(paginated_users_alias)) ``` gives ```sql WITH filtered_users AS (SELECT users.id AS id, users.name AS name FROM users), paginated_users AS (SELECT filtered_users.id AS id, filtered_users.name AS name FROM filtered_users ORDER BY lower(filtered_users.name) ASC LIMIT :param_1) SELECT (SELECT count(addresses.id) AS count_1 FROM addresses WHERE addresses.user_id = paginated_users.id) AS anon_1, paginated_users.id AS paginated_users_id, paginated_users.name AS paginated_users_name FROM paginated_users ``` The reason for which we need to defer the loading of column_property is due to performace purpose, if we defer loading the subquery after the LIMIT clause, Postgres query planner works differently and much much faster. **Error** ``` Traceback (most recent call last): File ""./src/controllers/site_controller.py"", line 180, in list File ""/tmp/pip-target-sb6aifnf/lib/python/sqlalchemy/orm/query.py"", line 3373, in all File ""/tmp/pip-target-sb6aifnf/lib/python/sqlalchemy/orm/query.py"", line 3535, in __iter__ File ""/tmp/pip-target-sb6aifnf/lib/python/sqlalchemy/orm/query.py"", line 3560, in _execute_and_instances File ""/tmp/pip-target-sb6aifnf/lib/python/sqlalchemy/engine/base.py"", line 1011, in execute File ""/tmp/pip-target-sb6aifnf/lib/python/sqlalchemy/sql/elements.py"", line 298, in _execute_on_connection File ""/tmp/pip-target-sb6aifnf/lib/python/sqlalchemy/engine/base.py"", line 1130, in _execute_clauseelement File ""/tmp/pip-target-sb6aifnf/lib/python/sqlalchemy/engine/base.py"", line 1317, in _execute_context File ""/tmp/pip-target-sb6aifnf/lib/python/sqlalchemy/engine/base.py"", line 1511, in _handle_dbapi_exception File ""/tmp/pip-target-sb6aifnf/lib/python/sqlalchemy/util/compat.py"", line 182, in raise_ File ""/tmp/pip-target-sb6aifnf/lib/python/sqlalchemy/engine/base.py"", line 1277, in _execute_context File ""/tmp/pip-target-sb6aifnf/lib/python/sqlalchemy/engine/default.py"", line 609, in do_execute sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedTable) missing FROM-clause entry for table ""addresses"" ... ``` **Versions.** * OS: Linux * Python: 3.6.10 * SQLAlchemy: 1.3.23 / 1.4.0 **Thank you very much!** "
622149,691394,https://api.github.com/repos/liquidz/vim-iced/issues/318,enhancement,2021-03-12T15:27:37Z,NONE,https://api.github.com/repos/liquidz/vim-iced,"Option to choose selector Hi, I have both FZF and Vim-clap installed and I'd prefer to use Clap for selector in Vim-iced. Looking at autoload/iced/component/selector.vim there doesn't seem to be option to choose the selector currently. "
532903,592292,https://api.github.com/repos/edkehayova18/sweet_spot_project/issues/7,enhancement,2021-02-10T20:10:56Z,OWNER,https://api.github.com/repos/edkehayova18/sweet_spot_project,Add txt files files that represent our data base
323273,359393,https://api.github.com/repos/hackbg/fadroma/issues/1,enhancement,2021-03-15T09:19:56Z,COLLABORATOR,https://api.github.com/repos/hackbg/fadroma,"imply `$tx_state` * `$tx_state` is local to generated handler functions. Moving [the `ok!` macro definition](https://github.com/hackbg/fadroma/blob/main/rs/lib.rs#L222) into [the handler function template](https://github.com/hackbg/fadroma/blob/main/rs/lib.rs#L248) allows `ok!(...)` to be used instead of `ok!(state,...)`. * Currently, the form `ok!(_,...)` means ""success, no state updates necessary"". This feature is not used by anyone yet, and if comparing 2 `$State` objects is cheaper than writing the same `$State` object, then this enhancement would benefit adding such a comparison [instead of this](https://github.com/hackbg/fadroma/blob/main/rs/lib.rs#L206) to avoid saving unchanged `$State` objects."
34389,38329,https://api.github.com/repos/gnosis/safe-ios/issues/896,bug,2021-01-27T16:17:49Z,COLLABORATOR,https://api.github.com/repos/gnosis/safe-ios,"[iOS] Banner is displayed after owner key importing **Bug description** Banner is displayed after owner key importing **Steps To Reproduce** 1. Install the app with the latest version 2. Add safe without owner key importing ( select skip import owner key ) 3. check balance page for the banner 4. go to the app settings and import owner key 5. Come back to the balance Current result: The owner key is imported but the banner is still displayed to the user on the balance page. The app restart required . Probably because there is no page update on page switching. It's really confusing for the user to see the banner when the owner was already added 6. Click Import owner key on the banner Current result: The import owner key flow is started ( note: remember that the owner key is already imported) 7. finish import owner key flow with new owner imported Current result: The owner key from step 4 is rewritten with new owner key **Expected Result** The banner should disappear if the owner key was imported without app restart or pull to refresh **Screenshots** **Device & App version** - Device/OS: iPhone 11/14.3 - App version: 2.9.0 (290) **Environment** staging, rinkeby **Additional info** (Optional) "
65612,72954,https://api.github.com/repos/juriburakov-gmail-com/cli/issues/7,bug,2021-01-27T21:58:08Z,NONE,https://api.github.com/repos/juriburakov-gmail-com/cli,"**Cards** Cards can be added to your board to track the progress of issues and pull requests. You can also add note cards, like this one!"
61965,68885,https://api.github.com/repos/skycoin/skywire/issues/707,bug,2021-03-02T02:28:02Z,MEMBER,https://api.github.com/repos/skycoin/skywire,Limit redialing attempts **Describe the bug** With the current implementation of the VPN client hello timeout in #704 we have a case where routes may be re-requested indefinitely. We should limit the number of retrials to 3 or implement exponential backoff for this scenario. 
533015,592421,https://api.github.com/repos/tokibito/django-ftpserver/issues/15,question,2018-02-24T05:10:14Z,NONE,https://api.github.com/repos/tokibito/django-ftpserver,Problem uploading files using Filezilla I managed to install ftp server and works great with windows and Mac folders but fails when connected to it using Filezilla. Any one has tried this before ? Appreciate help here. 
616330,684923,https://api.github.com/repos/phifogg/ioBroker.sainlogic/issues/64,enhancement,2021-03-16T12:04:36Z,NONE,https://api.github.com/repos/phifogg/ioBroker.sainlogic,Compatibility with Froggit DP1500? Any Info if it is compatible with [https://www.froggit.de/product_info.php?info=p410_dp1500-wi-fi-wetterserver-usb-dongle.html](url) As Froggit DP1500 supports soil moisture through WS View I'm curious if someone tried this yet.
532535,591876,https://api.github.com/repos/wojtekmaj/react-pdf/issues/399,question,2019-05-08T16:27:57Z,NONE,https://api.github.com/repos/wojtekmaj/react-pdf,"Unable to load file from aws s3 pre signed URL Hello Wojciech Maj, I have gone through existing issues related to CORS. The domain I am requesting to has enabled CORS and has GET as well as POST in allowed method. I am still getting following error. <img width=""1440"" alt=""Screenshot 2019-05-08 at 9 42 54 PM"" src=""https://user-images.githubusercontent.com/7983935/57390557-47a02e80-71da-11e9-832c-7f6bef1e752e.png""> Now, here is what I am doing. I am basically fetching pre signed URL from aws s3 and then using this url in file props of Document. In my network tab I see that in pre flight request allowed method is POST. However pdf.js uses GET to load PDF. <img width=""1440"" alt=""Screenshot 2019-05-08 at 9 50 05 PM"" src=""https://user-images.githubusercontent.com/7983935/57391614-846d2500-71dc-11e9-8cc3-369d94f04436.png""> As you can see **Access-Control-Request-Method: POST** . I tried sending httpHeader in file props as <Document file= {{ url: 'URL',httpHeaders: {'Access-Control-Request-Method': 'GET', ""Access- Control-Allow-Origin"": ""*""}, withCredentials: true }} onLoadSuccess={this.onDocumentLoadSuccess} renderMode=""canvas""> </Document> But if I send like this then I am not seeing any pre flight request in network tab and CORS issue persist. Thank you in advance! "
337036,374653,https://api.github.com/repos/mxew/firetable-user/issues/131,bug,2021-02-10T03:43:39Z,COLLABORATOR,https://api.github.com/repos/mxew/firetable-user,Login / Logout issues Login medium media query is jacked. Logout goes bonkers.
361489,401859,https://api.github.com/repos/michaeljones/breathe/issues/652,bug,2021-03-03T18:36:16Z,NONE,https://api.github.com/repos/michaeljones/breathe,"Spurious error with function pointer as template argument **Describe the bug** For this: /// @brief A template class template <void (*F)()> class C {}; Sphinx complains thusly: | [(DefinitionError('Invalid C++ declaration: Expected "","" or "">"". [error at 19]\n template<void(*)() F> C\n -------------------^'), 'If no parameter')] |/data/cwinter/breathe/source/index.rst:11: WARNING: Error in template parameter list. Invalid C++ declaration: Expected "","" or "">"". [error at 19] template<void(*)() F> C -------------------^ **To Reproduce** Copy source snippet above into .h file and run Sphinx with Breathe extension enabled (see project files) $ sphinx-autobuild source build **Expected behavior** Don't throw an error and produce the right type names. (When the error is thrown some types are assigned names with `PhonyNameDueToError`.) **Your project** [sphinx-templates.zip](https://github.com/michaeljones/breathe/files/6078319/sphinx-templates.zip) **Environment info** - OS: Ubuntu 18.04 - Python version: 3.8.0 - Sphinx version: 3.5.1 - Sphinx extensions: breathe - Extra tools: doxygen 1.9.2 (From https://github.com/sphinx-doc/sphinx/issues/8953)"
583809,648757,https://api.github.com/repos/redmod-team/profit/issues/85,enhancement,2021-03-09T08:44:41Z,CONTRIBUTOR,https://api.github.com/repos/redmod-team/profit,Add run tests to pytest Add automatic testing of functionality. E.g.: run the `mockup` example for each build.
347113,385887,https://api.github.com/repos/RSA-Bots/PandaProtector/issues/1,enhancement,2021-04-26T09:24:22Z,CONTRIBUTOR,https://api.github.com/repos/RSA-Bots/PandaProtector,Implement compile command TODO - [x] Update wandbox to include `fromStringv2` - [x] Create a type definition for it - [x] Decide on a list of languages to show in the compile command description 
462529,514037,https://api.github.com/repos/helium/hotspot-app/issues/180,bug,2021-02-09T20:50:20Z,MEMBER,https://api.github.com/repos/helium/hotspot-app,"Android: Settings > Require PIN clipped Its supposed to say ""immediately"" but looks like the string is clipped. android v24, pixel 3. ![IMG_1830](https://user-images.githubusercontent.com/19331274/107426594-4b5e9480-6ad5-11eb-8430-8ebeb21b94d4.jpg) "
214698,238743,https://api.github.com/repos/montessori-ressources/api/issues/23,enhancement,2020-10-05T16:20:57Z,MEMBER,https://api.github.com/repos/montessori-ressources/api,Study backend less solutions We can imagine to replace actual `api` project by a backend less solution like [firebase](https://firebase.google.com/). This particular solution allow to focus on front-end development by providing multiple tool that are replacing a backend: * manage authentification on multiple providers * manage cloud database with specific rights based on existing auth * manage file storage with specific rights based on existing auth [Here](https://medium.com/@brenda.clark/firebase-alternative-3-open-source-ways-to-follow-e45d9347bc8c) is an article about firebase alternatives.
118038,131163,https://api.github.com/repos/influxdata/telegraf/issues/7393,bug,2020-04-23T12:35:08Z,NONE,https://api.github.com/repos/influxdata/telegraf,"Telegraf log gets spammed/flooded if Elasticsearch receiver is in read-only state ### Relevant telegraf.conf: ```toml # Configuration for telegraf agent [agent] interval = ""10s"" round_interval = true metric_batch_size = 1000 metric_buffer_limit = 10000 collection_jitter = ""0s"" flush_interval = ""10s"" flush_jitter = ""0s"" precision = """" logtarget = ""file"" logfile = ""/dev/null"" # (Temporary fix for infinity loop of logs when Elasticsearch is in read only mode.) #logfile_rotation_interval = ""1d"" #logfile_rotation_max_archives = 7 hostname = """" omit_hostname = false [[outputs.elasticsearch]] urls = [ ""https://***:9200"" ] # required. timeout = ""5s"" enable_sniffer = false health_check_interval = ""10s"" username = ""***"" password = ""***"" index_name = ""***-%Y.%m.%d"" # required. tls_ca = ""/etc/telegraf/***-x509.pem"" tls_cert = ""/etc/telegraf/***-x509.pem"" tls_key = ""/etc/telegraf/***.key.pem"" manage_template = true template_name = ""edge"" overwrite_template = false # Telegraf logs [[inputs.tail]] files = [""/var/log/telegraf/telegraf.log""] from_beginning = false pipe = false data_format = ""value"" data_type = ""string"" name_override = ""log"" [inputs.tail.tags] metric_type = ""logs"" log_source = ""telegraf"" ``` ### System info: Telegraf version: 1.14.1 (installed via Apt/Deb package) OS version: Ubuntu 18.04 ### Docker No Docker instance is being used ### Steps to reproduce: <!-- Describe the steps to reproduce the bug. --> 1. Wait for Elasticsearch server to reach 95% used storage and automatically go into read-only mode. 2. Tail telegraf.log and see that every 10 second, the buffer (1000 lines) gets written with an error that Elasticsearch is in read-only mode. 3. I we also have the Tail input activated on Telegrafs log file, then this happens about 4 times every second, resulting in about 4000 lines get written every second. Please note that right now we have set the logging to /dev/null just to save us from getting our disks full each and every day. ;) ### Expected behavior: It seams reasonable that either these lines where deduplicated in the log or it did not try all writes at all if the first write against the server fails. We would like to see the same behaviour as if the Elasticsearch server did respond at all, like the read-only state would trigger the same kind of behaviour in Telegraf, as if it didn't respond at all. Because when the Elasticsearch server disk gets totally full, then it just stops responding overall, and then we only get 4 messages every ten seconds in the log saying that Elasticsearch cannot be reached (or something like that. Also wondering about best practise if we want to ship our telegraf logs from all servers to Elasticsearch for central logging, are we doing it wrong? ### Actual behavior: If Elasticsearch is up (accepting connections) but does not accept writes (in read-only mode), which happens when the servers hits 95% used storage (Elasticsearch disk watermark threshold). 1000 lines like the following are logged every 10 seconds. To be precise the number of metrics waiting to be written to Elasticsearch or 1000 lines wichever is smaller. If we also have turned on shipping of telegraf's own logs (via input.tail and send them to Elasticsearch for central storage of all logs), then it gets crazy and starts to loop over these 1000 lines and do it several times a second, instead of every 10 seconds, which results in several thousand lines of log getting written every second. ### Additional info: Output from telegraf.log ```toml 2020-04-17T21:02:59Z E! Elasticsearch indexing failure, id: 992, error: index [telegraf-2020.04.17] blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];, caused by: %!s(<nil>), %!s(<nil>) 2020-04-17T21:02:59Z E! Elasticsearch indexing failure, id: 993, error: index [telegraf-2020.04.17] blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];, caused by: %!s(<nil>), %!s(<nil>) 2020-04-17T21:02:59Z E! Elasticsearch indexing failure, id: 994, error: index [telegraf-2020.04.17] blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];, caused by: %!s(<nil>), %!s(<nil>) 2020-04-17T21:02:59Z E! Elasticsearch indexing failure, id: 995, error: index [telegraf-2020.04.17] blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];, caused by: %!s(<nil>), %!s(<nil>) 2020-04-17T21:02:59Z E! Elasticsearch indexing failure, id: 996, error: index [telegraf-2020.04.17] blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];, caused by: %!s(<nil>), %!s(<nil>) 2020-04-17T21:02:59Z E! Elasticsearch indexing failure, id: 997, error: index [telegraf-2020.04.17] blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];, caused by: %!s(<nil>), %!s(<nil>) 2020-04-17T21:02:59Z E! Elasticsearch indexing failure, id: 998, error: index [telegraf-2020.04.17] blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];, caused by: %!s(<nil>), %!s(<nil>) 2020-04-17T21:02:59Z E! Elasticsearch indexing failure, id: 999, error: index [telegraf-2020.04.17] blocked by: [FORBIDDEN/12/index read-only / allow delete (api)];, caused by: %!s(<nil>), %!s(<nil>) ``` "
263388,292934,https://api.github.com/repos/microsoft/CCF/issues/2151,enhancement,2021-02-02T13:30:44Z,MEMBER,https://api.github.com/repos/microsoft/CCF,Add view and seqno to /tx response To make the response more self-describing when it gets passed around.
368153,409255,https://api.github.com/repos/mossmann/hackrf/issues/785,question,2020-09-06T19:06:05Z,NONE,https://api.github.com/repos/mossmann/hackrf,"Python Library for Streaming HackRF I/Q Data Is anyone aware of a working Python library for streaming HackRF I/Q Data? I've been trying this one: https://github.com/dressel/pyhackrf and I'm able to run the read_samples() command to grab a single block of data, but I'm not able to get the callback example working to continuously stream I/Q data. Thx! Don"
690528,767447,https://api.github.com/repos/markkampe/Java_Terrain/issues/88,bug,2021-04-14T23:18:14Z,OWNER,https://api.github.com/repos/markkampe/Java_Terrain,"Arterial non-flow? Rivers work on old maps, but now seem broken: - [x] add arterial river to a gently sloping plane. - [x] add obstacles around which it must deflect - [x] add them all around the edges - [x] add them in middle points - [x] add support for multiple incoming rivers"
242100,269274,https://api.github.com/repos/MTrop/DoomTools/issues/9,enhancement,2021-02-11T00:05:43Z,OWNER,https://api.github.com/repos/MTrop/DoomTools,"[DECOHack] Expose Ability to set ""Unused"" Args Without Pointer Make a way to allow users to set the ""unused"" flags in states even without an action pointer, as they actually have some kind of purpose in Doom, after all! Proposed format: ``` SPRT A 2 (arg0, arg1) ``` This streamlines a bit of the parser, too. May need to rethink argument checking, though."
551665,613119,https://api.github.com/repos/communitybridge/easycla/issues/2583,bug,2021-02-05T13:10:56Z,COLLABORATOR,https://api.github.com/repos/communitybridge/easycla,"Getting error ""Unable to find project by repository, please contact to your administrator."" post email verification is done clicked on proceed to navigate to corporate console Getting error ""Unable to find project by repository, please contact to your administrator."" post email verification is done clicked on proceed to navigate to corporate console on staging Getting error Unable to find project by repository, please contact to your administrator. post email verification is done clicked on proceed to navigate to corporate console.mp4 https://images.zenhubusercontent.com/194341141/440850e2-eb2f-4be9-aaf4-938e4e49e018/getting_error_unable_to_find_project_by_repository__please_contact_to_your_administrator__post_email_verification_is_done_clicked_on_proceed_to_navigate_to_corporate_console.mp4"
181063,201297,https://api.github.com/repos/Regalis11/Barotrauma/issues/5525,bug,2021-04-15T18:50:33Z,COLLABORATOR,https://api.github.com/repos/Regalis11/Barotrauma,"Bots throw full oxygen tanks away when they are not in the main sub (e.g. in wrecks) Bots throw full oxygen tanks away when they are not in the main sub, resulting in suffocation and lost oxygen tanks while exploring e.g. wrecks. Happened because they tried to be smart and act early but then failed to swap the bottles because the current tank was not yet empty and the contain item objective failed. Steps to repro: 1. Take a full stack of oxygen bottles with you 2. Equip a diving suit 3. Teleport inside a wreck 4. Ensure that the hull floods, for example by spawning some explosions 5. Enter freecam mode and observe the bot's behavior: when the oxygen is at 10%, the bot throws all the oxygen tanks away unless the tank currently equipped in the suit is depleted. Does not happen when there's no oxygen tank inside the suit or if the tank is empty. To make it easier to test, you should make masks and suits deplete oxygen tanks faster. For that, do the following changes in divinggear.xml: ![image.png](https://images.zenhubusercontent.com/5c93b12055cf186934fc0a03/73454be6-d365-4337-bd70-3b5991b8f28f) Fixed in Regalis11/Barotrauma-development@40652d3."
241348,268440,https://api.github.com/repos/aaugustin/websockets/issues/683,bug,2019-10-30T11:54:07Z,NONE,https://api.github.com/repos/aaugustin/websockets,cibuildwheel is not running the test suite I noticed that the cibuildwheel run for Linux + Windows is not exercising the test suite: Linux: ``` + sh -c 'python3 -W default -m unittest' ~ /project ---------------------------------------------------------------------- Ran 0 tests in 0.000s ``` Windows: ``` + python -W default -m unittest Using default MSVC build environment for 64 bit architecture Executing: python -W default -m unittest ---------------------------------------------------------------------- Ran 0 tests in 0.000s OK ``` 
122833,136486,https://api.github.com/repos/GirkovArpa/temps-lite/issues/20,bug,2021-02-17T10:10:12Z,COLLABORATOR,https://api.github.com/repos/GirkovArpa/temps-lite,"12h time without trailing zero Yesterday I noticed that there is no trailing zero for minutes, when it is between hh:01 and hh:05 in 12h mode, but only there, and not in 24h mode."
335501,372967,https://api.github.com/repos/isontheline/pro.webssh.net/issues/259,enhancement,2021-04-14T05:54:18Z,OWNER,https://api.github.com/repos/isontheline/pro.webssh.net,"Snippets : Ability to manage them from settings section **Describe the feature** - [x] Ability to manage snippets from settings section - [x] Remove ""Only for this connection"" - [x] Ability to edit a snippet - [ ] ~~Add ability to launch a snippet at a connection startup~~ No instead use remote command - [ ] ~~Add documentation about Snippets~~ Later - [x] Update snippets icons on SSH shortcuts when dismissing the snippets menu"
663122,737091,https://api.github.com/repos/Jarrrk/HighLife/issues/2868,enhancement,2021-03-26T20:52:24Z,NONE,https://api.github.com/repos/Jarrrk/HighLife,Radio do you ever get bored of listening to the same old songs of los santos? not to worry! ive come up with an idea to bring new life and music to the city. create a new radio station made up of the highlife spotify soundtrack and bring everyone closer together as they explore the city of los santos delving into new soundtracks and genres of music all around them 
364699,405407,https://api.github.com/repos/r-lib/rlang/issues/1125,bug,2021-03-03T15:41:11Z,MEMBER,https://api.github.com/repos/r-lib/rlang,Wrong AST rotation Reported in tidyverse/dplyr#5786 ```r z <- 1 rlang::expr(x * y + !!z * x * z + 5) #> (x * y + 1 * x) * z + 5 ```
11958,13334,https://api.github.com/repos/jellyfin/jellyfin/issues/3741,bug,2020-07-29T11:36:16Z,NONE,https://api.github.com/repos/jellyfin/jellyfin,"Dangling file symlinks in library folders breaks polling for media files. **Describe the bug** I had some dangling file symlinks (not folder) in my TV and Movies folders - when scanning for media nothing would be found and while in the add folder menu for each library navigation of the file system would show no sub folders in these folders while dangling symlinks were present. **System (please complete the following information):** - OS: Unraid current - Virtualization: Docker - Clients: Browser - Browser: Firefox, Chrome - Jellyfin Version: Main: Jellyfin version: 10.6.1 - Playback: N/A - Installed Plugins: none - Reverse Proxy: none - Base URL: none - Networking: Bridge - Storage: local **To Reproduce** Add a dangling file symlink in a new library folder with media, hit scan, watch nothing get added / see the GUI unable to show you subfolders in the selected folder. **Expected behavior** Media to get added, gracious non-blocking failure on a dangled symlink. **Logs** Couldn't find anything in the logs which is why this was such an enormous pain in the ass to diagnose - errors are seen for dangling folder symlinks but I didn't see anything for file symlinks. Dangling folder output: ```System.IO.FileNotFoundException: Could not find file '/tv/bbc'. File name: '/tv/bbc' at Interop.ThrowExceptionForIoErrno(ErrorInfo errorInfo, String path, Boolean isDirectory, Func`2 errorRewriter) at Microsoft.Win32.SafeHandles.SafeFileHandle.Open(String path, OpenFlags flags, Int32 mode) at System.IO.FileStream..ctor(String path, FileMode mode, FileAccess access, FileShare share, Int32 bufferSize, FileOptions options) at Emby.Server.Implementations.IO.ManagedFileSystem.GetFileSystemMetadata(FileSystemInfo info) at System.Linq.Enumerable.SelectEnumerableIterator`2.MoveNext() at System.Collections.Generic.LargeArrayBuilder`1.AddRange(IEnumerable`1 items) at System.Collections.Generic.SparseArrayBuilder`1.AddRange(IEnumerable`1 items) at System.Collections.Generic.SparseArrayBuilder`1.ReserveOrAdd(IEnumerable`1 items) at System.Linq.Enumerable.Concat2Iterator`1.ToArray() at MediaBrowser.Controller.Providers.DirectoryService.GetFileSystemEntries(String path) at MediaBrowser.Controller.IO.FileData.GetFilteredFileSystemEntries(IDirectoryService directoryService, String path, IFileSystem fileSystem, IServerApplicationHost appHost, ILogger logger, ItemResolveArgs args, Int32 flattenFolderDepth, Boolean resolveShortcuts) at Emby.Server.Implementations.Library.LibraryManager.ResolvePath(FileSystemMetadata fileInfo, IDirectoryService directoryService, IItemResolver[] resolvers, Folder parent, String collectionType, LibraryOptions libraryOptions) [2020-07-29 01:25:06.092 +01:00] [ERR] [17] Emby.Server.Implementations.HttpServer.HttpListenerHost: Error processing request: ""The operation was canceled"". URL: ""http://x.x.x.x:8096/web/touchicon.png"" [2020-07-29 01:25:06.215 +01:00] [ERR] [19] Emby.Server.Implementations.Library.LibraryManager: Error in GetFilteredFileSystemEntries isPhysicalRoot: False IsVf: False``` **Screenshots** N/A "
332743,369921,https://api.github.com/repos/IQDM/IQDM-PDF/issues/20,bug,2021-03-11T18:54:00Z,CONTRIBUTOR,https://api.github.com/repos/IQDM/IQDM-PDF,"SNC Patient <=2020 reports may catch ""Set1"" If the Patient Name is too long, ""Set1"" gets picked up in `SNCPatientCustom.file_param_block`, throwing off all other file_param_block values. ![image](https://user-images.githubusercontent.com/4778878/110838868-956b9f00-8268-11eb-94f4-547d7b178ced.png) "
696697,774338,https://api.github.com/repos/anthonygoslar/LMS-Support/issues/142,enhancement,2021-05-08T05:53:43Z,OWNER,https://api.github.com/repos/anthonygoslar/LMS-Support,Admin dashboard Add the following rows to the visas tab: - course type - nationality 
595695,662012,https://api.github.com/repos/vaadin/flow/issues/9948,bug,2021-02-02T09:48:56Z,MEMBER,https://api.github.com/repos/vaadin/flow,"Server restart is required after removing a file from the theme 'components' folder ### Description of the bug / feature If you delete e.g. `frontend/themes/components/vaadin-button.css`, webpack compilation will then fail with ``` ERROR in ./themes/myproject/components/vaadin-button.css Module build failed (from ../node_modules/@vaadin/theme-loader/theme-loader.js): Error: ENOENT: no such file or directory, open '/.../frontend/themes/myproject/components/vaadin-button.css' ``` ### Minimal reproducible example 1. https://start.vaadin.com/?preset=prerelease&dl 2. Add vaadin-button.css to the folder 3. `mvn` 4. Remove vaadin-button.css from the folder ### Expected behavior The theme is recompiled without the button css ### Versions: - Vaadin / Flow version: 19 alpha 5"
476294,529331,https://api.github.com/repos/Kites-Foundation/hellomunnar-api/issues/26,enhancement,2021-02-20T08:38:25Z,NONE,https://api.github.com/repos/Kites-Foundation/hellomunnar-api,"create-review API create-review API requires a type field to sort reviews based on different categories such as Destinations, Activities, or Amenities. Schema `{ ""userId"": ""asdaly12hbldahbsdl21bekd"", ""type"": ""destinations"", ""Id"": ""D-047"", ""title"": ""Very GOod Experience"", ""rating"": 5, ""content"": ""Very good experience"", ""status"": ""pending"", ""profileImgUrl"": ""Image Urls as a json : https://cdn.hellomunnar.in/userContent/image.png"" }`"
480096,533587,https://api.github.com/repos/oci-labs/check-ins/issues/620,bug,2021-01-20T16:05:36Z,COLLABORATOR,https://api.github.com/repos/oci-labs/check-ins,BUG > File upload does not honor the configured directory (M) Current Behavior: Uploads do not land in the correct location Desired Behavior: Files are uploaded to the configured location
46188,51412,https://api.github.com/repos/traPtitech/traQ-Widget/issues/268,enhancement,2021-02-25T06:54:35Z,NONE,https://api.github.com/repos/traPtitech/traQ-Widget,要素間に空白が欲しい 以下のそれぞれの要素の間に適切な空白が欲しい - ユーザーアイコン&ユーザー名 - 本文 - 「traQで開く」
588839,654352,https://api.github.com/repos/UTFR/Lap-Simulation-App/issues/4,enhancement,2021-01-23T20:52:57Z,MEMBER,https://api.github.com/repos/UTFR/Lap-Simulation-App,Parameter Sweeps Add functionality for sweeping 1 parameter and saving as a sweep dataset. (different from rundata)
124789,138679,https://api.github.com/repos/microsoft/FluidFramework/issues/4832,bug,2021-01-16T03:07:13Z,MEMBER,https://api.github.com/repos/microsoft/FluidFramework,"SummaryAckWaitTimeout after Version Restore (Epoch change) Version restore for ODSP storage results in the data going back to a older time. Epoch number will change on the protocol to indicate that the version of the data and op stream has diverged from the version before, so that the client should reload. However, the data could be (always for ODSP?) restore to a time where a Summary is submitted, but the `SummaryAck` isn't in the op stream. That result in the client to wait for 2 mins (and issue the `SummaryAckWaitTimeout` error) before it would summarize. The client should be more resilient and summarize immediately if the the `SummaryOp` was from the previous Epoch from it's own `Join` message. "
381378,423958,https://api.github.com/repos/redaxo/redaxo/issues/4481,bug,2021-02-22T23:43:04Z,MEMBER,https://api.github.com/repos/redaxo/redaxo,"Exception: Error while executing statement ""SHOW FULL TABLES WHERE Table_type = ""BASE TABLE"" AND `Tables_in_redaxo` LIKE ""rex\_%"""": SQLSTATE[42S22]: Column not found: 1054 Unknown column 'Tables_in_redaxo' in 'where clause' Der Fehler tritt auf, wenn man eine gültige DB-Verbindung schon hinterlegt hat, das Setup erneut durchläuft, und dann dort eine andere DB auswählt. Ich denke, das liegt auch an der isInitialSetup-Methode. Vorher wurde nach der Eingabe der DB-Daten zum ersten Mal ein Verbindungsaufbau gemacht. Jetzt besteht dann schon eine Verbindung (wenn vorher schon gültige Daten), und es wird dann nicht korrekt die DB gewechselt, wenn man eine andere eingibt. Deswegen schlägt dann der untere Abruf fehl, da auf der alten DB nach den Tabellen der neuen DB gesucht wird. **Request-Uri:** /redaxo/index.php?page=setup&lang=de_de&step=5&setup_token=HFrS1Rloez44fV1aKjW0dpRkMGIeTLUaysAwVO7X2Ss **Request-Method:** POST **rex_sql_exception:** Error while executing statement ""SHOW FULL TABLES WHERE Table_type = ""BASE TABLE"" AND `Tables_in_redaxo` LIKE ""rex\_%"""": SQLSTATE[42S22]: Column not found: 1054 Unknown column 'Tables_in_redaxo' in 'where clause' **File:** redaxo/src/core/lib/sql/sql.php **Line:** 449 <details> <summary>Stacktrace</summary> | Function | File | Line | | ------------------------------------- | ------------------------------------- | -------- | | rex_sql->setQuery | redaxo/src/core/lib/sql/sql.php | 1200 | | rex_sql->getArray | redaxo/src/core/lib/sql/sql.php | 1720 | | rex_sql->fetchTablesAndViews | redaxo/src/core/lib/sql/sql.php | 1677 | | rex_sql->getTables | redaxo/src/core/lib/setup/import.php | 133 | | rex_setup_importer::verifyDbSchema | redaxo/src/core/pages/setup.step5.php | 7 | | require | redaxo/src/core/pages/setup.php | 263 | | include | redaxo/src/core/lib/be/controller.php | 475 | | rex_be_controller::{closure} | redaxo/src/core/lib/util/timer.php | 63 | | rex_timer::measure | redaxo/src/core/lib/be/controller.php | 483 | | rex_be_controller::includePath | redaxo/src/core/lib/be/controller.php | 415 | | rex_be_controller::includeCurrentPage | redaxo/src/core/backend.php | 233 | | require | redaxo/src/core/boot.php | 141 | | require | redaxo/index.php | 9 | </details> <details> <summary>System report (REDAXO 5.12.0-beta1#9899144da, PHP 7.4.14, MariaDB 10.5.8)</summary> | REDAXO | | | ------------: | :--------------------- | | Version | 5.12.0-beta1#9899144da | | PHP | | | ------------: | :--------- | | Version | 7.4.14 | | OPcache | yes | | Xdebug | no | | Database | | | ------------: | :------------- | | Version | MariaDB 10.5.8 | | Character set | utf8mb4 | | Server | | | ------------: | :------------- | | OS | Darwin | | SAPI | apache2handler | | Webserver | Apache/2.4.46 | | Request | | | ------------: | :------------ | | Browser | Safari/14.0.3 | | Protocol | HTTP/1.1 | | HTTPS | yes | | Packages | | | ------------: | :--------- | </details>"
550447,611780,https://api.github.com/repos/pycompression/python-isal/issues/11,enhancement,2020-09-26T06:49:00Z,COLLABORATOR,https://api.github.com/repos/pycompression/python-isal,Improve output method As of now it is distinct from zlibmodule.c. It is not a very efficient use of the buffer. zlibmodule.c's method however is slower. As implemented now on the buffer branch. Look for opprotunities to streamline this proces and make it more shared across the functions that need it.
97501,108338,https://api.github.com/repos/thorchain/asgardex-electron/issues/1300,bug,2021-04-09T20:40:12Z,NONE,https://api.github.com/repos/thorchain/asgardex-electron,"UI issues in swap view Noticed some issues in the swap view: - leading zero is not removed by backspace - after a certain number of zeros are appended, there's some sort of string parsing or conversion error, and the amount of btc decreases to zero instead of being converted properly - See video showing issues: https://user-images.githubusercontent.com/11140296/114238106-cac6e380-991f-11eb-9e2e-be9638285ba8.mov - [x] Using most recent release (0.1.0-alpha.2) - [ ] Using yarn - [ ] Using node 12.x - [ ] Using an up-to-date [master branch](https://github.com/thorchain/asgardex-electron/tree/master/) - [ ] Link to stacktrace in a Gist (for bugs) ## Expected Behavior - should be able to backspace until the field is empty - rune to btc value should be converted correctly ## Current Behavior - leading zero is not removed by backspace - after a certain number of zeros are appended, there's some sort of string parsing or conversion error, and the amount of btc decreases to zero instead of being converted properly ## Possible Solution - field/string manipulation errors ## Steps to Reproduce (for bugs) Open rune <-> btc swap view, and try entering a value with many zeros, or backspacing until the field is empty ## Context poor UX taints user trust, and the incorrect conversion is very concerning ## Your Environment Most recent alpha release https://user-images.githubusercontent.com/11140296/114238106-cac6e380-991f-11eb-9e2e-be9638285ba8.mov "
283141,314870,https://api.github.com/repos/chipsec/chipsec/issues/610,bug,2019-06-30T18:09:47Z,CONTRIBUTOR,https://api.github.com/repos/chipsec/chipsec,Decode issue with Dell UEFI firmware similar issue to https://github.com/chipsec/chipsec/issues/609 but with Dell UEFI firmware. [dell.spi.tar.gz](https://github.com/chipsec/chipsec/files/3343187/dell.spi.tar.gz) 
186979,207928,https://api.github.com/repos/tmtek/keycloak_devkit/issues/23,enhancement,2021-05-19T00:36:14Z,OWNER,https://api.github.com/repos/tmtek/keycloak_devkit,Add Support for CLI Scripts We should add a folder `./keycloak/scripts/` which can have .cli files placed in them. We should then add all files in it to `/opt/jboss/startup-scripts/`. This will be super useful for tweaking configuration.
358283,398313,https://api.github.com/repos/elkarte/Elkarte/issues/3039,bug,2017-10-29T21:58:11Z,CONTRIBUTOR,https://api.github.com/repos/elkarte/Elkarte,"Unwatched topics not marked as unread Reported here: https://www.elkarte.net/community/index.php?topic=4738.0 Seems that unwatched topics cannot be marked as read by visiting them, the only way is to use the button mark as read in MessageIndex. Found in 1.0.10, but likely present in 1.1."
575063,639053,https://api.github.com/repos/elizabethhillman/taskManager/issues/11,enhancement,2021-04-22T01:19:49Z,OWNER,https://api.github.com/repos/elizabethhillman/taskManager,Assign Task to User This feature will allow anyone who has access to a task board assign an existing task to be completed by someone who has access to the task board. The assignee should be visible on the task.
45695,50863,https://api.github.com/repos/PREreview/prereview/issues/334,bug,2021-04-25T21:50:26Z,MEMBER,https://api.github.com/repos/PREreview/prereview,"Preprint from preprint.org pdf not loading, name of preprint server not showing This preprint has recently received a request. It should say that it's from preprint.org server. Also why isn't the pdf loading? <img width=""1432"" alt=""Screen Shot 2021-04-25 at 2 49 14 PM"" src=""https://user-images.githubusercontent.com/13750121/116010704-856c0c80-a5d5-11eb-9592-c143a3109673.png""> "
284488,316399,https://api.github.com/repos/cosmos/cosmos-sdk/issues/8776,bug,2021-03-04T05:34:19Z,CONTRIBUTOR,https://api.github.com/repos/cosmos/cosmos-sdk,"migrate command failed with error `cannot unmarshal string into Go value of type uint32` <!-- < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < < ☺ v ✰ Thanks for opening an issue! ✰ v Before smashing the submit button please review the template. v Please also ensure that this is not a duplicate issue :) ☺ > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > > --> <!-- IMPORTANT: Prior to opening a bug report, check if it affects one of the core modules and if its elegible for a bug bounty on `SECURITY.md`. Bugs that are not submitted through the appropriate channels won't receive any bounty. --> ## Summary of Bug We took a state dump of akash mainnet at height 2155115. Migrate command for akash on v0.10.0 (with SDK version 0.41.3) failed with error `json: cannot unmarshal string into Go value of type uint32`. Later, we got to know issue is from multisig accounts in auth genesis state. Previously, `threshold` field in pubkey of multisig accounts was `string` and in v0.40, it is converted to `uint32`. ## Version v0.41.3 ## Steps to Reproduce This is the state dump file: https://github.com/akhilkumarpilli/akash-mainnet-export/blob/main/old_genesis_export.json ``` akash migrate v0.40 old_genesis_export.json --chain-id=akashnet-2 > 040_migrated_genesis.json panic: json: cannot unmarshal string into Go value of type uint32goroutine 1 [running]: github.com/cosmos/cosmos-sdk/codec.(*LegacyAmino).MustUnmarshalJSON(...) github.com/cosmos/cosmos-sdk@v0.41.3/codec/amino.go:171 github.com/cosmos/cosmos-sdk/x/genutil/legacy/v040.Migrate(0xc001051da0, 0x0, 0x0, 0x0, 0x0, 0x0, 0x7ffdbe85c1d8, 0xa, 0x2ed93a0, 0xc000f108d0, ...) github.com/cosmos/cosmos-sdk@v0.41.3/x/genutil/legacy/v040/migrate.go:56 +0x1e93 github.com/cosmos/cosmos-sdk/x/genutil/client/cli.MigrateGenesisCmd.func1(0xc001039600, 0xc001015ec0, 0x2, 0x3, 0x0, 0x0) github.com/cosmos/cosmos-sdk@v0.41.3/x/genutil/client/cli/migrate.go:100 +0x1f8 github.com/spf13/cobra.(*Command).execute(0xc001039600, 0xc001015e60, 0x3, 0x3, 0xc001039600, 0xc001015e60) github.com/spf13/cobra@v1.1.1/command.go:850 +0x47c github.com/spf13/cobra.(*Command).ExecuteC(0xc000ddbb80, 0x291570f, 0x5, 0xc000d52a50) github.com/spf13/cobra@v1.1.1/command.go:958 +0x375 github.com/spf13/cobra.(*Command).Execute(...) github.com/spf13/cobra@v1.1.1/command.go:895 github.com/spf13/cobra.(*Command).ExecuteContext(...) github.com/spf13/cobra@v1.1.1/command.go:888 github.com/ovrclk/akash/cmd/akash/cmd.Execute(0xc000ddbb80, 0x2edf3a0, 0xc000f0dc80) github.com/ovrclk/akash/cmd/akash/cmd/root.go:116 +0x26d main.main() github.com/ovrclk/akash/cmd/akash/main.go:14 +0x2a ``` ____ ## For Admin Use - [ ] Not duplicate issue - [ ] Appropriate labels applied - [ ] Appropriate contributors tagged - [ ] Contributor assigned/self-assigned "
655635,728773,https://api.github.com/repos/derailed/k9s/issues/1063,bug,2021-03-26T14:55:37Z,NONE,https://api.github.com/repos/derailed/k9s,"Weird colour scheme since 0.24.0 on Windows <img src=""https://raw.githubusercontent.com/derailed/k9s/master/assets/k9s_err.png"" align=""right"" width=""100"" height=""auto""/> <br/> <br/> <br/> **Describe the bug** The nice and readable default colours until 0.24.0 have been replaced with dark and dusty colours on dark gray background. Apart from looking ugly, it's also a lot less readable. I haven't customised colours, or applied skins. If I launch 0.23.10 and 0.24.4 side-by-side, one looks nice as it always did, and the other terrible. **To Reproduce** Steps to reproduce the behavior: 1. Start k9s 0.24.x on Windows 10 2. Recoil in horror 😉 **Expected behavior** Nice, readable default colours. **Screenshots** 0.24.x: ![image](https://user-images.githubusercontent.com/10578276/112649987-3f435200-8e4b-11eb-81a8-a3d33ca71f2a.png) ![image](https://user-images.githubusercontent.com/10578276/112650114-5b46f380-8e4b-11eb-90e9-930132a89e04.png) For comparison, 0.23.x: ![image](https://user-images.githubusercontent.com/10578276/112650216-7285e100-8e4b-11eb-9d66-628715c65059.png) ![image](https://user-images.githubusercontent.com/10578276/112650349-947f6380-8e4b-11eb-899b-7e6c8d98ef1f.png) **Versions (please complete the following information):** - OS: Windows 10 20H2 - K9s: 0.24.0, 0.24.4 - K8s: 1.18 **Additional context** I'm experiencing this both in Windows Terminal Preview and the traditional Command Prompt. "
325158,361467,https://api.github.com/repos/TablePlus/TablePlus-Windows/issues/106,enhancement,2019-10-01T21:11:10Z,NONE,https://api.github.com/repos/TablePlus/TablePlus-Windows,"Copy definition statement - outdated alert 1. Which driver are you using and version of it (Ex: PostgreSQL 10.0): PostgreSQL 9.6.14 2. Which TablePlus build number are you using (the number on the welcome screen, Ex: build 81): Version 2.9.3 (89) x64 3. The steps to reproduce this issue: Right click on materialized view and click on 'Copy definition statement' What appears is an alert stating: ``` Coming on Feb-2019 ``` "
194992,216822,https://api.github.com/repos/denniskraus14/PandemicGame/issues/16,question,2021-03-14T18:34:56Z,OWNER,https://api.github.com/repos/denniskraus14/PandemicGame,Test the which_cards() function This function is called when a player is trying to turn in a cured disease with more than the minimum amount of cards of that color needed. I.e a medic trying to cure red with 6 red cards.
74582,82928,https://api.github.com/repos/wsyxbcl/Reimu/issues/9,bug,2021-01-27T01:44:31Z,OWNER,https://api.github.com/repos/wsyxbcl/Reimu,"/define stock_mix with stocks in different market Known issue, timezone are considered to be consistent in get_profit_ratio as handling different timezones would be tricky. Possible fix in future: 1. a secondary mix or future trading model 2. (Why can't user just use different stock_mix instead)"
211569,235251,https://api.github.com/repos/thomasmichaelwallace/lockepick/issues/14,bug,2021-03-13T16:21:25Z,OWNER,https://api.github.com/repos/thomasmichaelwallace/lockepick,"Empty slots get double line of FF added Empty slots get a double line of FF added on load, which causes the file checksum to differ. It's not clear this actually causes any issues, but it confuses testing."
33858,37742,https://api.github.com/repos/TrainLCD/MobileApp/issues/580,bug,2021-03-12T08:22:28Z,MEMBER,https://api.github.com/repos/TrainLCD/MobileApp,英語環境以外はすべて日本語表示になってしまっている 仕様上は英語以外の言語設定で使われた場合すべて英語で表示されるべきだが、中国語設定のPixel 3では日本語で表示されている
355944,395716,https://api.github.com/repos/freqtrade/freqtrade/issues/4901,question,2021-05-09T11:12:16Z,NONE,https://api.github.com/repos/freqtrade/freqtrade,"Wrong duration of pairlocks with long timeframe ## Describe your environment * Operating system: ubuntu * Freqtrade Version: docker-4d9dc2a2 ## Describe the problem: I have a `12h` timeframe. Recently I have added some protections to stop bot from buying after several stops. Tonight some of them triggered. But after they must have gone bot didnt buy anything. I checked DB and seen that all of them was placed until the end of a candle instead of `now + stop_duration`. Here they are: `136|*|3 stoplosses in 15 min, locking for 30 min.|2021-05-09 03:58:02.107578|2021-05-09 12:00:00.000000|1` `137|VET/USDT|Auto lock|2021-05-09 03:58:02.592653|2021-05-09 12:00:00.000000|1` ### Steps to reproduce: 1. Timeframe with candle bigger than `stop_duration` 2. Triggered protection ### Observed Results: In pairstop 136 I exspected to have `until = '2021-05-09 04:28:02.107578'` I think the reason of this behaviour is in `exchange.timeframe_to_next_date` function that is used to calculate `until` "
699832,777805,https://api.github.com/repos/chicago-cdac/nm-exp-active-netrics/issues/4,enhancement,2021-03-02T00:57:03Z,MEMBER,https://api.github.com/repos/chicago-cdac/nm-exp-active-netrics,throughput tcp retransmissions ndt7-client retransmissions output was crucial to debugging the 5-port switch problem. I think we should definitely incorporate that into ours. 
99898,111011,https://api.github.com/repos/bexis/Module_ResourceManagement/issues/58,bug,2020-01-30T22:52:36Z,MEMBER,https://api.github.com/repos/bexis/Module_ResourceManagement,"It happens, that the variables in a Session are empty ![image](https://user-images.githubusercontent.com/15946467/72739852-d1dfc580-3ba4-11ea-9c5b-fc15a28d1a83.png) Can be related to my Computer or VS, but reason is unkown "
23611,26296,https://api.github.com/repos/jupyterhub/jupyterhub/issues/2213,question,2018-10-02T19:15:26Z,NONE,https://api.github.com/repos/jupyterhub/jupyterhub," traitlets.traitlets.TraitError: The 'ip' trait of a Server instance must be a unicode string, but a value of None <class 'NoneType'> was specified Just upgraded to latest version of JupyterHub and configurable-http-proxy and now get this error message: traitlets.traitlets.TraitError: The 'ip' trait of a Server instance must be a unicode string, but a value of None <class 'NoneType'> was specified Help!"
481412,535039,https://api.github.com/repos/microting/eform-angular-appointment-plugin/issues/138,enhancement,2021-05-31T18:17:41Z,MEMBER,https://api.github.com/repos/microting/eform-angular-appointment-plugin,Bump Microting.eForm from 5.2.4 to 5.2.5 TBD
607484,675102,https://api.github.com/repos/FAP-Cloud-Service/FAP-Backend/issues/36,enhancement,2021-04-30T11:54:58Z,CONTRIBUTOR,https://api.github.com/repos/FAP-Cloud-Service/FAP-Backend,CreateUser sollte 201 zurückgeben 201 statt 200
297473,330781,https://api.github.com/repos/tiangolo/fastapi/issues/3123,question,2021-04-23T15:26:54Z,NONE,https://api.github.com/repos/tiangolo/fastapi,"dependency override of dynamic dependencies Dependency overrides seem to have no effect when a dependency is used like this: ( notice this func returns a callable where it can access the args). ```python def authorize( resource: str, envelope: Optional[str] = None ) -> Callable: def inner() -> Tuple[str, Optional[str]]: print(resource, envelope) return resource, envelope return inner ``` Used like this: ```python @router.post(""/upload"") async def upload( fileobject: UploadFile = File(...), filename: str = Body(default=None), s3_client=Depends(get_s3_client), authnz=Depends(authorize(""s3_router@upload:member_get"")), ): ``` ```python # neither of these two work app.dependency_overrides[authorize(""s3_router@upload:member_get"")] = override_authorize app.dependency_overrides[authorize] = override_authorize ``` "
705953,784609,https://api.github.com/repos/openthread/openthread/issues/6574,bug,2021-05-06T04:51:39Z,MEMBER,https://api.github.com/repos/openthread/openthread,[github-actions] MATN_09_DefaultBRMulticastForwarding.py fails intermittently [logs_74026.zip](https://github.com/openthread/openthread/files/6431810/logs_74026.zip) [thread-border-router-results.zip](https://github.com/openthread/openthread/files/6431811/thread-border-router-results.zip) 
437533,486421,https://api.github.com/repos/gavinIRL/RHBot/issues/40,bug,2021-04-17T17:53:16Z,OWNER,https://api.github.com/repos/gavinIRL/RHBot,Fix bug causing enemies to always be detected Fix bug causing enemies to always be detected
667688,742119,https://api.github.com/repos/tooot-app/app/issues/1,enhancement,2020-10-28T22:44:51Z,COLLABORATOR,https://api.github.com/repos/tooot-app/app,Use fast-image https://github.com/DylanVann/react-native-fast-image
140192,155822,https://api.github.com/repos/Xcov19/covidX/issues/108,bug,2021-03-23T17:29:57Z,COLLABORATOR,https://api.github.com/repos/Xcov19/covidX,"Timeout when fetching @my_deps **Describe the bug** After running `docker-compose up --build`, a timeout occurs when fetching `@my_deps`. **To Reproduce** Steps to reproduce the behavior: 1. Clone the repository 2. Add a `.env` file in the cloned repository. 3. Run `docker-compose up --build` 4. Wait for building to reach stage of timing out while fetching `@my_deps` 5. See error **Expected behavior** `@my_deps` fetched successfully without timeout **Desktop:** - OS: Ubuntu 20.04.2.0 LTS"
123289,137001,https://api.github.com/repos/canonical/ubuntu-advantage-client/issues/1087,bug,2020-06-09T02:19:29Z,NONE,https://api.github.com/repos/canonical/ubuntu-advantage-client,"Can't enable FIPS on ubuntu pro machine When trying to enable FIPS on a AWS Ubuntu Pro instance by prompting ""ua enable fips"", it failed and returned ""GPG key '/usr/share/keyrings/ubuntu-fips-keyring.gpg' not found"" "
229581,255310,https://api.github.com/repos/pousse-cafe/pousse-cafe-eclipse-plugin/issues/14,enhancement,2021-02-08T12:20:53Z,MEMBER,https://api.github.com/repos/pousse-cafe/pousse-cafe-eclipse-plugin,Add hyperlinks to message classes Activating links on the message type name should expose the producers and consumers of the message.
664836,738978,https://api.github.com/repos/explosion/spaCy/issues/7065,bug,2021-02-14T18:39:09Z,NONE,https://api.github.com/repos/explosion/spaCy,"`entity_linker` pipeline is failing on ValueError ## How to reproduce the behaviour When I try to train my EL pipeline I get an error that sentence is not in the list: ```python Traceback (most recent call last): File ""/usr/lib/python3.8/runpy.py"", line 194, in _run_module_as_main return _run_code(code, main_globals, None, File ""/usr/lib/python3.8/runpy.py"", line 87, in _run_code exec(code, run_globals) File ""/path/venv/lib/python3.8/site-packages/spacy/__main__.py"", line 4, in <module> setup_cli() File ""/path/venv/lib/python3.8/site-packages/spacy/cli/_util.py"", line 68, in setup_cli command(prog_name=COMMAND) File ""/path/venv/lib/python3.8/site-packages/click/core.py"", line 829, in __call__ return self.main(*args, **kwargs) File ""/path/venv/lib/python3.8/site-packages/click/core.py"", line 782, in main rv = self.invoke(ctx) File ""/path/venv/lib/python3.8/site-packages/click/core.py"", line 1259, in invoke return _process_result(sub_ctx.command.invoke(sub_ctx)) File ""/path/venv/lib/python3.8/site-packages/click/core.py"", line 1066, in invoke return ctx.invoke(self.callback, **ctx.params) File ""/path/venv/lib/python3.8/site-packages/click/core.py"", line 610, in invoke return callback(*args, **kwargs) File ""/path/venv/lib/python3.8/site-packages/typer/main.py"", line 497, in wrapper return callback(**use_params) # type: ignore File ""/path/venv/lib/python3.8/site-packages/spacy/cli/train.py"", line 59, in train_cli train(nlp, output_path, use_gpu=use_gpu, stdout=sys.stdout, stderr=sys.stderr) File ""/path/venv/lib/python3.8/site-packages/spacy/training/loop.py"", line 114, in train raise e File ""/path/venv/lib/python3.8/site-packages/spacy/training/loop.py"", line 98, in train for batch, info, is_best_checkpoint in training_step_iterator: File ""/path/venv/lib/python3.8/site-packages/spacy/training/loop.py"", line 194, in train_while_improving nlp.update( File ""/path/venv/lib/python3.8/site-packages/spacy/language.py"", line 1106, in update proc.update(examples, sgd=None, losses=losses, **component_cfg[name]) File ""/path/venv/lib/python3.8/site-packages/spacy/pipeline/entity_linker.py"", line 229, in update sent_index = sentences.index(ent.sent) ValueError: Thomas Schippers introduced Kathleen Battle to his fellow conductor James Levine who selected Battle to sing in Mahler 's Symphony No. 8 at the Cincinnati Symphony Orchestra 's M ay Festival in 1974. is not in list ``` Based on the traceback I was able to find out [the code](https://github.com/explosion/spaCy/blob/master/spacy/pipeline/entity_linker.py#L221-L232) that causes it and here is a minimal working example: ```python text = """""" Thomas Schippers introduced Kathleen Battle to his fellow conductor James Levine who selected Battle to sing in Mahler 's Symphony No. 8 at the Cincinnati Symphony Orchestra 's M ay Festival in 1974. """""" nlp = spacy.load(""en_core_web_md"", exclude=[""tok2vec"", ""tagger"", ""parser"", ""tagger"", ""attribute_ruler"", ""lemmatizer"", ""ner""]) nlp.add_pipe(""sentencizer"") ruler = nlp.add_pipe(""entity_ruler"",) patterns = [{""label"": ""THING"", ""pattern"": [{""LOWER"": ""symphony""}, {""LOWER"": ""no""}, {""LOWER"": "".""}, {""LOWER"": ""8""}]}] ruler.add_patterns(patterns) doc = nlp(text) sentences = [s for s in doc.sents] for ent in doc.ents: sent_index = sentences.index(ent.sent) ``` The problem is that sentence contains `No.` abbreviation and `doc.sents` recognized the whole text as one sentence unlike `ent.sent` that thinks it's two sentences. ## Your Environment <!-- Include details of your environment. If you're using spaCy 1.7+, you can also type `python -m spacy info --markdown` and copy-paste the result here.--> spaCy version 3.0.3 Location /path/venv/lib/python3.8/site-packages/spacy Platform Linux-4.4.0-19041-Microsoft-x86_64-with-glibc2.29 Python version 3.8.5 Pipelines en_core_web_md (3.0.0), en_core_web_sm (3.0.0) "
269690,299925,https://api.github.com/repos/Akinori13/SimpleScheduler/issues/20,enhancement,2021-05-22T00:19:28Z,OWNER,https://api.github.com/repos/Akinori13/SimpleScheduler,Make Makefile ## Object To use Docker and Docker-compose more smoothly.
184220,204807,https://api.github.com/repos/numbersprotocol/capture-lite/issues/383,bug,2020-12-21T04:56:47Z,NONE,https://api.github.com/repos/numbersprotocol/capture-lite,"PostCapture 收到一半網路不預期掛掉，畫面全白 ## Description PostCapture 收到一半網路不預期掛掉，畫面全白 ## Steps to Reproduce 1. Send a PostCaptuee 2. On the receiver's phone, accept 3. It takes > 40s to procees, and the internet is suddenly broken 4. Reopen the App, see blank screen Note: it recovered automatically after keeping the screen on for 1min ## Environment - Version: 0.12.1 - OS: Android 10_ - Device: Samsung 5G"
440930,490190,https://api.github.com/repos/johannesjo/super-productivity/issues/427,enhancement,2020-07-01T14:11:32Z,NONE,https://api.github.com/repos/johannesjo/super-productivity,"Re-create sub tasks for repeating tasks <!--- Your issue may already be reported! Please search the issues before creating one. --> ### Your Environment <!--- Include as many relevant details about the environment you experienced the bug in --> * Version used: <!-- version number and package type (snap, deb, etc.) -->snap * Operating System and version: Ubuntu 18.04 * Desktop Environment: <!-- if on linux--> Elementary OS 5.1.4 * Browser Name and version: <!-- if using the web version--> ### Expected Behavior <!--- If you're describing a bug, tell us what should happen --> Create a main task for items that need to be carried out Make the main task repeatable so that it appears the next day Create subtasks under the main task Schedule the tasks for the next day <!--- If you're suggesting a change/improvement, tell us how it should work --> ### Current Behavior <!--- If describing a bug, tell us what happens instead of the expected behavior --> Open up the app the day after scheduling a sub-task from a repeatable main task Main task appears but there isn't a sub task anymore making the main task useless <!--- If suggesting a change/improvement, explain the difference from current behavior --> ### Steps to Reproduce (for bugs) <!--- Provide a link to a live example or an unambiguous set of steps to --> <!--- reproduce this bug. Include code to reproduce, if relevant --> 1. Create a main task 2. Add sub tasks 3. Make the main task repeatable and save 4. Wait the next day to find the sub tasks no longer appear under the main task ### Console Output <!--- Is there any output if you press Ctrl+Shift+i (Cmd+Alt+i for mac) in the console tab? If so please post it here. --> ### Error Log (Desktop only) <!--- For the desktop versions, there is also an error log file in case there is no console output. Usually, you can find it here: on Linux: ~/.config/superProductivity/log.log --or-- ~/snap/superproductivity/current/.config/superProductivity/log.log on macOS: ~/Library/Logs/superProductivity/log.log on Windows: %USERPROFILE%\AppData\Roaming\superProductivity\log.log . --> "
76148,84672,https://api.github.com/repos/nextcloud/bookmarks/issues/1542,bug,2021-05-14T18:30:05Z,NONE,https://api.github.com/repos/nextcloud/bookmarks,"Bookmarklet Not Working in Firefox, Chrome, or Edge **Describe the bug** Hi All, when I use the ""Add to NextCloud"" bookmarklet, the bookmarks are not added to my Nextcloud Bookmarks instance. The browser developer tools show this: What can I do to help fix this? This NC Instance has been upgraded from 19 to 21 Recently. **To Reproduce** Steps to reproduce the behavior: 1. In a browser with the Add to NextCloud bookmarklet available, click on Add Bookmarklet 2. Add Tag(s) to site 3. Click save. **Expected behavior** Bookmark is added to Nextcloud Bookmarks. **Screenshots** ![image](https://user-images.githubusercontent.com/13368910/118312808-ee052580-b4bf-11eb-90c2-e35eca183bf8.png) **Desktop (please complete the following information):** - OS: Windows 10 (1909 build 18363) - Browser: MS Edge (Chrome based), and Firefox - Version: Edge 90.0.818, Firefox 87.0 **Server (please complete the following information):** - OS: Ubuntu 20.04.02 - HTTP server: Apache 2.4.41 - Database: Mysql 8.0.25 - PHP version: PHP 7.4.3 - Nextcloud version: 21.0.1 - Bookmarks app version: 4.2.0 ~~~ - Activated Nextcloud Apps: - accessibility: 1.7.0 - activity: 2.14.3 - admin_audit: 1.11.0 - apporder: 0.12.0 - bookmarks: 4.2.0 - calendar: 2.2.1 - cloud_federation_api: 1.4.0 - comments: 1.11.0 - contacts: 3.5.1 - contactsinteraction: 1.2.0 - dav: 1.17.1 - deck: 1.4.2 - duplicatefinder: 0.0.8 - epubreader: 1.4.6 - federatedfilesharing: 1.11.0 - federation: 1.11.0 - files: 1.16.0 - files_external: 1.12.0 - files_markdown: 2.3.3 - files_pdfviewer: 2.1.0 - files_rightclick: 1.0.0 - files_sharing: 1.13.1 - files_trashbin: 1.11.0 - files_versions: 1.14.0 - files_videoplayer: 1.10.0 - firstrunwizard: 2.10.0 - logreader: 2.6.0 - lookup_server_connector: 1.9.0 - news: 15.4.3 - nextcloud_announcements: 1.10.0 - notifications: 2.9.0 - oauth2: 1.9.0 - onlyoffice: 7.0.2 - password_policy: 1.11.0 - photos: 1.3.0 - previewgenerator: 3.1.1 - privacy: 1.5.0 - provisioning_api: 1.11.0 - serverinfo: 1.11.0 - settings: 1.3.0 - sharebymail: 1.11.0 - sharerenamer: 2.7.3 - spreed: 11.2.1 - support: 1.4.0 - survey_client: 1.9.0 - systemtags: 1.11.0 - tasks: 0.13.6 - text: 3.2.0 - theming: 1.12.0 - twofactor_backupcodes: 1.10.0 - updatenotification: 1.11.0 - user_status: 1.1.1 - viewer: 1.5.0 - weather_status: 1.1.0 - workflowengine: 2.3.0 ~~~ - Nextcloud configuration: ~~~ { ""system"": { ""instanceid"": ""***REMOVED SENSITIVE VALUE***"", ""passwordsalt"": ""***REMOVED SENSITIVE VALUE***"", ""secret"": ""***REMOVED SENSITIVE VALUE***"", ""trusted_domains"": [ ""cloud.wellston.biz"", ""office.wellston.biz"" ], ""trusted_proxies"": ""***REMOVED SENSITIVE VALUE***"", ""datadirectory"": ""***REMOVED SENSITIVE VALUE***"", ""default_phone_region"": ""US"", ""overwrite.cli.url"": ""http:\/\/192.168.30.2"", ""dbtype"": ""mysql"", ""version"": ""21.0.1.1"", ""dbname"": ""***REMOVED SENSITIVE VALUE***"", ""dbhost"": ""***REMOVED SENSITIVE VALUE***"", ""dbtableprefix"": ""oc_"", ""dbuser"": ""***REMOVED SENSITIVE VALUE***"", ""dbpassword"": ""***REMOVED SENSITIVE VALUE***"", ""logtimezone"": ""UTC"", ""installed"": true, ""loglevel"": 0, ""updater.release.channel"": ""stable"", ""theme"": """", ""maintenance"": false, ""mail_smtpmode"": ""smtp"", ""mail_smtpauthtype"": ""LOGIN"", ""mail_from_address"": ""***REMOVED SENSITIVE VALUE***"", ""mail_domain"": ""***REMOVED SENSITIVE VALUE***"", ""mail_smtphost"": ""***REMOVED SENSITIVE VALUE***"", ""mail_smtpport"": ""587"", ""mail_smtpauth"": 1, ""mail_smtpsecure"": ""tls"", ""mail_smtpname"": ""***REMOVED SENSITIVE VALUE***"", ""mail_smtppassword"": ""***REMOVED SENSITIVE VALUE***"", ""memcache.locking"": ""\\OC\\Memcache\\Redis"", ""memcache.local"": ""\\OC\\Memcache\\Redis"", ""redis"": { ""host"": ""***REMOVED SENSITIVE VALUE***"", ""port"": 6379 }, ""mysql.utf8mb4"": true, ""has_rebuilt_cache"": true, ""app_install_overwrite"": [ ""apporder"", ""contacts"", ""bookmarks_fulltextsearch"", ""sharerenamer"", ""files_reader"", ""files_ebookreader"" ], ""overwriteprotocol"": ""https"", ""migrate_guest_user_data"": true, ""twofactor_enforced"": ""false"", ""twofactor_enforced_groups"": [], ""twofactor_enforced_excluded_groups"": [], ""encryption.legacy_format_support"": false, ""encryption.key_storage_migrated"": false }, ""apps"": { ""accessibility"": { ""enabled"": ""yes"", ""installed_version"": ""1.7.0"", ""types"": """" }, ""activity"": { ""enabled"": ""yes"", ""installed_version"": ""2.14.3"", ""types"": ""filesystem"" }, ""admin_audit"": { ""enabled"": ""yes"", ""installed_version"": ""1.11.0"", ""types"": ""logging"" }, ""apporder"": { ""enabled"": ""yes"", ""installed_version"": ""0.12.0"", ""order"": ""[\""\/index.php\/apps\/files\/\"",\""\/index.php\/apps\/rainloop\/\"",\""\/index.php\/apps\/deck\/\"",\""\/index.php\/apps\/calendar\/\"",\""\/index.php\/apps\/contacts\/\"",\""\/index.php\/apps\/tasks\/\"",\""\/index.php\/apps\/keeweb\/\"",\""\/index.php\/apps\/gallery\/\"",\""\/index.php\/apps\/spreed\/\""]"", ""types"": """" }, ""backgroundjob"": { ""lastjob"": ""4242"" }, ""bookmarks"": { ""enabled"": ""yes"", ""installed_version"": ""4.2.0"", ""performance.maxBookmarksperAccount"": """", ""previews.screenly.token"": """", ""previews.screenly.url"": """", ""previews.screenshotmachine.key"": """", ""previews.webshot.url"": """", ""privacy.enableScraping"": ""true"", ""types"": """" }, ""bookmarks_fulltextsearch"": { ""bookmarks_ttl"": ""1"", ""enabled"": ""no"", ""installed_version"": ""1.2.0"", ""types"": """" }, ""calendar"": { ""enabled"": ""yes"", ""installed_version"": ""2.2.1"", ""types"": """" }, ""carnet"": { ""enabled"": ""no"", ""installed_version"": ""0.23.8"", ""types"": ""filesystem"" }, ""cloud_federation_api"": { ""enabled"": ""yes"", ""installed_version"": ""1.4.0"", ""types"": ""filesystem"" }, ""cms_pico"": { ""enabled"": ""no"", ""installed_version"": ""1.0.4"", ""plugins_etag"": ""Wh96WqRlsW"", ""system_plugins"": ""{\""PicoDeprecated\"":{\""name\"":\""PicoDeprecated\"",\""type\"":1,\""compat\"":true}}"", ""system_templates"": ""{\""empty\"":{\""name\"":\""empty\"",\""type\"":1,\""compat\"":true},\""sample_pico\"":{\""name\"":\""sample_pico\"",\""type\"":1,\""compat\"":true}}"", ""system_themes"": ""{\""default\"":{\""name\"":\""default\"",\""type\"":1,\""compat\"":true}}"", ""themes_etag"": ""dTijS87Zpz"", ""types"": ""filesystem"" }, ""comments"": { ""enabled"": ""yes"", ""installed_version"": ""1.11.0"", ""types"": ""logging"" }, ""contacts"": { ""enabled"": ""yes"", ""installed_version"": ""3.5.1"", ""types"": ""dav"" }, ""contactsinteraction"": { ""enabled"": ""yes"", ""installed_version"": ""1.2.0"", ""types"": ""dav"" }, ""core"": { ""backgroundjobs_mode"": ""cron"", ""default_encryption_module"": ""OC_DEFAULT_MODULE"", ""enterpriseLogoChecked"": ""yes"", ""incoming_server2server_share_enabled"": ""no"", ""installedat"": ""1469039844.3352"", ""lastcron"": ""1621015208"", ""lastupdateResult"": ""[]"", ""lastupdatedat"": ""1621015013"", ""moveavatarsdone"": ""yes"", ""oc.integritycheck.checker"": <snip>, ""outgoing_server2server_share_enabled"": ""no"", ""previewsCleanedUp"": ""1"", ""public_documents"": ""documents\/public.php"", ""public_files"": ""files_sharing\/public.php"", ""public_webdav"": ""dav\/appinfo\/v1\/publicwebdav.php"", ""remote_caldav"": ""dav\/appinfo\/v1\/caldav.php"", ""remote_calendar"": ""dav\/appinfo\/v1\/caldav.php"", ""remote_carddav"": ""dav\/appinfo\/v1\/carddav.php"", ""remote_contacts"": ""dav\/appinfo\/v1\/carddav.php"", ""remote_dav"": ""dav\/appinfo\/v2\/remote.php"", ""remote_files"": ""dav\/appinfo\/v1\/webdav.php"", ""remote_webdav"": ""dav\/appinfo\/v1\/webdav.php"", ""repairlegacystoragesdone"": ""yes"", ""scss.variables"": ""9b0e5104e6a3c6a1b450df21a62de115"", ""shareapi_default_expire_date"": ""yes"", ""shareapi_default_permission_candelete"": ""no"", ""shareapi_default_permission_canshare"": ""no"", ""shareapi_default_permissions"": ""7"", ""shareapi_enforce_expire_date"": ""no"", ""shareapi_enforce_links_password"": ""no"", ""shareapi_public_link_disclaimertext"": ""Please upload your files here.\n"", ""theming.variables"": ""3380c74585402bc749599a676554ab7b"", ""updater.secret.created"": ""1620309722"", ""vendor"": ""nextcloud"" }, ""cospend"": { ""enabled"": ""no"", ""installed_version"": ""0.0.10"", ""types"": """" }, ""dashboard"": { ""enabled"": ""no"" }, ""dav"": { ""OCA\\DAV\\Migration\\ValueFixInsert_ran"": ""true"", ""buildCalendarReminderIndex"": ""yes"", ""buildCalendarSearchIndex"": ""yes"", ""chunks_migrated"": ""1"", ""enabled"": ""yes"", ""installed_version"": ""1.17.1"", ""regeneratedBirthdayCalendarsForYearFix"": ""yes"", ""sendEventRemindersPush"": ""yes"", ""types"": ""filesystem"" }, ""deck"": { ""enabled"": ""yes"", ""installed_version"": ""1.4.2"", ""types"": ""dav"" }, ""documents"": { ""enabled"": ""no"", ""installed_version"": ""0.13.1"", ""ocsid"": ""168711"", ""types"": """" }, ""drawio"": { ""DrawioLang"": ""auto"", ""DrawioTheme"": ""kennedy"", ""DrawioUrl"": ""https:\/\/www.draw.io"", ""DrawioXml"": ""yes"", ""enabled"": ""no"", ""installed_version"": ""1.0.0"", ""types"": ""filesystem"" }, ""duplicatefinder"": { ""enabled"": ""yes"", ""installed_version"": ""0.0.8"", ""types"": """" }, ""encryption"": { ""enabled"": ""no"", ""encryptHomeStorage"": ""0"", ""installed_version"": ""2.7.0"", ""masterKeyId"": ""master_7e4932cf"", ""publicShareKeyId"": ""pubShare_7e4932cf"", ""recoveryKeyId"": ""recoveryKey_7e4932cf"", ""types"": ""filesystem"" }, ""end_to_end_encryption"": { ""enabled"": ""no"", ""installed_version"": ""1.7.1"", ""types"": ""dav,filesystem"" }, ""epubreader"": { ""enabled"": ""yes"", ""installed_version"": ""1.4.6"", ""types"": """" }, ""external"": { ""enabled"": ""no"", ""installed_version"": ""3.8.1"", ""max_site"": ""3"", ""sites"": ""***REMOVED SENSITIVE VALUE***"", ""types"": """" }, ""federatedfilesharing"": { ""enabled"": ""yes"", ""installed_version"": ""1.11.0"", ""types"": """" }, ""federation"": { ""autoAddServers"": ""0"", ""enabled"": ""yes"", ""installed_version"": ""1.11.0"", ""types"": ""authentication"" }, ""files"": { ""cronjob_scan_files"": ""500"", ""enabled"": ""yes"", ""installed_version"": ""1.16.0"", ""types"": ""filesystem"" }, ""files_ebookreader"": { ""enabled"": ""no"", ""installed_version"": ""0.0.1"", ""types"": """" }, ""files_external"": { ""allow_user_mounting"": ""yes"", ""enabled"": ""yes"", ""installed_version"": ""1.12.0"", ""types"": ""filesystem"", ""user_mounting_backends"": ""dav,owncloud,sftp,amazons3,\\OC\\Files\\Storage\\SFTP_Key"" }, ""files_markdown"": { ""enabled"": ""yes"", ""installed_version"": ""2.3.3"", ""types"": """" }, ""files_pdfviewer"": { ""enabled"": ""yes"", ""installed_version"": ""2.1.0"", ""types"": """" }, ""files_reader"": { ""enabled"": ""no"", ""installed_version"": ""1.2.3"", ""ocsid"": ""167127"", ""types"": ""filesystem"" }, ""files_retention"": { ""enabled"": ""no"", ""installed_version"": ""1.0.1"", ""types"": ""filesystem"" }, ""files_rightclick"": { ""enabled"": ""yes"", ""installed_version"": ""1.0.0"", ""types"": """" }, ""files_sharing"": { ""enabled"": ""yes"", ""incoming_server2server_share_enabled"": ""no"", ""installed_version"": ""1.13.1"", ""outgoing_server2server_share_enabled"": ""no"", ""types"": ""filesystem"" }, ""files_texteditor"": { ""enabled"": ""no"", ""installed_version"": ""2.14.0"", ""types"": """" }, ""files_trashbin"": { ""enabled"": ""yes"", ""installed_version"": ""1.11.0"", ""types"": ""filesystem,dav"" }, ""files_versions"": { ""enabled"": ""yes"", ""installed_version"": ""1.14.0"", ""types"": ""filesystem,dav"" }, ""files_videoplayer"": { ""enabled"": ""yes"", ""installed_version"": ""1.10.0"", ""types"": """" }, ""firstrunwizard"": { ""enabled"": ""yes"", ""installed_version"": ""2.10.0"", ""types"": ""logging"" }, ""flowupload"": { ""enabled"": ""no"", ""installed_version"": ""1.0.0"", ""types"": """" }, ""fulltextsearch"": { ""app_navigation"": ""1"", ""cron_err_reset"": ""1561097455"", ""enabled"": ""no"", ""index_chunk"": ""20"", ""installed_version"": ""21.0.1"", ""provider_indexed"": ""{\""bookmarks\"":\""1\""}"", ""search_platform"": ""OCA\\FullTextSearch_ElasticSearch\\Platform\\ElasticSearchPlatform"", ""types"": """" }, ""fulltextsearch_elasticsearch"": { ""analyzer_tokenizer"": ""standard"", ""elastic_host"": ""http:\/\/localhost:9200"", ""elastic_index"": ""ncindex"", ""enabled"": ""no"", ""installed_version"": ""21.0.0"", ""types"": """" }, ""gallery"": { ""enabled"": ""no"", ""installed_version"": ""18.4.0"", ""types"": """" }, ""keeweb"": { ""enabled"": ""no"", ""installed_version"": ""0.4.0"", ""types"": """" }, ""logreader"": { ""enabled"": ""yes"", ""installed_version"": ""2.6.0"", ""levels"": ""11011"", ""live"": ""1"", ""types"": """" }, ""lookup_server_connector"": { ""enabled"": ""yes"", ""installed_version"": ""1.9.0"", ""types"": ""authentication"" }, ""mail"": { ""enabled"": ""no"", ""installed_version"": ""1.1.3"", ""types"": """" }, ""mindmaps"": { ""enabled"": ""no"", ""installed_version"": ""0.1.0"", ""types"": """" }, ""news"": { ""autoPurgeCount"": ""200"", ""autoPurgeMinimumInterval"": ""60"", ""enabled"": ""yes"", ""exploreUrl"": """", ""feedFetcherTimeout"": ""60"", ""installed_version"": ""15.4.3"", ""maxRedirects"": ""10"", ""types"": """", ""updateInterval"": ""3600"", ""useCronUpdates"": ""1"" }, ""nextcloud_announcements"": { ""enabled"": ""yes"", ""installed_version"": ""1.10.0"", ""pub_date"": ""Thu, 24 Oct 2019 00:00:00 +0200"", ""types"": ""logging"" }, ""notifications"": { ""enabled"": ""yes"", ""installed_version"": ""2.9.0"", ""types"": ""logging"" }, ""oauth2"": { ""enabled"": ""yes"", ""installed_version"": ""1.9.0"", ""types"": ""authentication"" }, ""onlyoffice"": { ""DocumentServerInternalUrl"": """", ""DocumentServerUrl"": ""https:\/\/office.wellston.biz\/"", ""StorageUrl"": """", ""customizationChat"": ""true"", ""customizationCompactHeader"": ""true"", ""customizationFeedback"": ""true"", ""customizationHelp"": ""true"", ""customizationToolbarNoTabs"": ""true"", ""defFormats"": ""{\""csv\"":\""false\"",\""doc\"":\""true\"",\""docm\"":\""false\"",\""docx\"":\""true\"",\""dotx\"":\""false\"",\""epub\"":\""false\"",\""html\"":\""false\"",\""odp\"":\""true\"",\""ods\"":\""true\"",\""odt\"":\""true\"",\""pdf\"":\""false\"",\""potm\"":\""false\"",\""potx\"":\""false\"",\""ppsm\"":\""false\"",\""ppsx\"":\""false\"",\""ppt\"":\""false\"",\""pptm\"":\""false\"",\""pptx\"":\""true\"",\""rtf\"":\""true\"",\""txt\"":\""false\"",\""xls\"":\""true\"",\""xlsm\"":\""false\"",\""xlsx\"":\""true\"",\""xltm\"":\""false\"",\""xltx\"":\""false\""}"", ""demo"": ""{\""available\"":true,\""enabled\"":false,\""start\"":{\""date\"":\""2020-01-25 16:52:50.711534\"",\""timezone_type\"":3,\""timezone\"":\""UTC\""}}"", ""editFormats"": ""{\""csv\"":\""true\"",\""odp\"":\""false\"",\""ods\"":\""false\"",\""odt\"":\""false\"",\""rtf\"":\""false\"",\""txt\"":\""true\""}"", ""enabled"": ""yes"", ""groups"": ""[]"", ""installed_version"": ""7.0.2"", ""jwt_secret"": """", ""sameTab"": ""false"", ""settings_error"": """", ""types"": ""filesystem"" }, ""ownnote"": { ""enabled"": ""no"", ""installed_version"": ""1.08"", ""ocsid"": ""168512"", ""types"": """" }, ""password_policy"": { ""enabled"": ""yes"", ""enforceNumericCharacters"": ""1"", ""enforceUpperLowerCase"": ""0"", ""installed_version"": ""1.11.0"", ""types"": ""authentication"" }, ""photos"": { ""enabled"": ""yes"", ""installed_version"": ""1.3.0"", ""types"": """" }, ""previewgenerator"": { ""enabled"": ""yes"", ""installed_version"": ""3.1.1"", ""types"": ""filesystem"" }, ""privacy"": { ""enabled"": ""yes"", ""installed_version"": ""1.5.0"", ""readableLocation"": ""fi"", ""types"": """" }, ""provisioning_api"": { ""enabled"": ""yes"", ""installed_version"": ""1.11.0"", ""types"": ""prevent_group_restriction"" }, ""rainloop"": { ""enabled"": ""no"", ""installed_version"": ""7.1.2"", ""rainloop-autologin"": ""1"", ""types"": """" }, ""recommendations"": { ""enabled"": ""no"", ""installed_version"": ""0.6.0"", ""types"": """" }, ""richdocuments"": { ""disable_certificate_verification"": ""yes"", ""doc_format"": ""odf"", ""enabled"": ""no"", ""installed_version"": ""3.7.3"", ""types"": ""filesystem,dav,prevent_group_restriction"", ""wopi_url"": ""https:\/\/cloud.wellston.biz"" }, ""richdocumentscode"": { ""enabled"": ""no"", ""installed_version"": ""4.2.602"", ""types"": """" }, ""serverinfo"": { ""enabled"": ""yes"", ""installed_version"": ""1.11.0"", ""types"": """" }, ""settings"": { ""enabled"": ""yes"", ""installed_version"": ""1.3.0"", ""types"": """" }, ""sharebymail"": { ""enabled"": ""yes"", ""installed_version"": ""1.11.0"", ""types"": ""filesystem"" }, ""sharerenamer"": { ""enabled"": ""yes"", ""installed_version"": ""2.7.3"", ""types"": """" }, ""socialsharing_email"": { ""enabled"": ""no"", ""installed_version"": ""2.2.0"", ""types"": """" }, ""spreed"": { ""enabled"": ""yes"", ""has_reference_id"": ""yes"", ""installed_version"": ""11.2.1"", ""project_access_invalidated"": ""1"", ""signaling_ticket_secret"": ""***REMOVED SENSITIVE VALUE***"", ""stun_servers"": ""***REMOVED SENSITIVE VALUE***"", ""types"": ""dav,prevent_group_restriction"" }, ""spreedme"": { ""OWNCLOUD_TEMPORARY_PASSWORD_LOGIN_ENABLED"": ""false"", ""SPREED_WEBRTC_BASEPATH"": ""\/webrtc\/"", ""SPREED_WEBRTC_IS_SHARED_INSTANCE"": ""false"", ""SPREED_WEBRTC_ORIGIN"": """", ""SPREED_WEBRTC_SHAREDSECRET"": ""69c75c13b227729203d071908166b16e1d69981c798d95a05ca191e1c9b8544d"", ""enabled"": ""no"", ""installed_version"": ""0.3.7"", ""is_set_up"": ""true"", ""ocsid"": ""174436"", ""types"": """" }, ""support"": { ""SwitchUpdaterServerHasRun"": ""yes"", ""enabled"": ""yes"", ""installed_version"": ""1.4.0"", ""types"": ""session"" }, ""survey_client"": { ""enabled"": ""yes"", ""installed_version"": ""1.9.0"", ""last_report"": ""{\""id\"":\""ocv9dnqcfoip\"",\""items\"":[[\""server\"",\""version\"",\""21.0.1.1\""],[\""server\"",\""code\"",\""other\""],[\""server\"",\""enable_avatars\"",\""yes\""],[\""server\"",\""enable_previews\"",\""yes\""],[\""server\"",\""memcache.local\"",\""\\\\OC\\\\Memcache\\\\Redis\""],[\""server\"",\""memcache.distributed\"",\""none\""],[\""server\"",\""asset-pipeline.enabled\"",\""no\""],[\""server\"",\""filelocking.enabled\"",\""yes\""],[\""server\"",\""memcache.locking\"",\""\\\\OC\\\\Memcache\\\\Redis\""],[\""server\"",\""debug\"",\""no\""],[\""server\"",\""cron\"",\""cron\""],[\""php\"",\""version\"",\""7.4.3\""],[\""php\"",\""memory_limit\"",-1],[\""php\"",\""max_execution_time\"",0],[\""php\"",\""upload_max_filesize\"",2097152],[\""database\"",\""type\"",\""mysql\""],[\""database\"",\""version\"",\""8.0.23\""],[\""database\"",\""size\"",832446464],[\""apps\"",\""accessibility\"",\""1.7.0\""],[\""apps\"",\""activity\"",\""2.14.3\""],[\""apps\"",\""admin_audit\"",\""1.11.0\""],[\""apps\"",\""apporder\"",\""0.12.0\""],[\""apps\"",\""bookmarks\"",\""4.1.0\""],[\""apps\"",\""bookmarks_fulltextsearch\"",\""disabled\""],[\""apps\"",\""calendar\"",\""2.2.1\""],[\""apps\"",\""carnet\"",\""disabled\""],[\""apps\"",\""cloud_federation_api\"",\""1.4.0\""],[\""apps\"",\""cms_pico\"",\""disabled\""],[\""apps\"",\""comments\"",\""1.11.0\""],[\""apps\"",\""contacts\"",\""3.5.1\""],[\""apps\"",\""contactsinteraction\"",\""1.2.0\""],[\""apps\"",\""cospend\"",\""disabled\""],[\""apps\"",\""dashboard\"",\""disabled\""],[\""apps\"",\""dav\"",\""1.17.1\""],[\""apps\"",\""deck\"",\""1.4.2\""],[\""apps\"",\""documents\"",\""disabled\""],[\""apps\"",\""drawio\"",\""disabled\""],[\""apps\"",\""duplicatefinder\"",\""0.0.6\""],[\""apps\"",\""encryption\"",\""disabled\""],[\""apps\"",\""end_to_end_encryption\"",\""disabled\""],[\""apps\"",\""epubreader\"",\""1.4.6\""],[\""apps\"",\""external\"",\""disabled\""],[\""apps\"",\""federatedfilesharing\"",\""1.11.0\""],[\""apps\"",\""federation\"",\""1.11.0\""],[\""apps\"",\""files\"",\""1.16.0\""],[\""apps\"",\""files_ebookreader\"",\""disabled\""],[\""apps\"",\""files_external\"",\""1.12.0\""],[\""apps\"",\""files_markdown\"",\""2.3.3\""],[\""apps\"",\""files_pdfviewer\"",\""2.1.0\""],[\""apps\"",\""files_reader\"",\""disabled\""],[\""apps\"",\""files_retention\"",\""disabled\""],[\""apps\"",\""files_rightclick\"",\""1.0.0\""],[\""apps\"",\""files_sharing\"",\""1.13.1\""],[\""apps\"",\""files_texteditor\"",\""disabled\""],[\""apps\"",\""files_trashbin\"",\""1.11.0\""],[\""apps\"",\""files_versions\"",\""1.14.0\""],[\""apps\"",\""files_videoplayer\"",\""1.10.0\""],[\""apps\"",\""firstrunwizard\"",\""2.10.0\""],[\""apps\"",\""flowupload\"",\""disabled\""],[\""apps\"",\""fulltextsearch\"",\""disabled\""],[\""apps\"",\""fulltextsearch_elasticsearch\"",\""disabled\""],[\""apps\"",\""gallery\"",\""disabled\""],[\""apps\"",\""keeweb\"",\""disabled\""],[\""apps\"",\""logreader\"",\""2.6.0\""],[\""apps\"",\""lookup_server_connector\"",\""1.9.0\""],[\""apps\"",\""mail\"",\""disabled\""],[\""apps\"",\""mindmaps\"",\""disabled\""],[\""apps\"",\""news\"",\""15.4.3\""],[\""apps\"",\""nextcloud_announcements\"",\""1.10.0\""],[\""apps\"",\""notifications\"",\""2.9.0\""],[\""apps\"",\""oauth2\"",\""1.9.0\""],[\""apps\"",\""onlyoffice\"",\""6.3.0\""],[\""apps\"",\""ownnote\"",\""disabled\""],[\""apps\"",\""password_policy\"",\""1.11.0\""],[\""apps\"",\""photos\"",\""1.3.0\""],[\""apps\"",\""previewgenerator\"",\""3.1.1\""],[\""apps\"",\""privacy\"",\""1.5.0\""],[\""apps\"",\""provisioning_api\"",\""1.11.0\""],[\""apps\"",\""rainloop\"",\""disabled\""],[\""apps\"",\""recommendations\"",\""disabled\""],[\""apps\"",\""richdocuments\"",\""disabled\""],[\""apps\"",\""richdocumentscode\"",\""disabled\""],[\""apps\"",\""serverinfo\"",\""1.11.0\""],[\""apps\"",\""settings\"",\""1.3.0\""],[\""apps\"",\""sharebymail\"",\""1.11.0\""],[\""apps\"",\""sharerenamer\"",\""2.7.3\""],[\""apps\"",\""socialsharing_email\"",\""disabled\""],[\""apps\"",\""spreed\"",\""11.2.1\""],[\""apps\"",\""spreedme\"",\""disabled\""],[\""apps\"",\""support\"",\""1.4.0\""],[\""apps\"",\""survey_client\"",\""1.9.0\""],[\""apps\"",\""systemtags\"",\""1.11.0\""],[\""apps\"",\""tasks\"",\""0.13.6\""],[\""apps\"",\""templateeditor\"",\""disabled\""],[\""apps\"",\""text\"",\""3.2.0\""],[\""apps\"",\""theming\"",\""1.12.0\""],[\""apps\"",\""theming_customcss\"",\""disabled\""],[\""apps\"",\""twofactor_backupcodes\"",\""1.10.0\""],[\""apps\"",\""updatenotification\"",\""1.11.0\""],[\""apps\"",\""user_external\"",\""2.0.0\""],[\""apps\"",\""user_status\"",\""1.1.1\""],[\""apps\"",\""viewer\"",\""1.5.0\""],[\""apps\"",\""weather\"",\""disabled\""],[\""apps\"",\""weather_status\"",\""1.1.0\""],[\""apps\"",\""workflowengine\"",\""2.3.0\""],[\""stats\"",\""num_files\"",624348],[\""stats\"",\""num_users\"",7],[\""stats\"",\""num_storages\"",11],[\""stats\"",\""num_storages_local\"",1],[\""stats\"",\""num_storages_home\"",7],[\""stats\"",\""num_storages_other\"",3],[\""stats\"",\""num_comments\"",51],[\""stats\"",\""num_comment_markers\"",1],[\""stats\"",\""num_systemtags\"",4],[\""stats\"",\""num_systemtags_mappings\"",1],[\""files_sharing\"",\""num_shares\"",6],[\""files_sharing\"",\""num_shares_user\"",1],[\""files_sharing\"",\""num_shares_groups\"",0],[\""files_sharing\"",\""num_shares_link\"",4],[\""files_sharing\"",\""num_shares_link_no_password\"",4],[\""files_sharing\"",\""num_fed_shares_sent\"",0],[\""files_sharing\"",\""num_fed_shares_received\"",0],[\""files_sharing\"",\""permissions_0_1\"",\""1\""],[\""files_sharing\"",\""permissions_4_1\"",\""1\""],[\""files_sharing\"",\""permissions_3_15\"",\""1\""],[\""files_sharing\"",\""permissions_3_1\"",\""3\""],[\""encryption\"",\""enabled\"",\""no\""],[\""encryption\"",\""default_module\"",\""yes\""]]}"", ""last_sent"": ""1620866709"", ""types"": """" }, ""systemtags"": { ""enabled"": ""yes"", ""installed_version"": ""1.11.0"", ""types"": ""logging"" }, ""tasks"": { ""enabled"": ""yes"", ""installed_version"": ""0.13.6"", ""types"": """" }, ""templateeditor"": { ""enabled"": ""no"", ""installed_version"": ""0.2"", ""types"": """" }, ""text"": { ""enabled"": ""yes"", ""installed_version"": ""3.2.0"", ""types"": ""dav"" }, ""theming"": { ""cachebuster"": ""1"", ""enabled"": ""yes"", ""installed_version"": ""1.12.0"", ""types"": ""logging"", ""url"": ""***REMOVED SENSITIVE VALUE***"" }, ""theming_customcss"": { ""enabled"": ""no"", ""installed_version"": ""1.8.0"", ""types"": """" }, ""twofactor_backupcodes"": { ""enabled"": ""yes"", ""installed_version"": ""1.10.0"", ""types"": """" }, ""updatenotification"": { ""apporder"": ""0.12.0"", ""bookmarks"": ""4.2.0"", ""bookmarks_fulltextsearch"": ""1.0.0"", ""calendar"": ""2.0.5"", ""carnet"": ""0.22.2"", ""contacts"": ""3.5.1"", ""core"": ""19.0.10.1"", ""deck"": ""1.2.7"", ""drawio"": ""0.9.4"", ""duplicatefinder"": ""0.0.8"", ""enabled"": ""yes"", ""epubreader"": ""1.4.6"", ""external"": ""3.0.4"", ""files_markdown"": ""2.3.2"", ""files_pdfviewer"": ""1.2.1"", ""files_rightclick"": ""0.15.1"", ""flowupload"": ""0.0.8"", ""fulltextsearch"": ""1.2.9"", ""fulltextsearch_elasticsearch"": ""1.2.6"", ""installed_version"": ""1.11.0"", ""keeweb"": ""0.3.1"", ""mail"": ""1.3.4"", ""news"": ""14.2.2"", ""onlyoffice"": ""7.0.2"", ""previewgenerator"": ""2.3.0"", ""rainloop"": ""5.1.0"", ""richdocuments"": ""1.12.35"", ""sharerenamer"": ""2.7.3"", ""spreed"": ""9.0.9"", ""spreedme"": ""0.3.7"", ""tasks"": ""0.13.6"", ""text"": ""1.0.2"", ""theming"": ""1.4.5"", ""theming_customcss"": ""1.6.0"", ""types"": """", ""update_check_errors"": ""0"", ""weather"": ""1.5.4"" }, ""user_external"": { ""installed_version"": ""2.0.0"", ""types"": ""prelogin,authentication"" }, ""user_status"": { ""enabled"": ""yes"", ""installed_version"": ""1.1.1"", ""types"": """" }, ""viewer"": { ""enabled"": ""yes"", ""installed_version"": ""1.5.0"", ""types"": """" }, ""weather"": { ""enabled"": ""no"", ""installed_version"": ""1.7.5"", ""openweathermap_api_key"": ""71fefb036fa124e5f8dae8f1cd3c9b98"", ""types"": """" }, ""weather_status"": { ""enabled"": ""yes"", ""installed_version"": ""1.1.0"", ""types"": """" }, ""workflowengine"": { ""enabled"": ""yes"", ""installed_version"": ""2.3.0"", ""types"": ""filesystem"" } } } ~~~ - Nextcloud external user backend: None **Additional context** The Android Bookmarks app still works fine. Adding An item directly from the Bookmarks app inside of NextCloud also works fine. **Web server error log** Appear normal Insert your webserver log here Appear Normal **Nextcloud log (nextcloud/data/nextcloud.log)** ``` Doesn't appear to make it into the nextcloud log. ``` **Browser log** After clicking the Save Button: ``` bookmarks-main.js?v=ef18e231-1:7 TypeError: n.childrenByFolder[-1] is not iterable at m.CREATE_BOOKMARK (bookmarks-main.js?v=ef18e231-1:1) at Array.<anonymous> (bookmarks-main.js?v=ef18e231-1:631) at m.dispatch (bookmarks-main.js?v=ef18e231-1:637) at m.dispatch (bookmarks-main.js?v=ef18e231-1:631) at i.submit (bookmarks-main.js?v=ef18e231-1:1112) at Ge (bookmarks-main.js?v=ef18e231-1:7) at HTMLButtonElement.n (bookmarks-main.js?v=ef18e231-1:7) at HTMLButtonElement.r._wrapper (bookmarks-main.js?v=ef18e231-1:7) ``` And it doesn't actually post anything to the server. "
315331,350572,https://api.github.com/repos/zbrateam/Zebra/issues/1764,bug,2021-03-10T09:25:05Z,NONE,https://api.github.com/repos/zbrateam/Zebra,"Add a feature to show repos that are down Probably not the place, but some kind of indicator to show which repo isnt loading, like cydia's spinner, sometimes i have updates that wont show because other repos are timing out or are just down & i cant even temporarily remove that repo as it doesnt show or say what repo is down, it just stays refreshing. Something like a '!' on the downed repo rather than sitting there for ages waiting for it to never update (well until downed repo is back up lol)"
700485,778534,https://api.github.com/repos/pxblue/doc-it/issues/393,bug,2021-04-19T13:54:17Z,MEMBER,https://api.github.com/repos/pxblue/doc-it,"Community icons are shifted upwards #### Describe the bug In `/community`, the icons in the info cards are top-aligned #### What is the expected behavior? Icons should be centered #### What are the steps to reproduce? 1. Go to https://pxblue.github.io/community 2. Observe that the icon styles are a bit wrong #### Screenshots or links to minimum reproduction example This `<span>` would appreciate a `display:flex` ![image](https://user-images.githubusercontent.com/8997218/115247781-171adc00-a0f5-11eb-8928-329c972fb122.png) #### Environment <!-- Describe any relevant environment information (e.g., Operating System, Library version number, browser used, etc.) where the issue was discovered --> #### Anything else to add? "
401814,446604,https://api.github.com/repos/molstar/molstar/issues/184,enhancement,2021-05-10T03:37:09Z,MEMBER,https://api.github.com/repos/molstar/molstar,"Geometry export: support volume & volumeInstance color type #173 will add new `dColorType` values: ""volume"" | ""volumeInstance"". Before merging it would be nice to add support for these to the geometry exporters. New `ColorData` fields: ``` tColorGrid: ValueCell.create(colors), uColorGridDim: ValueCell.create(Vec3.clone(dimension)), uColorGridTransform: ValueCell.create(Vec4.clone(transform)), ``` `getTrilinearlyInterpolated` (src\mol-geo\geometry\mesh\color-smoothing.ts) can be used to get trilinearly interpolated colors on the CPU."
6168,6885,https://api.github.com/repos/Dherrera54/git_web_practice_branch/issues/1,bug,2021-02-17T15:39:53Z,NONE,https://api.github.com/repos/Dherrera54/git_web_practice_branch,"ISSUE 1: Corrección de páginas 5 y 3 ### Identificador de corrección: `FIX1` Cree una rama con el nombre `fix_1` y muevase a dicha rama para corregir los siguientes errores: - En `pagina5.html`. La imagen y el título de la página no corresponden. - En `pagina3.html`. El link a la página siguiente apunta a una dirección equivocada. ### Soluciones: - En `pagina5.html`, cambiar la ruta de la imagen con id `imagen5` por `../imagenes/BD5.gif` y el texto del título con id `titulo5` por `Mi quinta página HTML`. - En `pagina3.html`, cambiar el link de navegación con id `enlace3` por `pagina4.html` y colocarle el nombre correcto `Mi cuarta página HTML`."
124689,138569,https://api.github.com/repos/Touhma/DSP_Plugins/issues/6,bug,2021-02-17T18:16:43Z,NONE,https://api.github.com/repos/Touhma/DSP_Plugins,"Lightning is weird Lighting is weird on at least the starting planet. On bright side of the planet, terrain is dark but vegetation/rocks are normal. On dark side of the planet, terrain is bright but vegetation/rocks are normal. Cluster 43370258-1024-A10 Planet is: Denebola I ![Screenshot_105](https://user-images.githubusercontent.com/47742123/108248777-91aa9800-7154-11eb-836e-2d96a3dab248.png) ![Screenshot_106](https://user-images.githubusercontent.com/47742123/108248778-92dbc500-7154-11eb-94d9-85f502069612.png) "
653761,726718,https://api.github.com/repos/microsoft/vscode/issues/122637,bug,2021-04-29T09:02:09Z,MEMBER,https://api.github.com/repos/microsoft/vscode,"Hex editor: open untitled file as hex should turn document dirty Steps to Reproduce: 1. open an untitled file and make it dirty 2. pick _Hex Editor: Open Active File in Hex Editor_ (or ""Reopen editor with..."") => 🐛 the hex editor opens but not dirty, I think it should be dirty given it is untitled and has user typed contents. ![image](https://user-images.githubusercontent.com/900690/116526918-61ad0d00-a8da-11eb-8c3a-cb82ba2a24bc.png) "
313946,349027,https://api.github.com/repos/OpenRTX/OpenRTX/issues/19,question,2021-03-21T15:19:31Z,NONE,https://api.github.com/repos/OpenRTX/OpenRTX,"RTOS / toolchain feasibility Hello fellow hams and developers! Thanks for your great work. This is an interesting and very poorly documented field. I understand the numerous obstac;les we have to pass, just to make a single radio boot up. This is not an issue, but a query out of my own curosity as a developer. Could you explain, for example: - OS: the background behind choosing a Miosix kernel for this development? Are we relying on some parts of the original radio firmware, and therefore need to build upon it, using the same OS? My question can also be formulated like this: without going into it's well known (dis)advantages right now, why not, for example, FreeRTOS? - Toolchain: I'm not sure about each radio, but the majority of the interesting ones seem to be running STM32 these days. So, once more, I am curious why not using StmCubeIDE from ST? - Hardware: I understand that manufacturers would like to prevent us from loading anything into their precious products (although 90% of the brands are not really manufactoring or developing anything :-) ). Therefore we have lack of documentation, obscure baseband chips, encrypted firmware images and other obstacles. So my question is: during the development phase, why not use JTAG interface to directly program the mcu? We could skip the whole cycle of wrapping, encrypting and downloading with yet-another-tool before running the latest code. When the work is done (if ever :-) ) the final fw image could be packed and released to the public, to be used with the radio's official upgrade tool. Apart from easing the testing, this could also attract more developers who may be put off by the numerous steps involved and the steep learning curve for each. In my own personal case, I am quite interested to get involved, but not keen on spending a lot of time to set up the n-th toolchain for this-or-that, of the many things I am trying to tackle. On the other hand, for the stm32, I have the IDE, in-circuit debugger and free rtos knowledge, where I could start today. Ofcourse, they are all free of charge. Well, that's just my own personal oppinion. By the way, I own an RT84 with specs quite similar to RT3s and md-uv380. The firmware for rt84 is identical to Baofeng 1701 (and another popular model, I can't remember right now). I prooved this by downloading from their manufacturer's support page and comparing the sha-512 checksums. RT84 uses an stm32 and, based on the checksum fact, it's a safe quess that both the mcu and the baseband hr_c6000 is also the same in those. Thanks to anyone taking the time to comment. yt1zkb"
220304,244995,https://api.github.com/repos/ttauri-project/ttauri/issues/121,bug,2021-03-26T19:51:27Z,MEMBER,https://api.github.com/repos/ttauri-project/ttauri,"Remove dependency on ADX, ADO instructions. Currently I am using ADX and ADO intrinsics which are not supported by AMD Excavator."
643155,714835,https://api.github.com/repos/ucb-rit/coldfront/issues/171,bug,2021-05-24T15:45:21Z,COLLABORATOR,https://api.github.com/repos/ucb-rit/coldfront,"Replace ""Memorandum of Use"" with ""Memorandum of Understanding"" MOU stands for ""Memorandum of Understanding"", not ""Memorandum of Use""."
555390,617216,https://api.github.com/repos/Jacobvs/Rotmg-Discord-Bot/issues/94,bug,2020-09-17T03:50:45Z,OWNER,https://api.github.com/repos/Jacobvs/Rotmg-Discord-Bot,"[BUG] Submitted by ""Blue The dummy locations in the qafk can only be EU locations. It also chooses EUWest which is often Full. Uploaded Image: https://res.cloudinary.com/darkmattr/image/upload/v1600314645/gh_issues/vcnwmjpwn8xjvpjvqvsu.png"
511436,568395,https://api.github.com/repos/Mondotosz/Web-Observation/issues/46,enhancement,2021-03-14T13:34:34Z,OWNER,https://api.github.com/repos/Mondotosz/Web-Observation,[Feature] Realtime username/email checker Add realtime username/email availability checker using [ajax](https://api.jquery.com/jquery.ajax/) or [XMLHttpRequest](https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest)
684574,760834,https://api.github.com/repos/alphagov/service-manual-frontend/issues/121,bug,2017-07-18T12:21:12Z,NONE,https://api.github.com/repos/alphagov/service-manual-frontend,"Service Toolkit - Feedback link / form sits outside of layout The link ""is anything wrong with this page"" and associated form on /service-toolkit is outside of the main page layout and hard aligned to the left. It should be aligned with the rest of the content. <img width=""377"" alt=""screen shot 2017-07-18 at 13 14 10"" src=""https://user-images.githubusercontent.com/23356842/28316577-47a24570-6bbb-11e7-9a02-47d382bb8bbd.png""> <img width=""600"" alt=""screen shot 2017-07-18 at 13 17 56"" src=""https://user-images.githubusercontent.com/23356842/28316650-961e8880-6bbb-11e7-8321-3633e5e92de1.png""> "
10996,12266,https://api.github.com/repos/twanh/note-system/issues/36,enhancement,2021-04-17T11:19:33Z,OWNER,https://api.github.com/repos/twanh/note-system,Show pandoc errors Show the error pandoc throws when the conversion went wrong. 
512293,569321,https://api.github.com/repos/nextauthjs/next-auth/issues/277,enhancement,2020-06-16T16:56:26Z,NONE,https://api.github.com/repos/nextauthjs/next-auth,"Refreshing Profile Data with a new session Is there a way such that when a person creates a new session (in a traditional sense, ie closing and reopening their browser) that profile data such as their name, image etc. can be reloaded whilst retaining tokens? One way of this would be such that vital data (ie access token, refresh token, expiry time) is in the 30 day cookie and current profile data is in a session cookie. Thanks."
508201,564794,https://api.github.com/repos/hoobs-org/hoobsd/issues/49,enhancement,2021-04-23T16:17:30Z,MEMBER,https://api.github.com/repos/hoobs-org/hoobsd,"Keep bridge status as manually set If you stop a bridge manually for testing other stuff and then you install a new plugin on a new bridge or remove an existing plugin from another bridge, all the manually stopped bridges start back up automatically on their own. All bridges manually stopped should remain stopped until they're turned back on or a reboot happens. "
507546,564076,https://api.github.com/repos/cota-eng/bista_front_nextjs/issues/25,enhancement,2021-04-30T00:00:45Z,OWNER,https://api.github.com/repos/cota-eng/bista_front_nextjs,検索トピック作成 - 画像集め - レイアウト etc
550929,612306,https://api.github.com/repos/ytdl-org/youtube-dl/issues/27969,question,2021-01-25T23:19:03Z,NONE,https://api.github.com/repos/ytdl-org/youtube-dl,"Hii i need a little help downloading this vod <!-- ###################################################################### WARNING! IGNORING THE FOLLOWING TEMPLATE WILL RESULT IN ISSUE CLOSED AS INCOMPLETE ###################################################################### --> ## Checklist <!-- Carefully read and work through this check list in order to prevent the most common mistakes and misuse of youtube-dl: - Look through the README (http://yt-dl.org/readme) and FAQ (http://yt-dl.org/faq) for similar questions - Search the bugtracker for similar questions: http://yt-dl.org/search-issues - Finally, put x into all relevant boxes (like this [x]) --> - [ ] I'm asking a question - [ ] I've looked through the README and FAQ for similar questions - [ ] I've searched the bugtracker for similar questions including closed ones ## Question <!-- Ask your question in an arbitrary form. Please make sure it's worded well enough to be understood, see https://github.com/ytdl-org/youtube-dl#is-the-description-of-the-issue-itself-sufficient. --> WRITE QUESTION HERE Hi Im trying to download a VOD but i get this message and i dont understand what i need to do ERROR: Unable to download JSON metadata: HTTP Error 404: Not Found (caused by <HTTPError 404: 'Not Found'>); please report this issue on https://yt-dl.org/bug . Make sure you are using the latest version; see https://yt-dl.org/update on how to update. Be sure to call youtube-dl with the --verbose flag and include its complete output. "
217606,241978,https://api.github.com/repos/JaCraig/FileCurator/issues/1,enhancement,2016-11-22T03:25:27Z,OWNER,https://api.github.com/repos/JaCraig/FileCurator,Add FTP support https://github.com/JaCraig/Craig-s-Utility-Library/blob/master/Utilities.IO/IO/FileSystem/Default/FtpFileSystem.cs
161178,179197,https://api.github.com/repos/TarsCloud/Tars/issues/619,question,2020-06-28T20:47:58Z,NONE,https://api.github.com/repos/TarsCloud/Tars,"Cannot Deploy the service using Docker ### What language are you using? nodejs ### What operating system (Linux, Ubuntu, …) and version? macOS ### What runtime / compiler are you using (e.g. jdk version or version of gcc) darwin I follow the instruction on this documentation and build the env using docker. https://tarscloud.github.io/TarsDocs/installation/docker.html And I follow the nodejs scaffold documentation to build the application, https://tarscloud.github.io/TarsDocs_en/dev/tars.js/nodetools-cli.html but when I want to upload the application, I cannot access to the virtual network I created. I think 172.25.0.3 is not public IP, how can I solve this problem. <img width=""1438"" alt=""Screen Shot 2020-06-28 at 4 05 31 PM"" src=""https://user-images.githubusercontent.com/25846666/85957878-1a26bf00-b95f-11ea-8b9d-cf57f8788b1b.png""> <img width=""1660"" alt=""Screen Shot 2020-06-28 at 4 10 14 PM"" src=""https://user-images.githubusercontent.com/25846666/85957881-1d21af80-b95f-11ea-83ec-e5835a54ab52.png""> "
489238,543747,https://api.github.com/repos/orkestral/venom/issues/806,bug,2021-04-05T00:17:08Z,NONE,https://api.github.com/repos/orkestral/venom,"Error: Protocol error (Runtime.callFunctionOn): Session closed. ## Description When the qrcode is read everything works as expected, but if you logout directly from Whatsapp app ou using `logout() ` function is triggered an error. ## Environment - **Venom version(s):** 3.0.12-alpha.0 - **Browser:** Chrome 88 - **OS:** Debian Stretch - **Node version:** Node 14 ## Steps to Reproduce 1. Read QrCode 2. Logout from Whatsapp ## Log Output > 0|index | Error: Protocol error (Runtime.callFunctionOn): Session closed. Most likely the page has been closed. > 0|index | at CDPSession.send (/var/www/whapi/node/node_modules/puppeteer/lib/cjs/puppeteer/common/Connection.js:195:35) > 0|index | at ExecutionContext._evaluateInternal (/var/www/whapi/node/node_modules/puppeteer/lib/cjs/puppeteer/common/ExecutionContext.js:200:50) > 0|index | at ExecutionContext.evaluate (/var/www/whapi/node/node_modules/puppeteer/lib/cjs/puppeteer/common/ExecutionContext.js:106:27) > 0|index | at DOMWorld.evaluate (/var/www/whapi/node/node_modules/puppeteer/lib/cjs/puppeteer/common/DOMWorld.js:90:24) > 0|index | at processTicksAndRejections (internal/process/task_queues.js:93:5) "
421364,468380,https://api.github.com/repos/nbuilding/N-lang/issues/130,bug,2021-04-11T21:47:18Z,CONTRIBUTOR,https://api.github.com/repos/nbuilding/N-lang,"times.sleep does not work At https://github.com/nbuilding/N-lang/blob/ebc0e7cb3fc21364e965866b4649611a12f461f7/python/libraries/times.py#L6-L7 There is a major error, as this code has not been touched for a very long, so it thinks that the value given in is an array, so it will cause an error when it is called."
248094,275934,https://api.github.com/repos/putyourlightson/craft-blitz/issues/291,question,2021-02-24T17:50:14Z,NONE,https://api.github.com/repos/putyourlightson/craft-blitz,"SQL errors while updating Blitz ### Question While updating Blitz on an existing site I ran into this SQL error. Choosing to restore the DB from the CP puts me into an endless loop -> database has been restored -> In order to to complete the update... click yes -> back to the error message again. - Hosted at Arcustech - Craft 3.4.22.1 - Blitz 3.7.0 (according composer, but that's probably after the failed update) Database Exception: SQLSTATE[HY000]: General error: 1025 Error on rename of './av04135b/#sql-242_2c38' to './av04135b/blitz_elementcaches' (errno: 150 - Foreign key constraint is incorrectly formed) The SQL being executed was: DROP INDEX `blitz_elementcaches_cacheId_elementId_unq_idx` ON `blitz_elementcaches` Migration: putyourlightson\blitz\migrations\m200721_120000_add_primary_keys Output: > drop index blitz_elementcaches_cacheId_elementId_unq_idx on {{%blitz_elementcaches}} ...Exception: SQLSTATE[HY000]: General error: 1025 Error on rename of './av04135b/#sql-242_2c38' to './av04135b/blitz_elementcaches' (errno: 150 - Foreign key constraint is incorrectly formed) The SQL being executed was: DROP INDEX `blitz_elementcaches_cacheId_elementId_unq_idx` ON `blitz_elementcaches` (/storage/av04135/www/public_html/vendor/yiisoft/yii2/db/Schema.php:674) #0 /storage/av04135/www/public_html/vendor/yiisoft/yii2/db/Command.php(1298): yii\db\Schema->convertException(Object(PDOException), 'DROP INDEX `bli...') #1 /storage/av04135/www/public_html/vendor/yiisoft/yii2/db/Command.php(1093): yii\db\Command->internalExecute('DROP INDEX `bli...') #2 /storage/av04135/www/public_html/vendor/yiisoft/yii2/db/Migration.php(507): yii\db\Command->execute() #3 /storage/av04135/www/public_html/vendor/craftcms/cms/src/helpers/MigrationHelper.php(118): yii\db\Migration->dropIndex('blitz_elementca...', '{{%blitz_elemen...') #4 /storage/av04135/www/public_html/vendor/putyourlightson/craft-blitz/src/migrations/m200721_120000_add_primary_keys.php(28): craft\helpers\MigrationHelper::dropIndexIfExists('{{%blitz_elemen...', Array, true, Object(putyourlightson\blitz\migrations\m200721_120000_add_primary_keys)) #5 /storage/av04135/www/public_html/vendor/craftcms/cms/src/db/Migration.php(52): putyourlightson\blitz\migrations\m200721_120000_add_primary_keys->safeUp() #6 /storage/av04135/www/public_html/vendor/craftcms/cms/src/db/MigrationManager.php(233): craft\db\Migration->up(true) #7 /storage/av04135/www/public_html/vendor/craftcms/cms/src/db/MigrationManager.php(153): craft\db\MigrationManager->migrateUp(Object(putyourlightson\blitz\migrations\m200721_120000_add_primary_keys)) #8 /storage/av04135/www/public_html/vendor/craftcms/cms/src/services/Updates.php(233): craft\db\MigrationManager->up() #9 /storage/av04135/www/public_html/vendor/craftcms/cms/src/controllers/BaseUpdaterController.php(510): craft\services\Updates->runMigrations(Array) #10 /storage/av04135/www/public_html/vendor/craftcms/cms/src/controllers/UpdaterController.php(203): craft\controllers\BaseUpdaterController->runMigrations(Array, 'restore-db') #11 [internal function]: craft\controllers\UpdaterController->actionMigrate() #12 /storage/av04135/www/public_html/vendor/yiisoft/yii2/base/InlineAction.php(57): call_user_func_array(Array, Array) #13 /storage/av04135/www/public_html/vendor/yiisoft/yii2/base/Controller.php(157): yii\base\InlineAction->runWithParams(Array) #14 /storage/av04135/www/public_html/vendor/craftcms/cms/src/web/Controller.php(178): yii\base\Controller->runAction('migrate', Array) #15 /storage/av04135/www/public_html/vendor/yiisoft/yii2/base/Module.php(528): craft\web\Controller->runAction('migrate', Array) #16 /storage/av04135/www/public_html/vendor/craftcms/cms/src/web/Application.php(291): yii\base\Module->runAction('updater/migrate', Array) #17 /storage/av04135/www/public_html/vendor/craftcms/cms/src/web/Application.php(646): craft\web\Application->runAction('updater/migrate') #18 /storage/av04135/www/public_html/vendor/craftcms/cms/src/web/Application.php(243): craft\web\Application->_processUpdateLogic(Object(craft\web\Request)) #19 /storage/av04135/www/public_html/vendor/yiisoft/yii2/base/Application.php(386): craft\web\Application->handleRequest(Object(craft\web\Request)) #20 /storage/av04135/www/public_html/public/index.php(42): yii\base\Application->run() #21 {main} "
713900,793424,https://api.github.com/repos/proftpd/proftpd/issues/1200,bug,2021-03-19T12:43:20Z,NONE,https://api.github.com/repos/proftpd/proftpd,"When SFTP client requests a lower version of SFTP protocol than allowed by SFTPClientMatch sftpProtocolVersion, mod_sftp does not respect the client ### What I Did `proftpd.conf`: ``` SFTPClientMatch "".*WinSCP.*"" sftpProtocolVersion 6 ``` Connect with WinSCP configured to ask for SFTP version 3 (or any lower than 6). ### What I Expected/Wanted `draft-ietf-secsh-filexfer-13` says in [*5.2. Server Initialization*](https://tools.ietf.org/html/draft-ietf-secsh-filexfer-13#section-5.2): > 'version' is the lower of the protocol version supported by the server and the version number received from the client. Even the SFTPv3 specification `draft-ietf-secsh-filexfer-02` says in [4. Protocol Initialization](https://tools.ietf.org/html/draft-ietf-secsh-filexfer-03#section-4): > The server responds with a SSH_FXP_VERSION packet, supplying the lowest of its own and the client's version number. So assume the only right solution is to disconnect the client. ### ProFTPD Version and Configuration ProFTPD built from the master (currently 5fa01bc3). Relevant code in `fxp_handle_init`: https://github.com/proftpd/proftpd/blob/v1.3.7a/contrib/mod_sftp/fxp.c#L7722-L7729 Thanks."
306146,340389,https://api.github.com/repos/raspbernetes/multi-arch-images/issues/207,bug,2021-02-22T09:14:45Z,CONTRIBUTOR,https://api.github.com/repos/raspbernetes/multi-arch-images,"csi-external-snapshotter missing versions 3.0.3 and 4.0.0, latest downgraded to 2.1.4 # Details **What steps did you take and what happened:** Image versions listed for `csi-external-snapshotter` are missing `3.0.3` and `4.0.0` on [docker hub raspbernetes/csi-external-snapshotter](https://hub.docker.com/r/raspbernetes/csi-external-snapshotter/tags?page=1&ordering=last_updated). However, versions `3.0.0` (oldest 3.x) and `2.1.4` (latest 2.x) do exist on docker hub. Additionally, `latest` points to `2.1.4`. Upon updating, should this point to `3.0.3`, `4.0.0` or the latest 2.x stable (`2.1.4`)? PR #206 fixed the build for csi-external-snapshotter (see #205), but accidentally made version `2.1.4` aliased by `latest`, despite `3.0.0` being the previous `latest`. This will cause a _downgrade_ on subsequent pulls for those using the `latest` tag. **What did you expect to happen:** Versions 3.0.3 and 4.0.0 should be made available, and _maybe_ `latest` should alias `4.0.0`. **Additional Information:** In what **order** should the [`.version` file](https://github.com/raspbernetes/multi-arch-images/blob/master/build/csi-external-snapshotter/.version) be updated? "
404754,449878,https://api.github.com/repos/libsdl-org/SDL/issues/1058,bug,2021-02-10T23:05:13Z,COLLABORATOR,https://api.github.com/repos/libsdl-org/SDL,"OpenGL doesn't work with --disable-threads # This bug report was migrated from our old Bugzilla tracker. **Reported in version:** HG 2.1 **Reported for operating system, platform:** Windows 7, x86_64 # Comments on the original bug report: On 2013-08-29 22:53:15 +0000, wrote: > Thread local storage is used to store current window and current opengl context. OpenGL worked before this changeset: 7596 (45e5c263c096) Ensure that the right window is current in SDL_GL_SwapWindow. On 2013-09-05 14:15:50 +0000, Sam Lantinga wrote: > Fixed, thanks! > http://hg.libsdl.org/SDL/rev/e928464b98ec "
411418,457298,https://api.github.com/repos/filetrust/icap-management-ui/issues/83,bug,2020-11-24T16:21:29Z,COLLABORATOR,https://api.github.com/repos/filetrust/icap-management-ui,"BUG - Error Getting Transaction Data is displayed in RequestHistory table when a Risk Filter is applied ""Not sure where the problem lies but on the Mgt UI Request History Page when only a time filter is applied, and there are no transaction, No Transaction Data Found is displayed when a filetype filter is applied, and there are no transaction, No Transaction Data Found is displayed when a Risk filter is applied, and there are no transactions, Error Getting Transaction Data is displayed"""
674096,749201,https://api.github.com/repos/home-assistant/android/issues/1302,bug,2021-01-18T02:28:55Z,NONE,https://api.github.com/repos/home-assistant/android,"status does not change from 'Home'. <!-- READ THIS FIRST: - Make sure you run the latest version of the Android app - Make sure you run the latest version of Home Assistant - Make sure to check the Companion docs for troubleshooting and configuration: https://companion.home-assistant.io/ - Make sure the bug you found is not already reported, we love to put work in bugfixes instead of closing duplicate bug reports DO NOT DELETE ANY TEXT from this template! All requested information is important. --> **Home Assistant Android version:** 3.0.2-full **Android version:** 8.1.0 **Phone model:** Motorola G5 **Home Assistant version:** 2021.2.0.dev20210115 **Last working Home Assistant release (if known):** n/a **Description of problem:** status does not change from ""Home"", although sensor.moto_g_5_plus_geocoded_location was updated. I have an automation that should trigger when I leave home, but it does not work reliably. Weird is that in the history it shows it never left home, however the history for the geocoded location did. So it looks like the app did indeed notice that GPS changed, and therefore this does not seem to be an issue with GPS or the phone. The address seen in the screenshot (North Bend) is more than 30 minutes away from home. I just came back from a hiking trip. **Traceback (if applicable, to get the logs you may refer to: https://companion.home-assistant.io/docs/troubleshooting/faqs/#android-crash-logs):** ``` ``` n/a **Screenshot of problem:** <img width=""428"" alt=""Screen Shot 2021-01-17 at 6 14 39 PM"" src=""https://user-images.githubusercontent.com/6658518/104865390-b0690500-58f0-11eb-916a-9594932ba4d5.png""> <img width=""419"" alt=""Screen Shot 2021-01-17 at 6 14 02 PM"" src=""https://user-images.githubusercontent.com/6658518/104865393-b232c880-58f0-11eb-8f4b-690746fec6fa.png""> **Additional information:** n/a"
39085,43552,https://api.github.com/repos/aws-amplify/amplify-codegen/issues/28,enhancement,2019-08-23T10:44:37Z,NONE,https://api.github.com/repos/aws-amplify/amplify-codegen,"Ability to generate different filename.swift files from directories of .graphql files **Is your feature request related to a problem? Please describe.** Yes, https://github.com/aws-amplify/amplify-cli/issues/2122 **Describe the solution you'd like** amplify codegen --max-depth --input=MySubAPIDirectory --output=MySubAPIDirectory.swift would produce an api using just the .graphql files in MySubAPIDirectory and save it as MySubAPIDirectory.swift Basically, I don't want to create the massive namespace polluting API.swift that has everything in it. I want nice clean sub apis with just the queries, mutations, and subscriptions that I use in my app. **Describe alternatives you've considered** See the bug report for how I'm doing it now. It produces an error and is a hack. "
126080,140099,https://api.github.com/repos/graphql-dotnet/graphql-dotnet/issues/1123,bug,2019-05-02T17:14:46Z,NONE,https://api.github.com/repos/graphql-dotnet/graphql-dotnet,"context.SubFields does not include fragment fields on a NonNull field ## Description `context.SubFields` is not being populated with fragment fields on NonNullGraphType fields. It works fine for nullable fields. ### Steps to reproduce Here's a failing test exposing the issue (drops right into `StarWarsSubFieldsTest.cs`): ``` [Fact] public void subfields_contains_keys_from_fragments_on_non_null_fields() { RootQuery.Field<NonNullGraphType<HumanType>>(""luke"", resolve: context => { context.SubFields.ShouldNotBeNull(); context.SubFields.Keys.ShouldContain(""id""); context.SubFields.Keys.ShouldContain(""name""); return new Human { Id = ""1"", Name = ""Luke"" }; }); var query = @"" query Luke { luke { ...HumanData } } fragment HumanData on Human { id name } ""; var expected = @"" { luke: { id: """"1"""", name: """"Luke"""" } } ""; AssertQuerySuccess(query, expected); } ``` (Note: The same test with `Field<HumanType>` instead of `Field<NonNullGraphType<HumanType>>` will already pass.) ### Expected result The fragment field keys should be contained in `context.SubFields.Keys`. ### Actual result The fragment field keys are not included in `context.SubFields.Keys`."
176944,196721,https://api.github.com/repos/flybywiresim/a32nx/issues/3862,enhancement,2021-03-09T02:02:32Z,NONE,https://api.github.com/repos/flybywiresim/a32nx,[REQUEST] HYD PAGE ON ECAM PLEASE IMPLEMENT LOWER ECAM HYD PAGE
503616,559769,https://api.github.com/repos/UCBerkeleySETI/turbo_seti/issues/205,bug,2021-03-03T13:12:22Z,COLLABORATOR,https://api.github.com/repos/UCBerkeleySETI/turbo_seti,"Doppler search drift indices are a complete mystery The drift_indexes subdirectory has text files numbered 2 through 11. They are used in the Doppler search (search_coarse_channels). However, there is no documentation of what they are and there is no source code for the program that generated the files. "
72328,80408,https://api.github.com/repos/PikaMug/Quests/issues/1601,question,2021-02-05T04:52:11Z,NONE,https://api.github.com/repos/PikaMug/Quests,Plugin Compatibility with Economy++ Are the rewards compatible with the Economy++ plugin? Just so i can keep the same economy going.
386333,429455,https://api.github.com/repos/CAVaccineInventory/vaccine-feed-ingest/issues/622,bug,2021-05-12T21:41:56Z,CONTRIBUTOR,https://api.github.com/repos/CAVaccineInventory/vaccine-feed-ingest,"Broken parse: tn/vaccinate_gov (Exception: This address doesn't look like it's for Tennessee: Somerville) ``` 2021-05-12T14:40:42-0700 INFO:stages/ingest.py:Parsing tn/vaccinate_gov and saving parsed output to /var/folders/yf/ps34_b0x5pn_ddj9skx0gwph0000gn/T/tmpdooc8y65_parse_tn_vaccinate_gov/output Traceback (most recent call last): File ""/Users/alecfwilson/Sites/vaccine-feed-ingest/vaccine_feed_ingest/runners/tn/vaccinate_gov/parse.py"", line 88, in <module> sys.exit(main(argv)) File ""/Users/alecfwilson/Sites/vaccine-feed-ingest/vaccine_feed_ingest/runners/tn/vaccinate_gov/parse.py"", line 73, in main parsed_locations = [parse_location(loc) for loc in locations] File ""/Users/alecfwilson/Sites/vaccine-feed-ingest/vaccine_feed_ingest/runners/tn/vaccinate_gov/parse.py"", line 73, in <listcomp> parsed_locations = [parse_location(loc) for loc in locations] File ""/Users/alecfwilson/Sites/vaccine-feed-ingest/vaccine_feed_ingest/runners/tn/vaccinate_gov/parse.py"", line 59, in parse_location result[""address""] = parse_address(desc_parts[0].strip()) File ""/Users/alecfwilson/Sites/vaccine-feed-ingest/vaccine_feed_ingest/runners/tn/vaccinate_gov/parse.py"", line 28, in parse_address raise Exception(f""This address doesn't look like it's for Tennessee: {address}"") Exception: This address doesn't look like it's for Tennessee: Somerville Traceback (most recent call last): File ""<string>"", line 1, in <module> File ""/Users/alecfwilson/Sites/vaccine-feed-ingest/.venv/lib/python3.9/site-packages/click/core.py"", line 829, in __call__ return self.main(*args, **kwargs) File ""/Users/alecfwilson/Sites/vaccine-feed-ingest/.venv/lib/python3.9/site-packages/click/core.py"", line 782, in main rv = self.invoke(ctx) File ""/Users/alecfwilson/Sites/vaccine-feed-ingest/.venv/lib/python3.9/site-packages/click/core.py"", line 1259, in invoke return _process_result(sub_ctx.command.invoke(sub_ctx)) File ""/Users/alecfwilson/Sites/vaccine-feed-ingest/.venv/lib/python3.9/site-packages/click/core.py"", line 1066, in invoke return ctx.invoke(self.callback, **ctx.params) File ""/Users/alecfwilson/Sites/vaccine-feed-ingest/.venv/lib/python3.9/site-packages/click/core.py"", line 610, in invoke return callback(*args, **kwargs) File ""/Users/alecfwilson/Sites/vaccine-feed-ingest/vaccine_feed_ingest/cli.py"", line 269, in parse ingest.run_parse( File ""/Users/alecfwilson/Sites/vaccine-feed-ingest/vaccine_feed_ingest/stages/ingest.py"", line 149, in run_parse raise e File ""/Users/alecfwilson/Sites/vaccine-feed-ingest/vaccine_feed_ingest/stages/ingest.py"", line 138, in run_parse subprocess.run( File ""/Users/alecfwilson/.pyenv/versions/3.9.2/lib/python3.9/subprocess.py"", line 528, in run raise CalledProcessError(retcode, process.args, subprocess.CalledProcessError: Command '['/Users/alecfwilson/Sites/vaccine-feed-ingest/vaccine_feed_ingest/runners/tn/vaccinate_gov/parse.py', '/var/folders/yf/ps34_b0x5pn_ddj9skx0gwph0000gn/T/tmpdooc8y65_parse_tn_vaccinate_gov/output', '/var/folders/yf/ps34_b0x5pn_ddj9skx0gwph0000gn/T/tmpdooc8y65_parse_tn_vaccinate_gov/input', 'None']' returned non-zero exit status 1. ```"
633542,704117,https://api.github.com/repos/rdok/spacex-explorer/issues/32,bug,2020-02-24T05:54:11Z,OWNER,https://api.github.com/repos/rdok/spacex-explorer,Deployement: DB name resolution fails. ``` In Connector.php line 70: PDO::__construct(): php_network_getaddresses: getaddrinfo failed: Name does not resolve ```
554780,616543,https://api.github.com/repos/JJeanniard/Panel-Games-Servers/issues/6,enhancement,2020-09-10T18:19:38Z,OWNER,https://api.github.com/repos/JJeanniard/Panel-Games-Servers,Users to user v0.1.0 - [x] model users - [x] CRUD * - [x] registre * - [x] update * - [x] delete * - [x] info - [x] status - [x] login - [x] logout - [x] security - [ ] vue 
649691,722185,https://api.github.com/repos/TheHotchkissRecord/henry-web/issues/21,bug,2021-01-21T20:54:37Z,MEMBER,https://api.github.com/repos/TheHotchkissRecord/henry-web,"next/previous buttons broken? choose an article from the left split, then try next or previous buttons. they don't work. might be a problem with === comparison again"
524472,582906,https://api.github.com/repos/flybywiresim/a32nx/issues/4024,bug,2021-03-18T21:09:21Z,NONE,https://api.github.com/repos/flybywiresim/a32nx,"If you click a link on the FlyPad on the weather map, the tablet becomes unuable **Mod Version** FBW Experimental version downloaded from the flybywire installer. (latest development version) **Describe the bug** The tablet is basically a web browser, and when you click one of those tiny links on the weather map it loads a page and you are unable to reset or go back. Thus making the tablet unusable. Not sure if this would be a bug report or a feature request, but maybe add a reset button to the tablet somewhere in the cockpit? **To Reproduce** Zoom in and click one of those tiny blue links. **References** https://i.imgur.com/hqxZ1mo.png **Additional context** Not really anything else to add. "
592967,659001,https://api.github.com/repos/niyazisuleymanov/termdoro/issues/2,enhancement,2021-05-27T21:44:00Z,OWNER,https://api.github.com/repos/niyazisuleymanov/termdoro,"Modify README, keep only what is needed for termdoro This project initially was a fork of [trehn/termdown](https://github.com/trehn/termdown); now, it is a terminal pomodoro which will use trehn/termdown. Hence, README, and other changes are necessary."
125964,139974,https://api.github.com/repos/jabardigitalservice/pikobar-pelaporan-backend/issues/1012,bug,2021-05-20T08:02:26Z,COLLABORATOR,https://api.github.com/repos/jabardigitalservice/pikobar-pelaporan-backend,Bug Data List Kasus ### Deskripsi **How to Reproduce Bug** 1. Mengakses server staging dinkes/faskes 2. Masuk pada menu list kasus **Actual Result:** Data pada list kasus tidak muncul (hanya loading saja) **Expected Result:**: Data list kasus muncul sesuai dengan yang telah diinputkan user **Lampiran** ![image](https://user-images.githubusercontent.com/63390998/118942499-fad0c000-b97c-11eb-826e-a0c186be1bb5.png) 
140775,156465,https://api.github.com/repos/asyncapi/generator-model-sdk/issues/97,enhancement,2021-02-23T12:29:49Z,NONE,https://api.github.com/repos/asyncapi/generator-model-sdk,"Add support for JSON Schema files as input #### Reason/Context Considering that we are potentially gonna have parsers written in other languages (not just JS. E.g. https://github.com/asyncapi/parser-go), It makes sense to support an input type that can be used to load schemas generated by any of those. This will allow using any convenient parser, no matters the language they are implemented on. This feature request was motivated by this [PR review comment](https://github.com/asyncapi/generator-model-sdk/pull/87#discussion_r580941224). #### Description Ideally, the parsers should be able to generate JSON Schema files so they can be used later by this generator. "
218108,242535,https://api.github.com/repos/ManageIQ/manageiq-api/issues/982,enhancement,2021-01-14T12:42:11Z,MEMBER,https://api.github.com/repos/ManageIQ/manageiq-api,"Retrieving a list of available rbac tenant quotas When retrieving the list of tenant quotas for a given tenant, the UI calls the [`Tenant#get_quotas`](https://github.com/ManageIQ/manageiq/blob/master/app/models/tenant.rb#L137-L141) method which merges together the assigned quotas with all the other quotas that can be possibly assigned. When requesting quotas for a given tenant via the API, I can only access the assigned oned, but not the possibilities. I am thinking about an `OPTIONS` request similarly to how we did it with the [snapshots](https://github.com/ManageIQ/manageiq-api/pull/943) but here we don't have a mixin, but the tenant quotas have a separate controller, while behaving as a subcollection. @abellotti I think I need your help on how to tackle this Parent issue: https://github.com/ManageIQ/manageiq-ui-classic/issues/6866"
572090,635767,https://api.github.com/repos/iamolegga/nestjs-pino/issues/424,question,2021-02-08T21:40:23Z,NONE,https://api.github.com/repos/iamolegga/nestjs-pino,"[QUESTION] Does the configuration of pino-http also configure pino? Hello, I'm using the syntax shown in https://github.com/iamolegga/nestjs-pino#asynchronous-configuration ```javascript @Module({ imports: [ LoggerModule.forRootAsync({ imports: [ConfigModule], inject: [ConfigService], useFactory: async (config: ConfigService) => { return { pinoHttp: { level: config.level, prettyPrint: true }, }; } }) ], ... }) class TestModule {} ``` I get this kind of logs: ``` {""level"":40,""time"":1612819694266,""pid"":37211,""hostname"":""..."",""context"":""..Service"",""msg"":""a message""} [1612819713135] INFO (my-app/37211 on truc): request completed res: { ""statusCode"": 201, ""headers"": { ""x-powered-by"": ""Express"", ""access-control-allow-origin"": ""*"", ""content-type"": ""application/vnd.api+json; charset=utf-8"", ""content-length"": ""91"", ""etag"": ""W/\""5b-otKW0l0jfPtZ563iVaysTjm6m5s\"""" } } responseTime: 12 ... ``` Some of them are pretty-printed, some others aren't. I also tried to force pino configuration: ```javascript ... useFactory: async (config: ConfigService) => { return { pinoHttp: { logger: pino({ level: config.level, prettyPrint: true }, level: config.level, prettyPrint: true }, } }) ], ... }) class TestModule {} ``` But no change. How to get the same configuration for all logs? - pino@6.11.0 - pino-http@5.5.0 - nestjs-pino@1.3.0 Thank you"
140808,156500,https://api.github.com/repos/nonlinear-labs-dev/C15/issues/2452,bug,2021-02-04T10:02:20Z,MEMBER,https://api.github.com/repos/nonlinear-labs-dev/C15,"Sound-Screen: Softbuttons reagieren oft erst beim zweiten Drücken Sound-Screen öffnen und mit dem ""Part..""-Softbutton in den Part-Parameter-Screen gehen, mit dem ""Sound""-Button zurück auf den Sound-Screen, nun muss man zweimal auf den ""Master""-Softbutton drücken, um in den Master-Parameter-Screen zu kommen. Danach zurück in den Soundscreen, nun muss man zweimal den ""Part...""-Softbutton drücken, um in den Part-Parameter-Screen zu kommen."
458108,509132,https://api.github.com/repos/FruityRazer/FruityUI/issues/7,enhancement,2020-06-09T16:54:54Z,MEMBER,https://api.github.com/repos/FruityRazer/FruityUI,Auto-Update Support Integrate Sparkle (or similar) for auto-update support.
665667,739882,https://api.github.com/repos/MarkHedleyJones/docker-bbq/issues/33,enhancement,2021-04-28T09:42:34Z,OWNER,https://api.github.com/repos/MarkHedleyJones/docker-bbq,Disable caching used by pip Can use the `--no-cache-dir` option for this
155089,172422,https://api.github.com/repos/Concordia-Modding-Community/discochat/issues/4,bug,2021-02-10T00:32:50Z,NONE,https://api.github.com/repos/Concordia-Modding-Community/discochat,/verify command crashes server because Java 8 does not support java.util.Optional.isEmpty() Crash report: [crash-2021-02-09_18.24.19-server.txt](https://github.com/Concordia-Modding-Community/discochat/files/5955042/crash-2021-02-09_18.24.19-server.txt) CommandVerify line 29 tries to call isEmpty() on an Optional. Java 11 has isEmpty() method but Java 8 doesn't seem to: https://docs.oracle.com/javase/8/docs/api/java/util/Optional.html We're probably stuck with Java 8 because that's what the clients use and that's what most modders are (probably) compiling against. I think we just need to logically invert the check to use isPresent() instead. 
101329,112602,https://api.github.com/repos/cli/cli/issues/3014,bug,2021-02-22T21:09:38Z,NONE,https://api.github.com/repos/cli/cli,"gh auth login fails from 1.6.0 to GHE < 3 ### Describe the bug gh auth login fails with an auth required error when trying to add a new auth to a GHE instance of version < 3.0.0 ``` gh version 1.6.0 (2021-02-17) https://github.com/cli/cli/releases/tag/v1.6.0 ``` ### Steps to reproduce the behavior 1. gh auth login 2. enter enterprise domain 3. choose to authenticate or not makes no difference 4. choose https or ssh makes no difference 5. choose paste token 6. Paste a valid token (that can be used from gh 1.2.0 and I think 1.5) 6. hit enter and fails ### Expected vs actual behavior gh auth should just work without errors, or at least have a compatibility table on the README ### Logs If you really need this, i'll reproduce again, I had cleared the terminal "
530350,589476,https://api.github.com/repos/zephyrproject-rtos/zephyr/issues/34772,bug,2021-05-03T13:53:28Z,COLLABORATOR,https://api.github.com/repos/zephyrproject-rtos/zephyr,"Mixed usage of signed/unsigned integer by the logging subsystem **Describe the bug** If `-Wextra` is enabled on an application using the logging subsystem a few compilers warnings related to signed/unsigned comparisons are reported **To Reproduce** Steps to reproduce the behavior: 1. Take any application that makes uses of the logging subsystem, e.g. `LOG_ERR(...)`. 2. Enable `-Wextra`, `target_compile_options(app PRIVATE -Wextra)` 3. Observe reported warnings **Expected behavior** I expect that logging subsystem makes consistent usage of signed/unsigned integers **Impact** `-Wextra` may be useful in applications that want to enforce stricter rules (e.g. MISRA) **Logs and console output** ``` zephyr/include/logging/log_msg2.h:297:39: warning: operand of ?: changes signedness from 'int' to 'unsigned int' due to unsignedness of other operand [-Wsign-compare] 297 | CBPRINTF_STATIC_PACKAGE(_msg->data, _plen, _plen, \ zephyr/include/sys/cbprintf_internal.h:230:19: warning: comparison of integer expressions of different signedness: 'int' and 'size_t' {aka 'unsigned int'} [-Wsign-compare] 230 | if (_buf && _idx < _max) { \ zephyr/include/sys/cbprintf_internal.h:320:22: warning: comparison of integer expressions of different signedness: 'int' and 'size_t' {aka 'unsigned int'} [-Wsign-compare] 320 | _outlen = (_pkg_len > _pmax) ? -ENOSPC : _pkg_len; \ ``` **Environment (please complete the following information):** - OS: Linux - Toolchain Zephyr SDK 0.12.4 - Commit SHA or Version used 5d2909654fb572bc059bfc530a669d086797fe6a **Additional context** Add any other context about the problem here. "
652706,725554,https://api.github.com/repos/swapnilsparsh/Rescue/issues/159,enhancement,2021-03-16T09:25:04Z,COLLABORATOR,https://api.github.com/repos/swapnilsparsh/Rescue,"Improve the format of email message Deliverable - - [ ] On clicking the `EMERGENCY!` button, the mail is sent to the saved contacts. Modify the format and design of the message sent through the mail. "
35064,39096,https://api.github.com/repos/MelvorIdle/melvoridle.github.io/issues/596,bug,2020-12-28T18:50:15Z,NONE,https://api.github.com/repos/MelvorIdle/melvoridle.github.io,"Idle Fish Cooking I play Melvor on my phone, so with the mobile app, the bug isn’t an error code just a minor inconvenience, when I go to cook food then proceed to go idle/off the app, then come back later it says 0 “whatever food” has been cooked, it’ll say I have been gone for 0 minutes this preventing me from getting event items like presents in the current event and all my food from being cooked. ![8F55FC33-68FB-4D47-BA37-15CD9ED22258](https://user-images.githubusercontent.com/76703481/103236634-f8f15c00-490a-11eb-93c5-17b33c688876.png) I hope this helps with the progression of the game and hopefully gets fixed sometime, the game itself is enjoyable so good luck Devs. -Friendly User"
541587,601956,https://api.github.com/repos/JasonBock/WebAssembly.Generators/issues/4,enhancement,2021-05-03T15:23:15Z,OWNER,https://api.github.com/repos/JasonBock/WebAssembly.Generators,"Generate a `Create()` Static Factory Method Instead of just providing a generated type to call methods on the .wasm module, which forces the developer to do something like this: ``` var collatz = Compile.FromBinary<CollatzTest>(""collatz.wasm""); var result = collatz(new ImportDictionary()).Exports.collatz(3); ``` The developer could do this: ``` var collatz = CollatzTest.Create(); var result = collatz.collatz(3); ``` The source generator would do something like this: ``` public static CollatzTest Create(string path = ""collatz.wasm"") => Compile.FromBinary<CollatzTest>(path)(new ImportDictionary()).Exports; ``` Since the developer has to specify the .wasm source file as an `AdditionalFile`, the SG should be able to provide the `path` with a default value. The developer can choose to provide a different one if needed. If there are imports, consider generating a interface with default implementations that a user can implement to handle callbacks. ``` public interface ICollatzCallbacks { void collatzCallback(int a0) { } } ``` Naming convention would be `$""I{ClassName}Callbacks""`. `Create()` would then be gen'd to do this: ``` public static CollatzTest Create(ICollatzCallbacks callbacks, string path = ""collatz.wasm"") => Compile.FromBinary<CollatzTest>(path)(new ImportDictionary { { ""imports"", ""collatzCallback"", new FunctionImport(new Action<int>(value => callbacks.collatzCallback(value))) } }).Exports; ``` Note that the developer isn't forced to use `Create()` - it's just a convenience method that should handle the majority of use cases."
301674,335417,https://api.github.com/repos/mhmerrill/arkouda/issues/762,bug,2021-04-15T17:06:02Z,COLLABORATOR,https://api.github.com/repos/mhmerrill/arkouda,"Off-by-one error in Strings.peel The inner for loops in the following code should iterate over `0..#(len-1)`, not `0..#len`: https://github.com/mhmerrill/arkouda/blob/5c4d04a15ca6fb150223a789bc43a70e393ac34c/src/SegmentedArray.chpl#L619-L630 Background: the `peel` function splits strings into left and right portions based on a delimiter. After the logic of finding the split point is all complete, this code copies the bytes of the left and right portions into their respective destination arrays. The `leftLengths` and `rightLengths` arrays are supplying the full lengths of the destination buffers, *including the null byte*, i.e. one greater than the actual length of the substring to be copied. Thus, when the code copies `#len` bytes from the source buffer, it is grabbing an extra byte from the source string and overwriting the destination's null terminator with it. This results in strings that are not null-terminated and misbehave in weird and hard-to-find ways. As part of this issue, we should consider adding validation on the `ak.Strings` class that checks for null terminators, and/or a CI test that checks for null-terminators after a `peel` operation. I am hopeful that resolving this issue will also address the sporadic CI failures for peel/stick and allow us to move this from experimental to fully supported functionality."
77780,86483,https://api.github.com/repos/Regalis11/Barotrauma/issues/4380,bug,2020-11-24T14:18:05Z,NONE,https://api.github.com/repos/Regalis11/Barotrauma,"Bots are unable to replace incompatible items in slots in favour of compatible items **Description** They are unable to replace incompatible items with compatible items. Examples : 1. Unable to swap the oxygen tank in welding tool in favour of welding fuel. 2. Unable to swap the welding fuel in diving suits in favour of oxygen tanks. (as for this they also tend to wear said suit and die due to being unable to swap welding fuel with oxygen. **Steps To Reproduce** - Use setup provided - Load into sub editor test mode - Place Mechanic's tool belt in the trash railgun shell and fire it (to get rid of tools with compatible items) - Flood room with Engineer in it, to replicate for 2. and observe - Order Mechanic to ""Fix Leaks"" - To then test for 1. either use the provided plasma cutter to create small leaks or create large leaks with the button labeled ""Breach Wall"" **Setup** [AIswitchTest.zip](https://github.com/Regalis11/Barotrauma/files/5590406/AIswitchTest.zip) **Version :** [0.11.0.8] (unstable) "
12787,14253,https://api.github.com/repos/sdttttt/vscode-bangumi/issues/187,bug,2021-04-02T00:56:56Z,OWNER,https://api.github.com/repos/sdttttt/vscode-bangumi,[BUG] 状态栏意外消失 2021.4..2 发现还是由于某时段空番剧引起的问题.
66405,73834,https://api.github.com/repos/HydraCG/Specifications/issues/16,enhancement,2013-11-22T15:03:19Z,MEMBER,https://api.github.com/repos/HydraCG/Specifications,"Introduce something like hydra:memberTemplate **This was proposed by @rubenverborgh [on the mailing list](http://lists.w3.org/Archives/Public/public-hydra/2013Nov/0037.html):** > Well, same thing in principle > > `:membersHaveTemplate a hydra:TemplatedLink .` > > Of course Hydra can't know what :membersHaveTemplate really _means_ Well, that's exactly what I propose. This precise link is going to be so common that I think we want it in Hydra itself. Perhaps `memberTemplate` is a better name. (Note: I'm unsure on how to use the `hydra:members` predicate, I might be doing it wrong.) Example of what I'd like: ``` </users> hydra:members </users/alfred>. </users> hydra:members </users/bernard>. </users> hydra:members </users/corey>. </users> hydra:membersTemplate [ a hydra:IriTemplate; hydra:template ""/users/{userid}"" ]. ``` The semantics of the `hydra:membersTemplate` property would be: ""members can be dereferenced by using the following template"". (Not: ""members need to have this template"".) Would such a property fit in the Hydra core vocabulary? "
596865,663309,https://api.github.com/repos/dstults/teachersFirst/issues/28,bug,2021-04-19T06:52:33Z,OWNER,https://api.github.com/repos/dstults/teachersFirst,Services page lacks input validation Required in case connection to database browns out or when there are zero services.
63908,71057,https://api.github.com/repos/thoth-station/graph-refresh-job/issues/563,bug,2021-01-27T06:00:14Z,MEMBER,https://api.github.com/repos/thoth-station/graph-refresh-job,"module not found issue w.r.t typing_extensions package **Describe the bug** The `typing_extension` package was not installed in the v0.3.1 graph-refresh properly. ``` Traceback (most recent call last): File ""producer.py"", line 37, in <module> from thoth.storages import __version__ as __storage__version__ File ""/opt/app-root/lib64/python3.8/site-packages/thoth/storages/__init__.py"", line 30, in <module> from .graph import GraphDatabase File ""/opt/app-root/lib64/python3.8/site-packages/thoth/storages/graph/__init__.py"", line 21, in <module> from .postgres import GraphDatabase File ""/opt/app-root/lib64/python3.8/site-packages/thoth/storages/graph/postgres.py"", line 54, in <module> from thoth.python import PackageVersion File ""/opt/app-root/lib64/python3.8/site-packages/thoth/python/__init__.py"", line 29, in <module> from .aiosource import AIOSource, AsyncIterablePackages, AsyncIterableVersions, AsyncIterableArtifacts File ""/opt/app-root/lib64/python3.8/site-packages/thoth/python/aiosource.py"", line 26, in <module> import aiohttp File ""/opt/app-root/lib64/python3.8/site-packages/aiohttp/__init__.py"", line 6, in <module> from .client import ( File ""/opt/app-root/lib64/python3.8/site-packages/aiohttp/client.py"", line 35, in <module> from . import hdrs, http, payload File ""/opt/app-root/lib64/python3.8/site-packages/aiohttp/http.py"", line 7, in <module> from .http_parser import ( File ""/opt/app-root/lib64/python3.8/site-packages/aiohttp/http_parser.py"", line 15, in <module> from .helpers import NO_EXTENSIONS, BaseTimerContext File ""/opt/app-root/lib64/python3.8/site-packages/aiohttp/helpers.py"", line 48, in <module> from typing_extensions import Protocol ModuleNotFoundError: No module named 'typing_extensions' ``` https://github.com/thoth-station/graph-refresh-job/blob/d090fada6ba13ee212efc5729bf51bd3c45ba532/Pipfile.lock#L866 **To Reproduce** Steps to reproduce the behavior: 1. Go to test environment 2. Run the graph-refresh job 3. See error **Expected behavior** To have graph-refresh functions successfully. "
55148,61322,https://api.github.com/repos/workcraft/workcraft/issues/1199,enhancement,2021-03-12T12:31:14Z,MEMBER,https://api.github.com/repos/workcraft/workcraft,"Editable property with predefined values A control element is needed that would enable selecting a value from a predefined list (similar to JComboBox), but also would allow the user to enter arbitrary values (as in JTextField). This control is immediately useful for _Arrow length_ property (with predefined values 0.0 - none, 0.2 - short, 0.4 - medium, 0.8 - long). Other properties, such as _Line width_ and _Arrow width_, can follow the same pattern. This control would be very useful for user-defined DPI values too (see #1198)."
348335,387255,https://api.github.com/repos/Azure-Samples/digital-twins-explorer/issues/103,bug,2021-03-04T08:54:24Z,NONE,https://api.github.com/repos/Azure-Samples/digital-twins-explorer,"Cannot create Twin using UI Hi! I was trying to pass Cholocate Factory Demo using [MS tutorial](https://docs.microsoft.com/en-us/learn/modules/develop-with-azure-digital-twins/build-azure-digital-twins-graph-for-chocolate-factory/7-exercise-build-digital-twin-graph). I got error on step where I need to create Twin for models that are uploaded and visible in Digital Twins Instance. I can hit + and input name of Twin ![image](https://user-images.githubusercontent.com/34028526/109937296-cd5e6980-7cdf-11eb-85f7-b5d7de9ff9ab.png) When I click Save button I am getting error: ![image](https://user-images.githubusercontent.com/34028526/109937424-f4b53680-7cdf-11eb-8100-52f7deeade7c.png) Same error was mentioned in Stack Overflow https://stackoverflow.com/questions/66453982/adt-explorer-error-cant-put-models-into-graph-view At same time I can create Twin using [RBAC-update branch](https://github.com/Azure-Samples/digital-twins-explorer/tree/RBAC-Update), while Oct-Bash return same error as Master branch. Any ideas why this error may happen?"
510893,567795,https://api.github.com/repos/marian-nmt/marian-dev/issues/835,bug,2021-03-17T15:40:54Z,NONE,https://api.github.com/repos/marian-nmt/marian-dev,"Issue with Marian FBGEMM build for cascadelake CPU (AVX512) ### Bug description I am try to build Marian-NMT for my Intel CascadeLake CPU which supports AVX512. ```sh $ grep avx512 /proc/cpuinfo flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp ibrs_enhanced fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat avx512_vnni md_clear arch_capabilities ``` But I face the following error during `make`: ``` [ 27%] Building CXX object src/3rd_party/fbgemm/CMakeFiles/fbgemm_avx2.dir/src/QuantUtilsAvx2.cc.o /tmp/ccAtxjvY.s: Assembler messages: /tmp/ccAtxjvY.s:49401: Error: invalid use of register ... make[2]: *** [src/3rd_party/fbgemm/CMakeFiles/fbgemm_avx2.dir/build.make:128: src/3rd_party/fbgemm/CMakeFiles/fbgemm_avx2.dir/src/QuantUtilsAvx2.cc.o] Error 1 make[1]: *** [CMakeFiles/Makefile2:1053: src/3rd_party/fbgemm/CMakeFiles/fbgemm_avx2.dir/all] Error 2 make: *** [Makefile:152: all] Error 2 ``` But I do not face this error on my Broadwell CPU which has support only till AVX2. ### How to reproduce Try on a Intel Cascade Lake CPU maybe? (not sure if the issue is because of this arch) To check if this bug is because of original FBGEMM (and not because of Marian), I tried building the latest FBGEMM from the original repo. It got built perfectly without any errors. I have installed the latest MKL libs: `intel-mkl-64bit-2020.0-088 libmkl libmkl-avx2 libmkl-avx512` ### Context * Marian version: v1.10.6 77c3e356 * CMake command: `cmake .. -DUSE_SENTENCEPIECE=on -DCOMPILE_CPU=on -DCOMPILE_SERVER=on -DCOMPILE_CUDA=off -DBUILD_ARCH=cascadelake -DUSE_FBGEMM=on` [cmake.log](https://github.com/marian-nmt/marian-dev/files/6157540/cmake.log) * Log file: [make.log](https://github.com/marian-nmt/marian-dev/files/6157551/make.log) I also see that the latest fb-gemm has many new optimizations (like [`QuantUtilsAvx512.cc`](https://github.com/pytorch/FBGEMM/blob/master/src/QuantUtilsAvx512.cc)) which is not yet supported in the Marian's fork as of 055d2a099"
379011,421342,https://api.github.com/repos/Electroblob77/Wizardry/issues/637,bug,2021-03-02T06:28:22Z,NONE,https://api.github.com/repos/Electroblob77/Wizardry,could not place the Receptacle on the Imbuement Altar Minecraft version: 1.12.2 Wizardry version: 4.3.4 Environment: Singleplayer and Server Issue details: the Receptacle cannot place to the each side of imbuement altar [https://media.giphy.com/media/5RtVXfHHqfeo2Wjf1L/giphy.gif](url)
658020,731421,https://api.github.com/repos/Pryx/git-md-diff/issues/47,enhancement,2021-03-17T20:27:47Z,OWNER,https://api.github.com/repos/Pryx/git-md-diff,"[FEATURE] Allow adding existing repositories Adding existing repositories seems like a useful feature, we should find out what we need to implement this."
240157,267124,https://api.github.com/repos/mihaeu/dephpend/issues/6,enhancement,2016-06-29T14:37:38Z,OWNER,https://api.github.com/repos/mihaeu/dephpend,Track variables defined in the current scope ... 
59156,65780,https://api.github.com/repos/biosimulators/Biosimulators_test_suite/issues/28,question,2021-02-21T18:09:24Z,MEMBER,https://api.github.com/repos/biosimulators/Biosimulators_test_suite,"Test suite documentation Hello @jonrkarr, Is there any kind of doc related to biosimulators_test_suite which can tell which test is shown in GH action logs checks for exactly what thing? Because it's not very much intuitive from the Test names themselves. I tried looking into code for few minutes, but to map out the complete functioning of the code, I'd have to spend a lot of time because of the high level of inheritance among the classes, which would be even more for all the tests cases. It'll help a great deal if we have a written test that checks for what (possibly with examples)."
695956,773518,https://api.github.com/repos/ChildMindInstitute/mindlogger-admin/issues/992,bug,2021-05-12T14:29:18Z,NONE,https://api.github.com/repos/ChildMindInstitute/mindlogger-admin,"Activities/items are not transferred to the applet builder **Steps to reproduce:** 1. Open the site https://library-staging.mindlogger.org/ 2. Choose any applet and navigate to the applet details page 3. Click the ""Add to basket"" button 4. Mark one activity 5. Add to basket this activity 6. Go to the basket 7. Click the ""ADD TO APPLET BUILDER"" button and log in 8. Select the account and click 'Add'> Add to existing applet 9. Choose the applet and click 'Add' 10. Look at the result **Actual result:** Activities/items are not transferred to the builder **Video:** https://www.screencast.com/t/nzyjI0xz4U **Expected result:** Activities/items are transferred to the builder **Environment:** https://library-staging.mindlogger.org/ (Win 10 // Chrome Version 90.0.4430.212) https://admin-staging.mindlogger.org/ (Win 10 // Chrome Version 90.0.4430.212)"
399559,444092,https://api.github.com/repos/mpi2/PhenotypeData/issues/513,bug,2021-01-21T10:16:59Z,CONTRIBUTOR,https://api.github.com/repos/mpi2/PhenotypeData,Histopath landing page isn't showing any significant hits The landing page: https://www.mousephenotype.org/data/landing_pages/histopath ![image.png](https://images.zenhubusercontent.com/5e26d9c19aca8856dc57b8c7/fb7bed4e-23ea-471f-baad-e1ca9cebdad7) Is not showing any significant hits. I would expect that some of the data to be significant -- specifically the Gene Lyst should have a significant histopath hit for Eye with Optic nerve https://www.mousephenotype.org/data/genes/MGI:107448 ![image.png](https://images.zenhubusercontent.com/5e26d9c19aca8856dc57b8c7/64ee6f9a-e9c4-4de2-b556-edd8822056a0) 
190673,212049,https://api.github.com/repos/fluxcd/image-automation-controller/issues/86,question,2021-01-13T16:15:32Z,NONE,https://api.github.com/repos/fluxcd/image-automation-controller,"Errors from ImageUpdateAutomation are not triggering a Discord alert I was fiddling with image automation a bit, and I managed to hit this error: `{""level"":""error"",""ts"":""2021-01-13T15:57:20.289Z"",""logger"":""controller"",""msg"":""Reconciler error"",""reconcilerGroup"":""image.toolkit.fluxcd.io"",""reconcilerKind"":""ImageUpdateAutomation"",""controller"":""imageupdateautomation"",""name"":""flux-system"",""namespace"":""flux-system"",""error"":""unknown error: ERROR: The key you are authenticating with has been marked as read only.""}` Which totally makes sense, as the GitHub key I use is set to read-only. What I did notice how-ever, is that this error is not shown to me on Discord, with an unmodified flux2 setup via Kustomize (configured to display errors on Discord). I would have expected this error to end up there, as most other errors flux2 generates does. When I looked further into this, I noticed that `eventSources` of `Alert` did not read `ImageUpdateAutomation` yet, but .. this is also not supported (yet?)."
449288,499354,https://api.github.com/repos/johndbritton/teleport/issues/87,bug,2021-01-05T16:31:01Z,NONE,https://api.github.com/repos/johndbritton/teleport,1.3.2 from home-brew is corrupted # Bug report <!-- Please fill these sections with the relevant information: --> ## What you were trying to do (and why) Installed the update out of homebrew and both my intel and my arm mac mentioned it was corrupted and should be moved to bin. 1.3.1 works perfectly. 
696306,773902,https://api.github.com/repos/OT-CONTAINER-KIT/redis-operator/issues/79,bug,2021-05-24T02:46:47Z,NONE,https://api.github.com/repos/OT-CONTAINER-KIT/redis-operator,"There are problems with NodePort I successfully ran the Redis cluster according to the content in the document, I could get through Podip :6379, but I could not get through SVCIP :6379 "
386530,429676,https://api.github.com/repos/okta/okta-oidc-ios/issues/264,question,2020-12-10T18:03:48Z,NONE,https://api.github.com/repos/okta/okta-oidc-ios,"is it using SafarWebViewController or WKWebview for showing Okta login page? Can someone please tell which methodology it is using? Whether it is using SafarWebViewController or WKWebview? ``` oktaOidc.signInWithBrowser(from: viewController) { stateManager, error in if let error = error { // Error return } ``` "
224409,249563,https://api.github.com/repos/AccelerateNetworks/NumberSearch/issues/169,bug,2021-03-14T22:20:56Z,COLLABORATOR,https://api.github.com/repos/AccelerateNetworks/NumberSearch,"Hardware page has become unorganized **Describe the bug** When the Hardware page was converted from a static list of hardware we sold to a dynamic list of hardware that we could manage through the Ops app (without making a PR or editing the repository on Github) the layout of phones on our hardware page was lost. **To Reproduce** Steps to reproduce the behavior: 1. Go to https://acceleratenetworks.com/hardware 2. Note how it is not pitching clients on our preferred devices first **Expected behavior** Prior to this change the page highlighted the GRP2615 (left), GRP2613 (middle) and GRP2612 (right) on its first row of hardware on desktop/tablet. Scott and I have discussed that we would like this to show the GRP2615 (left), DP722 (middle) and GRP2612W (right) but have no way to configure this. Provide some way to control the layout of items on this page. If we could set a numeric order (eg: This is item 1 (it will appear first on mobile, and upper left on a computer/tablet)) that would be ideal. **Screenshots** ![Screenshot from 2021-03-14 15-18-40](https://user-images.githubusercontent.com/1683673/111086347-dd90f880-84d8-11eb-8b96-84215904afdb.png) "
22210,24716,https://api.github.com/repos/tailwindlabs/tailwindui-issues/issues/452,bug,2021-01-23T14:54:30Z,NONE,https://api.github.com/repos/tailwindlabs/tailwindui-issues,"stats - simple with card, redundant max width? **What component (if applicable)** - URL for category: - Component name: stats - simple with card **Describe the bug** ``` <div class=""max-w-7xl mx-auto px-4 sm:px-6 lg:px-8""> <div class=""max-w-4xl mx-auto text-center""> ``` The first max-w-7xl mx-auto appears to do nothing given the max-w-4xl below. I am new to css, so feel free to close without explanation if there is an obvious reason why the max-w-7xl exists "
505353,561675,https://api.github.com/repos/MichealJWEllis/portfolio-generator/issues/1,enhancement,2021-04-05T16:17:26Z,OWNER,https://api.github.com/repos/MichealJWEllis/portfolio-generator,Capture user input **Description** - Capture user input with command-line arguments
152852,169936,https://api.github.com/repos/EcoJulia/SimpleSDMLayers.jl/issues/59,enhancement,2021-02-26T22:58:49Z,COLLABORATOR,https://api.github.com/repos/EcoJulia/SimpleSDMLayers.jl,"Convert layers+occurrence to features/labels Hi folks, I had a few feature ideas that have come up when using the package, happy to help implement any/all of them if they seem good. A feature I needed was to convert a set of layers and GBIF occupancy points to a set of features (a matrix of environmental variables at each point in the layer) with corresponding labels (0 for points in the layer without occurrence, 1 at each point with occurrence). It seems like this feature could have widespread utility for using this with `Turing` (as I did) or `Flux`. My (crude) example code below --- apologies if this already exists in some form ``` function features(environment, occurrence) xDim, yDim = size(environment[1]) numberSpatialPoints = xDim*yDim numFeatures = length(environment) featuresMatrix = zeros(numberSpatialPoints, numFeatures) labels = [false for i in 1:numberSpatialPoints] occupancyLayer = getOccupancyLayer(environment[1], occurrence) cursor = 1 for pt in 1:numberSpatialPoints if (!isnothing(environment[1][pt] )) for f in 1:numFeatures featuresMatrix[cursor, f] = environment[f][pt] labels[cursor] = occupancyLayer[pt] end cursor += 1 end end return (featuresMatrix[1:cursor, :], labels[1:cursor]) end ``` "
181010,201242,https://api.github.com/repos/python-restx/flask-restx/issues/272,question,2021-01-04T16:26:19Z,NONE,https://api.github.com/repos/python-restx/flask-restx,"Remove default HTTP 200 response code in doc **Ask a question** Hi, I was wondering if it's possible to remove the default ""200 - Success"" response in the swagger.json? My model: ``` user_model = api.model( ""User"", { ""user_id"": fields.String, ""project_id"": fields.Integer(default=1), ""reward_points"": fields.Integer(default=0), ""rank"": fields.String, }, ) ``` The route: ``` @api.route(""/"") class UserRouteList(Resource): @api.doc(model=user_model, body=user_model) @api.response(201, ""User created"", user_model) @api.marshal_with(user_model, code=201) def post(self): """"""Add user"""""" data = api.payload return ( userDB.add(data), 201 ) ``` **Additional context** flask-restx version: 0.2.0 ![image](https://user-images.githubusercontent.com/34584653/103555872-3593f900-4eb1-11eb-8d29-16f1629489ab.png) "
155418,172791,https://api.github.com/repos/graphchecker/moodle-qtype_graphchecker/issues/109,bug,2021-02-12T17:23:56Z,CONTRIBUTOR,https://api.github.com/repos/graphchecker/moodle-qtype_graphchecker,"Can't see Python stacktraces in some cases In GitLab by @Willem3141 on Aug 13, 2020, 17:19 We had an issue where Jobe wasn't installed on the server. It used to be that this would show the stacktrace, but now it only shows the ""invalid"" message with an empty ""Details"" section. Probably because of e3b5f667bfa094a97d5159397caf2c58aecfcf7b? To do: reproduce this and make sure this shows a stacktrace."
218111,242538,https://api.github.com/repos/IBM/carbon-components-angular/issues/1568,bug,2020-10-14T07:42:17Z,CONTRIBUTOR,https://api.github.com/repos/IBM/carbon-components-angular,"feat: Ability to hide the calendar icon in the datepicker input field component ## Description The ability to hide the calendar icon in the datepicker input field component ## Detailed description When using the date picker input field component I want to use the component as a `Simple date input` type. In the carbon documentation, can be [seen](https://www.carbondesignsystem.com/components/date-picker/usage/) that the Simple date input does not have the calendar icon on the right side of the input field. ![Screenshot 2020-10-14 at 09 23 46](https://user-images.githubusercontent.com/28896196/95956707-f8165700-0dfe-11eb-87e1-261e354180a9.png) With the current API's I am not able to remove the calendar icon from the component. _Is this a feature request (new component, new icon), a bug, or a general issue?_ Feature request _Is this issue related to a specific component?_ DatePickerInputComponent _What did you expect to happen? What happened instead? What would you like to see changed?_ Ability to remove the calendar icon from the date picker input field _What version of the Carbon Design System are you using?_ carbon-component: 10.21.0 carbon-components-angular: 4.19.1"
383034,425791,https://api.github.com/repos/CaffeineMC/sodium-fabric/issues/603,bug,2021-03-24T01:17:41Z,NONE,https://api.github.com/repos/CaffeineMC/sodium-fabric,Invisible Kibe items ### Expected Behavior No item should be invisible in the inventory. ### Actual Behavior Some of the items from Kibe are completely invisible in the inventory. _The blocks are visible when placed._ ### Reproduction Steps 1. Install Sodium (with [Immersive Portals compatibility](https://github.com/qouteall/sodium-fabric/releases/tag/ipc1165_2)) with [Indium](https://github.com/comp500/Indium/actions/runs/658347188) 2. Install [Kibe](https://www.curseforge.com/minecraft/mc-mods/kibe/files/3247476) 3. Search for `Entangled` in the creative menu. The `Entangled Bag` and `Entangled Chest` are invisible (so are the `Drawbridge` and `Tank`). ### Attachments ![image](https://user-images.githubusercontent.com/25808801/112239186-65cf7600-8c1c-11eb-885a-2533fde4677e.png) ### System Information - Java Version: Version 8 Update 281 - CPU: AMD Ryzen 5 3600 6-Core 3.6GHz - GPU: MSI GeForce GTX™ 1660 SUPER Ventus XS 6G OC
560697,623130,https://api.github.com/repos/Drunken-Developer-On-Space/docker-files/issues/1,enhancement,2021-01-24T07:56:25Z,CONTRIBUTOR,https://api.github.com/repos/Drunken-Developer-On-Space/docker-files,Nginx 만들기 Nginx 만들기 빰빠바바밥빰
152406,169444,https://api.github.com/repos/tabspacesoft/kotlin-spring-service-base/issues/1,enhancement,2021-01-27T11:58:51Z,COLLABORATOR,https://api.github.com/repos/tabspacesoft/kotlin-spring-service-base,Implement IoC depedency injection on services Requirement: - a controller must inject the service before using it
439352,488454,https://api.github.com/repos/wiverson/maven-jpackage-template/issues/12,enhancement,2021-03-14T20:59:25Z,OWNER,https://api.github.com/repos/wiverson/maven-jpackage-template,Add Windows Launch On Install Example Integrate the Windows installer enhancement to add launch on completion. https://gist.github.com/wiverson/45bbd58d928b4735ad141163579c4201
