,Unnamed: 0.1,Unnamed: 0,issue_url,issue_label,issue_created_at,issue_author_association,repository_url,issue_title,issue_body,text
115477,115477,128331,https://api.github.com/repos/luc-github/Repetier-Firmware-4-Davinci/issues/375,2.0,2021-04-07T08:18:54Z,NONE,https://api.github.com/repos/luc-github/Repetier-Firmware-4-Davinci,[Question] Verification fails at 69%,"I uploaded this firmware properly to my printer a few times before but when I tried to update it now it just gets stuck at verification at 69%
",[Question] Verification fails at 69% I uploaded this firmware properly to my printer a few times before but when I tried to update it now it just gets stuck at verification at 69% 
186880,186880,207817,https://api.github.com/repos/primefaces/primeng/issues/9823,1.0,2021-01-26T13:33:49Z,MEMBER,https://api.github.com/repos/primefaces/primeng,Add rowIndex to onRowUnselect,,Add rowIndex to onRowUnselect 
431133,431133,479284,https://api.github.com/repos/EOussama/anusic-api/issues/48,1.0,2021-01-29T12:04:32Z,OWNER,https://api.github.com/repos/EOussama/anusic-api,PWA configuration,Transform the app into a PWA.,PWA configuration Transform the app into a PWA.
239374,239374,266263,https://api.github.com/repos/nextcloud/server/issues/27132,0.0,2021-05-27T07:39:30Z,NONE,https://api.github.com/repos/nextcloud/server,Encryption-Migration fails when encryption.key_storage_migrated is set to false in config,"### Steps to reproduce
run command ""php occ encryption:migrate-key-storage-format"" with old files from nextcloud-versions before v20 and owncloud v7 (files back to 2015)

### Expected behaviour
All fileKey-files should be tested if they can be decrypted. If not (means if an exception occures) the fileKey-file should be base64-encoded, encrypted and stored back to the storage.

### Actual behaviour
If the option ""encryption.key_storage_migrated"" is set to false the decryption will success all the time, because the decryption-function will use a fallback which base64-encodes the file and throws no error. See:
https://github.com/nextcloud/server/blob/6b0859f28e2569e467490755f900e64024a0ca9d/lib/private/Encryption/Keys/Storage.php#L316

See the following line: it should throw an exception and migrates the file, but if no exception is thrown, no migration is performed.
https://github.com/nextcloud/server/blob/6b0859f28e2569e467490755f900e64024a0ca9d/core/Command/Encryption/MigrateKeyStorage.php#L187

After the ""migration"" is done the option ""encryption.key_storage_migrated"" is removed and the old files are not accessible any more, because the decryption-function throws a ""ServerNotAvailable"" function and the log is filled with ""Could not decrypt key"" because the fallback-option is not used any more.


### Server configuration

**Operating system:** Ubuntu

**Web server:** Apache2

**Database:** MariaDB

**PHP version:** 7.4

**Nextcloud version:** 21.0.1

**Updated from an older Nextcloud/ownCloud or fresh install:** Updated from Nextcloud 20, first installation was OwnCloud 6

**Where did you install Nextcloud from:** nextcloud.com

**List of activated apps:**
<details>
<summary>App list</summary>

```
Enabled:
  - accessibility: 1.7.0
  - activity: 2.14.3
  - admin_audit: 1.11.0
  - audioplayer: 3.1.0
  - bookmarks: 4.2.1
  - calendar: 2.2.1
  - cloud_federation_api: 1.4.0
  - comments: 1.11.0
  - contacts: 3.5.1
  - contactsinteraction: 1.2.0
  - dashboard: 7.1.0
  - dav: 1.17.1
  - deck: 1.4.2
  - encryption: 2.9.0
  - federatedfilesharing: 1.11.0
  - federation: 1.11.0
  - files: 1.16.0
  - files_external: 1.12.0
  - files_mindmap: 0.0.24
  - files_pdfviewer: 2.1.0
  - files_rightclick: 1.0.0
  - files_sharing: 1.13.1
  - files_trashbin: 1.11.0
  - files_versions: 1.14.0
  - files_videoplayer: 1.10.0
  - firstrunwizard: 2.10.0
  - gpxpod: 4.2.8
  - impersonate: 1.8.0
  - keeweb: 0.6.5
  - logreader: 2.6.0
  - lookup_server_connector: 1.9.0
  - mail: 1.9.5
  - news: 15.4.4
  - nextcloud_announcements: 1.10.0
  - notifications: 2.9.0
  - oauth2: 1.9.0
  - password_policy: 1.11.0
  - phonetrack: 0.6.7
  - photos: 1.3.0
  - polls: 1.8.3
  - privacy: 1.5.0
  - provisioning_api: 1.11.0
  - quota_warning: 1.10.0
  - serverinfo: 1.11.0
  - settings: 1.3.0
  - sharebymail: 1.11.0
  - support: 1.4.0
  - survey_client: 1.9.0
  - systemtags: 1.11.0
  - tasks: 0.13.6
  - text: 3.2.0
  - theming: 1.12.0
  - twofactor_backupcodes: 1.10.0
  - twofactor_totp: 6.0.0
  - twofactor_webauthn: 0.2.9
  - updatenotification: 1.11.0
  - user_status: 1.1.1
  - viewer: 1.5.0
  - weather_status: 1.1.0
  - workflowengine: 2.3.0
Disabled:
  - recommendations
  - user_ldap
```
</details>

**Nextcloud configuration:**
<details>
<summary>Config report</summary>

```
{
    ""system"": {
        ""instanceid"": ""***REMOVED SENSITIVE VALUE***"",
        ""passwordsalt"": ""***REMOVED SENSITIVE VALUE***"",
        ""trusted_domains"": [
            ""cloud.noeding-online.de"",
            ""cloud.xn--nding-jua.de""
        ],
        ""datadirectory"": ""***REMOVED SENSITIVE VALUE***"",
        ""tempdirectory"": ""\/www\/htdocs\/w00bd480\/tmp"",
        ""dbtype"": ""mysql"",
        ""version"": ""21.0.1.1"",
        ""dbname"": ""***REMOVED SENSITIVE VALUE***"",
        ""dbhost"": ""***REMOVED SENSITIVE VALUE***"",
        ""dbtableprefix"": ""oc_"",
        ""dbuser"": ""***REMOVED SENSITIVE VALUE***"",
        ""dbpassword"": ""***REMOVED SENSITIVE VALUE***"",
        ""installed"": true,
        ""theme"": """",
        ""maintenance"": false,
        ""mail_from_address"": ""***REMOVED SENSITIVE VALUE***"",
        ""mail_smtpmode"": ""smtp"",
        ""mail_domain"": ""***REMOVED SENSITIVE VALUE***"",
        ""forcessl"": true,
        ""trashbin_retention_obligation"": ""30, 60"",
        ""versions_retention_obligation"": ""auto"",
        ""loglevel"": 2,
        ""log_rotate_size"": 10485760,
        ""logtimezone"": ""Europe\/Berlin"",
        ""check_for_working_webdav"": true,
        ""check_for_working_htaccess"": true,
        ""xframe_restriction"": false,
        ""secret"": ""***REMOVED SENSITIVE VALUE***"",
        ""forceSSLforSubdomains"": true,
        ""enable_previews"": true,
        ""enabledPreviewProviders"": [
            ""OC\\Preview\\PNG"",
            ""OC\\Preview\\JPEG"",
            ""OC\\Preview\\GIF"",
            ""OC\\Preview\\BMP"",
            ""OC\\Preview\\XBitmap"",
            ""OC\\Preview\\MP3"",
            ""OC\\Preview\\TXT"",
            ""OC\\Preview\\MarkDown""
        ],
        ""singleuser"": false,
        ""remember_login_cookie_lifetime"": 1296000,
        ""session_lifetime"": 86400,
        ""session_keepalive"": true,
        ""appstore.experimental.enabled"": true,
        ""filesystem_check_changes"": 0,
        ""default_language"": ""de"",
        ""updatechecker"": false,
        ""cipher"": ""AES-256-CFB"",
        ""minimum.supported.desktop.version"": ""2.2.0"",
        ""filelocking.enabled"": true,
        ""overwrite.cli.url"": ""https:\/\/cloud.noeding-online.de"",
        ""integrity.check.disabled"": true,
        ""memcache.local"": ""\\OC\\Memcache\\ArrayCache"",
        ""mail_smtpauthtype"": ""LOGIN"",
        ""mail_smtphost"": ""***REMOVED SENSITIVE VALUE***"",
        ""mail_smtpport"": ""587"",
        ""mail_smtpsecure"": ""tls"",
        ""mail_smtpauth"": 1,
        ""mysql.utf8mb4"": false,
        ""app_install_overwrite"": [
            ""sensorlogger"",
            ""tasks"",
            ""keeweb"",
            ""polls"",
            ""files_mindmap"",
            ""contacts"",
            ""twofactor_webauthn"",
            ""spreed"",
            ""calendar""
        ],
        ""onlyoffice"": {
            ""verify_peer_off"": true
        },
        ""mail_smtpname"": ""***REMOVED SENSITIVE VALUE***"",
        ""mail_smtppassword"": ""***REMOVED SENSITIVE VALUE***"",
        ""mail_sendmailmode"": ""smtp"",
        ""encryption.legacy_format_support"": true,
        ""encryption.key_storage_migrated"": false,
        ""default_phone_region"": ""DE""
    }
}
```
</details>

**Are you using external storage, if yes which one:** SMB

**Are you using encryption:** yes

**Are you using an external user-backend, if yes which one:** no


### Client configuration
**Browser:** Chrome

**Operating system:** Windows 10

### Logs

#### Nextcloud log (data/nextcloud.log)
<details>
<summary>Nextcloud log</summary>

```
{""reqId"":""YK8-I5CdpSMKbXE8k18QSwAADBI"",""level"":4,""time"":""2021-05-27T08:41:39+02:00"",""remoteAddr"":""188.74.18.135"",""user"":""Username"",""app"":""webdav"",""method"":""GET"",""url"":""/remote.php/dav/files/Username/FILENAME.PDF"",""message"":{""Exception"":""Sabre\\DAV\\Exception"",""Message"":""Could not decrypt key"",""Code"":0,""Trace"":[{""file"":""/cloud/apps/dav/lib/Connector/Sabre/File.php"",""line"":436,""function"":""convertToSabreException"",""class"":""OCA\\DAV\\Connector\\Sabre\\File"",""type"":""->"",""args"":[{""__class__"":""OC\\ServerNotAvailableException""}]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/CorePlugin.php"",""line"":85,""function"":""get"",""class"":""OCA\\DAV\\Connector\\Sabre\\File"",""type"":""->"",""args"":[]},{""file"":""/cloud/3rdparty/sabre/event/lib/WildcardEmitterTrait.php"",""line"":89,""function"":""httpGet"",""class"":""Sabre\\DAV\\CorePlugin"",""type"":""->"",""args"":[{""__class__"":""Sabre\\HTTP\\Request""},{""__class__"":""Sabre\\HTTP\\Response""}]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/Server.php"",""line"":472,""function"":""emit"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[""method:GET"",[{""__class__"":""Sabre\\HTTP\\Request""},{""__class__"":""Sabre\\HTTP\\Response""}]]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/Server.php"",""line"":253,""function"":""invokeMethod"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[{""__class__"":""Sabre\\HTTP\\Request""},{""__class__"":""Sabre\\HTTP\\Response""}]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/Server.php"",""line"":321,""function"":""start"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[]},{""file"":""/cloud/apps/dav/lib/Server.php"",""line"":332,""function"":""exec"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[]},{""file"":""/cloud/apps/dav/appinfo/v2/remote.php"",""line"":35,""function"":""exec"",""class"":""OCA\\DAV\\Server"",""type"":""->"",""args"":[]},{""file"":""/cloud/remote.php"",""line"":167,""args"":[""/cloud/apps/dav/appinfo/v2/remote.php""],""function"":""require_once""}],""File"":""/cloud/apps/dav/lib/Connector/Sabre/File.php"",""Line"":677,""Previous"":{""Exception"":""OC\\ServerNotAvailableException"",""Message"":""Could not decrypt key"",""Code"":0,""Trace"":[{""file"":""/cloud/lib/private/Encryption/Keys/Storage.php"",""line"":104,""function"":""getKey"",""class"":""OC\\Encryption\\Keys\\Storage"",""type"":""->"",""args"":[""/Username/files_encryption/keys/files/FILENAME.PDF/OC_DEFAULT_MODULE/fileKey""]},{""file"":""/cloud/apps/encryption/lib/KeyManager.php"",""line"":452,""function"":""getFileKey"",""class"":""OC\\Encryption\\Keys\\Storage"",""type"":""->"",""args"":[""/Username/files/FILENAME.PDF"",""fileKey"",""OC_DEFAULT_MODULE""]},{""file"":""/cloud/apps/encryption/lib/Crypto/Encryption.php"",""line"":202,""function"":""getFileKey"",""class"":""OCA\\Encryption\\KeyManager"",""type"":""->"",""args"":[""/Username/files/FILENAME.PDF"",""Username""]},{""file"":""/cloud/lib/private/Files/Stream/Encryption.php"",""line"":287,""function"":""begin"",""class"":""OCA\\Encryption\\Crypto\\Encryption"",""type"":""->"",""args"":[""/Username/files/FILENAME.PDF"",""Username"",""r"",{""cipher"":""AES-256-CFB"",""oc_encryption_module"":""OC_DEFAULT_MODULE""},{""users"":[""Username""],""public"":false}]},{""function"":""stream_open"",""class"":""OC\\Files\\Stream\\Encryption"",""type"":""->"",""args"":[""ocencryption://"",""r"",0,null]},{""file"":""/cloud/lib/private/Files/Stream/Encryption.php"",""line"":214,""function"":""fopen"",""args"":[""ocencryption://"",""r"",false,null]},{""file"":""/cloud/lib/private/Files/Stream/Encryption.php"",""line"":189,""function"":""wrapSource"",""class"":""OC\\Files\\Stream\\Encryption"",""type"":""::"",""args"":[null,null,""ocencryption"",""OC\\Files\\Stream\\Encryption"",""r""]},{""file"":""/cloud/lib/private/Files/Storage/Wrapper/Encryption.php"",""line"":471,""function"":""wrap"",""class"":""OC\\Files\\Stream\\Encryption"",""type"":""::"",""args"":[null,""files/FILENAME.PDF"",""/Username/files/FILENAME.PDF"",{""cipher"":""AES-256-CFB"",""oc_encryption_module"":""OC_DEFAULT_MODULE""},""Username"",{""__class__"":""OCA\\Encryption\\Crypto\\Encryption""},{""cache"":null,""scanner"":null,""watcher"":null,""propagator"":null,""updater"":null,""__class__"":""OC\\Files\\Storage\\Wrapper\\Quota""},{""cache"":null,""scanner"":null,""watcher"":null,""propagator"":null,""updater"":null,""__class__"":""OC\\Files\\Storage\\Wrapper\\Encryption""},{""__class__"":""OC\\Encryption\\Util""},{""__class__"":""OC\\Encryption\\File""},""r"",220832,159010,8192,false]},{""file"":""/cloud/lib/private/Files/Storage/Wrapper/Wrapper.php"",""line"":302,""function"":""fopen"",""class"":""OC\\Files\\Storage\\Wrapper\\Encryption"",""type"":""->"",""args"":[""files/FILENAME.PDF"",""r""]},{""file"":""/cloud/lib/private/Files/View.php"",""line"":1166,""function"":""fopen"",""class"":""OC\\Files\\Storage\\Wrapper\\Wrapper"",""type"":""->"",""args"":[""files/FILENAME.PDF"",""r""]},{""file"":""/cloud/lib/private/Files/View.php"",""line"":1002,""function"":""basicOperation"",""class"":""OC\\Files\\View"",""type"":""->"",""args"":[""fopen"",""/FILENAME.PDF"",[""read""],""r""]},{""file"":""/cloud/apps/dav/lib/Connector/Sabre/File.php"",""line"":434,""function"":""fopen"",""class"":""OC\\Files\\View"",""type"":""->"",""args"":[""FILENAME.PDF"",""r""]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/CorePlugin.php"",""line"":85,""function"":""get"",""class"":""OCA\\DAV\\Connector\\Sabre\\File"",""type"":""->"",""args"":[]},{""file"":""/cloud/3rdparty/sabre/event/lib/WildcardEmitterTrait.php"",""line"":89,""function"":""httpGet"",""class"":""Sabre\\DAV\\CorePlugin"",""type"":""->"",""args"":[{""__class__"":""Sabre\\HTTP\\Request""},{""__class__"":""Sabre\\HTTP\\Response""}]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/Server.php"",""line"":472,""function"":""emit"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[""method:GET"",[{""__class__"":""Sabre\\HTTP\\Request""},{""__class__"":""Sabre\\HTTP\\Response""}]]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/Server.php"",""line"":253,""function"":""invokeMethod"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[{""__class__"":""Sabre\\HTTP\\Request""},{""__class__"":""Sabre\\HTTP\\Response""}]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/Server.php"",""line"":321,""function"":""start"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[]},{""file"":""/cloud/apps/dav/lib/Server.php"",""line"":332,""function"":""exec"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[]},{""file"":""/cloud/apps/dav/appinfo/v2/remote.php"",""line"":35,""function"":""exec"",""class"":""OCA\\DAV\\Server"",""type"":""->"",""args"":[]},{""file"":""/cloud/remote.php"",""line"":167,""args"":[""/cloud/apps/dav/appinfo/v2/remote.php""],""function"":""require_once""}],""File"":""/cloud/lib/private/Encryption/Keys/Storage.php"",""Line"":287,""Previous"":{""Exception"":""Exception"",""Message"":""Authenticated ciphertext could not be decoded."",""Code"":0,""Trace"":[{""file"":""/cloud/lib/private/Encryption/Keys/Storage.php"",""line"":285,""function"":""decrypt"",""class"":""OC\\Security\\Crypto"",""type"":""->"",""args"":[""*** sensitive parameters replaced ***""]},{""file"":""/cloud/lib/private/Encryption/Keys/Storage.php"",""line"":104,""function"":""getKey"",""class"":""OC\\Encryption\\Keys\\Storage"",""type"":""->"",""args"":[""/Username/files_encryption/keys/files/FILENAME.PDF/OC_DEFAULT_MODULE/fileKey""]},{""file"":""/cloud/apps/encryption/lib/KeyManager.php"",""line"":452,""function"":""getFileKey"",""class"":""OC\\Encryption\\Keys\\Storage"",""type"":""->"",""args"":[""/Username/files/FILENAME.PDF"",""fileKey"",""OC_DEFAULT_MODULE""]},{""file"":""/cloud/apps/encryption/lib/Crypto/Encryption.php"",""line"":202,""function"":""getFileKey"",""class"":""OCA\\Encryption\\KeyManager"",""type"":""->"",""args"":[""/Username/files/FILENAME.PDF"",""Username""]},{""file"":""/cloud/lib/private/Files/Stream/Encryption.php"",""line"":287,""function"":""begin"",""class"":""OCA\\Encryption\\Crypto\\Encryption"",""type"":""->"",""args"":[""/Username/files/FILENAME.PDF"",""Username"",""r"",{""cipher"":""AES-256-CFB"",""oc_encryption_module"":""OC_DEFAULT_MODULE""},{""users"":[""Username""],""public"":false}]},{""function"":""stream_open"",""class"":""OC\\Files\\Stream\\Encryption"",""type"":""->"",""args"":[""ocencryption://"",""r"",0,null]},{""file"":""/cloud/lib/private/Files/Stream/Encryption.php"",""line"":214,""function"":""fopen"",""args"":[""ocencryption://"",""r"",false,null]},{""file"":""/cloud/lib/private/Files/Stream/Encryption.php"",""line"":189,""function"":""wrapSource"",""class"":""OC\\Files\\Stream\\Encryption"",""type"":""::"",""args"":[null,null,""ocencryption"",""OC\\Files\\Stream\\Encryption"",""r""]},{""file"":""/cloud/lib/private/Files/Storage/Wrapper/Encryption.php"",""line"":471,""function"":""wrap"",""class"":""OC\\Files\\Stream\\Encryption"",""type"":""::"",""args"":[null,""files/FILENAME.PDF"",""/Username/files/FILENAME.PDF"",{""cipher"":""AES-256-CFB"",""oc_encryption_module"":""OC_DEFAULT_MODULE""},""Username"",{""__class__"":""OCA\\Encryption\\Crypto\\Encryption""},{""cache"":null,""scanner"":null,""watcher"":null,""propagator"":null,""updater"":null,""__class__"":""OC\\Files\\Storage\\Wrapper\\Quota""},{""cache"":null,""scanner"":null,""watcher"":null,""propagator"":null,""updater"":null,""__class__"":""OC\\Files\\Storage\\Wrapper\\Encryption""},{""__class__"":""OC\\Encryption\\Util""},{""__class__"":""OC\\Encryption\\File""},""r"",220832,159010,8192,false]},{""file"":""/cloud/lib/private/Files/Storage/Wrapper/Wrapper.php"",""line"":302,""function"":""fopen"",""class"":""OC\\Files\\Storage\\Wrapper\\Encryption"",""type"":""->"",""args"":[""files/FILENAME.PDF"",""r""]},{""file"":""/cloud/lib/private/Files/View.php"",""line"":1166,""function"":""fopen"",""class"":""OC\\Files\\Storage\\Wrapper\\Wrapper"",""type"":""->"",""args"":[""files/FILENAME.PDF"",""r""]},{""file"":""/cloud/lib/private/Files/View.php"",""line"":1002,""function"":""basicOperation"",""class"":""OC\\Files\\View"",""type"":""->"",""args"":[""fopen"",""/FILENAME.PDF"",[""read""],""r""]},{""file"":""/cloud/apps/dav/lib/Connector/Sabre/File.php"",""line"":434,""function"":""fopen"",""class"":""OC\\Files\\View"",""type"":""->"",""args"":[""FILENAME.PDF"",""r""]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/CorePlugin.php"",""line"":85,""function"":""get"",""class"":""OCA\\DAV\\Connector\\Sabre\\File"",""type"":""->"",""args"":[]},{""file"":""/cloud/3rdparty/sabre/event/lib/WildcardEmitterTrait.php"",""line"":89,""function"":""httpGet"",""class"":""Sabre\\DAV\\CorePlugin"",""type"":""->"",""args"":[{""__class__"":""Sabre\\HTTP\\Request""},{""__class__"":""Sabre\\HTTP\\Response""}]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/Server.php"",""line"":472,""function"":""emit"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[""method:GET"",[{""__class__"":""Sabre\\HTTP\\Request""},{""__class__"":""Sabre\\HTTP\\Response""}]]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/Server.php"",""line"":253,""function"":""invokeMethod"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[{""__class__"":""Sabre\\HTTP\\Request""},{""__class__"":""Sabre\\HTTP\\Response""}]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/Server.php"",""line"":321,""function"":""start"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[]},{""file"":""/cloud/apps/dav/lib/Server.php"",""line"":332,""function"":""exec"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[]},{""file"":""/cloud/apps/dav/appinfo/v2/remote.php"",""line"":35,""function"":""exec"",""class"":""OCA\\DAV\\Server"",""type"":""->"",""args"":[]},{""file"":""/cloud/remote.php"",""line"":167,""args"":[""/cloud/apps/dav/appinfo/v2/remote.php""],""function"":""require_once""}],""File"":""/cloud/lib/private/Security/Crypto.php"",""Line"":124}},""CustomMessage"":""--""},""userAgent"":""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36 Edg/90.0.818.66"",""version"":""21.0.1.1"",""id"":""60af4b1c151af""}
```
</details>



","Encryption-Migration fails when encryption.key_storage_migrated is set to false in config ### Steps to reproduce run command ""php occ encryption:migrate-key-storage-format"" with old files from nextcloud-versions before v20 and owncloud v7 (files back to 2015) ### Expected behaviour All fileKey-files should be tested if they can be decrypted. If not (means if an exception occures) the fileKey-file should be base64-encoded, encrypted and stored back to the storage. ### Actual behaviour If the option ""encryption.key_storage_migrated"" is set to false the decryption will success all the time, because the decryption-function will use a fallback which base64-encodes the file and throws no error. See: https://github.com/nextcloud/server/blob/6b0859f28e2569e467490755f900e64024a0ca9d/lib/private/Encryption/Keys/Storage.php#L316 See the following line: it should throw an exception and migrates the file, but if no exception is thrown, no migration is performed. https://github.com/nextcloud/server/blob/6b0859f28e2569e467490755f900e64024a0ca9d/core/Command/Encryption/MigrateKeyStorage.php#L187 After the ""migration"" is done the option ""encryption.key_storage_migrated"" is removed and the old files are not accessible any more, because the decryption-function throws a ""ServerNotAvailable"" function and the log is filled with ""Could not decrypt key"" because the fallback-option is not used any more. ### Server configuration **Operating system:** Ubuntu **Web server:** Apache2 **Database:** MariaDB **PHP version:** 7.4 **Nextcloud version:** 21.0.1 **Updated from an older Nextcloud/ownCloud or fresh install:** Updated from Nextcloud 20, first installation was OwnCloud 6 **Where did you install Nextcloud from:** nextcloud.com **List of activated apps:** <details> <summary>App list</summary> ``` Enabled: - accessibility: 1.7.0 - activity: 2.14.3 - admin_audit: 1.11.0 - audioplayer: 3.1.0 - bookmarks: 4.2.1 - calendar: 2.2.1 - cloud_federation_api: 1.4.0 - comments: 1.11.0 - contacts: 3.5.1 - contactsinteraction: 1.2.0 - dashboard: 7.1.0 - dav: 1.17.1 - deck: 1.4.2 - encryption: 2.9.0 - federatedfilesharing: 1.11.0 - federation: 1.11.0 - files: 1.16.0 - files_external: 1.12.0 - files_mindmap: 0.0.24 - files_pdfviewer: 2.1.0 - files_rightclick: 1.0.0 - files_sharing: 1.13.1 - files_trashbin: 1.11.0 - files_versions: 1.14.0 - files_videoplayer: 1.10.0 - firstrunwizard: 2.10.0 - gpxpod: 4.2.8 - impersonate: 1.8.0 - keeweb: 0.6.5 - logreader: 2.6.0 - lookup_server_connector: 1.9.0 - mail: 1.9.5 - news: 15.4.4 - nextcloud_announcements: 1.10.0 - notifications: 2.9.0 - oauth2: 1.9.0 - password_policy: 1.11.0 - phonetrack: 0.6.7 - photos: 1.3.0 - polls: 1.8.3 - privacy: 1.5.0 - provisioning_api: 1.11.0 - quota_warning: 1.10.0 - serverinfo: 1.11.0 - settings: 1.3.0 - sharebymail: 1.11.0 - support: 1.4.0 - survey_client: 1.9.0 - systemtags: 1.11.0 - tasks: 0.13.6 - text: 3.2.0 - theming: 1.12.0 - twofactor_backupcodes: 1.10.0 - twofactor_totp: 6.0.0 - twofactor_webauthn: 0.2.9 - updatenotification: 1.11.0 - user_status: 1.1.1 - viewer: 1.5.0 - weather_status: 1.1.0 - workflowengine: 2.3.0 Disabled: - recommendations - user_ldap ``` </details> **Nextcloud configuration:** <details> <summary>Config report</summary> ``` { ""system"": { ""instanceid"": ""***REMOVED SENSITIVE VALUE***"", ""passwordsalt"": ""***REMOVED SENSITIVE VALUE***"", ""trusted_domains"": [ ""cloud.noeding-online.de"", ""cloud.xn--nding-jua.de"" ], ""datadirectory"": ""***REMOVED SENSITIVE VALUE***"", ""tempdirectory"": ""\/www\/htdocs\/w00bd480\/tmp"", ""dbtype"": ""mysql"", ""version"": ""21.0.1.1"", ""dbname"": ""***REMOVED SENSITIVE VALUE***"", ""dbhost"": ""***REMOVED SENSITIVE VALUE***"", ""dbtableprefix"": ""oc_"", ""dbuser"": ""***REMOVED SENSITIVE VALUE***"", ""dbpassword"": ""***REMOVED SENSITIVE VALUE***"", ""installed"": true, ""theme"": """", ""maintenance"": false, ""mail_from_address"": ""***REMOVED SENSITIVE VALUE***"", ""mail_smtpmode"": ""smtp"", ""mail_domain"": ""***REMOVED SENSITIVE VALUE***"", ""forcessl"": true, ""trashbin_retention_obligation"": ""30, 60"", ""versions_retention_obligation"": ""auto"", ""loglevel"": 2, ""log_rotate_size"": 10485760, ""logtimezone"": ""Europe\/Berlin"", ""check_for_working_webdav"": true, ""check_for_working_htaccess"": true, ""xframe_restriction"": false, ""secret"": ""***REMOVED SENSITIVE VALUE***"", ""forceSSLforSubdomains"": true, ""enable_previews"": true, ""enabledPreviewProviders"": [ ""OC\\Preview\\PNG"", ""OC\\Preview\\JPEG"", ""OC\\Preview\\GIF"", ""OC\\Preview\\BMP"", ""OC\\Preview\\XBitmap"", ""OC\\Preview\\MP3"", ""OC\\Preview\\TXT"", ""OC\\Preview\\MarkDown"" ], ""singleuser"": false, ""remember_login_cookie_lifetime"": 1296000, ""session_lifetime"": 86400, ""session_keepalive"": true, ""appstore.experimental.enabled"": true, ""filesystem_check_changes"": 0, ""default_language"": ""de"", ""updatechecker"": false, ""cipher"": ""AES-256-CFB"", ""minimum.supported.desktop.version"": ""2.2.0"", ""filelocking.enabled"": true, ""overwrite.cli.url"": ""https:\/\/cloud.noeding-online.de"", ""integrity.check.disabled"": true, ""memcache.local"": ""\\OC\\Memcache\\ArrayCache"", ""mail_smtpauthtype"": ""LOGIN"", ""mail_smtphost"": ""***REMOVED SENSITIVE VALUE***"", ""mail_smtpport"": ""587"", ""mail_smtpsecure"": ""tls"", ""mail_smtpauth"": 1, ""mysql.utf8mb4"": false, ""app_install_overwrite"": [ ""sensorlogger"", ""tasks"", ""keeweb"", ""polls"", ""files_mindmap"", ""contacts"", ""twofactor_webauthn"", ""spreed"", ""calendar"" ], ""onlyoffice"": { ""verify_peer_off"": true }, ""mail_smtpname"": ""***REMOVED SENSITIVE VALUE***"", ""mail_smtppassword"": ""***REMOVED SENSITIVE VALUE***"", ""mail_sendmailmode"": ""smtp"", ""encryption.legacy_format_support"": true, ""encryption.key_storage_migrated"": false, ""default_phone_region"": ""DE"" } } ``` </details> **Are you using external storage, if yes which one:** SMB **Are you using encryption:** yes **Are you using an external user-backend, if yes which one:** no ### Client configuration **Browser:** Chrome **Operating system:** Windows 10 ### Logs #### Nextcloud log (data/nextcloud.log) <details> <summary>Nextcloud log</summary> ``` {""reqId"":""YK8-I5CdpSMKbXE8k18QSwAADBI"",""level"":4,""time"":""2021-05-27T08:41:39+02:00"",""remoteAddr"":""188.74.18.135"",""user"":""Username"",""app"":""webdav"",""method"":""GET"",""url"":""/remote.php/dav/files/Username/FILENAME.PDF"",""message"":{""Exception"":""Sabre\\DAV\\Exception"",""Message"":""Could not decrypt key"",""Code"":0,""Trace"":[{""file"":""/cloud/apps/dav/lib/Connector/Sabre/File.php"",""line"":436,""function"":""convertToSabreException"",""class"":""OCA\\DAV\\Connector\\Sabre\\File"",""type"":""->"",""args"":[{""__class__"":""OC\\ServerNotAvailableException""}]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/CorePlugin.php"",""line"":85,""function"":""get"",""class"":""OCA\\DAV\\Connector\\Sabre\\File"",""type"":""->"",""args"":[]},{""file"":""/cloud/3rdparty/sabre/event/lib/WildcardEmitterTrait.php"",""line"":89,""function"":""httpGet"",""class"":""Sabre\\DAV\\CorePlugin"",""type"":""->"",""args"":[{""__class__"":""Sabre\\HTTP\\Request""},{""__class__"":""Sabre\\HTTP\\Response""}]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/Server.php"",""line"":472,""function"":""emit"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[""method:GET"",[{""__class__"":""Sabre\\HTTP\\Request""},{""__class__"":""Sabre\\HTTP\\Response""}]]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/Server.php"",""line"":253,""function"":""invokeMethod"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[{""__class__"":""Sabre\\HTTP\\Request""},{""__class__"":""Sabre\\HTTP\\Response""}]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/Server.php"",""line"":321,""function"":""start"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[]},{""file"":""/cloud/apps/dav/lib/Server.php"",""line"":332,""function"":""exec"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[]},{""file"":""/cloud/apps/dav/appinfo/v2/remote.php"",""line"":35,""function"":""exec"",""class"":""OCA\\DAV\\Server"",""type"":""->"",""args"":[]},{""file"":""/cloud/remote.php"",""line"":167,""args"":[""/cloud/apps/dav/appinfo/v2/remote.php""],""function"":""require_once""}],""File"":""/cloud/apps/dav/lib/Connector/Sabre/File.php"",""Line"":677,""Previous"":{""Exception"":""OC\\ServerNotAvailableException"",""Message"":""Could not decrypt key"",""Code"":0,""Trace"":[{""file"":""/cloud/lib/private/Encryption/Keys/Storage.php"",""line"":104,""function"":""getKey"",""class"":""OC\\Encryption\\Keys\\Storage"",""type"":""->"",""args"":[""/Username/files_encryption/keys/files/FILENAME.PDF/OC_DEFAULT_MODULE/fileKey""]},{""file"":""/cloud/apps/encryption/lib/KeyManager.php"",""line"":452,""function"":""getFileKey"",""class"":""OC\\Encryption\\Keys\\Storage"",""type"":""->"",""args"":[""/Username/files/FILENAME.PDF"",""fileKey"",""OC_DEFAULT_MODULE""]},{""file"":""/cloud/apps/encryption/lib/Crypto/Encryption.php"",""line"":202,""function"":""getFileKey"",""class"":""OCA\\Encryption\\KeyManager"",""type"":""->"",""args"":[""/Username/files/FILENAME.PDF"",""Username""]},{""file"":""/cloud/lib/private/Files/Stream/Encryption.php"",""line"":287,""function"":""begin"",""class"":""OCA\\Encryption\\Crypto\\Encryption"",""type"":""->"",""args"":[""/Username/files/FILENAME.PDF"",""Username"",""r"",{""cipher"":""AES-256-CFB"",""oc_encryption_module"":""OC_DEFAULT_MODULE""},{""users"":[""Username""],""public"":false}]},{""function"":""stream_open"",""class"":""OC\\Files\\Stream\\Encryption"",""type"":""->"",""args"":[""ocencryption://"",""r"",0,null]},{""file"":""/cloud/lib/private/Files/Stream/Encryption.php"",""line"":214,""function"":""fopen"",""args"":[""ocencryption://"",""r"",false,null]},{""file"":""/cloud/lib/private/Files/Stream/Encryption.php"",""line"":189,""function"":""wrapSource"",""class"":""OC\\Files\\Stream\\Encryption"",""type"":""::"",""args"":[null,null,""ocencryption"",""OC\\Files\\Stream\\Encryption"",""r""]},{""file"":""/cloud/lib/private/Files/Storage/Wrapper/Encryption.php"",""line"":471,""function"":""wrap"",""class"":""OC\\Files\\Stream\\Encryption"",""type"":""::"",""args"":[null,""files/FILENAME.PDF"",""/Username/files/FILENAME.PDF"",{""cipher"":""AES-256-CFB"",""oc_encryption_module"":""OC_DEFAULT_MODULE""},""Username"",{""__class__"":""OCA\\Encryption\\Crypto\\Encryption""},{""cache"":null,""scanner"":null,""watcher"":null,""propagator"":null,""updater"":null,""__class__"":""OC\\Files\\Storage\\Wrapper\\Quota""},{""cache"":null,""scanner"":null,""watcher"":null,""propagator"":null,""updater"":null,""__class__"":""OC\\Files\\Storage\\Wrapper\\Encryption""},{""__class__"":""OC\\Encryption\\Util""},{""__class__"":""OC\\Encryption\\File""},""r"",220832,159010,8192,false]},{""file"":""/cloud/lib/private/Files/Storage/Wrapper/Wrapper.php"",""line"":302,""function"":""fopen"",""class"":""OC\\Files\\Storage\\Wrapper\\Encryption"",""type"":""->"",""args"":[""files/FILENAME.PDF"",""r""]},{""file"":""/cloud/lib/private/Files/View.php"",""line"":1166,""function"":""fopen"",""class"":""OC\\Files\\Storage\\Wrapper\\Wrapper"",""type"":""->"",""args"":[""files/FILENAME.PDF"",""r""]},{""file"":""/cloud/lib/private/Files/View.php"",""line"":1002,""function"":""basicOperation"",""class"":""OC\\Files\\View"",""type"":""->"",""args"":[""fopen"",""/FILENAME.PDF"",[""read""],""r""]},{""file"":""/cloud/apps/dav/lib/Connector/Sabre/File.php"",""line"":434,""function"":""fopen"",""class"":""OC\\Files\\View"",""type"":""->"",""args"":[""FILENAME.PDF"",""r""]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/CorePlugin.php"",""line"":85,""function"":""get"",""class"":""OCA\\DAV\\Connector\\Sabre\\File"",""type"":""->"",""args"":[]},{""file"":""/cloud/3rdparty/sabre/event/lib/WildcardEmitterTrait.php"",""line"":89,""function"":""httpGet"",""class"":""Sabre\\DAV\\CorePlugin"",""type"":""->"",""args"":[{""__class__"":""Sabre\\HTTP\\Request""},{""__class__"":""Sabre\\HTTP\\Response""}]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/Server.php"",""line"":472,""function"":""emit"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[""method:GET"",[{""__class__"":""Sabre\\HTTP\\Request""},{""__class__"":""Sabre\\HTTP\\Response""}]]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/Server.php"",""line"":253,""function"":""invokeMethod"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[{""__class__"":""Sabre\\HTTP\\Request""},{""__class__"":""Sabre\\HTTP\\Response""}]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/Server.php"",""line"":321,""function"":""start"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[]},{""file"":""/cloud/apps/dav/lib/Server.php"",""line"":332,""function"":""exec"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[]},{""file"":""/cloud/apps/dav/appinfo/v2/remote.php"",""line"":35,""function"":""exec"",""class"":""OCA\\DAV\\Server"",""type"":""->"",""args"":[]},{""file"":""/cloud/remote.php"",""line"":167,""args"":[""/cloud/apps/dav/appinfo/v2/remote.php""],""function"":""require_once""}],""File"":""/cloud/lib/private/Encryption/Keys/Storage.php"",""Line"":287,""Previous"":{""Exception"":""Exception"",""Message"":""Authenticated ciphertext could not be decoded."",""Code"":0,""Trace"":[{""file"":""/cloud/lib/private/Encryption/Keys/Storage.php"",""line"":285,""function"":""decrypt"",""class"":""OC\\Security\\Crypto"",""type"":""->"",""args"":[""*** sensitive parameters replaced ***""]},{""file"":""/cloud/lib/private/Encryption/Keys/Storage.php"",""line"":104,""function"":""getKey"",""class"":""OC\\Encryption\\Keys\\Storage"",""type"":""->"",""args"":[""/Username/files_encryption/keys/files/FILENAME.PDF/OC_DEFAULT_MODULE/fileKey""]},{""file"":""/cloud/apps/encryption/lib/KeyManager.php"",""line"":452,""function"":""getFileKey"",""class"":""OC\\Encryption\\Keys\\Storage"",""type"":""->"",""args"":[""/Username/files/FILENAME.PDF"",""fileKey"",""OC_DEFAULT_MODULE""]},{""file"":""/cloud/apps/encryption/lib/Crypto/Encryption.php"",""line"":202,""function"":""getFileKey"",""class"":""OCA\\Encryption\\KeyManager"",""type"":""->"",""args"":[""/Username/files/FILENAME.PDF"",""Username""]},{""file"":""/cloud/lib/private/Files/Stream/Encryption.php"",""line"":287,""function"":""begin"",""class"":""OCA\\Encryption\\Crypto\\Encryption"",""type"":""->"",""args"":[""/Username/files/FILENAME.PDF"",""Username"",""r"",{""cipher"":""AES-256-CFB"",""oc_encryption_module"":""OC_DEFAULT_MODULE""},{""users"":[""Username""],""public"":false}]},{""function"":""stream_open"",""class"":""OC\\Files\\Stream\\Encryption"",""type"":""->"",""args"":[""ocencryption://"",""r"",0,null]},{""file"":""/cloud/lib/private/Files/Stream/Encryption.php"",""line"":214,""function"":""fopen"",""args"":[""ocencryption://"",""r"",false,null]},{""file"":""/cloud/lib/private/Files/Stream/Encryption.php"",""line"":189,""function"":""wrapSource"",""class"":""OC\\Files\\Stream\\Encryption"",""type"":""::"",""args"":[null,null,""ocencryption"",""OC\\Files\\Stream\\Encryption"",""r""]},{""file"":""/cloud/lib/private/Files/Storage/Wrapper/Encryption.php"",""line"":471,""function"":""wrap"",""class"":""OC\\Files\\Stream\\Encryption"",""type"":""::"",""args"":[null,""files/FILENAME.PDF"",""/Username/files/FILENAME.PDF"",{""cipher"":""AES-256-CFB"",""oc_encryption_module"":""OC_DEFAULT_MODULE""},""Username"",{""__class__"":""OCA\\Encryption\\Crypto\\Encryption""},{""cache"":null,""scanner"":null,""watcher"":null,""propagator"":null,""updater"":null,""__class__"":""OC\\Files\\Storage\\Wrapper\\Quota""},{""cache"":null,""scanner"":null,""watcher"":null,""propagator"":null,""updater"":null,""__class__"":""OC\\Files\\Storage\\Wrapper\\Encryption""},{""__class__"":""OC\\Encryption\\Util""},{""__class__"":""OC\\Encryption\\File""},""r"",220832,159010,8192,false]},{""file"":""/cloud/lib/private/Files/Storage/Wrapper/Wrapper.php"",""line"":302,""function"":""fopen"",""class"":""OC\\Files\\Storage\\Wrapper\\Encryption"",""type"":""->"",""args"":[""files/FILENAME.PDF"",""r""]},{""file"":""/cloud/lib/private/Files/View.php"",""line"":1166,""function"":""fopen"",""class"":""OC\\Files\\Storage\\Wrapper\\Wrapper"",""type"":""->"",""args"":[""files/FILENAME.PDF"",""r""]},{""file"":""/cloud/lib/private/Files/View.php"",""line"":1002,""function"":""basicOperation"",""class"":""OC\\Files\\View"",""type"":""->"",""args"":[""fopen"",""/FILENAME.PDF"",[""read""],""r""]},{""file"":""/cloud/apps/dav/lib/Connector/Sabre/File.php"",""line"":434,""function"":""fopen"",""class"":""OC\\Files\\View"",""type"":""->"",""args"":[""FILENAME.PDF"",""r""]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/CorePlugin.php"",""line"":85,""function"":""get"",""class"":""OCA\\DAV\\Connector\\Sabre\\File"",""type"":""->"",""args"":[]},{""file"":""/cloud/3rdparty/sabre/event/lib/WildcardEmitterTrait.php"",""line"":89,""function"":""httpGet"",""class"":""Sabre\\DAV\\CorePlugin"",""type"":""->"",""args"":[{""__class__"":""Sabre\\HTTP\\Request""},{""__class__"":""Sabre\\HTTP\\Response""}]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/Server.php"",""line"":472,""function"":""emit"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[""method:GET"",[{""__class__"":""Sabre\\HTTP\\Request""},{""__class__"":""Sabre\\HTTP\\Response""}]]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/Server.php"",""line"":253,""function"":""invokeMethod"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[{""__class__"":""Sabre\\HTTP\\Request""},{""__class__"":""Sabre\\HTTP\\Response""}]},{""file"":""/cloud/3rdparty/sabre/dav/lib/DAV/Server.php"",""line"":321,""function"":""start"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[]},{""file"":""/cloud/apps/dav/lib/Server.php"",""line"":332,""function"":""exec"",""class"":""Sabre\\DAV\\Server"",""type"":""->"",""args"":[]},{""file"":""/cloud/apps/dav/appinfo/v2/remote.php"",""line"":35,""function"":""exec"",""class"":""OCA\\DAV\\Server"",""type"":""->"",""args"":[]},{""file"":""/cloud/remote.php"",""line"":167,""args"":[""/cloud/apps/dav/appinfo/v2/remote.php""],""function"":""require_once""}],""File"":""/cloud/lib/private/Security/Crypto.php"",""Line"":124}},""CustomMessage"":""--""},""userAgent"":""Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.212 Safari/537.36 Edg/90.0.818.66"",""version"":""21.0.1.1"",""id"":""60af4b1c151af""} ``` </details> "
31057,31057,34600,https://api.github.com/repos/iotaledger/firefly/issues/1015,0.0,2021-04-23T09:39:07Z,NONE,https://api.github.com/repos/iotaledger/firefly,Special characters in the storage path cause a white screen on Windows,"## Issue description

special character in windows 10 user name and user directory (like 채 in my case) prevent creating a firefly profile and token migration. Also for the creation of a firefly profile you only get a warning message - something went wrong - (see screenshot below) 
![image](https://user-images.githubusercontent.com/77152394/115851322-19e43c80-a427-11eb-9583-cd21933766e9.png)


## Wallet version

Firefly Version 1.0.0


## System specification

Windows 10

## Is it a repeatable issue?

Yes

## Steps To reproduce the issue

Explain how the maintainer can reproduce the issue.

1. start Firefly, select English, click and accept Privacy Policy 
2. select light/dark theme, continue, provide Profile Name (Tom), continue
3. then the windows ""Something went wrong"" appears in the right lower corner and disappears after 4 seconds
4. if you hit continue again, you can either create a new wallet or migrate or restore a wallet
5. in all cases you end up with a white screen, and nothing happens again at all

## Expected behaviour

Wallet should be created, Seed should be migrated

## Actual behaviour

White screen

## Errors

![image](https://user-images.githubusercontent.com/77152394/115852029-e9e96900-a427-11eb-9953-5da90aa0ebc0.png)

Error log: 
![image](https://user-images.githubusercontent.com/77152394/115852101-ff5e9300-a427-11eb-96da-4f1f15fffe54.png)

Diagnostic
![image](https://user-images.githubusercontent.com/77152394/115852154-0e454580-a428-11eb-9e5f-d061a12698b9.png)

Using a different user on the same computer but without special character did not trigger the issue, so it is assumed that the special character, in this case the 채, did trigger the error

By the way: Firefly 0.4.0 Beta worked with out any problems","Special characters in the storage path cause a white screen on Windows ## Issue description special character in windows 10 user name and user directory (like 채 in my case) prevent creating a firefly profile and token migration. Also for the creation of a firefly profile you only get a warning message - something went wrong - (see screenshot below) ![image](https://user-images.githubusercontent.com/77152394/115851322-19e43c80-a427-11eb-9583-cd21933766e9.png) ## Wallet version Firefly Version 1.0.0 ## System specification Windows 10 ## Is it a repeatable issue? Yes ## Steps To reproduce the issue Explain how the maintainer can reproduce the issue. 1. start Firefly, select English, click and accept Privacy Policy 2. select light/dark theme, continue, provide Profile Name (Tom), continue 3. then the windows ""Something went wrong"" appears in the right lower corner and disappears after 4 seconds 4. if you hit continue again, you can either create a new wallet or migrate or restore a wallet 5. in all cases you end up with a white screen, and nothing happens again at all ## Expected behaviour Wallet should be created, Seed should be migrated ## Actual behaviour White screen ## Errors ![image](https://user-images.githubusercontent.com/77152394/115852029-e9e96900-a427-11eb-9953-5da90aa0ebc0.png) Error log: ![image](https://user-images.githubusercontent.com/77152394/115852101-ff5e9300-a427-11eb-96da-4f1f15fffe54.png) Diagnostic ![image](https://user-images.githubusercontent.com/77152394/115852154-0e454580-a428-11eb-9e5f-d061a12698b9.png) Using a different user on the same computer but without special character did not trigger the issue, so it is assumed that the special character, in this case the 채, did trigger the error By the way: Firefly 0.4.0 Beta worked with out any problems"
610748,610748,678731,https://api.github.com/repos/N1Ran/BlockLimiter/issues/87,1.0,2021-04-25T14:18:23Z,OWNER,https://api.github.com/repos/N1Ran/BlockLimiter,ShutOff punishment needs to count how many of the said block is on.,"Without checking how many of the block is on, it spams punishment warning to player.  Also limit how often message is sent","ShutOff punishment needs to count how many of the said block is on. Without checking how many of the block is on, it spams punishment warning to player. Also limit how often message is sent"
216063,216063,240263,https://api.github.com/repos/locustio/locust/issues/1653,0.0,2020-12-10T16:36:34Z,NONE,https://api.github.com/repos/locustio/locust,locust should exit when a load shape returns None in headless mode,"Hello! 

### Describe the bug

When using a LoadTestShape class, the test finishes when its `tick` method returns `None`, but the Locust process keeps running, even when in `--headless` mode.

### Expected behavior

When Locust is run in `--headless` mode, it should automatically stop running when a `LoadTestShape` class `tick` method signals a test is complete by returning `None`.

### Actual behavior

The test is finished, but the Locust process does not exit.

### Steps to reproduce

I'm using Docker to run Locust.

file: repro.py
```
import logging

from locust import HttpUser, LoadTestShape, task


# Straight from:
# https://docs.locust.io/en/latest/generating-custom-load-shape.html?highlight=LoadTestShape
class MyCustomShape(LoadTestShape):
    time_limit = 20
    spawn_rate = 2

    def tick(self):
        run_time = self.get_run_time()

        if run_time < self.time_limit:
            # User count rounded to nearest hundred.
            user_count = round(run_time, -2)
            return (user_count, self.spawn_rate)

        return None


class User(HttpUser):

    @task
    def main(self):
        logging.info('Running main task...')

```

Then run the reproducer like:
```
docker run -v ""$PWD:/mnt/locust"" -w ""/mnt/locust"" locustio/locust -f repro.py --headless --host http://www.example.com --only-summary
[2020-12-10 16:19:21,864] 39c75587a12e/WARNING/locust.main: System open file limit '1024' is below minimum setting '10000'. It's not high enough for load testing, and the OS didn't allow locust to increase it by itself. See https://github.com/locustio/locust/wiki/Installation#increasing-maximum-number-of-open-files-limit for more info.
[2020-12-10 16:19:21,865] 39c75587a12e/INFO/locust.runners: Shape test starting. User count and spawn rate are ignored for this type of load test
[2020-12-10 16:19:21,865] 39c75587a12e/INFO/locust.main: No run time limit set, use CTRL+C to interrupt.
[2020-12-10 16:19:21,865] 39c75587a12e/INFO/locust.main: Starting Locust 1.4.1
[2020-12-10 16:19:21,866] 39c75587a12e/INFO/locust.runners: Shape worker starting
[2020-12-10 16:19:21,866] 39c75587a12e/INFO/locust.runners: Shape test updating to 0 users at 2.00 spawn rate
[2020-12-10 16:19:21,866] 39c75587a12e/INFO/root: Terminal was not a tty. Keyboard input disabled
[2020-12-10 16:19:21,866] 39c75587a12e/INFO/locust.runners: Spawning 0 users at the rate 2 users/s (0 users already running)...
[2020-12-10 16:19:21,867] 39c75587a12e/INFO/locust.runners: All users spawned: User: 0 (0 total running)
[2020-12-10 16:19:41,887] 39c75587a12e/INFO/locust.runners: Shape test stopping
```

Observe that Locust does not return control to the shell and keeps running.

### Environment

Dockerized. Everything needed to reproduce is described above.","locust should exit when a load shape returns None in headless mode Hello! ### Describe the bug When using a LoadTestShape class, the test finishes when its `tick` method returns `None`, but the Locust process keeps running, even when in `--headless` mode. ### Expected behavior When Locust is run in `--headless` mode, it should automatically stop running when a `LoadTestShape` class `tick` method signals a test is complete by returning `None`. ### Actual behavior The test is finished, but the Locust process does not exit. ### Steps to reproduce I'm using Docker to run Locust. file: repro.py ``` import logging from locust import HttpUser, LoadTestShape, task # Straight from: # https://docs.locust.io/en/latest/generating-custom-load-shape.html?highlight=LoadTestShape class MyCustomShape(LoadTestShape): time_limit = 20 spawn_rate = 2 def tick(self): run_time = self.get_run_time() if run_time < self.time_limit: # User count rounded to nearest hundred. user_count = round(run_time, -2) return (user_count, self.spawn_rate) return None class User(HttpUser): @task def main(self): logging.info('Running main task...') ``` Then run the reproducer like: ``` docker run -v ""$PWD:/mnt/locust"" -w ""/mnt/locust"" locustio/locust -f repro.py --headless --host http://www.example.com --only-summary [2020-12-10 16:19:21,864] 39c75587a12e/WARNING/locust.main: System open file limit '1024' is below minimum setting '10000'. It's not high enough for load testing, and the OS didn't allow locust to increase it by itself. See https://github.com/locustio/locust/wiki/Installation#increasing-maximum-number-of-open-files-limit for more info. [2020-12-10 16:19:21,865] 39c75587a12e/INFO/locust.runners: Shape test starting. User count and spawn rate are ignored for this type of load test [2020-12-10 16:19:21,865] 39c75587a12e/INFO/locust.main: No run time limit set, use CTRL+C to interrupt. [2020-12-10 16:19:21,865] 39c75587a12e/INFO/locust.main: Starting Locust 1.4.1 [2020-12-10 16:19:21,866] 39c75587a12e/INFO/locust.runners: Shape worker starting [2020-12-10 16:19:21,866] 39c75587a12e/INFO/locust.runners: Shape test updating to 0 users at 2.00 spawn rate [2020-12-10 16:19:21,866] 39c75587a12e/INFO/root: Terminal was not a tty. Keyboard input disabled [2020-12-10 16:19:21,866] 39c75587a12e/INFO/locust.runners: Spawning 0 users at the rate 2 users/s (0 users already running)... [2020-12-10 16:19:21,867] 39c75587a12e/INFO/locust.runners: All users spawned: User: 0 (0 total running) [2020-12-10 16:19:41,887] 39c75587a12e/INFO/locust.runners: Shape test stopping ``` Observe that Locust does not return control to the shell and keeps running. ### Environment Dockerized. Everything needed to reproduce is described above."
721444,721444,801793,https://api.github.com/repos/ZeligsoftDev/CX4CBDDS/issues/219,1.0,2021-03-01T18:47:48Z,COLLABORATOR,https://api.github.com/repos/ZeligsoftDev/CX4CBDDS,Automatically recreate diagrams when migrating models from 1.X to 2.X,"# **Issue and tracking information**


### Developer's time Estimated effort to fix (hours):

### Developer's Actual time spent on fix (hours)  


# **Issue reporter to provide a detailed description of the issue in the space below**
We would like the team to do a technical spike to see what it would take to recreate model assembly diagrams when converting between RSA and Papyrus. We understand that the information is lost when going from EMX -> UML. Unfortunately, we have many, many assemblies where losing the diagram appearance would result in many hours of effort to recreate the assemblies each time the model is migrated.

We imagine that a solution may require changes being made to RSA to allow for exporting of the information from an EMX to possible a "".di"" file, and we are open to something like that if it is necessary.

","Automatically recreate diagrams when migrating models from 1.X to 2.X # **Issue and tracking information** ### Developer's time Estimated effort to fix (hours): ### Developer's Actual time spent on fix (hours) # **Issue reporter to provide a detailed description of the issue in the space below** We would like the team to do a technical spike to see what it would take to recreate model assembly diagrams when converting between RSA and Papyrus. We understand that the information is lost when going from EMX -> UML. Unfortunately, we have many, many assemblies where losing the diagram appearance would result in many hours of effort to recreate the assemblies each time the model is migrated. We imagine that a solution may require changes being made to RSA to allow for exporting of the information from an EMX to possible a "".di"" file, and we are open to something like that if it is necessary. "
782214,782214,591646,https://api.github.com/repos/sqlcollaborative/dbatools/issues/6768,2.0,2020-08-27T07:27:21Z,NONE,https://api.github.com/repos/sqlcollaborative/dbatools,Table merge ETL ?,"Hi,

I've seen that there is a function which inserts data into a given table, but I've not seen one that would take a table from a data source and perform a MERGE statement, so that it inserts new rows, updates those which have the same key and either sets rows as deleted or deletes when data cannot be seen on source.

Will this be implemented? If it's not in your plans, how can I start the implementation? Is there a contribution guideline or something?

Thanks in advance for your reply.","Table merge ETL ? Hi, I've seen that there is a function which inserts data into a given table, but I've not seen one that would take a table from a data source and perform a MERGE statement, so that it inserts new rows, updates those which have the same key and either sets rows as deleted or deletes when data cannot be seen on source. Will this be implemented? If it's not in your plans, how can I start the implementation? Is there a contribution guideline or something? Thanks in advance for your reply."
239266,239266,266139,https://api.github.com/repos/conan-io/conan-center-index/issues/5569,0.0,2021-05-19T18:48:08Z,CONTRIBUTOR,https://api.github.com/repos/conan-io/conan-center-index,"[package] boost/1.76.0: build fails on MacOS Catalina, clang not found","### Package and Environment Details (include every applicable attribute)
  * Package Name/Version: **boost/1.76.0**
  * Operating System+version: **MacOS Catalina**
  * Compiler+version: **apple-clang**
  * Conan version: **conan 1.36.0**
  * Python version: **Python 3.8.6**


### Conan profile (output of `conan profile show default` or `conan profile show <profile>` if custom profile is in use)
```
Configuration for profile default:

[settings]
os=Macos
os_build=Macos
arch=x86_64
arch_build=x86_64
compiler=apple-clang
compiler.version=11.0
compiler.libcxx=libc++
build_type=Release
[options]
[build_requires]
[env]
```


### Steps to reproduce (Include if Applicable)

The build generates an invalid `user-config.jam` file with this line:

```
using ""clang-darwin"" :  :   -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.15.sdk -arch x86_64 :
<archiver>""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ar"" <ranlib>""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib""  ;
```

Giving an error when it tries to run `-isysroot` as a command:

```
warning: toolset clang-darwin initialization:
warning: can not find user-provided command '-isysroot' '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.15.sdk' '-arch' 'x86_64'

warning: initialized from /Users/jake/.conan/data/boost/1.76.0/_/_/source/source_subfolder/tools/build/user-config.jam:5

sh: -y: invalid option
```

<details>
  <summary>Longer log output</summary>

```
boost/1.76.0: 

WARN: replace_in_file didn't find pattern '/* thread_local */' in '/Users/jake/.conan/data/boost/1.76.0/_/_/source/source_subfolder/boost/stacktrace/detail/libbacktrace_impls.hpp' file.
WARN: replace_in_file didn't find pattern '/* static __thread */' in '/Users/jake/.conan/data/boost/1.76.0/_/_/source/source_subfolder/boost/stacktrace/detail/libbacktrace_impls.hpp' file.
boost/1.76.0: WARN: Patching user-config.jam
boost/1.76.0: WARN: 
using zlib : 1.2.11 : <include>""/Users/jake/.conan/data/zlib/1.2.11/_/_/package/0aa7be2d0914b6f3128105e305c90b9cb0cae86d/include"" <search>""/Users/jake/.conan/data/zlib/1.2.11/_/_/package/0aa7be2d0914b6f3128105e305c90b9cb0cae86d/lib"" <name>z ;
using bzip2 : 1.0.8 : <include>""/Users/jake/.conan/data/bzip2/1.0.8/_/_/package/e26f883c3e136952d830bcdc838898582f2a8d80/include"" <search>""/Users/jake/.conan/data/bzip2/1.0.8/_/_/package/e26f883c3e136952d830bcdc838898582f2a8d80/lib"" <name>bz2 ;
using ""clang-darwin"" :  :   -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacO
SX.platform/Developer/SDKs/MacOSX10.15.sdk -arch x86_64 : 
<archiver>""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ar"" <ranlib>""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib""  ;
boost/1.76.0: WARN: b2 -q target-os=darwin architecture=x86 address-model=64 binary-format=mach-o abi=sysv --layout=system --user-config=/Users/jake/.conan/data/boost/1.76.0/_/_/source/source_subfolder/tools/build/user-config.jam -sNO_ZLIB=0 -sNO_BZIP2=0 -sNO_LZMA=1 -sNO_ZSTD=1 boost.locale.iconv=on boost.locale.icu=off --disable-icu threading=multi visibility=hidden link=shared variant=debug --with-atomic --with-chrono --with-container --with-context --with-contract --with-coroutine --with-date_time --with-exception --with-filesystem --with-iostreams --with-locale --with-log --with-program_options --with-random --with-regex --with-serialization --with-stacktrace --with-system --with-test --with-thread --with-timer --with-type_erasure --with-wave
 toolset=clang-darwin pch=on -sICONV_PATH=/Users/jake/.conan/data/libiconv/1.16/_/_/package/0aa7be2d0914b6f3128105e305c90b9cb0cae86d linkflags=""-stdlib=libc++"" cxxflags=""-fPIC -stdlib=libc++ -DBOOST_STACKTRACE_ADDR2LINE_LOCATION=/usr/bin/addr2line"" install --prefix=/Users/jake/.conan/data/boost/1.76.0/_/_/package/919e25258b36635e511e92527cc7d25469a26c9c -j8 --abbreviate-paths -d0 --debug-configuration --build-dir=""/Users/jake/.conan/data/boost/1.76.0/_/_/build/919e25258b36635e511e92527cc7d25469a26c9c""
boost/1.76.0: ERROR: Package '919e25258b36635e511e92527cc7d25469a26c9c' build failed
boost/1.76.0: WARN: Build folder /Users/jake/.conan/data/boost/1.76.0/_/_/build/919e25258b36635e511e92527cc7d25469a26c9c
ERROR: boost/1.76.0: Error in build() method, line 774
	self.run(full_command, run_environment=True)
	ConanException: Error 1 while executing DYLD_LIBRARY_PATH=""/Users/jake/.conan/data/bzip2/1.0.8/_/_/package/e26f883c3e136952d830bcdc838898582f2a8d80/lib:/Users/jake/.conan/data/zlib/1.2.11/_/_/package/0aa7be2d0
914b6f3128105e305c90b9cb0cae86d/lib:/Users/jake/.conan/data/libiconv/1.16/_/_/package/0aa7be2d0914b6f3128105e305c90b9cb0cae86d/lib"" DYLD_FRAMEWORK_PATH="""" b2 -q target-os=darwin architecture=x86 address-model=64 binary-format=mach-o abi=sysv --layout=system --user-config=/Users/jake/.conan/data/boost/1.76.0/_/_/source/source_subfolder/tools/build/user-config.jam -sNO_ZLIB=0 -sNO_BZIP2=0 -sNO_LZMA=1 -sNO_ZSTD=1 boost.locale.iconv=on boost.locale.icu=off --disable-icu threading=multi visibility=hidden link=shared variant=debug --with-atomic --with-chrono --with-container --with-context --with-contract --with-coroutine --with-date_time --with-exception --with-filesystem --with-iostreams --with-locale --with-log --with-program_options --with-random --with-regex --with-serialization --with-stacktrace --with-system --with-test --with-thread --with-timer --with-type_erasure --with-wave toolset=clang-darwin pch=on -sICONV_PATH=/Users/jake/.conan/data/libiconv/1.16/_/_/package/0aa7be2d0914b6f3128105e305c90b9cb0cae86d 
linkflags=""-stdlib=libc++"" cxxflags=""-fPIC -stdlib=libc++ -DBOOST_STACKTRACE_ADDR2LINE_LOCATION=/usr/bin/addr2line"" install --prefix=/Users/jake/.conan/data/boost/1.76.0/_/_/package/919e25258b36635e511e92527cc7d25469a26c9c -j8 --abbreviate-paths -d0 --debug-configuration --build-dir=""/Users/jake/.conan/data/boost/1.76.0/_/_/build/919e25258b36635e511e92527cc7d25469a26c9c""
```
</details>

It seems like the compiler detection here is failing:

```python
    @property
    def _cxx(self):
        if ""CXX"" in os.environ:
            return os.environ[""CXX""]
        if tools.is_apple_os(self.settings.os) and self.settings.compiler == ""apple-clang"":
            return tools.XCRun(self.settings).cxx
```

I'm not sure what the internals of `XCRun` run exactly, but I do find clang this way:

```sh
$ xcrun --find clang
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang
$ xcrun --find clang++
/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang++
```","[package] boost/1.76.0: build fails on MacOS Catalina, clang not found ### Package and Environment Details (include every applicable attribute) * Package Name/Version: **boost/1.76.0** * Operating System+version: **MacOS Catalina** * Compiler+version: **apple-clang** * Conan version: **conan 1.36.0** * Python version: **Python 3.8.6** ### Conan profile (output of `conan profile show default` or `conan profile show <profile>` if custom profile is in use) ``` Configuration for profile default: [settings] os=Macos os_build=Macos arch=x86_64 arch_build=x86_64 compiler=apple-clang compiler.version=11.0 compiler.libcxx=libc++ build_type=Release [options] [build_requires] [env] ``` ### Steps to reproduce (Include if Applicable) The build generates an invalid `user-config.jam` file with this line: ``` using ""clang-darwin"" : : -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.15.sdk -arch x86_64 : <archiver>""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ar"" <ranlib>""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib"" ; ``` Giving an error when it tries to run `-isysroot` as a command: ``` warning: toolset clang-darwin initialization: warning: can not find user-provided command '-isysroot' '/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX10.15.sdk' '-arch' 'x86_64' warning: initialized from /Users/jake/.conan/data/boost/1.76.0/_/_/source/source_subfolder/tools/build/user-config.jam:5 sh: -y: invalid option ``` <details> <summary>Longer log output</summary> ``` boost/1.76.0: WARN: replace_in_file didn't find pattern '/* thread_local */' in '/Users/jake/.conan/data/boost/1.76.0/_/_/source/source_subfolder/boost/stacktrace/detail/libbacktrace_impls.hpp' file. WARN: replace_in_file didn't find pattern '/* static __thread */' in '/Users/jake/.conan/data/boost/1.76.0/_/_/source/source_subfolder/boost/stacktrace/detail/libbacktrace_impls.hpp' file. boost/1.76.0: WARN: Patching user-config.jam boost/1.76.0: WARN: using zlib : 1.2.11 : <include>""/Users/jake/.conan/data/zlib/1.2.11/_/_/package/0aa7be2d0914b6f3128105e305c90b9cb0cae86d/include"" <search>""/Users/jake/.conan/data/zlib/1.2.11/_/_/package/0aa7be2d0914b6f3128105e305c90b9cb0cae86d/lib"" <name>z ; using bzip2 : 1.0.8 : <include>""/Users/jake/.conan/data/bzip2/1.0.8/_/_/package/e26f883c3e136952d830bcdc838898582f2a8d80/include"" <search>""/Users/jake/.conan/data/bzip2/1.0.8/_/_/package/e26f883c3e136952d830bcdc838898582f2a8d80/lib"" <name>bz2 ; using ""clang-darwin"" : : -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/MacO SX.platform/Developer/SDKs/MacOSX10.15.sdk -arch x86_64 : <archiver>""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ar"" <ranlib>""/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/ranlib"" ; boost/1.76.0: WARN: b2 -q target-os=darwin architecture=x86 address-model=64 binary-format=mach-o abi=sysv --layout=system --user-config=/Users/jake/.conan/data/boost/1.76.0/_/_/source/source_subfolder/tools/build/user-config.jam -sNO_ZLIB=0 -sNO_BZIP2=0 -sNO_LZMA=1 -sNO_ZSTD=1 boost.locale.iconv=on boost.locale.icu=off --disable-icu threading=multi visibility=hidden link=shared variant=debug --with-atomic --with-chrono --with-container --with-context --with-contract --with-coroutine --with-date_time --with-exception --with-filesystem --with-iostreams --with-locale --with-log --with-program_options --with-random --with-regex --with-serialization --with-stacktrace --with-system --with-test --with-thread --with-timer --with-type_erasure --with-wave toolset=clang-darwin pch=on -sICONV_PATH=/Users/jake/.conan/data/libiconv/1.16/_/_/package/0aa7be2d0914b6f3128105e305c90b9cb0cae86d linkflags=""-stdlib=libc++"" cxxflags=""-fPIC -stdlib=libc++ -DBOOST_STACKTRACE_ADDR2LINE_LOCATION=/usr/bin/addr2line"" install --prefix=/Users/jake/.conan/data/boost/1.76.0/_/_/package/919e25258b36635e511e92527cc7d25469a26c9c -j8 --abbreviate-paths -d0 --debug-configuration --build-dir=""/Users/jake/.conan/data/boost/1.76.0/_/_/build/919e25258b36635e511e92527cc7d25469a26c9c"" boost/1.76.0: ERROR: Package '919e25258b36635e511e92527cc7d25469a26c9c' build failed boost/1.76.0: WARN: Build folder /Users/jake/.conan/data/boost/1.76.0/_/_/build/919e25258b36635e511e92527cc7d25469a26c9c ERROR: boost/1.76.0: Error in build() method, line 774 self.run(full_command, run_environment=True) ConanException: Error 1 while executing DYLD_LIBRARY_PATH=""/Users/jake/.conan/data/bzip2/1.0.8/_/_/package/e26f883c3e136952d830bcdc838898582f2a8d80/lib:/Users/jake/.conan/data/zlib/1.2.11/_/_/package/0aa7be2d0 914b6f3128105e305c90b9cb0cae86d/lib:/Users/jake/.conan/data/libiconv/1.16/_/_/package/0aa7be2d0914b6f3128105e305c90b9cb0cae86d/lib"" DYLD_FRAMEWORK_PATH="""" b2 -q target-os=darwin architecture=x86 address-model=64 binary-format=mach-o abi=sysv --layout=system --user-config=/Users/jake/.conan/data/boost/1.76.0/_/_/source/source_subfolder/tools/build/user-config.jam -sNO_ZLIB=0 -sNO_BZIP2=0 -sNO_LZMA=1 -sNO_ZSTD=1 boost.locale.iconv=on boost.locale.icu=off --disable-icu threading=multi visibility=hidden link=shared variant=debug --with-atomic --with-chrono --with-container --with-context --with-contract --with-coroutine --with-date_time --with-exception --with-filesystem --with-iostreams --with-locale --with-log --with-program_options --with-random --with-regex --with-serialization --with-stacktrace --with-system --with-test --with-thread --with-timer --with-type_erasure --with-wave toolset=clang-darwin pch=on -sICONV_PATH=/Users/jake/.conan/data/libiconv/1.16/_/_/package/0aa7be2d0914b6f3128105e305c90b9cb0cae86d linkflags=""-stdlib=libc++"" cxxflags=""-fPIC -stdlib=libc++ -DBOOST_STACKTRACE_ADDR2LINE_LOCATION=/usr/bin/addr2line"" install --prefix=/Users/jake/.conan/data/boost/1.76.0/_/_/package/919e25258b36635e511e92527cc7d25469a26c9c -j8 --abbreviate-paths -d0 --debug-configuration --build-dir=""/Users/jake/.conan/data/boost/1.76.0/_/_/build/919e25258b36635e511e92527cc7d25469a26c9c"" ``` </details> It seems like the compiler detection here is failing: ```python @property def _cxx(self): if ""CXX"" in os.environ: return os.environ[""CXX""] if tools.is_apple_os(self.settings.os) and self.settings.compiler == ""apple-clang"": return tools.XCRun(self.settings).cxx ``` I'm not sure what the internals of `XCRun` run exactly, but I do find clang this way: ```sh $ xcrun --find clang /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang $ xcrun --find clang++ /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang++ ```"
266798,266798,296708,https://api.github.com/repos/fossasia/open-event-frontend/issues/5857,1.0,2020-12-01T20:50:24Z,MEMBER,https://api.github.com/repos/fossasia/open-event-frontend,Make Access Form similar to Discount Form,"The discount form was simplified recently. Please simplify the access form in the same way.

Compare discount form
![Screenshot from 2020-12-01 21-33-12](https://user-images.githubusercontent.com/1583873/100795318-27b90700-341f-11eb-98d2-0ec64bbcd659.png)
",Make Access Form similar to Discount Form The discount form was simplified recently. Please simplify the access form in the same way. Compare discount form ![Screenshot from 2020-12-01 21-33-12](https://user-images.githubusercontent.com/1583873/100795318-27b90700-341f-11eb-98d2-0ec64bbcd659.png) 
402721,402721,447622,https://api.github.com/repos/asiliuk/BsuirScheduleApp/issues/20,0.0,2020-11-06T12:28:38Z,NONE,https://api.github.com/repos/asiliuk/BsuirScheduleApp,逵均龜 極龜 克棘剋剋龜戟均筠,"
 - Device: iphone 6s
 - OS: 14.1
 - App Version: 極棘剋筠畇戟

龜棘劇棘鈞龜 克棘剋剋龜戟均 逵極龜逵戟龜, 克逵克 閨畇棘 極棘畇均鈞克逵 戟筠 逵龜戟棘戟戟逵 
","逵均龜 極龜 克棘剋剋龜戟均筠 - Device: iphone 6s - OS: 14.1 - App Version: 極棘剋筠畇戟 龜棘劇棘鈞龜 克棘剋剋龜戟均 逵極龜逵戟龜, 克逵克 閨畇棘 極棘畇均鈞克逵 戟筠 逵龜戟棘戟戟逵 "
301307,301307,335010,https://api.github.com/repos/wmcadigital/wmn-cms/issues/90,0.0,2021-04-15T08:54:22Z,MEMBER,https://api.github.com/repos/wmcadigital/wmn-cms,Reusable content - telephones,"Add text ""Telephone:"" before the telephone number","Reusable content - telephones Add text ""Telephone:"" before the telephone number"
46392,46392,51634,https://api.github.com/repos/lerwine/FsInfoCat/issues/35,1.0,2021-03-02T17:06:02Z,OWNER,https://api.github.com/repos/lerwine/FsInfoCat,Create page for uploading crawl results,PowerShell module will be used to crawl file system and generate a package (zip file) of the crawl results.,Create page for uploading crawl results PowerShell module will be used to crawl file system and generate a package (zip file) of the crawl results.
241353,241353,268445,https://api.github.com/repos/theRealPadster/Mist-theme/issues/20,0.0,2020-03-13T03:13:27Z,OWNER,https://api.github.com/repos/theRealPadster/Mist-theme,Fix new folders being stuck in a gradient state,"I'm not sure if this is the theme itself or just a bug with GNOME 3.36. It seems to do this when I make a new folder, and the highlighted state sticks around, even if I close the folder, open another, etc. It goes away when I close the apps overview. 

![image](https://user-images.githubusercontent.com/1565883/76586343-f7a78d80-64b6-11ea-9812-43e0e5ace3ee.png)
","Fix new folders being stuck in a gradient state I'm not sure if this is the theme itself or just a bug with GNOME 3.36. It seems to do this when I make a new folder, and the highlighted state sticks around, even if I close the folder, open another, etc. It goes away when I close the apps overview. ![image](https://user-images.githubusercontent.com/1565883/76586343-f7a78d80-64b6-11ea-9812-43e0e5ace3ee.png) "
566780,566780,629852,https://api.github.com/repos/TheBusyBiscuit/luckyblocks-sf/issues/38,0.0,2021-02-16T15:10:28Z,NONE,https://api.github.com/repos/TheBusyBiscuit/luckyblocks-sf,bow enchants,"## Description (Required)
<!-- A clear and detailed description of what exactly the Issue consists of. -->
<!-- Please try to write as much as possible. ""it doesn't work"" is not sufficient. -->
<!-- Try to write at least 4-6 sentences. -->
Enchants for bow in custom surprise doesn't work
## Steps to reproduce the Issue (Required)
<!-- Youtube Videos and Screenshots are recommended! -->
Create custom surprise bow with enchants
Example:
```yaml  
  ExampleSurprise21:
    enabled: true
    lucklevel: LUCKY
    items:
      '1':
        type: BOW
        amount: 1
        displayname: '&e&lEnchanted Bow2'
        lore:
        - '&7Pro Lucky Bow to zkus znovu..'
        enchants:
        - UNBREAKING:4
```       
## Expected behavior (Required)
<!-- What did you expect to happen? -->
There will be functional enchants on the bow
## Server Log / Error Report
<!-- Take a look at your Server Log and please provide any error reports you can find via https://pastebin.com/ -->
<!-- We may discard your Issue if you just post it here, as it's unreadable for us. Please use Pastebin! -->
Error: `[15:54:18 WARN]: [SlimefunLuckyBlocks] Could not set ""UNBREAKING"" enchant for custom surprise ""ExampleSurprise21""`
## Environment (Required)
<!-- We may also close your Issue if you are not providing the exact version numbers. -->
<!-- ""latest"" IS NOT A VERSION NUMBER. -->
<!-- You can also just run ""/sf versions"" and show us a screenshot of that. -->

![image](https://user-images.githubusercontent.com/29830635/108081600-6d29bf80-7071-11eb-9cdc-5f53bb5ea136.png)

","bow enchants ## Description (Required) <!-- A clear and detailed description of what exactly the Issue consists of. --> <!-- Please try to write as much as possible. ""it doesn't work"" is not sufficient. --> <!-- Try to write at least 4-6 sentences. --> Enchants for bow in custom surprise doesn't work ## Steps to reproduce the Issue (Required) <!-- Youtube Videos and Screenshots are recommended! --> Create custom surprise bow with enchants Example: ```yaml ExampleSurprise21: enabled: true lucklevel: LUCKY items: '1': type: BOW amount: 1 displayname: '&e&lEnchanted Bow2' lore: - '&7Pro Lucky Bow to zkus znovu..' enchants: - UNBREAKING:4 ``` ## Expected behavior (Required) <!-- What did you expect to happen? --> There will be functional enchants on the bow ## Server Log / Error Report <!-- Take a look at your Server Log and please provide any error reports you can find via https://pastebin.com/ --> <!-- We may discard your Issue if you just post it here, as it's unreadable for us. Please use Pastebin! --> Error: `[15:54:18 WARN]: [SlimefunLuckyBlocks] Could not set ""UNBREAKING"" enchant for custom surprise ""ExampleSurprise21""` ## Environment (Required) <!-- We may also close your Issue if you are not providing the exact version numbers. --> <!-- ""latest"" IS NOT A VERSION NUMBER. --> <!-- You can also just run ""/sf versions"" and show us a screenshot of that. --> ![image](https://user-images.githubusercontent.com/29830635/108081600-6d29bf80-7071-11eb-9cdc-5f53bb5ea136.png) "
507921,507921,564493,https://api.github.com/repos/PrestaShop/PrestaShop/issues/13445,0.0,2019-04-17T06:31:29Z,CONTRIBUTOR,https://api.github.com/repos/PrestaShop/PrestaShop,BO: Tiny MCE editor do not work for all resolutions on manufacturers,"<!--
****************************
DO NOT disclose security issues here, contact security@prestashop.com instead!
****************************
-->

**Describe the bug**
When resolution on the device is low, the tinyMCE editor will not work well, the icons will not scale down with the box and on some resolutions the language selector will place itself above the icons making it impossible to upload or edit images.

**To Reproduce**
1. Click edit on a manufacturer in BO
2. Scale down the browserwindow.

**Additionnal information**
PrestaShop version: 1.7.5.1
PHP version: 7.2.x
","BO: Tiny MCE editor do not work for all resolutions on manufacturers <!-- **************************** DO NOT disclose security issues here, contact security@prestashop.com instead! **************************** --> **Describe the bug** When resolution on the device is low, the tinyMCE editor will not work well, the icons will not scale down with the box and on some resolutions the language selector will place itself above the icons making it impossible to upload or edit images. **To Reproduce** 1. Click edit on a manufacturer in BO 2. Scale down the browserwindow. **Additionnal information** PrestaShop version: 1.7.5.1 PHP version: 7.2.x "
111173,111173,123574,https://api.github.com/repos/ScoremanOrg/scoreman/issues/41,0.0,2021-01-14T16:56:43Z,COLLABORATOR,https://api.github.com/repos/ScoremanOrg/scoreman,Country selection on admin ui issues,"The list of countries are not ordered alphabetically.
There isnt the possibility of setting it to null/empty.",Country selection on admin ui issues The list of countries are not ordered alphabetically. There isnt the possibility of setting it to null/empty.
181829,181829,202135,https://api.github.com/repos/MissAimeeJay/taskmaster-pro/issues/2,1.0,2021-03-15T00:16:33Z,OWNER,https://api.github.com/repos/MissAimeeJay/taskmaster-pro,Update layout for new statuses,"- Add columns for In Progress, In Review, and Done.
- Add additional Bootstrap components.","Update layout for new statuses - Add columns for In Progress, In Review, and Done. - Add additional Bootstrap components."
233636,233636,259810,https://api.github.com/repos/eugenemel/maven/issues/95,0.0,2019-12-02T19:20:10Z,COLLABORATOR,https://api.github.com/repos/eugenemel/maven,Fix memory leaks in SummarizedCompound creation for DirectInfusion,"This might make sense as part of a larger system of creating `SummarizedCompound` objects once (as a part of loading library, perhaps, or perhaps stored in `DB` just as `DB.compounds` are stored.

Depending on memory pressure, this may not be especially high priority.","Fix memory leaks in SummarizedCompound creation for DirectInfusion This might make sense as part of a larger system of creating `SummarizedCompound` objects once (as a part of loading library, perhaps, or perhaps stored in `DB` just as `DB.compounds` are stored. Depending on memory pressure, this may not be especially high priority."
463615,463615,515233,https://api.github.com/repos/CATIA-Systems/FMIKit-Simulink/issues/214,1.0,2020-09-18T15:16:46Z,NONE,https://api.github.com/repos/CATIA-Systems/FMIKit-Simulink,Support derivative features,"Add support for input-, output-, and directional derivatives. @robha67","Support derivative features Add support for input-, output-, and directional derivatives. @robha67"
517631,517631,575247,https://api.github.com/repos/johannesjo/super-productivity/issues/626,1.0,2020-10-28T16:38:33Z,CONTRIBUTOR,https://api.github.com/repos/johannesjo/super-productivity,Use caldav as task provider,"## Problem Statement

I use Nextcloud deck and tasks to organize my tasks. I would like to use this data as source for tasks in super-productivity ad this would allow me to use it without having to duplicate the tasks here.


## :grey_question: Possible Solution 

Both data (Deck and Tasks) is available via CalDAV from nextcloud. Similar to the Jira- and  Gitlab-provider this could be used as a source for tasks. Caldav is a open protocol on top of webdav. Nextcloud tiself maintains a JS library for Caldav: https://github.com/nextcloud/cdav-library

## :arrow_heading_up: Describe alternatives you've considered

The only alternative I can think of is to dump the tasks regularly in a format the super-productivity can import and use that but it would be cumbersome.

## :heavy_plus_sign: Additional context

I would like to provide an initial implementation myself but cannot promise on any timeframe. If someone else wants to have a look into this I'm happy with that.",Use caldav as task provider ## Problem Statement I use Nextcloud deck and tasks to organize my tasks. I would like to use this data as source for tasks in super-productivity ad this would allow me to use it without having to duplicate the tasks here. ## :grey_question: Possible Solution Both data (Deck and Tasks) is available via CalDAV from nextcloud. Similar to the Jira- and Gitlab-provider this could be used as a source for tasks. Caldav is a open protocol on top of webdav. Nextcloud tiself maintains a JS library for Caldav: https://github.com/nextcloud/cdav-library ## :arrow_heading_up: Describe alternatives you've considered The only alternative I can think of is to dump the tasks regularly in a format the super-productivity can import and use that but it would be cumbersome. ## :heavy_plus_sign: Additional context I would like to provide an initial implementation myself but cannot promise on any timeframe. If someone else wants to have a look into this I'm happy with that.
387992,387992,431301,https://api.github.com/repos/openhab-scripters/openhab-helper-libraries/issues/379,1.0,2021-01-06T09:19:50Z,NONE,https://api.github.com/repos/openhab-scripters/openhab-helper-libraries,WHEN Trigger for Things,"Hello,

it is possible to add a When Trigger for Things? 
With the DSL Rule, i can observe a thing, with Jython i dont have a trigger for things.

My example for DSL:
```
rule ""Ger채t gest철rt""
when 
 Thing 'homematic:HM-LC-Sw4-DR:PEQ0172029:KEQ0055288' changed from ONLINE to OFFLINE
 then
 logInfo(""Heizung"", ""Die Heizungskontrolle kann nicht erreicht werden"")
   sendTelegram(""bot1"", ""Die Heizungskontrolle kann nicht erreicht werden"")
end

rule ""Ger채t gest철rt""
when 
 Thing 'homematic:HM-LC-Sw4-DR:PEQ0172029:KEQ0055288' changed from OFFLINE to ONLINE
 then
 logInfo(""Heizung"", ""Die Heizungskontrolle kann wieder erreicht werden"")
   sendTelegram(""bot1"", ""Die Heizungskontrolle kann wieder erreicht werden"")
end

```","WHEN Trigger for Things Hello, it is possible to add a When Trigger for Things? With the DSL Rule, i can observe a thing, with Jython i dont have a trigger for things. My example for DSL: ``` rule ""Ger채t gest철rt"" when Thing 'homematic:HM-LC-Sw4-DR:PEQ0172029:KEQ0055288' changed from ONLINE to OFFLINE then logInfo(""Heizung"", ""Die Heizungskontrolle kann nicht erreicht werden"") sendTelegram(""bot1"", ""Die Heizungskontrolle kann nicht erreicht werden"") end rule ""Ger채t gest철rt"" when Thing 'homematic:HM-LC-Sw4-DR:PEQ0172029:KEQ0055288' changed from OFFLINE to ONLINE then logInfo(""Heizung"", ""Die Heizungskontrolle kann wieder erreicht werden"") sendTelegram(""bot1"", ""Die Heizungskontrolle kann wieder erreicht werden"") end ```"
367752,367752,408811,https://api.github.com/repos/AY2021S2-CS2113-T10-3/tp/issues/18,0.0,2021-03-31T07:17:32Z,NONE,https://api.github.com/repos/AY2021S2-CS2113-T10-3/tp,Update file after a booking is made/cancelled,,Update file after a booking is made/cancelled 
286935,286935,319097,https://api.github.com/repos/michaelrsweet/pappl/issues/148,1.0,2021-02-09T22:19:23Z,NONE,https://api.github.com/repos/michaelrsweet/pappl,Printer Application server running as root not accessible for users,"I want to run the PostScript Printer Application in a Snap, the Snap auto-starting the Printer Application via `daemon: simple` in the `snapcraft.yaml`. This makes the Printer Application server running as root, which is as designed in the Snap world, system daemons run as root. I can, as any normal user, without problems add and configure printers and add user PPD files via the web interface, and I can print with CUPS using CUPS' temporary queues for IPP printers.

What does not work is using `ps-printer-app` for client operations (with subcommands ""printers"", ""jobs"",...) as a normal user, only as root `ps-printer-app` works as a client, but as normal user the problem is not a ""Permission denied"" but the server is simply not found. Even worse is that one does not simply get an error message but the client `ps-printer-app` starts another, personal server for the user leading to complete confusion (another bug, issue #149).

The problem is how the socket file name is created: The internal function `_papplMainloopGetServerPath()` takes the environment variable `TMPDIR` and in this directory a file named by the Printer Application itself with the **user ID of the caller** added and the extension `.sock`.

Now in my Snap environment the server is running as root, for making the printer available system-wide. The client instances of `ps-printer-app` are run by normal users and so they use a socket file name with the calling user's user IDs, and not the same as the server.

So what I want to ask for is that either
- the socket file name can be supplied by a command line option or environment variable, this I could supply in the wrapper script `scripts/run-ps-printer-app`.
- at build time one can choose between a user/developer mode (current behavior) and a system mode (socket file name without user ID)","Printer Application server running as root not accessible for users I want to run the PostScript Printer Application in a Snap, the Snap auto-starting the Printer Application via `daemon: simple` in the `snapcraft.yaml`. This makes the Printer Application server running as root, which is as designed in the Snap world, system daemons run as root. I can, as any normal user, without problems add and configure printers and add user PPD files via the web interface, and I can print with CUPS using CUPS' temporary queues for IPP printers. What does not work is using `ps-printer-app` for client operations (with subcommands ""printers"", ""jobs"",...) as a normal user, only as root `ps-printer-app` works as a client, but as normal user the problem is not a ""Permission denied"" but the server is simply not found. Even worse is that one does not simply get an error message but the client `ps-printer-app` starts another, personal server for the user leading to complete confusion (another bug, issue #149). The problem is how the socket file name is created: The internal function `_papplMainloopGetServerPath()` takes the environment variable `TMPDIR` and in this directory a file named by the Printer Application itself with the **user ID of the caller** added and the extension `.sock`. Now in my Snap environment the server is running as root, for making the printer available system-wide. The client instances of `ps-printer-app` are run by normal users and so they use a socket file name with the calling user's user IDs, and not the same as the server. So what I want to ask for is that either - the socket file name can be supplied by a command line option or environment variable, this I could supply in the wrapper script `scripts/run-ps-printer-app`. - at build time one can choose between a user/developer mode (current behavior) and a system mode (socket file name without user ID)"
720836,720836,801119,https://api.github.com/repos/WU-BIMAC/MicroMetaApp-React/issues/357,0.0,2021-04-01T22:11:47Z,MEMBER,https://api.github.com/repos/WU-BIMAC/MicroMetaApp-React,[BUG] MANAGE INSTRUMENT--> v46-1 attempt to open file from v42-1,"**Describe the bug**
Using v46-1 attempting to a file from 42-1 and also 44-0

**To Reproduce**
Steps to reproduce the behavior:
1. Launch app
2. Load from repo
3. ERROR 

**Desktop (please complete the following information):**
 - OS: MaOS
 - Version 46-1

**Additional context**

- **file from v42-1**

[COLEMAN_single_molecule_tracker_7_2021-03-09.txt](https://github.com/WU-BIMAC/MicroMetaApp-React/files/6246706/COLEMAN_single_molecule_tracker_7_2021-03-09.txt)

- **file from v44-0**

[FAKLARIS_andor_dragonfly_200_spinning_disk.txt](https://github.com/WU-BIMAC/MicroMetaApp-React/files/6246737/FAKLARIS_andor_dragonfly_200_spinning_disk.txt)
",[BUG] MANAGE INSTRUMENT--> v46-1 attempt to open file from v42-1 **Describe the bug** Using v46-1 attempting to a file from 42-1 and also 44-0 **To Reproduce** Steps to reproduce the behavior: 1. Launch app 2. Load from repo 3. ERROR **Desktop (please complete the following information):** - OS: MaOS - Version 46-1 **Additional context** - **file from v42-1** [COLEMAN_single_molecule_tracker_7_2021-03-09.txt](https://github.com/WU-BIMAC/MicroMetaApp-React/files/6246706/COLEMAN_single_molecule_tracker_7_2021-03-09.txt) - **file from v44-0** [FAKLARIS_andor_dragonfly_200_spinning_disk.txt](https://github.com/WU-BIMAC/MicroMetaApp-React/files/6246737/FAKLARIS_andor_dragonfly_200_spinning_disk.txt) 
769807,769807,467329,https://api.github.com/repos/metanorma/stepmod2mn/issues/17,1.0,2021-03-03T03:12:48Z,NONE,https://api.github.com/repos/metanorma/stepmod2mn,SVG conversion changes with new style,"Right now the SVGs built have this format:

```svg
<svg xmlns=""http://www.w3.org/2000/svg"" xlink=""http://www.w3.org/1999/xlink"" space=""preserve"" style=""enable-background:new 0 0 595.28 841.89;"" viewBox=""0 0 368 315"" y=""0px"" x=""0px"" id=""Layer_1"" version=""1.1"">
			<style type=""text/css"">.st0{fill:#FFFFFF;stroke:#000000;stroke-miterlimit:10;opacity:0}</style>
			<image xlink:href=""data:image/gif;base64,..."" height=""315"" width=""368"" style=""overflow:visible;""></image>
			<a xlink:href=""#basic_attribute_schema""><rect height=""41"" width=""133"" class=""st0"" y=""186"" x=""210""></rect></a><a xlink:href=""#action_schema""><rect height=""41"" width=""86"" class=""st0"" y=""10"" x=""10""></rect></a><a xlink:href=""#support_resource_schema""><rect height=""41"" width=""148"" class=""st0"" y=""264"" x=""210""></rect></a>
		</svg>
```

We need to make these changes:
1. Remove `xlink` ns and also replace `xlink:href` with just `href`
2. For the shapes, add `onmouseout=""this.style.opacity=0"" onmouseover=""this.style.opacity=1"" style=""opacity: 0; fill: rgb(33, 128, 255); fill-opacity: 0.3; stroke: rgb(0, 128, 255); stroke-width: 1px; stroke-linecap: butt; stroke-linejoin: miter; stroke-opacity: 1;""`
  * In the future we would want to use CSS to style these but it's not easy right now.
3. Remove `<style type=""text/css"">.st0{fill:#FFFFFF;stroke:#000000;stroke-miterlimit:10;opacity:0}</style>` because SVG classes are unscoped, they pollute the main CSS namespace with multiple definitions of `.st0`.

This is done in conjunction with metanorma/annotated-express#21.","SVG conversion changes with new style Right now the SVGs built have this format: ```svg <svg xmlns=""http://www.w3.org/2000/svg"" xlink=""http://www.w3.org/1999/xlink"" space=""preserve"" style=""enable-background:new 0 0 595.28 841.89;"" viewBox=""0 0 368 315"" y=""0px"" x=""0px"" id=""Layer_1"" version=""1.1""> <style type=""text/css"">.st0{fill:#FFFFFF;stroke:#000000;stroke-miterlimit:10;opacity:0}</style> <image xlink:href=""data:image/gif;base64,..."" height=""315"" width=""368"" style=""overflow:visible;""></image> <a xlink:href=""#basic_attribute_schema""><rect height=""41"" width=""133"" class=""st0"" y=""186"" x=""210""></rect></a><a xlink:href=""#action_schema""><rect height=""41"" width=""86"" class=""st0"" y=""10"" x=""10""></rect></a><a xlink:href=""#support_resource_schema""><rect height=""41"" width=""148"" class=""st0"" y=""264"" x=""210""></rect></a> </svg> ``` We need to make these changes: 1. Remove `xlink` ns and also replace `xlink:href` with just `href` 2. For the shapes, add `onmouseout=""this.style.opacity=0"" onmouseover=""this.style.opacity=1"" style=""opacity: 0; fill: rgb(33, 128, 255); fill-opacity: 0.3; stroke: rgb(0, 128, 255); stroke-width: 1px; stroke-linecap: butt; stroke-linejoin: miter; stroke-opacity: 1;""` * In the future we would want to use CSS to style these but it's not easy right now. 3. Remove `<style type=""text/css"">.st0{fill:#FFFFFF;stroke:#000000;stroke-miterlimit:10;opacity:0}</style>` because SVG classes are unscoped, they pollute the main CSS namespace with multiple definitions of `.st0`. This is done in conjunction with metanorma/annotated-express#21."
584609,584609,649659,https://api.github.com/repos/s3prl/s3prl/issues/76,1.0,2021-02-03T00:09:45Z,NONE,https://api.github.com/repos/s3prl/s3prl,tqdm.auto instead of tqdm,"Hi! Is it possible to make scripts using loop visualisation with tqdm more platform independent? For now, `runner.py` train method uses nested tqdm, which results in wrong output with many lines (for jupyter notebooks):
```
...
overall:  24% 23765/100000 [42:32<2:06:44, 10.02it/s]
overall:  24% 23767/100000 [42:32<2:02:27, 10.38it/s]
overall:  24% 23769/100000 [42:32<2:09:15,  9.83it/s]
overall:  24% 23771/100000 [42:33<2:04:34, 10.20it/s]
overall:  24% 23773/100000 [42:33<2:03:56, 10.25it/s]
overall:  24% 23775/100000 [42:33<2:01:58, 10.42it/s]
overall:  24% 23777/100000 [42:33<2:15:19,  9.39it/s]
overall:  24% 23779/100000 [42:33<2:05:46, 10.10it/s]
overall:  24% 23781/100000 [42:34<2:19:19,  9.12it/s]
overall:  24% 23782/100000 [42:34<2:18:51,  9.15it/s]
overall:  24% 23783/100000 [42:34<2:22:18,  8.93it/s]
overall:  24% 23784/100000 [42:34<2:19:59,  9.07it/s]
overall:  24% 23786/100000 [42:34<2:14:33,  9.44it/s]
overall:  24% 23787/100000 [42:34<2:13:22,  9.52it/s]
train: 100% 231/231 [00:24<00:00,  9.49it/s]

overall:  24% 23789/100000 [42:35<4:15:25,  4.97it/s]
overall:  24% 23790/100000 [42:35<3:46:34,  5.61it/s]
overall:  24% 23791/100000 [42:35<3:18:58,  6.38it/s]
overall:  24% 23793/100000 [42:36<2:55:28,  7.24it/s]
overall:  24% 23794/100000 [42:36<2:43:26,  7.77it/s]
overall:  24% 23796/100000 [42:36<2:25:14,  8.74it/s]
overall:  24% 23798/100000 [42:36<2:22:38,  8.90it/s]
overall:  24% 23800/100000 [42:36<2:14:05,  9.47it/s]
overall:  24% 23802/100000 [42:36<2:03:32, 10.28it/s]
overall:  24% 23804/100000 [42:37<2:02:08, 10.40it/s]
overall:  24% 23806/100000 [42:37<2:07:54,  9.93it/s]
overall:  24% 23808/100000 [42:37<2:19:42,  9.09i
```

This behaviour was seen on google colab.

Possible solution was mentioned in https://github.com/tqdm/tqdm/issues/375 issue.

","tqdm.auto instead of tqdm Hi! Is it possible to make scripts using loop visualisation with tqdm more platform independent? For now, `runner.py` train method uses nested tqdm, which results in wrong output with many lines (for jupyter notebooks): ``` ... overall: 24% 23765/100000 [42:32<2:06:44, 10.02it/s] overall: 24% 23767/100000 [42:32<2:02:27, 10.38it/s] overall: 24% 23769/100000 [42:32<2:09:15, 9.83it/s] overall: 24% 23771/100000 [42:33<2:04:34, 10.20it/s] overall: 24% 23773/100000 [42:33<2:03:56, 10.25it/s] overall: 24% 23775/100000 [42:33<2:01:58, 10.42it/s] overall: 24% 23777/100000 [42:33<2:15:19, 9.39it/s] overall: 24% 23779/100000 [42:33<2:05:46, 10.10it/s] overall: 24% 23781/100000 [42:34<2:19:19, 9.12it/s] overall: 24% 23782/100000 [42:34<2:18:51, 9.15it/s] overall: 24% 23783/100000 [42:34<2:22:18, 8.93it/s] overall: 24% 23784/100000 [42:34<2:19:59, 9.07it/s] overall: 24% 23786/100000 [42:34<2:14:33, 9.44it/s] overall: 24% 23787/100000 [42:34<2:13:22, 9.52it/s] train: 100% 231/231 [00:24<00:00, 9.49it/s] overall: 24% 23789/100000 [42:35<4:15:25, 4.97it/s] overall: 24% 23790/100000 [42:35<3:46:34, 5.61it/s] overall: 24% 23791/100000 [42:35<3:18:58, 6.38it/s] overall: 24% 23793/100000 [42:36<2:55:28, 7.24it/s] overall: 24% 23794/100000 [42:36<2:43:26, 7.77it/s] overall: 24% 23796/100000 [42:36<2:25:14, 8.74it/s] overall: 24% 23798/100000 [42:36<2:22:38, 8.90it/s] overall: 24% 23800/100000 [42:36<2:14:05, 9.47it/s] overall: 24% 23802/100000 [42:36<2:03:32, 10.28it/s] overall: 24% 23804/100000 [42:37<2:02:08, 10.40it/s] overall: 24% 23806/100000 [42:37<2:07:54, 9.93it/s] overall: 24% 23808/100000 [42:37<2:19:42, 9.09i ``` This behaviour was seen on google colab. Possible solution was mentioned in https://github.com/tqdm/tqdm/issues/375 issue. "
656912,656912,730190,https://api.github.com/repos/apache/openwhisk-catalog/issues/78,1.0,2016-07-13T05:14:37Z,MEMBER,https://api.github.com/repos/apache/openwhisk-catalog,Current build.gradle doesn't work for IDE environment,"According to PR #68 comment, current build.gradle doesn't work for Eclipse. We shall improve it in the future.
","Current build.gradle doesn't work for IDE environment According to PR #68 comment, current build.gradle doesn't work for Eclipse. We shall improve it in the future. "
262467,262467,291904,https://api.github.com/repos/304s/hello-world304/issues/1,0.0,2021-01-24T20:29:02Z,OWNER,https://api.github.com/repos/304s/hello-world304,For a https:/.github.com/org/repo/issues/n,I'm in need of a url,For a https:/.github.com/org/repo/issues/n I'm in need of a url
435756,435756,484435,https://api.github.com/repos/90poe/vscode-cy-helper/issues/33,1.0,2021-01-05T11:53:18Z,NONE,https://api.github.com/repos/90poe/vscode-cy-helper,Open VSX Listing: Signing the Publisher Agreement,"Thank you for being part of the Open VSX community by adding your extensions to the Open VSX Registry. Please note that the service was recently transferred to the Eclipse Foundation and urgent action on your part is needed so we can continue to list your extensions. To ensure uninterrupted service, please sign the [Eclipse Publisher Agreement](https://www.eclipse.org/legal/documents/eclipse-openvsx-publisher-agreement.pdf) **on or before January 8, 2021**. If not signed by that date, your extensions will be delisted and will no longer appear on the site nor be available via the API. If you sign at a later date, your extensions will then be re-activated. The signing process is [explained in the Wiki](https://github.com/eclipse/openvsx/wiki/Publishing-Extensions) (steps 1 and 2).

Please also note that all extensions MUST have a license in order to be listed.

More details are in these recent blog posts:
https://blogs.eclipse.org/post/brian-king/open-vsx-registry-under-new-management
https://blogs.eclipse.org/post/brian-king/new-era-open-vsx-registry

Today, theres growing momentum around open source tools and technologies that support Visual Studio (VS) Code extensions. Leading global organizations are adopting these tools and technologies. This momentum has spurred demand for a marketplace without restrictions and limitations. Thanks for joining us on this journey as we continue to build the Open VSX community. We look forward to continued innovation from you in 2021!
","Open VSX Listing: Signing the Publisher Agreement Thank you for being part of the Open VSX community by adding your extensions to the Open VSX Registry. Please note that the service was recently transferred to the Eclipse Foundation and urgent action on your part is needed so we can continue to list your extensions. To ensure uninterrupted service, please sign the [Eclipse Publisher Agreement](https://www.eclipse.org/legal/documents/eclipse-openvsx-publisher-agreement.pdf) **on or before January 8, 2021**. If not signed by that date, your extensions will be delisted and will no longer appear on the site nor be available via the API. If you sign at a later date, your extensions will then be re-activated. The signing process is [explained in the Wiki](https://github.com/eclipse/openvsx/wiki/Publishing-Extensions) (steps 1 and 2). Please also note that all extensions MUST have a license in order to be listed. More details are in these recent blog posts: https://blogs.eclipse.org/post/brian-king/open-vsx-registry-under-new-management https://blogs.eclipse.org/post/brian-king/new-era-open-vsx-registry Today, theres growing momentum around open source tools and technologies that support Visual Studio (VS) Code extensions. Leading global organizations are adopting these tools and technologies. This momentum has spurred demand for a marketplace without restrictions and limitations. Thanks for joining us on this journey as we continue to build the Open VSX community. We look forward to continued innovation from you in 2021! "
712320,712320,791684,https://api.github.com/repos/dmontagu/fastapi-utils/issues/85,0.0,2020-07-24T11:55:58Z,NONE,https://api.github.com/repos/dmontagu/fastapi-utils,CBV Router fails when path is empty,"**Describe the bug**
When the router path is empty string, cbv router fails.

```python
  File ""./test.py"", line 11, in <module>
    @cbv(router)
  File ""/Users/vinod/.pyenv/versions/3.6.10/envs/test/lib/python3.6/site-packages/fastapi_utils/cbv.py"", line 26, in decorator
    return _cbv(router, cls)
  File ""/Users/vinod/.pyenv/versions/3.6.10/envs/test/lib/python3.6/site-packages/fastapi_utils/cbv.py"", line 49, in _cbv
    router.include_router(cbv_router)
  File ""/Users/vinod/.pyenv/versions/3.6.10/envs/test/lib/python3.6/site-packages/fastapi/routing.py"", line 584, in include_router
    f""Prefix and path cannot be both empty (path operation: {name})""
Exception: Prefix and path cannot be both empty (path operation: get_items)

```

**To Reproduce**
Steps to reproduce the behavior:
1. Create a file `test.py`:
```python
from fastapi import APIRouter
from fastapi import FastAPI
from fastapi_utils.cbv import cbv

main_router = APIRouter()
child_router = APIRouter()


@cbv(child_router)
class MyClass:
    @child_router.get("""")
    def get_items(self):
        return {""hello"": ""world""}


main_router.include_router(child_router, prefix=""/items"")


app = FastAPI()
app.include_router(main_router)
```
2. Start the server with `uvicorn --reload test:app`

**Expected behavior**
The uvicorn server to start normally. The end point `http://localhost:8000/items` should return `{""hello"": ""world""}`

**Environment:**
 - OS: [e.g. macOS]
 - FastAPI Utils, FastAPI, and Pydantic versions 
    - fastapi==0.55.1
    - fastapi-utils==0.2.1
    - pydantic==1.4

- Python version: 3.6.10


**Additional context**
This is because because the cbv helper is including a third router under child router. FastAPI throws an error when both path and prefix are empty. 
If I use `@child_router.get(""/"")` instead of `@child_router.get("""")` and it is working. FastAPI responds with 307 to redirect the user to right endpoint. Since some http clients are not handling 307 correctly, is there a way to support empty path strings with cbv.
","CBV Router fails when path is empty **Describe the bug** When the router path is empty string, cbv router fails. ```python File ""./test.py"", line 11, in <module> @cbv(router) File ""/Users/vinod/.pyenv/versions/3.6.10/envs/test/lib/python3.6/site-packages/fastapi_utils/cbv.py"", line 26, in decorator return _cbv(router, cls) File ""/Users/vinod/.pyenv/versions/3.6.10/envs/test/lib/python3.6/site-packages/fastapi_utils/cbv.py"", line 49, in _cbv router.include_router(cbv_router) File ""/Users/vinod/.pyenv/versions/3.6.10/envs/test/lib/python3.6/site-packages/fastapi/routing.py"", line 584, in include_router f""Prefix and path cannot be both empty (path operation: {name})"" Exception: Prefix and path cannot be both empty (path operation: get_items) ``` **To Reproduce** Steps to reproduce the behavior: 1. Create a file `test.py`: ```python from fastapi import APIRouter from fastapi import FastAPI from fastapi_utils.cbv import cbv main_router = APIRouter() child_router = APIRouter() @cbv(child_router) class MyClass: @child_router.get("""") def get_items(self): return {""hello"": ""world""} main_router.include_router(child_router, prefix=""/items"") app = FastAPI() app.include_router(main_router) ``` 2. Start the server with `uvicorn --reload test:app` **Expected behavior** The uvicorn server to start normally. The end point `http://localhost:8000/items` should return `{""hello"": ""world""}` **Environment:** - OS: [e.g. macOS] - FastAPI Utils, FastAPI, and Pydantic versions - fastapi==0.55.1 - fastapi-utils==0.2.1 - pydantic==1.4 - Python version: 3.6.10 **Additional context** This is because because the cbv helper is including a third router under child router. FastAPI throws an error when both path and prefix are empty. If I use `@child_router.get(""/"")` instead of `@child_router.get("""")` and it is working. FastAPI responds with 307 to redirect the user to right endpoint. Since some http clients are not handling 307 correctly, is there a way to support empty path strings with cbv. "
470650,470650,523085,https://api.github.com/repos/qawolf/qawolf/issues/900,0.0,2021-01-14T18:19:01Z,CONTRIBUTOR,https://api.github.com/repos/qawolf/qawolf,Support case sensitive URLs,"## Bug description

If you paste a case sensitive URL in the input, when the code is generated it is changed.

## Steps to reproduce

1. Paste a case sensitive URL into the create modal
2. Notice code has a different URL

#### Thank you for reporting this bug 
","Support case sensitive URLs ## Bug description If you paste a case sensitive URL in the input, when the code is generated it is changed. ## Steps to reproduce 1. Paste a case sensitive URL into the create modal 2. Notice code has a different URL #### Thank you for reporting this bug  "
682479,682479,758507,https://api.github.com/repos/koichi-murakami/kut/issues/25,1.0,2021-03-05T03:11:04Z,OWNER,https://api.github.com/repos/koichi-murakami/kut,add mutex lock for time counting,add mutex lock for showing time information for multi-threading purposes.,add mutex lock for time counting add mutex lock for showing time information for multi-threading purposes.
583754,583754,648691,https://api.github.com/repos/Mzaien/next-redirects/issues/1,1.0,2021-03-12T20:30:06Z,OWNER,https://api.github.com/repos/Mzaien/next-redirects,Back button goes to other pages ,When the user presses the back button he goes to the second last page due to using router.replace which is not good tbh,Back button goes to other pages When the user presses the back button he goes to the second last page due to using router.replace which is not good tbh
251958,251958,280257,https://api.github.com/repos/elastic/beats/issues/12865,1.0,2019-07-11T08:56:51Z,CONTRIBUTOR,https://api.github.com/repos/elastic/beats,Add more helpful logs for beats enrollment with central management,"**Describe the enhancement:** The messages logged by a beat (e.g filebeat 7.2.0) are not really useful for troubleshooting issues with the beats enrollment. Ideally, the logs messages should be helpful and more intuitive.

**Describe a specific use case for the enhancement or feature:**

Examples are extracted from this [GH enhancement issue](https://github.com/elastic/beats/issues/12863). 

### Example 1

Running the enroll command (when Kibana uses TLS/SSL) without configuring filebeat to use the CA certificate:

```bash
filebeat -e -v -d ""*"" enroll https://kibana_url:5601 --username myuser --password stdin
<some debug logs>
This will replace your current settings. Do you want to continue? [Y/n]:Y
Enter password: 
<some debug logs>
Error creating a new enrollment token: fail to execute the HTTP POST request: Post https://kibana_url:5601/api/beats/enrollment_tokens: x509: certificate signed by unknown authority
```

The error message is confusing. CA certificate configuration is missing in this example but the error message refers to a `certificate signed by unknown authority`.

### Example 2

When running the beat enrollment command, adding a ""/"" after the port number in the Kibana URL (eg. https://kibana_url:5601/) will result in the beat enrollment failure. An error is logged: `Error creating a new enrollment token: error while parsing Kibana response: json: cannot unmarshal string into Go struct field BaseResponse.error of type api.ErrorResponse`

The error message is cryptic. It is unrelated to the ""incorrect"" Kibana URL.

### Example 3:

Incorrect credentials (e.g incorrect password) will result in the beat enrollment failure. An error is logged: `Error creating a new enrollment token: error while parsing Kibana response: json: cannot unmarshal string into Go struct field BaseResponse.error of type api.ErrorResponse.`

The error message is also cryptic. It is unrelated to the authentication failure. Take note that the authentication failure is logged in the Kibana logs.

### Others scenarios

I have not tested these but I can think of a few other scenarios:
- Kibana is unreachable.
- Roles/permissions issues when using `myuser` in the command line.
- Certificates issues (expired certificate, unsupported format, etc.).
- Incorrect settings in the command line (incorrect files paths, unknown settings, etc.).
- Incorrect settings in the filebeat.yml file (incorrect files paths, unknown settings, etc.).","Add more helpful logs for beats enrollment with central management **Describe the enhancement:** The messages logged by a beat (e.g filebeat 7.2.0) are not really useful for troubleshooting issues with the beats enrollment. Ideally, the logs messages should be helpful and more intuitive. **Describe a specific use case for the enhancement or feature:** Examples are extracted from this [GH enhancement issue](https://github.com/elastic/beats/issues/12863). ### Example 1 Running the enroll command (when Kibana uses TLS/SSL) without configuring filebeat to use the CA certificate: ```bash filebeat -e -v -d ""*"" enroll https://kibana_url:5601 --username myuser --password stdin <some debug logs> This will replace your current settings. Do you want to continue? [Y/n]:Y Enter password: <some debug logs> Error creating a new enrollment token: fail to execute the HTTP POST request: Post https://kibana_url:5601/api/beats/enrollment_tokens: x509: certificate signed by unknown authority ``` The error message is confusing. CA certificate configuration is missing in this example but the error message refers to a `certificate signed by unknown authority`. ### Example 2 When running the beat enrollment command, adding a ""/"" after the port number in the Kibana URL (eg. https://kibana_url:5601/) will result in the beat enrollment failure. An error is logged: `Error creating a new enrollment token: error while parsing Kibana response: json: cannot unmarshal string into Go struct field BaseResponse.error of type api.ErrorResponse` The error message is cryptic. It is unrelated to the ""incorrect"" Kibana URL. ### Example 3: Incorrect credentials (e.g incorrect password) will result in the beat enrollment failure. An error is logged: `Error creating a new enrollment token: error while parsing Kibana response: json: cannot unmarshal string into Go struct field BaseResponse.error of type api.ErrorResponse.` The error message is also cryptic. It is unrelated to the authentication failure. Take note that the authentication failure is logged in the Kibana logs. ### Others scenarios I have not tested these but I can think of a few other scenarios: - Kibana is unreachable. - Roles/permissions issues when using `myuser` in the command line. - Certificates issues (expired certificate, unsupported format, etc.). - Incorrect settings in the command line (incorrect files paths, unknown settings, etc.). - Incorrect settings in the filebeat.yml file (incorrect files paths, unknown settings, etc.)."
220890,220890,245643,https://api.github.com/repos/jon-perez18/Foodies/issues/2,1.0,2021-04-09T17:46:03Z,OWNER,https://api.github.com/repos/jon-perez18/Foodies,Login Page: Get and display users name from Google,,Login Page: Get and display users name from Google 
389977,389977,433478,https://api.github.com/repos/DLR-RM/stable-baselines3/issues/410,2.0,2021-04-28T12:52:36Z,NONE,https://api.github.com/repos/DLR-RM/stable-baselines3,Logging addional values from info dictionary in evaluate_policy in EvalCallback,"### Question
Hi there, 
First of all thanks a lot for this great repo, I really like it. My question is basically if there is a very simple way to log (e.g. for tensorboard) additonal metrics that are contained in the info buffer during the evaluate_policy function that is called in the EvalCallback during training? 

Let me explain what I mean in more detail. I am fully aware that if I call evaluate_policy on its own (after training for e.g.) I can pass a Callback function which then accesses the info field and logs additional metrics. However I feel like this is not possible during training. I would like to use the default way of evaluating my policy that is provided by you, i.e. i pass an environment to eval_env field of the learn() function. This will then create an EvalCallback class which in turn calls evaluate_policy in the _on_step function. evaluate_policy does actually have the info field, but does not return it. Which means EvalCallback has no way of accessing the info field that is produces in evaluate_policy and there is no way of logging additional metrics that are contained in the info field (as far as I can tell). 

Now yes I could completely rewrite the EvalCallback class and make sure that it passes another callback to evaluate_policy such that I can log additional metrics. However i feel like this is not the best option because I would have to copy and paste a lot of your code in order to change a small thing. Also I feel like it's safer to use the default way provided by you. So to sum up I believe that there probably is a simple way of doing it, but I am really not aware of how to do it. 

One idea I had was to wrap my evaluation environment into the Monitor class and then log certain things from there into a file and later on read it back from a different callback. But I am not sure if that is the best option. 

Update: I tried out my idea and it would work in principle. But at the end I realized that the Monitor class in the step() function only logs certain info fields when the episode is over, i.e. it does not allow one to sum up all the episode rewards and log them . 

thanks for your help 
","Logging addional values from info dictionary in evaluate_policy in EvalCallback ### Question Hi there, First of all thanks a lot for this great repo, I really like it. My question is basically if there is a very simple way to log (e.g. for tensorboard) additonal metrics that are contained in the info buffer during the evaluate_policy function that is called in the EvalCallback during training? Let me explain what I mean in more detail. I am fully aware that if I call evaluate_policy on its own (after training for e.g.) I can pass a Callback function which then accesses the info field and logs additional metrics. However I feel like this is not possible during training. I would like to use the default way of evaluating my policy that is provided by you, i.e. i pass an environment to eval_env field of the learn() function. This will then create an EvalCallback class which in turn calls evaluate_policy in the _on_step function. evaluate_policy does actually have the info field, but does not return it. Which means EvalCallback has no way of accessing the info field that is produces in evaluate_policy and there is no way of logging additional metrics that are contained in the info field (as far as I can tell). Now yes I could completely rewrite the EvalCallback class and make sure that it passes another callback to evaluate_policy such that I can log additional metrics. However i feel like this is not the best option because I would have to copy and paste a lot of your code in order to change a small thing. Also I feel like it's safer to use the default way provided by you. So to sum up I believe that there probably is a simple way of doing it, but I am really not aware of how to do it. One idea I had was to wrap my evaluation environment into the Monitor class and then log certain things from there into a file and later on read it back from a different callback. But I am not sure if that is the best option. Update: I tried out my idea and it would work in principle. But at the end I realized that the Monitor class in the step() function only logs certain info fields when the episode is over, i.e. it does not allow one to sum up all the episode rewards and log them . thanks for your help "
336452,336452,374005,https://api.github.com/repos/kaakaa/mattermost-plugin-reacji/issues/11,1.0,2021-04-09T05:02:15Z,OWNER,https://api.github.com/repos/kaakaa/mattermost-plugin-reacji,"Enable to specify all public channels for ""from channel""",,"Enable to specify all public channels for ""from channel"" "
518102,518102,575784,https://api.github.com/repos/NVIDIA/DALI/issues/2818,0.0,2021-03-26T08:52:15Z,NONE,https://api.github.com/repos/NVIDIA/DALI,bug: program get stuck when use ops.videoreader read a mp4 file,"Hi there, here my program (dali videoreader) always get stuck when processing the mp4 files down below, is there any solutions for this.

heres the mp4 file urls:
https://drive.google.com/file/d/1qCTHlgXtb22tZtfr06KNW8jAUyLBwc1q/view?usp=sharing
https://drive.google.com/file/d/1BdppV7x9hih7WQJyLw1cKGC_xdFklhVT/view?usp=sharing
https://drive.google.com/file/d/1ExxpvKzwqpheSqZz4QrxerThi1KA5KJx/view?usp=sharing
https://drive.google.com/file/d/1_kBufPCndOW9iQ4MgPK-cItAy9AnFEYt/view?usp=sharing
https://drive.google.com/file/d/1_kBufPCndOW9iQ4MgPK-cItAy9AnFEYt/view?usp=sharing

here's my code:
```python
import os
import cv2
import math
from nvidia.dali.pipeline import Pipeline
import nvidia.dali.ops as ops


class VideoPipe(Pipeline):
    def __init__(self, batch_size, num_threads, device_id, filenames, shuffle, sequence_length, step, stride):
        super(VideoPipe, self).__init__(batch_size, num_threads, device_id, seed=16)
        self.input = ops.VideoReader(device=""gpu"", filenames=filenames, sequence_length=sequence_length,
                                     shard_id=0, num_shards=1,
                                     random_shuffle=shuffle, skip_vfr_check=True, read_ahead=True, step=step,
                                     stride=stride)

    def define_graph(self):
        output = self.input(name=""Reader"") 
        return output


video_filename = ""test.mp4""
cap = cv2.VideoCapture(video_filename)
video_total_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)
video_fps = int(cap.get(cv2.CAP_PROP_FPS))
cap.release()

# extract a frame per 2 seconds
sequence_length = 2 * video_fps
max_round_count = min(math.floor(video_total_count / sequence_length), 30)
dali_pipe = VideoPipe(batch_size=1, num_threads=4, device_id=0, filenames=video_filename,
                      shuffle=False, sequence_length=1, stride=1, step=sequence_length)
dali_pipe.build()
for i in range(max_round_count):
    dali_out_gpu, = dali_pipe.run()
    dali_out_cpu = dali_out_gpu.as_cpu().as_array()
    print(dali_out_cpu.shape)


```
","bug: program get stuck when use ops.videoreader read a mp4 file Hi there, here my program (dali videoreader) always get stuck when processing the mp4 files down below, is there any solutions for this. heres the mp4 file urls: https://drive.google.com/file/d/1qCTHlgXtb22tZtfr06KNW8jAUyLBwc1q/view?usp=sharing https://drive.google.com/file/d/1BdppV7x9hih7WQJyLw1cKGC_xdFklhVT/view?usp=sharing https://drive.google.com/file/d/1ExxpvKzwqpheSqZz4QrxerThi1KA5KJx/view?usp=sharing https://drive.google.com/file/d/1_kBufPCndOW9iQ4MgPK-cItAy9AnFEYt/view?usp=sharing https://drive.google.com/file/d/1_kBufPCndOW9iQ4MgPK-cItAy9AnFEYt/view?usp=sharing here's my code: ```python import os import cv2 import math from nvidia.dali.pipeline import Pipeline import nvidia.dali.ops as ops class VideoPipe(Pipeline): def __init__(self, batch_size, num_threads, device_id, filenames, shuffle, sequence_length, step, stride): super(VideoPipe, self).__init__(batch_size, num_threads, device_id, seed=16) self.input = ops.VideoReader(device=""gpu"", filenames=filenames, sequence_length=sequence_length, shard_id=0, num_shards=1, random_shuffle=shuffle, skip_vfr_check=True, read_ahead=True, step=step, stride=stride) def define_graph(self): output = self.input(name=""Reader"") return output video_filename = ""test.mp4"" cap = cv2.VideoCapture(video_filename) video_total_count = cap.get(cv2.CAP_PROP_FRAME_COUNT) video_fps = int(cap.get(cv2.CAP_PROP_FPS)) cap.release() # extract a frame per 2 seconds sequence_length = 2 * video_fps max_round_count = min(math.floor(video_total_count / sequence_length), 30) dali_pipe = VideoPipe(batch_size=1, num_threads=4, device_id=0, filenames=video_filename, shuffle=False, sequence_length=1, stride=1, step=sequence_length) dali_pipe.build() for i in range(max_round_count): dali_out_gpu, = dali_pipe.run() dali_out_cpu = dali_out_gpu.as_cpu().as_array() print(dali_out_cpu.shape) ``` "
541567,541567,601932,https://api.github.com/repos/ehrbase/openEHR_SDK/issues/173,0.0,2021-02-08T19:16:17Z,NONE,https://api.github.com/repos/ehrbase/openEHR_SDK,AqlToDtoParser seems to assume there is a contains clause,"## Configuration information

<!-- To reproduce your problem is is mandatory to give the following information. You can get all of
them in one step by starting the EHRbase and requesting a GET on 
`%ehrbaseBaseUri%/ehrbase/rest/openehr/v1/status`.  -->

- EHRbase version: ehrbaseorg/ehrbase:latest docker image (says 0.14.0 at startup)
- openEHR_SDK version: developer-SNAPSHOT
- Archie version: ?
- PostgreSQL version: ehrbaseorg/ehrbase-postgres:latest
- Java Runtime version: 11.0.9.1
- Operating System version: ubuntu 20.10

## Steps to reproduce ## 

Trying to parse and aql with (AqlDto dto = new AqlToDtoParser().parse(aql))) where the aql is ""SELECT e/ehr_id/value FROM EHR e"" gives:
org.ehrbase.aql.parser.AqlParseException: Index 1 out of bounds for length 0

	at org.ehrbase.aql.parser.AqlToDtoParser.parse(AqlToDtoParser.java:42)

But running it against ehrbase aql endpoint works fine

Seems the AqlToDtoVisitor on line 66 calls visitContainsExpression when the query doesn't have any contains clause, and the visitor method parses the boolList, but doesn't take into account the case where the list is empty. 

## Actual result ##

org.ehrbase.aql.parser.AqlParseException: Index 1 out of bounds for length 0

	at org.ehrbase.aql.parser.AqlToDtoParser.parse(AqlToDtoParser.java:42)

## Expected result (Acceptance Criteria) ##

valid AqlDto

## Definition of Done ##

<!-- These checklist entries are used by our developers to deliver a solution with a base quality
we want to acheive. If you want to add other points specific to this issue, put them into the section
""Expected result (Acceptance Criteria)"" -->

- [ ] The defect is checked by an unit or an integration test (Robot)
- [ ] Merge Request approved
- [ ] Unit tests passed
- [ ] Build without errors
- [ ] Release notes prepared
- [ ] No additional runtime warnings
","AqlToDtoParser seems to assume there is a contains clause ## Configuration information <!-- To reproduce your problem is is mandatory to give the following information. You can get all of them in one step by starting the EHRbase and requesting a GET on `%ehrbaseBaseUri%/ehrbase/rest/openehr/v1/status`. --> - EHRbase version: ehrbaseorg/ehrbase:latest docker image (says 0.14.0 at startup) - openEHR_SDK version: developer-SNAPSHOT - Archie version: ? - PostgreSQL version: ehrbaseorg/ehrbase-postgres:latest - Java Runtime version: 11.0.9.1 - Operating System version: ubuntu 20.10 ## Steps to reproduce ## Trying to parse and aql with (AqlDto dto = new AqlToDtoParser().parse(aql))) where the aql is ""SELECT e/ehr_id/value FROM EHR e"" gives: org.ehrbase.aql.parser.AqlParseException: Index 1 out of bounds for length 0 at org.ehrbase.aql.parser.AqlToDtoParser.parse(AqlToDtoParser.java:42) But running it against ehrbase aql endpoint works fine Seems the AqlToDtoVisitor on line 66 calls visitContainsExpression when the query doesn't have any contains clause, and the visitor method parses the boolList, but doesn't take into account the case where the list is empty. ## Actual result ## org.ehrbase.aql.parser.AqlParseException: Index 1 out of bounds for length 0 at org.ehrbase.aql.parser.AqlToDtoParser.parse(AqlToDtoParser.java:42) ## Expected result (Acceptance Criteria) ## valid AqlDto ## Definition of Done ## <!-- These checklist entries are used by our developers to deliver a solution with a base quality we want to acheive. If you want to add other points specific to this issue, put them into the section ""Expected result (Acceptance Criteria)"" --> - [ ] The defect is checked by an unit or an integration test (Robot) - [ ] Merge Request approved - [ ] Unit tests passed - [ ] Build without errors - [ ] Release notes prepared - [ ] No additional runtime warnings "
16391,16391,18271,https://api.github.com/repos/oneapi-src/oneDNN/issues/1000,2.0,2021-03-02T09:34:41Z,NONE,https://api.github.com/repos/oneapi-src/oneDNN,Can the libraries build for intel processors be used on AMD processor?,"Can the libraries build for intel processors be used on AMD processor ?
Do we need to  build the libraries separately for AMD processors or can we use the same libraries which were built for intel?",Can the libraries build for intel processors be used on AMD processor? Can the libraries build for intel processors be used on AMD processor ? Do we need to build the libraries separately for AMD processors or can we use the same libraries which were built for intel?
368506,368506,409651,https://api.github.com/repos/ibm-hcbt/terraform-ibm-cloud-pak/issues/7,0.0,2021-04-05T19:44:20Z,NONE,https://api.github.com/repos/ibm-hcbt/terraform-ibm-cloud-pak,ROKS with VPC fails when default isn't the target resource group,Code to create ibm_is_vpc resource is not assigning the resource group provided to the module,ROKS with VPC fails when default isn't the target resource group Code to create ibm_is_vpc resource is not assigning the resource group provided to the module
345638,345638,384240,https://api.github.com/repos/cloudintelligenceworkshop/cloudintelligenceworkshop.github.io/issues/19,1.0,2020-05-19T23:14:43Z,COLLABORATOR,https://api.github.com/repos/cloudintelligenceworkshop/cloudintelligenceworkshop.github.io,Move the featured image down some  30 minutes, the head of AI is cut off ,Move the featured image down some  30 minutes the head of AI is cut off 
274172,274172,304916,https://api.github.com/repos/frikky/Shuffle/issues/311,0.0,2021-03-22T13:12:25Z,OWNER,https://api.github.com/repos/frikky/Shuffle,Length handler contains bug,https://discord.com/channels/747075026288902237/747110765609222158/823539567864184882,Length handler contains bug https://discord.com/channels/747075026288902237/747110765609222158/823539567864184882
338736,338736,376553,https://api.github.com/repos/erlef/infra-wg/issues/55,2.0,2021-03-16T03:35:45Z,MEMBER,https://api.github.com/repos/erlef/infra-wg,Newsletter system split brain issue,"We kicked off with two newsletter systems (mailchimp and wildapricot) and we need  reduce to one in order to minimize the operative and administrative burdens that come with this, as well as confusion for members. 

 Mailchimp is nice, it's much nicer to work with IMO, but in order to really utilize it we would need to sync member email addresses to it and I'd prefer we not. 
 
Wildapricot is not as nice for creating newsletters, but it's there, it works, thus I'm in favor of just switching to it. I suggest changing the form to a link for joining us as well. The alternative is to add subscribes as contacts in wildapricot if we think a lot of people who wouldn't be members, subscribe to the news letter. But we also just post the newsletter on the site too, that's part of my rationale for wanting to it from subscribe form to a join us link. ","Newsletter system split brain issue We kicked off with two newsletter systems (mailchimp and wildapricot) and we need reduce to one in order to minimize the operative and administrative burdens that come with this, as well as confusion for members. Mailchimp is nice, it's much nicer to work with IMO, but in order to really utilize it we would need to sync member email addresses to it and I'd prefer we not. Wildapricot is not as nice for creating newsletters, but it's there, it works, thus I'm in favor of just switching to it. I suggest changing the form to a link for joining us as well. The alternative is to add subscribes as contacts in wildapricot if we think a lot of people who wouldn't be members, subscribe to the news letter. But we also just post the newsletter on the site too, that's part of my rationale for wanting to it from subscribe form to a join us link. "
98248,98248,109160,https://api.github.com/repos/JonathanGatti/bug-track/issues/7,0.0,2021-01-16T18:55:53Z,OWNER,https://api.github.com/repos/JonathanGatti/bug-track,fix render list bug,,fix render list bug 
219875,219875,244502,https://api.github.com/repos/vslinko/obsidian-outliner/issues/26,0.0,2021-03-28T22:16:27Z,NONE,https://api.github.com/repos/vslinko/obsidian-outliner,[BUG] Letters are duplicated when zoomed in,"
**Describe the bug**
Letters are duplicated when zoomed in.
release 1.0.11 is working fine. 1.0.12 is the first that has the problem.

**Screenshots**
![obsidian_outliner_duplicated_letters](https://user-images.githubusercontent.com/27488268/112769885-ea0e6880-9023-11eb-8ca8-20ea9e92bd8e.gif)
",[BUG] Letters are duplicated when zoomed in **Describe the bug** Letters are duplicated when zoomed in. release 1.0.11 is working fine. 1.0.12 is the first that has the problem. **Screenshots** ![obsidian_outliner_duplicated_letters](https://user-images.githubusercontent.com/27488268/112769885-ea0e6880-9023-11eb-8ca8-20ea9e92bd8e.gif) 
249291,249291,277285,https://api.github.com/repos/ziglang/zig/issues/7188,0.0,2020-11-21T20:36:49Z,NONE,https://api.github.com/repos/ziglang/zig,Permit expression parameter for comma-list switch case for simple values,"```zig
const std = @import(""std"");

pub fn main() void {
    var d: u8 = 'd';
    switch (d) {
        'a'...'c' => |c| std.debug.print(""abc ({c})\n"", .{c}),
        'd', 'e' => |c| std.debug.print(""de ({c})\n"", .{c}),
        else => |c| std.debug.print(""other ({c})\n"", .{c}),
    }
}
```

```
./repro_switch_capture.zig:7:22: error: switch on type 'u8' provides no expression parameter
        'd', 'e' => |c| std.debug.print(""de ({c})\n"", c),
```

```
쨩 zig version
0.7.0+39336fd2e
```

I believe that an expression parameter would be useful here as, just like in the range-of-values situation, it makes the task of figuring out which case was matched more succinct.

Zig 0.7.0 documentation demonstrates using this for a `union(enum)` type, so it's surprising that it doesn't work in the simpler case of a plain value:
```
    // Switching on more complex enums is allowed.
    const b = switch (a) {
        // A capture group is allowed on a match, and will return the enum
        // value matched. If the payload types of both cases are the same
        // they can be put into the same switch prong.
        Item.a, Item.e => |item| item,

        // A reference to the matched value can be obtained using `*` syntax.
        Item.c => |*item| blk: {
            item.*.x += 1;
            break :blk 6;
        },

        // No else is required if the types cases was exhaustively handled
        Item.d => 8,
    };
```

Additionally, the error can currently be bypassed by converting one of the comma-separated cases to a trivial range:
```
const std = @import(""std"");

pub fn main() void {
    var d: u8 = 'd';
    switch (d) {
        'a'...'c' => |c| std.debug.print(""abc ({c})\n"", .{c}),
        'd'...'d', 'e' => |c| std.debug.print(""de ({c})\n"", .{c}),
        else => |c| std.debug.print(""other ({c})\n"", .{c}),
    }
}
```","Permit expression parameter for comma-list switch case for simple values ```zig const std = @import(""std""); pub fn main() void { var d: u8 = 'd'; switch (d) { 'a'...'c' => |c| std.debug.print(""abc ({c})\n"", .{c}), 'd', 'e' => |c| std.debug.print(""de ({c})\n"", .{c}), else => |c| std.debug.print(""other ({c})\n"", .{c}), } } ``` ``` ./repro_switch_capture.zig:7:22: error: switch on type 'u8' provides no expression parameter 'd', 'e' => |c| std.debug.print(""de ({c})\n"", c), ``` ``` 쨩 zig version 0.7.0+39336fd2e ``` I believe that an expression parameter would be useful here as, just like in the range-of-values situation, it makes the task of figuring out which case was matched more succinct. Zig 0.7.0 documentation demonstrates using this for a `union(enum)` type, so it's surprising that it doesn't work in the simpler case of a plain value: ``` // Switching on more complex enums is allowed. const b = switch (a) { // A capture group is allowed on a match, and will return the enum // value matched. If the payload types of both cases are the same // they can be put into the same switch prong. Item.a, Item.e => |item| item, // A reference to the matched value can be obtained using `*` syntax. Item.c => |*item| blk: { item.*.x += 1; break :blk 6; }, // No else is required if the types cases was exhaustively handled Item.d => 8, }; ``` Additionally, the error can currently be bypassed by converting one of the comma-separated cases to a trivial range: ``` const std = @import(""std""); pub fn main() void { var d: u8 = 'd'; switch (d) { 'a'...'c' => |c| std.debug.print(""abc ({c})\n"", .{c}), 'd'...'d', 'e' => |c| std.debug.print(""de ({c})\n"", .{c}), else => |c| std.debug.print(""other ({c})\n"", .{c}), } } ```"
255095,255095,283731,https://api.github.com/repos/SparkeyG/Botler/issues/9,1.0,2021-02-21T20:37:39Z,OWNER,https://api.github.com/repos/SparkeyG/Botler,room_clean w/o email,Add option to clean a room w/o sending out an email.,room_clean w/o email Add option to clean a room w/o sending out an email.
138851,138851,154328,https://api.github.com/repos/cac765/iot-people-counter/issues/12,1.0,2021-01-11T19:21:27Z,OWNER,https://api.github.com/repos/cac765/iot-people-counter,MQTT connect to broker optional,"The --broker-ip flag should be an optional argument. When --broker-ip is not used, the script will not create an MQTT client instance and will not attempt to connect to a broker / publish to a topic, but instead just run locally and continue to print to a console. If the --broker-ip flag is used, the script should attempt to connect to the specified IP address as a broker, and publish messages to that broker. The --topic flag cannot be used without the --broker-ip flag.","MQTT connect to broker optional The --broker-ip flag should be an optional argument. When --broker-ip is not used, the script will not create an MQTT client instance and will not attempt to connect to a broker / publish to a topic, but instead just run locally and continue to print to a console. If the --broker-ip flag is used, the script should attempt to connect to the specified IP address as a broker, and publish messages to that broker. The --topic flag cannot be used without the --broker-ip flag."
800968,800968,778754,https://api.github.com/repos/IUDevman/gamesense-client/issues/302,0.0,2021-04-28T05:51:31Z,NONE,https://api.github.com/repos/IUDevman/gamesense-client,[BUG],"GUI is invisible
when i press o to open the GUI, my mouse pops up as if the gui was open, but i cant see it. i tried binding it to other keys but it doesnt change anything. 

**To Reproduce**
Steps to reproduce the behavior:
1. Go to '...'
2. Turn on '...'
3. Toggle '...'
4. See error

**Expected behavior**
A clear and concise description of what you expected to happen.

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Information:**
 - OS [e.g. Windows 10]
 - Version [e.g. 2.2.6]
 - Other mods used Kami Blue, Wurstplustwo]

**Additional context**
Add any other context about the problem here (e.g. screenshots, videos)
","[BUG] GUI is invisible when i press o to open the GUI, my mouse pops up as if the gui was open, but i cant see it. i tried binding it to other keys but it doesnt change anything. **To Reproduce** Steps to reproduce the behavior: 1. Go to '...' 2. Turn on '...' 3. Toggle '...' 4. See error **Expected behavior** A clear and concise description of what you expected to happen. **Screenshots** If applicable, add screenshots to help explain your problem. **Information:** - OS [e.g. Windows 10] - Version [e.g. 2.2.6] - Other mods used Kami Blue, Wurstplustwo] **Additional context** Add any other context about the problem here (e.g. screenshots, videos) "
279290,279290,310615,https://api.github.com/repos/libsdl-org/SDL/issues/3557,0.0,2021-02-11T01:50:16Z,COLLABORATOR,https://api.github.com/repos/libsdl-org/SDL,OpenGL renderer doesn't always enable GL_TEXTURE_2D,"
# This bug report was migrated from our old Bugzilla tracker.

**Reported in version:** HG 2.1
**Reported for operating system, platform:** AmigaOS, PowerPC

# Comments on the original bug report:

On 2020-02-21 08:10:59 +0000, Juha Niemim짚ki wrote:

> It seems that when SDL_UpdateTexture() is called in a draw loop, GL_TEXTURE_2D gets disabled. This issue may only impact platforms without shaders.
> 
> A potential workaround is to add glEnable(data->textype) in SetCopyState:
> 
> http://hg.libsdl.org/SDL/file/28fcb5ef7ff1/src/render/opengl/SDL_render_gl.c#l1115
> 
> Can be reproduced on Linux when shaders are deactivated.

On 2020-03-20 20:47:32 +0000, Ryan C. Gordon wrote:

> 
> So this is cached state, so if we're turning it on and off, we need to check/update:
> 
> GL_RenderData::drawstate.texturing
> 
> It looks like several places (not just SDL_UpdateTexture) enable and disable it. This is likely a holdover from before we were aggressively caching state.
> 
> I need to go back and read up on the legacy rules of GL_TEXTURE_2D...I suspect we don't need to enable it every time we bind a texture, but only when drawing with one, which would mean the correct thing to do is remove all these enable/disable calls outside of the one in SetDrawState().
> 
> --ryan.

On 2020-03-22 18:34:03 +0000, Ryan C. Gordon wrote:

> 
> Ok, this is fixed by https://hg.libsdl.org/SDL/rev/1c73cc1e4a3a ...we don't need to enable GL_TEXTURE_* to change texture state, just to enable texturing during rendering.
> 
> --ryan.

","OpenGL renderer doesn't always enable GL_TEXTURE_2D # This bug report was migrated from our old Bugzilla tracker. **Reported in version:** HG 2.1 **Reported for operating system, platform:** AmigaOS, PowerPC # Comments on the original bug report: On 2020-02-21 08:10:59 +0000, Juha Niemim짚ki wrote: > It seems that when SDL_UpdateTexture() is called in a draw loop, GL_TEXTURE_2D gets disabled. This issue may only impact platforms without shaders. > > A potential workaround is to add glEnable(data->textype) in SetCopyState: > > http://hg.libsdl.org/SDL/file/28fcb5ef7ff1/src/render/opengl/SDL_render_gl.c#l1115 > > Can be reproduced on Linux when shaders are deactivated. On 2020-03-20 20:47:32 +0000, Ryan C. Gordon wrote: > > So this is cached state, so if we're turning it on and off, we need to check/update: > > GL_RenderData::drawstate.texturing > > It looks like several places (not just SDL_UpdateTexture) enable and disable it. This is likely a holdover from before we were aggressively caching state. > > I need to go back and read up on the legacy rules of GL_TEXTURE_2D...I suspect we don't need to enable it every time we bind a texture, but only when drawing with one, which would mean the correct thing to do is remove all these enable/disable calls outside of the one in SetDrawState(). > > --ryan. On 2020-03-22 18:34:03 +0000, Ryan C. Gordon wrote: > > Ok, this is fixed by https://hg.libsdl.org/SDL/rev/1c73cc1e4a3a ...we don't need to enable GL_TEXTURE_* to change texture state, just to enable texturing during rendering. > > --ryan. "
52335,52335,58216,https://api.github.com/repos/cypress-io/netlify-plugin-cypress/issues/96,1.0,2021-01-07T14:35:01Z,NONE,https://api.github.com/repos/cypress-io/netlify-plugin-cypress,Possibility to disable postBuild and run tests on preBuild exclusively,"**Is your feature request related to a problem? Please describe.**
I'm running a NextJS site on Netlify using `next-on-netlify`. This builds my website in a weird way, with the final published assets in a configuration that I nor cypress can understand. This makes my tests fail. However, if I spin up NextJS' dev server and test with Cypress against _that_, all works swimmingly.

At this point, my project would build perfectly if I could somehow stop the postBuild from running and testing exclusively with the preBuild.

**Describe the solution you'd like**
It'd be great if I could pass an option to `skipPostBuild: true` or similar, and only run my tests preBuild.

**Describe alternatives you've considered**
I've opened [an issue](https://github.com/netlify/next-on-netlify/issues/133) on next-on-netlify to also help build proper static output published assets.

","Possibility to disable postBuild and run tests on preBuild exclusively **Is your feature request related to a problem? Please describe.** I'm running a NextJS site on Netlify using `next-on-netlify`. This builds my website in a weird way, with the final published assets in a configuration that I nor cypress can understand. This makes my tests fail. However, if I spin up NextJS' dev server and test with Cypress against _that_, all works swimmingly. At this point, my project would build perfectly if I could somehow stop the postBuild from running and testing exclusively with the preBuild. **Describe the solution you'd like** It'd be great if I could pass an option to `skipPostBuild: true` or similar, and only run my tests preBuild. **Describe alternatives you've considered** I've opened [an issue](https://github.com/netlify/next-on-netlify/issues/133) on next-on-netlify to also help build proper static output published assets. "
355216,355216,394909,https://api.github.com/repos/Riey/kime/issues/350,2.0,2021-03-04T03:34:02Z,NONE,https://api.github.com/repos/Riey/kime,kime-indicator 而댄 ,"1.2.x 踰源吏 kime-indicator 諛대由 깆 泥댄ы듬ㅻ, 洹 댄 kime 泥닿  ㅻ낫 1.3.x 踰 而댄쇱 kime-indicator瑜 명吏 紐삵, ㅻⅨ ㅽ 1.3.x 踰 ㅼㅻ낫 kime-indicator媛  嫄 듬.
洹몃 scripts/build.sh 쇱 댁 蹂댁, kime-indicator 깆 愿 寃 援곗. 1.3 踰  諛대由  諛⑸ щ쇱吏?

--- build.sh    2021-02-26 01:56:53.000000000 +0900                      <--- 1.2.x ver
+++ build-new.sh        2021-03-02 16:10:06.000000000 +0900        <--- 1.3.x ver
@@ -67,18 +67,16 @@
     cp $TARGET_DIR/kime-check $KIME_OUT
 fi
 
-echo Build xim wayland indicator...
+echo Build xim wayland...
 
-cargo_build -p kime-xim -p kime-wayland -p kime-indicator
+cargo_build -p kime-xim -p kime-wayland
 
 cp $TARGET_DIR/kime-xim $KIME_OUT
 cp $TARGET_DIR/kime-wayland $KIME_OUT
-cp $TARGET_DIR/kime-indicator $KIME_OUT
 cp src/engine/cffi/kime_engine.h $KIME_OUT
 cp src/engine/cffi/kime_engine.hpp $KIME_OUT
 cp LICENSE $KIME_OUT
-cp res/default_config.yaml $KIME_OUT
-cp -R res/icons $KIME_OUT
+cp -R res/* $KIME_OUT
","kime-indicator 而댄 1.2.x 踰源吏 kime-indicator 諛대由 깆 泥댄ы듬ㅻ, 洹 댄 kime 泥닿  ㅻ낫 1.3.x 踰 而댄쇱 kime-indicator瑜 명吏 紐삵, ㅻⅨ ㅽ 1.3.x 踰 ㅼㅻ낫 kime-indicator媛  嫄 듬. 洹몃 scripts/build.sh 쇱 댁 蹂댁, kime-indicator 깆 愿 寃 援곗. 1.3 踰  諛대由  諛⑸ щ쇱吏? --- build.sh 2021-02-26 01:56:53.000000000 +0900 <--- 1.2.x ver +++ build-new.sh 2021-03-02 16:10:06.000000000 +0900 <--- 1.3.x ver @@ -67,18 +67,16 @@ cp $TARGET_DIR/kime-check $KIME_OUT fi -echo Build xim wayland indicator... +echo Build xim wayland... -cargo_build -p kime-xim -p kime-wayland -p kime-indicator +cargo_build -p kime-xim -p kime-wayland cp $TARGET_DIR/kime-xim $KIME_OUT cp $TARGET_DIR/kime-wayland $KIME_OUT -cp $TARGET_DIR/kime-indicator $KIME_OUT cp src/engine/cffi/kime_engine.h $KIME_OUT cp src/engine/cffi/kime_engine.hpp $KIME_OUT cp LICENSE $KIME_OUT -cp res/default_config.yaml $KIME_OUT -cp -R res/icons $KIME_OUT +cp -R res/* $KIME_OUT "
321844,321844,357786,https://api.github.com/repos/primefaces/primevue/issues/1162,0.0,2021-04-10T10:45:04Z,NONE,https://api.github.com/repos/primefaces/primevue,documentation: Wrong CSS variable name for secondary text color,"On https://www.primefaces.org/primevue/showcase/#/colors

says 
```
--text-secondary-color | Muted font text color with a secondary level.
```

..but this is actually called `--text-color-secondary`
",documentation: Wrong CSS variable name for secondary text color On https://www.primefaces.org/primevue/showcase/#/colors says ``` --text-secondary-color | Muted font text color with a secondary level. ``` ..but this is actually called `--text-color-secondary` 
225300,225300,250554,https://api.github.com/repos/Joystream/atlas/issues/91,0.0,2020-12-02T10:03:32Z,NONE,https://api.github.com/repos/Joystream/atlas,Wrong video player sizing for non-wide aspect ratios,"![player_example1](https://user-images.githubusercontent.com/4144334/100857027-0fc79e80-3484-11eb-8b8b-75c2a979362f.jpeg)
![player_example2](https://user-images.githubusercontent.com/4144334/100857034-12c28f00-3484-11eb-84d6-519f2b8eee09.jpeg)

On my screen I need to scroll down to view the controls of 480p videos (usually the older content e.g. videos on the Classic Documentaries or Classic Cartoons channels).

It seems that the height of this element should be reduced to allow easy access to the video controls.

![video](https://user-images.githubusercontent.com/4144334/100858053-608bc700-3485-11eb-830d-ca8c58c06f94.gif)

I was using Google Chrome and my screen size is 1680x1050.",Wrong video player sizing for non-wide aspect ratios ![player_example1](https://user-images.githubusercontent.com/4144334/100857027-0fc79e80-3484-11eb-8b8b-75c2a979362f.jpeg) ![player_example2](https://user-images.githubusercontent.com/4144334/100857034-12c28f00-3484-11eb-84d6-519f2b8eee09.jpeg) On my screen I need to scroll down to view the controls of 480p videos (usually the older content e.g. videos on the Classic Documentaries or Classic Cartoons channels). It seems that the height of this element should be reduced to allow easy access to the video controls. ![video](https://user-images.githubusercontent.com/4144334/100858053-608bc700-3485-11eb-830d-ca8c58c06f94.gif) I was using Google Chrome and my screen size is 1680x1050.
633647,633647,704233,https://api.github.com/repos/lvgl/docs/issues/200,1.0,2021-04-25T15:54:29Z,NONE,https://api.github.com/repos/lvgl/docs,We do need a up-to-date PDF doc,"We do need an up-to-date PDF doc for v7, but why was it pulled down? maybe it's too hard to keep up with new commits?","We do need a up-to-date PDF doc We do need an up-to-date PDF doc for v7, but why was it pulled down? maybe it's too hard to keep up with new commits?"
617089,617089,685764,https://api.github.com/repos/GrapheneOS/os_issue_tracker/issues/495,1.0,2021-03-11T19:35:12Z,NONE,https://api.github.com/repos/GrapheneOS/os_issue_tracker,Fallback option to force-enable IMS,"First off, here's a shortened explanation of how (from my reading and testing) IMS works. The following prerequisites must be met:

1. Carrier must support it on an infastructure level (we can assume this is true, VoLTE will become mandatory over the next few years as 2/3G networks are being sunsetted).
2. Device must support it - both software (given) and hardware (for us, this means Pixels - which support it).
3. Your account (SIM) must be flagged as IMS-enabled (user-dependant).

If these are all met, the carrier checks the device against a list of supported devices (not all carriers have such a list) and either provisions it - or doesn't. If the carrier provisions the device, VoLTE and VoWifi toggles will appear in the Settings app - and the user can enjoy IMS services.

This last part (carrier provisioning) is where the mess is. Some carrier do this via an APK, some through the Play Store, and others through CarrierConfig... 

The thing is, it's very simple to bypass this part. [Adding (or changing) a few lines in build.prop](https://gist.github.com/chenshaoju/ec18f2081cb12f85752f4c8259b54b9a) forces the toggles to appear in the Settings app - enabling the toggles will forcefully provision the device, and IMS *will work*. This has been widely verified (look for XDA threads on force-enabling VoLTE on Oneplus devices) and I've tested it myself using a Oneplus 3T - both on stock firmware and LineageOS.

This could be implemented either as an augmentation of the current CarrierConfig, as a toggle in developer options / network menu (""Force-enable IMS toggles""), or just plain enabled for all devices.

It's not perfect, and the idea may need some work, but it's much better than users being unable to continue using their device just because their carrier arbitrarily won't provision their device.","Fallback option to force-enable IMS First off, here's a shortened explanation of how (from my reading and testing) IMS works. The following prerequisites must be met: 1. Carrier must support it on an infastructure level (we can assume this is true, VoLTE will become mandatory over the next few years as 2/3G networks are being sunsetted). 2. Device must support it - both software (given) and hardware (for us, this means Pixels - which support it). 3. Your account (SIM) must be flagged as IMS-enabled (user-dependant). If these are all met, the carrier checks the device against a list of supported devices (not all carriers have such a list) and either provisions it - or doesn't. If the carrier provisions the device, VoLTE and VoWifi toggles will appear in the Settings app - and the user can enjoy IMS services. This last part (carrier provisioning) is where the mess is. Some carrier do this via an APK, some through the Play Store, and others through CarrierConfig... The thing is, it's very simple to bypass this part. [Adding (or changing) a few lines in build.prop](https://gist.github.com/chenshaoju/ec18f2081cb12f85752f4c8259b54b9a) forces the toggles to appear in the Settings app - enabling the toggles will forcefully provision the device, and IMS *will work*. This has been widely verified (look for XDA threads on force-enabling VoLTE on Oneplus devices) and I've tested it myself using a Oneplus 3T - both on stock firmware and LineageOS. This could be implemented either as an augmentation of the current CarrierConfig, as a toggle in developer options / network menu (""Force-enable IMS toggles""), or just plain enabled for all devices. It's not perfect, and the idea may need some work, but it's much better than users being unable to continue using their device just because their carrier arbitrarily won't provision their device."
335847,335847,373344,https://api.github.com/repos/bjucps209/spring2021-team3/issues/32,0.0,2021-04-29T01:19:13Z,COLLABORATOR,https://api.github.com/repos/bjucps209/spring2021-team3,Scores carry over between non-progressive games,,Scores carry over between non-progressive games 
608437,608437,676147,https://api.github.com/repos/mapbase-source/source-sdk-2013/issues/106,1.0,2021-03-09T17:38:41Z,NONE,https://api.github.com/repos/mapbase-source/source-sdk-2013,[MISC] Allow Discord RPC DLL to be used in a root bin folder,"### Is your feature request related to a problem? Please describe.
All server/client DLLs which don't have RPC disabled need to ship with `discord-rpc.dll` and the lack of it has been the source of some problems users have had in the past.

### Describe the solution you'd like
Ideally, we'd want something which could allow `discord-rpc.dll` to stay back in Mapbase's folders (e.g. `mapbase_shared/shared_misc/bin`) and derivative DLLs don't need to copy it over to be immediately adjacent.

The main solution I could think of is a separate ""wrapper"" which takes advantage of Source's app system and is loaded as an interface in `cdll_client_int.cpp`.","[MISC] Allow Discord RPC DLL to be used in a root bin folder ### Is your feature request related to a problem? Please describe. All server/client DLLs which don't have RPC disabled need to ship with `discord-rpc.dll` and the lack of it has been the source of some problems users have had in the past. ### Describe the solution you'd like Ideally, we'd want something which could allow `discord-rpc.dll` to stay back in Mapbase's folders (e.g. `mapbase_shared/shared_misc/bin`) and derivative DLLs don't need to copy it over to be immediately adjacent. The main solution I could think of is a separate ""wrapper"" which takes advantage of Source's app system and is loaded as an interface in `cdll_client_int.cpp`."
130127,130127,144645,https://api.github.com/repos/ReznikovRoman/airbnb-clone/issues/17,1.0,2021-05-13T19:53:14Z,OWNER,https://api.github.com/repos/ReznikovRoman/airbnb-clone,Success message after Profile change ,Show success (bootstrap) message after Profile change,Success message after Profile change Show success (bootstrap) message after Profile change
267355,267355,297339,https://api.github.com/repos/Hyperobjekt/seda-map/issues/414,0.0,2021-01-12T23:45:02Z,CONTRIBUTOR,https://api.github.com/repos/Hyperobjekt/seda-map,Location Panel: diverging bars for learning rates are incorrect,"For learning rates, the diverging bar should be below the midpoint for negative values.  Need to subtract 1 from the values in order for them to display properly.

![image](https://user-images.githubusercontent.com/21034/104387969-20404f80-54ed-11eb-904f-fc94315d96ed.png)
","Location Panel: diverging bars for learning rates are incorrect For learning rates, the diverging bar should be below the midpoint for negative values. Need to subtract 1 from the values in order for them to display properly. ![image](https://user-images.githubusercontent.com/21034/104387969-20404f80-54ed-11eb-904f-fc94315d96ed.png) "
293860,293860,326762,https://api.github.com/repos/KadeDev/Kade-Engine/issues/86,0.0,2021-03-29T17:53:08Z,NONE,https://api.github.com/repos/KadeDev/Kade-Engine,Are you pulling our leg about the delete note bug in the chart editor??,"So ive been trying to edit a chart and ive had many problems cause I cannot delete any of the notes I place. And ive tried every kind of bind I can think of, I spammed every button on my mouse and ive tried multiple keys on my keyboard. And ive seen multiple other issues on this repo mentioning the bug, and almost all of them were replied with ""works for me so idk"" and then it was closed.

Also, I am using version 1.3.1 on Windows","Are you pulling our leg about the delete note bug in the chart editor?? So ive been trying to edit a chart and ive had many problems cause I cannot delete any of the notes I place. And ive tried every kind of bind I can think of, I spammed every button on my mouse and ive tried multiple keys on my keyboard. And ive seen multiple other issues on this repo mentioning the bug, and almost all of them were replied with ""works for me so idk"" and then it was closed. Also, I am using version 1.3.1 on Windows"
410442,410442,456218,https://api.github.com/repos/anewjs/store/issues/4,0.0,2019-03-26T20:20:05Z,MEMBER,https://api.github.com/repos/anewjs/store,Selectors undefined,"Selector undefined used before definition in other selectors. Needs to work regardless of definition order.

Example:

```
// selectors.js
export const someSelector = ({ select }) => [
   select.anotherSelector, // ERROR: undefined
  ...
]

// Defined below usage causes error
export const anotherSelector = () => [
  ...
]
```","Selectors undefined Selector undefined used before definition in other selectors. Needs to work regardless of definition order. Example: ``` // selectors.js export const someSelector = ({ select }) => [ select.anotherSelector, // ERROR: undefined ... ] // Defined below usage causes error export const anotherSelector = () => [ ... ] ```"
786071,786071,630787,https://api.github.com/repos/publishpress/PublishPress-Blocks/issues/494,0.0,2021-04-28T19:01:39Z,COLLABORATOR,https://api.github.com/repos/publishpress/PublishPress-Blocks,Conflict with Web Stories plugin,"[Web Stories](https://wordpress.org/plugins/web-stories/) block is not listed in editor when PublishPress Blocks is activated. Seems related in how the icon is declared and our system crawl that information.
`Uncaught (in promise) TypeError: (destructured parameter) is undefined`",Conflict with Web Stories plugin [Web Stories](https://wordpress.org/plugins/web-stories/) block is not listed in editor when PublishPress Blocks is activated. Seems related in how the icon is declared and our system crawl that information. `Uncaught (in promise) TypeError: (destructured parameter) is undefined`
391343,391343,434996,https://api.github.com/repos/abrahamfast/restoon.com/issues/40,1.0,2021-03-23T19:19:30Z,OWNER,https://api.github.com/repos/abrahamfast/restoon.com,change logo size ,"Set larger in any page

- login and register
- navbar
- footer",change logo size Set larger in any page - login and register - navbar - footer
346438,346438,385138,https://api.github.com/repos/AppSecure-nrw/security-belts/issues/18,1.0,2021-02-19T09:17:58Z,MEMBER,https://api.github.com/repos/AppSecure-nrw/security-belts,Green belt activities,"- [x] Environment depending configuration parameters
- [x] Nightly Dependency (Software Library) Version Upgrade.
  - For example check for latest libraries, run tests, create pull request, team accept/rejects PR
- [x] Static analysis for all self written components
  - *tools* contrast, spotbugs, sonarqube, Amazon CodeGuru
  - *includes* input validation testing, output security requirements, [OWASP Testing Guide 4.9.4](https://owasp.org/www-project-web-security-testing-guide/v42/4-Web_Application_Security_Testing/09-Testing_for_Weak_Cryptography/04-Testing_for_Weak_Encryption.html)
- [x] Treatment of defects with high accuracy and high criticality
  - Independed of SAST & DAST
- [x] Integration of vulnerability issues into the development process
- [x] Stored Secrets
  - Testing of Key Management, Usage of pre-commit hooks in git
  - *tools* trufflehog, gitrob, sonarqube
- [x] Test security configuration of infrastructure
  - Also CIS for VMs, OS, Middleware, Appserver, Datenbank, ... 
- [x] Test security configuration of cloud environments: 
  - AWS / Azure, IAM, Buckets, ...
- [x] Test of Container Images Regarding Known Vulnerabilities
- [x] Do you identify and remove systems, applications, application dependencies, or services that are no longer used, have reached end of life, or are no longer actively developed or supported?
- [x] Testing for Default Credentials
  - *tools* hydra, nmap
  - [OWASP Testing Guide 4.4.2](https://owasp.org/www-project-web-security-testing-guide/v42/4-Web_Application_Security_Testing/04-Authentication_Testing/02-Testing_for_Default_Credentials.html)","Green belt activities - [x] Environment depending configuration parameters - [x] Nightly Dependency (Software Library) Version Upgrade. - For example check for latest libraries, run tests, create pull request, team accept/rejects PR - [x] Static analysis for all self written components - *tools* contrast, spotbugs, sonarqube, Amazon CodeGuru - *includes* input validation testing, output security requirements, [OWASP Testing Guide 4.9.4](https://owasp.org/www-project-web-security-testing-guide/v42/4-Web_Application_Security_Testing/09-Testing_for_Weak_Cryptography/04-Testing_for_Weak_Encryption.html) - [x] Treatment of defects with high accuracy and high criticality - Independed of SAST & DAST - [x] Integration of vulnerability issues into the development process - [x] Stored Secrets - Testing of Key Management, Usage of pre-commit hooks in git - *tools* trufflehog, gitrob, sonarqube - [x] Test security configuration of infrastructure - Also CIS for VMs, OS, Middleware, Appserver, Datenbank, ... - [x] Test security configuration of cloud environments: - AWS / Azure, IAM, Buckets, ... - [x] Test of Container Images Regarding Known Vulnerabilities - [x] Do you identify and remove systems, applications, application dependencies, or services that are no longer used, have reached end of life, or are no longer actively developed or supported? - [x] Testing for Default Credentials - *tools* hydra, nmap - [OWASP Testing Guide 4.4.2](https://owasp.org/www-project-web-security-testing-guide/v42/4-Web_Application_Security_Testing/04-Authentication_Testing/02-Testing_for_Default_Credentials.html)"
650784,650784,723409,https://api.github.com/repos/rotki/rotki/issues/2791,0.0,2021-04-25T19:53:41Z,CONTRIBUTOR,https://api.github.com/repos/rotki/rotki,User ended up with a corrupt token entry in the DB after conflict during upgrade,"## Problem Definition

A user contacted us via email and shared some screenshots which gave funny errors when trying to find/insert a token which should have been added via the v1 assets upgrade. The user said they had it already locally but opted to solve the confict by choosing remote.

I got their global.db and it seems that something is wrong.

```
sqlite> SELECT * from assets WHERE identifier=""_ceth_0xf1f955016EcbCd7321c7266BccFB96c68ea5E49b"";
_ceth_0xf1f955016EcbCd7321c7266BccFB96c68ea5E49b|C|Rally|RLY|||rally-2||0xf1f955016EcbCd7321c7266BccFB96c68ea5E49b

sqlite> SELECT * from ethereum_tokens where address=""0xf1f955016EcbCd7321c7266BccFB96c68ea5E49b"";
sqlite> 
```
So the asset has an entry in the `assets` table and not in the `ethereum_tokens` table. 

## Task

Figure out how this could have happened and if it's something on our side fix.","User ended up with a corrupt token entry in the DB after conflict during upgrade ## Problem Definition A user contacted us via email and shared some screenshots which gave funny errors when trying to find/insert a token which should have been added via the v1 assets upgrade. The user said they had it already locally but opted to solve the confict by choosing remote. I got their global.db and it seems that something is wrong. ``` sqlite> SELECT * from assets WHERE identifier=""_ceth_0xf1f955016EcbCd7321c7266BccFB96c68ea5E49b""; _ceth_0xf1f955016EcbCd7321c7266BccFB96c68ea5E49b|C|Rally|RLY|||rally-2||0xf1f955016EcbCd7321c7266BccFB96c68ea5E49b sqlite> SELECT * from ethereum_tokens where address=""0xf1f955016EcbCd7321c7266BccFB96c68ea5E49b""; sqlite> ``` So the asset has an entry in the `assets` table and not in the `ethereum_tokens` table. ## Task Figure out how this could have happened and if it's something on our side fix."
703791,703791,782190,https://api.github.com/repos/Jandini/RightTurn/issues/4,0.0,2021-03-21T13:58:31Z,OWNER,https://api.github.com/repos/Jandini/RightTurn,`WithSerilog()` does not allow to load multiple configuration files.,"appsettings.json
```JSON
{
  ""Serilog"": {
    ""MinimumLevel"": {
      ""Default"": ""Information""
    },
    ""WriteTo"": [
      {
        ""Name"": ""Console"",
        ""Args"": {
          ""theme"": ""Serilog.Sinks.SystemConsole.Themes.AnsiConsoleTheme::Literate, Serilog.Sinks.Console"",
          ""outputTemplate"": ""[{Timestamp:HH:mm:ss} {Level:u4}] {Message:lj}{NewLine}{Exception}""
        }
      },
      {
        ""Name"": ""File"",
        ""Args"": {
          ""path"": ""logs/.log"",
          ""rollingInterval"": ""Day""
        }
      }
    ]
  },
  ""Jira"": {
    ""ApiBaseUrl"": ""https://consilio.atlassian.net/rest/api/3/""    
  }
}  
```


appsettings.secrets.json
```JSON
{ 
  ""Jira"": {
    ""ApiUserToken"": ""USERTOKEN""
  }
}
```

Following code does not work: 
```C#
 static void Main(string[] args) => new Turn()
            .WithConfiguration((builder) => builder
                .AddJsonFile(""appsettings.json"", false)
                .AddJsonFile(""appsettings.secrets.json"", true))
            .WithSerilog()
            .WithUnhandledExceptionLogging()
            .WithConfigurationSettings<IJiraSettings, JiraSettings>(""Jira"")
            .Take<IJiraService, JiraService>((quick) => quick.Run());
```


Workaround: 
```C#
  static void Main(string[] args) => new Turn()
            .WithConfiguration((builder) => builder
                .AddJsonFile(""appsettings.json"", false)
                .AddJsonFile(""appsettings.secrets.json"", true))
            .WithLogging((logging, turn)=>logging.AddSerilog(
                new LoggerConfiguration()                
                    .ReadFrom.Configuration(turn.Directions.Configuration())
                    .CreateLogger(),
                dispose: true))
            .WithUnhandledExceptionLogging()
            .WithConfigurationSettings<IJiraSettings, JiraSettings>(""Jira"")
            .Take<IJiraService, JiraService>((quick) => quick.Run());
```","`WithSerilog()` does not allow to load multiple configuration files. appsettings.json ```JSON { ""Serilog"": { ""MinimumLevel"": { ""Default"": ""Information"" }, ""WriteTo"": [ { ""Name"": ""Console"", ""Args"": { ""theme"": ""Serilog.Sinks.SystemConsole.Themes.AnsiConsoleTheme::Literate, Serilog.Sinks.Console"", ""outputTemplate"": ""[{Timestamp:HH:mm:ss} {Level:u4}] {Message:lj}{NewLine}{Exception}"" } }, { ""Name"": ""File"", ""Args"": { ""path"": ""logs/.log"", ""rollingInterval"": ""Day"" } } ] }, ""Jira"": { ""ApiBaseUrl"": ""https://consilio.atlassian.net/rest/api/3/"" } } ``` appsettings.secrets.json ```JSON { ""Jira"": { ""ApiUserToken"": ""USERTOKEN"" } } ``` Following code does not work: ```C# static void Main(string[] args) => new Turn() .WithConfiguration((builder) => builder .AddJsonFile(""appsettings.json"", false) .AddJsonFile(""appsettings.secrets.json"", true)) .WithSerilog() .WithUnhandledExceptionLogging() .WithConfigurationSettings<IJiraSettings, JiraSettings>(""Jira"") .Take<IJiraService, JiraService>((quick) => quick.Run()); ``` Workaround: ```C# static void Main(string[] args) => new Turn() .WithConfiguration((builder) => builder .AddJsonFile(""appsettings.json"", false) .AddJsonFile(""appsettings.secrets.json"", true)) .WithLogging((logging, turn)=>logging.AddSerilog( new LoggerConfiguration() .ReadFrom.Configuration(turn.Directions.Configuration()) .CreateLogger(), dispose: true)) .WithUnhandledExceptionLogging() .WithConfigurationSettings<IJiraSettings, JiraSettings>(""Jira"") .Take<IJiraService, JiraService>((quick) => quick.Run()); ```"
356034,356034,395823,https://api.github.com/repos/rifkirizaalfiansyah/fppemlan-koperasi/issues/1,0.0,2020-12-25T03:26:22Z,OWNER,https://api.github.com/repos/rifkirizaalfiansyah/fppemlan-koperasi,"Kurang fungsi ubah, sort(ShellSort), search(JumpSearch) + perbaikan UI","UI saat ini dapat dikembangkan menjadi lebih enak untuk dilihat.

Untuk fungsi ubah, sort, dan search hanya perlu untuk menggunakan fungsi : 
~~1. ubah(int x)
parameter x = indeks dari array yang ingin diubah. (Persis dengan hapus(int x))~~
~~2. sort(int x)
parameter x = boolean(value:1 atau 0) untuk menentukan ascending atau descending menggunakan if/else.~~
~~3. search(int x)
parameter x = indeks array yag ingin dicari.~~","Kurang fungsi ubah, sort(ShellSort), search(JumpSearch) + perbaikan UI UI saat ini dapat dikembangkan menjadi lebih enak untuk dilihat. Untuk fungsi ubah, sort, dan search hanya perlu untuk menggunakan fungsi : ~~1. ubah(int x) parameter x = indeks dari array yang ingin diubah. (Persis dengan hapus(int x))~~ ~~2. sort(int x) parameter x = boolean(value:1 atau 0) untuk menentukan ascending atau descending menggunakan if/else.~~ ~~3. search(int x) parameter x = indeks array yag ingin dicari.~~"
21371,21371,23778,https://api.github.com/repos/StevenEddies/scavenge/issues/3,1.0,2021-05-15T18:44:44Z,OWNER,https://api.github.com/repos/StevenEddies/scavenge,Nav bar doesn't handle sub-pages,,Nav bar doesn't handle sub-pages 
179763,179763,199845,https://api.github.com/repos/Informatievlaanderen/GIPOD/issues/251,0.0,2021-01-25T17:19:49Z,NONE,https://api.github.com/repos/Informatievlaanderen/GIPOD,DELETE on contact organisation fails,"When we retrieve the contact organisations for the GIPOD GroundWork with id: 6825771
we get back the following list:
/api/v1/trench-synergies/9192307/contactorganisations/2f5bbc70-879b-46ee-be1b-fd4bf4f2763d
/api/v1/trench-synergies/9192307/contactorganisations/0aa7b3e1-10ac-4183-ba34-a4324dc6076e
/api/v1/trench-synergies/9192307/contactorganisations/2be6cf81-2778-4719-bc1d-8a8aacaae27d
/api/v1/trench-synergies/9192307/contactorganisations/89c58c78-d4c0-4cbd-a1ca-5f3a7af44342
/api/v1/trench-synergies/9192307/contactorganisations/7cd6b2e7-a58f-4a67-ac69-33a744abfb25

however when we try to remove the groundwork contact organisation with a 
DELETE to  /api/v1/trench-synergies/9192307/contactorganisations/0aa7b3e1-10ac-4183-ba34-a4324dc6076e we get back a HTTP 404
{""type"":""https://httpstatuses.com/404"",""title"":""The requested resource could not be found."",""status"":404,""detail"":""Contactorganisation with 0aa7b3e1-10ac-4183-ba34-a4324dc6076e does not exist""}","DELETE on contact organisation fails When we retrieve the contact organisations for the GIPOD GroundWork with id: 6825771 we get back the following list: /api/v1/trench-synergies/9192307/contactorganisations/2f5bbc70-879b-46ee-be1b-fd4bf4f2763d /api/v1/trench-synergies/9192307/contactorganisations/0aa7b3e1-10ac-4183-ba34-a4324dc6076e /api/v1/trench-synergies/9192307/contactorganisations/2be6cf81-2778-4719-bc1d-8a8aacaae27d /api/v1/trench-synergies/9192307/contactorganisations/89c58c78-d4c0-4cbd-a1ca-5f3a7af44342 /api/v1/trench-synergies/9192307/contactorganisations/7cd6b2e7-a58f-4a67-ac69-33a744abfb25 however when we try to remove the groundwork contact organisation with a DELETE to /api/v1/trench-synergies/9192307/contactorganisations/0aa7b3e1-10ac-4183-ba34-a4324dc6076e we get back a HTTP 404 {""type"":""https://httpstatuses.com/404"",""title"":""The requested resource could not be found."",""status"":404,""detail"":""Contactorganisation with 0aa7b3e1-10ac-4183-ba34-a4324dc6076e does not exist""}"
435201,435201,483810,https://api.github.com/repos/benank/everyone.dance/issues/29,0.0,2021-04-02T20:24:12Z,NONE,https://api.github.com/repos/benank/everyone.dance,everyone.dance.txt file step data returns all zeros while playing a song,"**Issue**
everyone.dance player card does not update with step data while playing a song. Song info while in the song selection screen updates just fine.

**Setup**
- everyone.dance 2.1.4
- StepMania 5.3-Outfox (4.9.7GG)
- Simply Love Outfox 4.9.1
- Running everyone.dance on the streaming machine connected over a network share to the StepMania machine.

**Partial Log Dump**
`/////////////////////////////////////////
00:37.902: WARNING: Error playing command:...hemes/Simply-Love-OutFox/BGAnimations/everyone.dance.lua:177: attempt to index a nil value (local 'song')`
`00:37.902: WARNING: /Appearance/Themes/Simply-Love-OutFox/BGAnimations/everyone.dance.lua:177: RefreshActiveSongData(data = ,(for generator) = (null),(for state) = (null),(for control) = 1,_ = 1,pn = PlayerNumber_P1,player_data = (null),song = (null),step_data = (null),(*temporary) = (null),(*temporary) = (null),(*temporary) = (null),(*temporary) = 0,(*temporary) = (null),(*temporary) = 35,(*temporary) = 35,(*temporary) = 35,(*temporary) = 35,(*temporary) = 2,(*temporary) = Valex's Magical 4-Arrow Adventure 2,(*temporary) = 35,(*temporary) = 35,(*temporary) = 2,(*temporary) = 35,(*temporary) = 50,(*temporary) = 0,(*temporary) = 0,(*temporary) = (null),(*temporary) = (null),(*temporary) = steps_info,(*temporary) = (null),(*temporary) = (null),(*temporary) = (null),(*temporary) = (null),(*temporary) = W4,(*temporary) = (null),(*temporary) = (null),(*temporary) = (null),(*temporary) = steps_info,(*temporary) = :,(*temporary) = W4,(*temporary) = :,(*temporary) = 0,(*temporary) = `
`00:37.902: WARNING: ,(*temporary) =  (local 'song'),(*temporary) = attempt to index a nil value (local 'song'))`
`00:37.902: WARNING: /Appearance/Themes/Simply-Love-OutFox/BGAnimations/everyone.dance.lua:283: unknown(s = (null))
/////////////////////////////////////////`","everyone.dance.txt file step data returns all zeros while playing a song **Issue** everyone.dance player card does not update with step data while playing a song. Song info while in the song selection screen updates just fine. **Setup** - everyone.dance 2.1.4 - StepMania 5.3-Outfox (4.9.7GG) - Simply Love Outfox 4.9.1 - Running everyone.dance on the streaming machine connected over a network share to the StepMania machine. **Partial Log Dump** `///////////////////////////////////////// 00:37.902: WARNING: Error playing command:...hemes/Simply-Love-OutFox/BGAnimations/everyone.dance.lua:177: attempt to index a nil value (local 'song')` `00:37.902: WARNING: /Appearance/Themes/Simply-Love-OutFox/BGAnimations/everyone.dance.lua:177: RefreshActiveSongData(data = ,(for generator) = (null),(for state) = (null),(for control) = 1,_ = 1,pn = PlayerNumber_P1,player_data = (null),song = (null),step_data = (null),(*temporary) = (null),(*temporary) = (null),(*temporary) = (null),(*temporary) = 0,(*temporary) = (null),(*temporary) = 35,(*temporary) = 35,(*temporary) = 35,(*temporary) = 35,(*temporary) = 2,(*temporary) = Valex's Magical 4-Arrow Adventure 2,(*temporary) = 35,(*temporary) = 35,(*temporary) = 2,(*temporary) = 35,(*temporary) = 50,(*temporary) = 0,(*temporary) = 0,(*temporary) = (null),(*temporary) = (null),(*temporary) = steps_info,(*temporary) = (null),(*temporary) = (null),(*temporary) = (null),(*temporary) = (null),(*temporary) = W4,(*temporary) = (null),(*temporary) = (null),(*temporary) = (null),(*temporary) = steps_info,(*temporary) = :,(*temporary) = W4,(*temporary) = :,(*temporary) = 0,(*temporary) = ` `00:37.902: WARNING: ,(*temporary) = (local 'song'),(*temporary) = attempt to index a nil value (local 'song'))` `00:37.902: WARNING: /Appearance/Themes/Simply-Love-OutFox/BGAnimations/everyone.dance.lua:283: unknown(s = (null)) /////////////////////////////////////////`"
110754,110754,123107,https://api.github.com/repos/opentelekomcloud/terraform-provider-opentelekomcloud/issues/965,1.0,2021-04-08T13:03:08Z,MEMBER,https://api.github.com/repos/opentelekomcloud/terraform-provider-opentelekomcloud,Set default DNS servers for the `vpc_subnet_v1`,"Currently, the subnet has an empty DNS list by default.

As #940 shows, this can lead to various unobvious problems.
","Set default DNS servers for the `vpc_subnet_v1` Currently, the subnet has an empty DNS list by default. As #940 shows, this can lead to various unobvious problems. "
537663,537663,597582,https://api.github.com/repos/BlenderDefender/blender_project_starter/issues/6,1.0,2021-02-06T15:49:16Z,OWNER,https://api.github.com/repos/BlenderDefender/blender_project_starter,Support for more/less folders (let the user decide),"**Is your feature request related to a problem? Please describe.**
The Addon is good already, but sadly, it's set to have exactly 5 Folders. That messes with Blender's UI when less are needed (e.g. only a folder for Blender Files) and it's a huge limitation, if more folders are needed (e.g. Animation, Concept Art, References, Sounds, Rigging, Shading, Lighting, Texturing, Modelling, Sculpting, ...)

**Describe the solution you'd like**
Let the User decide how many folders he needs. Add an option to add and remove folders.","Support for more/less folders (let the user decide) **Is your feature request related to a problem? Please describe.** The Addon is good already, but sadly, it's set to have exactly 5 Folders. That messes with Blender's UI when less are needed (e.g. only a folder for Blender Files) and it's a huge limitation, if more folders are needed (e.g. Animation, Concept Art, References, Sounds, Rigging, Shading, Lighting, Texturing, Modelling, Sculpting, ...) **Describe the solution you'd like** Let the User decide how many folders he needs. Add an option to add and remove folders."
789231,789231,662247,https://api.github.com/repos/koba1mobile/MemeStorage/issues/1,1.0,2021-01-16T02:28:32Z,OWNER,https://api.github.com/repos/koba1mobile/MemeStorage,대몄 怨듭 ν湲,"- [ ] 몃   or 뱀 대몄 怨듭 대몄媛 λ댁 .
- [ ] 대몄 λ 대몄瑜 怨듭 寃쎌 대몄 寃쎈瑜 媛몄⑤.",대몄 怨듭 ν湲 - [ ] 몃  or 뱀 대몄 怨듭 대몄媛 λ댁 . - [ ] 대몄 λ 대몄瑜 怨듭 寃쎌 대몄 寃쎈瑜 媛몄⑤.
47596,47596,52975,https://api.github.com/repos/ucbds-infra/otter-grader/issues/215,0.0,2021-02-04T18:04:59Z,NONE,https://api.github.com/repos/ucbds-infra/otter-grader,KeyError: 'test',"**Describe the bug**
Autograder fails to grade student submissions.

Here's the error message:

```
Traceback (most recent call last):
  File ""/autograder/source/run_otter.py"", line 11, in <module>
    run_autograder('/autograder')
  File ""/root/miniconda3/envs/otter-gradescope-env/lib/python3.7/site-packages/otter/run/run_autograder/__init__.py"", line 48, in main
    output = run_autograder(options)
  File ""/root/miniconda3/envs/otter-gradescope-env/lib/python3.7/site-packages/otter/run/run_autograder/run_autograder.py"", line 182, in run_autograder
    script=script,
  File ""/root/miniconda3/envs/otter-gradescope-env/lib/python3.7/site-packages/otter/execute/__init__.py"", line 132, in grade_notebook
    extra_tests.append(OKTestFile.from_file(t))
  File ""/root/miniconda3/envs/otter-gradescope-env/lib/python3.7/site-packages/otter/test_files/ok_test.py"", line 134, in from_file
    test_spec = test_globals['test']
KeyError: 'test'
```

Here's how I generated the `autograder.zip` file to upload to Gradescope

```
(base) taylor@taylor-Precision-T1700:~/UVa/all_teaching/spring21_1602/labs/lab01$ ls
error.jpg  lab01.ipynb  map.jpg  METADATA  numberline_0.png  numberline_1.png  tests
(base) taylor@taylor-Precision-T1700:~/UVa/all_teaching/spring21_1602/labs/lab01$ otter generate -t tests/
(base) taylor@taylor-Precision-T1700:~/UVa/all_teaching/spring21_1602/labs/lab01$ ls
autograder.zip  lab01.ipynb  METADATA          numberline_1.png
error.jpg       map.jpg      numberline_0.png  tests
```","KeyError: 'test' **Describe the bug** Autograder fails to grade student submissions. Here's the error message: ``` Traceback (most recent call last): File ""/autograder/source/run_otter.py"", line 11, in <module> run_autograder('/autograder') File ""/root/miniconda3/envs/otter-gradescope-env/lib/python3.7/site-packages/otter/run/run_autograder/__init__.py"", line 48, in main output = run_autograder(options) File ""/root/miniconda3/envs/otter-gradescope-env/lib/python3.7/site-packages/otter/run/run_autograder/run_autograder.py"", line 182, in run_autograder script=script, File ""/root/miniconda3/envs/otter-gradescope-env/lib/python3.7/site-packages/otter/execute/__init__.py"", line 132, in grade_notebook extra_tests.append(OKTestFile.from_file(t)) File ""/root/miniconda3/envs/otter-gradescope-env/lib/python3.7/site-packages/otter/test_files/ok_test.py"", line 134, in from_file test_spec = test_globals['test'] KeyError: 'test' ``` Here's how I generated the `autograder.zip` file to upload to Gradescope ``` (base) taylor@taylor-Precision-T1700:~/UVa/all_teaching/spring21_1602/labs/lab01$ ls error.jpg lab01.ipynb map.jpg METADATA numberline_0.png numberline_1.png tests (base) taylor@taylor-Precision-T1700:~/UVa/all_teaching/spring21_1602/labs/lab01$ otter generate -t tests/ (base) taylor@taylor-Precision-T1700:~/UVa/all_teaching/spring21_1602/labs/lab01$ ls autograder.zip lab01.ipynb METADATA numberline_1.png error.jpg map.jpg numberline_0.png tests ```"
756298,756298,331900,https://api.github.com/repos/openzim/zim-tools/issues/242,2.0,2021-05-16T15:35:50Z,NONE,https://api.github.com/repos/openzim/zim-tools,Installing zim-tools fails on Ubuntu Server 20.04.2 -- partial workaround is to download mustache.hpp into /usr/include,"Summary: zim-tools install instructions at https://github.com/openzim/zim-tools#compilation do not work on Ubuntu Server 20.04.2

_Thanks if anybody has suggestions for PROBLEM 2 OF 2 below!_

### PROBLEM 1 OF 2:

```
git clone https://github.com/openzim/zim-tools
cd zim-tools
meson . build
```

...can be solved with this workaround: (thanks to @curtathompson and @georgejhunt)

```
cd /usr/include
wget https://raw.githubusercontent.com/kainjow/Mustache/master/mustache.hpp
cd /opt/iiab/zim-tools
meson . build
```

Error Log 1: (output of `meson . build`)
https://paste.ubuntu.com/p/wZkcfSHsTm/

Error Log 2: (/opt/iiab/zim-tools/build/meson-logs/meson-log.txt)
https://paste.ubuntu.com/p/HK45rXKqFS/

### PROBLEM 2 OF 2: (this is the output of `ninja -C build`)

```
ninja: Entering directory `build'
[2/22] Compiling C++ object 'src/25a6634@@zimsearch@exe/zimsearch.cpp.o'.
FAILED: src/25a6634@@zimsearch@exe/zimsearch.cpp.o
c++ -Isrc/25a6634@@zimsearch@exe -Isrc -I../src -I/usr/local/include -fdiagnostics-color=always -pipe -D_FILE_OFFSET_BITS=64 -Wall -Winvalid-pch -Wnon-virtual-dtor -Werror -std=c++11 -g -Werror -Wall '-DVERSION=""2.2.0""' -MD -MQ 'src/25a6634@@zimsearch@exe/zimsearch.cpp.o' -MF 'src/25a6634@@zimsearch@exe/zimsearch.cpp.o.d' -o 'src/25a6634@@zimsearch@exe/zimsearch.cpp.o' -c ../src/zimsearch.cpp
../src/zimsearch.cpp: In function void printSearchResults(zim::Search&):
../src/zimsearch.cpp:28:23: error: iterator is not a member of zim::Search
   28 |     for (zim::Search::iterator it = search.begin(); it != search.end(); ++it)
      |                       ^~~~~~~~
../src/zimsearch.cpp:28:53: error: it was not declared in this scope; did you mean int?
   28 |     for (zim::Search::iterator it = search.begin(); it != search.end(); ++it)
      |                                                     ^~
      |                                                     int
../src/zimsearch.cpp:28:66: error: class zim::Search has no member named end
   28 |     for (zim::Search::iterator it = search.begin(); it != search.end(); ++it)
      |                                                                  ^~~
../src/zimsearch.cpp: In function int main(int, char**):
../src/zimsearch.cpp:65:34: error: no matching function for call to zim::Search::Search(zim::Archive&)
   65 |     zim::Search search(zimarchive);
      |                                  ^
In file included from ../src/zimsearch.cpp:21:
/usr/local/include/zim/search.h:182:9: note: candidate: zim::Search::Search(std::shared_ptr<zim::InternalDataBase>, const zim::Query&)
  182 |         Search(std::shared_ptr<InternalDataBase> p_internalDb, const Query& query);
      |         ^~~~~~
/usr/local/include/zim/search.h:182:9: note:   candidate expects 2 arguments, 1 provided
/usr/local/include/zim/search.h:162:9: note: candidate: zim::Search::Search(zim::Search&&)
  162 |         Search(Search&& s);
      |         ^~~~~~
/usr/local/include/zim/search.h:162:25: note:   no known conversion for argument 1 from zim::Archive to zim::Search&&
  162 |         Search(Search&& s);
      |                ~~~~~~~~~^
../src/zimsearch.cpp:66:12: error: class zim::Search has no member named set_query; did you mean zim::Query zim::Search::m_query? (not accessible from this context)
   66 |     search.set_query(s);
      |            ^~~~~~~~~
In file included from ../src/zimsearch.cpp:21:
/usr/local/include/zim/search.h:188:16: note: declared private here
  188 |          Query m_query;
      |                ^~~~~~~
[3/22] Compiling C++ object 'src/25a6634@@zimpatch@exe/zimpatch.cpp.o'.
FAILED: src/25a6634@@zimpatch@exe/zimpatch.cpp.o
c++ -Isrc/25a6634@@zimpatch@exe -Isrc -I../src -I/usr/local/include -fdiagnostics-color=always -pipe -D_FILE_OFFSET_BITS=64 -Wall -Winvalid-pch -Wnon-virtual-dtor -Werror -std=c++11 -g -Werror -Wall '-DVERSION=""2.2.0""' -MD -MQ 'src/25a6634@@zimpatch@exe/zimpatch.cpp.o' -MF 'src/25a6634@@zimpatch@exe/zimpatch.cpp.o.d' -o 'src/25a6634@@zimpatch@exe/zimpatch.cpp.o' -c ../src/zimpatch.cpp
../src/zimpatch.cpp: In function void create(const string&, const string&, const string&):
../src/zimpatch.cpp:67:14: error: class zim::writer::Creator has no member named configMinClusterSize; did you mean configClusterSize?
   67 |   zimCreator.configMinClusterSize(2048);
      |              ^~~~~~~~~~~~~~~~~~~~
      |              configClusterSize
[4/22] Compiling C++ object 'src/25a6634@@zimpatch@exe/tools.cpp.o'.
ninja: build stopped: subcommand failed.
```","Installing zim-tools fails on Ubuntu Server 20.04.2 -- partial workaround is to download mustache.hpp into /usr/include Summary: zim-tools install instructions at https://github.com/openzim/zim-tools#compilation do not work on Ubuntu Server 20.04.2 _Thanks if anybody has suggestions for PROBLEM 2 OF 2 below!_ ### PROBLEM 1 OF 2: ``` git clone https://github.com/openzim/zim-tools cd zim-tools meson . build ``` ...can be solved with this workaround: (thanks to @curtathompson and @georgejhunt) ``` cd /usr/include wget https://raw.githubusercontent.com/kainjow/Mustache/master/mustache.hpp cd /opt/iiab/zim-tools meson . build ``` Error Log 1: (output of `meson . build`) https://paste.ubuntu.com/p/wZkcfSHsTm/ Error Log 2: (/opt/iiab/zim-tools/build/meson-logs/meson-log.txt) https://paste.ubuntu.com/p/HK45rXKqFS/ ### PROBLEM 2 OF 2: (this is the output of `ninja -C build`) ``` ninja: Entering directory `build' [2/22] Compiling C++ object 'src/25a6634@@zimsearch@exe/zimsearch.cpp.o'. FAILED: src/25a6634@@zimsearch@exe/zimsearch.cpp.o c++ -Isrc/25a6634@@zimsearch@exe -Isrc -I../src -I/usr/local/include -fdiagnostics-color=always -pipe -D_FILE_OFFSET_BITS=64 -Wall -Winvalid-pch -Wnon-virtual-dtor -Werror -std=c++11 -g -Werror -Wall '-DVERSION=""2.2.0""' -MD -MQ 'src/25a6634@@zimsearch@exe/zimsearch.cpp.o' -MF 'src/25a6634@@zimsearch@exe/zimsearch.cpp.o.d' -o 'src/25a6634@@zimsearch@exe/zimsearch.cpp.o' -c ../src/zimsearch.cpp ../src/zimsearch.cpp: In function void printSearchResults(zim::Search&): ../src/zimsearch.cpp:28:23: error: iterator is not a member of zim::Search 28 | for (zim::Search::iterator it = search.begin(); it != search.end(); ++it) | ^~~~~~~~ ../src/zimsearch.cpp:28:53: error: it was not declared in this scope; did you mean int? 28 | for (zim::Search::iterator it = search.begin(); it != search.end(); ++it) | ^~ | int ../src/zimsearch.cpp:28:66: error: class zim::Search has no member named end 28 | for (zim::Search::iterator it = search.begin(); it != search.end(); ++it) | ^~~ ../src/zimsearch.cpp: In function int main(int, char**): ../src/zimsearch.cpp:65:34: error: no matching function for call to zim::Search::Search(zim::Archive&) 65 | zim::Search search(zimarchive); | ^ In file included from ../src/zimsearch.cpp:21: /usr/local/include/zim/search.h:182:9: note: candidate: zim::Search::Search(std::shared_ptr<zim::InternalDataBase>, const zim::Query&) 182 | Search(std::shared_ptr<InternalDataBase> p_internalDb, const Query& query); | ^~~~~~ /usr/local/include/zim/search.h:182:9: note: candidate expects 2 arguments, 1 provided /usr/local/include/zim/search.h:162:9: note: candidate: zim::Search::Search(zim::Search&&) 162 | Search(Search&& s); | ^~~~~~ /usr/local/include/zim/search.h:162:25: note: no known conversion for argument 1 from zim::Archive to zim::Search&& 162 | Search(Search&& s); | ~~~~~~~~~^ ../src/zimsearch.cpp:66:12: error: class zim::Search has no member named set_query; did you mean zim::Query zim::Search::m_query? (not accessible from this context) 66 | search.set_query(s); | ^~~~~~~~~ In file included from ../src/zimsearch.cpp:21: /usr/local/include/zim/search.h:188:16: note: declared private here 188 | Query m_query; | ^~~~~~~ [3/22] Compiling C++ object 'src/25a6634@@zimpatch@exe/zimpatch.cpp.o'. FAILED: src/25a6634@@zimpatch@exe/zimpatch.cpp.o c++ -Isrc/25a6634@@zimpatch@exe -Isrc -I../src -I/usr/local/include -fdiagnostics-color=always -pipe -D_FILE_OFFSET_BITS=64 -Wall -Winvalid-pch -Wnon-virtual-dtor -Werror -std=c++11 -g -Werror -Wall '-DVERSION=""2.2.0""' -MD -MQ 'src/25a6634@@zimpatch@exe/zimpatch.cpp.o' -MF 'src/25a6634@@zimpatch@exe/zimpatch.cpp.o.d' -o 'src/25a6634@@zimpatch@exe/zimpatch.cpp.o' -c ../src/zimpatch.cpp ../src/zimpatch.cpp: In function void create(const string&, const string&, const string&): ../src/zimpatch.cpp:67:14: error: class zim::writer::Creator has no member named configMinClusterSize; did you mean configClusterSize? 67 | zimCreator.configMinClusterSize(2048); | ^~~~~~~~~~~~~~~~~~~~ | configClusterSize [4/22] Compiling C++ object 'src/25a6634@@zimpatch@exe/tools.cpp.o'. ninja: build stopped: subcommand failed. ```"
182166,182166,202501,https://api.github.com/repos/MrAlex94/Waterfox/issues/1631,0.0,2020-06-25T09:50:22Z,NONE,https://api.github.com/repos/MrAlex94/Waterfox,Unable to run either Classic or Current versions of Waterfox on openSUSE LEAP 15.1 and 15.2,"Everytime I start waterfox classic or current (latest versions) it fails with an error because the correct version of libc is not installed. This makes waterfox unusable on Leap, the last version which does run is 2020.03. Can you please fix this so I can run Leap without having to make massive changes to the software which is installed by default on a stable system.
","Unable to run either Classic or Current versions of Waterfox on openSUSE LEAP 15.1 and 15.2 Everytime I start waterfox classic or current (latest versions) it fails with an error because the correct version of libc is not installed. This makes waterfox unusable on Leap, the last version which does run is 2020.03. Can you please fix this so I can run Leap without having to make massive changes to the software which is installed by default on a stable system. "
594870,594870,661113,https://api.github.com/repos/rectorphp/rector/issues/6192,0.0,2021-04-22T10:58:46Z,CONTRIBUTOR,https://api.github.com/repos/rectorphp/rector,[Prefixed] PHP Fatal error:  Declaration of RectorPrefix20210422\Symfony\Component\DependencyInjection\ServiceLocator::has(string $id) must be compatible with RectorPrefix20210422\Psr\Container\ContainerInterface::has($id),"# Bug Report

| Subject        | Details                                                         |
| :------------- | :---------------------------------------------------------------|
| Rector version | latest tagged release and master too              |
| Installed as   | prefixed Rector                           |

I'm getting this error:
```
PHP Fatal error:  Declaration of RectorPrefix20210422\Symfony\Component\DependencyInjection\ServiceLocator::has(string $id) must be compatible with RectorPrefix20210422\Psr\Container\ContainerInterface::has($id) in /Volumes/CS/www/website/vendor/rector/rector-prefixed/vendor/symfony/dependency-injection/ServiceLocator.php on line 41
Fatal error: Declaration of RectorPrefix20210422\Symfony\Component\DependencyInjection\ServiceLocator::has(string $id) must be compatible with RectorPrefix20210422\Psr\Container\ContainerInterface::has($id) in /Volumes/CS/www/website/vendor/rector/rector-prefixed/vendor/symfony/dependency-injection/ServiceLocator.php on line 41
```

Seems like the prefixed build is broken.",[Prefixed] PHP Fatal error: Declaration of RectorPrefix20210422\Symfony\Component\DependencyInjection\ServiceLocator::has(string $id) must be compatible with RectorPrefix20210422\Psr\Container\ContainerInterface::has($id) # Bug Report | Subject | Details | | :------------- | :---------------------------------------------------------------| | Rector version | latest tagged release and master too | | Installed as | prefixed Rector | I'm getting this error: ``` PHP Fatal error: Declaration of RectorPrefix20210422\Symfony\Component\DependencyInjection\ServiceLocator::has(string $id) must be compatible with RectorPrefix20210422\Psr\Container\ContainerInterface::has($id) in /Volumes/CS/www/website/vendor/rector/rector-prefixed/vendor/symfony/dependency-injection/ServiceLocator.php on line 41 Fatal error: Declaration of RectorPrefix20210422\Symfony\Component\DependencyInjection\ServiceLocator::has(string $id) must be compatible with RectorPrefix20210422\Psr\Container\ContainerInterface::has($id) in /Volumes/CS/www/website/vendor/rector/rector-prefixed/vendor/symfony/dependency-injection/ServiceLocator.php on line 41 ``` Seems like the prefixed build is broken.
332281,332281,369411,https://api.github.com/repos/ros2/rosbag2/issues/378,1.0,2020-04-15T15:57:42Z,NONE,https://api.github.com/repos/ros2/rosbag2,Export generic_subscription.hpp/cpp and generic_publisher.hpp/cpp for external use,"## Description

I am working on creating a ROS cloud extension which will allow the customer to stream video and raw data to an external peer, and I would like it to allow for any ROS message types which the user may input. These files are currently located in the rosbag2_transport package.","Export generic_subscription.hpp/cpp and generic_publisher.hpp/cpp for external use ## Description I am working on creating a ROS cloud extension which will allow the customer to stream video and raw data to an external peer, and I would like it to allow for any ROS message types which the user may input. These files are currently located in the rosbag2_transport package."
779328,779328,563059,https://api.github.com/repos/bitrise-steplib/bitrise-step-android-build/issues/24,1.0,2021-01-18T09:58:45Z,NONE,https://api.github.com/repos/bitrise-steplib/bitrise-step-android-build,Add option to build AAB and APK the same time,"`*.aab` files cannot be installed to local devices and can be distributed only through Google Play Store. For testing purposes our ""Deploy to Bitrise.io"" step generated an additional `*.apk` from the already built bundle so it could be installed on devices. 

However this approach had a limitation (the new `*.apk` was not signed with the same key the `*.aab` has been signed with but a debug key) which caused confusion in a lot of cases so we will deprecate that method and instead we'll let the users build both `*.aab` and `*.apk` in the build step https://github.com/bitrise-steplib/steps-deploy-to-bitrise-io/issues/93. We'll make sure sign-apk, deploy-to-playstore and other steps will handle the newly generated apk and aab properly.

This way we get a properly signed `*.aab` for store deployment and a properly signed `*.apk` for local testing.","Add option to build AAB and APK the same time `*.aab` files cannot be installed to local devices and can be distributed only through Google Play Store. For testing purposes our ""Deploy to Bitrise.io"" step generated an additional `*.apk` from the already built bundle so it could be installed on devices. However this approach had a limitation (the new `*.apk` was not signed with the same key the `*.aab` has been signed with but a debug key) which caused confusion in a lot of cases so we will deprecate that method and instead we'll let the users build both `*.aab` and `*.apk` in the build step https://github.com/bitrise-steplib/steps-deploy-to-bitrise-io/issues/93. We'll make sure sign-apk, deploy-to-playstore and other steps will handle the newly generated apk and aab properly. This way we get a properly signed `*.aab` for store deployment and a properly signed `*.apk` for local testing."
543377,543377,603949,https://api.github.com/repos/GoodDollar/GoodDAPP/issues/2897,0.0,2021-01-12T10:28:05Z,NONE,https://api.github.com/repos/GoodDollar/GoodDAPP,[BUG] User is able to enter more than 1 space in a row on the name input stage of the Sign-up via passwordless ,"**Steps to reproduce:**
1. Open https://goodqa.netlify.app/
2. Click on the Sign-up button
3. Click on the ""Don't have a social account? Try this"" button
4. Complete the Phone number verification via the Passwordless method
5. Enter the name in the input field on the sign-up page
6. Enter more than 1 space in a row before/after the name 
7. Pay attention to the entered spaces in the input field

**Expected result:** It shouldn't be possible to enter more than 1 space in a row before/after the name in the name input field on the Sign-up page

**Actual result:** User is able to enter more than 1 space in a row on the name input stage of the Sign-up via passwordless 

**Environment:** QA 1.18.0-0

**Devices list:** Desktop // Windows 10 // Chrome v.87.0.4280.88

**Additional info:  after creating of wallet user's name is shifted due to many spaces** 

**Attachment:**
https://www.dropbox.com/s/nflr938hm5iegn4/There%20is%20no%20validation%20of%20input%20space%20as%20first%20symbol.mp4?dl=0","[BUG] User is able to enter more than 1 space in a row on the name input stage of the Sign-up via passwordless **Steps to reproduce:** 1. Open https://goodqa.netlify.app/ 2. Click on the Sign-up button 3. Click on the ""Don't have a social account? Try this"" button 4. Complete the Phone number verification via the Passwordless method 5. Enter the name in the input field on the sign-up page 6. Enter more than 1 space in a row before/after the name 7. Pay attention to the entered spaces in the input field **Expected result:** It shouldn't be possible to enter more than 1 space in a row before/after the name in the name input field on the Sign-up page **Actual result:** User is able to enter more than 1 space in a row on the name input stage of the Sign-up via passwordless **Environment:** QA 1.18.0-0 **Devices list:** Desktop // Windows 10 // Chrome v.87.0.4280.88 **Additional info: after creating of wallet user's name is shifted due to many spaces** **Attachment:** https://www.dropbox.com/s/nflr938hm5iegn4/There%20is%20no%20validation%20of%20input%20space%20as%20first%20symbol.mp4?dl=0"
212920,212920,236764,https://api.github.com/repos/alf45tar/PedalinoMini/issues/171,1.0,2021-01-06T09:31:12Z,NONE,https://api.github.com/repos/alf45tar/PedalinoMini,How to switch profiles?,"Now Boot button switch Banks as I can see. But is there still way to switch profiles without Web UI? 
I need to swich it quickly because of different pedal config for BiasFX and Looper operations.",How to switch profiles? Now Boot button switch Banks as I can see. But is there still way to switch profiles without Web UI? I need to swich it quickly because of different pedal config for BiasFX and Looper operations.
492465,492465,547356,https://api.github.com/repos/DestinyItemManager/DIM/issues/6459,0.0,2021-01-22T16:50:42Z,NONE,https://api.github.com/repos/DestinyItemManager/DIM,Calculation of Destiny 2 armor Base Stats incorrectly includes disabled Armor Mods,"**What version of DIM are you using?**
Version 6.48.0 (release), built on 18/01/2021, 02:47:29
Orange DIM icon.

**What Browser and OS are you using?**
Firefox 84.0.2 (64-bit)

**Describe the bug and how to make it happen**
Calculation of base stats incorrectly includes Armor Mods that are disabled.
![Capture](https://user-images.githubusercontent.com/17741825/105518615-6b6a1780-5cd0-11eb-88e3-5c23dbdd2d41.PNG)
This armour has 7 Resilence and 62 total base stats; the Armor Mods are disabled and do not affect the stats.
It is calculated as -3 Resilience and 52 total base stats. (Affects the web application and .csv export.)
In this case the Armor Mods were disabled upon the release of Beyond Light, which increased the energy costs.","Calculation of Destiny 2 armor Base Stats incorrectly includes disabled Armor Mods **What version of DIM are you using?** Version 6.48.0 (release), built on 18/01/2021, 02:47:29 Orange DIM icon. **What Browser and OS are you using?** Firefox 84.0.2 (64-bit) **Describe the bug and how to make it happen** Calculation of base stats incorrectly includes Armor Mods that are disabled. ![Capture](https://user-images.githubusercontent.com/17741825/105518615-6b6a1780-5cd0-11eb-88e3-5c23dbdd2d41.PNG) This armour has 7 Resilence and 62 total base stats; the Armor Mods are disabled and do not affect the stats. It is calculated as -3 Resilience and 52 total base stats. (Affects the web application and .csv export.) In this case the Armor Mods were disabled upon the release of Beyond Light, which increased the energy costs."
257274,257274,286152,https://api.github.com/repos/assimp/assimp/issues/3441,0.0,2020-10-06T18:20:51Z,MEMBER,https://api.github.com/repos/assimp/assimp,Issue 25126 in oss-fuzz: assimp:assimp_fuzzer: Stack-overflow in Assimp::XGLImporter::ReadObject,"**Describe the bug**
New issue 25126 by ClusterFuzz-External: assimp:assimp_fuzzer: Stack-overflow in Assimp::XGLImporter::ReadObject
https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=25126

**To Reproduce**
Detailed Report: https://oss-fuzz.com/testcase?key=5726440337965056

Project: assimp
Fuzzing Engine: libFuzzer
Fuzz Target: assimp_fuzzer
Job Type: libfuzzer_asan_assimp
Platform Id: linux

Crash Type: Stack-overflow
Crash Address: 0x7ffc326c4d38
Crash State:
  Assimp::XGLImporter::ReadObject
  
Sanitizer: address (ASAN)

Crash Revision: https://oss-fuzz.com/revisions?job=libfuzzer_asan_assimp&revision=202008080609

Reproducer Testcase: https://oss-fuzz.com/download?testcase_id=5726440337965056

Issue filed automatically.

See https://google.github.io/oss-fuzz/advanced-topics/reproducing for instructions to reproduce this bug locally.
When you fix this bug, please
  * mention the fix revision(s).
  * state whether the bug was a short-lived regression or an old bug in any stable releases.
  * add any other useful information.
This information can help downstream consumers.

If you need to contact the OSS-Fuzz team with a question, concern, or any other feedback, please file an issue at https://github.com/google/oss-fuzz/issues. Comments on individual Monorail issues are not monitored.

**Expected behavior**
No crash

**Desktop (please complete the following information):**
 - All
","Issue 25126 in oss-fuzz: assimp:assimp_fuzzer: Stack-overflow in Assimp::XGLImporter::ReadObject **Describe the bug** New issue 25126 by ClusterFuzz-External: assimp:assimp_fuzzer: Stack-overflow in Assimp::XGLImporter::ReadObject https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=25126 **To Reproduce** Detailed Report: https://oss-fuzz.com/testcase?key=5726440337965056 Project: assimp Fuzzing Engine: libFuzzer Fuzz Target: assimp_fuzzer Job Type: libfuzzer_asan_assimp Platform Id: linux Crash Type: Stack-overflow Crash Address: 0x7ffc326c4d38 Crash State: Assimp::XGLImporter::ReadObject Sanitizer: address (ASAN) Crash Revision: https://oss-fuzz.com/revisions?job=libfuzzer_asan_assimp&revision=202008080609 Reproducer Testcase: https://oss-fuzz.com/download?testcase_id=5726440337965056 Issue filed automatically. See https://google.github.io/oss-fuzz/advanced-topics/reproducing for instructions to reproduce this bug locally. When you fix this bug, please * mention the fix revision(s). * state whether the bug was a short-lived regression or an old bug in any stable releases. * add any other useful information. This information can help downstream consumers. If you need to contact the OSS-Fuzz team with a question, concern, or any other feedback, please file an issue at https://github.com/google/oss-fuzz/issues. Comments on individual Monorail issues are not monitored. **Expected behavior** No crash **Desktop (please complete the following information):** - All "
706184,706184,784870,https://api.github.com/repos/theupdateframework/specification/issues/145,1.0,2021-01-27T12:13:34Z,MEMBER,https://api.github.com/repos/theupdateframework/specification,Automated publishing workflow,"Automate publishing the specification to GitHub pages via Github Actions.

My current proposal is:
1. a CI workflow will build each PR and publish to an appropriately named directory in the `gh-pages` branch, i.e. this PR might be published to `wip/pulls/143` (and then would be browsable at theupdateframework.github.io/specifcation/wip/pulls/143). The workflow would also update the PR with a link to the rendered document.
2. a cleanup workflow would run periodically and compare the children of `wip/pulls` to open PRs, removing any children of `wip/pulls` for which there isn't a corresponding open PR
3. a release workflow will be triggered on changes to `master`, and:
    1. make a release on GitHub with a corresponding versioned tag
    2. build the spec for that release and publish it to the `latest` directory of the `gh-pages` branch
    3. also publish the built spec to a versioned subdirectory of the `gh-pages` branch
    4. update a listing page (index.html?) to point to the versioned subdirectory (the listing will enable browsers to find: the latest spec, specific versioned spec releases, and the most recent draft)
    5. __NOTE__: once this is done we need to update theupdateframework.io to point to the generated latest specification (and index of published versions)
4. a draft workflow will be triggered on changes to `draft`, and:
    1. build the spec in the `draft` branch
    2. publish the spec to a `draft` subdirectory of the `gh-pages` branch
5. a nag workflow will be triggered on changes to `master` and file an issue requesting `draft` is updated

Questions:
* Should we be signing spec releases (and therefore not doing automated releases on push to master)?
* Is the cleanup workflow necessary or, for the sake of a ~200K per PR, should we retain history for the PRs?

_Originally posted by @joshuagl in https://github.com/theupdateframework/specification/issues/143#issuecomment-762334990_

- [ ] PRs trigger a build and publish to a wip/pulls subdirectory of the `gh-pages` branch
- [ ] Updated master branch triggers a release (tag in repo and published release on GitHub)
- [ ] Release triggers a build and publishes to _both_ latest and versioned subdirectories of `gh-pages` branch (and updates index)
- [ ] theupdateframework.io updated to link to published specification on theupdateframework.github.io/specification
- [ ] Updated master branch files an issue to rebase draft branch
- [ ] Updated draft branch builds the spec and publishes it to the draft subdirectory of the `gh-pages` branch","Automated publishing workflow Automate publishing the specification to GitHub pages via Github Actions. My current proposal is: 1. a CI workflow will build each PR and publish to an appropriately named directory in the `gh-pages` branch, i.e. this PR might be published to `wip/pulls/143` (and then would be browsable at theupdateframework.github.io/specifcation/wip/pulls/143). The workflow would also update the PR with a link to the rendered document. 2. a cleanup workflow would run periodically and compare the children of `wip/pulls` to open PRs, removing any children of `wip/pulls` for which there isn't a corresponding open PR 3. a release workflow will be triggered on changes to `master`, and: 1. make a release on GitHub with a corresponding versioned tag 2. build the spec for that release and publish it to the `latest` directory of the `gh-pages` branch 3. also publish the built spec to a versioned subdirectory of the `gh-pages` branch 4. update a listing page (index.html?) to point to the versioned subdirectory (the listing will enable browsers to find: the latest spec, specific versioned spec releases, and the most recent draft) 5. __NOTE__: once this is done we need to update theupdateframework.io to point to the generated latest specification (and index of published versions) 4. a draft workflow will be triggered on changes to `draft`, and: 1. build the spec in the `draft` branch 2. publish the spec to a `draft` subdirectory of the `gh-pages` branch 5. a nag workflow will be triggered on changes to `master` and file an issue requesting `draft` is updated Questions: * Should we be signing spec releases (and therefore not doing automated releases on push to master)? * Is the cleanup workflow necessary or, for the sake of a ~200K per PR, should we retain history for the PRs? _Originally posted by @joshuagl in https://github.com/theupdateframework/specification/issues/143#issuecomment-762334990_ - [ ] PRs trigger a build and publish to a wip/pulls subdirectory of the `gh-pages` branch - [ ] Updated master branch triggers a release (tag in repo and published release on GitHub) - [ ] Release triggers a build and publishes to _both_ latest and versioned subdirectories of `gh-pages` branch (and updates index) - [ ] theupdateframework.io updated to link to published specification on theupdateframework.github.io/specification - [ ] Updated master branch files an issue to rebase draft branch - [ ] Updated draft branch builds the spec and publishes it to the draft subdirectory of the `gh-pages` branch"
679521,679521,755206,https://api.github.com/repos/pnp/powershell/issues/595,1.0,2021-04-19T20:20:44Z,CONTRIBUTOR,https://api.github.com/repos/pnp/powershell,[FEATURE] Help Files for *PnPAzureAD* Cmdlets Missing,"There are help files for *PnPAAD* cmdlets, however those can be considered outdated:
![image](https://user-images.githubusercontent.com/5260172/114222464-4a33d180-9977-11eb-8b89-786ccb9a327d.png)

When running Get-Help against any PnPAzureAD cmdlet, it looks like there is not much details:
![image](https://user-images.githubusercontent.com/5260172/114222605-78b1ac80-9977-11eb-8411-3c3a25eabcca.png)

https://docs.microsoft.com/en-us/powershell/module/sharepoint-pnp/get-pnpazureaduser gives 404 error.

Related issue:
https://github.com/MicrosoftDocs/office-docs-powershell/issues/7575","[FEATURE] Help Files for *PnPAzureAD* Cmdlets Missing There are help files for *PnPAAD* cmdlets, however those can be considered outdated: ![image](https://user-images.githubusercontent.com/5260172/114222464-4a33d180-9977-11eb-8b89-786ccb9a327d.png) When running Get-Help against any PnPAzureAD cmdlet, it looks like there is not much details: ![image](https://user-images.githubusercontent.com/5260172/114222605-78b1ac80-9977-11eb-8411-3c3a25eabcca.png) https://docs.microsoft.com/en-us/powershell/module/sharepoint-pnp/get-pnpazureaduser gives 404 error. Related issue: https://github.com/MicrosoftDocs/office-docs-powershell/issues/7575"
115024,115024,127839,https://api.github.com/repos/uw-biorobotics/IKBT/issues/29,1.0,2019-12-06T17:14:44Z,NONE,https://api.github.com/repos/uw-biorobotics/IKBT,Python 3.x support?,Python 2.7 is being deprecated. Do you plan to migrate to 3.x any time soon?,Python 3.x support? Python 2.7 is being deprecated. Do you plan to migrate to 3.x any time soon?
454304,454304,504925,https://api.github.com/repos/Pronto-AG/Pronto-MIA-App/issues/41,1.0,2021-04-30T14:28:51Z,CONTRIBUTOR,https://api.github.com/repos/Pronto-AG/Pronto-MIA-App,Implement deploymentplan publish,,Implement deploymentplan publish 
389674,389674,433143,https://api.github.com/repos/JoseExposito/touchegg/issues/475,0.0,2021-03-31T02:49:25Z,NONE,https://api.github.com/repos/JoseExposito/touchegg,libstdc++.so.6(GLIBCXX_3.4.26)(64bit) is needed by touchegg-2.0.8-1.x86_64 on centos 8,I got this error when trying install touchegg on centos 8.3.2011. However I can't find any installation of the  `libstdc++.so.6(GLIBCXX_3.4.26)(64bit)` available for centos 8 yet. Is there any way to solve this problem? Thanks,libstdc++.so.6(GLIBCXX_3.4.26)(64bit) is needed by touchegg-2.0.8-1.x86_64 on centos 8 I got this error when trying install touchegg on centos 8.3.2011. However I can't find any installation of the `libstdc++.so.6(GLIBCXX_3.4.26)(64bit)` available for centos 8 yet. Is there any way to solve this problem? Thanks
393814,393814,437718,https://api.github.com/repos/pluggedcomputing/pixel/issues/64,0.0,2021-02-25T17:32:36Z,COLLABORATOR,https://api.github.com/repos/pluggedcomputing/pixel,"Ao acerta a resposta de uma pergunta, card n찾o passa para a pr처xima pergunta apenas as alternativas","# Relat처rio de Bug

### Pr챕 Requisitos
> Entrar no aplicativo.

### Passos 
> Entrar em uns dois n챠veis 1, 2 ou 3.
> Acerta resposta de uma pergunta, card n찾o ira passa para o pr처ximo.

### Resultado esperado
> Card passe para o pr처ximo da lista.

### Poss챠vel Solu챌찾o 
> Verificar se o card esta passando para o pr처ximo item da lista antes de desbloquear a pergunta.

### Artefatos       
##### Ambiente: 
* [ ]  Produ챌찾o
* [X]  Desenvolvimento
* [ ]  Outro
> Se selecionou 'Outro', especifique.

","Ao acerta a resposta de uma pergunta, card n찾o passa para a pr처xima pergunta apenas as alternativas # Relat처rio de Bug ### Pr챕 Requisitos > Entrar no aplicativo. ### Passos > Entrar em uns dois n챠veis 1, 2 ou 3. > Acerta resposta de uma pergunta, card n찾o ira passa para o pr처ximo. ### Resultado esperado > Card passe para o pr처ximo da lista. ### Poss챠vel Solu챌찾o > Verificar se o card esta passando para o pr처ximo item da lista antes de desbloquear a pergunta. ### Artefatos ##### Ambiente: * [ ] Produ챌찾o * [X] Desenvolvimento * [ ] Outro > Se selecionou 'Outro', especifique. "
683742,683742,759915,https://api.github.com/repos/BeeStation/NSV13/issues/1376,0.0,2021-04-24T15:43:42Z,NONE,https://api.github.com/repos/BeeStation/NSV13,Fighter fuel tanks do not have sprites,"<!-- Write **BELOW** The Headers and **ABOVE** The comments else it may not be viewable -->
## Round ID: 

<!--- **INCLUDE THE ROUND ID**
If you discovered this issue from playing beestation hosted servers:--> 2291

## Testmerges: 
#1289:'[READY] [ANTAG] IT CAME FROM OUTER SPACE....' by Kmc2000 at commit bedf7833db 
#1362: 'Gunpowder loading on munitions trolley' by TheFakeElon at commit 256a23c3c0
#1368: '[Experimental] Lowpop PVP!' by Kmc2000 at commit b2c4cb538f
#1370: 'Advanced reactor fuel rods port' by TheFakeElon at commit 541365bcdc
#1371: 'Adds a wall to the Atlas arrivals shuttle to prevent felenids from being deafened' by Bokkiewokkie at commit 98172cfcf1

<!-- If you're certain the issue is to be caused by a test merge [OOC tab -> Show Server Revision], report it in the pull request's comment section rather than on the tracker(If you're unsure you can refer to the issue number by prefixing said number with #. The issue number can be found beside the title after submitting it to the tracker).If no testmerges are active, feel free to remove this section. -->

## Reproduction:
I took fuel tanks out of the fighters in maintenance mode. Both Extended and Standard tanks did not have sprites when they were taken out. That's all that I did.

<!-- Explain your issue in detail, including the steps to reproduce it. Issues without proper reproduction steps or explanation are open to being ignored/closed by maintainers.-->

<!-- **For Admins:** Oddities induced by var-edits and other admin tools are not necessarily bugs. Verify that your issues occur under regular circumstances before reporting them. -->
","Fighter fuel tanks do not have sprites <!-- Write **BELOW** The Headers and **ABOVE** The comments else it may not be viewable --> ## Round ID: <!--- **INCLUDE THE ROUND ID** If you discovered this issue from playing beestation hosted servers:--> 2291 ## Testmerges: #1289:'[READY] [ANTAG] IT CAME FROM OUTER SPACE....' by Kmc2000 at commit bedf7833db #1362: 'Gunpowder loading on munitions trolley' by TheFakeElon at commit 256a23c3c0 #1368: '[Experimental] Lowpop PVP!' by Kmc2000 at commit b2c4cb538f #1370: 'Advanced reactor fuel rods port' by TheFakeElon at commit 541365bcdc #1371: 'Adds a wall to the Atlas arrivals shuttle to prevent felenids from being deafened' by Bokkiewokkie at commit 98172cfcf1 <!-- If you're certain the issue is to be caused by a test merge [OOC tab -> Show Server Revision], report it in the pull request's comment section rather than on the tracker(If you're unsure you can refer to the issue number by prefixing said number with #. The issue number can be found beside the title after submitting it to the tracker).If no testmerges are active, feel free to remove this section. --> ## Reproduction: I took fuel tanks out of the fighters in maintenance mode. Both Extended and Standard tanks did not have sprites when they were taken out. That's all that I did. <!-- Explain your issue in detail, including the steps to reproduce it. Issues without proper reproduction steps or explanation are open to being ignored/closed by maintainers.--> <!-- **For Admins:** Oddities induced by var-edits and other admin tools are not necessarily bugs. Verify that your issues occur under regular circumstances before reporting them. --> "
167519,167519,186285,https://api.github.com/repos/PirateNetwork/pirate/issues/25,0.0,2021-01-26T02:17:27Z,NONE,https://api.github.com/repos/PirateNetwork/pirate,getblocktemplate close the node without errors in debug.log,"Hello!

If we run node with options:
```
mineraddress=OURADDRESS
disablewallet=1
minetolocalwallet=0
```

After full synchronization rpc command ""getinfo"" works fine. But rpc command ""getblocktemplate"" close the node without errors in debug.log.","getblocktemplate close the node without errors in debug.log Hello! If we run node with options: ``` mineraddress=OURADDRESS disablewallet=1 minetolocalwallet=0 ``` After full synchronization rpc command ""getinfo"" works fine. But rpc command ""getblocktemplate"" close the node without errors in debug.log."
435264,435264,483880,https://api.github.com/repos/turms-im/turms/issues/667,1.0,2021-04-03T14:42:10Z,COLLABORATOR,https://api.github.com/repos/turms-im/turms,Replace Webpack with rollup for turms-client-js only,,Replace Webpack with rollup for turms-client-js only 
631383,631383,701701,https://api.github.com/repos/glepnir/lspsaga.nvim/issues/123,0.0,2021-02-25T11:44:38Z,NONE,https://api.github.com/repos/glepnir/lspsaga.nvim,render_hover_doc is causing a crash with tsserver,"### Description
`render_hover_doc` causes neovim to be unresponsive and use 100% of cpu. In Python it works, it only happened to me with tsserver.

**Expected Behavior**
It does not crash.

**Actual Behavior**
It crashes.

**Neovim Built in Behavior**
The built-in hover handler works fine.

### Details

<!-- Steps to reproduce -->
<details><summary>Reproduce</summary>

1. nvim -u test.vim the min config that only lspsaga
2. post your program language min code snippet that can reproduce your issue
3. 
</details>

<!-- Environment Information -->
<details><summary>Environment</summary>

- nvim --version output: 
- Operating system: 
- lspsaga commit: 8e0526a

</details>
","render_hover_doc is causing a crash with tsserver ### Description `render_hover_doc` causes neovim to be unresponsive and use 100% of cpu. In Python it works, it only happened to me with tsserver. **Expected Behavior** It does not crash. **Actual Behavior** It crashes. **Neovim Built in Behavior** The built-in hover handler works fine. ### Details <!-- Steps to reproduce --> <details><summary>Reproduce</summary> 1. nvim -u test.vim the min config that only lspsaga 2. post your program language min code snippet that can reproduce your issue 3. </details> <!-- Environment Information --> <details><summary>Environment</summary> - nvim --version output: - Operating system: - lspsaga commit: 8e0526a </details> "
390522,390522,434090,https://api.github.com/repos/ccxt/ccxt/issues/8240,2.0,2021-01-11T10:38:31Z,NONE,https://api.github.com/repos/ccxt/ccxt,HitBTC order not found,"- OS: macOs
- Programming Language version: php
- CCXT version: 1.40.30

```
    $uid    = '';
    $apiKey = '***';
    $secret = '***';
    $name   = ""hitbtc"";
    
    $exchange_class = ""\\ccxt\\$name"";
    $exchange = new $exchange_class(array(
        'uid'    => $uid,
        'apiKey' => $apiKey,
        'secret' => $secret,
        'enableRateLimit' => true
    ));
    
    try {
        $order = $exchange->create_order(""IOST/USDT"", ""limit"", ""sell"", 36630, 0.013);
        var_dump($order);

        sleep(5);

        $orderbook = $exchange->fetchOrder($order[""id""], ""IOST/USDT"");
        var_dump($orderbook);
    } catch (Exception $E) {
        var_dump($E->getMessage());
    };
```

```
array(20) {
  'id' =>
  string(32) ""29eefaf3a2c345d3ae29f6940e93290d""
  'clientOrderId' =>
  string(32) ""29eefaf3a2c345d3ae29f6940e93290d""
  'timestamp' =>
  int(1610361214073)
  'datetime' =>
  string(24) ""2021-01-11T10:33:34.073Z""
  'lastTradeTimestamp' =>
  int(1610361214073)
  'status' =>
  string(4) ""open""
  'symbol' =>
  string(9) ""IOST/USDT""
  'type' =>
  string(5) ""limit""
  'timeInForce' =>
  string(3) ""GTC""
  'side' =>
  string(4) ""sell""
  'price' =>
  double(0.013)
  'stopPrice' =>
  NULL
  'average' =>
  NULL
  'amount' =>
  double(36630)
  'cost' =>
  double(0)
  'filled' =>
  double(0)
  'remaining' =>
  double(36630)
  'fee' =>
  NULL
  'trades' =>
  NULL
  'info' =>
  array(13) {
    'id' =>
    int(386838135428)
    'clientOrderId' =>
    string(32) ""29eefaf3a2c345d3ae29f6940e93290d""
    'symbol' =>
    string(7) ""IOSTUSD""
    'side' =>
    string(4) ""sell""
    'status' =>
    string(3) ""new""
    'type' =>
    string(5) ""limit""
    'timeInForce' =>
    string(3) ""GTC""
    'price' =>
    string(10) ""0.01300000""
    'quantity' =>
    string(5) ""36630""
    'postOnly' =>
    bool(false)
    'cumQuantity' =>
    string(1) ""0""
    'createdAt' =>
    string(24) ""2021-01-11T10:33:34.073Z""
    'updatedAt' =>
    string(24) ""2021-01-11T10:33:34.073Z""
  }
}

string(55) ""hitbtc order 29eefaf3a2c345d3ae29f6940e93290d not found""
```

All created limit orders were not found. I do not understand this is a problem with the stock exchange or in the library?","HitBTC order not found - OS: macOs - Programming Language version: php - CCXT version: 1.40.30 ``` $uid = ''; $apiKey = '***'; $secret = '***'; $name = ""hitbtc""; $exchange_class = ""\\ccxt\\$name""; $exchange = new $exchange_class(array( 'uid' => $uid, 'apiKey' => $apiKey, 'secret' => $secret, 'enableRateLimit' => true )); try { $order = $exchange->create_order(""IOST/USDT"", ""limit"", ""sell"", 36630, 0.013); var_dump($order); sleep(5); $orderbook = $exchange->fetchOrder($order[""id""], ""IOST/USDT""); var_dump($orderbook); } catch (Exception $E) { var_dump($E->getMessage()); }; ``` ``` array(20) { 'id' => string(32) ""29eefaf3a2c345d3ae29f6940e93290d"" 'clientOrderId' => string(32) ""29eefaf3a2c345d3ae29f6940e93290d"" 'timestamp' => int(1610361214073) 'datetime' => string(24) ""2021-01-11T10:33:34.073Z"" 'lastTradeTimestamp' => int(1610361214073) 'status' => string(4) ""open"" 'symbol' => string(9) ""IOST/USDT"" 'type' => string(5) ""limit"" 'timeInForce' => string(3) ""GTC"" 'side' => string(4) ""sell"" 'price' => double(0.013) 'stopPrice' => NULL 'average' => NULL 'amount' => double(36630) 'cost' => double(0) 'filled' => double(0) 'remaining' => double(36630) 'fee' => NULL 'trades' => NULL 'info' => array(13) { 'id' => int(386838135428) 'clientOrderId' => string(32) ""29eefaf3a2c345d3ae29f6940e93290d"" 'symbol' => string(7) ""IOSTUSD"" 'side' => string(4) ""sell"" 'status' => string(3) ""new"" 'type' => string(5) ""limit"" 'timeInForce' => string(3) ""GTC"" 'price' => string(10) ""0.01300000"" 'quantity' => string(5) ""36630"" 'postOnly' => bool(false) 'cumQuantity' => string(1) ""0"" 'createdAt' => string(24) ""2021-01-11T10:33:34.073Z"" 'updatedAt' => string(24) ""2021-01-11T10:33:34.073Z"" } } string(55) ""hitbtc order 29eefaf3a2c345d3ae29f6940e93290d not found"" ``` All created limit orders were not found. I do not understand this is a problem with the stock exchange or in the library?"
698559,698559,776387,https://api.github.com/repos/openpmix/prrte/issues/807,1.0,2021-03-05T15:53:50Z,CONTRIBUTOR,https://api.github.com/repos/openpmix/prrte,Support empty relative node specifier (+e) in rankfiles,"This is a feature request to add support for +e (empty relative node) to rankfiles. PR #720 (Rankfile per prun) does not cover the use-case with multiple concurrent prun invocations where you want to run multiple independent jobs in one DVM without sharing any nodes.

I think the latter use case needs support for +e relative node specifier. With +n, separate jobs end up allocated onto different slots on the same nodes.

Since jobs are independent it doesn't make sense to require constructing a set of rankfiles (one rankfile per job) that are aware of each other, i.e. one set of rankfiles per one particular set of jobs.

Desired:
```
cat arankfile 
rank 0=+e0 slot=0
rank 1=+e1 slot=0
# ^ one rankfile, re-used for each job, by means of relative node specs

prte --daemonize

prun -n 2  --map-by rankfile:FILE=arankfile:NOLOCAL bash hostname-sleep.sh 10 &
b07n13
b07n14

prun -n 2  --map-by rankfile:FILE=arankfile:NOLOCAL bash hostname-sleep.sh 10 &
b07n15
b07n16

pterm
```

Actual:
The above syntax is rejected (only `+nX` is supported).
With the following rankfile, both jobs are allocated onto the same two nodes (as expected):
```
rank 0=+n0 slot=0
rank 1=+n1 slot=0
```","Support empty relative node specifier (+e) in rankfiles This is a feature request to add support for +e (empty relative node) to rankfiles. PR #720 (Rankfile per prun) does not cover the use-case with multiple concurrent prun invocations where you want to run multiple independent jobs in one DVM without sharing any nodes. I think the latter use case needs support for +e relative node specifier. With +n, separate jobs end up allocated onto different slots on the same nodes. Since jobs are independent it doesn't make sense to require constructing a set of rankfiles (one rankfile per job) that are aware of each other, i.e. one set of rankfiles per one particular set of jobs. Desired: ``` cat arankfile rank 0=+e0 slot=0 rank 1=+e1 slot=0 # ^ one rankfile, re-used for each job, by means of relative node specs prte --daemonize prun -n 2 --map-by rankfile:FILE=arankfile:NOLOCAL bash hostname-sleep.sh 10 & b07n13 b07n14 prun -n 2 --map-by rankfile:FILE=arankfile:NOLOCAL bash hostname-sleep.sh 10 & b07n15 b07n16 pterm ``` Actual: The above syntax is rejected (only `+nX` is supported). With the following rankfile, both jobs are allocated onto the same two nodes (as expected): ``` rank 0=+n0 slot=0 rank 1=+n1 slot=0 ```"
708217,708217,787118,https://api.github.com/repos/gestaolegalufmg/gestaolegal/issues/81,0.0,2021-03-15T12:39:26Z,NONE,https://api.github.com/repos/gestaolegalufmg/gestaolegal,Bug ao inserir data no cadastro de processo judicial como administrador #issueanterior,"1.Logado como administrador (navegador chrome), depois de criado um caso, tentei associar um processo ao caso (casos/novo_processo/)
2.Eu inseri uma data de distribui챌찾o, mas n찾o inseri uma data de transito em julgado, e o erro na imagem apareceu. A data 챕 v찼lida.
3.Suspeito que ele esteja colocando ""Data de Transito em julgado"" como obrigat처ria. Acontece que ela n찾o pode ser obrigat처ria porque o transito em julgado demora muito para ocorrer (estamos falando de 5 at챕 10 anos em m챕dia). Logo, tem que ser opcional.
![image](https://user-images.githubusercontent.com/71410583/111154732-4e382380-8572-11eb-968c-ff4d306acd81.png)
","Bug ao inserir data no cadastro de processo judicial como administrador #issueanterior 1.Logado como administrador (navegador chrome), depois de criado um caso, tentei associar um processo ao caso (casos/novo_processo/) 2.Eu inseri uma data de distribui챌찾o, mas n찾o inseri uma data de transito em julgado, e o erro na imagem apareceu. A data 챕 v찼lida. 3.Suspeito que ele esteja colocando ""Data de Transito em julgado"" como obrigat처ria. Acontece que ela n찾o pode ser obrigat처ria porque o transito em julgado demora muito para ocorrer (estamos falando de 5 at챕 10 anos em m챕dia). Logo, tem que ser opcional. ![image](https://user-images.githubusercontent.com/71410583/111154732-4e382380-8572-11eb-968c-ff4d306acd81.png) "
285370,285370,317366,https://api.github.com/repos/voyansi/package-manager/issues/79,0.0,2021-02-09T18:01:21Z,CONTRIBUTOR,https://api.github.com/repos/voyansi/package-manager,Add certificate signing to installer,Needs to be integrated into Circle CI job?,Add certificate signing to installer Needs to be integrated into Circle CI job?
684108,684108,760324,https://api.github.com/repos/misskey-dev/mfm.js/issues/34,1.0,2021-03-27T09:25:55Z,COLLABORATOR,https://api.github.com/repos/misskey-dev/mfm.js,孃textⓦ배餓孃倻,孃ャ배易縕삠ャ,孃textⓦ배餓孃倻 孃ャ배易縕삠ャ
426917,426917,474561,https://api.github.com/repos/javers/javers/issues/1092,0.0,2021-05-19T06:58:03Z,NONE,https://api.github.com/repos/javers/javers,Javers Diff - Converting InitialValueChange with JsonConverter throws error,"Hello Javers-Team,
I found a bug which affects the JsonConverter.
An error is thrown in the JsonConverter when the JSON includes an InitialValueChange.

Example:
I created a Diff of two objects. One has a new child with initial values. This diff is converted to JSON with:
```java
Javers javers = JaversBuilder.javers().withTerminalChanges(false).build();
Diff diff = javers.compare(fooOldRevision, fooCurrent);
javers.getJsonConverter().toJson(diff);
```

The output-JSON of this is:
``` json
{
  ""changes"": [
    {
      ""changeType"": ""NewObject"",
      ""globalId"": {
        ""entity"": ""cms.domain.Bar"",
        ""cdoId"": ""58e90e85-e7c6-47f1-96b2-e71b7d936132""
      }
    },
    {
      ""changeType"": ""InitialValueChange"",
      ""globalId"": {
        ""entity"": ""cms.domain.Bar"",
        ""cdoId"": ""58e90e85-e7c6-47f1-96b2-e71b7d936132""
      },
      ""property"": ""id"",
      ""propertyChangeType"": ""PROPERTY_VALUE_CHANGED""
    }
  ]
}
```

If I now take this JSON and put it in the method
```java
Diff diff = javers.getJsonConverter().fromJson(changes, Diff.class);
```
to convert it to a Diff again, an error is thrown: `MALFORMED_CHANGE_TYPE_FIELD: no such Change type - 'InitialChange'`

This error seems to be thrown in the ChangeTypeAdapter.class as the InitialValueChange.class is **not** part of the constructor of this class.

Thank you for your help!","Javers Diff - Converting InitialValueChange with JsonConverter throws error Hello Javers-Team, I found a bug which affects the JsonConverter. An error is thrown in the JsonConverter when the JSON includes an InitialValueChange. Example: I created a Diff of two objects. One has a new child with initial values. This diff is converted to JSON with: ```java Javers javers = JaversBuilder.javers().withTerminalChanges(false).build(); Diff diff = javers.compare(fooOldRevision, fooCurrent); javers.getJsonConverter().toJson(diff); ``` The output-JSON of this is: ``` json { ""changes"": [ { ""changeType"": ""NewObject"", ""globalId"": { ""entity"": ""cms.domain.Bar"", ""cdoId"": ""58e90e85-e7c6-47f1-96b2-e71b7d936132"" } }, { ""changeType"": ""InitialValueChange"", ""globalId"": { ""entity"": ""cms.domain.Bar"", ""cdoId"": ""58e90e85-e7c6-47f1-96b2-e71b7d936132"" }, ""property"": ""id"", ""propertyChangeType"": ""PROPERTY_VALUE_CHANGED"" } ] } ``` If I now take this JSON and put it in the method ```java Diff diff = javers.getJsonConverter().fromJson(changes, Diff.class); ``` to convert it to a Diff again, an error is thrown: `MALFORMED_CHANGE_TYPE_FIELD: no such Change type - 'InitialChange'` This error seems to be thrown in the ChangeTypeAdapter.class as the InitialValueChange.class is **not** part of the constructor of this class. Thank you for your help!"
438342,438342,487324,https://api.github.com/repos/ethersphere/bee/issues/1077,0.0,2020-12-29T08:48:26Z,NONE,https://api.github.com/repos/ethersphere/bee,Error: could not connect to backend at http://goerli-geth.dappnode:8545,"#### Summary
I was following the tutorial (https://medium.com/ethereum-swarm/how-to-run-bee-on-a-dappnode-raspberry-pi-7b4993ff7583) to make a raspberrypi run Bee.

#### Steps to reproduce
I get an error saying

> time=""2020-12-29T08:45:12Z"" level=info msg=""could not connect to backend at http://goerli-geth.dappnode:8545. In a swap-enabled network a working blockchain node (for goerli network in production) is required. Check your node or specify another node using --swap-endpoint.""
> Error: could not get chain id from ethereum backend: Post ""http://goerli-geth.dappnode:8545"": dial tcp: lookup goerli-geth.dappnode on 127.0.0.11:53: no such host

I ran `docker ps` on the pi but didn't see anything related to goerli-geth.

","Error: could not connect to backend at http://goerli-geth.dappnode:8545 #### Summary I was following the tutorial (https://medium.com/ethereum-swarm/how-to-run-bee-on-a-dappnode-raspberry-pi-7b4993ff7583) to make a raspberrypi run Bee. #### Steps to reproduce I get an error saying > time=""2020-12-29T08:45:12Z"" level=info msg=""could not connect to backend at http://goerli-geth.dappnode:8545. In a swap-enabled network a working blockchain node (for goerli network in production) is required. Check your node or specify another node using --swap-endpoint."" > Error: could not get chain id from ethereum backend: Post ""http://goerli-geth.dappnode:8545"": dial tcp: lookup goerli-geth.dappnode on 127.0.0.11:53: no such host I ran `docker ps` on the pi but didn't see anything related to goerli-geth. "
747751,747751,246665,https://api.github.com/repos/tsYaroslav/homepage/issues/20,1.0,2021-01-11T18:38:31Z,OWNER,https://api.github.com/repos/tsYaroslav/homepage,Styling intro section,,Styling intro section 
483877,483877,537768,https://api.github.com/repos/microsoft/vscode-docker/issues/2825,0.0,2021-03-31T07:46:07Z,NONE,https://api.github.com/repos/microsoft/vscode-docker,"Fail to execute the ""Compose Up"" action for a .NET Core MVC project on Windows container","**OS:** Win 10
**Build Version:** 20210329.3
**.NET Core SDK:** 5.0.201

**Repro Steps:**
1. Switch Docker Desktop to windows containers.
2. Open a .NET Core MVC project in VS Code Insiders.
3. Add Docker files with ""Windows OS"" and including Docker compose files for this project.
4. Right click the docker-compose.yml file -> Select ""Compose Up"".
5. Check whether the ""Compose Up"" action is executed successfully or not.

**Expect:**
The ""Compose Up"" action is executed successfully.

**Actual:**
Fail to execute the ""Compose Up"" action.
![image](https://user-images.githubusercontent.com/45614674/113107468-8f008f80-9236-11eb-8bcd-e3a640875d21.png)

**More Info:**
1. This issue does not reproduce on Linux container.
2. This issue does not reproduce for a .NET Core Console app.","Fail to execute the ""Compose Up"" action for a .NET Core MVC project on Windows container **OS:** Win 10 **Build Version:** 20210329.3 **.NET Core SDK:** 5.0.201 **Repro Steps:** 1. Switch Docker Desktop to windows containers. 2. Open a .NET Core MVC project in VS Code Insiders. 3. Add Docker files with ""Windows OS"" and including Docker compose files for this project. 4. Right click the docker-compose.yml file -> Select ""Compose Up"". 5. Check whether the ""Compose Up"" action is executed successfully or not. **Expect:** The ""Compose Up"" action is executed successfully. **Actual:** Fail to execute the ""Compose Up"" action. ![image](https://user-images.githubusercontent.com/45614674/113107468-8f008f80-9236-11eb-8bcd-e3a640875d21.png) **More Info:** 1. This issue does not reproduce on Linux container. 2. This issue does not reproduce for a .NET Core Console app."
316356,316356,351710,https://api.github.com/repos/stanfordnlp/stanza/issues/628,2.0,2021-02-24T19:46:23Z,NONE,https://api.github.com/repos/stanfordnlp/stanza,csv file,"I want to process a csv file that contains a column called ""tweets"" instead of just one sentence like below:
doc = nlp(""Barack Obama was born in Hawaii.  He was elected president in 2008."")

I want to read the csv file instead, is that possible and how it should be?

thank you.","csv file I want to process a csv file that contains a column called ""tweets"" instead of just one sentence like below: doc = nlp(""Barack Obama was born in Hawaii. He was elected president in 2008."") I want to read the csv file instead, is that possible and how it should be? thank you."
385008,385008,427980,https://api.github.com/repos/microsoft/vscode/issues/121296,0.0,2021-04-14T14:43:00Z,MEMBER,https://api.github.com/repos/microsoft/vscode,"Terminal profiles are valid when using a shell off $PATH, but then fail to launch","I have the following profiles on mac:

```
  ""fish"": {
    ""path"": ""fish"",
    ""icon"": ""code""
  },
  ""tmux"": {
    ""path"": ""tmux""
  }
```

Both profiles show up and the paths do exist. When I run it I get an `execvp` error.","Terminal profiles are valid when using a shell off $PATH, but then fail to launch I have the following profiles on mac: ``` ""fish"": { ""path"": ""fish"", ""icon"": ""code"" }, ""tmux"": { ""path"": ""tmux"" } ``` Both profiles show up and the paths do exist. When I run it I get an `execvp` error."
305415,305415,339583,https://api.github.com/repos/uncharted-distil/distil/issues/2140,0.0,2020-12-19T17:02:07Z,COLLABORATOR,https://api.github.com/repos/uncharted-distil/distil,Geo facet update time too long on large datasets,"The heatmap view of the data presented by the geofacet does not scale well.  In working with the `locust-medium` dataset, which is about 17K tiles, it would take minutes for it to display the first time.  It seems like the time is spent entirely in the DB query given that running `top` during this time shows postgres processes eating up most of the CPU.  We may need to place an upper limit on the number of samples used in the heatmap query to speed things up.
","Geo facet update time too long on large datasets The heatmap view of the data presented by the geofacet does not scale well. In working with the `locust-medium` dataset, which is about 17K tiles, it would take minutes for it to display the first time. It seems like the time is spent entirely in the DB query given that running `top` during this time shows postgres processes eating up most of the CPU. We may need to place an upper limit on the number of samples used in the heatmap query to speed things up. "
559377,559377,621671,https://api.github.com/repos/PojavLauncherTeam/PojavLauncher/issues/891,1.0,2021-02-14T22:19:04Z,NONE,https://api.github.com/repos/PojavLauncherTeam/PojavLauncher,[F-REQ],"Shaders in Pojavlauncher Soon?
",[F-REQ] Shaders in Pojavlauncher Soon? 
355083,355083,394763,https://api.github.com/repos/getsentry/sentry-mobile/issues/152,0.0,2021-03-02T08:56:23Z,COLLABORATOR,https://api.github.com/repos/getsentry/sentry-mobile,Fix failing unit tests,"```
00:06 +7 -1: /Users/denis/Repos/sentry/sentry-mobile/test/util/relative_date_time_test.dart: relativeFromNow months to year threshold [E]
  Expected: '10 months ago'
    Actual: '9 months ago'
     Which: is different.
            Expected: 10 months  ...
              Actual: 9 months a ...
                      ^
             Differ at offset 0
  Below default days to years threshold
  
  package:test_api                        expect
  util/relative_date_time_test.dart 86:7  main.<fn>.<fn>
```",Fix failing unit tests ``` 00:06 +7 -1: /Users/denis/Repos/sentry/sentry-mobile/test/util/relative_date_time_test.dart: relativeFromNow months to year threshold [E] Expected: '10 months ago' Actual: '9 months ago' Which: is different. Expected: 10 months ... Actual: 9 months a ... ^ Differ at offset 0 Below default days to years threshold package:test_api expect util/relative_date_time_test.dart 86:7 main.<fn>.<fn> ```
28666,28666,31923,https://api.github.com/repos/SeedCompany/cord-api-v3/issues/1533,0.0,2020-11-10T11:07:55Z,CONTRIBUTOR,https://api.github.com/repos/SeedCompany/cord-api-v3,"""Intern"", ""ProjectManager"" and ""Consultant"" is not allowed to advance the project from `Consultant Endorsement` step.","**Roles:** Intern, Project Manager, Consultant

**Describe the bug**
`Intern`, `ProjectManager` and `Consultant` is not allowed to advance the project from `Consultant Endorsement` step.

**Steps to Reproduce**
1. Login as `ProjectManager`,`Intern`
2. Create New Project and go to created Project's detail page
3. Click on `Early Conversation` > `Submit for Concept Approval`
4. Navigate Back to Project detail page by clicking the button from redirected page.
5. Login as `Administrator` and search project created by `Intern` and `Project Manager`
6. Click on `Pending Concept Approval` >`Approve`
7. Click on `Prep For Consultant Endorsement` > `Submit for Consultant Endorsement`
8. Login as `ProjectManager` , `Intern`
9. Click on `Pending Consultant Endorsement`

**Expected Result**
`Intern`, `ProjectManager` and `Consultant` should be allowed to advance the project from `Consultant Endorsement` step.

**Actual Result**
`Intern`, `ProjectManager` and `Consultant` is not allowed to advance the project from `Consultant Endorsement` step.
See video -  https://www.awesomescreenshot.com/video/1664602?key=ac6476b9fbaeb8a671f6dc7d4464a2b4

CordAPIV3# 13948548","""Intern"", ""ProjectManager"" and ""Consultant"" is not allowed to advance the project from `Consultant Endorsement` step. **Roles:** Intern, Project Manager, Consultant **Describe the bug** `Intern`, `ProjectManager` and `Consultant` is not allowed to advance the project from `Consultant Endorsement` step. **Steps to Reproduce** 1. Login as `ProjectManager`,`Intern` 2. Create New Project and go to created Project's detail page 3. Click on `Early Conversation` > `Submit for Concept Approval` 4. Navigate Back to Project detail page by clicking the button from redirected page. 5. Login as `Administrator` and search project created by `Intern` and `Project Manager` 6. Click on `Pending Concept Approval` >`Approve` 7. Click on `Prep For Consultant Endorsement` > `Submit for Consultant Endorsement` 8. Login as `ProjectManager` , `Intern` 9. Click on `Pending Consultant Endorsement` **Expected Result** `Intern`, `ProjectManager` and `Consultant` should be allowed to advance the project from `Consultant Endorsement` step. **Actual Result** `Intern`, `ProjectManager` and `Consultant` is not allowed to advance the project from `Consultant Endorsement` step. See video - https://www.awesomescreenshot.com/video/1664602?key=ac6476b9fbaeb8a671f6dc7d4464a2b4 CordAPIV3# 13948548"
396932,396932,441180,https://api.github.com/repos/aws/aws-cdk/issues/10782,0.0,2020-10-08T06:51:09Z,NONE,https://api.github.com/repos/aws/aws-cdk,[pipelines] self-update build fails with named pipeline stack,"<!--
description of the bug:
-->

When naming the pipeline stack using the `stackName` property with a different name than the `id`, the self-update build fails with an error that it cannot find the stack.

### Reproduction Steps

<!--
minimal amount of code that causes the bug (if possible) or a reference:
-->
Create a pipeline project and give the pipeline stack a custom name.
```typescript
import * as cdk from '@aws-cdk/core';
import { PipelineStack } from '../lib/pipeline-stack';

const app = new cdk.App();

new PipelineStack(app, 'PipelineStack', {
    stackName: 'Pipeline'
});

app.synth();
```
Then deploy the project and have a look at the pipeline execution.

### What did you expect to happen?

<!--
What were you trying to achieve by performing the steps above?
-->
I expected the pipeline stack to be named 'Pipeline'. This happened successfully on the first deploy from my local command line. Then I expected the pipeline build to execute successfully and update the pipeline, however this step failed. It works fine, when I don't supply a `stackName`.

### What actually happened?

The update build failed with the error message that it could not find the stack 'Pipeline'. 
<!--
What is the unexpected behavior you were seeing? If you got an error, paste it here.
-->
```
95	No stack found matching 'Pipeline'. Use ""list"" to print manifest
96	Error: No stack found matching 'Pipeline'. Use ""list"" to print manifest
97	    at CloudAssembly.selectStacks (/usr/local/lib/node_modules/aws-cdk/lib/api/cxapp/cloud-assembly.ts:115:15)
98	    at CdkToolkit.selectStacksForDeploy (/usr/local/lib/node_modules/aws-cdk/lib/cdk-toolkit.ts:381:35)
99	    at CdkToolkit.deploy (/usr/local/lib/node_modules/aws-cdk/lib/cdk-toolkit.ts:111:20)
100	    at initCommandLine (/usr/local/lib/node_modules/aws-cdk/bin/cdk.ts:197:9)
```



### Environment

  - **CLI Version      : 1.66.0**
  - **Framework Version: 1.66.0**
  - **Node.js Version: v14.11.0** <!-- Version of Node.js (run the command `node -v`) -->
  - **OS               :  Linux x86_64**
  - **Language (Version): Typescript** <!-- [all | TypeScript (3.8.3) | Java (8)| Python (3.7.3) | etc... ] -->

### Other

<!-- e.g. detailed explanation, stacktraces, related issues, suggestions on how to fix, links for us to have context, eg. associated pull-request, stackoverflow, slack, etc -->




--- 

This is :bug: Bug Report
","[pipelines] self-update build fails with named pipeline stack <!-- description of the bug: --> When naming the pipeline stack using the `stackName` property with a different name than the `id`, the self-update build fails with an error that it cannot find the stack. ### Reproduction Steps <!-- minimal amount of code that causes the bug (if possible) or a reference: --> Create a pipeline project and give the pipeline stack a custom name. ```typescript import * as cdk from '@aws-cdk/core'; import { PipelineStack } from '../lib/pipeline-stack'; const app = new cdk.App(); new PipelineStack(app, 'PipelineStack', { stackName: 'Pipeline' }); app.synth(); ``` Then deploy the project and have a look at the pipeline execution. ### What did you expect to happen? <!-- What were you trying to achieve by performing the steps above? --> I expected the pipeline stack to be named 'Pipeline'. This happened successfully on the first deploy from my local command line. Then I expected the pipeline build to execute successfully and update the pipeline, however this step failed. It works fine, when I don't supply a `stackName`. ### What actually happened? The update build failed with the error message that it could not find the stack 'Pipeline'. <!-- What is the unexpected behavior you were seeing? If you got an error, paste it here. --> ``` 95 No stack found matching 'Pipeline'. Use ""list"" to print manifest 96 Error: No stack found matching 'Pipeline'. Use ""list"" to print manifest 97 at CloudAssembly.selectStacks (/usr/local/lib/node_modules/aws-cdk/lib/api/cxapp/cloud-assembly.ts:115:15) 98 at CdkToolkit.selectStacksForDeploy (/usr/local/lib/node_modules/aws-cdk/lib/cdk-toolkit.ts:381:35) 99 at CdkToolkit.deploy (/usr/local/lib/node_modules/aws-cdk/lib/cdk-toolkit.ts:111:20) 100 at initCommandLine (/usr/local/lib/node_modules/aws-cdk/bin/cdk.ts:197:9) ``` ### Environment - **CLI Version : 1.66.0** - **Framework Version: 1.66.0** - **Node.js Version: v14.11.0** <!-- Version of Node.js (run the command `node -v`) --> - **OS : Linux x86_64** - **Language (Version): Typescript** <!-- [all | TypeScript (3.8.3) | Java (8)| Python (3.7.3) | etc... ] --> ### Other <!-- e.g. detailed explanation, stacktraces, related issues, suggestions on how to fix, links for us to have context, eg. associated pull-request, stackoverflow, slack, etc --> --- This is :bug: Bug Report "
49292,49292,54840,https://api.github.com/repos/ukanth/afwall/issues/327,0.0,2014-11-23T15:34:06Z,NONE,https://api.github.com/repos/ukanth/afwall,Tethering DNS problem,"When AFWALL is enabled, USB tethering DNS resolution does not work. However, browsing sites by ip works, so the only problem is the DNS.

`(Tethering) - DHCP+DNS services` is enabled.
Enabling or disabling `(root) - Applications running as root` or `(Kernel) - Linux Kernel` has no effect.

Versions: AFWall+ (v1.3.4.1), Android 4.4.4 Cyanogenmod 11-20140805-M9-hammerhead, Nexus 5.

There were similar issues before: #178 , #4 

Edit: Using Black list mode solves this, see attached image.
![screenshot_2014-12-07-12-11-30](https://cloud.githubusercontent.com/assets/5030488/5330634/2db14bf2-7e0b-11e4-8c4f-b6366b7163ad.png)
","Tethering DNS problem When AFWALL is enabled, USB tethering DNS resolution does not work. However, browsing sites by ip works, so the only problem is the DNS. `(Tethering) - DHCP+DNS services` is enabled. Enabling or disabling `(root) - Applications running as root` or `(Kernel) - Linux Kernel` has no effect. Versions: AFWall+ (v1.3.4.1), Android 4.4.4 Cyanogenmod 11-20140805-M9-hammerhead, Nexus 5. There were similar issues before: #178 , #4 Edit: Using Black list mode solves this, see attached image. ![screenshot_2014-12-07-12-11-30](https://cloud.githubusercontent.com/assets/5030488/5330634/2db14bf2-7e0b-11e4-8c4f-b6366b7163ad.png) "
555559,555559,617408,https://api.github.com/repos/quitegreensky/akivymd/issues/2,1.0,2020-08-07T12:59:58Z,CONTRIBUTOR,https://api.github.com/repos/quitegreensky/akivymd,I have some youtube tutorials i would like to show you,"@quitegreensky Only if you accept, I can give you the link to check it out and add it to the README.md documentation if you like","I have some youtube tutorials i would like to show you @quitegreensky Only if you accept, I can give you the link to check it out and add it to the README.md documentation if you like"
583765,583765,648708,https://api.github.com/repos/klikli-dev/occultism/issues/204,0.0,2021-03-12T22:33:33Z,NONE,https://api.github.com/repos/klikli-dev/occultism,Abras' Conjure says no uses,"**Describe the bug**
The page about Abras' Conjure says that it has no uses but the rainy weather and thunderstorm ritual pages say otherwise

**To Reproduce**
Steps to reproduce the behavior:
1. Open Dictionary of Spirits
2. Go to Abras' Conjure, it says no uses
3. Go to rainy weather/thunderstorm ritual page, says needs Abras' Conjure

**Expected behavior**
Ritual page of Abras' Conjure shows uses.

**Screenshots**
![grafik](https://user-images.githubusercontent.com/42120270/111005171-9b59a100-838a-11eb-82f5-952b14b02858.png)
![grafik](https://user-images.githubusercontent.com/42120270/111005189-a1e81880-838a-11eb-9dbc-0fbf04380f23.png)

**System (please complete the following information):**
- Occultism Version: occultism-1.16.5-1.0.15
- OS: Windows 10
- Minecraft Version: 1.16.5
- Forge 36.0.54
- curios-forge-1.16.5-4.0.5.0
- Patchouli-1.16.4-50
- jei-1.16.4-7.6.1.71","Abras' Conjure says no uses **Describe the bug** The page about Abras' Conjure says that it has no uses but the rainy weather and thunderstorm ritual pages say otherwise **To Reproduce** Steps to reproduce the behavior: 1. Open Dictionary of Spirits 2. Go to Abras' Conjure, it says no uses 3. Go to rainy weather/thunderstorm ritual page, says needs Abras' Conjure **Expected behavior** Ritual page of Abras' Conjure shows uses. **Screenshots** ![grafik](https://user-images.githubusercontent.com/42120270/111005171-9b59a100-838a-11eb-82f5-952b14b02858.png) ![grafik](https://user-images.githubusercontent.com/42120270/111005189-a1e81880-838a-11eb-9dbc-0fbf04380f23.png) **System (please complete the following information):** - Occultism Version: occultism-1.16.5-1.0.15 - OS: Windows 10 - Minecraft Version: 1.16.5 - Forge 36.0.54 - curios-forge-1.16.5-4.0.5.0 - Patchouli-1.16.4-50 - jei-1.16.4-7.6.1.71"
654556,654556,727587,https://api.github.com/repos/nucypher/nuit/issues/8,0.0,2021-04-21T09:19:45Z,CONTRIBUTOR,https://api.github.com/repos/nucypher/nuit,Mobile Layout issues,"mobile portrait layout needs some work

https://d.pr/i/B9J2nI",Mobile Layout issues mobile portrait layout needs some work https://d.pr/i/B9J2nI
534543,534543,594118,https://api.github.com/repos/noinnion/greader/issues/111,1.0,2016-01-07T09:36:14Z,NONE,https://api.github.com/repos/noinnion/greader,No RTL support,"There is no support for languages with **_RTL (Right To Left)**_ direction. This makes it really hard and cumbersome to read articles in these languages.You can examine this by e.g. this blog in Persian language:

www.zoomit.ir
",No RTL support There is no support for languages with **_RTL (Right To Left)**_ direction. This makes it really hard and cumbersome to read articles in these languages.You can examine this by e.g. this blog in Persian language: www.zoomit.ir 
373999,373999,415755,https://api.github.com/repos/cloud-bulldozer/osde2e-scale-wrapper/issues/20,1.0,2020-12-01T15:38:05Z,COLLABORATOR,https://api.github.com/repos/cloud-bulldozer/osde2e-scale-wrapper,Change some logging to debug,"We have some command output being given as info when it should likely be in debug. Particularly during the thread creation. We should trim the info down to something like ""Starting cluster X""

```
2020-12-01 15:34:32.624 INFO osde2e-wrapper - _build_cluster: Attempting cluster installation
2020-12-01 15:34:32.624 INFO osde2e-wrapper - _build_cluster: Output directory set to /osde2e/dec_1/329
2020-12-01 15:34:47.635 INFO osde2e-wrapper - main: Starting Cluster thread 331
```","Change some logging to debug We have some command output being given as info when it should likely be in debug. Particularly during the thread creation. We should trim the info down to something like ""Starting cluster X"" ``` 2020-12-01 15:34:32.624 INFO osde2e-wrapper - _build_cluster: Attempting cluster installation 2020-12-01 15:34:32.624 INFO osde2e-wrapper - _build_cluster: Output directory set to /osde2e/dec_1/329 2020-12-01 15:34:47.635 INFO osde2e-wrapper - main: Starting Cluster thread 331 ```"
790957,790957,679530,https://api.github.com/repos/dothq-extensions/shield-db/issues/7,1.0,2021-03-07T23:42:47Z,MEMBER,https://api.github.com/repos/dothq-extensions/shield-db,TODO: Credit owners of lists in sources.ts,We should credit the owners of the lists that are being used for Dot Shield because it's the right thing to do.,TODO: Credit owners of lists in sources.ts We should credit the owners of the lists that are being used for Dot Shield because it's the right thing to do.
777377,777377,543538,https://api.github.com/repos/native-ly/native-color-picker/issues/110,0.0,2020-09-23T18:52:01Z,MEMBER,https://api.github.com/repos/native-ly/native-color-picker,Fix types,,Fix types 
307919,307919,342366,https://api.github.com/repos/graphql-dotnet/graphql-dotnet/issues/1867,1.0,2020-09-17T22:36:20Z,NONE,https://api.github.com/repos/graphql-dotnet/graphql-dotnet,Field arguments not available on FieldConfig,"I'm using the `Action<SchemaBuilder>` parameter of `Schema.For` to customise some GraphQL types in a schema. In particular I'd like to set the descriptions of some field arguments this way, but it seems `FieldConfig` (from `builder.Types.For(""myType"").FieldFor(""myField"", services)`) doesn't have an `Arguments` field exposing this metadata. Is there a particular reason for this? It seems like an omission to me.","Field arguments not available on FieldConfig I'm using the `Action<SchemaBuilder>` parameter of `Schema.For` to customise some GraphQL types in a schema. In particular I'd like to set the descriptions of some field arguments this way, but it seems `FieldConfig` (from `builder.Types.For(""myType"").FieldFor(""myField"", services)`) doesn't have an `Arguments` field exposing this metadata. Is there a particular reason for this? It seems like an omission to me."
89486,89486,99466,https://api.github.com/repos/JF002/Pinetime/issues/78,0.0,2020-10-04T00:29:44Z,CONTRIBUTOR,https://api.github.com/repos/JF002/Pinetime,Going out of range makes reconnection fail,"For some reason I can't reconnect to the PineTime after going out of range for a bit of time. 

Everything else I have is still able to, so something about the PineTime and/or NimBLE causes issues.","Going out of range makes reconnection fail For some reason I can't reconnect to the PineTime after going out of range for a bit of time. Everything else I have is still able to, so something about the PineTime and/or NimBLE causes issues."
529140,529140,588119,https://api.github.com/repos/snowpackjs/snowpack/issues/2961,0.0,2021-03-22T17:00:19Z,NONE,https://api.github.com/repos/snowpackjs/snowpack,[BUG] error importing files from a folder starting with . since v3.1.0,"### Bug Report Quick Checklist

- [x] I am on the latest version of Snowpack & all plugins.
- [x] I use package manager **yarn** (Fill in: npm, yarn, pnpm, etc).
- [x] I run Snowpack on OS **windows** (Fill in: Windows, Mac, Linux, etc).
- [x] I run Snowpack on Node.js v12+

### Describe the bug

Files are no longer found when imported from a folder that begins with `.` inside of the src folder

### To Reproduce

1. `npm init snowpack-app --template @snowpack/app-template-svelte`
2. Add a file in a folder that starts with a dot to the src folder, something like `/src/.test/hello.js`
3. import file from another js/svelte file like `src
4. run build
5. See error! `[13:55:08] [snowpack] Error: Not Found (/dist/.test/hello.js)`

### Expected behavior

A clear and concise description of what you expected to happen.

### Anything else?

This was working in 3.0.13

If you change the above subfolder name from `.test` to `_test` then everything works.

Repro repo setup here: https://github.com/johlrich/snowpack-import-repro
","[BUG] error importing files from a folder starting with . since v3.1.0 ### Bug Report Quick Checklist - [x] I am on the latest version of Snowpack & all plugins. - [x] I use package manager **yarn** (Fill in: npm, yarn, pnpm, etc). - [x] I run Snowpack on OS **windows** (Fill in: Windows, Mac, Linux, etc). - [x] I run Snowpack on Node.js v12+ ### Describe the bug Files are no longer found when imported from a folder that begins with `.` inside of the src folder ### To Reproduce 1. `npm init snowpack-app --template @snowpack/app-template-svelte` 2. Add a file in a folder that starts with a dot to the src folder, something like `/src/.test/hello.js` 3. import file from another js/svelte file like `src 4. run build 5. See error! `[13:55:08] [snowpack] Error: Not Found (/dist/.test/hello.js)` ### Expected behavior A clear and concise description of what you expected to happen. ### Anything else? This was working in 3.0.13 If you change the above subfolder name from `.test` to `_test` then everything works. Repro repo setup here: https://github.com/johlrich/snowpack-import-repro "
519816,519816,577701,https://api.github.com/repos/vukisic/SCADA_Project/issues/68,1.0,2021-02-16T10:09:41Z,OWNER,https://api.github.com/repos/vukisic/SCADA_Project,NetworkModelService,Transition of NetworkModelService to ServiceFabric Stateful service with Azure Table Storage,NetworkModelService Transition of NetworkModelService to ServiceFabric Stateful service with Azure Table Storage
409927,409927,455639,https://api.github.com/repos/apache/incubator-echarts/issues/13974,0.0,2021-01-07T14:02:10Z,NONE,https://api.github.com/repos/apache/incubator-echarts,"Error: Unknown object type ""asyncfunction"" in rollup-plugin-typescript2","### Version
5.0.0

### Steps to reproduce
https://github.com/apache/incubator-echarts/wiki/How-to-setup-the-dev-environment

Called `node build/build.js --watch`, got:

```
i18n build completed
[1/5/2021, 1:34:05 PM] build bundle start
[1/5/2021, 1:34:22 PM] build error

PLUGIN_ERROR

Error: Unknown object type ""asyncfunction""
    at Object._object (/Users/kmadejski/Projects/echarts/node_modules/rollup-plugin-typescript2/dist/rollup-plugin-typescript2.cjs.js:23697:17)
```

### What is expected?
Project will build

### What is actually happening?
Is not building

---
This is registered as https://github.com/ezolenko/rollup-plugin-typescript2/issues/105, bumping version to 0.29.x resolved the issue, will send PR.

Question: What is the general approach to fix issue present in multiple versions. Do you:

- fix it in newest and backmerge
- fix in oldest supported version observed and cherry-picked in new?
- some other approach?

It would be good to document it in https://github.com/apache/incubator-echarts/wiki/How-to-make-a-pull-request.

<!-- This issue is generated by echarts-issue-helper. DO NOT REMOVE -->
<!-- This issue is in English. DO NOT REMOVE -->","Error: Unknown object type ""asyncfunction"" in rollup-plugin-typescript2 ### Version 5.0.0 ### Steps to reproduce https://github.com/apache/incubator-echarts/wiki/How-to-setup-the-dev-environment Called `node build/build.js --watch`, got: ``` i18n build completed [1/5/2021, 1:34:05 PM] build bundle start [1/5/2021, 1:34:22 PM] build error PLUGIN_ERROR Error: Unknown object type ""asyncfunction"" at Object._object (/Users/kmadejski/Projects/echarts/node_modules/rollup-plugin-typescript2/dist/rollup-plugin-typescript2.cjs.js:23697:17) ``` ### What is expected? Project will build ### What is actually happening? Is not building --- This is registered as https://github.com/ezolenko/rollup-plugin-typescript2/issues/105, bumping version to 0.29.x resolved the issue, will send PR. Question: What is the general approach to fix issue present in multiple versions. Do you: - fix it in newest and backmerge - fix in oldest supported version observed and cherry-picked in new? - some other approach? It would be good to document it in https://github.com/apache/incubator-echarts/wiki/How-to-make-a-pull-request. <!-- This issue is generated by echarts-issue-helper. DO NOT REMOVE --> <!-- This issue is in English. DO NOT REMOVE -->"
773279,773279,502603,https://api.github.com/repos/X-Sharp/XSharpPublic/issues/568,0.0,2021-02-17T10:51:02Z,NONE,https://api.github.com/repos/X-Sharp/XSharpPublic,ADS Function parameters not set as IN/OUT ,"**Describe the bug**

Parameters set for AS CHAR[] in ADS Function definitions should have InAttribute] [OutAttribute]  added.

e.g.

```
	[DllImport(""ace32.dll"", CharSet := CharSet.Ansi)];
        PUBLIC STATIC EXTERN METHOD AdsGetServerName(hConnect AS IntPtr, pucName AS CHAR[] , pusLen REF WORD ) AS DWORD 
```

Should be [InAttribute] [OutAttribute] pucName AS CHAR[]

```
	[DllImport(""ace32.dll"", CharSet := CharSet.Ansi)];
        PUBLIC STATIC EXTERN METHOD AdsGetServerName(hConnect AS IntPtr, [InAttribute] [OutAttribute] pucName AS CHAR[] , pusLen REF WORD ) AS DWORD 
```


Another example is 

```
 [DllImport(""ace32.dll"", CharSet := CharSet.Ansi)];
        PUBLIC STATIC EXTERN METHOD AdsGetServerTime(hConnect AS IntPtr,  pucDateBuf AS CHAR[], pusDateBufLen REF WORD , plTime OUT INT , [InAttribute] [OutAttribute] pucTimeBuf AS CHAR[] , pusTimeBufLen REF WORD ) AS DWORD 
```
	
Should be [InAttribute] [OutAttribute] pucDateBuf AS CHAR[]   (pucTimeBuf  is ok !)
	
```
    [DllImport(""ace32.dll"", CharSet := CharSet.Ansi)];
        PUBLIC STATIC EXTERN METHOD AdsGetServerTime(hConnect AS IntPtr,  [InAttribute] [OutAttribute] pucDateBuf AS CHAR[], pusDateBufLen REF WORD , plTime OUT INT , [InAttribute] [OutAttribute] pucTimeBuf AS CHAR[] , pusTimeBufLen REF WORD ) AS DWORD 
```

**Expected behavior**
Without the above change, the call to each function passes nothing back in the Reference Value.

**Additional context**
There are quite a few wrong, but some ok e.g. AdsGetLastError() is ok.
","ADS Function parameters not set as IN/OUT **Describe the bug** Parameters set for AS CHAR[] in ADS Function definitions should have InAttribute] [OutAttribute] added. e.g. ``` [DllImport(""ace32.dll"", CharSet := CharSet.Ansi)]; PUBLIC STATIC EXTERN METHOD AdsGetServerName(hConnect AS IntPtr, pucName AS CHAR[] , pusLen REF WORD ) AS DWORD ``` Should be [InAttribute] [OutAttribute] pucName AS CHAR[] ``` [DllImport(""ace32.dll"", CharSet := CharSet.Ansi)]; PUBLIC STATIC EXTERN METHOD AdsGetServerName(hConnect AS IntPtr, [InAttribute] [OutAttribute] pucName AS CHAR[] , pusLen REF WORD ) AS DWORD ``` Another example is ``` [DllImport(""ace32.dll"", CharSet := CharSet.Ansi)]; PUBLIC STATIC EXTERN METHOD AdsGetServerTime(hConnect AS IntPtr, pucDateBuf AS CHAR[], pusDateBufLen REF WORD , plTime OUT INT , [InAttribute] [OutAttribute] pucTimeBuf AS CHAR[] , pusTimeBufLen REF WORD ) AS DWORD ``` Should be [InAttribute] [OutAttribute] pucDateBuf AS CHAR[] (pucTimeBuf is ok !) ``` [DllImport(""ace32.dll"", CharSet := CharSet.Ansi)]; PUBLIC STATIC EXTERN METHOD AdsGetServerTime(hConnect AS IntPtr, [InAttribute] [OutAttribute] pucDateBuf AS CHAR[], pusDateBufLen REF WORD , plTime OUT INT , [InAttribute] [OutAttribute] pucTimeBuf AS CHAR[] , pusTimeBufLen REF WORD ) AS DWORD ``` **Expected behavior** Without the above change, the call to each function passes nothing back in the Reference Value. **Additional context** There are quite a few wrong, but some ok e.g. AdsGetLastError() is ok. "
276537,276537,307541,https://api.github.com/repos/cta-wave/dash-hls/issues/26,0.0,2021-01-27T10:42:48Z,COLLABORATOR,https://api.github.com/repos/cta-wave/dash-hls,Definitions Need Updating,"The definitions section was abandoned at the start, it needs a cleanup pass after text editorial is complete

Terms of note needing definitions:
- Active Bit-Rate (4.1.2)
- Aggregating Response (4.2.2)","Definitions Need Updating The definitions section was abandoned at the start, it needs a cleanup pass after text editorial is complete Terms of note needing definitions: - Active Bit-Rate (4.1.2) - Aggregating Response (4.2.2)"
367077,367077,408059,https://api.github.com/repos/lggruspe/slipbox/issues/9,0.0,2021-03-18T03:51:27Z,OWNER,https://api.github.com/repos/lggruspe/slipbox,Fix notes preprocessor,"Notes preprocessor inserts HTML comments into notes, so it only supports Markdown and HTML? It's supposed to work with other formats supported by Pandoc.","Fix notes preprocessor Notes preprocessor inserts HTML comments into notes, so it only supports Markdown and HTML? It's supposed to work with other formats supported by Pandoc."
715695,715695,795436,https://api.github.com/repos/kosatnkn/cauldron/issues/10,0.0,2021-05-23T02:02:24Z,OWNER,https://api.github.com/repos/kosatnkn/cauldron,License File not Removing,The `LICENSE` file should be removed in the created new project.,License File not Removing The `LICENSE` file should be removed in the created new project.
183462,183462,203951,https://api.github.com/repos/Kotlin/dokka/issues/1753,2.0,2021-02-23T10:39:13Z,NONE,https://api.github.com/repos/Kotlin/dokka,Dokka Javadoc plugin currently does not support generating documentation for multiplatform project,"**Question**
An older version of 1.4.0-rc is working, but new one generates this error

**Screenshots**
If applicable, add screenshots to help explain your problem

**Installation**
- Operating system: Linux
- Build tool: Gradle v6.8.2
- Dokka version: 1.4.20

**Additional context**
I need exactly javadoc, because I need to push my library to Maven Central, and javadoc is one of artifactory requirements.
```
plugins {
    ....
    id(""org.jetbrains.dokka"") version ""1.4.10.2""
    ...
}

...
tasks {
    create<Jar>(""javadocJar"") {
        dependsOn(dokkaJavadoc)
        archiveClassifier.set(""javadoc"")
        from(dokkaJavadoc.get().outputDirectory)
    }

    dokkaJavadoc {
        dokkaSourceSets {
            named(""commonMain"") {
                displayName.set(""common"")
                platform.set(org.jetbrains.dokka.Platform.common)
            }
        }
    }
}
...
```
","Dokka Javadoc plugin currently does not support generating documentation for multiplatform project **Question** An older version of 1.4.0-rc is working, but new one generates this error **Screenshots** If applicable, add screenshots to help explain your problem **Installation** - Operating system: Linux - Build tool: Gradle v6.8.2 - Dokka version: 1.4.20 **Additional context** I need exactly javadoc, because I need to push my library to Maven Central, and javadoc is one of artifactory requirements. ``` plugins { .... id(""org.jetbrains.dokka"") version ""1.4.10.2"" ... } ... tasks { create<Jar>(""javadocJar"") { dependsOn(dokkaJavadoc) archiveClassifier.set(""javadoc"") from(dokkaJavadoc.get().outputDirectory) } dokkaJavadoc { dokkaSourceSets { named(""commonMain"") { displayName.set(""common"") platform.set(org.jetbrains.dokka.Platform.common) } } } } ... ``` "
571373,571373,634960,https://api.github.com/repos/oauth2-proxy/oauth2-proxy/issues/1037,2.0,2021-02-10T09:51:59Z,NONE,https://api.github.com/repos/oauth2-proxy/oauth2-proxy,Question: Call auth server /userinfo endpoint and forward content to resource servers,"I would like oauth2-proxy to get the userinfo from authorization server after getting the access_token. I tried to figure out whether oauth2-proxy is able to do that. But I could not get an answer from your documentation.

## Expected Behavior

I would like to have something like that:

- The user is redirected to the authorization server to login.
- The user is redirected back to oauth2-proxy.
- oauth2-proxy uses the token endpoint to get an access token
- HOWTO: oauth2-proxy uses the userinfo endpoint to get further user information
- HOWTO: oauth2-proxy caches the userinfo for every access_token (as long as valid)
- oauth2-proxy returns a session cookie
- HOWTO: oauth2-proxy provides access_token AND the userinfo to resource server

The HOWTOs are what I am not sure about.

## Current Behavior

That's the question. I saw that there is an option --profile-url that may point to a userinfo endpoint. But I am not sure what it does? Is it only for getting the E-mail address?

The concrete questions are:
- How does oauth2-proxy use the userinfo endpoint of authorization server?
- Is it possible to forward the userinfo results to the resource server with every request?",Question: Call auth server /userinfo endpoint and forward content to resource servers I would like oauth2-proxy to get the userinfo from authorization server after getting the access_token. I tried to figure out whether oauth2-proxy is able to do that. But I could not get an answer from your documentation. ## Expected Behavior I would like to have something like that: - The user is redirected to the authorization server to login. - The user is redirected back to oauth2-proxy. - oauth2-proxy uses the token endpoint to get an access token - HOWTO: oauth2-proxy uses the userinfo endpoint to get further user information - HOWTO: oauth2-proxy caches the userinfo for every access_token (as long as valid) - oauth2-proxy returns a session cookie - HOWTO: oauth2-proxy provides access_token AND the userinfo to resource server The HOWTOs are what I am not sure about. ## Current Behavior That's the question. I saw that there is an option --profile-url that may point to a userinfo endpoint. But I am not sure what it does? Is it only for getting the E-mail address? The concrete questions are: - How does oauth2-proxy use the userinfo endpoint of authorization server? - Is it possible to forward the userinfo results to the resource server with every request?
313819,313819,348891,https://api.github.com/repos/EGC-Hueznar/decide/issues/210,1.0,2021-01-09T11:24:06Z,NONE,https://api.github.com/repos/EGC-Hueznar/decide,CA-037 Implementar logout en el bot de Discord,,CA-037 Implementar logout en el bot de Discord 
281547,281547,313109,https://api.github.com/repos/rosalindfranklininstitute/rfi-file-monitor/issues/159,1.0,2021-01-13T15:26:39Z,MEMBER,https://api.github.com/repos/rosalindfranklininstitute/rfi-file-monitor,DirectoryWatchdogEngine: distinguish between patterns for files and directories,The allowed patterns and ignored patterns are currently applied to both files and directories which is not very useful.,DirectoryWatchdogEngine: distinguish between patterns for files and directories The allowed patterns and ignored patterns are currently applied to both files and directories which is not very useful.
534767,534767,594361,https://api.github.com/repos/pharo-project/pharo/issues/8955,0.0,2021-04-04T11:02:58Z,MEMBER,https://api.github.com/repos/pharo-project/pharo,failing test on CI: ReleaseTest>>testUndeclared,"**Bug description**
a method in RBChangeMethodNameRefactoring accesses a variable that does not exist.

Error
Found undeclared references: #(#searchInPackages)
Stacktrace
TestFailure
Found undeclared references: #(#searchInPackages)
ReleaseTest(TestAsserter)>>assert:description:resumable:
ReleaseTest(TestAsserter)>>assert:description:
ReleaseTest>>testUndeclared",failing test on CI: ReleaseTest>>testUndeclared **Bug description** a method in RBChangeMethodNameRefactoring accesses a variable that does not exist. Error Found undeclared references: #(#searchInPackages) Stacktrace TestFailure Found undeclared references: #(#searchInPackages) ReleaseTest(TestAsserter)>>assert:description:resumable: ReleaseTest(TestAsserter)>>assert:description: ReleaseTest>>testUndeclared
427255,427255,474931,https://api.github.com/repos/postgrespro/pg_probackup/issues/342,0.0,2021-03-05T14:00:11Z,CONTRIBUTOR,https://api.github.com/repos/postgrespro/pg_probackup,More robust overwriting of pg_probackup.conf,Currently there are no error-checking and no synchronization to disk before rename.,More robust overwriting of pg_probackup.conf Currently there are no error-checking and no synchronization to disk before rename.
347678,347678,386526,https://api.github.com/repos/polyadic/funcky/issues/264,1.0,2021-01-11T17:24:24Z,CONTRIBUTOR,https://api.github.com/repos/polyadic/funcky,Add Nullary Overloads for `True` and `False`,,Add Nullary Overloads for `True` and `False` 
737886,737886,149315,https://api.github.com/repos/ScottPlot/ScottPlot/issues/833,0.0,2021-02-25T08:44:46Z,NONE,https://api.github.com/repos/ScottPlot/ScottPlot,"CoordinateFromPixelY, CoordinateFromPixel provides incorrect data","Hi,

I have noticed that CoordinateFromPixelY provides incorrect data, this bug can be seen in demo as well with mousemove event.

I am plotting my own data with plotsignal event, tried with scatter and got the same results. The data is plotted correctly as i have already tested it out.

My data
![image](https://user-images.githubusercontent.com/19565936/109126420-e2725000-7755-11eb-990b-16507ddbb461.png)

Demo
![image](https://user-images.githubusercontent.com/19565936/109126782-51e83f80-7756-11eb-930a-1685d947d74c.png)


```cs
 private void Ploter_MouseMove(object sender, MouseEventArgs e)
        {
            double mouseCoordY = e.MouseDevice.GetPosition(Ploter).Y;
            YCoordinateLabel.Text = $""{Ploter.plt.CoordinateFromPixelY(mouseCoordY):0.00000000}"";
            Ploter.Render();
        }
```

I tried other demos, but demo code is done with different lib than it is in nuget from Scott WPF.","CoordinateFromPixelY, CoordinateFromPixel provides incorrect data Hi, I have noticed that CoordinateFromPixelY provides incorrect data, this bug can be seen in demo as well with mousemove event. I am plotting my own data with plotsignal event, tried with scatter and got the same results. The data is plotted correctly as i have already tested it out. My data ![image](https://user-images.githubusercontent.com/19565936/109126420-e2725000-7755-11eb-990b-16507ddbb461.png) Demo ![image](https://user-images.githubusercontent.com/19565936/109126782-51e83f80-7756-11eb-930a-1685d947d74c.png) ```cs private void Ploter_MouseMove(object sender, MouseEventArgs e) { double mouseCoordY = e.MouseDevice.GetPosition(Ploter).Y; YCoordinateLabel.Text = $""{Ploter.plt.CoordinateFromPixelY(mouseCoordY):0.00000000}""; Ploter.Render(); } ``` I tried other demos, but demo code is done with different lib than it is in nuget from Scott WPF."
432266,432266,480545,https://api.github.com/repos/KMCGamer/google-domain-filter/issues/35,0.0,2020-12-23T15:13:55Z,OWNER,https://api.github.com/repos/KMCGamer/google-domain-filter,Allow user to choose method of filtering,"There are two ways to go about filtering a domain from a google search:

1. Add `-site:` to the initial query.
2. Loop over page results and add `displaynone` to each result match.

There are pros and cons to each.

#### `-site`:
##### Pros:
1. Removes any chance of a domain showing up in the results at the http request level (this is a big pro).
##### Cons:
1. In page google search apps such as ""define"" and ""translate"" will not show up (this is a google issue, not a bug).
2. `-site:` search query shows up on the google search page and is ugly.
3. DOM manipulation is annoyingly difficult and finicky. It is hard to account for every possibility. 
4. Also, what if google changes their html/css/js, then this method would not work.

#### `displaynone`:
##### Pros:
1. It is easier to just make a google search result disappear from the page based a domain match.
##### Cons:
1. There may be instances where a google search page has few to no results if you filter many domains or your query is narrow.

You will need to allow the user to make the choice between these two methods, all while educating the user on the differences between them.","Allow user to choose method of filtering There are two ways to go about filtering a domain from a google search: 1. Add `-site:` to the initial query. 2. Loop over page results and add `displaynone` to each result match. There are pros and cons to each. #### `-site`: ##### Pros: 1. Removes any chance of a domain showing up in the results at the http request level (this is a big pro). ##### Cons: 1. In page google search apps such as ""define"" and ""translate"" will not show up (this is a google issue, not a bug). 2. `-site:` search query shows up on the google search page and is ugly. 3. DOM manipulation is annoyingly difficult and finicky. It is hard to account for every possibility. 4. Also, what if google changes their html/css/js, then this method would not work. #### `displaynone`: ##### Pros: 1. It is easier to just make a google search result disappear from the page based a domain match. ##### Cons: 1. There may be instances where a google search page has few to no results if you filter many domains or your query is narrow. You will need to allow the user to make the choice between these two methods, all while educating the user on the differences between them."
347449,347449,386263,https://api.github.com/repos/MauroDataMapper/mdm-ui/issues/134,1.0,2021-05-20T08:08:17Z,NONE,https://api.github.com/repos/MauroDataMapper/mdm-ui,Add link to documentation to home page for MDM ,"https://maurodatamapper.github.io

Add link above to home page for all instances, in BIG BOLD Letters.. possibly flashing with a giphy so you don't miss it.","Add link to documentation to home page for MDM https://maurodatamapper.github.io Add link above to home page for all instances, in BIG BOLD Letters.. possibly flashing with a giphy so you don't miss it."
749281,749281,261605,https://api.github.com/repos/gcurtiss/protocol3/issues/8,0.0,2021-03-16T13:44:09Z,COLLABORATOR,https://api.github.com/repos/gcurtiss/protocol3,/stats returns ranking of -1 for all players and Time played is none,code monkeys go brrrrr,/stats returns ranking of -1 for all players and Time played is none code monkeys go brrrrr
763407,763407,403222,https://api.github.com/repos/zapccu/HMCCU/issues/47,0.0,2021-05-17T12:04:56Z,OWNER,https://api.github.com/repos/zapccu/HMCCU,Autoscaling of values with unit 100% doesn't work for HMCCUDEV devices,,Autoscaling of values with unit 100% doesn't work for HMCCUDEV devices 
522841,522841,581072,https://api.github.com/repos/magicalmusings/magicalmusings.github.io/issues/24,1.0,2020-10-10T20:56:16Z,OWNER,https://api.github.com/repos/magicalmusings/magicalmusings.github.io,5E SRD: Add 4th-Level Spells to Spell List,"The following 4th Level Spells from the 5th Edition System Reference Document (5e SRD) need to be added in Markdown format to the site under the ```_posts/spells/fourth-level/``` directory. There will be a template-spell.md file in the spells folder for use as needed. 

You can find information on Spells, including sources, at the following link:
https://5e.tools/spells.html

## Specifications

- Post should be titled ```YYYY-MM-DD-spells-4-<spell_name>.md```
  - EXAMPLE: 2020-10-10-spells-0-kaboom.md
- Follow ```template-spell.md``` format for inputting spell information. Info should include:
  - Spell Name (Druid Splash)
  - School (i.e. Evocation, Necromancy)
  - Casting Time (i.e. 1 Bonus Action)
  - Range (i.e. Self / 60 Feet)
  - Duration (i.e. Instantaneous)
  - Components (i.e. V, S, M)
- Pull requests should include completed spell post in the proper directory: ```_posts/spells/cantrips/YYYY-MM-DD-spells-4-<spell_name>.md```

## Spells Needed

- [x] Arcane Eye

- [x] Aura of Life 

- [x] Aura of Purity

- [x] Banishment

- [x] Blight

- [x] Charm Monster

- [x] Compulsion

- [x] Confusion

- [x] Conjure Barlgura (UA)

- [x] Conjure Knowbot (UA)

- [x] Conjure Minor Elementals

- [x] Conjure Woodland Beings

- [x] Control Water

- [x] Death Ward

- [x] Dimension Door

- [x] Divination

- [x] Dominate Beast

- [x] Ego Whip (UA)

- [x] Elemental Bane

- [x] Evard's Black Tentacles

- [x] Fabricate

- [x] Find Greater Steed

- [x] Fire Shield

- [x] Freedom of Movement

- [x] Galder's Speedy Courier

- [x] Giant Insect

- [x] Grasping Vine

- [x] Gravity Sinkhole

- [x] Greater Invisibility

- [x] Guardian of Faith

- [x] Guardian of Nature

- [x] Hallucinatory Terrain

- [x] Ice Storm

- [x] Leomund's Secret Chest

- [x] Locate Creature

- [x] Mordenkainen's Faithful Hound

- [x] Mordenkainen's Private Sanctum

- [ ] Otiluke's Resilient Sphere

- [ ] Phantasmal Killer

- [ ] Polymorph

- [ ] Shadow of Moil

- [ ] Sickening Radiance

- [ ] Staggering Smite

- [ ] Stone Shape

- [ ] Stoneskin

- [ ] Storm Sphere

- [ ] Summon Abberant Spirit (UA)

- [ ] Summon Elemental Spirit (UA)

- [ ] Summon Greater Demon

- [ ] Synchronicity (UA)

- [ ] System Backdoor (UA)

- [ ] Vitriolic Sphere

- [ ] Wall of Fire

- [ ] Watery Sphere","5E SRD: Add 4th-Level Spells to Spell List The following 4th Level Spells from the 5th Edition System Reference Document (5e SRD) need to be added in Markdown format to the site under the ```_posts/spells/fourth-level/``` directory. There will be a template-spell.md file in the spells folder for use as needed. You can find information on Spells, including sources, at the following link: https://5e.tools/spells.html ## Specifications - Post should be titled ```YYYY-MM-DD-spells-4-<spell_name>.md``` - EXAMPLE: 2020-10-10-spells-0-kaboom.md - Follow ```template-spell.md``` format for inputting spell information. Info should include: - Spell Name (Druid Splash) - School (i.e. Evocation, Necromancy) - Casting Time (i.e. 1 Bonus Action) - Range (i.e. Self / 60 Feet) - Duration (i.e. Instantaneous) - Components (i.e. V, S, M) - Pull requests should include completed spell post in the proper directory: ```_posts/spells/cantrips/YYYY-MM-DD-spells-4-<spell_name>.md``` ## Spells Needed - [x] Arcane Eye - [x] Aura of Life - [x] Aura of Purity - [x] Banishment - [x] Blight - [x] Charm Monster - [x] Compulsion - [x] Confusion - [x] Conjure Barlgura (UA) - [x] Conjure Knowbot (UA) - [x] Conjure Minor Elementals - [x] Conjure Woodland Beings - [x] Control Water - [x] Death Ward - [x] Dimension Door - [x] Divination - [x] Dominate Beast - [x] Ego Whip (UA) - [x] Elemental Bane - [x] Evard's Black Tentacles - [x] Fabricate - [x] Find Greater Steed - [x] Fire Shield - [x] Freedom of Movement - [x] Galder's Speedy Courier - [x] Giant Insect - [x] Grasping Vine - [x] Gravity Sinkhole - [x] Greater Invisibility - [x] Guardian of Faith - [x] Guardian of Nature - [x] Hallucinatory Terrain - [x] Ice Storm - [x] Leomund's Secret Chest - [x] Locate Creature - [x] Mordenkainen's Faithful Hound - [x] Mordenkainen's Private Sanctum - [ ] Otiluke's Resilient Sphere - [ ] Phantasmal Killer - [ ] Polymorph - [ ] Shadow of Moil - [ ] Sickening Radiance - [ ] Staggering Smite - [ ] Stone Shape - [ ] Stoneskin - [ ] Storm Sphere - [ ] Summon Abberant Spirit (UA) - [ ] Summon Elemental Spirit (UA) - [ ] Summon Greater Demon - [ ] Synchronicity (UA) - [ ] System Backdoor (UA) - [ ] Vitriolic Sphere - [ ] Wall of Fire - [ ] Watery Sphere"
746877,746877,238004,https://api.github.com/repos/kochetkov/DotLauncher/issues/3,1.0,2021-03-09T23:22:25Z,OWNER,https://api.github.com/repos/kochetkov/DotLauncher,Caching game information obtained from Origin,,Caching game information obtained from Origin 
634493,634493,705191,https://api.github.com/repos/Inboxen/Inboxen/issues/146,1.0,2016-04-22T11:06:35Z,MEMBER,https://api.github.com/repos/Inboxen/Inboxen,"""Report problem"" button","A button to allow users to report problems.

Issues like #101 are hard to diagnose without access to the offending email. Also, I don't have permission to go trawling through Jessica's emails to find one that has the reported issue. A ""report problem"" button would be quite explicit about giving admins permission to access whatever they need to to resolve the issue, as well as giving them other relevant information (user, browser, etc.)

Solution:

Extend the current ticketing system with extra field(s ) and create views for reporting from a particular page (e.g. one for those without JS, and an API endpoint for those who have)
","""Report problem"" button A button to allow users to report problems. Issues like #101 are hard to diagnose without access to the offending email. Also, I don't have permission to go trawling through Jessica's emails to find one that has the reported issue. A ""report problem"" button would be quite explicit about giving admins permission to access whatever they need to to resolve the issue, as well as giving them other relevant information (user, browser, etc.) Solution: Extend the current ticketing system with extra field(s ) and create views for reporting from a particular page (e.g. one for those without JS, and an API endpoint for those who have) "
774849,774849,518349,https://api.github.com/repos/typeorm/typeorm/issues/2136,0.0,2018-05-14T13:29:33Z,NONE,https://api.github.com/repos/typeorm/typeorm,ALTER query on every start with a CURRENT_TIMESTAMP default in MySQL,"**Issue type:**

[ ] question
[x] bug report
[ ] feature request
[ ] documentation issue

**Database system/driver:**

[ ] `cordova`
[ ] `mongodb`
[ ] `mssql`
[x] `mysql` / `mariadb`
[ ] `oracle`
[ ] `postgres`
[ ] `sqlite`
[ ] `sqljs`
[ ] `react-native`

**TypeORM version:**

[x] `latest`
[ ] `@next`
[ ] `0.x.x` (or put your version here)

**Steps to reproduce or a small repository showing the problem:**
When connecting to a MySQL database with `default: () => 'CURRENT_TIMESTAMP'` on one of the properties, the column will receive an ALTER query.

https://gist.github.com/Ionaru/6744272f96b122eda1abbdf8d46131d1

Queries that are executed when running the script:
```sql
START TRANSACTION
SELECT DATABASE() AS `db_name`
SELECT * FROM `INFORMATION_SCHEMA`.`TABLES` WHERE (`TABLE_SCHEMA` = 'web_evetrack_test_2' AND `TABLE_NAME` = 'bar')
SELECT * FROM `INFORMATION_SCHEMA`.`COLUMNS` WHERE (`TABLE_SCHEMA` = 'web_evetrack_test_2' AND `TABLE_NAME` = 'bar')
SELECT * FROM `INFORMATION_SCHEMA`.`KEY_COLUMN_USAGE` WHERE `CONSTRAINT_NAME` = 'PRIMARY' AND ((`TABLE_SCHEMA` = 'web_evetrack_test_2' AND `TABLE_NAME` = 'bar'))
SELECT `SCHEMA_NAME`, `DEFAULT_CHARACTER_SET_NAME` as `CHARSET`, `DEFAULT_COLLATION_NAME` AS `COLLATION` FROM `INFORMATION_SCHEMA`.`SCHEMATA`
SELECT `s`.* FROM `INFORMATION_SCHEMA`.`STATISTICS` `s` LEFT JOIN `INFORMATION_SCHEMA`.`REFERENTIAL_CONSTRAINTS` `rc` ON `s`.`INDEX_NAME` = `rc`.`CONSTRAINT_NAME` WHERE ((`s`.`TABLE_SCHEMA` = 'web_evetrack_test_2' AND `s`.`TABLE_NAME` = 'bar')) AND `s`.`INDEX_NAME` != 'PRIMARY' AND `rc`.`CONSTRAINT_NAME` IS NULL
SELECT `kcu`.`TABLE_SCHEMA`, `kcu`.`TABLE_NAME`, `kcu`.`CONSTRAINT_NAME`, `kcu`.`COLUMN_NAME`, `kcu`.`REFERENCED_TABLE_SCHEMA`, `kcu`.`REFERENCED_TABLE_NAME`, `kcu`.`REFERENCED_COLUMN_NAME`, `rc`.`DELETE_RULE` `ON_DELETE`, `rc`.`UPDATE_RULE` `ON_UPDATE` FROM `INFORMATION_SCHEMA`.`KEY_COLUMN_USAGE` `kcu` INNER JOIN `INFORMATION_SCHEMA`.`REFERENTIAL_CONSTRAINTS` `rc` ON `rc`.`constraint_name` = `kcu`.`constraint_name` WHERE (`kcu`.`TABLE_SCHEMA` = 'web_evetrack_test_2' AND `kcu`.`TABLE_NAME` = 'bar')
ALTER TABLE `bar` CHANGE `lastLogin` `lastLogin` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP
COMMIT
```

**Edit**
Loks like this is an issue with the Date type field as a whole, the same ALTER query behaviour is happening with this column:
```typescript
    @Column({
        nullable: true,
    })
    public lastLogin?: Date;
```
```sql
...
ALTER TABLE `bar` CHANGE `tokenExpiry` `tokenExpiry` datetime NULL
COMMIT
```","ALTER query on every start with a CURRENT_TIMESTAMP default in MySQL **Issue type:** [ ] question [x] bug report [ ] feature request [ ] documentation issue **Database system/driver:** [ ] `cordova` [ ] `mongodb` [ ] `mssql` [x] `mysql` / `mariadb` [ ] `oracle` [ ] `postgres` [ ] `sqlite` [ ] `sqljs` [ ] `react-native` **TypeORM version:** [x] `latest` [ ] `@next` [ ] `0.x.x` (or put your version here) **Steps to reproduce or a small repository showing the problem:** When connecting to a MySQL database with `default: () => 'CURRENT_TIMESTAMP'` on one of the properties, the column will receive an ALTER query. https://gist.github.com/Ionaru/6744272f96b122eda1abbdf8d46131d1 Queries that are executed when running the script: ```sql START TRANSACTION SELECT DATABASE() AS `db_name` SELECT * FROM `INFORMATION_SCHEMA`.`TABLES` WHERE (`TABLE_SCHEMA` = 'web_evetrack_test_2' AND `TABLE_NAME` = 'bar') SELECT * FROM `INFORMATION_SCHEMA`.`COLUMNS` WHERE (`TABLE_SCHEMA` = 'web_evetrack_test_2' AND `TABLE_NAME` = 'bar') SELECT * FROM `INFORMATION_SCHEMA`.`KEY_COLUMN_USAGE` WHERE `CONSTRAINT_NAME` = 'PRIMARY' AND ((`TABLE_SCHEMA` = 'web_evetrack_test_2' AND `TABLE_NAME` = 'bar')) SELECT `SCHEMA_NAME`, `DEFAULT_CHARACTER_SET_NAME` as `CHARSET`, `DEFAULT_COLLATION_NAME` AS `COLLATION` FROM `INFORMATION_SCHEMA`.`SCHEMATA` SELECT `s`.* FROM `INFORMATION_SCHEMA`.`STATISTICS` `s` LEFT JOIN `INFORMATION_SCHEMA`.`REFERENTIAL_CONSTRAINTS` `rc` ON `s`.`INDEX_NAME` = `rc`.`CONSTRAINT_NAME` WHERE ((`s`.`TABLE_SCHEMA` = 'web_evetrack_test_2' AND `s`.`TABLE_NAME` = 'bar')) AND `s`.`INDEX_NAME` != 'PRIMARY' AND `rc`.`CONSTRAINT_NAME` IS NULL SELECT `kcu`.`TABLE_SCHEMA`, `kcu`.`TABLE_NAME`, `kcu`.`CONSTRAINT_NAME`, `kcu`.`COLUMN_NAME`, `kcu`.`REFERENCED_TABLE_SCHEMA`, `kcu`.`REFERENCED_TABLE_NAME`, `kcu`.`REFERENCED_COLUMN_NAME`, `rc`.`DELETE_RULE` `ON_DELETE`, `rc`.`UPDATE_RULE` `ON_UPDATE` FROM `INFORMATION_SCHEMA`.`KEY_COLUMN_USAGE` `kcu` INNER JOIN `INFORMATION_SCHEMA`.`REFERENTIAL_CONSTRAINTS` `rc` ON `rc`.`constraint_name` = `kcu`.`constraint_name` WHERE (`kcu`.`TABLE_SCHEMA` = 'web_evetrack_test_2' AND `kcu`.`TABLE_NAME` = 'bar') ALTER TABLE `bar` CHANGE `lastLogin` `lastLogin` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMIT ``` **Edit** Loks like this is an issue with the Date type field as a whole, the same ALTER query behaviour is happening with this column: ```typescript @Column({ nullable: true, }) public lastLogin?: Date; ``` ```sql ... ALTER TABLE `bar` CHANGE `tokenExpiry` `tokenExpiry` datetime NULL COMMIT ```"
258121,258121,287081,https://api.github.com/repos/autopkg/apettinen-recipes/issues/29,0.0,2020-12-09T11:05:06Z,NONE,https://api.github.com/repos/autopkg/apettinen-recipes,Git LFS recipes broken due to upstream changes to macOS release packaging,"As of v2.12.0 of git-lfs the packaging/release format for git-lfs has changed (See: https://github.com/git-lfs/git-lfs/releases/tag/v2.12.0) and this is causing the AutoPkg recipes to silently fail.

Specifically, the `git-lfs` maintainers have stopped packaging macOS releases as compressed `.tar.gz` archives and, instead, are now packaging them as `.zip` files. The reason for this change is due to Apple not allowing tarballs to be signed/notarized (but `.zip` files are) and more info about this change can be seen in the inciting PR here => https://github.com/git-lfs/git-lfs/pull/4143

As you can see below, the most recent release that the AutoPkg recipe is picking up is the final release of `git-lfs` which was packaged as a tarball (and newer, more recent releases are being ignored):
```
$ autopkg run git-lfs.munki
Processing git-lfs.munki...

The following new items were downloaded:
    Download Path
    -------------
    /Users/Shared/autopkg/Cache/local.munki.git-lfs/downloads/git-lfs-amd64-2.11.0.tar.gz

The following packages were built:
    Identifier          Version  Pkg Path
    ----------          -------  --------
    com.github.git-lfs  2.11.0   /Users/Shared/autopkg/Cache/local.munki.git-lfs/git-lfs-amd64-2.11.0.pkg
```","Git LFS recipes broken due to upstream changes to macOS release packaging As of v2.12.0 of git-lfs the packaging/release format for git-lfs has changed (See: https://github.com/git-lfs/git-lfs/releases/tag/v2.12.0) and this is causing the AutoPkg recipes to silently fail. Specifically, the `git-lfs` maintainers have stopped packaging macOS releases as compressed `.tar.gz` archives and, instead, are now packaging them as `.zip` files. The reason for this change is due to Apple not allowing tarballs to be signed/notarized (but `.zip` files are) and more info about this change can be seen in the inciting PR here => https://github.com/git-lfs/git-lfs/pull/4143 As you can see below, the most recent release that the AutoPkg recipe is picking up is the final release of `git-lfs` which was packaged as a tarball (and newer, more recent releases are being ignored): ``` $ autopkg run git-lfs.munki Processing git-lfs.munki... The following new items were downloaded: Download Path ------------- /Users/Shared/autopkg/Cache/local.munki.git-lfs/downloads/git-lfs-amd64-2.11.0.tar.gz The following packages were built: Identifier Version Pkg Path ---------- ------- -------- com.github.git-lfs 2.11.0 /Users/Shared/autopkg/Cache/local.munki.git-lfs/git-lfs-amd64-2.11.0.pkg ```"
347662,347662,386508,https://api.github.com/repos/0m4r/MMM-covid19/issues/8,0.0,2021-01-12T03:50:20Z,NONE,https://api.github.com/repos/0m4r/MMM-covid19,module doesn't show country's information,"I installed the module and tried exact same as sample configuration.
It only showed World numbers but countries.

Here is the output.

![image](https://user-images.githubusercontent.com/29009351/104267302-559e5c00-545f-11eb-9297-e8e89a133eb9.png)
",module doesn't show country's information I installed the module and tried exact same as sample configuration. It only showed World numbers but countries. Here is the output. ![image](https://user-images.githubusercontent.com/29009351/104267302-559e5c00-545f-11eb-9297-e8e89a133eb9.png) 
54160,54160,60255,https://api.github.com/repos/blindlobstar/games-predictions/issues/54,1.0,2021-04-21T21:04:06Z,OWNER,https://api.github.com/repos/blindlobstar/games-predictions,Create `GameAuth` service,Implement service for getting SteamId and notofing about it,Create `GameAuth` service Implement service for getting SteamId and notofing about it
403824,403824,448845,https://api.github.com/repos/MelvorIdle/melvoridle.github.io/issues/840,0.0,2021-03-16T00:31:02Z,CONTRIBUTOR,https://api.github.com/repos/MelvorIdle/melvoridle.github.io,Minor: Getting set to 0 HP by the first hit of a multi-hit enemy special attack does not kill the player,"**Describe the bug**
If you are set to 0 HP by the first hit of a multi-hit special attack, you will not die and are able to regenerate hitpoints and cheat death.

**To Reproduce**
To test this I first set up a monster to reliably produce the edge case:
```js
enemySpecialAttacks[3].chance = 100;
MONSTERS[0].hasSpecialAttack = true;
MONSTERS[0].specialAttackID = [3];
```
I then breakpointed the `attackPlayer()` call for the first hit of a multi-hit spec, and started combat with the monster (in this case Black Knight)
At the breakpoint I set player HP to ` combatData.player.hitpoints = 10`
Then I let the game continue execution, and you can see that you get set to 0 HP and don't die. Eating food/having regen can bring you back to life.

**Expected behavior**
If the first hit of a mult-hit enemy special attack sets the player to 0 HP they should die.

**Fix**
- [x] Add the death checking code after the first call to `attackPlayer` for a multi-hit enemy special attack
```js
        if (
          enemyAttackCount > 1 &&
          !combatData.enemy.stunned &&
          !combatData.enemy.sleep
        ) {
          attackPlayer(enemySpec, specID);
         // Insert the death checking here
          let enemyCombatStatus = checkCombatStatus(0);
          if (!enemyCombatStatus) {
            //DEATH
            monsterStats[enemyInCombat].stats[3]++;
            stopCombat(true, true);
          }
          // End of inserted code
          let count = 1;
          if (
            combatData.player.hitpoints > 0 &&
            combatData.enemy.hitpoints > 0
          ) {
            enemyAttackTimer = setInterval(function () {
              attackPlayer(enemySpec, specID);
              count++;
              if (
                (count >= enemyAttackCount ||
                  combatData.player.hitpoints <= 0) &&
                combatData.enemy.hitpoints > 0
              ) {
                clearInterval(enemyAttackTimer);
                if (combatData.enemy.intoTheMist) {
                  combatData.enemy.intoTheMist = false;
                  combatData.enemy.increasedDamageReduction = 0;
                  activateEnemyBuffs();
                }
                let enemyCombatStatus = checkCombatStatus(0);
                //Repeat if not ded
                if (enemyCombatStatus) startCombat(2);
                else {
                  //DEATH
                  monsterStats[enemyInCombat].stats[3]++;
                  stopCombat(true, true);
                }
              }
            }, count * attackInterval);
          }

```
**Browser**
Browser agnostic bug.

**Are you using any scripts?**
Nothing but the above modifications to produce the edge case.
","Minor: Getting set to 0 HP by the first hit of a multi-hit enemy special attack does not kill the player **Describe the bug** If you are set to 0 HP by the first hit of a multi-hit special attack, you will not die and are able to regenerate hitpoints and cheat death. **To Reproduce** To test this I first set up a monster to reliably produce the edge case: ```js enemySpecialAttacks[3].chance = 100; MONSTERS[0].hasSpecialAttack = true; MONSTERS[0].specialAttackID = [3]; ``` I then breakpointed the `attackPlayer()` call for the first hit of a multi-hit spec, and started combat with the monster (in this case Black Knight) At the breakpoint I set player HP to ` combatData.player.hitpoints = 10` Then I let the game continue execution, and you can see that you get set to 0 HP and don't die. Eating food/having regen can bring you back to life. **Expected behavior** If the first hit of a mult-hit enemy special attack sets the player to 0 HP they should die. **Fix** - [x] Add the death checking code after the first call to `attackPlayer` for a multi-hit enemy special attack ```js if ( enemyAttackCount > 1 && !combatData.enemy.stunned && !combatData.enemy.sleep ) { attackPlayer(enemySpec, specID); // Insert the death checking here let enemyCombatStatus = checkCombatStatus(0); if (!enemyCombatStatus) { //DEATH monsterStats[enemyInCombat].stats[3]++; stopCombat(true, true); } // End of inserted code let count = 1; if ( combatData.player.hitpoints > 0 && combatData.enemy.hitpoints > 0 ) { enemyAttackTimer = setInterval(function () { attackPlayer(enemySpec, specID); count++; if ( (count >= enemyAttackCount || combatData.player.hitpoints <= 0) && combatData.enemy.hitpoints > 0 ) { clearInterval(enemyAttackTimer); if (combatData.enemy.intoTheMist) { combatData.enemy.intoTheMist = false; combatData.enemy.increasedDamageReduction = 0; activateEnemyBuffs(); } let enemyCombatStatus = checkCombatStatus(0); //Repeat if not ded if (enemyCombatStatus) startCombat(2); else { //DEATH monsterStats[enemyInCombat].stats[3]++; stopCombat(true, true); } } }, count * attackInterval); } ``` **Browser** Browser agnostic bug. **Are you using any scripts?** Nothing but the above modifications to produce the edge case. "
220840,220840,245585,https://api.github.com/repos/maemo-leste/bugtracker/issues/426,0.0,2020-07-20T18:02:36Z,NONE,https://api.github.com/repos/maemo-leste/bugtracker,We need to set all the standard XDG_* envvars,"spec:
https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html",We need to set all the standard XDG_* envvars spec: https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html
347685,347685,386534,https://api.github.com/repos/ginger-kang/gagopa/issues/14,0.0,2021-01-07T16:48:59Z,CONTRIBUTOR,https://api.github.com/repos/ginger-kang/gagopa,濡洹몄 湲곕,"## ㅇ 댁 댁

濡洹몄 ㅽ , 臾대 寃쎄李쎌 .

##  湲곕 寃곌낵

濡洹몄 ㅽ  寃쎄李 ㅼ

##  ㅽщ┛

","濡洹몄 湲곕 ## ㅇ 댁 댁 濡洹몄 ㅽ , 臾대 寃쎄李쎌 . ##  湲곕 寃곌낵 濡洹몄 ㅽ  寃쎄李 ㅼ ##  ㅽщ┛ "
327080,327080,363609,https://api.github.com/repos/cloud-barista/cb-spider/issues/330,0.0,2021-02-09T11:09:34Z,MEMBER,https://api.github.com/repos/cloud-barista/cb-spider,[AWS Driver] Error when adding a new subnet with an existing VPC,"### 利
- 湲곗〈  VPC 濡 subnet 異媛 寃쎌 ㅻ 諛
- AWS Subnet  , Spider 硫 蹂댁 異媛吏 .
- 愿 API AddSubnet()

### 遺
- AWS Driver VPC 諛 Subnet  NameID ㅼ 怨 吏 .
- 李멸 
![image](https://user-images.githubusercontent.com/46367962/107353519-7a462c00-6b10-11eb-951a-2dc205ea36fb.png)
","[AWS Driver] Error when adding a new subnet with an existing VPC ### 利 - 湲곗〈 VPC 濡 subnet 異媛 寃쎌 ㅻ 諛 - AWS Subnet  , Spider 硫 蹂댁 異媛吏 . - 愿 API AddSubnet() ### 遺 - AWS Driver VPC 諛 Subnet  NameID ㅼ 怨 吏 . - 李멸 ![image](https://user-images.githubusercontent.com/46367962/107353519-7a462c00-6b10-11eb-951a-2dc205ea36fb.png) "
713107,713107,792536,https://api.github.com/repos/rucio/rucio/issues/2213,1.0,2019-02-18T15:14:56Z,MEMBER,https://api.github.com/repos/rucio/rucio,Removing last replica which is a constituent,"Motivation
----------
When the last replica of a file is removed in the reaper, it should only be removed from the dataset if it is not a constituent of an existing archive replica. This also implies, if a archive replica is removed and there are no replicas on the constituents, the constituents need to be removed from their parent datasets.
","Removing last replica which is a constituent Motivation ---------- When the last replica of a file is removed in the reaper, it should only be removed from the dataset if it is not a constituent of an existing archive replica. This also implies, if a archive replica is removed and there are no replicas on the constituents, the constituents need to be removed from their parent datasets. "
131961,131961,146684,https://api.github.com/repos/crowbartools/Firebot/issues/1203,1.0,2021-05-27T03:10:49Z,COLLABORATOR,https://api.github.com/repos/crowbartools/Firebot,[Feature Request] Show channel reward cost in table,"ebiggz via Discord:

Setari suggested it might be good to show the channel reward costs at the top level table!",[Feature Request] Show channel reward cost in table ebiggz via Discord: Setari suggested it might be good to show the channel reward costs at the top level table!
346878,346878,385629,https://api.github.com/repos/yiisoft/yii2/issues/18572,2.0,2021-03-18T11:42:41Z,NONE,https://api.github.com/repos/yiisoft/yii2,Problem after creating crud generator using gii(yii2),"
I am running using this
http://localhost/yiiadv/advanced/frontend/web/index.php?r=entry
how to run the code?
I am getting this error

Not Found (#404)
Page not found.
The above error occurred while the Web server was processing your request.

Please contact us if you think this is a server error. Thank you.",Problem after creating crud generator using gii(yii2) I am running using this http://localhost/yiiadv/advanced/frontend/web/index.php?r=entry how to run the code? I am getting this error Not Found (#404) Page not found. The above error occurred while the Web server was processing your request. Please contact us if you think this is a server error. Thank you.
138725,138725,154189,https://api.github.com/repos/metanorma/mn-samples-iho/issues/66,1.0,2021-02-24T10:45:50Z,CONTRIBUTOR,https://api.github.com/repos/metanorma/mn-samples-iho,Update GHA workflow to latest metanorma-build-scripts,"https://github.com/metanorma/metanorma-build-scripts/blob/66c598c9b41922c505aa9d03b0999f1c6e8e5ca9/cimas-config/gh-actions/samples/macos.yml#L26-L32

This is very clean. Can we update the repo to use this?",Update GHA workflow to latest metanorma-build-scripts https://github.com/metanorma/metanorma-build-scripts/blob/66c598c9b41922c505aa9d03b0999f1c6e8e5ca9/cimas-config/gh-actions/samples/macos.yml#L26-L32 This is very clean. Can we update the repo to use this?
611807,611807,679893,https://api.github.com/repos/simonschaufi/gkh_rss_import/issues/13,0.0,2021-03-15T15:21:31Z,NONE,https://api.github.com/repos/simonschaufi/gkh_rss_import,Invalid cache identifier for image with parameters,"When I installed the extension and put it on a page, edit the plugin and then view my page I get a typo3 error message.  So I can't see the page anymore. I used the latest version of the plugin 7.0.2 and I use typo3 version 10.4.13.
This is the error:

Core: Exception handler (WEB): Uncaught TYPO3 Exception: #1233058486: ""ff85589e3e130c31938d33f3f65f9beb96e30a79sl=1"" is not a valid cache entry identifier. | InvalidArgumentException thrown in file /data/html/typo3source/versie10/typo3_src-10.4.13/typo3/sysext/core/Classes/Cache/Frontend/AbstractFrontend.php in line 91. Requested URL: ......
","Invalid cache identifier for image with parameters When I installed the extension and put it on a page, edit the plugin and then view my page I get a typo3 error message. So I can't see the page anymore. I used the latest version of the plugin 7.0.2 and I use typo3 version 10.4.13. This is the error: Core: Exception handler (WEB): Uncaught TYPO3 Exception: #1233058486: ""ff85589e3e130c31938d33f3f65f9beb96e30a79sl=1"" is not a valid cache entry identifier. | InvalidArgumentException thrown in file /data/html/typo3source/versie10/typo3_src-10.4.13/typo3/sysext/core/Classes/Cache/Frontend/AbstractFrontend.php in line 91. Requested URL: ...... "
726451,726451,34661,https://api.github.com/repos/nx-dotnet/nx-dotnet/issues/27,0.0,2021-04-27T17:32:41Z,CONTRIBUTOR,https://api.github.com/repos/nx-dotnet/nx-dotnet,[BUG] Output directory does not follow the Nx pattern,"**Describe the bug**
The output directory added to the `csproj` file after generating a new project does not follow the pattern used by official Nx plugins. The generator `@nrwl/angular:application` (for example) will specify an output path that is identical to the project root, other than a `dist/` prefix.

**To Reproduce**
Steps to reproduce the behavior:
1. Create a new Nx workspace
2. Generate a new .NET application with `npx nx generate @nx-dotnet/core:app my-app --template console --language C# --test-template none`
3. Open the generated file `apps/my-app/MyApp.csproj`
4. The `OutputPath` element specifies a path of `../../dist/my-app`, which is missing the `apps` part of the original file path.

**Expected behavior**
The `OutputPath` element should have been `../../dist/apps/my-app` to match the pattern of other Nx generators. 

**Environment:**
 - OS: Windows
 - Browser: N/A
 - Version: 0.2.0
 - Affected Packages: `@nx-dotnet/core`

**Additional context**
When the project directory contains additional folder nesting (such as when the `--directory` flag is specified), the `OutputPath` element contains the extra directories, but it still does not contain the `apps` portion of the file path. The output path given in `workspace.json` never includes extra directories and, as a result, is sometimes inconsistent with the `csproj` file.

If the output path follows the standard Nx pattern, then the `outputs` property of the `workspace.json` file becomes unnecessary, as the explicit and default values are the same. It is worth nothing though that `@nrwl/angular` will explicitly specify the output path, even when it matches the inferred default.","[BUG] Output directory does not follow the Nx pattern **Describe the bug** The output directory added to the `csproj` file after generating a new project does not follow the pattern used by official Nx plugins. The generator `@nrwl/angular:application` (for example) will specify an output path that is identical to the project root, other than a `dist/` prefix. **To Reproduce** Steps to reproduce the behavior: 1. Create a new Nx workspace 2. Generate a new .NET application with `npx nx generate @nx-dotnet/core:app my-app --template console --language C# --test-template none` 3. Open the generated file `apps/my-app/MyApp.csproj` 4. The `OutputPath` element specifies a path of `../../dist/my-app`, which is missing the `apps` part of the original file path. **Expected behavior** The `OutputPath` element should have been `../../dist/apps/my-app` to match the pattern of other Nx generators. **Environment:** - OS: Windows - Browser: N/A - Version: 0.2.0 - Affected Packages: `@nx-dotnet/core` **Additional context** When the project directory contains additional folder nesting (such as when the `--directory` flag is specified), the `OutputPath` element contains the extra directories, but it still does not contain the `apps` portion of the file path. The output path given in `workspace.json` never includes extra directories and, as a result, is sometimes inconsistent with the `csproj` file. If the output path follows the standard Nx pattern, then the `outputs` property of the `workspace.json` file becomes unnecessary, as the explicit and default values are the same. It is worth nothing though that `@nrwl/angular` will explicitly specify the output path, even when it matches the inferred default."
28374,28374,31599,https://api.github.com/repos/RenderHeads/UnityPlugin-AVProDeckLink/issues/38,1.0,2021-01-18T04:48:33Z,NONE,https://api.github.com/repos/RenderHeads/UnityPlugin-AVProDeckLink,Add timecode to output SDI,"Is it possible to add timecode to the output?
I wish I could add the SDI input timecode to the output timecode.
In a similar discussion in the past, it was said that it would be supported in the future.
I would like to know if it is currently in progress.","Add timecode to output SDI Is it possible to add timecode to the output? I wish I could add the SDI input timecode to the output timecode. In a similar discussion in the past, it was said that it would be supported in the future. I would like to know if it is currently in progress."
156622,156622,174130,https://api.github.com/repos/altitudenetworks/dynamoquery/issues/71,0.0,2021-03-12T19:32:55Z,NONE,https://api.github.com/repos/altitudenetworks/dynamoquery,added extra fields in upsert_record breaks _convert_record,"upsert_record on DynamoTable breaks when using DynamoDictClass record.  In the upsert_record code it converts the passed in record to a dict and then adds extra fields which it passes to _convert_record.  The default implementation attempts to pass the dict into the record_class constructor.  It doesn't look like dataclasses are designed to handle this method of initialization or maybe there is a bug as I get an error about missing required positional arguments for all of the required fields in the record.

Below is a test (pytest) that exhibits the behavior.
Python version: 3.8.5
OS: ubuntu 20.04 (WSL)
requires moto

```
import logging
from dataclasses import dataclass
from typing import Any, Optional

import boto3
from dynamo_query import DynamoDictClass, DynamoTable
from moto import mock_dynamodb2

@dataclass
class MyTestRecord(DynamoDictClass):
  required1: str
  required2: str
  optional: Optional[str] = None

  @DynamoDictClass.compute_key(""pk"")
  def get_pk(self) -> str:
    return self.required1

  @DynamoDictClass.compute_key(""sort"")
  def get_sort(self) -> str:
    return self.required2


# Create your dynamo table manager with your record class
class MyTestTable(DynamoTable[MyTestRecord]):
  sort_key_name = ""sort""
  record_class = MyTestRecord

  def __init__(self, table_name: str, endpoint_url: str = None, logger: Optional[logging.Logger] = None) -> None:
    super().__init__(logger=logger)
    self.table_name = table_name
    self.endpoint_url = endpoint_url

  # use this property to define your table resource
  @property
  def table(self) -> Any:
    return boto3.resource(""dynamodb"", endpoint_url=self.endpoint_url,
    region_name=""us-west-1"",
            aws_access_key_id=""null"",
            aws_secret_access_key=""null"").Table(self.table_name)

@mock_dynamodb2
def test_upsert():
  table = MyTestTable(""test"")
  res = table.upsert_record(MyTestRecord(required1=""req1"", required2=""req2"", optional=""opt""))
  assert res is not None

```

The tests fails with this output:
```
=================================== FAILURES ===================================
_________________________________ test_upsert __________________________________
   @mock_dynamodb2
    def test_upsert():
      table = MyTestTable(""test"")
>     res = table.upsert_record(MyTestRecord(required1=""req1"", required2=""req2"", optional=""opt""))

tests/test_dynamoquery_bug.py:45: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
../../venvs/project/lib/python3.8/site-packages/dynamo_query/dynamo_table.py:914: in upsert_record
    new_record = self._convert_record(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <tests.test_dynamoquery_bug.MyTestTable object at 0x7f804f5a9a00>
record = {'dt_created': '2021-03-12T19:19:23.649553', 'dt_modified': '2021-03-12T19:19:23.649553', 'optional': 'opt', 'pk': 'req1', ...}

    def _convert_record(self, record: Union[_RecordType, Dict[str, Any]]) -> _RecordType:
        # pylint: disable=isinstance-second-argument-not-valid-type
        if self.record_class and not isinstance(record, self.record_class):
            # pylint: disable=not-callable
>           return self.record_class(record)  # type: ignore
E           TypeError: __init__() missing 1 required positional argument: 'required2'

../../venvs/project/lib/python3.8/site-packages/dynamo_query/dynamo_table.py:222: TypeError

```","added extra fields in upsert_record breaks _convert_record upsert_record on DynamoTable breaks when using DynamoDictClass record. In the upsert_record code it converts the passed in record to a dict and then adds extra fields which it passes to _convert_record. The default implementation attempts to pass the dict into the record_class constructor. It doesn't look like dataclasses are designed to handle this method of initialization or maybe there is a bug as I get an error about missing required positional arguments for all of the required fields in the record. Below is a test (pytest) that exhibits the behavior. Python version: 3.8.5 OS: ubuntu 20.04 (WSL) requires moto ``` import logging from dataclasses import dataclass from typing import Any, Optional import boto3 from dynamo_query import DynamoDictClass, DynamoTable from moto import mock_dynamodb2 @dataclass class MyTestRecord(DynamoDictClass): required1: str required2: str optional: Optional[str] = None @DynamoDictClass.compute_key(""pk"") def get_pk(self) -> str: return self.required1 @DynamoDictClass.compute_key(""sort"") def get_sort(self) -> str: return self.required2 # Create your dynamo table manager with your record class class MyTestTable(DynamoTable[MyTestRecord]): sort_key_name = ""sort"" record_class = MyTestRecord def __init__(self, table_name: str, endpoint_url: str = None, logger: Optional[logging.Logger] = None) -> None: super().__init__(logger=logger) self.table_name = table_name self.endpoint_url = endpoint_url # use this property to define your table resource @property def table(self) -> Any: return boto3.resource(""dynamodb"", endpoint_url=self.endpoint_url, region_name=""us-west-1"", aws_access_key_id=""null"", aws_secret_access_key=""null"").Table(self.table_name) @mock_dynamodb2 def test_upsert(): table = MyTestTable(""test"") res = table.upsert_record(MyTestRecord(required1=""req1"", required2=""req2"", optional=""opt"")) assert res is not None ``` The tests fails with this output: ``` =================================== FAILURES =================================== _________________________________ test_upsert __________________________________ @mock_dynamodb2 def test_upsert(): table = MyTestTable(""test"") > res = table.upsert_record(MyTestRecord(required1=""req1"", required2=""req2"", optional=""opt"")) tests/test_dynamoquery_bug.py:45: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ../../venvs/project/lib/python3.8/site-packages/dynamo_query/dynamo_table.py:914: in upsert_record new_record = self._convert_record( _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = <tests.test_dynamoquery_bug.MyTestTable object at 0x7f804f5a9a00> record = {'dt_created': '2021-03-12T19:19:23.649553', 'dt_modified': '2021-03-12T19:19:23.649553', 'optional': 'opt', 'pk': 'req1', ...} def _convert_record(self, record: Union[_RecordType, Dict[str, Any]]) -> _RecordType: # pylint: disable=isinstance-second-argument-not-valid-type if self.record_class and not isinstance(record, self.record_class): # pylint: disable=not-callable > return self.record_class(record) # type: ignore E TypeError: __init__() missing 1 required positional argument: 'required2' ../../venvs/project/lib/python3.8/site-packages/dynamo_query/dynamo_table.py:222: TypeError ```"
240854,240854,267891,https://api.github.com/repos/pcko1/bscscan-python/issues/21,0.0,2021-05-26T11:56:47Z,NONE,https://api.github.com/repos/pcko1/bscscan-python,[BUG] Circular import error,"**Describe the bug**
A clear and concise description of what the bug is.

Upon installing either via PyPI or git (master or stable branch) using pipenv the ""from bscscan import BscScan"" import fails with ""ImportError: cannot import name 'BscScan' from partially initialized module 'bscscan' (most likely due to a circular import)"". I am using python 3.8.10.

**To Reproduce**
In order to assist you with your problem, we need a minimal code snippet that replicates the bug. Avoid disclosing your API keys.

Steps to reproduce the behavior:

1. Run ""pipenv install bscscan-python""
2. Create script with single line `from bscscan import BscScan` as suggested from the docs
3. Run script and get error

**Expected behavior**
A clear and concise description of what you expected to happen.

The import should work based on the documentation.

**Screenshots**
If applicable, add screenshots to help explain your problem.

N/A

**System info (please complete the following information):**
 - OS and version: macOS 11.13.1
 - Python version: 3.8.10
 - `bscscan-python` version: 2.0.0

**Additional context**
Add any other context about the problem here.","[BUG] Circular import error **Describe the bug** A clear and concise description of what the bug is. Upon installing either via PyPI or git (master or stable branch) using pipenv the ""from bscscan import BscScan"" import fails with ""ImportError: cannot import name 'BscScan' from partially initialized module 'bscscan' (most likely due to a circular import)"". I am using python 3.8.10. **To Reproduce** In order to assist you with your problem, we need a minimal code snippet that replicates the bug. Avoid disclosing your API keys. Steps to reproduce the behavior: 1. Run ""pipenv install bscscan-python"" 2. Create script with single line `from bscscan import BscScan` as suggested from the docs 3. Run script and get error **Expected behavior** A clear and concise description of what you expected to happen. The import should work based on the documentation. **Screenshots** If applicable, add screenshots to help explain your problem. N/A **System info (please complete the following information):** - OS and version: macOS 11.13.1 - Python version: 3.8.10 - `bscscan-python` version: 2.0.0 **Additional context** Add any other context about the problem here."
693923,693923,771263,https://api.github.com/repos/Samsung/ONE/issues/4433,1.0,2020-09-25T08:05:03Z,CONTRIBUTOR,https://api.github.com/repos/Samsung/ONE,[arser] Support short option,"It would be helpful for users if arser supports short option.

Let's support this!",[arser] Support short option It would be helpful for users if arser supports short option. Let's support this!
189832,189832,211108,https://api.github.com/repos/CLIxIndia-Dev/CLIxDashboard/issues/32,0.0,2021-04-06T04:48:37Z,NONE,https://api.github.com/repos/CLIxIndia-Dev/CLIxDashboard,Reduce Gaps in Mobile View Heading,"**Change Case in Title**
As a Test Engineer, I  want to see the gap in headings reduced in mobile view so that it improves accessibility

**To Reproduce**
Steps to reproduce the behavior:
1. Go to 'https://staging-clixdashboard.tiss.edu/home' on Phone
2. Scroll to Headings
3. See error

**Expected behavior**
There should not be gaps
**Screenshots**
![169492861_233502728561568_3226494481591800555_n](https://user-images.githubusercontent.com/14256897/113660325-71617900-96c1-11eb-9db1-e977116e3cbd.png)

**Desktop (please complete the following information):**
 - OS: [Android 11]
 - Browser [chrome]
 - Version [89.0]
","Reduce Gaps in Mobile View Heading **Change Case in Title** As a Test Engineer, I want to see the gap in headings reduced in mobile view so that it improves accessibility **To Reproduce** Steps to reproduce the behavior: 1. Go to 'https://staging-clixdashboard.tiss.edu/home' on Phone 2. Scroll to Headings 3. See error **Expected behavior** There should not be gaps **Screenshots** ![169492861_233502728561568_3226494481591800555_n](https://user-images.githubusercontent.com/14256897/113660325-71617900-96c1-11eb-9db1-e977116e3cbd.png) **Desktop (please complete the following information):** - OS: [Android 11] - Browser [chrome] - Version [89.0] "
529249,529249,588238,https://api.github.com/repos/SpaceCowboyS01/DekketScris/issues/4,1.0,2021-04-14T16:50:23Z,OWNER,https://api.github.com/repos/SpaceCowboyS01/DekketScris,Documento sezione 4 ,"- Conclusione 
- Riferimenti",Documento sezione 4 - Conclusione - Riferimenti
327963,327963,364589,https://api.github.com/repos/microsoft/TypeScript/issues/38070,0.0,2020-04-20T14:05:09Z,COLLABORATOR,https://api.github.com/repos/microsoft/TypeScript,TypeError: Cannot read property 'escapedName' of undefined in 'getImport' during 'documentHighlights',"<!--header {""fiveLineHash"":""c9833e14d77c75ad25607bf9861a5e6a""} headerend-->
This issue comes from crash dumps in telemetry. We've tried to de-duplicate issues on a best-effort basis, comparing the sequence of methods called and the command requested while ignoring line numbers.
**TypeScript version prefix**: 3.8.3
**VSCode version**: 1.43.2
**Command requested**: documentHighlights
**Hitting sessions**: 1523
**Five line hash**: c9833e14d77c75ad25607bf9861a5e6a
**Stack**:
```
    at getImport (tsserver.js:112740:36)
    at getImportOrExportSymbol (tsserver.js:112653:68)
    at getImportOrExportReferences (tsserver.js:114124:56)
    at getReferencesAtLocation (tsserver.js:114054:17)
    at getReferencesInContainer (tsserver.js:113998:21)
    at getReferencesInContainerOrFiles (tsserver.js:113556:21)
    at getReferencedSymbolsForSymbol (tsserver.js:113547:21)
    at getReferencedSymbolsForNode (tsserver.js:113346:34)
    at getReferenceEntriesForNode (tsserver.js:113065:40)
    at getSemanticDocumentHighlights (tsserver.js:111729:57)
    at getDocumentHighlights (tsserver.js:111717:20)
    at getDocumentHighlights (tsserver.js:135456:42)
    at Session.getDocumentHighlights (tsserver.js:145100:71)
    at _a.<computed> (tsserver.js:144490:61)
    at <anonymous> (tsserver.js:146003:88)
    at Session.executeWithRequestId (tsserver.js:145994:28)
    at Session.executeCommand (tsserver.js:146003:33)
    at Session.onMessage (tsserver.js:146027:35)
    at <anonymous> (tsserver.js:147342:27)
    at unknown (suppressed.js)
    at unknown (suppressed.js)
    at unknown (suppressed.js)
    at unknown (suppressed.js)
    at unknown (suppressed.js)
    at unknown (suppressed.js)
    at unknown (suppressed.js)
    at unknown (suppressed.js)
    at unknown (suppressed.js)
```","TypeError: Cannot read property 'escapedName' of undefined in 'getImport' during 'documentHighlights' <!--header {""fiveLineHash"":""c9833e14d77c75ad25607bf9861a5e6a""} headerend--> This issue comes from crash dumps in telemetry. We've tried to de-duplicate issues on a best-effort basis, comparing the sequence of methods called and the command requested while ignoring line numbers. **TypeScript version prefix**: 3.8.3 **VSCode version**: 1.43.2 **Command requested**: documentHighlights **Hitting sessions**: 1523 **Five line hash**: c9833e14d77c75ad25607bf9861a5e6a **Stack**: ``` at getImport (tsserver.js:112740:36) at getImportOrExportSymbol (tsserver.js:112653:68) at getImportOrExportReferences (tsserver.js:114124:56) at getReferencesAtLocation (tsserver.js:114054:17) at getReferencesInContainer (tsserver.js:113998:21) at getReferencesInContainerOrFiles (tsserver.js:113556:21) at getReferencedSymbolsForSymbol (tsserver.js:113547:21) at getReferencedSymbolsForNode (tsserver.js:113346:34) at getReferenceEntriesForNode (tsserver.js:113065:40) at getSemanticDocumentHighlights (tsserver.js:111729:57) at getDocumentHighlights (tsserver.js:111717:20) at getDocumentHighlights (tsserver.js:135456:42) at Session.getDocumentHighlights (tsserver.js:145100:71) at _a.<computed> (tsserver.js:144490:61) at <anonymous> (tsserver.js:146003:88) at Session.executeWithRequestId (tsserver.js:145994:28) at Session.executeCommand (tsserver.js:146003:33) at Session.onMessage (tsserver.js:146027:35) at <anonymous> (tsserver.js:147342:27) at unknown (suppressed.js) at unknown (suppressed.js) at unknown (suppressed.js) at unknown (suppressed.js) at unknown (suppressed.js) at unknown (suppressed.js) at unknown (suppressed.js) at unknown (suppressed.js) at unknown (suppressed.js) ```"
325146,325146,361455,https://api.github.com/repos/zephyrproject-rtos/zephyr/issues/3514,1.0,2017-04-26T12:40:41Z,COLLABORATOR,https://api.github.com/repos/zephyrproject-rtos/zephyr,Bluetooth: controller: LE Advertising Extensions,"**_Reported by Vinayak Kariappa Chettimada:_**
LE Advertising Extensions controller implementation
(Imported from Jira ZEP-2073)",Bluetooth: controller: LE Advertising Extensions **_Reported by Vinayak Kariappa Chettimada:_** LE Advertising Extensions controller implementation (Imported from Jira ZEP-2073)
376109,376109,418100,https://api.github.com/repos/Samarium150/mirai-console-lolicon/issues/34,1.0,2021-03-23T15:25:35Z,NONE,https://api.github.com/repos/Samarium150/mirai-console-lolicon,野밥瘟API룟瑥룡曆삣餓ｇ,"②ⓧ릎也썲瑥룡긴營瀯窯野쇠닺ⓨㅁ兀ο瑥룡曆삣ゅ阿餓ｇ
get餓ㅵ뻠溫닸δ餓뜻餓ㅵ亮
鰲餓δ양녔у경餓뜹ゆζ誤罌у계⑨
emmm也썲窯밧",野밥瘟API룟瑥룡曆삣餓ｇ ②ⓧ릎也썲瑥룡긴營瀯窯野쇠닺ⓨㅁ兀ο瑥룡曆삣ゅ阿餓ｇ get餓ㅵ뻠溫닸δ餓뜻餓ㅵ亮 鰲餓δ양녔у경餓뜹ゆζ誤罌у계⑨ emmm也썲窯밧
546741,546741,607678,https://api.github.com/repos/confrm/confrm/issues/37,0.0,2021-01-13T07:40:02Z,CONTRIBUTOR,https://api.github.com/repos/confrm/confrm,"When changing node package, only one node can be changed at a time",,"When changing node package, only one node can be changed at a time "
762563,762563,394649,https://api.github.com/repos/bpmn-io/dmn-testing-plugin/issues/21,0.0,2021-04-28T21:15:13Z,NONE,https://api.github.com/repos/bpmn-io/dmn-testing-plugin,Test button won't show in Camunda modeler v4.x,"The test button won't show in Camunda modeler (v4.3 and v4.7.0 tested)

I've dropped the project into resources/plugins of the v4.7.0 Camunda modeler for mac OS (11.2.2).

Open a dmn file, click the overview for a decision table, no test button will show.","Test button won't show in Camunda modeler v4.x The test button won't show in Camunda modeler (v4.3 and v4.7.0 tested) I've dropped the project into resources/plugins of the v4.7.0 Camunda modeler for mac OS (11.2.2). Open a dmn file, click the overview for a decision table, no test button will show."
546184,546184,607056,https://api.github.com/repos/benawad/dogehouse/issues/2335,0.0,2021-04-26T13:08:40Z,NONE,https://api.github.com/repos/benawad/dogehouse,Menu z-index bug,"Account menu BUG

There is a z-index error when I click may account on the navbar the menu.
THE menu is below the ""Your feed""

![sketch-1619442470027](https://user-images.githubusercontent.com/78096552/116087509-8d53ab80-a6be-11eb-9896-a3c2096d1f99.png)
","Menu z-index bug Account menu BUG There is a z-index error when I click may account on the navbar the menu. THE menu is below the ""Your feed"" ![sketch-1619442470027](https://user-images.githubusercontent.com/78096552/116087509-8d53ab80-a6be-11eb-9896-a3c2096d1f99.png) "
431635,431635,479843,https://api.github.com/repos/JoK3rLeE/Asus-S510UQ-BQ178T/issues/4,0.0,2021-01-20T19:40:36Z,NONE,https://api.github.com/repos/JoK3rLeE/Asus-S510UQ-BQ178T,can't sleep/wake,"hi, I have a problem with sleep and can't wake up (black screen). how to fix it?

Asus S510UQ - Big Sur 11.1
","can't sleep/wake hi, I have a problem with sleep and can't wake up (black screen). how to fix it? Asus S510UQ - Big Sur 11.1 "
762946,762946,398529,https://api.github.com/repos/sourcegraph/sourcegraph/issues/16007,0.0,2020-11-20T07:12:20Z,CONTRIBUTOR,https://api.github.com/repos/sourcegraph/sourcegraph,Ensure that indexed repos on Sourcegraph.com are cloned,"We need to ensure that any user owned repos or repos in the `default-repos` table on Sourcegraph.com are always cloned, even after a gitserver rebalance.

See slack for more context: https://sourcegraph.slack.com/archives/CMBA8F926/p1605771633147700
","Ensure that indexed repos on Sourcegraph.com are cloned We need to ensure that any user owned repos or repos in the `default-repos` table on Sourcegraph.com are always cloned, even after a gitserver rebalance. See slack for more context: https://sourcegraph.slack.com/archives/CMBA8F926/p1605771633147700 "
750670,750670,275265,https://api.github.com/repos/AdoptOpenJDK/openjdk-build/issues/2559,0.0,2021-04-07T18:56:24Z,CONTRIBUTOR,https://api.github.com/repos/AdoptOpenJDK/openjdk-build,Slackin badge in README returns 404 error,"**What are you trying to do?**
Click on Slack link in [README](https://github.com/AdoptOpenJDK/openjdk-build#readme)

<img width=""139"" alt=""Screen Shot 2021-04-07 at 2 51 59 PM"" src=""https://user-images.githubusercontent.com/2836948/113919092-2f176500-97b1-11eb-8f0d-33df9412c186.png"">


**Expected behaviour:**
To click on Slack link and be taken to Slack or Slack invite page

**Observed behaviour:**
Click on link returns 404 error
<img width=""687"" alt=""Screen Shot 2021-04-07 at 2 55 06 PM"" src=""https://user-images.githubusercontent.com/2836948/113919165-435b6200-97b1-11eb-8c26-d981d3bdfb45.png"">

","Slackin badge in README returns 404 error **What are you trying to do?** Click on Slack link in [README](https://github.com/AdoptOpenJDK/openjdk-build#readme) <img width=""139"" alt=""Screen Shot 2021-04-07 at 2 51 59 PM"" src=""https://user-images.githubusercontent.com/2836948/113919092-2f176500-97b1-11eb-8f0d-33df9412c186.png""> **Expected behaviour:** To click on Slack link and be taken to Slack or Slack invite page **Observed behaviour:** Click on link returns 404 error <img width=""687"" alt=""Screen Shot 2021-04-07 at 2 55 06 PM"" src=""https://user-images.githubusercontent.com/2836948/113919165-435b6200-97b1-11eb-8c26-d981d3bdfb45.png""> "
545917,545917,606760,https://api.github.com/repos/votca/xtp/issues/653,0.0,2021-01-22T22:53:43Z,MEMBER,https://api.github.com/repos/votca/xtp,BSE Triplet energies with dynamical screening are not written to HDF5,Reason: copy & paste variable names.,BSE Triplet energies with dynamical screening are not written to HDF5 Reason: copy & paste variable names.
437021,437021,485842,https://api.github.com/repos/vabene1111/recipes/issues/266,1.0,2020-12-18T15:27:55Z,NONE,https://api.github.com/repos/vabene1111/recipes,Hosting with traefik + sub-path README,"Hi,

It took me quite some time to figure out how to host this under a sub-path, so I thought I might share this info for others; maybe you can integrate it into the README / examples.

My setup is docker-compose / traefik / apache / recipes. Swapping out apache for nginx should be straightforward.

Relevant parts:

docker-compose:
```yml
  apache:
    # omitting other config
    volumes:
      - ./recipes/static:/var/www/recipes/static:ro
      - ./recipes/media:/var/www/recipes/media:ro
    labels:
      traefik.enable: true
      traefik.http.routers.apache-recipes.rule: Host(`<host>`) && PathPrefix(`/<www path>`)
      traefik.http.routers.apache-recipes.entrypoints: http
      traefik.http.routers.apache-recipes.service: apache
      traefik.http.services.apache.loadbalancer.server.port: 80
      traefik.http.services.apache.loadbalancer.server.scheme: http
...

  recipes:
    volumes:
      - ./recipes/static:/opt/recipes/staticfiles:rw
      - ./recipes/media:/opt/recipes/mediafiles:rw
    environment:
      # all the other env
      - SCRIPT_NAME=/<sub path>
      - STATIC_URL=/<www path>/static/
      - MEDIA_URL=/<www path>/media/
    labels:
      traefik.enable: true
      traefik.http.routers.recipes.rule: Host(`<host>`) && PathPrefix(`/<sub path>`)
      traefik.http.routers.recipes.entrypoints: http
      traefik.http.services.recipes.loadbalancer.server.port: 8080
      traefik.http.services.recipes.loadbalancer.server.scheme: http
```

apache: 
```
  Alias /<www path>/static/ /var/www/recipes/static/
  Alias /<www path>/media/ /var/www/recipes/media/
  <Directory ""/var/www/recipes/"">
    Require all granted
  </Directory>
```

I used two paths `<sub path>` and `<www path>` for simplicity. In my case I have `<sub path> = recipes` and `<www path> = serve/recipes`. One could also change the matching rules of traefik to have everything under one path.

I left out the TLS config in this example for simplicty.","Hosting with traefik + sub-path README Hi, It took me quite some time to figure out how to host this under a sub-path, so I thought I might share this info for others; maybe you can integrate it into the README / examples. My setup is docker-compose / traefik / apache / recipes. Swapping out apache for nginx should be straightforward. Relevant parts: docker-compose: ```yml apache: # omitting other config volumes: - ./recipes/static:/var/www/recipes/static:ro - ./recipes/media:/var/www/recipes/media:ro labels: traefik.enable: true traefik.http.routers.apache-recipes.rule: Host(`<host>`) && PathPrefix(`/<www path>`) traefik.http.routers.apache-recipes.entrypoints: http traefik.http.routers.apache-recipes.service: apache traefik.http.services.apache.loadbalancer.server.port: 80 traefik.http.services.apache.loadbalancer.server.scheme: http ... recipes: volumes: - ./recipes/static:/opt/recipes/staticfiles:rw - ./recipes/media:/opt/recipes/mediafiles:rw environment: # all the other env - SCRIPT_NAME=/<sub path> - STATIC_URL=/<www path>/static/ - MEDIA_URL=/<www path>/media/ labels: traefik.enable: true traefik.http.routers.recipes.rule: Host(`<host>`) && PathPrefix(`/<sub path>`) traefik.http.routers.recipes.entrypoints: http traefik.http.services.recipes.loadbalancer.server.port: 8080 traefik.http.services.recipes.loadbalancer.server.scheme: http ``` apache: ``` Alias /<www path>/static/ /var/www/recipes/static/ Alias /<www path>/media/ /var/www/recipes/media/ <Directory ""/var/www/recipes/""> Require all granted </Directory> ``` I used two paths `<sub path>` and `<www path>` for simplicity. In my case I have `<sub path> = recipes` and `<www path> = serve/recipes`. One could also change the matching rules of traefik to have everything under one path. I left out the TLS config in this example for simplicty."
497851,497851,553337,https://api.github.com/repos/Ride-The-Lightning/RTL/issues/576,0.0,2020-12-23T13:40:29Z,COLLABORATOR,https://api.github.com/repos/Ride-The-Lightning/RTL,Dashboard layout fix,Dashboard layout is not as expected on IPad landscape mode and Operator -> Inbound channel liquidity component.,Dashboard layout fix Dashboard layout is not as expected on IPad landscape mode and Operator -> Inbound channel liquidity component.
669209,669209,743793,https://api.github.com/repos/crev-dev/cargo-crev/issues/152,1.0,2019-01-11T01:04:13Z,COLLABORATOR,https://api.github.com/repos/crev-dev/cargo-crev,`cargo crev change passphrase`,"Especially in the light of #151 , it would be great if people could just re-generate the whole Id file.","`cargo crev change passphrase` Especially in the light of #151 , it would be great if people could just re-generate the whole Id file."
706452,706452,785169,https://api.github.com/repos/LorenzoBettini/edelta/issues/320,1.0,2021-03-18T14:09:49Z,OWNER,https://api.github.com/repos/LorenzoBettini/edelta,Port to Xtext 2.25 and Eclipse 2021-03,,Port to Xtext 2.25 and Eclipse 2021-03 
223572,223572,248632,https://api.github.com/repos/UFOMG/ufomg_be/issues/6,1.0,2021-02-22T18:03:00Z,COLLABORATOR,https://api.github.com/repos/UFOMG/ufomg_be,Make lat and long fields required for report post request,"Change to nullable false in migration and model and send the field through the validation check method within the report resource file.
Add tests for sad path.",Make lat and long fields required for report post request Change to nullable false in migration and model and send the field through the validation check method within the report resource file. Add tests for sad path.
627155,627155,696980,https://api.github.com/repos/frankenstein91/Arch-Ansible-Install/issues/24,1.0,2021-05-01T11:25:22Z,OWNER,https://api.github.com/repos/frankenstein91/Arch-Ansible-Install,no ntp after reboot,"https://github.com/frankenstein91/Arch-Ansible-Install/blob/0ff91cb49a630df2c1afd572d8434ca8ae6ebc80/roles/arch2disk/tasks/main.yml#L15-L19

We forgot to enable NTP in the chroot as well",no ntp after reboot https://github.com/frankenstein91/Arch-Ansible-Install/blob/0ff91cb49a630df2c1afd572d8434ca8ae6ebc80/roles/arch2disk/tasks/main.yml#L15-L19 We forgot to enable NTP in the chroot as well
95580,95580,106233,https://api.github.com/repos/reportportal/reportportal/issues/1244,0.0,2020-12-04T15:48:54Z,NONE,https://api.github.com/repos/reportportal/reportportal,[v5.3.3] 500 error after attempt to delete items marked as 'To Investigate',"**Describe the bug**
Attempt to delete 'To Investigate' items leads to ""errorCode"":5000,""message"":""Unclassified error [org.hibernate.exception.ConstraintViolationException: could not execute statement]"" 

**To Reproduce**
1. I have 3 separate reports (first run, rerun and second rerun). Each run has 'To Investigate' items which means failed test cases.
2. I'm trying to delete all 'To Investigate' items from the first report in order to merge it into the second report without duplicates. Delete operation has been succeed.
3. I'm trying to merge the first and the second reports. Merge operation has been succeed.
4. Now I have only 2 reports (rerun and second rerun) and I'm trying to delete all 'To Investigate' items from the first report in order to merge it into the second one. But the exception was thrown **{""errorCode"":5000,""message"":""Unclassified error [org.hibernate.exception.ConstraintViolationException: could not execute statement]""}**

**Expected behavior**
Delete operation has been succeed

**Screenshots**
![Screenshot_7](https://user-images.githubusercontent.com/17621174/101183309-04c56780-3658-11eb-88ac-da27137389d6.png)

**Additional context**
In previous version of ReportPortal I didn't observe problems like that
","[v5.3.3] 500 error after attempt to delete items marked as 'To Investigate' **Describe the bug** Attempt to delete 'To Investigate' items leads to ""errorCode"":5000,""message"":""Unclassified error [org.hibernate.exception.ConstraintViolationException: could not execute statement]"" **To Reproduce** 1. I have 3 separate reports (first run, rerun and second rerun). Each run has 'To Investigate' items which means failed test cases. 2. I'm trying to delete all 'To Investigate' items from the first report in order to merge it into the second report without duplicates. Delete operation has been succeed. 3. I'm trying to merge the first and the second reports. Merge operation has been succeed. 4. Now I have only 2 reports (rerun and second rerun) and I'm trying to delete all 'To Investigate' items from the first report in order to merge it into the second one. But the exception was thrown **{""errorCode"":5000,""message"":""Unclassified error [org.hibernate.exception.ConstraintViolationException: could not execute statement]""}** **Expected behavior** Delete operation has been succeed **Screenshots** ![Screenshot_7](https://user-images.githubusercontent.com/17621174/101183309-04c56780-3658-11eb-88ac-da27137389d6.png) **Additional context** In previous version of ReportPortal I didn't observe problems like that "
352499,352499,391896,https://api.github.com/repos/cheng21tang/Project-3/issues/49,1.0,2021-05-25T20:58:53Z,COLLABORATOR,https://api.github.com/repos/cheng21tang/Project-3,Visit a Homepage -- Sign Up/In,"BE: 
- Generate keys
- Input userdata + public key into database
- Return the keys",Visit a Homepage -- Sign Up/In BE: - Generate keys - Input userdata + public key into database - Return the keys
346949,346949,385705,https://api.github.com/repos/PostHog/posthog/issues/3576,0.0,2021-03-04T09:55:59Z,NONE,https://api.github.com/repos/PostHog/posthog,"Events stopped being added for an Action, whilst still working for identical duplicate Action","## Bug description

We have an action defined for a custom event ""user signed up"" (ID: 32) that filters where a property ""test_user = false"" and ""gender = female"". Since one month there are no new events showing in the UI and none of our slack messages are triggered. Today we tried to make a new action (ID: 119) with the same configuration and the events then show correctly.

**DB Query to examine action configuration**
It appears the action match group steps are configured exactly the same:

```
SELECT action_id, event, properties from posthog_actionstep where action_id in (32, 119);

# Old Action (32)
32
""user signed up""
[{""key"": ""gender"", ""type"": ""person"", ""value"": ""female"", ""operator"": ""exact""}, {""key"": ""test_user"", ""type"": ""person"", ""value"": ""false"", ""operator"": ""exact""}]

# New Action (119)
119
""user signed up""
[{""key"": ""gender"", ""type"": ""person"", ""value"": ""female"", ""operator"": ""exact""}, {""key"": ""test_user"", ""type"": ""person"", ""value"": ""false"", ""operator"": ""exact""}]
```

**DB Query to examine matched events**

```
SELECT action_id, count(*) from posthog_action_events where action_id in (32, 119) GROUP by action_id;
32	2159
119	2383
```

## Expected behavio(u)r

We expect the action to perform reliably in capturing events for both display in dashboards (this is how we noticed - the numbers didn't match our internal database) as well as the slack notifications that we use.

## How to reproduce

Not sure how to get into this state as we can't see any clear difference and when we create a ""new"" action with the same configuration it seems to work fine. My gut feeling is there might be some cache issues but not sure.

## Environment

- [ ] PostHog self-hosted with Kubernetes 1.9, Helm chart 1.4.8, posthog version: 1.21.0

## Additional context

One month ago when the events stopped for this Action we were on Posthog 1.19.0 I think. We also noticed another Action with the same issue which we ""fixed"" by deleting and re-adding the filters but this is obviously not ideal. Hence with this action we decided not to modify it so that we can try and investigate what the root cause of the issue is.

#### *Thank you* for your bug report  we love squashing them!
","Events stopped being added for an Action, whilst still working for identical duplicate Action ## Bug description We have an action defined for a custom event ""user signed up"" (ID: 32) that filters where a property ""test_user = false"" and ""gender = female"". Since one month there are no new events showing in the UI and none of our slack messages are triggered. Today we tried to make a new action (ID: 119) with the same configuration and the events then show correctly. **DB Query to examine action configuration** It appears the action match group steps are configured exactly the same: ``` SELECT action_id, event, properties from posthog_actionstep where action_id in (32, 119); # Old Action (32) 32 ""user signed up"" [{""key"": ""gender"", ""type"": ""person"", ""value"": ""female"", ""operator"": ""exact""}, {""key"": ""test_user"", ""type"": ""person"", ""value"": ""false"", ""operator"": ""exact""}] # New Action (119) 119 ""user signed up"" [{""key"": ""gender"", ""type"": ""person"", ""value"": ""female"", ""operator"": ""exact""}, {""key"": ""test_user"", ""type"": ""person"", ""value"": ""false"", ""operator"": ""exact""}] ``` **DB Query to examine matched events** ``` SELECT action_id, count(*) from posthog_action_events where action_id in (32, 119) GROUP by action_id; 32 2159 119 2383 ``` ## Expected behavio(u)r We expect the action to perform reliably in capturing events for both display in dashboards (this is how we noticed - the numbers didn't match our internal database) as well as the slack notifications that we use. ## How to reproduce Not sure how to get into this state as we can't see any clear difference and when we create a ""new"" action with the same configuration it seems to work fine. My gut feeling is there might be some cache issues but not sure. ## Environment - [ ] PostHog self-hosted with Kubernetes 1.9, Helm chart 1.4.8, posthog version: 1.21.0 ## Additional context One month ago when the events stopped for this Action we were on Posthog 1.19.0 I think. We also noticed another Action with the same issue which we ""fixed"" by deleting and re-adding the filters but this is obviously not ideal. Hence with this action we decided not to modify it so that we can try and investigate what the root cause of the issue is. #### *Thank you* for your bug report  we love squashing them! "
99952,99952,111067,https://api.github.com/repos/Joystream/hydra/issues/163,0.0,2021-01-13T13:24:48Z,MEMBER,https://api.github.com/repos/Joystream/hydra,Scaffold command is failing while installing `@dzlzv/hydra-cli`,"The `typeorm-model-generator` package is failing during the building process:

```bash
....
warning @dzlzv/hydra-cli > typeorm-model-generator > sqlite3 > node-gyp > request@2.88.2: request has been deprecated, see https://github.com/request/request/issues/3142
warning @dzlzv/hydra-cli > typeorm-model-generator > mssql > tedious > @azure/ms-rest-nodeauth > adal-node > request@2.88.2: request has been deprecated, see https://github.com/request/request/issues/3142
warning @dzlzv/hydra-cli > typeorm-model-generator > sqlite3 > node-gyp > request > har-validator@5.1.5: this library is no longer supported
 Fetching packages...
[3/4]   Linking dependencies...
[4/4]   Building fresh packages...
[-/6]  waiting...
[-/6]  waiting...
[3/6]  sqlite3
[-/6]  waiting...
error /tmp/sample3/node_modules/sqlite3: Command failed.
Exit code: 1
Command: node-pre-gyp install --fallback-to-build
Arguments: 
Directory: /tmp/sample3/node_modules/sqlite3
....
```

`hydra-cli` no longer uses this package so removing the package from dependencies and releasing a new version of should work.","Scaffold command is failing while installing `@dzlzv/hydra-cli` The `typeorm-model-generator` package is failing during the building process: ```bash .... warning @dzlzv/hydra-cli > typeorm-model-generator > sqlite3 > node-gyp > request@2.88.2: request has been deprecated, see https://github.com/request/request/issues/3142 warning @dzlzv/hydra-cli > typeorm-model-generator > mssql > tedious > @azure/ms-rest-nodeauth > adal-node > request@2.88.2: request has been deprecated, see https://github.com/request/request/issues/3142 warning @dzlzv/hydra-cli > typeorm-model-generator > sqlite3 > node-gyp > request > har-validator@5.1.5: this library is no longer supported Fetching packages... [3/4]  Linking dependencies... [4/4]  Building fresh packages... [-/6]  waiting... [-/6]  waiting... [3/6]  sqlite3 [-/6]  waiting... error /tmp/sample3/node_modules/sqlite3: Command failed. Exit code: 1 Command: node-pre-gyp install --fallback-to-build Arguments: Directory: /tmp/sample3/node_modules/sqlite3 .... ``` `hydra-cli` no longer uses this package so removing the package from dependencies and releasing a new version of should work."
750010,750010,268652,https://api.github.com/repos/musakahya/swe573/issues/121,0.0,2021-02-01T23:22:50Z,OWNER,https://api.github.com/repos/musakahya/swe573,[Bug24] Remove amp from word cloud,Add amp between the words that are eliminated from the word cloud.,[Bug24] Remove amp from word cloud Add amp between the words that are eliminated from the word cloud.
106303,106303,118149,https://api.github.com/repos/uclaacm/teach-la-go-backend/issues/25,1.0,2020-11-20T03:13:51Z,MEMBER,https://api.github.com/repos/uclaacm/teach-la-go-backend,ClassCreateProgram Endpoint,,ClassCreateProgram Endpoint 
515258,515258,572609,https://api.github.com/repos/Deweh/CyberCAT-SimpleGUI/issues/12,0.0,2021-01-17T17:15:28Z,OWNER,https://api.github.com/repos/Deweh/CyberCAT-SimpleGUI,"""Save Changes"" button not appearing","The ""Save Changes"" button does not show up for some users on version >= 0.04a
I am unable to reproduce this issue locally.

Screenshot provided by affected user: https://i.imgur.com/j1KmnXQ.jpg","""Save Changes"" button not appearing The ""Save Changes"" button does not show up for some users on version >= 0.04a I am unable to reproduce this issue locally. Screenshot provided by affected user: https://i.imgur.com/j1KmnXQ.jpg"
331137,331137,368137,https://api.github.com/repos/hashicorp/packer/issues/9623,2.0,2020-07-21T12:35:43Z,NONE,https://api.github.com/repos/hashicorp/packer,Build 'vsphere-iso' errored: error creating vm: host '' not found,"Hello  there.
With continuance to the previous issue that was automatically closed ( https://github.com/hashicorp/packer/issues/8817 )
It is Imposible for me to provisin a template using Packer 1.6 on vSphere 6.7.
im  getting the following error:
Build 'vsphere-iso' errored: error creating vm: host '' not found

This is the template im using:
`

{
    ""builders"": [
      {
        ""type"":                 ""vsphere-iso"",
  
        ""vcenter_server"":       ""vsphere.domain.net"",
        ""insecure_connection"":  ""true"",
        ""username"":             ""admin@vsphere.local"",
        ""password"":             ""adminpass"",
        ""datacenter"":           ""Datacenter-IT"",
        ""Cluster"":              ""IT-256GB"",
        ""resource_pool"":        ""IT-256GB-DS"",
       
        ""communicator"":         ""winrm"",
        ""winrm_username"":       ""Superman"",
        ""winrm_password"":       ""A123456a"",
        ""vm_name"":              ""TEMPLATE-TERM"",
        ""folder"":               ""WinTemplate-IT"",
        ""convert_to_template"":  ""true"",
        ""cpus"":                 ""2"",
        ""ram"":                  ""4096"",
        ""disk_controller_type"": ""lsilogic-sas"",
	      ""guest_os_type"":        ""windows9Server64Guest"",
	      ""iso_paths"": [
          ""[VMFS_ISO_G400PTK] Windows-ISO/SW_DVD9_Win_Server_STD_CORE_2019_1809.1_64Bit_English_DC_STD_MLF_X22-02970.ISO"",
          ""[VMFS_ISO_G400PTK] VM Tools 10.1.0/VMWare-Tools-10.1.0-core-4449150/vmtools/VMTools 10.1.0-windows.iso""
        ],

        ""floppy_files"": [
          ""floppy/autounattend.xml"",
          ""floppy/setup.ps1"",
          ""floppy/vmtools.cmd""
        ],
        
        ""network_adapters"" : [
          {
          ""network_card"": ""vmxnet3""
          }
        ],

        ""storage"": [
          {
            ""disk_size"": ""71680"",
            ""disk_thin_provisioned"": false
          }
        ]
      }
    ]
  }

`
accorid to @sylviamoss who helped me with this issue, the problem has to do with the missing network config - if it is missing, Packer will look for the Host config, and if both are missing, Packer will throw that error.
He has compiled some binaries with an error handling mechanism that should throw more details when this error occurs - but those details never come up (maybe the error in my case is not the network config thing, and i ""fall down"" on some other problem)

this is the log output for those binaries (the same output comes up for the main release as well):

2020/06/25 00:33:34 [WARN] Config file doesn't exist: C:\Users\user\AppData\Roaming\packer.config
2020/06/25 00:33:34 Setting cache directory: packer_cache
cannot determine if process is in background: Process background check error: not implemented yet
2020/06/25 00:33:34 Creating plugin client for path: packer.exe
2020/06/25 00:33:34 Starting plugin: packer.exe []string{""packer.exe"", ""plugin"", ""packer-builder-vsphere-iso""}
2020/06/25 00:33:34 Waiting for RPC address for: packer.exe
2020/06/25 00:33:34 packer.exe plugin: [INFO] Packer version: 1.6.0-dev (caf0d09) [go1.13.12 windows amd64]
2020/06/25 00:33:34 packer.exe plugin: Checking 'PACKER_CONFIG' for a config file path
2020/06/25 00:33:34 packer.exe plugin: 'PACKER_CONFIG' not set; checking the default config file path
2020/06/25 00:33:34 packer.exe plugin: Attempting to open config file: C:\Users\user\AppData\Roaming\packer.config
2020/06/25 00:33:34 packer.exe plugin: [WARN] Config file doesn't exist: C:\Users\user\AppData\Roaming\packer.config
2020/06/25 00:33:34 packer.exe plugin: Setting cache directory: packer_cache
2020/06/25 00:33:34 packer.exe plugin: args: []string{""packer-builder-vsphere-iso""}
2020/06/25 00:33:34 packer.exe plugin: Plugin port range: [10000,25000]
2020/06/25 00:33:34 packer.exe plugin: Plugin address: tcp 127.0.0.1:10000
2020/06/25 00:33:34 packer.exe plugin: Waiting for connection...
2020/06/25 00:33:34 Received tcp RPC address for packer.exe: addr is 127.0.0.1:10000
2020/06/25 00:33:34 packer.exe plugin: Serving a plugin connection...
2020/06/25 00:33:34 Preparing build: vsphere-iso
2020/06/25 00:33:34 ui: vsphere-iso: output will be in this color.
2020/06/25 00:33:34 ui:
2020/06/25 00:33:34 Build debug mode: false
2020/06/25 00:33:34 Force build: false
2020/06/25 00:33:34 On error:
2020/06/25 00:33:34 Waiting on builds to complete...
2020/06/25 00:33:34 Starting build run: vsphere-iso
2020/06/25 00:33:34 Running builder: vsphere-iso
2020/06/25 00:33:34 [INFO] (telemetry) Starting builder vsphere-iso
2020/06/25 00:33:35 ui: ==> vsphere-iso: Creating VM...
2020/06/25 00:33:35 [INFO] (telemetry) ending vsphere-iso
2020/06/25 00:33:35 ui error: Build 'vsphere-iso' errored: error creating vm: host '' not found
2020/06/25 00:33:35 machine readable: error-count []string{""1""}
2020/06/25 00:33:35 ui error:
==> Some builds didn't complete successfully and had errors:
2020/06/25 00:33:35 machine readable: vsphere-iso,error []string{""error creating vm: host '' not found""}
2020/06/25 00:33:35 ui error: --> vsphere-iso: error creating vm: host '' not found
2020/06/25 00:33:35 ui:
==> Builds finished but no artifacts were created.
2020/06/25 00:33:35 [INFO] (telemetry) Finalizing.
2020/06/25 00:33:36 waiting for all plugin processes to complete...
2020/06/25 00:33:36 packer.exe: plugin process exited


I realy want to start using packer and automatically build templates for our environemt, i hope someone can help me with this.
Thank ahead :)

","Build 'vsphere-iso' errored: error creating vm: host '' not found Hello there. With continuance to the previous issue that was automatically closed ( https://github.com/hashicorp/packer/issues/8817 ) It is Imposible for me to provisin a template using Packer 1.6 on vSphere 6.7. im getting the following error: Build 'vsphere-iso' errored: error creating vm: host '' not found This is the template im using: ` { ""builders"": [ { ""type"": ""vsphere-iso"", ""vcenter_server"": ""vsphere.domain.net"", ""insecure_connection"": ""true"", ""username"": ""admin@vsphere.local"", ""password"": ""adminpass"", ""datacenter"": ""Datacenter-IT"", ""Cluster"": ""IT-256GB"", ""resource_pool"": ""IT-256GB-DS"", ""communicator"": ""winrm"", ""winrm_username"": ""Superman"", ""winrm_password"": ""A123456a"", ""vm_name"": ""TEMPLATE-TERM"", ""folder"": ""WinTemplate-IT"", ""convert_to_template"": ""true"", ""cpus"": ""2"", ""ram"": ""4096"", ""disk_controller_type"": ""lsilogic-sas"", ""guest_os_type"": ""windows9Server64Guest"", ""iso_paths"": [ ""[VMFS_ISO_G400PTK] Windows-ISO/SW_DVD9_Win_Server_STD_CORE_2019_1809.1_64Bit_English_DC_STD_MLF_X22-02970.ISO"", ""[VMFS_ISO_G400PTK] VM Tools 10.1.0/VMWare-Tools-10.1.0-core-4449150/vmtools/VMTools 10.1.0-windows.iso"" ], ""floppy_files"": [ ""floppy/autounattend.xml"", ""floppy/setup.ps1"", ""floppy/vmtools.cmd"" ], ""network_adapters"" : [ { ""network_card"": ""vmxnet3"" } ], ""storage"": [ { ""disk_size"": ""71680"", ""disk_thin_provisioned"": false } ] } ] } ` accorid to @sylviamoss who helped me with this issue, the problem has to do with the missing network config - if it is missing, Packer will look for the Host config, and if both are missing, Packer will throw that error. He has compiled some binaries with an error handling mechanism that should throw more details when this error occurs - but those details never come up (maybe the error in my case is not the network config thing, and i ""fall down"" on some other problem) this is the log output for those binaries (the same output comes up for the main release as well): 2020/06/25 00:33:34 [WARN] Config file doesn't exist: C:\Users\user\AppData\Roaming\packer.config 2020/06/25 00:33:34 Setting cache directory: packer_cache cannot determine if process is in background: Process background check error: not implemented yet 2020/06/25 00:33:34 Creating plugin client for path: packer.exe 2020/06/25 00:33:34 Starting plugin: packer.exe []string{""packer.exe"", ""plugin"", ""packer-builder-vsphere-iso""} 2020/06/25 00:33:34 Waiting for RPC address for: packer.exe 2020/06/25 00:33:34 packer.exe plugin: [INFO] Packer version: 1.6.0-dev (caf0d09) [go1.13.12 windows amd64] 2020/06/25 00:33:34 packer.exe plugin: Checking 'PACKER_CONFIG' for a config file path 2020/06/25 00:33:34 packer.exe plugin: 'PACKER_CONFIG' not set; checking the default config file path 2020/06/25 00:33:34 packer.exe plugin: Attempting to open config file: C:\Users\user\AppData\Roaming\packer.config 2020/06/25 00:33:34 packer.exe plugin: [WARN] Config file doesn't exist: C:\Users\user\AppData\Roaming\packer.config 2020/06/25 00:33:34 packer.exe plugin: Setting cache directory: packer_cache 2020/06/25 00:33:34 packer.exe plugin: args: []string{""packer-builder-vsphere-iso""} 2020/06/25 00:33:34 packer.exe plugin: Plugin port range: [10000,25000] 2020/06/25 00:33:34 packer.exe plugin: Plugin address: tcp 127.0.0.1:10000 2020/06/25 00:33:34 packer.exe plugin: Waiting for connection... 2020/06/25 00:33:34 Received tcp RPC address for packer.exe: addr is 127.0.0.1:10000 2020/06/25 00:33:34 packer.exe plugin: Serving a plugin connection... 2020/06/25 00:33:34 Preparing build: vsphere-iso 2020/06/25 00:33:34 ui: vsphere-iso: output will be in this color. 2020/06/25 00:33:34 ui: 2020/06/25 00:33:34 Build debug mode: false 2020/06/25 00:33:34 Force build: false 2020/06/25 00:33:34 On error: 2020/06/25 00:33:34 Waiting on builds to complete... 2020/06/25 00:33:34 Starting build run: vsphere-iso 2020/06/25 00:33:34 Running builder: vsphere-iso 2020/06/25 00:33:34 [INFO] (telemetry) Starting builder vsphere-iso 2020/06/25 00:33:35 ui: ==> vsphere-iso: Creating VM... 2020/06/25 00:33:35 [INFO] (telemetry) ending vsphere-iso 2020/06/25 00:33:35 ui error: Build 'vsphere-iso' errored: error creating vm: host '' not found 2020/06/25 00:33:35 machine readable: error-count []string{""1""} 2020/06/25 00:33:35 ui error: ==> Some builds didn't complete successfully and had errors: 2020/06/25 00:33:35 machine readable: vsphere-iso,error []string{""error creating vm: host '' not found""} 2020/06/25 00:33:35 ui error: --> vsphere-iso: error creating vm: host '' not found 2020/06/25 00:33:35 ui: ==> Builds finished but no artifacts were created. 2020/06/25 00:33:35 [INFO] (telemetry) Finalizing. 2020/06/25 00:33:36 waiting for all plugin processes to complete... 2020/06/25 00:33:36 packer.exe: plugin process exited I realy want to start using packer and automatically build templates for our environemt, i hope someone can help me with this. Thank ahead :) "
9306,9306,10386,https://api.github.com/repos/trufflesuite/ganache-core/issues/259,0.0,2018-12-13T21:14:40Z,CONTRIBUTOR,https://api.github.com/repos/trufflesuite/ganache-core,SendTransaction generate multiple errors when sent from a locked account,"<!--- Provide a general summary of the issue in the Title above -->
Sending a transaction in secure mode (when all accounts are locked) generates multiple error events. 

<!--- DO NOT PASTE ONLY IMAGES OF TERMINAL OUTPUT AS AN ISSUE --->

<!--- WINDOWS USERS: Please READ all of the error / debug output and make sure that the issue 
      isn't due to you missing something before creating an issue. A large portion of Windows 
      issues turn out to be easily self-fixable if you actually read the output before dumping
      it in an issue here. Thanks! ---> 

## Expected Behavior
<!--- If you're describing a bug, tell us what should happen -->
<!--- If you're suggesting a change/improvement, tell us how it should work -->
Expecting a single error noting that the account is locked.
## Current Behavior
<!--- If describing a bug, tell us what happens instead of the expected behavior -->
<!--- If suggesting a change/improvement, explain the difference from current behavior -->
Currently seeing two very different error objects reporting the account is locked.
## Possible Solution
<!--- Not obligatory, but suggest a fix/reason for the bug, -->
<!--- or ideas how to implement the addition or change -->
Use `try/catch` and `async/await` with `sendTransaction` in secure mode.
## Steps to Reproduce (for bugs)
<!--- Provide a link to a live example, or an unambiguous set of steps to -->
<!--- reproduce this bug. Include code to reproduce, if relevant -->
Execute the following code and monitor `err` in the callback.
```
var web3 = new Web3();
    web3.setProvider(
      Ganache.provider({
        mnemonic: mnemonic,
        secure: true
      })
    );

    web3.eth.sendTransaction(
      {
        from: expectedAddress,
        to: ""0x1234567890123456789012345678901234567890"", // doesn't need to exist
        value: web3.utils.toWei(1, ""ether""),
        gasLimit: 90000
      },
      function(**err**, tx) {
        if (!**err**) {
          return done(
            new Error(""We expected the account to be locked, which should throw an error when sending a transaction"")
          );
        }

        /* checking for ""**signer account is locked**""  but have to resort to this. */
        assert(
          err.message.toLowerCase().indexOf(""could not unlock signer account"") >= 0,
          ""Expected error message containing \""could not unlock signer account\"" "" +
            ""(case insensitive check). Received the following error message, instead. "" +
            `""${err.message}""`
        );
      }
```

## Context
<!--- How has this issue affected you? What are you trying to accomplish? -->
<!--- Providing context helps us come up with a solution that is most useful in the real world -->
Ensuring that I can not send a transaction from a locked account.","SendTransaction generate multiple errors when sent from a locked account <!--- Provide a general summary of the issue in the Title above --> Sending a transaction in secure mode (when all accounts are locked) generates multiple error events. <!--- DO NOT PASTE ONLY IMAGES OF TERMINAL OUTPUT AS AN ISSUE ---> <!--- WINDOWS USERS: Please READ all of the error / debug output and make sure that the issue isn't due to you missing something before creating an issue. A large portion of Windows issues turn out to be easily self-fixable if you actually read the output before dumping it in an issue here. Thanks! ---> ## Expected Behavior <!--- If you're describing a bug, tell us what should happen --> <!--- If you're suggesting a change/improvement, tell us how it should work --> Expecting a single error noting that the account is locked. ## Current Behavior <!--- If describing a bug, tell us what happens instead of the expected behavior --> <!--- If suggesting a change/improvement, explain the difference from current behavior --> Currently seeing two very different error objects reporting the account is locked. ## Possible Solution <!--- Not obligatory, but suggest a fix/reason for the bug, --> <!--- or ideas how to implement the addition or change --> Use `try/catch` and `async/await` with `sendTransaction` in secure mode. ## Steps to Reproduce (for bugs) <!--- Provide a link to a live example, or an unambiguous set of steps to --> <!--- reproduce this bug. Include code to reproduce, if relevant --> Execute the following code and monitor `err` in the callback. ``` var web3 = new Web3(); web3.setProvider( Ganache.provider({ mnemonic: mnemonic, secure: true }) ); web3.eth.sendTransaction( { from: expectedAddress, to: ""0x1234567890123456789012345678901234567890"", // doesn't need to exist value: web3.utils.toWei(1, ""ether""), gasLimit: 90000 }, function(**err**, tx) { if (!**err**) { return done( new Error(""We expected the account to be locked, which should throw an error when sending a transaction"") ); } /* checking for ""**signer account is locked**"" but have to resort to this. */ assert( err.message.toLowerCase().indexOf(""could not unlock signer account"") >= 0, ""Expected error message containing \""could not unlock signer account\"" "" + ""(case insensitive check). Received the following error message, instead. "" + `""${err.message}""` ); } ``` ## Context <!--- How has this issue affected you? What are you trying to accomplish? --> <!--- Providing context helps us come up with a solution that is most useful in the real world --> Ensuring that I can not send a transaction from a locked account."
81739,81739,90871,https://api.github.com/repos/RPTools/maptool/issues/2249,0.0,2020-10-01T01:23:48Z,NONE,https://api.github.com/repos/RPTools/maptool,Javascript continues to run on closed Overlay,"**Describe the bug**
When an overlay is closed the javascript continues to run. Running the overlay again does not replace the prior javascipt resulting in multiple sets of coding running to no purpose.

**To Reproduce**
Run this macro [meteor.mtmacro.txt](https://github.com/RPTools/maptool/files/5308969/meteor.mtmacro.txt) and you get a meteor storm. Each frame writes the frame number to chat(console.log).

Close the overlay 
`[closeOverlay(""Weather"")]`

The frame numbers continue in chat.
Rinse and repeat.
Watch your MapTool choke.

Haven't tested with Frame5/Dialog5.

**Expected behavior**
Javascript should stop execution on closing the Overlay

**Screenshots**
If applicable, add screenshots to help explain your problem.

**MapTool Info**
- Version: 1.7.0

**Desktop (please complete the following information):**
 - OS: Win10

**Additional context**
Workaround found: before closing the overlay, write a blank script to the overlay.
```
[h:name = ""Weather""]
[overlay(name, ""zorder=-1""): {
<script>
[r:'


']
</script>
}]

[h:closeOverlay(name)]
```","Javascript continues to run on closed Overlay **Describe the bug** When an overlay is closed the javascript continues to run. Running the overlay again does not replace the prior javascipt resulting in multiple sets of coding running to no purpose. **To Reproduce** Run this macro [meteor.mtmacro.txt](https://github.com/RPTools/maptool/files/5308969/meteor.mtmacro.txt) and you get a meteor storm. Each frame writes the frame number to chat(console.log). Close the overlay `[closeOverlay(""Weather"")]` The frame numbers continue in chat. Rinse and repeat. Watch your MapTool choke. Haven't tested with Frame5/Dialog5. **Expected behavior** Javascript should stop execution on closing the Overlay **Screenshots** If applicable, add screenshots to help explain your problem. **MapTool Info** - Version: 1.7.0 **Desktop (please complete the following information):** - OS: Win10 **Additional context** Workaround found: before closing the overlay, write a blank script to the overlay. ``` [h:name = ""Weather""] [overlay(name, ""zorder=-1""): { <script> [r:' '] </script> }] [h:closeOverlay(name)] ```"
295324,295324,328404,https://api.github.com/repos/VeryEager/transient-terminal-gp/issues/13,0.0,2021-01-10T21:44:27Z,OWNER,https://api.github.com/repos/VeryEager/transient-terminal-gp,Solution fitness may be incorrectly reported ,"The average fitness of the best solution may be incorrectly reported by the program, skewing the results. This may be an issue in where the fitness of an individual is calculated.","Solution fitness may be incorrectly reported The average fitness of the best solution may be incorrectly reported by the program, skewing the results. This may be an issue in where the fitness of an individual is calculated."
611325,611325,679368,https://api.github.com/repos/telerik/kendo-react/issues/783,1.0,2020-11-09T08:42:00Z,CONTRIBUTOR,https://api.github.com/repos/telerik/kendo-react,Extend the RadioButton and Checkbox components props.,"Extend the RadioButton and Checkbox components props.

The RadioButton and Checkbox component are input elements and should accept the same props as the Input component does.

For example, currently passing a standard title attribute will result in a TypeScript error.","Extend the RadioButton and Checkbox components props. Extend the RadioButton and Checkbox components props. The RadioButton and Checkbox component are input elements and should accept the same props as the Input component does. For example, currently passing a standard title attribute will result in a TypeScript error."
319296,319296,354971,https://api.github.com/repos/JimothyGreene/EE461L-Group2-FinalProject/issues/79,1.0,2021-04-05T13:54:06Z,COLLABORATOR,https://api.github.com/repos/JimothyGreene/EE461L-Group2-FinalProject,Billing API,Create an endpoint to send billing information/invoices to the frontend,Billing API Create an endpoint to send billing information/invoices to the frontend
258096,258096,287056,https://api.github.com/repos/Kaiserreich/Kaiserreich-4/issues/13284,0.0,2021-01-20T22:03:16Z,NONE,https://api.github.com/repos/Kaiserreich/Kaiserreich-4,ROM - Nicolae Shenaniganry,"**Quick questions**
OS: Win10
HOI4 version: 1.10.3
Kaiserreich version: 0.16
List any other mods used: official music/model submod/s, spot optimization
Were you using Steam? Y
Were you in multiplayer? N
Which expansions do you NOT have? BftB

**Explanation of the issue:**
ROM goes Camarilla, Carol gets shot, then Nicolae II takes power, then he gets replaced by an undistinguished suit, then the military restores democracy?

**Steps to reproduce:**

no idea

**Possible cause:**
no idea

**Screenshots:**
![image](https://user-images.githubusercontent.com/43826798/105245891-7f7f0f00-5b40-11eb-9833-a222e3522367.png)
![image](https://user-images.githubusercontent.com/43826798/105245929-8ad23a80-5b40-11eb-9a56-0baf6a38c383.png)
![image](https://user-images.githubusercontent.com/43826798/105246829-ca4d5680-5b41-11eb-959e-4414588c37d7.png)
","ROM - Nicolae Shenaniganry **Quick questions** OS: Win10 HOI4 version: 1.10.3 Kaiserreich version: 0.16 List any other mods used: official music/model submod/s, spot optimization Were you using Steam? Y Were you in multiplayer? N Which expansions do you NOT have? BftB **Explanation of the issue:** ROM goes Camarilla, Carol gets shot, then Nicolae II takes power, then he gets replaced by an undistinguished suit, then the military restores democracy? **Steps to reproduce:** no idea **Possible cause:** no idea **Screenshots:** ![image](https://user-images.githubusercontent.com/43826798/105245891-7f7f0f00-5b40-11eb-9833-a222e3522367.png) ![image](https://user-images.githubusercontent.com/43826798/105245929-8ad23a80-5b40-11eb-9a56-0baf6a38c383.png) ![image](https://user-images.githubusercontent.com/43826798/105246829-ca4d5680-5b41-11eb-959e-4414588c37d7.png) "
535385,535385,595042,https://api.github.com/repos/hchiam/slides/issues/120,1.0,2021-04-21T04:00:15Z,OWNER,https://api.github.com/repos/hchiam/slides,update PR template to remind to add Cypress test cases,,update PR template to remind to add Cypress test cases 
442739,442739,492163,https://api.github.com/repos/shibayan/keyvault-acmebot/issues/230,1.0,2021-01-26T14:58:24Z,NONE,https://api.github.com/repos/shibayan/keyvault-acmebot,Add multiple domains from the command-line,"**Is your feature request related to a problem? Please describe.**
I need to add multiple domains (50+)

**Describe the solution you'd like**
I would like to add the domains using `az cli`, eg: `az keyvault-acmebot --resource-group $RG --domain-name mydomain.tld ..etc`

**Describe alternatives you've considered**
Add one by one using the web UI.


","Add multiple domains from the command-line **Is your feature request related to a problem? Please describe.** I need to add multiple domains (50+) **Describe the solution you'd like** I would like to add the domains using `az cli`, eg: `az keyvault-acmebot --resource-group $RG --domain-name mydomain.tld ..etc` **Describe alternatives you've considered** Add one by one using the web UI. "
424038,424038,471365,https://api.github.com/repos/hengband/hengband/issues/976,1.0,2021-04-29T08:35:42Z,MEMBER,https://api.github.com/repos/hengband/hengband,겹녈녈ャ╉쇈/뷩겹ュ쑴域삠녈녈若獒,"꿴
葉佯╊璵백ｃ╉㎯令㎯욍밤易",겹녈녈ャ╉쇈/뷩겹ュ쑴域삠녈녈若獒 꿴 葉佯╊璵백ｃ╉㎯令㎯욍밤易
121427,121427,134932,https://api.github.com/repos/so-wise/so-wise-gyre/issues/3,1.0,2021-02-23T10:21:43Z,CONTRIBUTOR,https://api.github.com/repos/so-wise/so-wise-gyre,Updates based on B-SOSE development,"- Turn on 3D DIFFKR
- Turn off AB3 for now
- Turn on exact_conserv, non-linear free surface
- Copy B-SOSE CPP_OPTIONS.h from lines 90-92
- Compare with B-SOSE smooth options ","Updates based on B-SOSE development - Turn on 3D DIFFKR - Turn off AB3 for now - Turn on exact_conserv, non-linear free surface - Copy B-SOSE CPP_OPTIONS.h from lines 90-92 - Compare with B-SOSE smooth options "
517372,517372,574959,https://api.github.com/repos/coredns/coredns/issues/3765,0.0,2020-03-23T15:36:47Z,NONE,https://api.github.com/repos/coredns/coredns,"plugin/autopath, plugin/cache: Reproducing bugs around autopath","**What happened**:

- CoreDNS gets confused about namespace/service ownership of PodIPs
- The problem does not appear to resolve with time
- Primary issue: A race condition between two requests can cause an authoritative NXDOMAIN on an IPv6 request and a NOERROR on the IPv4 request for an autopath'd request - This combo causes the stub resolver to stop searching search domains and return to the caller that the name does not exist (rather than proceeding through search domains).
- Secondary issue: The cache, in cases beyond where autopath is involved, can cache records in a way that cause CoreDNS to violate the guidance given in RFC 4074 (https://tools.ietf.org/html/rfc4074) as there is no coordination between any of the records for the same name in the cache.  For example, when adding a NoError response to the cache, any other NxDomain records for the same name should be removed (for example, across A/AAAA records).
- Possible additional issues:
  - Reverse resolution for a PodIP will probably return the namespace/pod name
  - Autopath + Pods/Verified has danger that is more drastic that the documentation notes imply.  Autopath has a race condition (because of the way Pods/Verified works) where it will *always* (as in: cannot stop it from happening, not that it happens on every request) result in a stub resolver thinking that a name does not exist.  The percentage of times that this can happen depends on how frequently pods start and stop in a given cluster.

**What you expected to happen**:

See above.

**How to reproduce it (as minimally and precisely as possible)**:

I can provide the reproduction instructions after confirmation that there is interest in fixing these bugs.

As a preview, the issue is that Kubernetes will reuse PodIPs immediately in different namespaces.  When a PodIP is reused it has been observed that CoreDNS does not end up with a correct internal state about what namespace/service that PodIP belongs to.  I did not look further to figure out if the bug is in Kubernetes itself, in the Kubernetes client API, or in the usage of the Kubernetes Client API. 

**Anything else we need to know?**:

[TBC]

**Environment**:

- the version of CoreDNS: master
- Corefile:
- logs, if applicable: there are no log messages in the app that would catch this condition - we should consider adding verbose logging messages that can be enabled to troubleshoot this kind of problem without having to modify and recompile the app
- OS (e.g: `cat /etc/os-release`):
- Others:
","plugin/autopath, plugin/cache: Reproducing bugs around autopath **What happened**: - CoreDNS gets confused about namespace/service ownership of PodIPs - The problem does not appear to resolve with time - Primary issue: A race condition between two requests can cause an authoritative NXDOMAIN on an IPv6 request and a NOERROR on the IPv4 request for an autopath'd request - This combo causes the stub resolver to stop searching search domains and return to the caller that the name does not exist (rather than proceeding through search domains). - Secondary issue: The cache, in cases beyond where autopath is involved, can cache records in a way that cause CoreDNS to violate the guidance given in RFC 4074 (https://tools.ietf.org/html/rfc4074) as there is no coordination between any of the records for the same name in the cache. For example, when adding a NoError response to the cache, any other NxDomain records for the same name should be removed (for example, across A/AAAA records). - Possible additional issues: - Reverse resolution for a PodIP will probably return the namespace/pod name - Autopath + Pods/Verified has danger that is more drastic that the documentation notes imply. Autopath has a race condition (because of the way Pods/Verified works) where it will *always* (as in: cannot stop it from happening, not that it happens on every request) result in a stub resolver thinking that a name does not exist. The percentage of times that this can happen depends on how frequently pods start and stop in a given cluster. **What you expected to happen**: See above. **How to reproduce it (as minimally and precisely as possible)**: I can provide the reproduction instructions after confirmation that there is interest in fixing these bugs. As a preview, the issue is that Kubernetes will reuse PodIPs immediately in different namespaces. When a PodIP is reused it has been observed that CoreDNS does not end up with a correct internal state about what namespace/service that PodIP belongs to. I did not look further to figure out if the bug is in Kubernetes itself, in the Kubernetes client API, or in the usage of the Kubernetes Client API. **Anything else we need to know?**: [TBC] **Environment**: - the version of CoreDNS: master - Corefile: - logs, if applicable: there are no log messages in the app that would catch this condition - we should consider adding verbose logging messages that can be enabled to troubleshoot this kind of problem without having to modify and recompile the app - OS (e.g: `cat /etc/os-release`): - Others: "
754282,754282,311198,https://api.github.com/repos/libsdl-org/SDL/issues/3249,0.0,2021-02-11T01:30:24Z,COLLABORATOR,https://api.github.com/repos/libsdl-org/SDL,[PATCH] Use-after-free in Cocoa video backend after SDL_DestroyWindow,"
# This bug report was migrated from our old Bugzilla tracker.

These attachments are available in the static archive:

* [Patch to clear contentView (fix-use-after-free.patch, text/plain, 2019-04-29 00:50:36 +0000, 1090 bytes)](https://bugzilla.libsdl.org/attachment.cgi?id=3770)
* [Full ASan output (asan.txt, text/plain, 2019-04-29 00:52:11 +0000, 25661 bytes)](https://bugzilla.libsdl.org/attachment.cgi?id=3771)

**Reported in version:** HG 2.1
**Reported for operating system, platform:** macOS 10.13, x86

# Comments on the original bug report:

On 2019-04-29 00:50:36 +0000, Cameron Gutman wrote:

> Created attachment 3770
> Patch to clear contentView
> 
> AddressSanitizer found the following use-after-free (full context attached):
> ==95569==ERROR: AddressSanitizer: heap-use-after-free on address 0x611001408a80 at pc 0x000100d9ee7a bp 0x7ffeefbfbb80 sp 0x7ffeefbfbb78
> READ of size 8 at 0x611001408a80 thread T0
> 2019-04-27 19:20:38.514018-0700 atos[95573:710920] examining /Users/USER/*/Moonlight.app/Contents/MacOS/Moonlight [95569]
> 2019-04-27 19:20:38.916726-0700 atos[95575:710936] examining /Users/USER/*/Moonlight.app/Contents/MacOS/Moonlight [95569]
>     # 0 0x100d9ee79 in -[SDLView updateLayer] SDL_cocoawindow.m:1193
>     # 1 0x7fff3a7f1954 in _NSViewUpdateLayer (AppKit:x86_64+0x125954)
>     # 2 0x7fff3a7f136e in -[_NSViewBackingLayer display] (AppKit:x86_64+0x12536e)
>     # 3 0x7fff47aabd1c in CA::Layer::display_if_needed(CA::Transaction*) (QuartzCore:x86_64+0x14d1c)
>     # 4 0x7fff47a99f41 in CA::Context::commit_transaction(CA::Transaction*) (QuartzCore:x86_64+0x2f41)
>     # 5 0x7fff47a99589 in CA::Transaction::commit() (QuartzCore:x86_64+0x2589)
>     # 6 0x7fff3a7e80a0 in __65+[CATransaction(NSCATransaction) NS_setFlushesWithDisplayRefresh]_block_invoke (AppKit:x86_64+0x11c0a0)
>     # 7 0x7fff3d0bde87 in __CFRUNLOOP_IS_CALLING_OUT_TO_AN_OBSERVER_CALLBACK_FUNCTION__ (CoreFoundation:x86_64h+0x97e87)
>     # 8 0x7fff3d0bddbc in __CFRunLoopDoObservers (CoreFoundation:x86_64h+0x97dbc)
>     # 9 0x7fff3d0604cf in __CFRunLoopRun (CoreFoundation:x86_64h+0x3a4cf)
>     # 10 0x7fff3d05fe0d in CFRunLoopRunSpecific (CoreFoundation:x86_64h+0x39e0d)
>     # 11 0x7fff3c34c9da in RunCurrentEventLoopInMode (HIToolbox:x86_64+0xa9da)
>     # 12 0x7fff3c34c61c in ReceiveNextEventCommon (HIToolbox:x86_64+0xa61c)
>     # 13 0x7fff3c34c4a5 in _BlockUntilNextEventMatchingListInModeWithFilter (HIToolbox:x86_64+0xa4a5)
>     # 14 0x7fff3a6e6ffa in _DPSNextEvent (AppKit:x86_64+0x1affa)
>     # 15 0x7fff3a6e5d92 in -[NSApplication(NSEvent) _nextEventMatchingEventMask:untilDate:inMode:dequeue:] (AppKit:x86_64+0x19d92)
>     # 16 0x7fff3a6dfeaf in -[NSApplication run] (AppKit:x86_64+0x13eaf)
>     # 17 0x109318cca in QCocoaEventDispatcher::processEvents(QFlags<QEventLoop::ProcessEventsFlag>) (libqcocoa.dylib:x86_64+0x33cca)
>     # 18 0x102b0150e in QEventLoop::exec(QFlags<QEventLoop::ProcessEventsFlag>) (QtCore:x86_64+0x1e450e)
>     # 19 0x102b06451 in QCoreApplication::exec() (QtCore:x86_64+0x1e9451)
>     # 20 0x10000b67f in main main.cpp:470
>     # 21 0x7fff694d83d4 in start (libdyld.dylib:x86_64+0x163d4)
> 
> 0x611001408a80 is located 192 bytes inside of 216-byte region [0x6110014089c0,0x611001408a98)
> freed by thread T0 here:
>     # 0 0x102f6220d in wrap_free (libclang_rt.asan_osx_dynamic.dylib:x86_64h+0x5c20d)
>     # 1 0x100d401c8 in SDL_free_REAL SDL_malloc.c:5431
>     # 2 0x10112fede in SDL_DestroyWindow_REAL SDL_video.c:2758
>     # 3 0x10128f803 in SDL_DestroyWindow SDL_dynapi_procs.h:577
>     # 4 0x10010a7da in Session::exec(int, int) session.cpp:1256
>     # 5 0x100174323 in Session::qt_static_metacall(QObject*, QMetaObject::Call, int, void**) moc_session.cpp:112
>     # 6 0x1001757e4 in Session::qt_metacall(QMetaObject::Call, int, void**) moc_session.cpp:199
> 
> 
> The problem is that the contentView is still around while the window is being asynchronously closed. If we receive an updateLayer callback before the window is destroyed, it will access the freed SDL_WindowData memory. Clearing contentView prior to freeing SDL_WindowData makes the use-after-free go away.
> 
> I believe this is the real cause behind https://bugzilla.libsdl.org/show_bug.cgi?id=4394 and https://bugzilla.libsdl.org/show_bug.cgi?id=4386

On 2019-04-29 00:52:11 +0000, Cameron Gutman wrote:

> Created attachment 3771
> Full ASan output

On 2019-05-18 18:48:54 +0000, Ryan C. Gordon wrote:

> 
> Tagging a bunch of bugs with ""target-2.0.10"" so we have a clear list of things to address before a 2.0.10 release.
> 
> Please note that ""addressing"" one of these bugs might mean deciding to defer on it until after 2.0.10, or resolving it as WONTFIX, etc. This is just here to tell us we should look at it carefully, and soon.
> 
> If you have new information or feedback on this issue, this is a good time to add it to the conversation, as we're likely to be paying attention to this specific report in the next few days/weeks.
> 
> Thanks!
> 
> --ryan.

On 2019-05-21 04:18:53 +0000, Ryan C. Gordon wrote:

> 
> This patch is now https://hg.libsdl.org/SDL/rev/132a2af7edac, thanks!
> 
> --ryan.

","[PATCH] Use-after-free in Cocoa video backend after SDL_DestroyWindow # This bug report was migrated from our old Bugzilla tracker. These attachments are available in the static archive: * [Patch to clear contentView (fix-use-after-free.patch, text/plain, 2019-04-29 00:50:36 +0000, 1090 bytes)](https://bugzilla.libsdl.org/attachment.cgi?id=3770) * [Full ASan output (asan.txt, text/plain, 2019-04-29 00:52:11 +0000, 25661 bytes)](https://bugzilla.libsdl.org/attachment.cgi?id=3771) **Reported in version:** HG 2.1 **Reported for operating system, platform:** macOS 10.13, x86 # Comments on the original bug report: On 2019-04-29 00:50:36 +0000, Cameron Gutman wrote: > Created attachment 3770 > Patch to clear contentView > > AddressSanitizer found the following use-after-free (full context attached): > ==95569==ERROR: AddressSanitizer: heap-use-after-free on address 0x611001408a80 at pc 0x000100d9ee7a bp 0x7ffeefbfbb80 sp 0x7ffeefbfbb78 > READ of size 8 at 0x611001408a80 thread T0 > 2019-04-27 19:20:38.514018-0700 atos[95573:710920] examining /Users/USER/*/Moonlight.app/Contents/MacOS/Moonlight [95569] > 2019-04-27 19:20:38.916726-0700 atos[95575:710936] examining /Users/USER/*/Moonlight.app/Contents/MacOS/Moonlight [95569] > # 0 0x100d9ee79 in -[SDLView updateLayer] SDL_cocoawindow.m:1193 > # 1 0x7fff3a7f1954 in _NSViewUpdateLayer (AppKit:x86_64+0x125954) > # 2 0x7fff3a7f136e in -[_NSViewBackingLayer display] (AppKit:x86_64+0x12536e) > # 3 0x7fff47aabd1c in CA::Layer::display_if_needed(CA::Transaction*) (QuartzCore:x86_64+0x14d1c) > # 4 0x7fff47a99f41 in CA::Context::commit_transaction(CA::Transaction*) (QuartzCore:x86_64+0x2f41) > # 5 0x7fff47a99589 in CA::Transaction::commit() (QuartzCore:x86_64+0x2589) > # 6 0x7fff3a7e80a0 in __65+[CATransaction(NSCATransaction) NS_setFlushesWithDisplayRefresh]_block_invoke (AppKit:x86_64+0x11c0a0) > # 7 0x7fff3d0bde87 in __CFRUNLOOP_IS_CALLING_OUT_TO_AN_OBSERVER_CALLBACK_FUNCTION__ (CoreFoundation:x86_64h+0x97e87) > # 8 0x7fff3d0bddbc in __CFRunLoopDoObservers (CoreFoundation:x86_64h+0x97dbc) > # 9 0x7fff3d0604cf in __CFRunLoopRun (CoreFoundation:x86_64h+0x3a4cf) > # 10 0x7fff3d05fe0d in CFRunLoopRunSpecific (CoreFoundation:x86_64h+0x39e0d) > # 11 0x7fff3c34c9da in RunCurrentEventLoopInMode (HIToolbox:x86_64+0xa9da) > # 12 0x7fff3c34c61c in ReceiveNextEventCommon (HIToolbox:x86_64+0xa61c) > # 13 0x7fff3c34c4a5 in _BlockUntilNextEventMatchingListInModeWithFilter (HIToolbox:x86_64+0xa4a5) > # 14 0x7fff3a6e6ffa in _DPSNextEvent (AppKit:x86_64+0x1affa) > # 15 0x7fff3a6e5d92 in -[NSApplication(NSEvent) _nextEventMatchingEventMask:untilDate:inMode:dequeue:] (AppKit:x86_64+0x19d92) > # 16 0x7fff3a6dfeaf in -[NSApplication run] (AppKit:x86_64+0x13eaf) > # 17 0x109318cca in QCocoaEventDispatcher::processEvents(QFlags<QEventLoop::ProcessEventsFlag>) (libqcocoa.dylib:x86_64+0x33cca) > # 18 0x102b0150e in QEventLoop::exec(QFlags<QEventLoop::ProcessEventsFlag>) (QtCore:x86_64+0x1e450e) > # 19 0x102b06451 in QCoreApplication::exec() (QtCore:x86_64+0x1e9451) > # 20 0x10000b67f in main main.cpp:470 > # 21 0x7fff694d83d4 in start (libdyld.dylib:x86_64+0x163d4) > > 0x611001408a80 is located 192 bytes inside of 216-byte region [0x6110014089c0,0x611001408a98) > freed by thread T0 here: > # 0 0x102f6220d in wrap_free (libclang_rt.asan_osx_dynamic.dylib:x86_64h+0x5c20d) > # 1 0x100d401c8 in SDL_free_REAL SDL_malloc.c:5431 > # 2 0x10112fede in SDL_DestroyWindow_REAL SDL_video.c:2758 > # 3 0x10128f803 in SDL_DestroyWindow SDL_dynapi_procs.h:577 > # 4 0x10010a7da in Session::exec(int, int) session.cpp:1256 > # 5 0x100174323 in Session::qt_static_metacall(QObject*, QMetaObject::Call, int, void**) moc_session.cpp:112 > # 6 0x1001757e4 in Session::qt_metacall(QMetaObject::Call, int, void**) moc_session.cpp:199 > > > The problem is that the contentView is still around while the window is being asynchronously closed. If we receive an updateLayer callback before the window is destroyed, it will access the freed SDL_WindowData memory. Clearing contentView prior to freeing SDL_WindowData makes the use-after-free go away. > > I believe this is the real cause behind https://bugzilla.libsdl.org/show_bug.cgi?id=4394 and https://bugzilla.libsdl.org/show_bug.cgi?id=4386 On 2019-04-29 00:52:11 +0000, Cameron Gutman wrote: > Created attachment 3771 > Full ASan output On 2019-05-18 18:48:54 +0000, Ryan C. Gordon wrote: > > Tagging a bunch of bugs with ""target-2.0.10"" so we have a clear list of things to address before a 2.0.10 release. > > Please note that ""addressing"" one of these bugs might mean deciding to defer on it until after 2.0.10, or resolving it as WONTFIX, etc. This is just here to tell us we should look at it carefully, and soon. > > If you have new information or feedback on this issue, this is a good time to add it to the conversation, as we're likely to be paying attention to this specific report in the next few days/weeks. > > Thanks! > > --ryan. On 2019-05-21 04:18:53 +0000, Ryan C. Gordon wrote: > > This patch is now https://hg.libsdl.org/SDL/rev/132a2af7edac, thanks! > > --ryan. "
455973,455973,506791,https://api.github.com/repos/LycheeOrg/Lychee/issues/868,0.0,2021-01-14T22:18:48Z,CONTRIBUTOR,https://api.github.com/repos/LycheeOrg/Lychee,Deleting double-nested albums fails,"```
+----------------+----------------+-------+------+------+
| id             | parent_id      | title | _lft | _rgt |
+----------------+----------------+-------+------+------+
| 16106622698316 |           NULL | 1     |   77 |   82 |
| 16106622758220 | 16106622698316 | 2     |   78 |   81 |
| 16106622793387 | 16106622758220 | 3     |   79 |   80 |
+----------------+----------------+-------+------+------+
```

When I try to delete `1`, I get a server error, with the following in the logs:

```
[2021-01-14 16:12:53] local.INFO: select `photos`.* from `photos` left join `albums` on `photos`.`album_id` = `albums`.`id` where `albums`.`_lft` >= ? and `albums`.`_rgt` <= ? [77,82] 
[2021-01-14 16:12:53] local.ERROR: SQLSTATE[23000]: Integrity constraint violation: 1451 Cannot delete or update a parent row: a foreign key constraint fails (`homestead2`.`albums`, CONSTRAINT `albums_parent_id_foreign` FOREIGN KEY (`parent_id`) REFERENCES `albums` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT) (SQL: delete from `albums` where `_lft` > 77 and `_rgt` <= 82) {""exception"":""[object] (Illuminate\\Database\\QueryException(code: 23000): SQLSTATE[23000]: Integrity constraint violation: 1451 Cannot delete or update a parent row: a foreign key constraint fails (`homestead2`.`albums`, CONSTRAINT `albums_parent_id_foreign` FOREIGN KEY (`parent_id`) REFERENCES `albums` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT) (SQL: delete from `albums` where `_lft` > 77 and `_rgt` <= 82) at [...]/Lychee/vendor/laravel/framework/src/Illuminate/Database/Connection.php:678)
```","Deleting double-nested albums fails ``` +----------------+----------------+-------+------+------+ | id | parent_id | title | _lft | _rgt | +----------------+----------------+-------+------+------+ | 16106622698316 | NULL | 1 | 77 | 82 | | 16106622758220 | 16106622698316 | 2 | 78 | 81 | | 16106622793387 | 16106622758220 | 3 | 79 | 80 | +----------------+----------------+-------+------+------+ ``` When I try to delete `1`, I get a server error, with the following in the logs: ``` [2021-01-14 16:12:53] local.INFO: select `photos`.* from `photos` left join `albums` on `photos`.`album_id` = `albums`.`id` where `albums`.`_lft` >= ? and `albums`.`_rgt` <= ? [77,82] [2021-01-14 16:12:53] local.ERROR: SQLSTATE[23000]: Integrity constraint violation: 1451 Cannot delete or update a parent row: a foreign key constraint fails (`homestead2`.`albums`, CONSTRAINT `albums_parent_id_foreign` FOREIGN KEY (`parent_id`) REFERENCES `albums` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT) (SQL: delete from `albums` where `_lft` > 77 and `_rgt` <= 82) {""exception"":""[object] (Illuminate\\Database\\QueryException(code: 23000): SQLSTATE[23000]: Integrity constraint violation: 1451 Cannot delete or update a parent row: a foreign key constraint fails (`homestead2`.`albums`, CONSTRAINT `albums_parent_id_foreign` FOREIGN KEY (`parent_id`) REFERENCES `albums` (`id`) ON DELETE RESTRICT ON UPDATE RESTRICT) (SQL: delete from `albums` where `_lft` > 77 and `_rgt` <= 82) at [...]/Lychee/vendor/laravel/framework/src/Illuminate/Database/Connection.php:678) ```"
294775,294775,327789,https://api.github.com/repos/ream/ream/issues/215,0.0,2021-03-06T10:24:21Z,NONE,https://api.github.com/repos/ream/ream,Feature request: Ability to add routes programmatically,"At the moment we can use a hook `onCreatedApp` in `enchance-app.ts` where we have an access to `app`, `router` and `initiateState`.
If I add a new route using router API (e.g router.addRoute({...})  this route will work only after the application loaded in the browser. So I can go to this new page, and it will be rendered.
But if I reload the page it will give me 404 error. It happens because this hook `onCreatedApp` has not been taken to consideration during SSR.

Thank you for this framework.","Feature request: Ability to add routes programmatically At the moment we can use a hook `onCreatedApp` in `enchance-app.ts` where we have an access to `app`, `router` and `initiateState`. If I add a new route using router API (e.g router.addRoute({...}) this route will work only after the application loaded in the browser. So I can go to this new page, and it will be rendered. But if I reload the page it will give me 404 error. It happens because this hook `onCreatedApp` has not been taken to consideration during SSR. Thank you for this framework."
401450,401450,446200,https://api.github.com/repos/tarantool/metrics/issues/168,0.0,2021-01-11T11:59:36Z,CONTRIBUTOR,https://api.github.com/repos/tarantool/metrics,Tests don't work properly,It seems to be luatest exited before end of testing,Tests don't work properly It seems to be luatest exited before end of testing
104629,104629,116264,https://api.github.com/repos/elastic/kibana/issues/84757,0.0,2020-12-02T12:49:12Z,NONE,https://api.github.com/repos/elastic/kibana,[Security Solution] server.basePath not honoured everywhere in SIEM app,"**Describe the bug:**

I've kibana under the https://..../kibana path available, and therefore server.basePath: /kibana set in kibana.yml.

However, in the SIEM app, the top Menu which shows the path of the page where I am, i.e. Security / Hosts / All hosts whem I'm on the hosts tab. Then the link behind ""Security"" points to https://.../app/security/overview instead of /kibana/app/security/overview. 

The link behind the ""Hosts"" properly points to /kibana/app/security/hosts?...

The same is true for the SIEM icon in the menu line below where we have the SIEM icon, ""Overview"" ""Detections"" ""Hosts"" etc.
The link behind ""Overview"" correctly points to /kibana/app/security/overview?...
However, the link behind the SIEM Icon left of it, points to /app/security/overview?...

**Kibana/Elasticsearch Stack version:**

7.10.0

**Server OS version:**
Ubuntu 18.04

**Browser and Browser OS versions:**

Firefox 83, Windows 10

**Elastic Endpoint version:**

**Original install method (e.g. download page, yum, from source, etc.):**
deb packages

**Functional Area (e.g. Endpoint management, timelines, resolver, etc.):**

Main navigation of SIEM application.

**Steps to reproduce:**

1.
2.
3.

**Current behavior:**

**Expected behavior:**

These two links mentioned above should also honour server.basePath

**Screenshots (if relevant):**

**Errors in browser console (if relevant):**

**Provide logs and/or server output (if relevant):**

**Any additional context (logs, chat logs, magical formulas, etc.):**
","[Security Solution] server.basePath not honoured everywhere in SIEM app **Describe the bug:** I've kibana under the https://..../kibana path available, and therefore server.basePath: /kibana set in kibana.yml. However, in the SIEM app, the top Menu which shows the path of the page where I am, i.e. Security / Hosts / All hosts whem I'm on the hosts tab. Then the link behind ""Security"" points to https://.../app/security/overview instead of /kibana/app/security/overview. The link behind the ""Hosts"" properly points to /kibana/app/security/hosts?... The same is true for the SIEM icon in the menu line below where we have the SIEM icon, ""Overview"" ""Detections"" ""Hosts"" etc. The link behind ""Overview"" correctly points to /kibana/app/security/overview?... However, the link behind the SIEM Icon left of it, points to /app/security/overview?... **Kibana/Elasticsearch Stack version:** 7.10.0 **Server OS version:** Ubuntu 18.04 **Browser and Browser OS versions:** Firefox 83, Windows 10 **Elastic Endpoint version:** **Original install method (e.g. download page, yum, from source, etc.):** deb packages **Functional Area (e.g. Endpoint management, timelines, resolver, etc.):** Main navigation of SIEM application. **Steps to reproduce:** 1. 2. 3. **Current behavior:** **Expected behavior:** These two links mentioned above should also honour server.basePath **Screenshots (if relevant):** **Errors in browser console (if relevant):** **Provide logs and/or server output (if relevant):** **Any additional context (logs, chat logs, magical formulas, etc.):** "
241485,241485,268589,https://api.github.com/repos/bagisto/bagisto/issues/2873,1.0,2020-04-13T01:17:01Z,NONE,https://api.github.com/repos/bagisto/bagisto,Transactions and Rollbacks not being implemented,"Bagisto Version: 1.0.0+

In an application that involves creating transactions and saving multiple records in multiple tables with any given action should require the use of database transactions and exception handling to rollback all actions if an error occurs. This is currently not the case.

I am receiving a 500 error when executing a checkout request and emails are being generated that the order was executed but no order was actually created within the system and the items are still in the cart. This means that there are no failsafe especially with the prospects of the community creating packages to tap into various areas of code execution.

I would suggest that some refactoring be done to accommodate for failsafe execution with the use of Database Transactions.",Transactions and Rollbacks not being implemented Bagisto Version: 1.0.0+ In an application that involves creating transactions and saving multiple records in multiple tables with any given action should require the use of database transactions and exception handling to rollback all actions if an error occurs. This is currently not the case. I am receiving a 500 error when executing a checkout request and emails are being generated that the order was executed but no order was actually created within the system and the items are still in the cart. This means that there are no failsafe especially with the prospects of the community creating packages to tap into various areas of code execution. I would suggest that some refactoring be done to accommodate for failsafe execution with the use of Database Transactions.
47406,47406,52762,https://api.github.com/repos/AdRoll/rebar3_hank/issues/40,1.0,2020-12-17T15:36:56Z,COLLABORATOR,https://api.github.com/repos/AdRoll/rebar3_hank,[unnecessary_function_arguments] Add callbacks checks,"Related to https://github.com/AdRoll/rebar3_hank/issues/8
Avoid ignoring files which implement behaviours but check their internal functions are not callbacks.
",[unnecessary_function_arguments] Add callbacks checks Related to https://github.com/AdRoll/rebar3_hank/issues/8 Avoid ignoring files which implement behaviours but check their internal functions are not callbacks. 
142690,142690,158606,https://api.github.com/repos/infinitel8p/PokeDex/issues/12,0.0,2021-03-09T17:58:57Z,COLLABORATOR,https://api.github.com/repos/infinitel8p/PokeDex,Fix search function,"Paras, Mauzi, Mew, Kabuto  error
Search does not match whole word.","Fix search function Paras, Mauzi, Mew, Kabuto  error Search does not match whole word."
702973,702973,781277,https://api.github.com/repos/KieranHsieh/GLB/issues/17,1.0,2021-05-09T22:17:16Z,OWNER,https://api.github.com/repos/KieranHsieh/GLB,Thread Safety on multithreaded functionalities,RenderCommand compilation and resource destruction should be thread safe,Thread Safety on multithreaded functionalities RenderCommand compilation and resource destruction should be thread safe
370448,370448,411821,https://api.github.com/repos/telerik/kendo-ui-core/issues/5683,1.0,2020-03-24T14:38:41Z,CONTRIBUTOR,https://api.github.com/repos/telerik/kendo-ui-core,Close button in group indicator should have a href attribute,"Currently the close button in the group indicator does not have a href attribute. It should be included in order to meet accessibility requiremetns.

![image](https://user-images.githubusercontent.com/11771009/77437918-e54e1d80-6ded-11ea-97c9-fce9a8c32dd4.png)
",Close button in group indicator should have a href attribute Currently the close button in the group indicator does not have a href attribute. It should be included in order to meet accessibility requiremetns. ![image](https://user-images.githubusercontent.com/11771009/77437918-e54e1d80-6ded-11ea-97c9-fce9a8c32dd4.png) 
116685,116685,129667,https://api.github.com/repos/MeteorDevelopment/meteor-client/issues/745,1.0,2021-05-15T14:39:57Z,NONE,https://api.github.com/repos/MeteorDevelopment/meteor-client,[Suggestion] AutoConfigBot,"**Describe the feature**
A module that automatically configures the crystalaura based on how much ping you have, and based on what server you are on.

","[Suggestion] AutoConfigBot **Describe the feature** A module that automatically configures the crystalaura based on how much ping you have, and based on what server you are on. "
434540,434540,483084,https://api.github.com/repos/laravel/cashier-stripe/issues/1163,0.0,2021-05-21T10:24:17Z,NONE,https://api.github.com/repos/laravel/cashier-stripe,Stripe Checkout not working with Coupons,"- Cashier Version: 12.13.0
- Laravel Version: 8.40.0
- PHP Version: 8.0.3

### Description:
It's not possible to generate a Stripe Checkout session through Cashier when using Coupons via the `->withCoupon()` method.

#### There are two issues:
(1) The Stripe API does not accept both `allow_promotion_codes` and `discounts` parameters. Stripe throws an exception even when the `allow_promotion_codes` parameter is set to `false`.

(2) The `discount` parameter in the session creation payload needs to be an indexed array.

Both issues seem to be in inconsistent implementation of the Checkout API. It's not very well documented and this different from the way how regular subscriptions are created (without Checkout). See https://stripe.com/docs/billing/subscriptions/discounts for more details.


### Steps To Reproduce:
```
$checkoutSession = Auth::user()
  ->newSubscription('prod_xxxxxx', 'price_xxxxxx')
  ->withCoupon('xxxxxx')
  ->checkout();
```

#### API throws the following exception:
```
You may only specify one of these parameters: allow_promotion_codes, discounts. 
```

### Suggested solution:
When using a Coupon, the `allow_promotion_codes` needs to be removed from the options instead of passing it along with the value `false`. Also, the discount needs to be passed as a single-element indexed array.

I'd be happy to create a PR for this.

","Stripe Checkout not working with Coupons - Cashier Version: 12.13.0 - Laravel Version: 8.40.0 - PHP Version: 8.0.3 ### Description: It's not possible to generate a Stripe Checkout session through Cashier when using Coupons via the `->withCoupon()` method. #### There are two issues: (1) The Stripe API does not accept both `allow_promotion_codes` and `discounts` parameters. Stripe throws an exception even when the `allow_promotion_codes` parameter is set to `false`. (2) The `discount` parameter in the session creation payload needs to be an indexed array. Both issues seem to be in inconsistent implementation of the Checkout API. It's not very well documented and this different from the way how regular subscriptions are created (without Checkout). See https://stripe.com/docs/billing/subscriptions/discounts for more details. ### Steps To Reproduce: ``` $checkoutSession = Auth::user() ->newSubscription('prod_xxxxxx', 'price_xxxxxx') ->withCoupon('xxxxxx') ->checkout(); ``` #### API throws the following exception: ``` You may only specify one of these parameters: allow_promotion_codes, discounts. ``` ### Suggested solution: When using a Coupon, the `allow_promotion_codes` needs to be removed from the options instead of passing it along with the value `false`. Also, the discount needs to be passed as a single-element indexed array. I'd be happy to create a PR for this. "
198404,198404,220595,https://api.github.com/repos/TheGameCreators/GameGuruRepo/issues/871,0.0,2021-01-29T18:45:41Z,NONE,https://api.github.com/repos/TheGameCreators/GameGuruRepo,Tiny Installer Error [SOLVED]," When I try to install I get the following error. I saved the installer exe to my desktop.

![Clipboard01](https://user-images.githubusercontent.com/75511721/106314783-2743bd80-6262-11eb-9e93-4fd4cc959b89.jpg)
",Tiny Installer Error [SOLVED] When I try to install I get the following error. I saved the installer exe to my desktop. ![Clipboard01](https://user-images.githubusercontent.com/75511721/106314783-2743bd80-6262-11eb-9e93-4fd4cc959b89.jpg) 
250012,250012,278100,https://api.github.com/repos/rahulbot/DataBasic/issues/400,0.0,2021-01-24T18:18:24Z,OWNER,https://api.github.com/repos/rahulbot/DataBasic,"language missing from DCP page, but shows on main page","A user noted - for some reason the danish option shows up on the main database.io site, but for some reason doesn't on the culture page.

![DataBasic_io_and_Data_Culture_Project](https://user-images.githubusercontent.com/673178/105639485-9d9d8580-5e46-11eb-9975-d12607740228.jpg)
","language missing from DCP page, but shows on main page A user noted - for some reason the danish option shows up on the main database.io site, but for some reason doesn't on the culture page. ![DataBasic_io_and_Data_Culture_Project](https://user-images.githubusercontent.com/673178/105639485-9d9d8580-5e46-11eb-9975-d12607740228.jpg) "
217326,217326,241669,https://api.github.com/repos/fyne-io/fyne/issues/1886,2.0,2021-01-30T19:31:20Z,NONE,https://api.github.com/repos/fyne-io/fyne,Image in a custom widget doesn't update until window resize,"<!-- Please search for open issues that relate to the same problem before opening a new one. -->

### Describe the bug:
<!-- A clear and concise description about the bug. -->
canvas.Image inside of a custom widget won't refresh until the window gets resized.
I haven't looked ""under the hood"" yet, but I feel like #1480 is of similar origin. 
### Screenshots:
<!-- If applicable, add screenshots or gifs to help explain your problem. -->
http://0x0.st/-o8B.mp4

### Example code:
<!-- If applicable, add a short code snippet to help explain and simplify reproduction of the problem. -->
```go
package main

import (
	""fmt""
	""image/color""
	""fyne.io/fyne/v2""
	""fyne.io/fyne/v2/app""
	""fyne.io/fyne/v2/canvas""
	""fyne.io/fyne/v2/widget""
	""github.com/fogleman/gg""
)

type Clicker struct {
	widget.BaseWidget
	Image *canvas.Image

}

func (g *Clicker) Tapped(a *fyne.PointEvent) {
	fmt.Println(""Click!"")
	if g.Image.Image == nil {
		im, _ := gg.LoadPNG(g.Image.File)
		c := gg.NewContextForImage(im)
		c.DrawCircle(100, 100, 100)
		c.SetRGB(0, 255, 255)
		c.Fill()
		g.Image = canvas.NewImageFromImage(c.Image())
		g.Image.FillMode = canvas.ImageFillStretch
		g.Image.Refresh()
	}
	return
}

func NewClicker(s string) (*Clicker, error) {
	ret := &Clicker{}
	ret.ExtendBaseWidget(ret)
	ret.Image = canvas.NewImageFromFile(s)
	ret.Image.FillMode = canvas.ImageFillStretch
	return ret, nil
}

func (g *Clicker) CreateRenderer() fyne.WidgetRenderer {
	return &clickerRenderer{clicker: g}
}

type clickerRenderer struct {
	clicker *Clicker
}

func (g *clickerRenderer) BackgroundColor() color.Color {
	return color.Transparent
}

func (g *clickerRenderer) Destroy() {
}

func (g *clickerRenderer) Layout(size fyne.Size) {
	g.clicker.Image.Resize(size)
}

func (g *clickerRenderer) MinSize() fyne.Size {
	return fyne.NewSize(1, 1)
}

func (g *clickerRenderer) Objects() []fyne.CanvasObject {
	return []fyne.CanvasObject{g.clicker.Image}
}

func (g *clickerRenderer) Refresh() {
	g.clicker.Image.Refresh()
}

func main() {
	a := app.New()
	w := a.NewWindow(""Hello"")
	i, _ := NewClicker(""test.png"")
	w.SetContent(i)
	w.ShowAndRun()
}

```



### Device (please complete the following information):
 - **OS:** Linux
 - **Version:** 5.10.11;
 - **Go version:** 1.15.7
 - **Fyne version:** 2.0
","Image in a custom widget doesn't update until window resize <!-- Please search for open issues that relate to the same problem before opening a new one. --> ### Describe the bug: <!-- A clear and concise description about the bug. --> canvas.Image inside of a custom widget won't refresh until the window gets resized. I haven't looked ""under the hood"" yet, but I feel like #1480 is of similar origin. ### Screenshots: <!-- If applicable, add screenshots or gifs to help explain your problem. --> http://0x0.st/-o8B.mp4 ### Example code: <!-- If applicable, add a short code snippet to help explain and simplify reproduction of the problem. --> ```go package main import ( ""fmt"" ""image/color"" ""fyne.io/fyne/v2"" ""fyne.io/fyne/v2/app"" ""fyne.io/fyne/v2/canvas"" ""fyne.io/fyne/v2/widget"" ""github.com/fogleman/gg"" ) type Clicker struct { widget.BaseWidget Image *canvas.Image } func (g *Clicker) Tapped(a *fyne.PointEvent) { fmt.Println(""Click!"") if g.Image.Image == nil { im, _ := gg.LoadPNG(g.Image.File) c := gg.NewContextForImage(im) c.DrawCircle(100, 100, 100) c.SetRGB(0, 255, 255) c.Fill() g.Image = canvas.NewImageFromImage(c.Image()) g.Image.FillMode = canvas.ImageFillStretch g.Image.Refresh() } return } func NewClicker(s string) (*Clicker, error) { ret := &Clicker{} ret.ExtendBaseWidget(ret) ret.Image = canvas.NewImageFromFile(s) ret.Image.FillMode = canvas.ImageFillStretch return ret, nil } func (g *Clicker) CreateRenderer() fyne.WidgetRenderer { return &clickerRenderer{clicker: g} } type clickerRenderer struct { clicker *Clicker } func (g *clickerRenderer) BackgroundColor() color.Color { return color.Transparent } func (g *clickerRenderer) Destroy() { } func (g *clickerRenderer) Layout(size fyne.Size) { g.clicker.Image.Resize(size) } func (g *clickerRenderer) MinSize() fyne.Size { return fyne.NewSize(1, 1) } func (g *clickerRenderer) Objects() []fyne.CanvasObject { return []fyne.CanvasObject{g.clicker.Image} } func (g *clickerRenderer) Refresh() { g.clicker.Image.Refresh() } func main() { a := app.New() w := a.NewWindow(""Hello"") i, _ := NewClicker(""test.png"") w.SetContent(i) w.ShowAndRun() } ``` ### Device (please complete the following information): - **OS:** Linux - **Version:** 5.10.11; - **Go version:** 1.15.7 - **Fyne version:** 2.0 "
52568,52568,58480,https://api.github.com/repos/vslinko/obsidian-outliner/issues/19,0.0,2021-03-28T04:28:27Z,NONE,https://api.github.com/repos/vslinko/obsidian-outliner,[BUG] Opening another note when zoomed in maintains the outline bar,"**Describe the bug**
After zooming in on a bullet, opening another note keeps the header bar at the top still.

**To Reproduce**
Steps to reproduce the behavior:
1. Zoom in on list
2. Open another note
3. Observe bar

**Expected behavior**
The outliner bar should only be shown for the original note.

**Screenshots**
Original note zoomed in:
![Screen Shot 2021-03-27 at 9 27 17 PM](https://user-images.githubusercontent.com/23715862/112742412-36ce4280-8f43-11eb-8755-7b42a9c39137.png)

New note:
![Screen Shot 2021-03-27 at 9 28 01 PM](https://user-images.githubusercontent.com/23715862/112742432-4fd6f380-8f43-11eb-8ca0-e4921918440a.png)


**Desktop (please complete the following information):**
 - OS: Mac OS
 - Obsidian 11.10","[BUG] Opening another note when zoomed in maintains the outline bar **Describe the bug** After zooming in on a bullet, opening another note keeps the header bar at the top still. **To Reproduce** Steps to reproduce the behavior: 1. Zoom in on list 2. Open another note 3. Observe bar **Expected behavior** The outliner bar should only be shown for the original note. **Screenshots** Original note zoomed in: ![Screen Shot 2021-03-27 at 9 27 17 PM](https://user-images.githubusercontent.com/23715862/112742412-36ce4280-8f43-11eb-8755-7b42a9c39137.png) New note: ![Screen Shot 2021-03-27 at 9 28 01 PM](https://user-images.githubusercontent.com/23715862/112742432-4fd6f380-8f43-11eb-8ca0-e4921918440a.png) **Desktop (please complete the following information):** - OS: Mac OS - Obsidian 11.10"
81074,81074,90130,https://api.github.com/repos/nss-evening-cohort-14/gitsub-e14-team-2-electric-boogaloo/issues/19,1.0,2021-02-06T18:45:43Z,CONTRIBUTOR,https://api.github.com/repos/nss-evening-cohort-14/gitsub-e14-team-2-electric-boogaloo,Repos Page View,"# User Story

As a user, I should be able to view all of my repos.

# Acceptance Criteria

WHEN the user visits the repos page
THEN they see all of their repos

# Dependencies

- #3
- #35 

# Dev Notes

Loop through an array of repos.","Repos Page View # User Story As a user, I should be able to view all of my repos. # Acceptance Criteria WHEN the user visits the repos page THEN they see all of their repos # Dependencies - #3 - #35 # Dev Notes Loop through an array of repos."
663780,663780,737800,https://api.github.com/repos/dream11/kong-host-interpolate-by-header/issues/14,1.0,2021-05-10T22:16:07Z,CONTRIBUTOR,https://api.github.com/repos/dream11/kong-host-interpolate-by-header,ci step to automatically publish on master merge,"- [ ] check if branch is rebased with master/other_branch on pr
- [ ] publish on github as release on master merge using release draft action
- [ ] publish on luarocks on master merge using release draft action
- [ ] increment version with prepare for next release
- [ ] automerge using label use https://github.com/pascalgn/automerge-action",ci step to automatically publish on master merge - [ ] check if branch is rebased with master/other_branch on pr - [ ] publish on github as release on master merge using release draft action - [ ] publish on luarocks on master merge using release draft action - [ ] increment version with prepare for next release - [ ] automerge using label use https://github.com/pascalgn/automerge-action
102760,102760,114206,https://api.github.com/repos/avkonst/hookstate/issues/141,1.0,2021-02-23T19:05:32Z,OWNER,https://api.github.com/repos/avkonst/hookstate,Add broadcasted plugin to NPM and documentation,,Add broadcasted plugin to NPM and documentation 
636599,636599,707519,https://api.github.com/repos/NethServer/dev/issues/6483,0.0,2021-04-14T22:01:19Z,MEMBER,https://api.github.com/repos/NethServer/dev,Cockpit settings: unable to show root password,"**Steps to reproduce**

- Login into Cockpit
- Go in Settings page
- Start to write new root password
- Try to show the hidden password

**Expected behavior**

Password is shown

**Actual behavior**

Password is not shown and an error is reported

**Components**

```
nethserver-cockpit
nethserver-cockpit-lib
```

----

Console error:

```
TypeError: t.togglePass is not a function
    at click (Settings.vue?be8d:1)
    at ne (vue.runtime.esm.js:1854)
    at HTMLButtonElement.n (vue.runtime.esm.js:2179)
    at HTMLButtonElement.Qi.o._wrapper (vue.runtime.esm.js:6911)
```
",Cockpit settings: unable to show root password **Steps to reproduce** - Login into Cockpit - Go in Settings page - Start to write new root password - Try to show the hidden password **Expected behavior** Password is shown **Actual behavior** Password is not shown and an error is reported **Components** ``` nethserver-cockpit nethserver-cockpit-lib ``` ---- Console error: ``` TypeError: t.togglePass is not a function at click (Settings.vue?be8d:1) at ne (vue.runtime.esm.js:1854) at HTMLButtonElement.n (vue.runtime.esm.js:2179) at HTMLButtonElement.Qi.o._wrapper (vue.runtime.esm.js:6911) ``` 
265827,265827,295621,https://api.github.com/repos/slackapi/bolt-js/issues/733,1.0,2021-01-07T19:27:11Z,CONTRIBUTOR,https://api.github.com/repos/slackapi/bolt-js,"Remove orgAuthorize method, just support authorize","### Description

For Bolt@v3, let's remove the recently added `orgAuthorize` method and instead focus on using just `authorize`. `authorize` will need to be updated to handle the org wide installation use case. 

### What type of issue is this? (place an `x` in one of the `[ ]`)
- [x] enhancement (feature request)


### Requirements (place an `x` in each of the `[ ]`)
* [x] I've read and understood the [Contributing guidelines](https://github.com/slackapi/bolt/blob/main/.github/contributing.md) and have done my best effort to follow them.
* [x] I've read and agree to the [Code of Conduct](https://slackhq.github.io/code-of-conduct).
* [x] I've searched for any related issues and avoided creating a duplicate issue.","Remove orgAuthorize method, just support authorize ### Description For Bolt@v3, let's remove the recently added `orgAuthorize` method and instead focus on using just `authorize`. `authorize` will need to be updated to handle the org wide installation use case. ### What type of issue is this? (place an `x` in one of the `[ ]`) - [x] enhancement (feature request) ### Requirements (place an `x` in each of the `[ ]`) * [x] I've read and understood the [Contributing guidelines](https://github.com/slackapi/bolt/blob/main/.github/contributing.md) and have done my best effort to follow them. * [x] I've read and agree to the [Code of Conduct](https://slackhq.github.io/code-of-conduct). * [x] I've searched for any related issues and avoided creating a duplicate issue."
705688,705688,784315,https://api.github.com/repos/striderxfossility/tppmodcyberpunk/issues/13,0.0,2021-02-12T15:11:55Z,NONE,https://api.github.com/repos/striderxfossility/tppmodcyberpunk,Problem with headless charakter in photomode,"Hello, I'm using TPP mod in combination with IGCS camera to take better angles in mid-dialogues scenes. It works quite good, but in the latest version I've got something like this:
![photomode_12022021_155538](https://user-images.githubusercontent.com/60363662/107784956-4f481c00-6d4c-11eb-9072-4a47bbdf134e.png)
I tried to switch back and forth between FPP and TPP but it doesn't work","Problem with headless charakter in photomode Hello, I'm using TPP mod in combination with IGCS camera to take better angles in mid-dialogues scenes. It works quite good, but in the latest version I've got something like this: ![photomode_12022021_155538](https://user-images.githubusercontent.com/60363662/107784956-4f481c00-6d4c-11eb-9072-4a47bbdf134e.png) I tried to switch back and forth between FPP and TPP but it doesn't work"
154282,154282,171515,https://api.github.com/repos/erikhuck/PhylogenyWebsite/issues/2,2.0,2021-01-12T23:53:52Z,OWNER,https://api.github.com/repos/erikhuck/PhylogenyWebsite,Establish Communication with Dr. Payne about the project,"We need to be able to communicate, I imagine consistently, with Dr. Payne since he's the mentor for this project. The easiest way to do that is to invite him either to our team, our GitHub repo, or both. He may be up for both or neither of those things though. If he's not up for that, we'll need to find another way to communicate with him, even if that means assigning someone in the group to send him occasional emails. I'll ask him about it in class next week.","Establish Communication with Dr. Payne about the project We need to be able to communicate, I imagine consistently, with Dr. Payne since he's the mentor for this project. The easiest way to do that is to invite him either to our team, our GitHub repo, or both. He may be up for both or neither of those things though. If he's not up for that, we'll need to find another way to communicate with him, even if that means assigning someone in the group to send him occasional emails. I'll ask him about it in class next week."
532370,532370,591695,https://api.github.com/repos/usrdjan/firebase-2021/issues/2,1.0,2021-02-08T20:23:50Z,OWNER,https://api.github.com/repos/usrdjan/firebase-2021,Enable SignIn with email and password,,Enable SignIn with email and password 
129633,129633,144081,https://api.github.com/repos/alpheios-project/alignment-editor-new/issues/226,0.0,2021-02-22T17:31:08Z,NONE,https://api.github.com/repos/alpheios-project/alignment-editor-new,Sentence view: how should it work?,"related to #212 
I did align a Latin and Greek text for testing.
the first Latin line is ""odi et amo"" which is aligned with the following Greek text:  罐琯恝溯북  關溯꽝  慣消겅炤  炤뙈싸닯씜  消慣貫貫慣款溯늴  館館   
I aligned odi with 罐琯恝溯북, et with 關溯꽝, amo with 慣消겅炤 and there are 3 greek words left out.
With sentence view = 0, I would expect to see the sentence around the aligned word (but I could be wrong). in this case there is only one sentence (and no punctuation), so for each of the aligned words ""odi"", ""et"", ""amo"", I should get the same sentence (there is only one). Instead, I get only translated word with the 3 words left out. So, what should the logic be for sentence = 0 ? Not sure if this is broken because of #212 

see attachments:

![Screen Shot 2021-02-22 at 6 09 50 PM](https://user-images.githubusercontent.com/41396793/108745948-ff333b80-753b-11eb-8e41-96357f9b3897.png)

![Screen Shot 2021-02-22 at 6 10 01 PM](https://user-images.githubusercontent.com/41396793/108745978-05c1b300-753c-11eb-8eb4-3fb51ebc8f26.png)

![Screen Shot 2021-02-22 at 6 14 09 PM](https://user-images.githubusercontent.com/41396793/108746015-11ad7500-753c-11eb-8bde-24a143ed978d.png)

![Screen Shot 2021-02-22 at 6 14 20 PM](https://user-images.githubusercontent.com/41396793/108746026-170abf80-753c-11eb-8497-b11a2b88599c.png)


","Sentence view: how should it work? related to #212 I did align a Latin and Greek text for testing. the first Latin line is ""odi et amo"" which is aligned with the following Greek text: 罐琯恝溯북 關溯꽝 慣消겅炤 炤뙈싸닯씜 消慣貫貫慣款溯늴 館館 I aligned odi with 罐琯恝溯북, et with 關溯꽝, amo with 慣消겅炤 and there are 3 greek words left out. With sentence view = 0, I would expect to see the sentence around the aligned word (but I could be wrong). in this case there is only one sentence (and no punctuation), so for each of the aligned words ""odi"", ""et"", ""amo"", I should get the same sentence (there is only one). Instead, I get only translated word with the 3 words left out. So, what should the logic be for sentence = 0 ? Not sure if this is broken because of #212 see attachments: ![Screen Shot 2021-02-22 at 6 09 50 PM](https://user-images.githubusercontent.com/41396793/108745948-ff333b80-753b-11eb-8e41-96357f9b3897.png) ![Screen Shot 2021-02-22 at 6 10 01 PM](https://user-images.githubusercontent.com/41396793/108745978-05c1b300-753c-11eb-8eb4-3fb51ebc8f26.png) ![Screen Shot 2021-02-22 at 6 14 09 PM](https://user-images.githubusercontent.com/41396793/108746015-11ad7500-753c-11eb-8bde-24a143ed978d.png) ![Screen Shot 2021-02-22 at 6 14 20 PM](https://user-images.githubusercontent.com/41396793/108746026-170abf80-753c-11eb-8497-b11a2b88599c.png) "
637786,637786,708816,https://api.github.com/repos/FlaxEngine/FlaxEngine/issues/120,0.0,2021-01-20T09:22:32Z,NONE,https://api.github.com/repos/FlaxEngine/FlaxEngine,Input.MousePosition has a DPI issue,"Hi,

I have a DPI monitor so I had to use **/ Platform.DpiScale** to make a raycast from the mouse position project correctly on my PC:
```
var pos = Input.MousePosition / Platform.DpiScale;
            var ray = Camera.MainCamera.ConvertMouseToRay(pos);
            if (Physics.RayCast(ray.Position, ray.Direction, out var hit))
            {
                //DebugDraw.DrawLine(ray.Position, hit.Point, Color.Red, 10f);
                var decal = Scene.AddChild<Decal>();
                decal.Position = hit.Point;
                decal.Material = DecalMaterial;
                decal.Direction = hit.Normal;
            }
```
Even after doing that, it still isn't perfect though. Please see the following video: https://drive.google.com/file/d/10KGqWgjzruKXSCokLlgdIMYiU3I5PRgz/view?usp=sharing","Input.MousePosition has a DPI issue Hi, I have a DPI monitor so I had to use **/ Platform.DpiScale** to make a raycast from the mouse position project correctly on my PC: ``` var pos = Input.MousePosition / Platform.DpiScale; var ray = Camera.MainCamera.ConvertMouseToRay(pos); if (Physics.RayCast(ray.Position, ray.Direction, out var hit)) { //DebugDraw.DrawLine(ray.Position, hit.Point, Color.Red, 10f); var decal = Scene.AddChild<Decal>(); decal.Position = hit.Point; decal.Material = DecalMaterial; decal.Direction = hit.Normal; } ``` Even after doing that, it still isn't perfect though. Please see the following video: https://drive.google.com/file/d/10KGqWgjzruKXSCokLlgdIMYiU3I5PRgz/view?usp=sharing"
427157,427157,474824,https://api.github.com/repos/BudgeGrub/Budgegrub/issues/22,1.0,2021-01-28T20:57:56Z,COLLABORATOR,https://api.github.com/repos/BudgeGrub/Budgegrub,Removable list items (expenses) functionality,"Our list items (still unstyled) need to also be capable of being removed.

As a user with a budget and a list of expenses on the page

When I no longer need to pay a certain expense
I want to be able to remove it with a click of a button

AC
_________________________

>When a list item is added to the ul and page
It needs to now also have an X button next to it so that it can be deleted.
The X button will also need to be styled

>When the X button is clicked
The list item next to it will be removed from the list and page.
The cost of the list item will need to be readded to the budget correctly.",Removable list items (expenses) functionality Our list items (still unstyled) need to also be capable of being removed. As a user with a budget and a list of expenses on the page When I no longer need to pay a certain expense I want to be able to remove it with a click of a button AC _________________________ >When a list item is added to the ul and page It needs to now also have an X button next to it so that it can be deleted. The X button will also need to be styled >When the X button is clicked The list item next to it will be removed from the list and page. The cost of the list item will need to be readded to the budget correctly.
308525,308525,343040,https://api.github.com/repos/OpenRCT2/OpenRCT2/issues/11438,0.0,2020-04-24T12:56:35Z,NONE,https://api.github.com/repos/OpenRCT2/OpenRCT2,Shrinking map freezes game,"I was fucking around resizing an old savegame, and then the game froze with a loud repeating sound that may or may not be the error message sound. I tried singling out what caused the problem by isolating small scenery, large scenery and rides around the border, I couldn't figure out a pattern.

See for yourself, try resizing the map to 123x123. That's when it happens.

[game freezes.zip](https://github.com/OpenRCT2/OpenRCT2/files/4528951/game.freezes.zip)

May or may not be related to https://github.com/OpenRCT2/OpenRCT2/issues/9955.

Not quite an urgent thing for me, but I can imagine you want this bug gone.

Using version 0.2.6 6c3c857 on windows 8.","Shrinking map freezes game I was fucking around resizing an old savegame, and then the game froze with a loud repeating sound that may or may not be the error message sound. I tried singling out what caused the problem by isolating small scenery, large scenery and rides around the border, I couldn't figure out a pattern. See for yourself, try resizing the map to 123x123. That's when it happens. [game freezes.zip](https://github.com/OpenRCT2/OpenRCT2/files/4528951/game.freezes.zip) May or may not be related to https://github.com/OpenRCT2/OpenRCT2/issues/9955. Not quite an urgent thing for me, but I can imagine you want this bug gone. Using version 0.2.6 6c3c857 on windows 8."
269264,269264,299437,https://api.github.com/repos/libsdl-org/SDL/issues/2422,0.0,2021-02-11T00:37:19Z,COLLABORATOR,https://api.github.com/repos/libsdl-org/SDL,"Audio callback gets delayed if pavucontrol isn't started (if it's started, there is no delay)","
# This bug report was migrated from our old Bugzilla tracker.

These attachments are available in the static archive:

* [MWE (MWE.c, text/x-csrc, 2017-03-25 13:52:57 +0000, 828 bytes)](https://bugzilla.libsdl.org/attachment.cgi?id=2707)

**Reported in version:** 2.0.5
**Reported for operating system, platform:** Linux, x86_64

# Comments on the original bug report:

On 2017-03-25 13:52:57 +0000, Andre wrote:

> Created attachment 2707
> MWE
> 
> Run my attached MWE.
> 
> If pavucontrol is not opened, then the output will be:
> 
> 	Started at 31, expect next in 11
> 	Callback at 2010
> 	Callback at 2010
> 	Callback at 2010
> 	Callback at 2010
> 	Callback at 2010
> 	Callback at 2010
> 
> If pavucontrol is opened, then the output will be:
> 
> 	Started at 18, expect next in 11
> 	Callback at 32
> 	Callback at 52
> 	Callback at 52
> 	Callback at 72
> 	Callback at 72
> 	Callback at 93
> 	Callback at 113
> 	Callback at 113
> 	Callback at 136
> 	Callback at 136
> 	Callback at 153
> 	Callback at 153
> 	Callback at 173
> 	Callback at 193
> 
> I expected my program to behave the latter also without pavucontrol opened. If pavucontrol is not opened, the callback gets delayed by 2 seconds.
> 
> Nominal Animal at Stackoverflow (https://stackoverflow.com/questions/42990071) said that the delay could be due to internal buffering.
> 
> I have tested this with SDL2 and pulseaudio:
> 
> * Linux 4.10.4
> * SDL 2.0.5
> * pulseaudio 10.0
> * alsa 1.1.3
> * pavucontrol 3.0
> 
> I compiled the MWE with: gcc -lSDL2 MWE.c

On 2018-08-06 21:20:19 +0000, Ryan C. Gordon wrote:

> 
> Hello, and sorry if you're getting dozens of copies of this message by email.
> 
> We are closing out bugs that appear to be abandoned in some form. This can happen for lots of reasons: we couldn't reproduce it, conversation faded out, the bug was noted as fixed in a comment but we forgot to mark it resolved, the report is good but the fix is impractical, we fixed it a long time ago without realizing there was an associated report, etc.
> 
> Individually, any of these bugs might have a better resolution (such as WONTFIX or WORKSFORME or INVALID) but we've added a new resolution of ABANDONED to make this easily searchable and make it clear that it's not necessarily unreasonable to revive a given bug report.
> 
> So if this bug is still a going concern and you feel it should still be open: please feel free to reopen it! But unless you respond, we'd like to consider these bugs closed, as many of them are several years old and overwhelming our ability to prioritize recent issues.
> 
> (please note that hundred of bug reports were sorted through here, so we apologize for any human error. Just reopen the bug in that case!)
> 
> Thanks,
> --ryan.

","Audio callback gets delayed if pavucontrol isn't started (if it's started, there is no delay) # This bug report was migrated from our old Bugzilla tracker. These attachments are available in the static archive: * [MWE (MWE.c, text/x-csrc, 2017-03-25 13:52:57 +0000, 828 bytes)](https://bugzilla.libsdl.org/attachment.cgi?id=2707) **Reported in version:** 2.0.5 **Reported for operating system, platform:** Linux, x86_64 # Comments on the original bug report: On 2017-03-25 13:52:57 +0000, Andre wrote: > Created attachment 2707 > MWE > > Run my attached MWE. > > If pavucontrol is not opened, then the output will be: > > Started at 31, expect next in 11 > Callback at 2010 > Callback at 2010 > Callback at 2010 > Callback at 2010 > Callback at 2010 > Callback at 2010 > > If pavucontrol is opened, then the output will be: > > Started at 18, expect next in 11 > Callback at 32 > Callback at 52 > Callback at 52 > Callback at 72 > Callback at 72 > Callback at 93 > Callback at 113 > Callback at 113 > Callback at 136 > Callback at 136 > Callback at 153 > Callback at 153 > Callback at 173 > Callback at 193 > > I expected my program to behave the latter also without pavucontrol opened. If pavucontrol is not opened, the callback gets delayed by 2 seconds. > > Nominal Animal at Stackoverflow (https://stackoverflow.com/questions/42990071) said that the delay could be due to internal buffering. > > I have tested this with SDL2 and pulseaudio: > > * Linux 4.10.4 > * SDL 2.0.5 > * pulseaudio 10.0 > * alsa 1.1.3 > * pavucontrol 3.0 > > I compiled the MWE with: gcc -lSDL2 MWE.c On 2018-08-06 21:20:19 +0000, Ryan C. Gordon wrote: > > Hello, and sorry if you're getting dozens of copies of this message by email. > > We are closing out bugs that appear to be abandoned in some form. This can happen for lots of reasons: we couldn't reproduce it, conversation faded out, the bug was noted as fixed in a comment but we forgot to mark it resolved, the report is good but the fix is impractical, we fixed it a long time ago without realizing there was an associated report, etc. > > Individually, any of these bugs might have a better resolution (such as WONTFIX or WORKSFORME or INVALID) but we've added a new resolution of ABANDONED to make this easily searchable and make it clear that it's not necessarily unreasonable to revive a given bug report. > > So if this bug is still a going concern and you feel it should still be open: please feel free to reopen it! But unless you respond, we'd like to consider these bugs closed, as many of them are several years old and overwhelming our ability to prioritize recent issues. > > (please note that hundred of bug reports were sorted through here, so we apologize for any human error. Just reopen the bug in that case!) > > Thanks, > --ryan. "
651918,651918,724683,https://api.github.com/repos/y0sh1DE/comiebot/issues/38,0.0,2021-03-04T11:20:30Z,OWNER,https://api.github.com/repos/y0sh1DE/comiebot,rolehandler broke,"dunno what happend, but its broken. 

gonna fix this later","rolehandler broke dunno what happend, but its broken. gonna fix this later"
738604,738604,156583,https://api.github.com/repos/wesnoth/wesnoth/issues/5553,1.0,2021-02-16T22:27:56Z,CONTRIBUTOR,https://api.github.com/repos/wesnoth/wesnoth,Offscreen video rendering of replays,"### Game and System Information
 - What version of the game are you running?
Stable

 - What OS are you running?
 Linux

### Describe the desired feature
I'd like to be able to render videos of replays offscreen and as fast as possible. I'm interested in implementing it myself. In the absence of better advice I'd probably use: https://github.com/kallaballa/SDLVideoCapture. The downside of that project is that it depends on ffmpeg. Would that be acceptable?
",Offscreen video rendering of replays ### Game and System Information - What version of the game are you running? Stable - What OS are you running? Linux ### Describe the desired feature I'd like to be able to render videos of replays offscreen and as fast as possible. I'm interested in implementing it myself. In the absence of better advice I'd probably use: https://github.com/kallaballa/SDLVideoCapture. The downside of that project is that it depends on ffmpeg. Would that be acceptable? 
268891,268891,299028,https://api.github.com/repos/libsdl-org/SDL/issues/2692,0.0,2021-02-11T00:54:42Z,COLLABORATOR,https://api.github.com/repos/libsdl-org/SDL,SDL_main export,"
# This bug report was migrated from our old Bugzilla tracker.

These attachments are available in the static archive:

* [Dependency Walker SDL_main export (bug.png, image/png, 2017-10-28 11:47:05 +0000, 43984 bytes)](https://bugzilla.libsdl.org/attachment.cgi?id=3047)

**Reported in version:** 2.0.6
**Reported for operating system, platform:** Windows 7, x86

# Comments on the original bug report:

On 2017-10-28 11:47:05 +0000,  wrote:

> Created attachment 3047
> Dependency Walker SDL_main export
> 
> I noticed that after updating SDL to 2.0.6 my application now exports SDL_main.
> 
> At GitHub SDL mirror (branch 2.0.5) SDL_main prototyped as
> extern C_LINKAGE int SDL_main(int argc, char *argv[]);
> but at branch 2.0.6 prototype is
> extern C_LINKAGE DECLSPEC int SDL_main(int argc, char *argv[]);

On 2017-10-28 11:55:05 +0000, Ozkan Sezer wrote:

> DECLSPEC added by http://hg.libsdl.org/SDL/rev/a8c29f5b679f on Aug. 28, 2017:
> ""Removed the need for libSDL2main.a on Android, and separated JNI initialization out for other integrations""

On 2017-11-02 00:41:40 +0000, Sam Lantinga wrote:

> Fixed, thanks!
> https://hg.libsdl.org/SDL/rev/b2d2705511d1

","SDL_main export # This bug report was migrated from our old Bugzilla tracker. These attachments are available in the static archive: * [Dependency Walker SDL_main export (bug.png, image/png, 2017-10-28 11:47:05 +0000, 43984 bytes)](https://bugzilla.libsdl.org/attachment.cgi?id=3047) **Reported in version:** 2.0.6 **Reported for operating system, platform:** Windows 7, x86 # Comments on the original bug report: On 2017-10-28 11:47:05 +0000, wrote: > Created attachment 3047 > Dependency Walker SDL_main export > > I noticed that after updating SDL to 2.0.6 my application now exports SDL_main. > > At GitHub SDL mirror (branch 2.0.5) SDL_main prototyped as > extern C_LINKAGE int SDL_main(int argc, char *argv[]); > but at branch 2.0.6 prototype is > extern C_LINKAGE DECLSPEC int SDL_main(int argc, char *argv[]); On 2017-10-28 11:55:05 +0000, Ozkan Sezer wrote: > DECLSPEC added by http://hg.libsdl.org/SDL/rev/a8c29f5b679f on Aug. 28, 2017: > ""Removed the need for libSDL2main.a on Android, and separated JNI initialization out for other integrations"" On 2017-11-02 00:41:40 +0000, Sam Lantinga wrote: > Fixed, thanks! > https://hg.libsdl.org/SDL/rev/b2d2705511d1 "
243079,243079,270356,https://api.github.com/repos/elastic/apm-agent-dotnet/issues/1233,0.0,2021-03-18T18:57:43Z,COLLABORATOR,https://api.github.com/repos/elastic/apm-agent-dotnet,Startup hook setup + ASP.NET Core: HTTP request with unhandled exception is not captured,"With above setup, nothing is captured. The transaction is missing and the error for the unhandled exception isn't captured.

I looked at logs during a call, and it seems that the transaction is started, but after the exception, none of the events we expect [here](https://github.com/elastic/apm-agent-dotnet/blob/master/src/Elastic.Apm.AspNetCore/DiagnosticListener/AspNetCoreDiagnosticListener.cs#L38) are received. We listen to `Microsoft.AspNetCore.Diagnostics.UnhandledException`, `Microsoft.AspNetCore.Diagnostics.HandledException`, and `Microsoft.AspNetCore.Hosting.UnhandledException` - none of those seemed to be triggered.","Startup hook setup + ASP.NET Core: HTTP request with unhandled exception is not captured With above setup, nothing is captured. The transaction is missing and the error for the unhandled exception isn't captured. I looked at logs during a call, and it seems that the transaction is started, but after the exception, none of the events we expect [here](https://github.com/elastic/apm-agent-dotnet/blob/master/src/Elastic.Apm.AspNetCore/DiagnosticListener/AspNetCoreDiagnosticListener.cs#L38) are received. We listen to `Microsoft.AspNetCore.Diagnostics.UnhandledException`, `Microsoft.AspNetCore.Diagnostics.HandledException`, and `Microsoft.AspNetCore.Hosting.UnhandledException` - none of those seemed to be triggered."
618764,618764,687630,https://api.github.com/repos/alteryx/evalml/issues/2115,0.0,2021-04-07T21:18:35Z,CONTRIBUTOR,https://api.github.com/repos/alteryx/evalml,Partial Dependence Contour Plots Showing NaNs in our model understanding demo,"In our model understanding demo, our two-way partial dependence plot shows NaN in the right-most region of the plot:

![image](https://user-images.githubusercontent.com/41651716/113935611-bc17e980-97c4-11eb-9e25-4780106a9a74.png)

Is this expected? I think we may be extending the x axis range farther than it should?","Partial Dependence Contour Plots Showing NaNs in our model understanding demo In our model understanding demo, our two-way partial dependence plot shows NaN in the right-most region of the plot: ![image](https://user-images.githubusercontent.com/41651716/113935611-bc17e980-97c4-11eb-9e25-4780106a9a74.png) Is this expected? I think we may be extending the x axis range farther than it should?"
612601,612601,680787,https://api.github.com/repos/ArmaForces/Website/issues/177,1.0,2021-02-07T23:23:35Z,MEMBER,https://api.github.com/repos/ArmaForces/Website,Feature request: Modset download page translation,We could use some localization/header to translate the page to English.,Feature request: Modset download page translation We could use some localization/header to translate the page to English.
132294,132294,147046,https://api.github.com/repos/apnadkarni/ruff/issues/39,1.0,2021-01-26T03:02:53Z,OWNER,https://api.github.com/repos/apnadkarni/ruff,Add a search/index feature like tcl-docs,,Add a search/index feature like tcl-docs 
490089,490089,544691,https://api.github.com/repos/OpenAF/openaf/issues/196,0.0,2020-11-30T17:32:52Z,COLLABORATOR,https://api.github.com/repos/OpenAF/openaf,Using $sec.getObj with empty argument,"__Problem__

Taking, for example, an object, ""ExampleObj"", that takes 3 arguments to be created: arg1, arg2 and arg3.
Usually it will be created like this:

````javascript
var example = new ExampleObj(arg1, arg2, arg3);

// OR

var example = new ExampleObj(arg1, arg2); // if arg3 is optional
````

After setting arg1 and arg2 with $sec.setObj, there might be errors indicating that arg3 is not boolean:

````javascript
$sec().setObj(""example"", ""ExampleObj"", { arg1: ""a"", arg2: ""b"" });

// The following might return an error
var example = $sec().getObj(""example"");
````

__Workaround__

Always provide all arguments on $sec().setObj.","Using $sec.getObj with empty argument __Problem__ Taking, for example, an object, ""ExampleObj"", that takes 3 arguments to be created: arg1, arg2 and arg3. Usually it will be created like this: ````javascript var example = new ExampleObj(arg1, arg2, arg3); // OR var example = new ExampleObj(arg1, arg2); // if arg3 is optional ```` After setting arg1 and arg2 with $sec.setObj, there might be errors indicating that arg3 is not boolean: ````javascript $sec().setObj(""example"", ""ExampleObj"", { arg1: ""a"", arg2: ""b"" }); // The following might return an error var example = $sec().getObj(""example""); ```` __Workaround__ Always provide all arguments on $sec().setObj."
718901,718901,798982,https://api.github.com/repos/TimPrimmer/robot-gladiators/issues/8,1.0,2021-05-20T22:56:48Z,OWNER,https://api.github.com/repos/TimPrimmer/robot-gladiators,Randomize fight order in the fight() function for each new enemy-robot round,,Randomize fight order in the fight() function for each new enemy-robot round 
326875,326875,363385,https://api.github.com/repos/bitcoin-s/bitcoin-s/issues/3032,0.0,2021-05-04T19:22:23Z,CONTRIBUTOR,https://api.github.com/repos/bitcoin-s/bitcoin-s,CI to docker hub publish failing on master,"https://github.com/bitcoin-s/bitcoin-s/runs/2503221421#step:4:1035

",CI to docker hub publish failing on master https://github.com/bitcoin-s/bitcoin-s/runs/2503221421#step:4:1035 
527645,527645,586449,https://api.github.com/repos/FranzDiebold/ng-google-sheets-db-library/issues/8,2.0,2021-02-18T18:27:13Z,NONE,https://api.github.com/repos/FranzDiebold/ng-google-sheets-db-library,[Not an issue] Number vs string types,"Sorry Franz, but I don't know other way of contact you without opening this issue.
It's not an issue, rather a silly JavaScript/TypeScript doubt that I stumble on, for which I have a workaround but I would apreciate if you could spare some of our knowlegde with me.

I was declaring my sheet's data interface with some field columns with type other than `string`, like `semana: number; `.
I would never guess that, in Angular's TypeScript environment, my whole program would run flawlessy holding string values in the Article.semana number-typed property! But actually it does! 
Further in my code, I'm using ExcelJS to export an archive and I realise that, after fetching the google sheet I need to archive.semana = parseInt(archive.semana) and voil찼: article.semana passes to hold a number instead of a string.

So, could you help me with the following 2 questions?
1) ng-google-sheets-db-library package will always return a sequence of characters, no matter the type we declare in the data interface?
2) how can a object's property of type number can hold a string without an error being thrown during execution of the JavaScript/TypeScript code?
```
export interface Article {
  semana: number;
  data_informe: string;
  ID: string;
  excluir: string;
  autores: string;
  titulo: string;
  tecnologias: string;
  sumario_achados: string;
  aval_qual_metod: string;
  resumo: string;
  referencia_bibliografica: string;
  pa챠s: string;
  NE: number;
  URL: string;

  tipo_estudo: string;
  data_publ: string;
}


export const articleAttributesMapping = {
  semana: 'SEM.',
  data_informe: 'DATA do INFORME',
  ID: 'ID',
  excluir: 'EXCLUIR?',
  autores: 'AUTORES',
  titulo: 'TTULO',
  tecnologias: 'ESPECIFICAO da TECNOLOGIA',
  sumario_achados: 'SUMRIO dos ACHADOS',
  aval_qual_metod: 'AVALIAO da QUALIDADE METODOLGICA',
  resumo: 'RESUMO',
  referencia_bibliografica: 'REFERNCIA (Vancouver)',
  pa챠s: 'PAS',
  NE: 'NVEL de EVIDNCIA',
  URL: 'URL',

  tipo_estudo: 'TIPO de ESTUDO',
  data_publ: 'DATA PUBL',
};
```

Thank you very much for your time!
Jos챕
","[Not an issue] Number vs string types Sorry Franz, but I don't know other way of contact you without opening this issue. It's not an issue, rather a silly JavaScript/TypeScript doubt that I stumble on, for which I have a workaround but I would apreciate if you could spare some of our knowlegde with me. I was declaring my sheet's data interface with some field columns with type other than `string`, like `semana: number; `. I would never guess that, in Angular's TypeScript environment, my whole program would run flawlessy holding string values in the Article.semana number-typed property! But actually it does! Further in my code, I'm using ExcelJS to export an archive and I realise that, after fetching the google sheet I need to archive.semana = parseInt(archive.semana) and voil찼: article.semana passes to hold a number instead of a string. So, could you help me with the following 2 questions? 1) ng-google-sheets-db-library package will always return a sequence of characters, no matter the type we declare in the data interface? 2) how can a object's property of type number can hold a string without an error being thrown during execution of the JavaScript/TypeScript code? ``` export interface Article { semana: number; data_informe: string; ID: string; excluir: string; autores: string; titulo: string; tecnologias: string; sumario_achados: string; aval_qual_metod: string; resumo: string; referencia_bibliografica: string; pa챠s: string; NE: number; URL: string; tipo_estudo: string; data_publ: string; } export const articleAttributesMapping = { semana: 'SEM.', data_informe: 'DATA do INFORME', ID: 'ID', excluir: 'EXCLUIR?', autores: 'AUTORES', titulo: 'TTULO', tecnologias: 'ESPECIFICAO da TECNOLOGIA', sumario_achados: 'SUMRIO dos ACHADOS', aval_qual_metod: 'AVALIAO da QUALIDADE METODOLGICA', resumo: 'RESUMO', referencia_bibliografica: 'REFERNCIA (Vancouver)', pa챠s: 'PAS', NE: 'NVEL de EVIDNCIA', URL: 'URL', tipo_estudo: 'TIPO de ESTUDO', data_publ: 'DATA PUBL', }; ``` Thank you very much for your time! Jos챕 "
73427,73427,81650,https://api.github.com/repos/hameye/MARCIA/issues/11,1.0,2021-01-30T11:08:32Z,COLLABORATOR,https://api.github.com/repos/hameye/MARCIA,mask export,"Hello,
When exporting the mask, the result is an image of the mask, not the mask itself: we have axes and title. Would it be possible to also export the mask itself, ie an image holding only zeros and ones which could be used for merging and calculating things in an imaging soft?  Maybe that could be done with an extra argument on the save_mask function, default as it is now and mask itself with a boolean given afterwards?

We need that in order to keep the signal from a series of minerals only, applied to images, not the raw datacube that will be afterwards used in XMapTools. XMapTools cannot manage the datacube.

Best regards,
Jean ","mask export Hello, When exporting the mask, the result is an image of the mask, not the mask itself: we have axes and title. Would it be possible to also export the mask itself, ie an image holding only zeros and ones which could be used for merging and calculating things in an imaging soft? Maybe that could be done with an extra argument on the save_mask function, default as it is now and mask itself with a boolean given afterwards? We need that in order to keep the signal from a series of minerals only, applied to images, not the raw datacube that will be afterwards used in XMapTools. XMapTools cannot manage the datacube. Best regards, Jean "
414718,414718,460975,https://api.github.com/repos/rmusick2000/CodeEquityTester/issues/7972,0.0,2021-04-17T21:21:10Z,NONE,https://api.github.com/repos/rmusick2000/CodeEquityTester,IR Accrued,,IR Accrued 
700114,700114,778118,https://api.github.com/repos/DouglasGabr/mongoose-lean-defaults/issues/19,0.0,2021-05-12T21:21:35Z,NONE,https://api.github.com/repos/DouglasGabr/mongoose-lean-defaults,"First param to `schema.plugin()` must be a function, got ""object""","**Describe the bug**
Going from v1.0.1 to v1.1.0 is in fact a breaking change. Since we have a project that imports

""mongoose-lean-defaults"": ""^1.0.1"" (notice that we allow minor version upgrades with ""^""), 
the minor version was bumped to v1.1.1 when doing an upgrade, causing this issue :

![image](https://user-images.githubusercontent.com/6865470/118045040-698e9780-b345-11eb-83ac-7a1333998b64.png)
 
Perhaps changing this package's version to 2.0.0 for that breaking change (v1.1.0) (following the [semver](https://semver.org/) system) would be a good idea to save other people some troubleshooting time.

All in all, thanks a lot for that great plugin.

**Additional context**  
Mongoose version:  5.10.6
Node version: 14.15.1
","First param to `schema.plugin()` must be a function, got ""object"" **Describe the bug** Going from v1.0.1 to v1.1.0 is in fact a breaking change. Since we have a project that imports ""mongoose-lean-defaults"": ""^1.0.1"" (notice that we allow minor version upgrades with ""^""), the minor version was bumped to v1.1.1 when doing an upgrade, causing this issue : ![image](https://user-images.githubusercontent.com/6865470/118045040-698e9780-b345-11eb-83ac-7a1333998b64.png) Perhaps changing this package's version to 2.0.0 for that breaking change (v1.1.0) (following the [semver](https://semver.org/) system) would be a good idea to save other people some troubleshooting time. All in all, thanks a lot for that great plugin. **Additional context** Mongoose version: 5.10.6 Node version: 14.15.1 "
368063,368063,409157,https://api.github.com/repos/declanslevin/o-and-xs/issues/8,1.0,2021-01-20T17:05:19Z,OWNER,https://api.github.com/repos/declanslevin/o-and-xs,[Data Restructure] Add .isHuman to player objects,"Suggested in [this comment](https://github.com/declanslevin/o-and-xs/pull/6/files#r560170960) : 

Add a `.isHuman` boolean to the player objects and remove `store.singlePlayer`",[Data Restructure] Add .isHuman to player objects Suggested in [this comment](https://github.com/declanslevin/o-and-xs/pull/6/files#r560170960) : Add a `.isHuman` boolean to the player objects and remove `store.singlePlayer`
269965,269965,300228,https://api.github.com/repos/rero/ng-core/issues/156,1.0,2020-03-31T07:55:49Z,COLLABORATOR,https://api.github.com/repos/rero/ng-core,Match the user interface to guidelines,,Match the user interface to guidelines 
655429,655429,728544,https://api.github.com/repos/EleutherAI/gpt-neox/issues/128,0.0,2021-02-17T17:36:37Z,MEMBER,https://api.github.com/repos/EleutherAI/gpt-neox,Figure out why 1-bit Adam pretends to run,"We have been mystified by the fact that we havent seen any speed-up from 1-bit Adam, but we recently discovered that it requires OpenMPI to function. This explains the lack of improvement (we do not currently have a working OpenMPI implementation) but does not explain why the code acts like it runs without a problem. There are two tasks here:

[ ] figure out the code is currently doing
[ ] figure out how to get 1-bit Adam to work (once OpenMPI exists)","Figure out why 1-bit Adam pretends to run We have been mystified by the fact that we havent seen any speed-up from 1-bit Adam, but we recently discovered that it requires OpenMPI to function. This explains the lack of improvement (we do not currently have a working OpenMPI implementation) but does not explain why the code acts like it runs without a problem. There are two tasks here: [ ] figure out the code is currently doing [ ] figure out how to get 1-bit Adam to work (once OpenMPI exists)"
3032,3032,3394,https://api.github.com/repos/pavjacko/renative/issues/445,2.0,2020-03-25T19:46:28Z,NONE,https://api.github.com/repos/pavjacko/renative,rnv platform eject not working,"I'm trying to execute `rnv platform eject` in order to modify the `build.gradle` file on Android.

When the command is executed I can't select any option and there is a `Disabled` label alongside each option.

Nothing happens when `<a>` or any other key is pressed. There is not interactivity at all.

The only thing I can do is press `Enter` but I just get an error.

_Command line after **rnv platform eject**_
![image](https://user-images.githubusercontent.com/20349612/77577985-843e4c80-6eb6-11ea-95c4-d8b77076295e.png)

_Error after pressing **Enter**_
```
$ rnv platform eject - ERRROR! Cannot read property 'undefined' of undefined
TypeError: Cannot read property 'undefined' of undefined
    at rnvPlatformEject$ (C:\Users\MyUser\AppData\Roaming\npm\node_modules\rnv\src\platformTools\index.js:99:13)
    at tryCatch (C:\Users\MyUser\AppData\Roaming\npm\node_modules\rnv\node_modules\@babel\runtime\node_modules\regenerator-runtime\runtime.js:62:40)
    at Generator.invoke [as _invoke] (C:\Users\MyUser\AppData\Roaming\npm\node_modules\rnv\node_modules\@babel\runtime\node_modules\regenerator-runtime\runtime.js:288:22)
    at Generator.prototype.<computed> [as next] (C:\Users\MyUser\AppData\Roaming\npm\node_modules\rnv\node_modules\@babel\runtime\node_modules\regenerator-runtime\runtime.js:114:21)
    at tryCatch (C:\Users\MyUser\AppData\Roaming\npm\node_modules\rnv\node_modules\@babel\runtime\node_modules\regenerator-runtime\runtime.js:62:40)
    at invoke (C:\Users\MyUser\AppData\Roaming\npm\node_modules\rnv\node_modules\@babel\runtime\node_modules\regenerator-runtime\runtime.js:152:20)
    at C:\Users\MyUser\AppData\Roaming\npm\node_modules\rnv\node_modules\@babel\runtime\node_modules\regenerator-runtime\runtime.js:162:13
    at processTicksAndRejections (internal/process/task_queues.js:97:5)
```
",rnv platform eject not working I'm trying to execute `rnv platform eject` in order to modify the `build.gradle` file on Android. When the command is executed I can't select any option and there is a `Disabled` label alongside each option. Nothing happens when `<a>` or any other key is pressed. There is not interactivity at all. The only thing I can do is press `Enter` but I just get an error. _Command line after **rnv platform eject**_ ![image](https://user-images.githubusercontent.com/20349612/77577985-843e4c80-6eb6-11ea-95c4-d8b77076295e.png) _Error after pressing **Enter**_ ``` $ rnv platform eject - ERRROR! Cannot read property 'undefined' of undefined TypeError: Cannot read property 'undefined' of undefined at rnvPlatformEject$ (C:\Users\MyUser\AppData\Roaming\npm\node_modules\rnv\src\platformTools\index.js:99:13) at tryCatch (C:\Users\MyUser\AppData\Roaming\npm\node_modules\rnv\node_modules\@babel\runtime\node_modules\regenerator-runtime\runtime.js:62:40) at Generator.invoke [as _invoke] (C:\Users\MyUser\AppData\Roaming\npm\node_modules\rnv\node_modules\@babel\runtime\node_modules\regenerator-runtime\runtime.js:288:22) at Generator.prototype.<computed> [as next] (C:\Users\MyUser\AppData\Roaming\npm\node_modules\rnv\node_modules\@babel\runtime\node_modules\regenerator-runtime\runtime.js:114:21) at tryCatch (C:\Users\MyUser\AppData\Roaming\npm\node_modules\rnv\node_modules\@babel\runtime\node_modules\regenerator-runtime\runtime.js:62:40) at invoke (C:\Users\MyUser\AppData\Roaming\npm\node_modules\rnv\node_modules\@babel\runtime\node_modules\regenerator-runtime\runtime.js:152:20) at C:\Users\MyUser\AppData\Roaming\npm\node_modules\rnv\node_modules\@babel\runtime\node_modules\regenerator-runtime\runtime.js:162:13 at processTicksAndRejections (internal/process/task_queues.js:97:5) ``` 
113124,113124,125720,https://api.github.com/repos/MattiaG-afk/debrpm/issues/13,1.0,2021-05-20T20:49:20Z,OWNER,https://api.github.com/repos/MattiaG-afk/debrpm,Man page,Create man page for debrpm,Man page Create man page for debrpm
66032,66032,73421,https://api.github.com/repos/skni-kod/roguelike/issues/125,0.0,2021-04-17T23:30:07Z,COLLABORATOR,https://api.github.com/repos/skni-kod/roguelike,Naprawa potek,"Podczas podnoszenia potion처w czasami gdy ma si ich 0 to podnosz si na 2 sloty na raz.
![image](https://user-images.githubusercontent.com/51511929/115129365-77225d00-9fe5-11eb-9f83-4aa8bba36a2f.png)
",Naprawa potek Podczas podnoszenia potion처w czasami gdy ma si ich 0 to podnosz si na 2 sloty na raz. ![image](https://user-images.githubusercontent.com/51511929/115129365-77225d00-9fe5-11eb-9f83-4aa8bba36a2f.png) 
506931,506931,563387,https://api.github.com/repos/chkr1011/MQTTnet/issues/1160,0.0,2021-05-06T12:09:16Z,NONE,https://api.github.com/repos/chkr1011/MQTTnet,mqttNet performance on larger messages,"### Receiving larger messages on mqttNet client is slow
When subscribing to a topic with a wildcard (+/topic) on broker (in our case moquitto), 
that has around 900 persistent messages with an average size of 180KB,
the performance of mqttNet client on receiving messages is horribly slow.

I started the project that has only the managed client in it subscribing to +/topic, and incrementing a counter on received messages.
After starting the project I also connected separate mqtt client software (mqtt.fx) to same broker and subscribed to same topic.
**For mqtt.fx it took approximately 12 seconds to receive all 900 messages from the broker.**

**meantime mqttNet client that was running at the same time had only received 40 messages.**

it looks like the ApplicationMessageReceivedHandler was firing approximately 3-4 times a second in this case.

I also tested with topics that have higher volume of messages but message size was smaller, there the performance of mqttNet and mqtt.fx was comparable.

### Which project is your bug related to?
- Client 
OR
- ManagedClient


","mqttNet performance on larger messages ### Receiving larger messages on mqttNet client is slow When subscribing to a topic with a wildcard (+/topic) on broker (in our case moquitto), that has around 900 persistent messages with an average size of 180KB, the performance of mqttNet client on receiving messages is horribly slow. I started the project that has only the managed client in it subscribing to +/topic, and incrementing a counter on received messages. After starting the project I also connected separate mqtt client software (mqtt.fx) to same broker and subscribed to same topic. **For mqtt.fx it took approximately 12 seconds to receive all 900 messages from the broker.** **meantime mqttNet client that was running at the same time had only received 40 messages.** it looks like the ApplicationMessageReceivedHandler was firing approximately 3-4 times a second in this case. I also tested with topics that have higher volume of messages but message size was smaller, there the performance of mqttNet and mqtt.fx was comparable. ### Which project is your bug related to? - Client OR - ManagedClient "
13730,13730,15296,https://api.github.com/repos/gigascience/gigadb-website/issues/533,1.0,2020-11-23T03:45:33Z,MEMBER,https://api.github.com/repos/gigascience/gigadb-website,Issues with using pgdmp files as data for running tests,"It is problematic to add new test data into the test harness for the GigaDB application because of the use of PostgreSQL `pgdmp` files. In order for new data to be added into pgdmp files, one has to load data from `gigadb_testdata.pgdmp` or `production_like.pgdmp` files into a database. New data are then inserted into the relevant tables and then a new `pgdmp` file is created for use by the Behat tests. Writing new acceptance tests will likely require this process to be repeated which makes it tedious to perform.

It would be more convenient if test data can be provided in the form of CSV files which are transformed into Yii database migration scripts that are executed prior to each test being executed in a process that is already in place for deploying a database for development work - see #469. With CSV files, we can easily see what data is contained in database table rows. Any changes to the test data can be made directly to the CSV files which are loaded into a test database as Yii migration files for tests to run against.","Issues with using pgdmp files as data for running tests It is problematic to add new test data into the test harness for the GigaDB application because of the use of PostgreSQL `pgdmp` files. In order for new data to be added into pgdmp files, one has to load data from `gigadb_testdata.pgdmp` or `production_like.pgdmp` files into a database. New data are then inserted into the relevant tables and then a new `pgdmp` file is created for use by the Behat tests. Writing new acceptance tests will likely require this process to be repeated which makes it tedious to perform. It would be more convenient if test data can be provided in the form of CSV files which are transformed into Yii database migration scripts that are executed prior to each test being executed in a process that is already in place for deploying a database for development work - see #469. With CSV files, we can easily see what data is contained in database table rows. Any changes to the test data can be made directly to the CSV files which are loaded into a test database as Yii migration files for tests to run against."
411966,411966,457908,https://api.github.com/repos/dellhpc/omnia/issues/69,1.0,2020-05-08T15:39:34Z,CONTRIBUTOR,https://api.github.com/repos/dellhpc/omnia,make network interfaces parameter or get from inventory,"**Is your feature request related to a problem? Please describe.**
the network interface for k8s is currently hard coded in `startmaster`. It should either be a user defined variable or do some magic with ansible's inventory.  We have several adapters on most nodes so I would prefer to start with a user defined variable. 

**Describe the solution you'd like**
create variable in inventory file
use variable in `startmaster`  playbook

**Describe alternatives you've considered**


**Additional context**
Add any other context or screenshots about the feature request here.
",make network interfaces parameter or get from inventory **Is your feature request related to a problem? Please describe.** the network interface for k8s is currently hard coded in `startmaster`. It should either be a user defined variable or do some magic with ansible's inventory. We have several adapters on most nodes so I would prefer to start with a user defined variable. **Describe the solution you'd like** create variable in inventory file use variable in `startmaster` playbook **Describe alternatives you've considered** **Additional context** Add any other context or screenshots about the feature request here. 
100480,100480,111655,https://api.github.com/repos/SeanWallach/SYSC-4806/issues/37,1.0,2021-03-21T16:44:55Z,COLLABORATOR,https://api.github.com/repos/SeanWallach/SYSC-4806,Add to cart feature,"A user should be able to add a book to their cart and then purchase that book later on with all books that are in their cart. These books should then be ""owned"" by the user somehow, and quantity of the book should be taken from the ""library""","Add to cart feature A user should be able to add a book to their cart and then purchase that book later on with all books that are in their cart. These books should then be ""owned"" by the user somehow, and quantity of the book should be taken from the ""library"""
119157,119157,132401,https://api.github.com/repos/sberdevices/salute-issues/issues/58,0.0,2020-11-17T10:38:47Z,NONE,https://api.github.com/repos/sberdevices/salute-issues,[鬼逵剋] 棘剋筠 逵橘劇逵逵 劇逵逵極逵 克戟棘極克龜 (suggestions) 棘 戟筠均棘 棘逵 戟逵 克逵戟筠.,"**畇筠 戟逵筠剋 閨逵均**: 勻 極龜剋棘菌筠戟龜龜 ""鬼逵剋"".
**極龜逵戟龜筠 極棘閨剋筠劇**: 棘剋筠 棘均棘 克逵克 劇逵逵極 閨剋 鈞逵克 極棘 逵橘劇逵 筠均棘 克戟棘極克龜 (suggestions) 戟筠 閨龜逵  克逵戟逵.
![timeout_sugg_bug_scrn](https://user-images.githubusercontent.com/18159237/99379565-e9c5ca00-28d9-11eb-89a6-cd99d97f8daf.jpeg)
逵克 極棘勻棘龜: 鈞逵極克逵筠劇 逵極極, 勻克剋逵筠劇 劇棘閨龜剋戟龜克. 畇劇 極 劇龜戟, 勻克剋逵筠劇 劇棘閨龜剋戟龜克.
逵 極筠畇畇筠橘 勻筠龜龜 鬼逵剋逵 逵克棘均棘 鈞逵劇筠筠戟棘 戟筠 閨剋棘.

**棘閨剋筠劇逵 勻棘極棘龜鈞勻棘畇龜  畇均龜 極棘剋鈞棘勻逵筠剋筠橘?** 畇逵.
**棘極棘剋戟龜筠剋戟逵 龜戟棘劇逵龜**: 筠龜 ""鬼逵剋逵"" 20.11.0.4145","[鬼逵剋] 棘剋筠 逵橘劇逵逵 劇逵逵極逵 克戟棘極克龜 (suggestions) 棘 戟筠均棘 棘逵 戟逵 克逵戟筠. **畇筠 戟逵筠剋 閨逵均**: 勻 極龜剋棘菌筠戟龜龜 ""鬼逵剋"". **極龜逵戟龜筠 極棘閨剋筠劇**: 棘剋筠 棘均棘 克逵克 劇逵逵極 閨剋 鈞逵克 極棘 逵橘劇逵 筠均棘 克戟棘極克龜 (suggestions) 戟筠 閨龜逵  克逵戟逵. ![timeout_sugg_bug_scrn](https://user-images.githubusercontent.com/18159237/99379565-e9c5ca00-28d9-11eb-89a6-cd99d97f8daf.jpeg) 逵克 極棘勻棘龜: 鈞逵極克逵筠劇 逵極極, 勻克剋逵筠劇 劇棘閨龜剋戟龜克. 畇劇 極 劇龜戟, 勻克剋逵筠劇 劇棘閨龜剋戟龜克. 逵 極筠畇畇筠橘 勻筠龜龜 鬼逵剋逵 逵克棘均棘 鈞逵劇筠筠戟棘 戟筠 閨剋棘. **棘閨剋筠劇逵 勻棘極棘龜鈞勻棘畇龜  畇均龜 極棘剋鈞棘勻逵筠剋筠橘?** 畇逵. **棘極棘剋戟龜筠剋戟逵 龜戟棘劇逵龜**: 筠龜 ""鬼逵剋逵"" 20.11.0.4145"
254073,254073,282605,https://api.github.com/repos/F5Networks/f5-appsvcs-extension/issues/189,2.0,2019-11-14T07:30:28Z,NONE,https://api.github.com/repos/F5Networks/f5-appsvcs-extension,[BigIP-HA] All EPs are not updated and services restarted on BigIP after performing 25 EPs Attach operation in same go.,"<!--- Verify first that your issue/request is not already reported in GitHub -->

##### Do you already have an issue opened with F5 support?
Github Issues are consistently monitored by F5 staff, but should be considered as best effort only and you should not expect to receive the same level of response as provided by F5 Support. Please [open an case](https://support.f5.com/csp/article/K2633) with F5 if this is a critical issue.


##### ISSUE TYPE
<!--- Pick one below and delete the rest: -->
 - Bug Report
 #### AS3 BUILD/ VERSION
3.14.0-3

##### BIGIP VERSION
v13.1
##### SUMMARY
[BigIP-HA] All EPs are not updated and services restarted on BigIP after performing 25 EPs Attach operation in same go.
- This is observed only when BigIPs are configured in HA
##### STEPS TO REPRODUCE
- Defect can be reproduced everytime with below steps.
- Configure BigIPs in HA
- Configure service discovery on the BigIP
- POST 25 or more endpoints in single operation for attach operation

##### EXPECTED RESULTS
The operation should complete successfully and the endpoints should be added to respective pools.

##### ACTUAL RESULTS
Observations :

Not All Endpoints were added as nodes and pool members.

Observed both the BigIPs went unreachable one after another restarting all services. 
","[BigIP-HA] All EPs are not updated and services restarted on BigIP after performing 25 EPs Attach operation in same go. <!--- Verify first that your issue/request is not already reported in GitHub --> ##### Do you already have an issue opened with F5 support? Github Issues are consistently monitored by F5 staff, but should be considered as best effort only and you should not expect to receive the same level of response as provided by F5 Support. Please [open an case](https://support.f5.com/csp/article/K2633) with F5 if this is a critical issue. ##### ISSUE TYPE <!--- Pick one below and delete the rest: --> - Bug Report #### AS3 BUILD/ VERSION 3.14.0-3 ##### BIGIP VERSION v13.1 ##### SUMMARY [BigIP-HA] All EPs are not updated and services restarted on BigIP after performing 25 EPs Attach operation in same go. - This is observed only when BigIPs are configured in HA ##### STEPS TO REPRODUCE - Defect can be reproduced everytime with below steps. - Configure BigIPs in HA - Configure service discovery on the BigIP - POST 25 or more endpoints in single operation for attach operation ##### EXPECTED RESULTS The operation should complete successfully and the endpoints should be added to respective pools. ##### ACTUAL RESULTS Observations : Not All Endpoints were added as nodes and pool members. Observed both the BigIPs went unreachable one after another restarting all services. "
672641,672641,747588,https://api.github.com/repos/jbergstroem/hadolint-gh-action/issues/13,1.0,2021-04-11T15:18:37Z,OWNER,https://api.github.com/repos/jbergstroem/hadolint-gh-action,Support custom path to hadolint and jq,"Instead of overriding the path in a shell environment, we can allow the user to pass custom direct paths to hadolint and jq instead. This makes it easier to work in stricter environment where there may be limits to what can be overridden or changed.","Support custom path to hadolint and jq Instead of overriding the path in a shell environment, we can allow the user to pass custom direct paths to hadolint and jq instead. This makes it easier to work in stricter environment where there may be limits to what can be overridden or changed."
271158,271158,301551,https://api.github.com/repos/microsoft/vscode-edge-devtools/issues/186,1.0,2020-08-11T14:03:02Z,CONTRIBUTOR,https://api.github.com/repos/microsoft/vscode-edge-devtools,[headless instances] There should be a way to delete the instances in the list of targets,As we aren't opening a new window with the headless instances there is no way for the user to close the sessions. A sensible way would be to add a close icon next to each instance to be able to close it from VS Code.,[headless instances] There should be a way to delete the instances in the list of targets As we aren't opening a new window with the headless instances there is no way for the user to close the sessions. A sensible way would be to add a close icon next to each instance to be able to close it from VS Code.
525516,525516,584075,https://api.github.com/repos/jedimud/tintin-data/issues/37,0.0,2021-02-16T04:31:27Z,CONTRIBUTOR,https://api.github.com/repos/jedimud/tintin-data,Infinite loop when parsing opal potion,You can't wear an opal potion there.,Infinite loop when parsing opal potion You can't wear an opal potion there.
226413,226413,251794,https://api.github.com/repos/aarome/aarome/issues/356,0.0,2020-09-11T19:52:51Z,COLLABORATOR,https://api.github.com/repos/aarome/aarome,Request Forms in News section,"There are two blocks in the News section ( https://www.aarome.org/news ) that are supposed to go to web forms: ""Submit Your News"" and ""Film and Photography Request Form."" AAR web forms aren't working, and that's OK for now. I rerouted the AAR Library request forms to the existing Google forms. These two pages will need some attention.

First, can we unpublish ""Submit Your News""? This box doesn't need to appear on the News index page, and we can deal with it later.

Second, can the link for ""Film and Photography Request Form"" go to the Google form that was being used on the old site? You can see it embedded here: https://old.aarome.org/content/filmingphotography-permission-request-form.

I bring this up in part because there's going to be two shoots at the Rome campus this fall. One is for a perfume commercial (Gucci or some other luxury Italian brand). Another is for an Amazon Prime TV series, _Tom Clancy's Jack Ryan_. AAR is going to be the American Embassy. What fun!","Request Forms in News section There are two blocks in the News section ( https://www.aarome.org/news ) that are supposed to go to web forms: ""Submit Your News"" and ""Film and Photography Request Form."" AAR web forms aren't working, and that's OK for now. I rerouted the AAR Library request forms to the existing Google forms. These two pages will need some attention. First, can we unpublish ""Submit Your News""? This box doesn't need to appear on the News index page, and we can deal with it later. Second, can the link for ""Film and Photography Request Form"" go to the Google form that was being used on the old site? You can see it embedded here: https://old.aarome.org/content/filmingphotography-permission-request-form. I bring this up in part because there's going to be two shoots at the Rome campus this fall. One is for a perfume commercial (Gucci or some other luxury Italian brand). Another is for an Amazon Prime TV series, _Tom Clancy's Jack Ryan_. AAR is going to be the American Embassy. What fun!"
361439,361439,401807,https://api.github.com/repos/RFD-FHEM/RFFHEM/issues/909,1.0,2020-12-06T18:55:52Z,NONE,https://api.github.com/repos/RFD-FHEM/RFFHEM,BEST Cirrus Draw (07F57800) Deckenl체fter,"##  Specifications for new sensor / switch / or other device ... 

  - manufacturer: best / AEG
  - model name: Cirrus Draw (07F57800)
  - [pictures of the device](https://amazon.de/dp/B00XJWJ160)
  - controlled by [SEAV BeSmart S4 New B](https://amazon.de/dp/B00BHFLYG6)

  
## Specifications 

  - Microcontroller: SignalESP with CC1101
  - Version (Firmware): 3.4.0
  
<!-- ( can be found here devicename -> Internals -> version ) -->
  - Versionmodul (FHEM Module): 3.5.0 
  
<!--( can be found here: devicename -> Internals -> versionmodul ) -->


The codes from the remote are not recognized by any current implementation (no ""Decoded"" in log). It uses 433.92 MHz. There are four buttons on the remote (level up, level down, light toggle, run 5 minutes at level 1). According to an Amazon review programming the remote requires an [additional cable](https://amazon.de/dp/B00UV5PJHS).

Pressing six times **light toggle**:
```
2020.12.06 19:00:01 4: sduino: Read, msg READredu: MU;P0=-19987;P1=205;P2=-530;P3=501;P4=-253;P6=-4094;D=01234123412123434123412123412123412121216123412341212343412341212341212341212121612341234121234341234121234121234121212161234123412123434123412123412123412121216123412341212343412341212341212341212121;CP=1;R=70;
2020.12.06 19:00:03 4: sduino: Read, msg READredu: MU;P0=-11154;P1=221;P2=-517;P3=500;P4=-240;P5=-4110;D=01234123412123434123412123412123412121215123412341212343412341212341212341212121512341234121234341234121234121234121212151234123412123434123412123412123412121215123412341212343412341212341212341212121;CP=1;R=72;
2020.12.06 19:00:05 4: sduino: Read, msg READredu: MU;P0=-24164;P1=216;P2=-531;P3=499;P4=-242;P6=-4108;D=01234123412123434123412123412123412121216123412341212343412341212341212341212121612341234121234341234121234121234121212161234123412123434123412123412123412121216123412341212343412341212341212341212121;CP=1;R=72;
2020.12.06 19:00:06 4: sduino: Read, msg READredu: MU;P0=-24367;P1=221;P2=-529;P3=496;P4=-254;P5=-4104;D=01234123412123434123412123412123412121215123412341212343412341212341212341212121512341234121234341234121234121234121212151234123412123434123412123412123412121215123412341212343412341212341212341212121;CP=1;R=72;
2020.12.06 19:00:08 4: sduino: Read, msg READredu: MU;P0=-14511;P1=215;P2=-532;P3=506;P4=-239;P6=-4105;D=01234123412123434123412123412123412121216123412341212343412341212341212341212121612341234121234341234121234121234121212161234123412123434123412123412123412121216123412341212343412341212341212341212121;CP=1;R=72;
2020.12.06 19:00:09 4: sduino: Read, msg READredu: MU;P0=-30314;P1=210;P2=-532;P3=499;P4=-243;P5=-4119;D=01234123412123434123412123412123412121215123412341212343412341212341212341212121512341234121234341234121234121234121212151234123412123434123412123412123412121215123412341212343412341212341212341212121;CP=1;R=72;
```

Pressing six times **5mins**:
```
2020.12.06 19:00:13 4: sduino: Read, msg READredu: MU;P0=-23944;P1=220;P2=-529;P3=483;P4=-252;P5=-3828;D=01234123412123434123412123412121212121235123412341212343412341212341212121212123512341234121234341234121234121212121212351234123412123434123412123412121212121235123412341212343412341212341212121212123;CP=1;R=74;
2020.12.06 19:00:14 4: sduino: Read, msg READredu: MU;P0= -8307;P1=215;P2=-535;P3=489;P4=-242;P5=-3835;D=01234123412123434123412123412121212121235123412341212343412341212341212121212123512341234121234341234121234121212121212351234123412123434123412123412121212121235123412341212343412341212341212121212123;CP=1;R=72;
2020.12.06 19:00:16 4: sduino: Read, msg READredu: MU;P0=-16831;P1=224;P2=-521;P3=499;P4=-238;P5=-3826;D=01234123412123434123412123412121212121235123412341212343412341212341212121212123512341234121234341234121234121212121212351234123412123434123412123412121212121235123412341212343412341212341212121212123;CP=1;R=72;
2020.12.06 19:00:17 4: sduino: Read, msg READredu: MU;P0=-29782;P1=215;P2=-534;P3=491;P4=-231;P5=-3832;D=01234123412123434123412123412121212121235123412341212343412341212341212121212123512341234121234341234121234121212121212351234123412123434123412123412121212121235123412341212343412341212341212121212123;CP=1;R=72;
2020.12.06 19:00:19 4: sduino: Read, msg READredu: MU;P0= -1919;P1=209;P2=-537;P3=485;P4=-248;P5=-3840;D=01234123412123434123412123412121212121235123412341212343412341212341212121212123512341234121234341234121234121212121212351234123412123434123412123412121212121235123412341212343412341212341212121212123;CP=1;R=70;
2020.12.06 19:00:21 4: sduino: Read, msg READredu: MU;P0=-16275;P1=211;P2=-525;P3=504;P4=-239;P5=-3826;D=01234123412123434123412123412121212121235123412341212343412341212341212121212123512341234121234341234121234121212121212351234123412123434123412123412121212121235123412341212343412341212341212121212123;CP=1;R=70;
```

Pressing six times **level up**:
```
2020.12.06 19:00:25 4: sduino: Read, msg READredu: MU;P0= -8617;P1=204;P2=-544;P3=490;P4=-246;P6=-4106;D=01234123412123434123412123412121234121216123412341212343412341212341212123412121612341234121234341234121234121212341212161234123412123434123412123412121234121216123412341212343412341212341212123412121;CP=1;R=70;
2020.12.06 19:00:26 4: sduino: Read, msg READredu: MU;P0= -8473;P1=216;P2=-530;P3=491;P4=-250;P5=-4116;D=01234123412123434123412123412121234121215123412341212343412341212341212123412121512341234121234341234121234121212341212151234123412123434123412123412121234121215123412341212343412341212341212123412121;CP=1;R=69;
2020.12.06 19:00:28 4: sduino: Read, msg READredu: MU;P0=-11158;P1=216;P2=-532;P3=487;P4=-257;P5=-4114;D=01234123412123434123412123412121234121215123412341212343412341212341212123412121512341234121234341234121234121212341212151234123412123434123412123412121234121215123412341212343412341212341212123412121;CP=1;R=70;
2020.12.06 19:00:29 4: sduino: Read, msg READredu: MU;P0= -4308;P1=210;P2=-537;P3=490;P4=-245;         D=01234123412123434123412123412121234121210123412341212343412341212341212123412121012341234121234341234121234121212341212101234123412123434123412123412121234121210123412341212343412341212341212123412121;CP=1;R=70;
2020.12.06 19:00:31 4: sduino: Read, msg READredu: MU;P0=-21640;P1=218;P2=-534;P3=488;P4=-251;P5=-4105;D=01234123412123434123412123412121234121215123412341212343412341212341212123412121512341234121234341234121234121212341212151234123412123434123412123412121234121215123412341212343412341212341212123412121;CP=1;R=68;
2020.12.06 19:00:32 4: sduino: Read, msg READredu: MU;P0=-13496;P1=233;P2=-518;P3=504;P4=-233;P5=-4103;D=01234123412123434123412123412121234121215123412341212343412341212341212123412121512341234121234341234121234121212341212151234123412123434123412123412121234121215123412341212343412341212341212123412121;CP=1;R=66;
```

Pressing six times **level down**:
```
2020.12.06 19:00:34 4: sduino: Read, msg READredu: MU;P0=-14542;P1=221;P2=-522;P3=492;P4=-240;P5=-4114;D=01234123412123434123412123412121212341215123412341212343412341212341212121234121512341234121234341234121234121212123412151234123412123434123412123412121212341215123412341212343412341212341212121234121;CP=1;R=62;
2020.12.06 19:00:35 4: sduino: Read, msg READredu: MU;P0=-17386;P1=214;P2=-534;P3=490;P4=-251;P5=-4120;D=01234123412123434123412123412121212341215123412341212343412341212341212121234121512341234121234341234121234121212123412151234123412123434123412123412121212341215123412341212343412341212341212121234121;CP=1;R=66;
2020.12.06 19:00:37 4: sduino: Read, msg READredu: MU;P0=-11470;P1=211;P2=-527;P3=504;P4=-239;P6=-4101;D=01234123412123434123412123412121212341216123412341212343412341212341212121234121612341234121234341234121234121212123412161234123412123434123412123412121212341216123412341212343412341212341212121234121;CP=1;R=66;
2020.12.06 19:00:38 4: sduino: Read, msg READredu: MU;P0= -6119;P1=224;P2=-531;P3=496;P4=-237;P5=-4108;D=01234123412123434123412123412121212341215123412341212343412341212341212121234121512341234121234341234121234121212123412151234123412123434123412123412121212341215123412341212343412341212341212121234121;CP=1;R=66;
2020.12.06 19:00:39 4: sduino: Read, msg READredu: MU;P0=-31962;P1=208;P2=-535;P3=497;P4=-246;P5=-4102;D=01234123412123434123412123412121212341215123412341212343412341212341212121234121512341234121234341234121234121212123412151234123412123434123412123412121212341215123412341212343412341212341212121234121;CP=1;R=66;
2020.12.06 19:00:41 4: sduino: Read, msg READredu: MU;P0=-30672;P1=220;P2=-532;P3=497;P4=-241;P5=-4106;D=01234123412123434123412123412121212341215123412341212343412341212341212121234121512341234121234341234121234121212123412151234123412123434123412123412121212341215123412341212343412341212341212121234121;CP=1;R=66;
```

I found the following codes to be working:
```
# toggle light
set sduino raw SR;;P0=-19987;;P1=205;;P2=-530;;P3=501;;P4=-253;;P6=-4094;;D=01234123412123434123412123412123412121216123412341212343412341212341212341212121612341234121234341234121234121234121212161234123412123434123412123412123412121216123412341212343412341212341212341212121;;
# run 5 minutes at level 1
set sduino raw SR;;P0=-23944;;P1=220;;P2=-529;;P3=483;;P4=-252;;P5=-3828;;D=01234123412123434123412123412121212121235123412341212343412341212341212121212123512341234121234341234121234121212121212351234123412123434123412123412121212121235123412341212343412341212341212121212123;;
# go one level up
set sduino raw SR;;P0=-11158;;P1=216;;P2=-532;;P3=487;;P4=-257;;P5=-4114;;D=01234123412123434123412123412121234121215123412341212343412341212341212123412121512341234121234341234121234121212341212151234123412123434123412123412121234121215123412341212343412341212341212123412121;;
# go one level down
set sduino raw SR;;P0=-14542;;P1=221;;P2=-522;;P3=492;;P4=-240;;P5=-4114;;D=01234123412123434123412123412121212341215123412341212343412341212341212121234121512341234121234341234121234121212123412151234123412123434123412123412121212341215123412341212343412341212341212121234121;;
```

Sending level up/down with R=4 does **not** take you to the highest/lowest level - it behaves as sending with R=1.","BEST Cirrus Draw (07F57800) Deckenl체fter ## Specifications for new sensor / switch / or other device ... - manufacturer: best / AEG - model name: Cirrus Draw (07F57800) - [pictures of the device](https://amazon.de/dp/B00XJWJ160) - controlled by [SEAV BeSmart S4 New B](https://amazon.de/dp/B00BHFLYG6) ## Specifications - Microcontroller: SignalESP with CC1101 - Version (Firmware): 3.4.0 <!-- ( can be found here devicename -> Internals -> version ) --> - Versionmodul (FHEM Module): 3.5.0 <!--( can be found here: devicename -> Internals -> versionmodul ) --> The codes from the remote are not recognized by any current implementation (no ""Decoded"" in log). It uses 433.92 MHz. There are four buttons on the remote (level up, level down, light toggle, run 5 minutes at level 1). According to an Amazon review programming the remote requires an [additional cable](https://amazon.de/dp/B00UV5PJHS). Pressing six times **light toggle**: ``` 2020.12.06 19:00:01 4: sduino: Read, msg READredu: MU;P0=-19987;P1=205;P2=-530;P3=501;P4=-253;P6=-4094;D=01234123412123434123412123412123412121216123412341212343412341212341212341212121612341234121234341234121234121234121212161234123412123434123412123412123412121216123412341212343412341212341212341212121;CP=1;R=70; 2020.12.06 19:00:03 4: sduino: Read, msg READredu: MU;P0=-11154;P1=221;P2=-517;P3=500;P4=-240;P5=-4110;D=01234123412123434123412123412123412121215123412341212343412341212341212341212121512341234121234341234121234121234121212151234123412123434123412123412123412121215123412341212343412341212341212341212121;CP=1;R=72; 2020.12.06 19:00:05 4: sduino: Read, msg READredu: MU;P0=-24164;P1=216;P2=-531;P3=499;P4=-242;P6=-4108;D=01234123412123434123412123412123412121216123412341212343412341212341212341212121612341234121234341234121234121234121212161234123412123434123412123412123412121216123412341212343412341212341212341212121;CP=1;R=72; 2020.12.06 19:00:06 4: sduino: Read, msg READredu: MU;P0=-24367;P1=221;P2=-529;P3=496;P4=-254;P5=-4104;D=01234123412123434123412123412123412121215123412341212343412341212341212341212121512341234121234341234121234121234121212151234123412123434123412123412123412121215123412341212343412341212341212341212121;CP=1;R=72; 2020.12.06 19:00:08 4: sduino: Read, msg READredu: MU;P0=-14511;P1=215;P2=-532;P3=506;P4=-239;P6=-4105;D=01234123412123434123412123412123412121216123412341212343412341212341212341212121612341234121234341234121234121234121212161234123412123434123412123412123412121216123412341212343412341212341212341212121;CP=1;R=72; 2020.12.06 19:00:09 4: sduino: Read, msg READredu: MU;P0=-30314;P1=210;P2=-532;P3=499;P4=-243;P5=-4119;D=01234123412123434123412123412123412121215123412341212343412341212341212341212121512341234121234341234121234121234121212151234123412123434123412123412123412121215123412341212343412341212341212341212121;CP=1;R=72; ``` Pressing six times **5mins**: ``` 2020.12.06 19:00:13 4: sduino: Read, msg READredu: MU;P0=-23944;P1=220;P2=-529;P3=483;P4=-252;P5=-3828;D=01234123412123434123412123412121212121235123412341212343412341212341212121212123512341234121234341234121234121212121212351234123412123434123412123412121212121235123412341212343412341212341212121212123;CP=1;R=74; 2020.12.06 19:00:14 4: sduino: Read, msg READredu: MU;P0= -8307;P1=215;P2=-535;P3=489;P4=-242;P5=-3835;D=01234123412123434123412123412121212121235123412341212343412341212341212121212123512341234121234341234121234121212121212351234123412123434123412123412121212121235123412341212343412341212341212121212123;CP=1;R=72; 2020.12.06 19:00:16 4: sduino: Read, msg READredu: MU;P0=-16831;P1=224;P2=-521;P3=499;P4=-238;P5=-3826;D=01234123412123434123412123412121212121235123412341212343412341212341212121212123512341234121234341234121234121212121212351234123412123434123412123412121212121235123412341212343412341212341212121212123;CP=1;R=72; 2020.12.06 19:00:17 4: sduino: Read, msg READredu: MU;P0=-29782;P1=215;P2=-534;P3=491;P4=-231;P5=-3832;D=01234123412123434123412123412121212121235123412341212343412341212341212121212123512341234121234341234121234121212121212351234123412123434123412123412121212121235123412341212343412341212341212121212123;CP=1;R=72; 2020.12.06 19:00:19 4: sduino: Read, msg READredu: MU;P0= -1919;P1=209;P2=-537;P3=485;P4=-248;P5=-3840;D=01234123412123434123412123412121212121235123412341212343412341212341212121212123512341234121234341234121234121212121212351234123412123434123412123412121212121235123412341212343412341212341212121212123;CP=1;R=70; 2020.12.06 19:00:21 4: sduino: Read, msg READredu: MU;P0=-16275;P1=211;P2=-525;P3=504;P4=-239;P5=-3826;D=01234123412123434123412123412121212121235123412341212343412341212341212121212123512341234121234341234121234121212121212351234123412123434123412123412121212121235123412341212343412341212341212121212123;CP=1;R=70; ``` Pressing six times **level up**: ``` 2020.12.06 19:00:25 4: sduino: Read, msg READredu: MU;P0= -8617;P1=204;P2=-544;P3=490;P4=-246;P6=-4106;D=01234123412123434123412123412121234121216123412341212343412341212341212123412121612341234121234341234121234121212341212161234123412123434123412123412121234121216123412341212343412341212341212123412121;CP=1;R=70; 2020.12.06 19:00:26 4: sduino: Read, msg READredu: MU;P0= -8473;P1=216;P2=-530;P3=491;P4=-250;P5=-4116;D=01234123412123434123412123412121234121215123412341212343412341212341212123412121512341234121234341234121234121212341212151234123412123434123412123412121234121215123412341212343412341212341212123412121;CP=1;R=69; 2020.12.06 19:00:28 4: sduino: Read, msg READredu: MU;P0=-11158;P1=216;P2=-532;P3=487;P4=-257;P5=-4114;D=01234123412123434123412123412121234121215123412341212343412341212341212123412121512341234121234341234121234121212341212151234123412123434123412123412121234121215123412341212343412341212341212123412121;CP=1;R=70; 2020.12.06 19:00:29 4: sduino: Read, msg READredu: MU;P0= -4308;P1=210;P2=-537;P3=490;P4=-245; D=01234123412123434123412123412121234121210123412341212343412341212341212123412121012341234121234341234121234121212341212101234123412123434123412123412121234121210123412341212343412341212341212123412121;CP=1;R=70; 2020.12.06 19:00:31 4: sduino: Read, msg READredu: MU;P0=-21640;P1=218;P2=-534;P3=488;P4=-251;P5=-4105;D=01234123412123434123412123412121234121215123412341212343412341212341212123412121512341234121234341234121234121212341212151234123412123434123412123412121234121215123412341212343412341212341212123412121;CP=1;R=68; 2020.12.06 19:00:32 4: sduino: Read, msg READredu: MU;P0=-13496;P1=233;P2=-518;P3=504;P4=-233;P5=-4103;D=01234123412123434123412123412121234121215123412341212343412341212341212123412121512341234121234341234121234121212341212151234123412123434123412123412121234121215123412341212343412341212341212123412121;CP=1;R=66; ``` Pressing six times **level down**: ``` 2020.12.06 19:00:34 4: sduino: Read, msg READredu: MU;P0=-14542;P1=221;P2=-522;P3=492;P4=-240;P5=-4114;D=01234123412123434123412123412121212341215123412341212343412341212341212121234121512341234121234341234121234121212123412151234123412123434123412123412121212341215123412341212343412341212341212121234121;CP=1;R=62; 2020.12.06 19:00:35 4: sduino: Read, msg READredu: MU;P0=-17386;P1=214;P2=-534;P3=490;P4=-251;P5=-4120;D=01234123412123434123412123412121212341215123412341212343412341212341212121234121512341234121234341234121234121212123412151234123412123434123412123412121212341215123412341212343412341212341212121234121;CP=1;R=66; 2020.12.06 19:00:37 4: sduino: Read, msg READredu: MU;P0=-11470;P1=211;P2=-527;P3=504;P4=-239;P6=-4101;D=01234123412123434123412123412121212341216123412341212343412341212341212121234121612341234121234341234121234121212123412161234123412123434123412123412121212341216123412341212343412341212341212121234121;CP=1;R=66; 2020.12.06 19:00:38 4: sduino: Read, msg READredu: MU;P0= -6119;P1=224;P2=-531;P3=496;P4=-237;P5=-4108;D=01234123412123434123412123412121212341215123412341212343412341212341212121234121512341234121234341234121234121212123412151234123412123434123412123412121212341215123412341212343412341212341212121234121;CP=1;R=66; 2020.12.06 19:00:39 4: sduino: Read, msg READredu: MU;P0=-31962;P1=208;P2=-535;P3=497;P4=-246;P5=-4102;D=01234123412123434123412123412121212341215123412341212343412341212341212121234121512341234121234341234121234121212123412151234123412123434123412123412121212341215123412341212343412341212341212121234121;CP=1;R=66; 2020.12.06 19:00:41 4: sduino: Read, msg READredu: MU;P0=-30672;P1=220;P2=-532;P3=497;P4=-241;P5=-4106;D=01234123412123434123412123412121212341215123412341212343412341212341212121234121512341234121234341234121234121212123412151234123412123434123412123412121212341215123412341212343412341212341212121234121;CP=1;R=66; ``` I found the following codes to be working: ``` # toggle light set sduino raw SR;;P0=-19987;;P1=205;;P2=-530;;P3=501;;P4=-253;;P6=-4094;;D=01234123412123434123412123412123412121216123412341212343412341212341212341212121612341234121234341234121234121234121212161234123412123434123412123412123412121216123412341212343412341212341212341212121;; # run 5 minutes at level 1 set sduino raw SR;;P0=-23944;;P1=220;;P2=-529;;P3=483;;P4=-252;;P5=-3828;;D=01234123412123434123412123412121212121235123412341212343412341212341212121212123512341234121234341234121234121212121212351234123412123434123412123412121212121235123412341212343412341212341212121212123;; # go one level up set sduino raw SR;;P0=-11158;;P1=216;;P2=-532;;P3=487;;P4=-257;;P5=-4114;;D=01234123412123434123412123412121234121215123412341212343412341212341212123412121512341234121234341234121234121212341212151234123412123434123412123412121234121215123412341212343412341212341212123412121;; # go one level down set sduino raw SR;;P0=-14542;;P1=221;;P2=-522;;P3=492;;P4=-240;;P5=-4114;;D=01234123412123434123412123412121212341215123412341212343412341212341212121234121512341234121234341234121234121212123412151234123412123434123412123412121212341215123412341212343412341212341212121234121;; ``` Sending level up/down with R=4 does **not** take you to the highest/lowest level - it behaves as sending with R=1."
633423,633423,703984,https://api.github.com/repos/maykar/plex_assistant/issues/93,0.0,2021-02-12T22:09:10Z,NONE,https://api.github.com/repos/maykar/plex_assistant,Start scripts not working for certain devices,"I installed the latest version. I am using IFTTT. Here is a relevant portion of the log:
```
2021-02-12 16:54:28 DEBUG (SyncWorker_4) [custom_components.plex_assistant.const] IFTTT Call: play Christmas vacation on living room
2021-02-12 16:54:28 DEBUG (SyncWorker_1) [custom_components.plex_assistant.const] Command: play Christmas vacation on living room
2021-02-12 16:54:29 DEBUG (SyncWorker_1) [custom_components.plex_assistant.const] Processed Command: media = christmas vacation, device = living room
2021-02-12 16:54:49 WARNING (SyncWorker_1) [custom_components.plex_assistant.const] Cast device not found: ""Living Room"".
```

If I set the default device to one of the entities that the plex integration creates, for example media_player.plex_plex_for_roku_living_room and call plex assistant it will play on the device if plex is already open. I renamed the friendly name of this device to  ""Living Room"" but still get the above error. However, I do have mutiple friendly names of ""living room"" including for example media_player.living_room which is what I use launch the plex app. I wonder if some sort of mapping like you have where we map a script to a device would work to map a streaming device to a friendly device name.","Start scripts not working for certain devices I installed the latest version. I am using IFTTT. Here is a relevant portion of the log: ``` 2021-02-12 16:54:28 DEBUG (SyncWorker_4) [custom_components.plex_assistant.const] IFTTT Call: play Christmas vacation on living room 2021-02-12 16:54:28 DEBUG (SyncWorker_1) [custom_components.plex_assistant.const] Command: play Christmas vacation on living room 2021-02-12 16:54:29 DEBUG (SyncWorker_1) [custom_components.plex_assistant.const] Processed Command: media = christmas vacation, device = living room 2021-02-12 16:54:49 WARNING (SyncWorker_1) [custom_components.plex_assistant.const] Cast device not found: ""Living Room"". ``` If I set the default device to one of the entities that the plex integration creates, for example media_player.plex_plex_for_roku_living_room and call plex assistant it will play on the device if plex is already open. I renamed the friendly name of this device to ""Living Room"" but still get the above error. However, I do have mutiple friendly names of ""living room"" including for example media_player.living_room which is what I use launch the plex app. I wonder if some sort of mapping like you have where we map a script to a device would work to map a streaming device to a friendly device name."
585602,585602,650748,https://api.github.com/repos/PawelLawrynowicz/Cursed-Blackjack/issues/2,0.0,2021-04-05T12:09:39Z,OWNER,https://api.github.com/repos/PawelLawrynowicz/Cursed-Blackjack,Balance bug,Balance shows wrong value after round's end,Balance bug Balance shows wrong value after round's end
420421,420421,467330,https://api.github.com/repos/metanorma/stepmod2mn/issues/15,1.0,2021-02-25T06:06:58Z,NONE,https://api.github.com/repos/metanorma/stepmod2mn,SVG routine should convert the per-document diagrams,"For every STEPmod standard part there are some diagrams that are per-document (not per-schema). We need to convert these into SVGs too:

https://github.com/metanorma/annotated-express/blob/fe8b266e266179b6fbe3ee74b358221bb7b00cfe/data/documents/resources/fundamentals_of_product_description_and_support/resource.xml#L1151-L1158

```
   <!-- Schema Interface express-g diagrams  -->
   <!-- refer to p41ed2 as example  -->
   <schema_diag>
      <express-g>
         <imgfile file=""schema_diagexpg1.xml""
                  title=""The schemas of this part of ISO 10303""/>
      </express-g>
   </schema_diag>
```

The actual image xml is:
```xml
<?xml version=""1.0""?>
<?xml-stylesheet type=""text/xsl"" href=""../../../xsl/res_doc/imgfile.xsl"" ?>
<!DOCTYPE imgfile.content SYSTEM ""../../../dtd/text.ent"">
<imgfile.content module=""fundamentals_of_product_description_and_support"" file=""schema_diagexpg1.xml"">
	<img src=""schema_diagexpg1.gif"">
		<img.area shape=""poly"" coords=""301,39,301,95,528,95,528,39,301,39"" href=""../../resources/group_schema.xml#group_schema""/>
		<img.area shape=""poly"" coords=""301,644,301,700,528,700,528,644,301,644"" href=""../../resources/qualifications_schema.xml#qualifications_schema""/>
		<img.area shape=""poly"" coords=""301,115,301,171,528,171,528,115,301,115"" href=""../../resources/location_schema.xml#location_schema""/>
...
```

In the document.adoc, this should be translated into:

```adoc
[.svgmap]
====
image:: schema_diagexpg1.svg[]

* <<express: group_schema >>; 1
* <<express: qualifications_schema >>; 2
* <<express: location_schema >>; 3
...
====
```","SVG routine should convert the per-document diagrams For every STEPmod standard part there are some diagrams that are per-document (not per-schema). We need to convert these into SVGs too: https://github.com/metanorma/annotated-express/blob/fe8b266e266179b6fbe3ee74b358221bb7b00cfe/data/documents/resources/fundamentals_of_product_description_and_support/resource.xml#L1151-L1158 ``` <!-- Schema Interface express-g diagrams --> <!-- refer to p41ed2 as example --> <schema_diag> <express-g> <imgfile file=""schema_diagexpg1.xml"" title=""The schemas of this part of ISO 10303""/> </express-g> </schema_diag> ``` The actual image xml is: ```xml <?xml version=""1.0""?> <?xml-stylesheet type=""text/xsl"" href=""../../../xsl/res_doc/imgfile.xsl"" ?> <!DOCTYPE imgfile.content SYSTEM ""../../../dtd/text.ent""> <imgfile.content module=""fundamentals_of_product_description_and_support"" file=""schema_diagexpg1.xml""> <img src=""schema_diagexpg1.gif""> <img.area shape=""poly"" coords=""301,39,301,95,528,95,528,39,301,39"" href=""../../resources/group_schema.xml#group_schema""/> <img.area shape=""poly"" coords=""301,644,301,700,528,700,528,644,301,644"" href=""../../resources/qualifications_schema.xml#qualifications_schema""/> <img.area shape=""poly"" coords=""301,115,301,171,528,171,528,115,301,115"" href=""../../resources/location_schema.xml#location_schema""/> ... ``` In the document.adoc, this should be translated into: ```adoc [.svgmap] ==== image:: schema_diagexpg1.svg[] * <<express: group_schema >>; 1 * <<express: qualifications_schema >>; 2 * <<express: location_schema >>; 3 ... ==== ```"
248112,248112,275954,https://api.github.com/repos/practice-uffs/web-feedback/issues/181,1.0,2020-12-01T19:49:26Z,CONTRIBUTOR,https://api.github.com/repos/practice-uffs/web-feedback,Postar coment찼rios em issue do github quando algum coment찼rio 챕 criado no web-feedback,"Essa issue est찼 relacionada com #180 

Quando houver uma intera챌찾o com um servi챌o no web-feedback (como coment찼rio de um cliente ou de um admin), essa intera챌찾o deve ser refletida no github tamb챕m para n찾o termos um ""telefone sem fio"". O objetivo dessa issue 챕 fazer essa integra챌찾o.

Os servi챌os no webfeedback tem um campo relacionado com um link de uma issue. Logo, quando um coment찼rio for criado em um servi챌o, pode-se verificar se o campo da URL da issue tem alguma coisa. Se tiver, quer dizer que esse servi챌o est찼 relacionado com uma issue. Com a URL da issue, pode-se utilizar a API do github para postar um coment찼rio nessa issue em espec챠fico.","Postar coment찼rios em issue do github quando algum coment찼rio 챕 criado no web-feedback Essa issue est찼 relacionada com #180 Quando houver uma intera챌찾o com um servi챌o no web-feedback (como coment찼rio de um cliente ou de um admin), essa intera챌찾o deve ser refletida no github tamb챕m para n찾o termos um ""telefone sem fio"". O objetivo dessa issue 챕 fazer essa integra챌찾o. Os servi챌os no webfeedback tem um campo relacionado com um link de uma issue. Logo, quando um coment찼rio for criado em um servi챌o, pode-se verificar se o campo da URL da issue tem alguma coisa. Se tiver, quer dizer que esse servi챌o est찼 relacionado com uma issue. Com a URL da issue, pode-se utilizar a API do github para postar um coment찼rio nessa issue em espec챠fico."
400689,400689,445355,https://api.github.com/repos/pmvdbijl7/socionus/issues/4,1.0,2021-03-18T12:21:25Z,OWNER,https://api.github.com/repos/pmvdbijl7/socionus,Setup authentication,,Setup authentication 
514573,514573,571853,https://api.github.com/repos/fossasia/open-event-frontend/issues/4866,0.0,2020-08-25T09:08:59Z,MEMBER,https://api.github.com/repos/fossasia/open-event-frontend,"Public Speakers and Schedule Page: No Lazy Loading, it Slows Down Users Too Much","Public speakers page and schedule pages should have not lazy loading as it slows down the usage of the site too much, e.g. compare here https://eventyay.com/e/8fa7fd14/speakers","Public Speakers and Schedule Page: No Lazy Loading, it Slows Down Users Too Much Public speakers page and schedule pages should have not lazy loading as it slows down the usage of the site too much, e.g. compare here https://eventyay.com/e/8fa7fd14/speakers"
485804,485804,539916,https://api.github.com/repos/jandelgado/jled/issues/70,2.0,2021-02-08T04:36:23Z,NONE,https://api.github.com/repos/jandelgado/jled,Arduino Mega Pin issue,"Hi Jandelgado,

I seem to be having a different issue with using pins on the Arduino Mega.  The project works great on any PWM pins, but I can't seem to get anything running on the extra pins in the A1-8 and 22-53 pin ranges.  I had a good read of the similar issue posted about the ESP, and the alternative GPIO(?) numbers don't seem to work either.  I can get these pins to work by using the standard digitalWrite blink function, however.  Once again, thanks for all your hard work on this project. Any ideas on this are appreciated! 

Here is the code I'm using: 

#include <jled.h>

JLed leds[] = {

// Blue LEDs (Works great)

    JLed(12).Breathe(1000).DelayAfter(2900),
    JLed(11).Breathe(1000). DelayBefore(100). DelayAfter(2800). MaxBrightness(100),
    JLed(13).Breathe(1000). DelayBefore(200). DelayAfter(2700). MaxBrightness(100),
    JLed(10).Breathe(1000). DelayBefore(300). DelayAfter(2600). MaxBrightness(100),
    JLed(9).Breathe(1000). DelayBefore(500). DelayAfter(2400).  MaxBrightness(100), 
    JLed(8).Breathe(1000). DelayBefore(700). DelayAfter(2200).  MaxBrightness(100), 
    JLed(7).Breathe(1000). DelayBefore(900). DelayAfter(2000).  MaxBrightness(100), 
    JLed(6).Breathe(1000). DelayBefore(1100). DelayAfter(1800). MaxBrightness(100),
    JLed(5).Breathe(1000). DelayBefore(1300). DelayAfter(1600). MaxBrightness(100),
    JLed(4).Breathe(1000). DelayBefore(1500). DelayAfter(1400). MaxBrightness(100),
    JLed(3).Breathe(1000). DelayBefore(1700). DelayAfter(1200). MaxBrightness(100),
    JLed(2).Breathe(1000). DelayBefore(1900). DelayAfter(1000). MaxBrightness(100),
    
// White LEDs (doesn't work)

    JLed(A8).Blink (250, 250). MaxBrightness(100),
    JLed(14).Blink(250, 250). MaxBrightness(100),
    JLed(29).Blink(250, 250). MaxBrightness(100). Repeat(5),
    JLed(25).Blink(250, 250). MaxBrightness(100). Repeat(5),
    JLed(49).Blink(250, 250). MaxBrightness(100). Repeat(5),
    JLed(48).Blink(250, 250). MaxBrightness(100). Repeat(10),
    
};
auto sequence = JLedSequence(JLedSequence::eMode::PARALLEL, leds).Repeat(1000);


void setup() { }

void loop() {
   
    sequence.Update();

    
    delay(1);

}

Cheers,
Steph","Arduino Mega Pin issue Hi Jandelgado, I seem to be having a different issue with using pins on the Arduino Mega. The project works great on any PWM pins, but I can't seem to get anything running on the extra pins in the A1-8 and 22-53 pin ranges. I had a good read of the similar issue posted about the ESP, and the alternative GPIO(?) numbers don't seem to work either. I can get these pins to work by using the standard digitalWrite blink function, however. Once again, thanks for all your hard work on this project. Any ideas on this are appreciated! Here is the code I'm using: #include <jled.h> JLed leds[] = { // Blue LEDs (Works great) JLed(12).Breathe(1000).DelayAfter(2900), JLed(11).Breathe(1000). DelayBefore(100). DelayAfter(2800). MaxBrightness(100), JLed(13).Breathe(1000). DelayBefore(200). DelayAfter(2700). MaxBrightness(100), JLed(10).Breathe(1000). DelayBefore(300). DelayAfter(2600). MaxBrightness(100), JLed(9).Breathe(1000). DelayBefore(500). DelayAfter(2400). MaxBrightness(100), JLed(8).Breathe(1000). DelayBefore(700). DelayAfter(2200). MaxBrightness(100), JLed(7).Breathe(1000). DelayBefore(900). DelayAfter(2000). MaxBrightness(100), JLed(6).Breathe(1000). DelayBefore(1100). DelayAfter(1800). MaxBrightness(100), JLed(5).Breathe(1000). DelayBefore(1300). DelayAfter(1600). MaxBrightness(100), JLed(4).Breathe(1000). DelayBefore(1500). DelayAfter(1400). MaxBrightness(100), JLed(3).Breathe(1000). DelayBefore(1700). DelayAfter(1200). MaxBrightness(100), JLed(2).Breathe(1000). DelayBefore(1900). DelayAfter(1000). MaxBrightness(100), // White LEDs (doesn't work) JLed(A8).Blink (250, 250). MaxBrightness(100), JLed(14).Blink(250, 250). MaxBrightness(100), JLed(29).Blink(250, 250). MaxBrightness(100). Repeat(5), JLed(25).Blink(250, 250). MaxBrightness(100). Repeat(5), JLed(49).Blink(250, 250). MaxBrightness(100). Repeat(5), JLed(48).Blink(250, 250). MaxBrightness(100). Repeat(10), }; auto sequence = JLedSequence(JLedSequence::eMode::PARALLEL, leds).Repeat(1000); void setup() { } void loop() { sequence.Update(); delay(1); } Cheers, Steph"
267900,267900,297937,https://api.github.com/repos/smslit/cocogo/issues/1,0.0,2021-02-22T02:47:05Z,OWNER,https://api.github.com/repos/smslit/cocogo,岳鸚窯 - RuntimeWarning: More than 20 figures have been opened,matplotlib 鴉訝뷴뜻凉 figure 鸚ゅ warning,岳鸚窯 - RuntimeWarning: More than 20 figures have been opened matplotlib 鴉訝뷴뜻凉 figure 鸚ゅ warning
370375,370375,411739,https://api.github.com/repos/oam-dev/kubevela/issues/1394,0.0,2021-04-01T03:19:40Z,COLLABORATOR,https://api.github.com/repos/oam-dev/kubevela,`vela show` can not find component of helm,"**Describe the bug**
<!--
A clear and concise description of what the bug is.
-->

Declare Helm charts as app components via `ComponentDefinition`.

```yaml
apiVersion: core.oam.dev/v1beta1
kind: ComponentDefinition
metadata:
  name: kibana-chart
  annotations:
    definition.oam.dev/description: helm chart for kibana
spec:
  workload:
    definition:
      apiVersion: apps/v1
      kind: Deployment
  schematic:
    helm:
      release:
        chart:
          spec:
            chart: ""kibana""
            version: ""7.11.1""
      repository:
        url: ""https://helm.elastic.co/""
```

However, it cannot be viewed with the `vela show` command.

**Screenshots**
<!--
If applicable, add screenshots to help explain your problem.
-->

![image](https://user-images.githubusercontent.com/24563928/113238384-3b944d00-92db-11eb-9c6d-41f73dc19145.png)

![image](https://user-images.githubusercontent.com/24563928/113238524-87df8d00-92db-11eb-9fdb-8f538b9da38c.png)

**Cluster information**
<!--
Describe your kubernetes cluster information.
- Kubernetes Version [e.g. 1.16.9]
-->

- Kubernetes Version 1.19.1 (kind)

","`vela show` can not find component of helm **Describe the bug** <!-- A clear and concise description of what the bug is. --> Declare Helm charts as app components via `ComponentDefinition`. ```yaml apiVersion: core.oam.dev/v1beta1 kind: ComponentDefinition metadata: name: kibana-chart annotations: definition.oam.dev/description: helm chart for kibana spec: workload: definition: apiVersion: apps/v1 kind: Deployment schematic: helm: release: chart: spec: chart: ""kibana"" version: ""7.11.1"" repository: url: ""https://helm.elastic.co/"" ``` However, it cannot be viewed with the `vela show` command. **Screenshots** <!-- If applicable, add screenshots to help explain your problem. --> ![image](https://user-images.githubusercontent.com/24563928/113238384-3b944d00-92db-11eb-9c6d-41f73dc19145.png) ![image](https://user-images.githubusercontent.com/24563928/113238524-87df8d00-92db-11eb-9fdb-8f538b9da38c.png) **Cluster information** <!-- Describe your kubernetes cluster information. - Kubernetes Version [e.g. 1.16.9] --> - Kubernetes Version 1.19.1 (kind) "
207964,207964,231240,https://api.github.com/repos/psk907/fluttermoji/issues/2,0.0,2021-01-19T05:27:15Z,NONE,https://api.github.com/repos/psk907/fluttermoji,Default Svg image get display while using SvgPicture.string(encoded),"Default Svg image get display while using SvgPicture.String(decoded), First I encode the current FluttermojiCircleAvatar using the 
FluttermojiFunctions and then decode it to display with the help of  SvgPicture.String(decoded). 
","Default Svg image get display while using SvgPicture.string(encoded) Default Svg image get display while using SvgPicture.String(decoded), First I encode the current FluttermojiCircleAvatar using the FluttermojiFunctions and then decode it to display with the help of SvgPicture.String(decoded). "
392954,392954,436778,https://api.github.com/repos/clastix/capsule-proxy/issues/63,1.0,2021-03-14T20:09:33Z,MEMBER,https://api.github.com/repos/clastix/capsule-proxy,Setting up CI linting checks,"As we're doing with [Capsule](https://github.com/clastix/capsule/blob/56adfe6a35d2271f1556d794614007aee656dbb5/.github/workflows/ci.yml#L10-L20), we should define the linting checks and implement them at CI level using GitHub Actions.","Setting up CI linting checks As we're doing with [Capsule](https://github.com/clastix/capsule/blob/56adfe6a35d2271f1556d794614007aee656dbb5/.github/workflows/ci.yml#L10-L20), we should define the linting checks and implement them at CI level using GitHub Actions."
472272,472272,524881,https://api.github.com/repos/activeloopai/Hub/issues/618,0.0,2021-02-25T17:39:28Z,CONTRIBUTOR,https://api.github.com/repos/activeloopai/Hub,[BUG] Broken Links in Docs ,"##  Bug Report

In the Notes Subsection of the [How to Upload a Dataset](https://docs.activeloop.ai/en/latest/dataset.html) page in docs, the links to all the examples (Uploading MNIST, Uploading CIFAR, and Uploading COCO) are broken.

### 截 Current Behavior

The links are broken and point to older versions of the examples directory

### ㎞ Possible Solution  (optional)

Fix links to redirect to [examples/old/](https://github.com/activeloopai/Hub/tree/master/examples/old) directory
","[BUG] Broken Links in Docs  ##  Bug Report In the Notes Subsection of the [How to Upload a Dataset](https://docs.activeloop.ai/en/latest/dataset.html) page in docs, the links to all the examples (Uploading MNIST, Uploading CIFAR, and Uploading COCO) are broken. ### 截 Current Behavior The links are broken and point to older versions of the examples directory ### ㎞ Possible Solution (optional) Fix links to redirect to [examples/old/](https://github.com/activeloopai/Hub/tree/master/examples/old) directory "
269161,269161,299326,https://api.github.com/repos/libsdl-org/SDL/issues/2524,0.0,2021-02-11T00:43:53Z,COLLABORATOR,https://api.github.com/repos/libsdl-org/SDL,Call made to glGetString before context creation,"
# This bug report was migrated from our old Bugzilla tracker.

These attachments are available in the static archive:

* [preload library source (preload.c, text/plain, 2017-08-04 11:38:00 +0000, 2181 bytes)](https://bugzilla.libsdl.org/attachment.cgi?id=2818)

**Reported in version:** 2.0.5
**Reported for operating system, platform:** Linux, x86_64

# Comments on the original bug report:

On 2017-08-04 11:38:00 +0000, Baldur Karlsson wrote:

> Created attachment 2818
> preload library source
> 
> In 36f40b8cc979 there was a call added in X11_GL_LoadLibrary to SDL_GL_DeduceMaxSupportedESProfile, which then calls SDL_GL_ExtensionSupported to check for ES compatibility, which ends up calling glGetString (for the version to see if it should use glGetStringi) and other things.
> 
> However this happens before any context is created or made current, so I don't believe it's valid to do. Probably in most cases these simple queries aren't context-dependent but just return fixed compile-time strings, so nothing blows up, but I ran into a crash with renderdoc because I require a context at that point.
> 
> To repro/prove this, compile a simple program like this:
> 
> 
> #include <SDL2/SDL.h>
> 
> int main(int argc, char **argv)
> {;
>   SDL_Init(SDL_INIT_VIDEO);
>   SDL_Window *win = SDL_CreateWindow(""test"", -32, -32, 32, 32, SDL_WINDOW_OPENGL|SDL_WINDOW_HIDDEN);
>   SDL_GLContext ctx = SDL_GL_CreateContext(win);
>   return 0;
> }
> 
> 
> And then run with SDL_OPENGL_LIBRARY=./libpreload.so pointing to the compiled preload.c from the attachment. It's a bit of an arbitrary repro case but the real one involves a full GL interceptor so this is nice and simple. It shows the order of the calls:
> 
> $ SDL_OPENGL_LIBRARY=./libpreload.so ./SDLtest
> Inside hooked glGetString(1f02)
> Inside hooked glGetString(1f03)
> Inside hooked glGetString(1f02)
> Inside hooked glGetString(1f03)
> Inside hooked glGetString(1f02)
> Inside hooked glGetString(1f03)
> Inside hooked glXCreateContext
> Inside hooked glGetString(1f00)
> Inside hooked glGetString(1f02)
> Inside hooked glGetString(1f03)
> Inside hooked glGetString(1f02)
> Inside hooked glGetString(1f03)
> Inside hooked glGetString(1f02)
> Inside hooked glGetString(1f03)
> Inside hooked glXCreateContext

On 2017-08-08 00:49:08 +0000, Mark Callow wrote:

> One fix is to remove calls to SDL_GL_DeduceMaxSupportedESProfile and instead in the *_GL_InitExtensions functions separately test for {GLX,WGL}_EXT_create_context_es_profile and {GLX,WGL}_EXT_create_context_es2_profile in that order.
> 
> This will fail if someone is trying to create an ES 3.1 or 3.2 context and only 3.0 & 2.0 are available.
> 
> To fully fix this, in the event that {GLX,WGL}_EXT_create_context_es_profile is found and the app is requesting an ES 3.1 or 3.2 context, *_GL_LoadLibrary will need to attempt to create a sacrificial context of the requested version which it can then delete. If it fails, it can go ahead and load the OpenGL ES library.
> 
> For now I've linked this to the bugs associated with 36f40b8cc979 which Sam reopened. However I think it is simpler to discuss the fix here. I'm not sure what is the utility of reopening those others.

On 2017-08-08 20:07:49 +0000, Mark Callow wrote:

> Note that WIN_GL_InitExtensions is already creating a sacrificial context, for other reasons, which is why this issue only happens on Linux/GLX.

On 2017-08-08 20:37:07 +0000, Mark Callow wrote:

> I don't understand why the code sample ends up calling glXCreateContext twice. The only call I have found in the source is from SDL_GL_CreateContext. There are no calls to it from any code invoked by SDL_CreateWindow. Anyone know?

On 2017-08-08 20:42:59 +0000, Baldur Karlsson wrote:

> If you mean the original code sample I posted, it's because underneath SDL_Init in SDL_video.c there's a function called ShouldUseTextureFramebuffer() that creates a temporary window & context to check the vendor string on linux, then the code sample itself creates a context (the second call).

On 2017-08-09 05:25:35 +0000, Ryan C. Gordon wrote:

> (Sorry if you get a lot of copies of this email, we're touching dozens of bug reports right now.)
> 
> Tagging a bunch of bugs as target-2.0.6.
> 
> This means we're in the final stretch for an official SDL 2.0.6 release! These are the bugs we really want to fix before shipping if humanly possible.
> 
> That being said, we don't promise to fix them because of this tag, we just want to make sure we don't forget to deal with them before we bless a final 2.0.6 release, and generally be organized about what we're aiming to ship. After some debate, we might just remove this tag again and deal with it for a later release.
> 
> Hopefully you'll hear more about this bug soon. If you have more information (including ""this got fixed at some point, nevermind""), we would love to have you come add more information to the bug report when you have a moment.
> 
> Thanks!
> --ryan.

On 2017-08-09 20:44:07 +0000, Mark Callow wrote:

> (In reply to Baldur Karlsson from comment # 4)
> > If you mean the original code sample I posted, it's because underneath
> > SDL_Init in SDL_video.c there's a function called
> > ShouldUseTextureFramebuffer() that creates a temporary window & context to
> > check the vendor string on linux, then the code sample itself creates a
> > context (the second call).
> 
> Thanks.
> 
> It's unrelated to this issue but I think that code needs to be revisited. A very large number of OpenGL h/w accelerated devices are not being recognized as such. Intel's has been providing good open source drivers for their embedded graphics h/w for some years as a standard part of the Mesa distribution.
> 
> Related to this issue, it would probably be good to use the same sacrificial context to query the vendor string and finding out which es_compatibility extensions are supported. That would mean moving the vendor query.

On 2017-08-09 23:17:37 +0000, Sam Lantinga wrote:

> Mark, would you mind creating a tested patch that covers this issue and the various OpenGL ES use cases?
> 
> Thanks!

On 2017-08-10 00:46:56 +0000, Mark Callow wrote:

> Sam, I do not have suitable hardware, i.e. a GPU whose driver supports GLX_EXT_create_context_es{,2}_profile, which is only NVIDIA as far as I am aware. So, although I can probably create a patch, I can only test the paths used when the extension is not found, which will traverse none of the code to fix this issue. Also because I am sick at present it might be some time before I can get to it.

On 2017-08-10 01:50:01 +0000, Sam Lantinga wrote:

> Okay, thanks for letting us know.

On 2017-09-01 17:58:34 +0000, Ryan C. Gordon wrote:

> 
> There used to be a sacrificial context on X11, too, but previously, the only reason we had this on Windows was because your function pointers from wglGetProcAddress() are context-specific and we needed to look up a context-specific function to _then_ create a modern OpenGL context; it's wild, but that's how it works. glX does not have this requirement and I decided taunting the GL driver gods by creating and immediately destroying the extra context was worth avoiding.
> 
> I've added this back, in https://hg.libsdl.org/SDL/rev/1717e5011161, and https://hg.libsdl.org/SDL/rev/37688701d4ce makes this more robust.
> 
> I can confirm this definitely creates a context, makes it current, correctly looks up the extensions, and then destroys the temporary context.
> 
> --ryan.

On 2017-09-01 18:11:39 +0000, Ryan C. Gordon wrote:

> 
> (additional fixes https://hg.libsdl.org/SDL/rev/71be1b793327 and  https://hg.libsdl.org/SDL/rev/f9cf3fb0b2f7 because I'm too quick on the trigger when pushing to revision control...)
> 
> --ryan.

","Call made to glGetString before context creation # This bug report was migrated from our old Bugzilla tracker. These attachments are available in the static archive: * [preload library source (preload.c, text/plain, 2017-08-04 11:38:00 +0000, 2181 bytes)](https://bugzilla.libsdl.org/attachment.cgi?id=2818) **Reported in version:** 2.0.5 **Reported for operating system, platform:** Linux, x86_64 # Comments on the original bug report: On 2017-08-04 11:38:00 +0000, Baldur Karlsson wrote: > Created attachment 2818 > preload library source > > In 36f40b8cc979 there was a call added in X11_GL_LoadLibrary to SDL_GL_DeduceMaxSupportedESProfile, which then calls SDL_GL_ExtensionSupported to check for ES compatibility, which ends up calling glGetString (for the version to see if it should use glGetStringi) and other things. > > However this happens before any context is created or made current, so I don't believe it's valid to do. Probably in most cases these simple queries aren't context-dependent but just return fixed compile-time strings, so nothing blows up, but I ran into a crash with renderdoc because I require a context at that point. > > To repro/prove this, compile a simple program like this: > > > #include <SDL2/SDL.h> > > int main(int argc, char **argv) > {; > SDL_Init(SDL_INIT_VIDEO); > SDL_Window *win = SDL_CreateWindow(""test"", -32, -32, 32, 32, SDL_WINDOW_OPENGL|SDL_WINDOW_HIDDEN); > SDL_GLContext ctx = SDL_GL_CreateContext(win); > return 0; > } > > > And then run with SDL_OPENGL_LIBRARY=./libpreload.so pointing to the compiled preload.c from the attachment. It's a bit of an arbitrary repro case but the real one involves a full GL interceptor so this is nice and simple. It shows the order of the calls: > > $ SDL_OPENGL_LIBRARY=./libpreload.so ./SDLtest > Inside hooked glGetString(1f02) > Inside hooked glGetString(1f03) > Inside hooked glGetString(1f02) > Inside hooked glGetString(1f03) > Inside hooked glGetString(1f02) > Inside hooked glGetString(1f03) > Inside hooked glXCreateContext > Inside hooked glGetString(1f00) > Inside hooked glGetString(1f02) > Inside hooked glGetString(1f03) > Inside hooked glGetString(1f02) > Inside hooked glGetString(1f03) > Inside hooked glGetString(1f02) > Inside hooked glGetString(1f03) > Inside hooked glXCreateContext On 2017-08-08 00:49:08 +0000, Mark Callow wrote: > One fix is to remove calls to SDL_GL_DeduceMaxSupportedESProfile and instead in the *_GL_InitExtensions functions separately test for {GLX,WGL}_EXT_create_context_es_profile and {GLX,WGL}_EXT_create_context_es2_profile in that order. > > This will fail if someone is trying to create an ES 3.1 or 3.2 context and only 3.0 & 2.0 are available. > > To fully fix this, in the event that {GLX,WGL}_EXT_create_context_es_profile is found and the app is requesting an ES 3.1 or 3.2 context, *_GL_LoadLibrary will need to attempt to create a sacrificial context of the requested version which it can then delete. If it fails, it can go ahead and load the OpenGL ES library. > > For now I've linked this to the bugs associated with 36f40b8cc979 which Sam reopened. However I think it is simpler to discuss the fix here. I'm not sure what is the utility of reopening those others. On 2017-08-08 20:07:49 +0000, Mark Callow wrote: > Note that WIN_GL_InitExtensions is already creating a sacrificial context, for other reasons, which is why this issue only happens on Linux/GLX. On 2017-08-08 20:37:07 +0000, Mark Callow wrote: > I don't understand why the code sample ends up calling glXCreateContext twice. The only call I have found in the source is from SDL_GL_CreateContext. There are no calls to it from any code invoked by SDL_CreateWindow. Anyone know? On 2017-08-08 20:42:59 +0000, Baldur Karlsson wrote: > If you mean the original code sample I posted, it's because underneath SDL_Init in SDL_video.c there's a function called ShouldUseTextureFramebuffer() that creates a temporary window & context to check the vendor string on linux, then the code sample itself creates a context (the second call). On 2017-08-09 05:25:35 +0000, Ryan C. Gordon wrote: > (Sorry if you get a lot of copies of this email, we're touching dozens of bug reports right now.) > > Tagging a bunch of bugs as target-2.0.6. > > This means we're in the final stretch for an official SDL 2.0.6 release! These are the bugs we really want to fix before shipping if humanly possible. > > That being said, we don't promise to fix them because of this tag, we just want to make sure we don't forget to deal with them before we bless a final 2.0.6 release, and generally be organized about what we're aiming to ship. After some debate, we might just remove this tag again and deal with it for a later release. > > Hopefully you'll hear more about this bug soon. If you have more information (including ""this got fixed at some point, nevermind""), we would love to have you come add more information to the bug report when you have a moment. > > Thanks! > --ryan. On 2017-08-09 20:44:07 +0000, Mark Callow wrote: > (In reply to Baldur Karlsson from comment # 4) > > If you mean the original code sample I posted, it's because underneath > > SDL_Init in SDL_video.c there's a function called > > ShouldUseTextureFramebuffer() that creates a temporary window & context to > > check the vendor string on linux, then the code sample itself creates a > > context (the second call). > > Thanks. > > It's unrelated to this issue but I think that code needs to be revisited. A very large number of OpenGL h/w accelerated devices are not being recognized as such. Intel's has been providing good open source drivers for their embedded graphics h/w for some years as a standard part of the Mesa distribution. > > Related to this issue, it would probably be good to use the same sacrificial context to query the vendor string and finding out which es_compatibility extensions are supported. That would mean moving the vendor query. On 2017-08-09 23:17:37 +0000, Sam Lantinga wrote: > Mark, would you mind creating a tested patch that covers this issue and the various OpenGL ES use cases? > > Thanks! On 2017-08-10 00:46:56 +0000, Mark Callow wrote: > Sam, I do not have suitable hardware, i.e. a GPU whose driver supports GLX_EXT_create_context_es{,2}_profile, which is only NVIDIA as far as I am aware. So, although I can probably create a patch, I can only test the paths used when the extension is not found, which will traverse none of the code to fix this issue. Also because I am sick at present it might be some time before I can get to it. On 2017-08-10 01:50:01 +0000, Sam Lantinga wrote: > Okay, thanks for letting us know. On 2017-09-01 17:58:34 +0000, Ryan C. Gordon wrote: > > There used to be a sacrificial context on X11, too, but previously, the only reason we had this on Windows was because your function pointers from wglGetProcAddress() are context-specific and we needed to look up a context-specific function to _then_ create a modern OpenGL context; it's wild, but that's how it works. glX does not have this requirement and I decided taunting the GL driver gods by creating and immediately destroying the extra context was worth avoiding. > > I've added this back, in https://hg.libsdl.org/SDL/rev/1717e5011161, and https://hg.libsdl.org/SDL/rev/37688701d4ce makes this more robust. > > I can confirm this definitely creates a context, makes it current, correctly looks up the extensions, and then destroys the temporary context. > > --ryan. On 2017-09-01 18:11:39 +0000, Ryan C. Gordon wrote: > > (additional fixes https://hg.libsdl.org/SDL/rev/71be1b793327 and https://hg.libsdl.org/SDL/rev/f9cf3fb0b2f7 because I'm too quick on the trigger when pushing to revision control...) > > --ryan. "
721899,721899,802293,https://api.github.com/repos/nasa/gunns/issues/9,1.0,2021-03-11T12:28:24Z,CONTRIBUTOR,https://api.github.com/repos/nasa/gunns,Test gunnsdraw netexport in CI,- [x] Change SIM_test to export its network drawings at build-time.  This will add some regression testing for netexport.py.,Test gunnsdraw netexport in CI - [x] Change SIM_test to export its network drawings at build-time. This will add some regression testing for netexport.py.
484050,484050,537966,https://api.github.com/repos/swoole/swoole-src/issues/4119,2.0,2021-03-26T02:23:30Z,NONE,https://api.github.com/repos/swoole/swoole-src,Is it possible to run WordPress on Swoole?,"I'd like to know if its possible to run WordPress on Swoole? Any prototypes, POC out there?","Is it possible to run WordPress on Swoole? I'd like to know if its possible to run WordPress on Swoole? Any prototypes, POC out there?"
735382,735382,124407,https://api.github.com/repos/Deathspike/animesync/issues/15,1.0,2021-01-03T18:48:15Z,NONE,https://api.github.com/repos/Deathspike/animesync,More subtitle languages support,"Consider this please as a feature request. Adding a parameter such as --defSub to set one subtitle language as a default language while muxing to mkv would be also awesone
",More subtitle languages support Consider this please as a feature request. Adding a parameter such as --defSub to set one subtitle language as a default language while muxing to mkv would be also awesone 
732571,732571,96300,https://api.github.com/repos/AOSC-Dev/aosc-os-abbs/issues/1389,0.0,2018-09-21T06:50:33Z,MEMBER,https://api.github.com/repos/AOSC-Dev/aosc-os-abbs,latrace: libltaudit.so has undefined symbol,"Bug description & Reproducing steps
-----------------------
```
lion@Lion-Laptop [ Debug ] $ latrace /bin/true
ERROR: ld.so: object '/usr/lib/libltaudit.so.0.5.11' cannot be loaded as audit interface: undefined symbol: lt_args_wrap; ignored.

/bin/true finished - exited, status=0
```
Package and version
------------------------------
latrace 0.5.11 amd64
","latrace: libltaudit.so has undefined symbol Bug description & Reproducing steps ----------------------- ``` lion@Lion-Laptop [ Debug ] $ latrace /bin/true ERROR: ld.so: object '/usr/lib/libltaudit.so.0.5.11' cannot be loaded as audit interface: undefined symbol: lt_args_wrap; ignored. /bin/true finished - exited, status=0 ``` Package and version ------------------------------ latrace 0.5.11 amd64 "
627329,627329,697171,https://api.github.com/repos/GLinBoy/jcart-backend/issues/12,0.0,2021-04-11T08:27:20Z,OWNER,https://api.github.com/repos/GLinBoy/jcart-backend,primit all swagger urls,,primit all swagger urls 
237626,237626,264312,https://api.github.com/repos/flutter/gallery/issues/514,1.0,2021-05-26T06:45:51Z,NONE,https://api.github.com/repos/flutter/gallery,How to run this project?help me please!,"![image](https://user-images.githubusercontent.com/13111596/119614391-d0757b80-be30-11eb-9787-5b1d1809aea0.png)

i want to run this project to simulator.
but have a fail.who can help me.thanks!",How to run this project?help me please! ![image](https://user-images.githubusercontent.com/13111596/119614391-d0757b80-be30-11eb-9787-5b1d1809aea0.png) i want to run this project to simulator. but have a fail.who can help me.thanks!
5222,5222,5821,https://api.github.com/repos/MUTUAL-DE-SERVICIOS-AL-POLICIA/PVT/issues/1423,1.0,2021-02-17T10:39:12Z,CONTRIBUTOR,https://api.github.com/repos/MUTUAL-DE-SERVICIOS-AL-POLICIA/PVT,Liberar tr찼mite del usuario (Workflow),,Liberar tr찼mite del usuario (Workflow) 
170809,170809,189917,https://api.github.com/repos/cBioPortal/cbioportal/issues/8482,0.0,2021-04-01T00:09:16Z,MEMBER,https://api.github.com/repos/cBioPortal/cbioportal,Error in mutations tab,"For https://www.cbioportal.org/results?plots_horz_selection=%7B%7D&plots_vert_selection=%7B%7D&plots_coloring_selection=%7B%7D&data_priority=0&tab_index=tab_visualize&Action=Submit&session_id=6064e7b9e4b0242bd5d45f5f

Mutation tab doesn't load

<img width=""693"" alt=""Screen Shot 2021-03-31 at 8 08 39 PM"" src=""https://user-images.githubusercontent.com/12956870/113225939-f0d3f000-925c-11eb-8b2a-a50e4348b039.png"">
","Error in mutations tab For https://www.cbioportal.org/results?plots_horz_selection=%7B%7D&plots_vert_selection=%7B%7D&plots_coloring_selection=%7B%7D&data_priority=0&tab_index=tab_visualize&Action=Submit&session_id=6064e7b9e4b0242bd5d45f5f Mutation tab doesn't load <img width=""693"" alt=""Screen Shot 2021-03-31 at 8 08 39 PM"" src=""https://user-images.githubusercontent.com/12956870/113225939-f0d3f000-925c-11eb-8b2a-a50e4348b039.png""> "
520148,520148,578077,https://api.github.com/repos/topcoder-platform/forums-plugins/issues/1,1.0,2020-03-05T21:43:49Z,CONTRIBUTOR,https://api.github.com/repos/topcoder-platform/forums-plugins,Create a Topcoder Theme,"- [ ] Get a Design
- [ ] Create a Topcoder Theme",Create a Topcoder Theme - [ ] Get a Design - [ ] Create a Topcoder Theme
538809,538809,598854,https://api.github.com/repos/programmer2514/BEE2.4-Installer-Automatic/issues/2,0.0,2021-02-25T22:19:02Z,NONE,https://api.github.com/repos/programmer2514/BEE2.4-Installer-Automatic,help,"It just says no internet connection

Do i need to set something up?",help It just says no internet connection Do i need to set something up?
221635,221635,246464,https://api.github.com/repos/Andretan322/homepage/issues/18,1.0,2021-01-12T21:59:41Z,OWNER,https://api.github.com/repos/Andretan322/homepage,Create .git/hooks/pre-commit file that should look roughly like this,"```
#!/bin/sh
if workbox generateSW workbox-config.js ; then
  git add sw.js
  exit 0
else
  echo ""Cannot generate sw.js""
  echo ""Aborting""
fi
```","Create .git/hooks/pre-commit file that should look roughly like this ``` #!/bin/sh if workbox generateSW workbox-config.js ; then git add sw.js exit 0 else echo ""Cannot generate sw.js"" echo ""Aborting"" fi ```"
28497,28497,31735,https://api.github.com/repos/aemiers/flashcards-starter/issues/5,1.0,2021-02-01T23:37:29Z,OWNER,https://api.github.com/repos/aemiers/flashcards-starter,Create Turn Class,- [x] Turn Class passes all of the Turn Test tests,Create Turn Class - [x] Turn Class passes all of the Turn Test tests
513615,513615,570782,https://api.github.com/repos/brave/brave-browser/issues/14254,0.0,2021-02-19T15:00:24Z,COLLABORATOR,https://api.github.com/repos/brave/brave-browser,[Android] Bottom toolbar appears in landscape mode,"@samartnik regarding bottom toolbar orientation, I got ""bottom toolbar"" thingy in landscape mode IF, I open ""tabs switcher"". 

In NTP landscape mode the bottom toolbar shown in split second and then puff. Gone. 

But, IF the tab is used to open any url (including ""chrome://what-do-I-call-this-?"") the bottom toolbar is shown.

- tab opening ""https://brave.com"" :
![Screenshot_20210219-063631](https://user-images.githubusercontent.com/28621428/108435955-18f32b00-727d-11eb-9901-f5af730803a8.png)

- tab opening ""chrome://version"" :
![Screenshot_20210219-065046](https://user-images.githubusercontent.com/28621428/108436916-e813f580-727e-11eb-920f-466b39b7b6a1.png)

- tab opening ""about:blank"" :
![Screenshot_20210219-070041](https://user-images.githubusercontent.com/28621428/108437582-37a6f100-7280-11eb-963f-901110ca3205.png)

However, none of them ( the buttons) is working. Is it supposed to be like this? Do I need to open new issue?

_Originally posted by @Revenrof in https://github.com/brave/brave-browser/issues/14211#issuecomment-781714978_","[Android] Bottom toolbar appears in landscape mode @samartnik regarding bottom toolbar orientation, I got ""bottom toolbar"" thingy in landscape mode IF, I open ""tabs switcher"". In NTP landscape mode the bottom toolbar shown in split second and then puff. Gone. But, IF the tab is used to open any url (including ""chrome://what-do-I-call-this-?"") the bottom toolbar is shown. - tab opening ""https://brave.com"" : ![Screenshot_20210219-063631](https://user-images.githubusercontent.com/28621428/108435955-18f32b00-727d-11eb-9901-f5af730803a8.png) - tab opening ""chrome://version"" : ![Screenshot_20210219-065046](https://user-images.githubusercontent.com/28621428/108436916-e813f580-727e-11eb-920f-466b39b7b6a1.png) - tab opening ""about:blank"" : ![Screenshot_20210219-070041](https://user-images.githubusercontent.com/28621428/108437582-37a6f100-7280-11eb-963f-901110ca3205.png) However, none of them ( the buttons) is working. Is it supposed to be like this? Do I need to open new issue? _Originally posted by @Revenrof in https://github.com/brave/brave-browser/issues/14211#issuecomment-781714978_"
388197,388197,431529,https://api.github.com/repos/smilevideo/Didi-Shou-Chang/issues/14,0.0,2021-02-28T14:44:02Z,OWNER,https://api.github.com/repos/smilevideo/Didi-Shou-Chang,some flac files don't play in the browser,"e.g. https://drive.google.com/file/d/1CAVNlqWwPLlErKQj2pmJfk2hLl5KJ-37/view?usp=sharing
think im at the mercy of the browsers, doesn't really have anything to do with my code","some flac files don't play in the browser e.g. https://drive.google.com/file/d/1CAVNlqWwPLlErKQj2pmJfk2hLl5KJ-37/view?usp=sharing think im at the mercy of the browsers, doesn't really have anything to do with my code"
87776,87776,97567,https://api.github.com/repos/mecbil/P3_02_BlogSources/issues/21,1.0,2021-04-29T22:28:26Z,OWNER,https://api.github.com/repos/mecbil/P3_02_BlogSources,"find one : Post, User, Comment ...","try to do a function to one (Post, User or a Comment )","find one : Post, User, Comment ... try to do a function to one (Post, User or a Comment )"
332636,332636,369808,https://api.github.com/repos/gianlucafrei/Application-Gateway/issues/3,1.0,2020-10-24T15:21:30Z,COLLABORATOR,https://api.github.com/repos/gianlucafrei/Application-Gateway,Sl4j,We should improve the general logging. Check if the logging is implemented state of the art.,Sl4j We should improve the general logging. Check if the logging is implemented state of the art.
231529,231529,257480,https://api.github.com/repos/miyanokomiya/blendic-svg/issues/1,1.0,2021-02-23T12:41:13Z,OWNER,https://api.github.com/repos/miyanokomiya/blendic-svg,SVG Elements Tree,"- [x] show SVG elements tree in a side panel
- [x] select and sync elements in the canvas and the tree
- [x] enable to select `<g>` tags and weight paint

## Problems
### How to transform `<g>` nested elements?
```pug
g#g_1
  g#g_2
```
```yaml
- born_1
  - born_1_1
  - born_1_2
- born_2
```

If the parent born of `g_1` is `born_1`, `born_2` must not be a parent of `g_2`.
Futhermore, the transformation of `g_2` must be relative on the parent `g_1` space.","SVG Elements Tree - [x] show SVG elements tree in a side panel - [x] select and sync elements in the canvas and the tree - [x] enable to select `<g>` tags and weight paint ## Problems ### How to transform `<g>` nested elements? ```pug g#g_1 g#g_2 ``` ```yaml - born_1 - born_1_1 - born_1_2 - born_2 ``` If the parent born of `g_1` is `born_1`, `born_2` must not be a parent of `g_2`. Futhermore, the transformation of `g_2` must be relative on the parent `g_1` space."
83043,83043,92325,https://api.github.com/repos/TsubakiBotPad/pad-cogs/issues/525,0.0,2021-01-16T08:54:13Z,COLLABORATOR,https://api.github.com/repos/TsubakiBotPad/pad-cogs,fluff names need to not let you prioritize wrong part of the tree,"test case:

6249 bride roche",fluff names need to not let you prioritize wrong part of the tree test case: 6249 bride roche
69963,69963,77761,https://api.github.com/repos/NAIST-SD-PBL-PAL/Teddy-plus/issues/18,0.0,2021-01-29T05:48:29Z,NONE,https://api.github.com/repos/NAIST-SD-PBL-PAL/Teddy-plus,Unrecognized VM option 'UseParNewGC'," Error: Could not create the Java Virtual Machine. Error: A fatal exception has occurred. Program will exit.

ElasticSearch2.2.0 supports only Java 1.8",Unrecognized VM option 'UseParNewGC' Error: Could not create the Java Virtual Machine. Error: A fatal exception has occurred. Program will exit. ElasticSearch2.2.0 supports only Java 1.8
92465,92465,102760,https://api.github.com/repos/coneda/kor/issues/323,0.0,2021-03-12T03:41:38Z,MEMBER,https://api.github.com/repos/coneda/kor,entities can't be removed from global/personal groups,,entities can't be removed from global/personal groups 
237556,237556,264234,https://api.github.com/repos/htl-leonding-project/leo-iot/issues/101,2.0,2021-04-19T09:02:50Z,COLLABORATOR,https://api.github.com/repos/htl-leonding-project/leo-iot,Cascade Types ?,,Cascade Types ? 
731603,731603,86503,https://api.github.com/repos/andretkachenko/nexus-bot/issues/87,1.0,2020-12-23T15:50:18Z,OWNER,https://api.github.com/repos/andretkachenko/nexus-bot,Add slash command support,"Discord added a new feature for the bot developers - slash commands.
This allows using / to show your bot's list, just like built-in /shrug etc.
However, it is not yet implemented by the DiscordJS  ([#5103](https://github.com/discordjs/discord.js/issues/5103)), so it may take some time before I will be able to implement slash commands for the bot.

This issue is raised just to show people who are curious about the future development of the bot, which features are planned to be added.","Add slash command support Discord added a new feature for the bot developers - slash commands. This allows using / to show your bot's list, just like built-in /shrug etc. However, it is not yet implemented by the DiscordJS ([#5103](https://github.com/discordjs/discord.js/issues/5103)), so it may take some time before I will be able to implement slash commands for the bot. This issue is raised just to show people who are curious about the future development of the bot, which features are planned to be added."
252536,252536,280895,https://api.github.com/repos/Slimefun-Addon-Community/LiteXpansion/issues/20,0.0,2021-01-20T22:04:48Z,NONE,https://api.github.com/repos/Slimefun-Addon-Community/LiteXpansion,[BUG] Back button dont work in UU matter section inside guide.,"<!-- FILL IN THE FORM BELOW -->

## Description (REQUIRED)
In the slimefun guide when you click the UU matter section it breaks & the back button wont let you go back to the main men.


## Steps to reproduce the Issue (REQUIRED)
1) Open slimefun guide
2) Click UU matter
3) Try to press the back button in the left.


## Expected behavior (REQUIRED)
The back button will not work & you will be unable to return to the main guide without a server restart.

## Environment (REQUIRED)
<!-- Any info without the exact version numbers will be closed! -->
<!-- ""latest"" IS NOT A VERSION NUMBER. -->
<!-- We recommend running ""/sf versions"" and showing us a screenshot of that. -->
<!-- Make sure that the screenshot covers the entire output of that command. -->
<!-- If your issue is related to other plugins, make sure to include the versions of these plugins too! -->

 - Server Software (Spigot/Paper):
 - Minecraft version:  1.16.4
 - CS-CoreLib version: DEV 91
 - Slimefun version: RC 18
 - LiteXpansion version: DEV 123
","[BUG] Back button dont work in UU matter section inside guide. <!-- FILL IN THE FORM BELOW --> ## Description (REQUIRED) In the slimefun guide when you click the UU matter section it breaks & the back button wont let you go back to the main men. ## Steps to reproduce the Issue (REQUIRED) 1) Open slimefun guide 2) Click UU matter 3) Try to press the back button in the left. ## Expected behavior (REQUIRED) The back button will not work & you will be unable to return to the main guide without a server restart. ## Environment (REQUIRED) <!-- Any info without the exact version numbers will be closed! --> <!-- ""latest"" IS NOT A VERSION NUMBER. --> <!-- We recommend running ""/sf versions"" and showing us a screenshot of that. --> <!-- Make sure that the screenshot covers the entire output of that command. --> <!-- If your issue is related to other plugins, make sure to include the versions of these plugins too! --> - Server Software (Spigot/Paper): - Minecraft version: 1.16.4 - CS-CoreLib version: DEV 91 - Slimefun version: RC 18 - LiteXpansion version: DEV 123 "
586692,586692,651958,https://api.github.com/repos/Spring-Framework-Java-Apps/simpleworklist/issues/331,1.0,2021-01-02T21:29:15Z,COLLABORATOR,https://api.github.com/repos/Spring-Framework-Java-Apps/simpleworklist,Edit Project: update HTML Layout to current Bootstrap Version,,Edit Project: update HTML Layout to current Bootstrap Version 
659121,659121,732632,https://api.github.com/repos/gordominossi/InfOS/issues/16,0.0,2021-01-18T23:57:18Z,OWNER,https://api.github.com/repos/gordominossi/InfOS,Create mock machines for usage in OCEmu,"- [ ] Multiblocks
- [x] Cleanroom
- [x] Power",Create mock machines for usage in OCEmu - [ ] Multiblocks - [x] Cleanroom - [x] Power
213176,213176,237051,https://api.github.com/repos/sfu-dhil/bep/issues/63,0.0,2021-05-26T20:03:45Z,CONTRIBUTOR,https://api.github.com/repos/sfu-dhil/bep,Make the transaction numbers visible on the transactions list & details,"Currently, the transaction number only shows up under books or parishes to note the relevant transactions. However, if it was also visible on the Transactions list and Transaction details, it would make it easier for us to direct each other to any transactions we have questions or concerns about in the future (i.e. See Transaction number 576, rather than having to note what it says, what source it came from, etc.). And would it be helpful to format these numbers as 00001, 00562 (or as many number places as we think we will use) making it clear to users that this is an arbitrary number.","Make the transaction numbers visible on the transactions list & details Currently, the transaction number only shows up under books or parishes to note the relevant transactions. However, if it was also visible on the Transactions list and Transaction details, it would make it easier for us to direct each other to any transactions we have questions or concerns about in the future (i.e. See Transaction number 576, rather than having to note what it says, what source it came from, etc.). And would it be helpful to format these numbers as 00001, 00562 (or as many number places as we think we will use) making it clear to users that this is an arbitrary number."
414183,414183,460379,https://api.github.com/repos/cgkineo/adapt-globalAudio/issues/1,0.0,2021-05-17T13:37:03Z,MEMBER,https://api.github.com/repos/cgkineo/adapt-globalAudio,Add globals definitions for play/pause aria-labels,,Add globals definitions for play/pause aria-labels 
481184,481184,534781,https://api.github.com/repos/standard/vscode-standardjs/issues/100,0.0,2020-01-27T17:52:39Z,NONE,https://api.github.com/repos/standard/vscode-standardjs,Extension doesn't load babel config files with babel-eslint,"**What version of this package are you using?**
1.2.3
**What operating system, Node.js, and npm version?**
W10, 12.7.0, 6.10.0
**What happened?**
Doesn't load babel config when using babel-eslint
`Parsing error: No Babel config file detected for filename`
![image](https://user-images.githubusercontent.com/7280931/73199891-03710780-4136-11ea-89d8-a76e686074bd.png)

**What did you expect to happen?**
Parsing works in terminal using `standard` and it should in vscode as well.

","Extension doesn't load babel config files with babel-eslint **What version of this package are you using?** 1.2.3 **What operating system, Node.js, and npm version?** W10, 12.7.0, 6.10.0 **What happened?** Doesn't load babel config when using babel-eslint `Parsing error: No Babel config file detected for filename` ![image](https://user-images.githubusercontent.com/7280931/73199891-03710780-4136-11ea-89d8-a76e686074bd.png) **What did you expect to happen?** Parsing works in terminal using `standard` and it should in vscode as well. "
366257,366257,407151,https://api.github.com/repos/fri-team/Swapify/issues/463,0.0,2021-05-17T15:11:51Z,COLLABORATOR,https://api.github.com/repos/fri-team/Swapify,Autodeploy_necessary_files_not_copied,"Some files from project need to be copied to aws before deploying. Those files are ""docker-compose.yml"", ""Dockerfile"", ""nginx.conf"", ""init-letsencrypt.sh""","Autodeploy_necessary_files_not_copied Some files from project need to be copied to aws before deploying. Those files are ""docker-compose.yml"", ""Dockerfile"", ""nginx.conf"", ""init-letsencrypt.sh"""
171512,171512,190702,https://api.github.com/repos/vaadin/vaadin-messages/issues/49,1.0,2021-03-08T07:52:44Z,MEMBER,https://api.github.com/repos/vaadin/vaadin-messages,Java APIs to Message docs examples,"The docs has TS examples for all components, but Java examples are missing. Implement them.","Java APIs to Message docs examples The docs has TS examples for all components, but Java examples are missing. Implement them."
482689,482689,536458,https://api.github.com/repos/PokeNavBot/issue-tracker/issues/606,1.0,2021-01-22T13:37:35Z,NONE,https://api.github.com/repos/PokeNavBot/issue-tracker,Include member mention or user.id in trainer profile embed,"**Is your feature request related to a problem? Please describe.**
From a bot's perspective, the trainer info embed doesn't have anything in it to identify exactly which user it belongs to.
In a profile settings channel with lots of activity, sometimes more than 1 trainer will do a $trainer or $profile command before PokeNav responds, so it's harder to tell which embed belongs to which user (again, this is from a bot's perspective).

**Describe the solution you'd like**
The trainer info embed could include the user.id, or a user mention from which the bot could retrieve the user.id itself. This could be in the footer for example to not impact the existing layout.

**Describe alternatives you've considered**
The bot can do a $trainer call and read the trainer embed response it gets, but by having the ability to identify the user from the embed, it could just scan/read any embed the users are already doing when viewing their profile.

**Additional comment**
Now that I think about it, if this info was in all profile feedback embeds (meaning the pokenav response from individual commands like $ign, $stc, etc.), that would be even more awesome, as I could update my own records or trigger my own custom behavior if it falls in one of my filters, even if they don't do another $trainer or $profile call when done updating their profile.
","Include member mention or user.id in trainer profile embed **Is your feature request related to a problem? Please describe.** From a bot's perspective, the trainer info embed doesn't have anything in it to identify exactly which user it belongs to. In a profile settings channel with lots of activity, sometimes more than 1 trainer will do a $trainer or $profile command before PokeNav responds, so it's harder to tell which embed belongs to which user (again, this is from a bot's perspective). **Describe the solution you'd like** The trainer info embed could include the user.id, or a user mention from which the bot could retrieve the user.id itself. This could be in the footer for example to not impact the existing layout. **Describe alternatives you've considered** The bot can do a $trainer call and read the trainer embed response it gets, but by having the ability to identify the user from the embed, it could just scan/read any embed the users are already doing when viewing their profile. **Additional comment** Now that I think about it, if this info was in all profile feedback embeds (meaning the pokenav response from individual commands like $ign, $stc, etc.), that would be even more awesome, as I could update my own records or trigger my own custom behavior if it falls in one of my filters, even if they don't do another $trainer or $profile call when done updating their profile. "
423334,423334,470576,https://api.github.com/repos/pkosiec/mongo-seeding/issues/139,1.0,2021-01-05T11:46:22Z,OWNER,https://api.github.com/repos/pkosiec/mongo-seeding,Migrate CI pipelines to Github Actions,"As Travis open source free plan has been removed recently, this repository should be migrated to GitHub Actions.","Migrate CI pipelines to Github Actions As Travis open source free plan has been removed recently, this repository should be migrated to GitHub Actions."
687022,687022,763539,https://api.github.com/repos/Delikt/wannaplay/issues/3,0.0,2021-03-07T18:59:55Z,OWNER,https://api.github.com/repos/Delikt/wannaplay,Multichoice Abort Button dont work,"the script runs straight forward - Fix needed



쨈쨈쨈#Multichoice

    cmd=(dialog --separate-output --checklist ""Choose your Weapon: (use SPACE for selection and ENTER to confirm)"" 22 76 16)
        options=(1 ""Install Graphic Card Driver Packages"" off
                2 ""Install WineHQ and Winetricks"" off
                3 ""Install Vulkan API"" off
                4 ""Install 32-bit Game support"" off
                5 ""Additional Libraries for Origin, Battle.net, Uplay etc."" off
                6 ""Configure Esync support"" off
                7 ""Install latest ProtonGE Release"" off
                8 ""Install Protontricks + GUI"" off
                9 ""Install native Steam Gaming Plattform"" off
                10 ""Install Lutris Open Gaming Plattform"" off
                11 ""Install MangoHUD - FPS Overlay"" off
                12 ""Install OBS - Open Broadcast Software"" off)
        choices=$(""${cmd[@]}"" ""${options[@]}"" 2>&1 >/dev/tty)
        clear
        for choice in $choices
        do
            case $choice in
                1)
                    GPUinst=true
                    ;;
                2)
                    winehq=true
                    ;;
                3)
                    vulkanapi=true
                    ;;
                4)
                    bitsupp=true
                    ;;
                5)
                    additionallibinst=true
                    ;;
                6)
                    confesync=true
                    ;;
                7)	
                    instprotonGE=true
                    ;;    
                8)	
                    instprotontricks=true
                    ;;       
                9)
                    steam=true
                    ;;
                10)
                    lutris=true
                    ;;
                11)
                    mangohud=true
                    ;;
                12)
                    obs=true
                    ;;
            esac
        done
쨈쨈쨈","Multichoice Abort Button dont work the script runs straight forward - Fix needed 쨈쨈쨈#Multichoice cmd=(dialog --separate-output --checklist ""Choose your Weapon: (use SPACE for selection and ENTER to confirm)"" 22 76 16) options=(1 ""Install Graphic Card Driver Packages"" off 2 ""Install WineHQ and Winetricks"" off 3 ""Install Vulkan API"" off 4 ""Install 32-bit Game support"" off 5 ""Additional Libraries for Origin, Battle.net, Uplay etc."" off 6 ""Configure Esync support"" off 7 ""Install latest ProtonGE Release"" off 8 ""Install Protontricks + GUI"" off 9 ""Install native Steam Gaming Plattform"" off 10 ""Install Lutris Open Gaming Plattform"" off 11 ""Install MangoHUD - FPS Overlay"" off 12 ""Install OBS - Open Broadcast Software"" off) choices=$(""${cmd[@]}"" ""${options[@]}"" 2>&1 >/dev/tty) clear for choice in $choices do case $choice in 1) GPUinst=true ;; 2) winehq=true ;; 3) vulkanapi=true ;; 4) bitsupp=true ;; 5) additionallibinst=true ;; 6) confesync=true ;; 7) instprotonGE=true ;; 8) instprotontricks=true ;; 9) steam=true ;; 10) lutris=true ;; 11) mangohud=true ;; 12) obs=true ;; esac done 쨈쨈쨈"
448876,448876,498897,https://api.github.com/repos/eclipse/tycho/issues/25,1.0,2021-04-09T06:18:22Z,CONTRIBUTOR,https://api.github.com/repos/eclipse/tycho,Relax synchronization in Mojos,"https://bugs.eclipse.org/bugs/show_bug.cgi?id=571434
https://bugzillaattachments.eclipsecontent.org/bugs/attachment.cgi?id=285635

Currently most (all?) tycho Mojos synchronize on a static lock, effectively allowing only different goals to run in parallel.
Especially the (relatively) long-running compile and package mojos spend more time waiting for the lock than doing actual work in a build with 32 threads.

Maven only recommends that pessimistic lock pattern ""if a mojo uses a known-non-threadsafe external dependency"" [1].
AFAICS that's not the case. Removing the locks speeds up a mvn clean package -T 2C (=32) a lot: 18min vs 1h before.
See the attached comparison.


[1] https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Maven+3","Relax synchronization in Mojos https://bugs.eclipse.org/bugs/show_bug.cgi?id=571434 https://bugzillaattachments.eclipsecontent.org/bugs/attachment.cgi?id=285635 Currently most (all?) tycho Mojos synchronize on a static lock, effectively allowing only different goals to run in parallel. Especially the (relatively) long-running compile and package mojos spend more time waiting for the lock than doing actual work in a build with 32 threads. Maven only recommends that pessimistic lock pattern ""if a mojo uses a known-non-threadsafe external dependency"" [1]. AFAICS that's not the case. Removing the locks speeds up a mvn clean package -T 2C (=32) a lot: 18min vs 1h before. See the attached comparison. [1] https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Maven+3"
260036,260036,289204,https://api.github.com/repos/beyond-io/roo.me/issues/236,0.0,2021-05-22T01:25:10Z,COLLABORATOR,https://api.github.com/repos/beyond-io/roo.me,fix under 500 rent in the search mechanism,"**Describe the bug**
In the search mechanism, whenever the rent price was under 500, the mechanism would show a negative number.
Changed it to a minumum 1.

**To Reproduce**
Steps to reproduce the behavior:
Go to the search mechanism when rent is under 500.

**Expected behavior**
whenever rent is under 500, rent  = 1.","fix under 500 rent in the search mechanism **Describe the bug** In the search mechanism, whenever the rent price was under 500, the mechanism would show a negative number. Changed it to a minumum 1. **To Reproduce** Steps to reproduce the behavior: Go to the search mechanism when rent is under 500. **Expected behavior** whenever rent is under 500, rent = 1."
133160,133160,147997,https://api.github.com/repos/BurnySc2/sc2-planner/issues/21,0.0,2021-01-21T03:55:18Z,NONE,https://api.github.com/repos/BurnySc2/sc2-planner,Terran upgrades still include DurableMaterials. ,"I don't think you can upgrade it, but it was removed in Hots. ","Terran upgrades still include DurableMaterials. I don't think you can upgrade it, but it was removed in Hots. "
167174,167174,185896,https://api.github.com/repos/xzippyzachx/softwareproject_group9/issues/10,0.0,2021-03-24T02:46:32Z,NONE,https://api.github.com/repos/xzippyzachx/softwareproject_group9,Override current tablature pop-up window doesn't work sometimes,"ID# 10
Who Raised: Nobaiha Zaman Rayta
Title: Override current tablature pop-up window doesn't work sometimes
Version: master - 823856fc829043e4af28117cf8e8d9016b24e834
Platform: Windows 10
Reproduction: 1. Open the application
2. Input a text tab
3. Convert and save tab
Expected Outcome: After pressing yes on the current tablature pop-up window it closes the windows and overrides the tablature
Actual Outcome: After pressing yes, the tab does get overridden but the popup window doesn't close. 
Priority: low
Severity: low
Screenshots:
![image](https://user-images.githubusercontent.com/77299896/112246616-5c003f80-8c29-11eb-9a79-641f110da847.png)
","Override current tablature pop-up window doesn't work sometimes ID# 10 Who Raised: Nobaiha Zaman Rayta Title: Override current tablature pop-up window doesn't work sometimes Version: master - 823856fc829043e4af28117cf8e8d9016b24e834 Platform: Windows 10 Reproduction: 1. Open the application 2. Input a text tab 3. Convert and save tab Expected Outcome: After pressing yes on the current tablature pop-up window it closes the windows and overrides the tablature Actual Outcome: After pressing yes, the tab does get overridden but the popup window doesn't close. Priority: low Severity: low Screenshots: ![image](https://user-images.githubusercontent.com/77299896/112246616-5c003f80-8c29-11eb-9a79-641f110da847.png) "
400177,400177,444779,https://api.github.com/repos/El-Potato-Slayer/Wordent/issues/6,1.0,2021-02-10T09:13:00Z,OWNER,https://api.github.com/repos/El-Potato-Slayer/Wordent,Add a select box for categories in article creation form,,Add a select box for categories in article creation form 
635949,635949,706813,https://api.github.com/repos/ccxt/ccxt/issues/9173,2.0,2021-05-11T23:48:44Z,NONE,https://api.github.com/repos/ccxt/ccxt,Can exchange.createOrder(...) return an empty response string,"OS: Windows Server 2019 Datacenter
Programming Language version: Node.js 15.3.0
CCXT version: 1.47.3
Exchange: All Exchanges
Method: binance.createOrder()

Hello!

The ccxt is great. Just a wonderful creation! 

I have a question about when we create an order using: `exchange.createOrder(...)`.
```
async function _createOrder() {

    var exchange = new ccxt.binance(); const params = {};
    const response = await exchange.createOrder(""BTC/USDT"", ""limit"", ""buy"", 0.01, 56200, params);

    console.log(response);
}
```
We receive a **response** with a format that look like this when everything works:
```
{
	id: '60s8asdfsafask3453lk345lj3l',
        symbol: 'BTC/USDT',
        amount: '0.01',
        etc...
}
```
I am in the process of implementing scenarios of what could happen which leads me to this question. I have tried the code above perheps 20 times while implementing code.

What I wonder is if there is a scenario where we **Do Not** get a response from: `exchange.createOrder` with any information about what has happened. 

1. For example can response be completely empty with No information at all like an EMPTY string?
2. For example let us assume that the internet connection goes down 1 millisecond after the: `exchange.createOrder` has been executed and the internet connection works again after 1 hour. What happens here in the response?
3. Perheps I am looking for all other possible responses which can come out from this except a successful response?

I beleive question 1. is one which I wonder about much.
I am not sure if I have described the question well enough, but perheps the id챕a of what I wonder about can be seen.

Thank you!
","Can exchange.createOrder(...) return an empty response string OS: Windows Server 2019 Datacenter Programming Language version: Node.js 15.3.0 CCXT version: 1.47.3 Exchange: All Exchanges Method: binance.createOrder() Hello! The ccxt is great. Just a wonderful creation! I have a question about when we create an order using: `exchange.createOrder(...)`. ``` async function _createOrder() { var exchange = new ccxt.binance(); const params = {}; const response = await exchange.createOrder(""BTC/USDT"", ""limit"", ""buy"", 0.01, 56200, params); console.log(response); } ``` We receive a **response** with a format that look like this when everything works: ``` { id: '60s8asdfsafask3453lk345lj3l', symbol: 'BTC/USDT', amount: '0.01', etc... } ``` I am in the process of implementing scenarios of what could happen which leads me to this question. I have tried the code above perheps 20 times while implementing code. What I wonder is if there is a scenario where we **Do Not** get a response from: `exchange.createOrder` with any information about what has happened. 1. For example can response be completely empty with No information at all like an EMPTY string? 2. For example let us assume that the internet connection goes down 1 millisecond after the: `exchange.createOrder` has been executed and the internet connection works again after 1 hour. What happens here in the response? 3. Perheps I am looking for all other possible responses which can come out from this except a successful response? I beleive question 1. is one which I wonder about much. I am not sure if I have described the question well enough, but perheps the id챕a of what I wonder about can be seen. Thank you! "
286741,286741,318880,https://api.github.com/repos/invoiceninja/dockerfiles/issues/296,2.0,2021-03-15T16:35:03Z,NONE,https://api.github.com/repos/invoiceninja/dockerfiles,[Question] Still need cron container in v5?,"I'm trying to upgrade from v4 to v5.

In v4 there was a dedicated [""cron"" container](https://github.com/invoiceninja/dockerfiles/blob/4.5.17/docker-compose/docker-compose.yml#L54).

In the v5 examples that no longer exists. However [the docs](https://invoice-ninja.readthedocs.io/en/latest/configure.html#recurring-invoices-and-reminder-emails) still mention the need for this.

Should I still be using a cron container in v5, or are the docs outdated?","[Question] Still need cron container in v5? I'm trying to upgrade from v4 to v5. In v4 there was a dedicated [""cron"" container](https://github.com/invoiceninja/dockerfiles/blob/4.5.17/docker-compose/docker-compose.yml#L54). In the v5 examples that no longer exists. However [the docs](https://invoice-ninja.readthedocs.io/en/latest/configure.html#recurring-invoices-and-reminder-emails) still mention the need for this. Should I still be using a cron container in v5, or are the docs outdated?"
699133,699133,777030,https://api.github.com/repos/CCALI/a2jauthor/issues/169,0.0,2021-04-05T15:11:38Z,CONTRIBUTOR,https://api.github.com/repos/CCALI/a2jauthor,URL WCAG icon isn't in consistent spot for MI interview,"Partner reported new icon for hyperlinks isn't consistently placed in their interview text. 

![image](https://user-images.githubusercontent.com/7662028/113589276-c97f7900-95f6-11eb-8a5b-002229f8c1b0.png)

I can't replicate in a new GI or in an existing GI with a hyperlink, but my existing GI only had one. I had to add a new hyperlink to it to replicate the 2 hyperlinks in the partner GI. 

You can see the partner GI issue on the first page of their interview. 
[CDC Eviction Moratorium Declaration.zip](https://github.com/CCALI/a2jauthor/files/6258835/CDC.Eviction.Moratorium.Declaration.zip)


Initially, the icon for hyperlinks wasn't displaying for their second hyperlink, but I had the author delete it and re-link it. Then the icon appeared, but it's in front of the link, instead of after it like expected. 

![image](https://user-images.githubusercontent.com/7662028/113589691-4b6fa200-95f7-11eb-9d43-10c970b618b1.png)

@AnubhavDhingra and @mikemitchel can you please look at the MI interview and see if you can see why their experience is different than expected?","URL WCAG icon isn't in consistent spot for MI interview Partner reported new icon for hyperlinks isn't consistently placed in their interview text. ![image](https://user-images.githubusercontent.com/7662028/113589276-c97f7900-95f6-11eb-8a5b-002229f8c1b0.png) I can't replicate in a new GI or in an existing GI with a hyperlink, but my existing GI only had one. I had to add a new hyperlink to it to replicate the 2 hyperlinks in the partner GI. You can see the partner GI issue on the first page of their interview. [CDC Eviction Moratorium Declaration.zip](https://github.com/CCALI/a2jauthor/files/6258835/CDC.Eviction.Moratorium.Declaration.zip) Initially, the icon for hyperlinks wasn't displaying for their second hyperlink, but I had the author delete it and re-link it. Then the icon appeared, but it's in front of the link, instead of after it like expected. ![image](https://user-images.githubusercontent.com/7662028/113589691-4b6fa200-95f7-11eb-9d43-10c970b618b1.png) @AnubhavDhingra and @mikemitchel can you please look at the MI interview and see if you can see why their experience is different than expected?"
358044,358044,398038,https://api.github.com/repos/ISAAKiel/mortAAR/issues/59,0.0,2021-01-10T18:48:56Z,MEMBER,https://api.github.com/repos/ISAAKiel/mortAAR,"lapply(life_table, lt.function) falls back on default values","Unfortunately, the strategy to cater at the same time for mortaar_life_tables as well as mortaar_life_table_lists does not seem to work properly. In the case of mortaar_life_table_lists, the code snippet `lapply(x, lt.function)` falls back on default values, any custom values are ignored. Therefore, the task is to pipe custom values through the function `lt.function.mortaar_life_table_list`.","lapply(life_table, lt.function) falls back on default values Unfortunately, the strategy to cater at the same time for mortaar_life_tables as well as mortaar_life_table_lists does not seem to work properly. In the case of mortaar_life_table_lists, the code snippet `lapply(x, lt.function)` falls back on default values, any custom values are ignored. Therefore, the task is to pipe custom values through the function `lt.function.mortaar_life_table_list`."
201649,201649,224207,https://api.github.com/repos/shift-hyperloop/Software2021/issues/27,1.0,2021-02-09T17:49:02Z,CONTRIBUTOR,https://api.github.com/repos/shift-hyperloop/Software2021,Make visualizer responsive (scalable),,Make visualizer responsive (scalable) 
572570,572570,636296,https://api.github.com/repos/ghga-de/datameta/issues/13,1.0,2021-02-13T17:44:54Z,COLLABORATOR,https://api.github.com/repos/ghga-de/datameta,Support non-Excel formats,"Extend sample sheet reading to support CSV and TSV, autodetect format if possible (German vs English CSV etc).","Support non-Excel formats Extend sample sheet reading to support CSV and TSV, autodetect format if possible (German vs English CSV etc)."
643654,643654,715404,https://api.github.com/repos/Spine-project/SpineOpt.jl/issues/345,0.0,2021-03-29T06:42:49Z,COLLABORATOR,https://api.github.com/repos/Spine-project/SpineOpt.jl,`connection_flow` or `connection_intact_flow`?,"I have been tricked multiple times by this. It seems that if no investments, `connection_flow` has no actual meaning, and one needs to look at `connection_intact_flow`?

Another related question is, connection investments only work for the PTDF model? That is, one cannot study investments in connections using the 'normal' transport flow model?","`connection_flow` or `connection_intact_flow`? I have been tricked multiple times by this. It seems that if no investments, `connection_flow` has no actual meaning, and one needs to look at `connection_intact_flow`? Another related question is, connection investments only work for the PTDF model? That is, one cannot study investments in connections using the 'normal' transport flow model?"
328806,328806,365530,https://api.github.com/repos/surveyjs/survey-library/issues/2726,1.0,2021-03-21T10:22:59Z,MEMBER,https://api.github.com/repos/surveyjs/survey-library,Trim strings on comparing question value and question correctValue,"We do not trim value on comparing the question `value` and `correctValue` propertiy It makes sense to trim string value, before comparing them.","Trim strings on comparing question value and question correctValue We do not trim value on comparing the question `value` and `correctValue` propertiy It makes sense to trim string value, before comparing them."
382644,382644,425361,https://api.github.com/repos/ChildMindInstitute/mindlogger-app/issues/1551,0.0,2021-02-16T10:15:54Z,NONE,https://api.github.com/repos/ChildMindInstitute/mindlogger-app,The additional question mark icon is shown in the tapped state,"**Steps to reproduce:**
1. Log in to the admin panel https://admin-staging.mindlogger.org/ (bughunterqa123@gmail.com // 123456)
2. Go to the applet builder and create an applet with radio/checkbox items and specifying the tooltip option description with long text
3. Log in to the app
4. Open the activity and tap on the question mark
5. Look at the result

**Actual result:**  The Additional question mark icon is shown in the tapped state
![2021-02-16_12-08-36.png](https://images.zenhubusercontent.com/5e59389dceb759b87367c8cb/9d74576d-50cc-4f69-9c36-3bff0d80af84)
**Expected result**: The Additional question mark icon is shown in the tapped state
**Environment:**
Staging
Pixel 4XL//Android 11
ML v 0.14. 80",The additional question mark icon is shown in the tapped state **Steps to reproduce:** 1. Log in to the admin panel https://admin-staging.mindlogger.org/ (bughunterqa123@gmail.com // 123456) 2. Go to the applet builder and create an applet with radio/checkbox items and specifying the tooltip option description with long text 3. Log in to the app 4. Open the activity and tap on the question mark 5. Look at the result **Actual result:** The Additional question mark icon is shown in the tapped state ![2021-02-16_12-08-36.png](https://images.zenhubusercontent.com/5e59389dceb759b87367c8cb/9d74576d-50cc-4f69-9c36-3bff0d80af84) **Expected result**: The Additional question mark icon is shown in the tapped state **Environment:** Staging Pixel 4XL//Android 11 ML v 0.14. 80
393403,393403,437270,https://api.github.com/repos/usdigitalresponse/npi-lawyer-client-matching/issues/63,1.0,2021-05-10T20:41:28Z,COLLABORATOR,https://api.github.com/repos/usdigitalresponse/npi-lawyer-client-matching,Use list of attorneys from Airtable instead of Google sheet (or combine the two),,Use list of attorneys from Airtable instead of Google sheet (or combine the two) 
672800,672800,747757,https://api.github.com/repos/nystudio107/craft-retour/issues/170,0.0,2021-04-11T09:44:41Z,NONE,https://api.github.com/repos/nystudio107/craft-retour,Issue when trying to composer install on shared hosting that still runs on Composer 1.10.0,"### Describe the bug
Getting the following error when trying to deploy on a shared hosting that still runs on Composer 1.10.0 (unfortunately I can't change the version as it is a shared hosting)
Locally my server is running composer 2.0 and runs fine.

``` 
Your requirements could not be resolved to an installable set of packages.

    Problem 1
      - Installation request for jean85/pretty-package-versions 2.0.3 -> satisfiable by jean85/pretty-package-versions[2.0.3].
      - jean85/pretty-package-versions 2.0.3 requires composer-runtime-api ^2.0.0 -> no matching package found.
    Problem 2
      - jean85/pretty-package-versions 2.0.3 requires composer-runtime-api ^2.0.0 -> no matching package found.
      - nystudio107/craft-retour 3.1.52 requires jean85/pretty-package-versions ^1.5 || ^2.0 -> satisfiable by jean85/pretty-package-versions[2.0.3].
      - Installation request for nystudio107/craft-retour 3.1.52 -> satisfiable by nystudio107/craft-retour[3.1.52].
```

### To reproduce
Steps to reproduce the behaviour:
1. Install / select composer 1.10.0
2. composer require / install the latest nystudio107/craft-retour package
3. See error message from above

### Versions
- Plugin version: 3.1.52
- Craft version: 3.6.11.2
",Issue when trying to composer install on shared hosting that still runs on Composer 1.10.0 ### Describe the bug Getting the following error when trying to deploy on a shared hosting that still runs on Composer 1.10.0 (unfortunately I can't change the version as it is a shared hosting) Locally my server is running composer 2.0 and runs fine. ``` Your requirements could not be resolved to an installable set of packages. Problem 1 - Installation request for jean85/pretty-package-versions 2.0.3 -> satisfiable by jean85/pretty-package-versions[2.0.3]. - jean85/pretty-package-versions 2.0.3 requires composer-runtime-api ^2.0.0 -> no matching package found. Problem 2 - jean85/pretty-package-versions 2.0.3 requires composer-runtime-api ^2.0.0 -> no matching package found. - nystudio107/craft-retour 3.1.52 requires jean85/pretty-package-versions ^1.5 || ^2.0 -> satisfiable by jean85/pretty-package-versions[2.0.3]. - Installation request for nystudio107/craft-retour 3.1.52 -> satisfiable by nystudio107/craft-retour[3.1.52]. ``` ### To reproduce Steps to reproduce the behaviour: 1. Install / select composer 1.10.0 2. composer require / install the latest nystudio107/craft-retour package 3. See error message from above ### Versions - Plugin version: 3.1.52 - Craft version: 3.6.11.2 
490403,490403,545038,https://api.github.com/repos/cube-js/cube.js/issues/1794,2.0,2021-01-15T17:49:30Z,NONE,https://api.github.com/repos/cube-js/cube.js,Access USER_CONTEXT in asyncModule,"**I need to load the schemas dynamically based on the current tenant (this data is in the `req.authInfo` object)**

Ex: For a tenant 1 I need to load schemas A and B, for a tenant 2 I need to load schemas C and D.
Ideally, I could have access to `USER_CONTEXT` within the callback function of `asyncModule`.

Do you have any idea how this can be resolved?

The code below demonstrates the way I thought about implementing. This code does not work because I made the callback function of asyncModule receive context, which would be the request context. I also hid the generateSchema function.

```
const fetch = require('node-fetch');
const { BASE_URL } = require('../config/envVariables');

asyncModule(async (context) => {

  const currentApp = context.authInfo.appId;

  const response = await fetch(`${BASE_URL}/schemas`);
  const schemas = await response.json();
  const filteredSchemas = schemas.filter(currentSchema => currentSchema.appId === currentApp);

  filteredSchemas.forEach((schema) => {
       generateSchema(schema);
  });
  
  function generateSchema(schema) {
      ...
  }
});
```","Access USER_CONTEXT in asyncModule **I need to load the schemas dynamically based on the current tenant (this data is in the `req.authInfo` object)** Ex: For a tenant 1 I need to load schemas A and B, for a tenant 2 I need to load schemas C and D. Ideally, I could have access to `USER_CONTEXT` within the callback function of `asyncModule`. Do you have any idea how this can be resolved? The code below demonstrates the way I thought about implementing. This code does not work because I made the callback function of asyncModule receive context, which would be the request context. I also hid the generateSchema function. ``` const fetch = require('node-fetch'); const { BASE_URL } = require('../config/envVariables'); asyncModule(async (context) => { const currentApp = context.authInfo.appId; const response = await fetch(`${BASE_URL}/schemas`); const schemas = await response.json(); const filteredSchemas = schemas.filter(currentSchema => currentSchema.appId === currentApp); filteredSchemas.forEach((schema) => { generateSchema(schema); }); function generateSchema(schema) { ... } }); ```"
781129,781129,581070,https://api.github.com/repos/gfranco19/finalProject/issues/65,1.0,2021-01-19T05:44:07Z,COLLABORATOR,https://api.github.com/repos/gfranco19/finalProject,Refactor Upload Page to Generate Google User images,"Working on backend to fix the user login to google login and pull user images to explorer page that cannot be edited. 
On Account page User will be able to edit their images accordingly and only see their images posted. 

Schema will include Google credentials, and AuthID to be able to generate to account and explorer. 
Explorer page will see ALL posts from ALL users. 

Shay will work around front when back end is fully functional. ","Refactor Upload Page to Generate Google User images Working on backend to fix the user login to google login and pull user images to explorer page that cannot be edited. On Account page User will be able to edit their images accordingly and only see their images posted. Schema will include Google credentials, and AuthID to be able to generate to account and explorer. Explorer page will see ALL posts from ALL users. Shay will work around front when back end is fully functional. "
581204,581204,645853,https://api.github.com/repos/WWBN/AVideo/issues/4198,2.0,2020-12-18T10:58:27Z,NONE,https://api.github.com/repos/WWBN/AVideo,"RE User Steps on How To Setup The ""LIVE"" and the ""Live Link"" sections on YouPHPTube","Dear Daniel,

Are there now any clear steps on how to setup the ""Live"" section of YouPHPTube? Once we tried (see old case: Chat and Webcam Issues #3087) but we never really got anywhere as then you said it was ""experimental"".

However, we would now like to try again especially given this COVVID stuff as getting this section working would be helpful.

The areas of concern are simply clear directives as to what many of the settings are actually referring to  for instance  under the ""Devices Stream Info"" what exactly is the application to have as input under things like ""Server URL"" are you talking about the external media server or are you talking about the local server. For instance we have an ""external"" server that runs ffmpeg and streams media but if I recall the server on which YouPHPTube is running on also has ffmpeg. so which do we point to?

Since there is no ""Pop Up"" help when you hover your mouse over where it says ""Server URL"" it is hard to figure out what exactly needs to be placed as input in this field. Same for the other fields on the page .

The same for the parameters on the ""Add a Live Link"" a ""Pop Up"" descriptive guide would help tremendously as not every body is a Media Streaming Guru and they should not need to be to use it, after all you do not need to be a motor mechanic in order to drive a car.thus these parameters could do with a little pop-up descriptive.

We would like to get this section working so that we can atleast use it to stream LIVE so any guidance to make this happen would be appreciated. We do have a separate server that already streams via OBS but for this YouPHPTube we would like to simply use the ""WEBCAM"" to stream visuals and audio and the rtmp server could be our external server so how would we go about doing this using YouPHPTube?

These settings are of concern: Do yo have proper working examples of what should go there and a little explanation?
=================
Player URL:
Live URL:
Server URL:
Stream name/key:
==================

Aslo on the l""Live Stuff"" under ""CONTENT in the Admin Panel 
what goes in these fields below thus what is referred to as the ""PlayerServer"" woudl that be YouPHPTube server or our external server that already streams content that we can use as an rtmp server? Or is that even our desktop where the Webcam is located? Then what shoudl go in the ""SERVER"" section? The YouPHPTube server ? Also what ""FORMAT"" shoudl the entry into the field be for instance rtmp://MyYOuPHPTubeServer/live or http://MyYOuPHPTubeServer/live etc. etc. All these thigns need some pop up help or info.
-------------
SERVER
PLAYERSERVER

When you click the red ""LIVE"" button nothing happens even though we have a webcam on our PC so how do we get the server YOuPHPTube to recognize our webcam and to actually stream form it?
 All these steps do need guidance so if you could help that would be appreciated:



Thanks
Lusjames/Fuquan
[](url)
","RE User Steps on How To Setup The ""LIVE"" and the ""Live Link"" sections on YouPHPTube Dear Daniel, Are there now any clear steps on how to setup the ""Live"" section of YouPHPTube? Once we tried (see old case: Chat and Webcam Issues #3087) but we never really got anywhere as then you said it was ""experimental"". However, we would now like to try again especially given this COVVID stuff as getting this section working would be helpful. The areas of concern are simply clear directives as to what many of the settings are actually referring to for instance under the ""Devices Stream Info"" what exactly is the application to have as input under things like ""Server URL"" are you talking about the external media server or are you talking about the local server. For instance we have an ""external"" server that runs ffmpeg and streams media but if I recall the server on which YouPHPTube is running on also has ffmpeg. so which do we point to? Since there is no ""Pop Up"" help when you hover your mouse over where it says ""Server URL"" it is hard to figure out what exactly needs to be placed as input in this field. Same for the other fields on the page . The same for the parameters on the ""Add a Live Link"" a ""Pop Up"" descriptive guide would help tremendously as not every body is a Media Streaming Guru and they should not need to be to use it, after all you do not need to be a motor mechanic in order to drive a car.thus these parameters could do with a little pop-up descriptive. We would like to get this section working so that we can atleast use it to stream LIVE so any guidance to make this happen would be appreciated. We do have a separate server that already streams via OBS but for this YouPHPTube we would like to simply use the ""WEBCAM"" to stream visuals and audio and the rtmp server could be our external server so how would we go about doing this using YouPHPTube? These settings are of concern: Do yo have proper working examples of what should go there and a little explanation? ================= Player URL: Live URL: Server URL: Stream name/key: ================== Aslo on the l""Live Stuff"" under ""CONTENT in the Admin Panel what goes in these fields below thus what is referred to as the ""PlayerServer"" woudl that be YouPHPTube server or our external server that already streams content that we can use as an rtmp server? Or is that even our desktop where the Webcam is located? Then what shoudl go in the ""SERVER"" section? The YouPHPTube server ? Also what ""FORMAT"" shoudl the entry into the field be for instance rtmp://MyYOuPHPTubeServer/live or http://MyYOuPHPTubeServer/live etc. etc. All these thigns need some pop up help or info. ------------- SERVER PLAYERSERVER When you click the red ""LIVE"" button nothing happens even though we have a webcam on our PC so how do we get the server YOuPHPTube to recognize our webcam and to actually stream form it? All these steps do need guidance so if you could help that would be appreciated: Thanks Lusjames/Fuquan [](url) "
708972,708972,787958,https://api.github.com/repos/alexmercerind/youtube-search-python/issues/70,0.0,2021-04-22T08:40:16Z,NONE,https://api.github.com/repos/alexmercerind/youtube-search-python,descriptionSnippet returns None,"Search results return None for descriptionSnippet fields for any type of search query. Tried the example searches and Harry Styles custom search too.
Is this an issue related to not using YouTube API v3 ?",descriptionSnippet returns None Search results return None for descriptionSnippet fields for any type of search query. Tried the example searches and Harry Styles custom search too. Is this an issue related to not using YouTube API v3 ?
190631,190631,212006,https://api.github.com/repos/Checkmarx/kics/issues/1810,1.0,2021-01-20T13:40:10Z,CONTRIBUTOR,https://api.github.com/repos/Checkmarx/kics,Fix formatting for all terraform and ansible queries,"### Platform
*Terraform, Ansible*

### Provider
*All*

### Description
*Run `opa fmt --write` for all terraform and ansible rego files*","Fix formatting for all terraform and ansible queries ### Platform *Terraform, Ansible* ### Provider *All* ### Description *Run `opa fmt --write` for all terraform and ansible rego files*"
246128,246128,273754,https://api.github.com/repos/nlnwa/gowarcserver/issues/11,0.0,2021-03-01T11:44:29Z,CONTRIBUTOR,https://api.github.com/repos/nlnwa/gowarcserver,Bug: indexing with cdxj causes a panic,"**Describe the bug**
gowarcserver panics when i try to index ``testdata/IAH-20080430204825-00000-blackbook.warc`` 

**To Reproduce**
Steps to reproduce the behavior:
1. checkout branch in pr #3 (badger-control in fork)
2.  run gowarcserver index with ``-f cdxj`` i.e ``./warcserver index -f cdxj ./testdata/IAH-20080430204825-00000-blackbook.warc``

**Expected behavior**
gowarcserver should index the files or report a user error to the terminal.

**Additional context**
```bash
[akselhjerpbakk@localhost gowarcserver]$ ./warcserver index -f cdxj ./testdata/IAH-20080430204825-00000-blackbook.warc 
Using config file: /home/akselhjerpbakk/Projects/warcproject/gowarcserver/config.yaml
Format: cdxj
Count:  2
panic: runtime error: invalid memory address or nil pointer dereference
[signal SIGSEGV: segmentation violation code=0x1 addr=0x10 pc=0x91749c]

goroutine 1 [running]:
github.com/golang/protobuf/jsonpb.(*jsonWriter).marshalMessage(0xc0001c9aa0, 0xcd9ba0, 0xc0001d4a00, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0)
        /home/akselhjerpbakk/go/pkg/mod/github.com/golang/protobuf@v1.4.0-rc.4/jsonpb/encode.go:219 +0x73c
github.com/golang/protobuf/jsonpb.(*Marshaler).marshal(0x0, 0xccfca0, 0xc0001d4a00, 0x32, 0x2e2, 0xc0001d4a00, 0xc000330040, 0x0)
        /home/akselhjerpbakk/go/pkg/mod/github.com/golang/protobuf@v1.4.0-rc.4/jsonpb/encode.go:116 +0x207
github.com/golang/protobuf/jsonpb.(*Marshaler).MarshalToString(...)
        /home/akselhjerpbakk/go/pkg/mod/github.com/golang/protobuf@v1.4.0-rc.4/jsonpb/encode.go:78
github.com/nlnwa/gowarcserver/pkg/index.(*CdxJ).Write(0xc000010268, 0xcd4920, 0xc00007cd40, 0x7ffee18cb20a, 0x32, 0x2e2, 0x0, 0x0)
        /home/akselhjerpbakk/Projects/warcproject/gowarcserver/pkg/index/indexwriter.go:74 +0xe6
github.com/nlnwa/gowarcserver/cmd/warcserver/cmd/index.readFile(0xc0001dc5a0, 0x0, 0x0)
        /home/akselhjerpbakk/Projects/warcproject/gowarcserver/cmd/warcserver/cmd/index/index.go:120 +0x15f
github.com/nlnwa/gowarcserver/cmd/warcserver/cmd/index.runE(0xc0001dc5a0, 0x0, 0x0)
        /home/akselhjerpbakk/Projects/warcproject/gowarcserver/cmd/warcserver/cmd/index/index.go:92 +0xf0
github.com/nlnwa/gowarcserver/cmd/warcserver/cmd/index.NewCommand.func2(0xc0001d3400, 0xc0001dc780, 0x1, 0x3, 0x0, 0x0)
        /home/akselhjerpbakk/Projects/warcproject/gowarcserver/cmd/warcserver/cmd/index/index.go:79 +0xba
github.com/spf13/cobra.(*Command).execute(0xc0001d3400, 0xc0001dc6f0, 0x3, 0x3, 0xc0001d3400, 0xc0001dc6f0)
        /home/akselhjerpbakk/go/pkg/mod/github.com/spf13/cobra@v0.0.5/command.go:826 +0x47c
github.com/spf13/cobra.(*Command).ExecuteC(0xc0001d2f00, 0xc000000180, 0xc0001c9f78, 0x4118e5)
        /home/akselhjerpbakk/go/pkg/mod/github.com/spf13/cobra@v0.0.5/command.go:914 +0x30b
github.com/spf13/cobra.(*Command).Execute(...)
        /home/akselhjerpbakk/go/pkg/mod/github.com/spf13/cobra@v0.0.5/command.go:864
main.main()
        /home/akselhjerpbakk/Projects/warcproject/gowarcserver/cmd/warcserver/main.go:27 +0x2b
```","Bug: indexing with cdxj causes a panic **Describe the bug** gowarcserver panics when i try to index ``testdata/IAH-20080430204825-00000-blackbook.warc`` **To Reproduce** Steps to reproduce the behavior: 1. checkout branch in pr #3 (badger-control in fork) 2. run gowarcserver index with ``-f cdxj`` i.e ``./warcserver index -f cdxj ./testdata/IAH-20080430204825-00000-blackbook.warc`` **Expected behavior** gowarcserver should index the files or report a user error to the terminal. **Additional context** ```bash [akselhjerpbakk@localhost gowarcserver]$ ./warcserver index -f cdxj ./testdata/IAH-20080430204825-00000-blackbook.warc Using config file: /home/akselhjerpbakk/Projects/warcproject/gowarcserver/config.yaml Format: cdxj Count: 2 panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x10 pc=0x91749c] goroutine 1 [running]: github.com/golang/protobuf/jsonpb.(*jsonWriter).marshalMessage(0xc0001c9aa0, 0xcd9ba0, 0xc0001d4a00, 0x0, 0x0, 0x0, 0x0, 0x0, 0x0) /home/akselhjerpbakk/go/pkg/mod/github.com/golang/protobuf@v1.4.0-rc.4/jsonpb/encode.go:219 +0x73c github.com/golang/protobuf/jsonpb.(*Marshaler).marshal(0x0, 0xccfca0, 0xc0001d4a00, 0x32, 0x2e2, 0xc0001d4a00, 0xc000330040, 0x0) /home/akselhjerpbakk/go/pkg/mod/github.com/golang/protobuf@v1.4.0-rc.4/jsonpb/encode.go:116 +0x207 github.com/golang/protobuf/jsonpb.(*Marshaler).MarshalToString(...) /home/akselhjerpbakk/go/pkg/mod/github.com/golang/protobuf@v1.4.0-rc.4/jsonpb/encode.go:78 github.com/nlnwa/gowarcserver/pkg/index.(*CdxJ).Write(0xc000010268, 0xcd4920, 0xc00007cd40, 0x7ffee18cb20a, 0x32, 0x2e2, 0x0, 0x0) /home/akselhjerpbakk/Projects/warcproject/gowarcserver/pkg/index/indexwriter.go:74 +0xe6 github.com/nlnwa/gowarcserver/cmd/warcserver/cmd/index.readFile(0xc0001dc5a0, 0x0, 0x0) /home/akselhjerpbakk/Projects/warcproject/gowarcserver/cmd/warcserver/cmd/index/index.go:120 +0x15f github.com/nlnwa/gowarcserver/cmd/warcserver/cmd/index.runE(0xc0001dc5a0, 0x0, 0x0) /home/akselhjerpbakk/Projects/warcproject/gowarcserver/cmd/warcserver/cmd/index/index.go:92 +0xf0 github.com/nlnwa/gowarcserver/cmd/warcserver/cmd/index.NewCommand.func2(0xc0001d3400, 0xc0001dc780, 0x1, 0x3, 0x0, 0x0) /home/akselhjerpbakk/Projects/warcproject/gowarcserver/cmd/warcserver/cmd/index/index.go:79 +0xba github.com/spf13/cobra.(*Command).execute(0xc0001d3400, 0xc0001dc6f0, 0x3, 0x3, 0xc0001d3400, 0xc0001dc6f0) /home/akselhjerpbakk/go/pkg/mod/github.com/spf13/cobra@v0.0.5/command.go:826 +0x47c github.com/spf13/cobra.(*Command).ExecuteC(0xc0001d2f00, 0xc000000180, 0xc0001c9f78, 0x4118e5) /home/akselhjerpbakk/go/pkg/mod/github.com/spf13/cobra@v0.0.5/command.go:914 +0x30b github.com/spf13/cobra.(*Command).Execute(...) /home/akselhjerpbakk/go/pkg/mod/github.com/spf13/cobra@v0.0.5/command.go:864 main.main() /home/akselhjerpbakk/Projects/warcproject/gowarcserver/cmd/warcserver/main.go:27 +0x2b ```"
288237,288237,320533,https://api.github.com/repos/AutomatedCX/automatedcx-api/issues/35,0.0,2021-04-21T20:12:49Z,COLLABORATOR,https://api.github.com/repos/AutomatedCX/automatedcx-api,Fix chatbot response on dialog flow,"**Currently**
---------------

Nothing is answered when the natura intent gets triggered.

**Expected**
----------------

- Use ngrok to simulate production flow
- Apply the fix

**References**
--------------------

- Messenger conversation",Fix chatbot response on dialog flow **Currently** --------------- Nothing is answered when the natura intent gets triggered. **Expected** ---------------- - Use ngrok to simulate production flow - Apply the fix **References** -------------------- - Messenger conversation
61781,61781,68670,https://api.github.com/repos/nextcloud/mail/issues/4514,0.0,2021-02-12T05:10:06Z,NONE,https://api.github.com/repos/nextcloud/mail,Could not load message.,"## Steps to reproduce
1. Host hydroxide (proton OSS bridge) on same host
2. Configure Mail to use Proton Bridge
3. Use it and most of the time there are time outs + general slowness. Works sometimes though

## Expected behaviour
Tell us what should happen

## Actual behaviour
Tell us what happens instead

## Error
```
OCA\Mail\Exception\ServiceException: Could not load message
  at OCA\Mail\Service\MailManager::getMessage
     /var/www/html/custom_apps/mail/lib/Controller/MessagesController.php, line 219
  at OCA\Mail\Controller\MessagesController::getBody
     /var/www/html/lib/private/AppFramework/Http/Dispatcher.php, line 170
  at OC\AppFramework\Http\Dispatcher::executeController
     /var/www/html/lib/private/AppFramework/Http/Dispatcher.php, line 100
  at OC\AppFramework\Http\Dispatcher::dispatch
     /var/www/html/lib/private/AppFramework/App.php, line 137
  at OC\AppFramework\App::main
     /var/www/html/lib/private/AppFramework/Routing/RouteActionHandler.php, line 47
  at OC\AppFramework\Routing\RouteActionHandler::__invoke
  at call_user_func
     /var/www/html/lib/private/Route/Router.php, line 297
  at OC\Route\Router::match
     /var/www/html/lib/base.php, line 1011
  at OC::handleRequest
     /var/www/html/index.php, line 37

```","Could not load message. ## Steps to reproduce 1. Host hydroxide (proton OSS bridge) on same host 2. Configure Mail to use Proton Bridge 3. Use it and most of the time there are time outs + general slowness. Works sometimes though ## Expected behaviour Tell us what should happen ## Actual behaviour Tell us what happens instead ## Error ``` OCA\Mail\Exception\ServiceException: Could not load message at OCA\Mail\Service\MailManager::getMessage /var/www/html/custom_apps/mail/lib/Controller/MessagesController.php, line 219 at OCA\Mail\Controller\MessagesController::getBody /var/www/html/lib/private/AppFramework/Http/Dispatcher.php, line 170 at OC\AppFramework\Http\Dispatcher::executeController /var/www/html/lib/private/AppFramework/Http/Dispatcher.php, line 100 at OC\AppFramework\Http\Dispatcher::dispatch /var/www/html/lib/private/AppFramework/App.php, line 137 at OC\AppFramework\App::main /var/www/html/lib/private/AppFramework/Routing/RouteActionHandler.php, line 47 at OC\AppFramework\Routing\RouteActionHandler::__invoke at call_user_func /var/www/html/lib/private/Route/Router.php, line 297 at OC\Route\Router::match /var/www/html/lib/base.php, line 1011 at OC::handleRequest /var/www/html/index.php, line 37 ```"
596266,596266,662639,https://api.github.com/repos/godotengine/godot/issues/36714,0.0,2020-03-01T21:32:32Z,NONE,https://api.github.com/repos/godotengine/godot,Disabling Script Editor disables opening scripts in External Editor,"**Godot version:** 3.2

**OS/device including version:** Win10

**Issue description:**
Disabling Script Editor in the ""Manage Editor Features..."" makes it so that the external editor (at least VSCode for me) doesn't work. Which is kinda funny since otherwise you probably don't wanna disable it?

Meaning, it doesn't open anymore when:
- opening Godot
- try to open scripts for almost anywhere in the editor

**Steps to reproduce:**
1. Use a external editor (only tested with VSCode).
2. Disable the Script Editor using Editor -> Manage Editor Features... -> Uncheck Script Editor
3. Try to open any script...
","Disabling Script Editor disables opening scripts in External Editor **Godot version:** 3.2 **OS/device including version:** Win10 **Issue description:** Disabling Script Editor in the ""Manage Editor Features..."" makes it so that the external editor (at least VSCode for me) doesn't work. Which is kinda funny since otherwise you probably don't wanna disable it? Meaning, it doesn't open anymore when: - opening Godot - try to open scripts for almost anywhere in the editor **Steps to reproduce:** 1. Use a external editor (only tested with VSCode). 2. Disable the Script Editor using Editor -> Manage Editor Features... -> Uncheck Script Editor 3. Try to open any script... "
45079,45079,50184,https://api.github.com/repos/damienbod/angular-auth-oidc-client/issues/1001,2.0,2021-03-05T09:50:48Z,NONE,https://api.github.com/repos/damienbod/angular-auth-oidc-client,Manual renew refresh token/ silent renew:false is not working,"Hi All,
       I would like to achieve the below scenario. 
**STS Config (using Identity server4)**
```

new Client
            {
                ClientId = ""clientangular"",
                ClientName = ""Angular Client"",
                AllowedGrantTypes = GrantTypes.Code,
                RequireClientSecret = false,
                AllowedScopes = new List<string>
                {
                    IdentityServerConstants.StandardScopes.OpenId,
                    IdentityServerConstants.StandardScopes.Profile,
                    ""api1"",
                    ""roles""
                },

                
                RedirectUris = new List<string> { ""http://localhost:4200"" },
                PostLogoutRedirectUris = new List<string> {""http://localhost:4200"" },
                AllowedCorsOrigins = new List<string> { ""http://localhost:4200"" },

                
                RequireConsent= false,
                RequirePkce = true,
                AllowAccessTokensViaBrowser = true,
                AccessTokenLifetime = 60,  
                AllowOfflineAccess = true,
                //AbsoluteRefreshTokenLifetime = 21600, //6hrs
                

                RefreshTokenExpiration = TokenExpiration.Sliding,   //once refresh token issued then renew the timing of token expiration
                UpdateAccessTokenClaimsOnRefresh = true
            }
```

**Client Side (Angular)**

```
oidcConfigService.withConfig({
      stsServer: 'https://localhost:5001',
      redirectUrl: window.location.origin,
      
      clientId: 'clientangular',
      scope: 'openid profile api1 offline_access',
      responseType: 'code',
      triggerAuthorizationResultEvent: true,
      postLogoutRedirectUri: `${window.location.origin}/unauthorized`,
      
      renewTimeBeforeTokenExpiresInSeconds: 5,
      silentRenew: false,
      
      logLevel: LogLevel.Debug,
      historyCleanupOff: true,
      
    });

```
**Issues**
1) I keep Silent renew as **false**  but it is still calling the  refresh token silently while accessing the API. How to avoid/stop calling refresh token silently?
 

From Angular I want to achieve the below

1) Want to check the access_token is expired or not?
2) Call refreshToken manually , is it correct? But I am getting issue, the error details are attached
                         this.oidcSecurityService.forceRefreshSession().subscribe((result) => console.log(result));
![image](https://user-images.githubusercontent.com/45000952/110098368-10513780-7ddb-11eb-8027-ee6d6a03afa0.png)
","Manual renew refresh token/ silent renew:false is not working Hi All, I would like to achieve the below scenario. **STS Config (using Identity server4)** ``` new Client { ClientId = ""clientangular"", ClientName = ""Angular Client"", AllowedGrantTypes = GrantTypes.Code, RequireClientSecret = false, AllowedScopes = new List<string> { IdentityServerConstants.StandardScopes.OpenId, IdentityServerConstants.StandardScopes.Profile, ""api1"", ""roles"" }, RedirectUris = new List<string> { ""http://localhost:4200"" }, PostLogoutRedirectUris = new List<string> {""http://localhost:4200"" }, AllowedCorsOrigins = new List<string> { ""http://localhost:4200"" }, RequireConsent= false, RequirePkce = true, AllowAccessTokensViaBrowser = true, AccessTokenLifetime = 60, AllowOfflineAccess = true, //AbsoluteRefreshTokenLifetime = 21600, //6hrs RefreshTokenExpiration = TokenExpiration.Sliding, //once refresh token issued then renew the timing of token expiration UpdateAccessTokenClaimsOnRefresh = true } ``` **Client Side (Angular)** ``` oidcConfigService.withConfig({ stsServer: 'https://localhost:5001', redirectUrl: window.location.origin, clientId: 'clientangular', scope: 'openid profile api1 offline_access', responseType: 'code', triggerAuthorizationResultEvent: true, postLogoutRedirectUri: `${window.location.origin}/unauthorized`, renewTimeBeforeTokenExpiresInSeconds: 5, silentRenew: false, logLevel: LogLevel.Debug, historyCleanupOff: true, }); ``` **Issues** 1) I keep Silent renew as **false** but it is still calling the refresh token silently while accessing the API. How to avoid/stop calling refresh token silently? From Angular I want to achieve the below 1) Want to check the access_token is expired or not? 2) Call refreshToken manually , is it correct? But I am getting issue, the error details are attached this.oidcSecurityService.forceRefreshSession().subscribe((result) => console.log(result)); ![image](https://user-images.githubusercontent.com/45000952/110098368-10513780-7ddb-11eb-8027-ee6d6a03afa0.png) "
374141,374141,415910,https://api.github.com/repos/ditrit/gandalf/issues/136,1.0,2021-02-19T09:44:32Z,CONTRIBUTOR,https://api.github.com/repos/ditrit/gandalf,Create API controller CLI,,Create API controller CLI 
212963,212963,236811,https://api.github.com/repos/highlightjs/highlight.js/issues/3023,0.0,2021-02-27T15:08:36Z,NONE,https://api.github.com/repos/highlightjs/highlight.js,(php) having an extra php class,"**Describe the issue**
When I add the ""language-php"" class to the code element, the coloring is okay, but it adds an extra php tag. If I don't give a class, it adds the php class and there is no problem.

**Which language seems to have the issue?**
Only php, i haven't seen such problem in other languages

**Are you using `highlight` or `highlightAuto`?**
highlightAll

**Sample Code to Reproduce**
You can take a look at the php block. Other languages seem to be fine.
![Xd](https://user-images.githubusercontent.com/52415595/109390969-b7d6f180-7925-11eb-989e-6b1a551897d0.png)

**Expected behavior**
When we add the ""language-php"" class to the code element, it should not add the extra php tag.
","(php) having an extra php class **Describe the issue** When I add the ""language-php"" class to the code element, the coloring is okay, but it adds an extra php tag. If I don't give a class, it adds the php class and there is no problem. **Which language seems to have the issue?** Only php, i haven't seen such problem in other languages **Are you using `highlight` or `highlightAuto`?** highlightAll **Sample Code to Reproduce** You can take a look at the php block. Other languages seem to be fine. ![Xd](https://user-images.githubusercontent.com/52415595/109390969-b7d6f180-7925-11eb-989e-6b1a551897d0.png) **Expected behavior** When we add the ""language-php"" class to the code element, it should not add the extra php tag. "
268175,268175,298239,https://api.github.com/repos/getsentry/sentry-cocoa/issues/937,0.0,2021-02-08T12:26:33Z,NONE,https://api.github.com/repos/getsentry/sentry-cocoa,"Sentry crashes on Launch, trying to serialize a broken session object","### Environment

* How do you use Sentry: Sentry SaaS (sentry.io)
* Which SDK and version: 6.1.4 - macOS

### Steps to Reproduce

* (unknown: app crashes / closed in a weird state - )
* launch app & initialize sentry

### Expected Result

* SDK should not crash the app

### Actual Result

* crashes trying to create Session object from a broken dictionary on disc


----

While we haven't figured out how the broken dictionary lands on disc, we can see the crash happening on app launch.
Here's the relevant backtrace:

```
#5	0x00000001025be812 in -[SentrySession serialize] at /<derived-data-and-app>/SourcePackages/checkouts/sentry-cocoa/Sources/Sentry/SentrySession.m:129
#6	0x000000010259f726 in -[SentryEnvelopeItem initWithSession:] at /<derived-data-and-app>/SourcePackages/checkouts/sentry-cocoa/Sources/Sentry/SentryEnvelope.m:122
#7	0x000000010259fb2a in -[SentryEnvelope initWithSession:] at /<derived-data-and-app>/SourcePackages/checkouts/sentry-cocoa/Sources/Sentry/SentryEnvelope.m:158
#8	0x000000010258fe22 in -[SentryClient captureSession:] at /<derived-data-and-app>/SourcePackages/checkouts/sentry-cocoa/Sources/Sentry/SentryClient.m:258
#9	0x00000001025aafd7 in -[SentryHub closeCachedSessionWithTimestamp:] at /<derived-data-and-app>/SourcePackages/checkouts/sentry-cocoa/Sources/Sentry/SentryHub.m:147
#10	0x00000001025bfc8d in -[SentrySessionTracker endCachedSession] at /<derived-data-and-app>/SourcePackages/checkouts/sentry-cocoa/Sources/Sentry/SentrySessionTracker.m:110
#11	0x00000001025bf979 in -[SentrySessionTracker start] at /<derived-data-and-app>/SourcePackages/checkouts/sentry-cocoa/Sources/Sentry/SentrySessionTracker.m:70
#12	0x000000010258bff5 in -[SentryAutoSessionTrackingIntegration installWithOptions:] at /<derived-data-and-app>/SourcePackages/checkouts/sentry-cocoa/Sources/Sentry/SentryAutoSessionTrackingIntegration.m:27
#13	0x00000001025b646c in +[SentrySDK installIntegrations] at /<derived-data-and-app>/SourcePackages/checkouts/sentry-cocoa/Sources/Sentry/SentrySDK.m:241
#14	0x00000001025b4e0f in +[SentrySDK startWithOptionsObject:] at /<derived-data-and-app>/SourcePackages/checkouts/sentry-cocoa/Sources/Sentry/SentrySDK.m:82
#15	0x00000001025b4eb6 in +[SentrySDK startWithConfigureOptions:] at /<derived-data-and-app>/SourcePackages/checkouts/sentry-cocoa/Sources/Sentry/SentrySDK.m:89
[...]
```

The crash itself is happening in the serialize method:
```
- (NSDictionary<NSString *, id> *)serialize
{
    @synchronized(self) {
        NSMutableDictionary *serializedData = @{
            @""sid"" : _sessionId.UUIDString,
            @""errors"" : @(_errors),
            @""started"" : [_started sentry_toIso8601String],
        }
                                                  .mutableCopy;
```

trying to insert a nil value into the dictionary. `_started` is nil in case of the broken cached Session dictionary on disc.
I haven't dug any deeper, but it feels like the SDK could be more robust in case of broken cached data on disc.  
(We haven't been able to figure out *why* there's the broken dictionary on disc though..).

Is there anything else we can provide? 
Thanks for looking into this!

","Sentry crashes on Launch, trying to serialize a broken session object ### Environment * How do you use Sentry: Sentry SaaS (sentry.io) * Which SDK and version: 6.1.4 - macOS ### Steps to Reproduce * (unknown: app crashes / closed in a weird state - ) * launch app & initialize sentry ### Expected Result * SDK should not crash the app ### Actual Result * crashes trying to create Session object from a broken dictionary on disc ---- While we haven't figured out how the broken dictionary lands on disc, we can see the crash happening on app launch. Here's the relevant backtrace: ``` #5 0x00000001025be812 in -[SentrySession serialize] at /<derived-data-and-app>/SourcePackages/checkouts/sentry-cocoa/Sources/Sentry/SentrySession.m:129 #6 0x000000010259f726 in -[SentryEnvelopeItem initWithSession:] at /<derived-data-and-app>/SourcePackages/checkouts/sentry-cocoa/Sources/Sentry/SentryEnvelope.m:122 #7 0x000000010259fb2a in -[SentryEnvelope initWithSession:] at /<derived-data-and-app>/SourcePackages/checkouts/sentry-cocoa/Sources/Sentry/SentryEnvelope.m:158 #8 0x000000010258fe22 in -[SentryClient captureSession:] at /<derived-data-and-app>/SourcePackages/checkouts/sentry-cocoa/Sources/Sentry/SentryClient.m:258 #9 0x00000001025aafd7 in -[SentryHub closeCachedSessionWithTimestamp:] at /<derived-data-and-app>/SourcePackages/checkouts/sentry-cocoa/Sources/Sentry/SentryHub.m:147 #10 0x00000001025bfc8d in -[SentrySessionTracker endCachedSession] at /<derived-data-and-app>/SourcePackages/checkouts/sentry-cocoa/Sources/Sentry/SentrySessionTracker.m:110 #11 0x00000001025bf979 in -[SentrySessionTracker start] at /<derived-data-and-app>/SourcePackages/checkouts/sentry-cocoa/Sources/Sentry/SentrySessionTracker.m:70 #12 0x000000010258bff5 in -[SentryAutoSessionTrackingIntegration installWithOptions:] at /<derived-data-and-app>/SourcePackages/checkouts/sentry-cocoa/Sources/Sentry/SentryAutoSessionTrackingIntegration.m:27 #13 0x00000001025b646c in +[SentrySDK installIntegrations] at /<derived-data-and-app>/SourcePackages/checkouts/sentry-cocoa/Sources/Sentry/SentrySDK.m:241 #14 0x00000001025b4e0f in +[SentrySDK startWithOptionsObject:] at /<derived-data-and-app>/SourcePackages/checkouts/sentry-cocoa/Sources/Sentry/SentrySDK.m:82 #15 0x00000001025b4eb6 in +[SentrySDK startWithConfigureOptions:] at /<derived-data-and-app>/SourcePackages/checkouts/sentry-cocoa/Sources/Sentry/SentrySDK.m:89 [...] ``` The crash itself is happening in the serialize method: ``` - (NSDictionary<NSString *, id> *)serialize { @synchronized(self) { NSMutableDictionary *serializedData = @{ @""sid"" : _sessionId.UUIDString, @""errors"" : @(_errors), @""started"" : [_started sentry_toIso8601String], } .mutableCopy; ``` trying to insert a nil value into the dictionary. `_started` is nil in case of the broken cached Session dictionary on disc. I haven't dug any deeper, but it feels like the SDK could be more robust in case of broken cached data on disc. (We haven't been able to figure out *why* there's the broken dictionary on disc though..). Is there anything else we can provide? Thanks for looking into this! "
185494,185494,206265,https://api.github.com/repos/theodo/falco/issues/163,1.0,2020-03-31T14:37:23Z,CONTRIBUTOR,https://api.github.com/repos/theodo/falco,No automatic deploy on private instance,"At this time, there is no update mechanism on falco private instance. For an already created instance, there is no way to update and get the latest features.","No automatic deploy on private instance At this time, there is no update mechanism on falco private instance. For an already created instance, there is no way to update and get the latest features."
629917,629917,700068,https://api.github.com/repos/microsoft/vscode/issues/111756,0.0,2020-12-02T16:39:47Z,MEMBER,https://api.github.com/repos/microsoft/vscode,Double tooltip,"* safari (maybe only safari)
* open repo in codespaces
* hover of an issue in the GH view
* :bug: there are double tooltips


<img width=""628"" alt=""Screenshot 2020-12-02 at 14 05 44"" src=""https://user-images.githubusercontent.com/1794099/100902537-4245bb80-34c5-11eb-82fc-68c46fb65e05.png"">
","Double tooltip * safari (maybe only safari) * open repo in codespaces * hover of an issue in the GH view * :bug: there are double tooltips <img width=""628"" alt=""Screenshot 2020-12-02 at 14 05 44"" src=""https://user-images.githubusercontent.com/1794099/100902537-4245bb80-34c5-11eb-82fc-68c46fb65e05.png""> "
654903,654903,727971,https://api.github.com/repos/the-parkers/playGround/issues/44,1.0,2021-05-17T16:01:28Z,CONTRIBUTOR,https://api.github.com/repos/the-parkers/playGround,Features of user profile page,"- [x] Can Edit profile attributes
- [x] Shows users favorited parks
- [x] Shows Events made by that user
",Features of user profile page - [x] Can Edit profile attributes - [x] Shows users favorited parks - [x] Shows Events made by that user 
173584,173584,193009,https://api.github.com/repos/glific/glific/issues/914,0.0,2021-01-12T10:21:53Z,NONE,https://api.github.com/repos/glific/glific,ErlangError happened in Oban Glific.Jobs.MinuteWorker#perform,"**Message**

```
  ** (ErlangError) Erlang error: ""%Protocol.UndefinedError{description: \""\"", protocol: String.Chars, value: #Ecto.Changeset<action: :insert, changes: %{body: \""Hi {{1}},\\nPlease find the attached bill.\"", category: \""PAYMENT_UPDATE\"", example: \""Hi [bob], \\nPlease find the attached bill.\"", is_active: true, is_hsm: true, is_reserved: false, is_source: false, label: \""document_template_1\"", language_id: 1, number_parameters: 1, organization_id: 2, shortcode: \""document_template_1\"", status: \""APPROVED\"", translations: %{}, type: :document, uuid: \""4f452190-4684-47c1-a92e-70ffeebb1a4e\""}, errors: [label: {\""has already been taken\"", [constraint: :unique, constraint_name: \""session_templates_label_language_id_organization_id_index\""]}], data: #Glific.Templates.SessionTemplate<>, valid?: false>}""
```

**Backtrace (last 10 lines)**

```
lib/string/chars.ex:3 String.Chars.impl_for!/1
lib/string/chars.ex:22 String.Chars.to_string/1
lib/glific/templates.ex:320 Glific.Templates.insert_hsm/3
lib/enum.ex:783 Enum.""-each/2-lists^foreach/1-0-""/2
lib/glific/providers/gupshup/template.ex:68 Glific.Providers.Gupshup.Template.update_hsm_templates/1
lib/enum.ex:789 anonymous fn/3 in Enum.each/2
maps.erl:233 :maps.fold_1/3
lib/enum.ex:2127 Enum.each/2
```

View on AppSignal: https://appsignal.com/project-tech4dev/sites/5f480c425ac13f7330101f30/exceptions/incidents/28?timestamp=2021-01-12T00:00:38Z    ","ErlangError happened in Oban Glific.Jobs.MinuteWorker#perform **Message** ``` ** (ErlangError) Erlang error: ""%Protocol.UndefinedError{description: \""\"", protocol: String.Chars, value: #Ecto.Changeset<action: :insert, changes: %{body: \""Hi {{1}},\\nPlease find the attached bill.\"", category: \""PAYMENT_UPDATE\"", example: \""Hi [bob], \\nPlease find the attached bill.\"", is_active: true, is_hsm: true, is_reserved: false, is_source: false, label: \""document_template_1\"", language_id: 1, number_parameters: 1, organization_id: 2, shortcode: \""document_template_1\"", status: \""APPROVED\"", translations: %{}, type: :document, uuid: \""4f452190-4684-47c1-a92e-70ffeebb1a4e\""}, errors: [label: {\""has already been taken\"", [constraint: :unique, constraint_name: \""session_templates_label_language_id_organization_id_index\""]}], data: #Glific.Templates.SessionTemplate<>, valid?: false>}"" ``` **Backtrace (last 10 lines)** ``` lib/string/chars.ex:3 String.Chars.impl_for!/1 lib/string/chars.ex:22 String.Chars.to_string/1 lib/glific/templates.ex:320 Glific.Templates.insert_hsm/3 lib/enum.ex:783 Enum.""-each/2-lists^foreach/1-0-""/2 lib/glific/providers/gupshup/template.ex:68 Glific.Providers.Gupshup.Template.update_hsm_templates/1 lib/enum.ex:789 anonymous fn/3 in Enum.each/2 maps.erl:233 :maps.fold_1/3 lib/enum.ex:2127 Enum.each/2 ``` View on AppSignal: https://appsignal.com/project-tech4dev/sites/5f480c425ac13f7330101f30/exceptions/incidents/28?timestamp=2021-01-12T00:00:38Z "
487365,487365,541645,https://api.github.com/repos/benoitc/gunicorn/issues/2293,2.0,2020-03-18T16:20:15Z,NONE,https://api.github.com/repos/benoitc/gunicorn,ModuleNotFoundError: No module named 'django',"Hi,

have a problem with gunicorn/Django
cd intensetbm_app/intensetbm-etool 
gunicorn intenseTBM_eTool.wsgi:application

error:ModuleNotFoundError: No module named 'django'

project:
envs
intensetbm_app
|   intensetbm-etool
|   |   intenseTBM_eTool
|   |   |    wsgi.py
|   |   |    settings.py
|   |   |    ...
|   |   manage.py
|   |   ...
intensetbm_static

wsgi.py
import os
from django.core.wsgi import get_wsgi_application
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'intenseTBM_eTool.settings')
application = get_wsgi_application()","ModuleNotFoundError: No module named 'django' Hi, have a problem with gunicorn/Django cd intensetbm_app/intensetbm-etool gunicorn intenseTBM_eTool.wsgi:application error:ModuleNotFoundError: No module named 'django' project: envs intensetbm_app | intensetbm-etool | | intenseTBM_eTool | | | wsgi.py | | | settings.py | | | ... | | manage.py | | ... intensetbm_static wsgi.py import os from django.core.wsgi import get_wsgi_application os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'intenseTBM_eTool.settings') application = get_wsgi_application()"
77644,77644,86328,https://api.github.com/repos/locustio/locust/issues/1716,0.0,2021-03-01T06:24:59Z,NONE,https://api.github.com/repos/locustio/locust,How to use multiple hosts in multiple classes,"<!-- 
If you have a general question about how to use Locust, please check Stack Overflow first https://stackoverflow.com/questions/tagged/locust

You can also ask new questions on SO, https://stackoverflow.com/questions/ask just remember to tag your question with ""locust"". Do not immediately post your issue here after posting to SO, wait for an answer there instead.

Use this form only for reporting actual bugs in locust. Be mindful that the developers of locust are unpaid volunteers, so make sure you have tried everything you can think of before filing a bug :) 
-->

### Describe the bug
<!-- A clear and concise description of what the bug is -->

I need to test some APIs having different addresses, I have created locustfile as mentioned below, but only api1 is working, endpoints in api2 are not being called

I tried suggestions from Issue: https://github.com/locustio/locust/issues/150 and put full path as `self.client.post('http://localhost:6001/ep1')` but the same problem persists

### Expected behavior
<!-- Tell us what you think should happen -->

### Actual behavior
<!-- Tell us what happens instead. Include screenshots if this an issue with the GUI. -->

### Steps to reproduce
<!-- Please provide a minimal reproducible code example (https://stackoverflow.com/help/minimal-reproducible-example) --> 
**locustfile.py**
```
from locust import HttpUser, task, between

class api1(HttpUser):

    host = 'http://localhost:6001'
    wait_time = between(2, 4)

    @task()
    def api1_ep1(self):
        self.client.post('/ep1')
        
    @task()
    def api1_ep2(self):
        self.client.post('/ep2')
        

class api2(HttpUser):

    host = 'http://localhost:6002'
    wait_time = between(2, 4)

    @task()
    def api2_ep1(self):
        self.client.post('/ep1')

    @task()
    def api2_ep2(self):
        self.client.post('/ep2')
```

### Environment

- OS: Ubuntu 18.04 LTS
- Python version: Python 3.6.9 
- Locust version: 1.4.3
- Locust command line that you ran: locust
- Locust file contents (anonymized if necessary):","How to use multiple hosts in multiple classes <!-- If you have a general question about how to use Locust, please check Stack Overflow first https://stackoverflow.com/questions/tagged/locust You can also ask new questions on SO, https://stackoverflow.com/questions/ask just remember to tag your question with ""locust"". Do not immediately post your issue here after posting to SO, wait for an answer there instead. Use this form only for reporting actual bugs in locust. Be mindful that the developers of locust are unpaid volunteers, so make sure you have tried everything you can think of before filing a bug :) --> ### Describe the bug <!-- A clear and concise description of what the bug is --> I need to test some APIs having different addresses, I have created locustfile as mentioned below, but only api1 is working, endpoints in api2 are not being called I tried suggestions from Issue: https://github.com/locustio/locust/issues/150 and put full path as `self.client.post('http://localhost:6001/ep1')` but the same problem persists ### Expected behavior <!-- Tell us what you think should happen --> ### Actual behavior <!-- Tell us what happens instead. Include screenshots if this an issue with the GUI. --> ### Steps to reproduce <!-- Please provide a minimal reproducible code example (https://stackoverflow.com/help/minimal-reproducible-example) --> **locustfile.py** ``` from locust import HttpUser, task, between class api1(HttpUser): host = 'http://localhost:6001' wait_time = between(2, 4) @task() def api1_ep1(self): self.client.post('/ep1') @task() def api1_ep2(self): self.client.post('/ep2') class api2(HttpUser): host = 'http://localhost:6002' wait_time = between(2, 4) @task() def api2_ep1(self): self.client.post('/ep1') @task() def api2_ep2(self): self.client.post('/ep2') ``` ### Environment - OS: Ubuntu 18.04 LTS - Python version: Python 3.6.9 - Locust version: 1.4.3 - Locust command line that you ran: locust - Locust file contents (anonymized if necessary):"
547325,547325,608341,https://api.github.com/repos/iv-org/invidious/issues/62,1.0,2018-08-01T22:16:48Z,CONTRIBUTOR,https://api.github.com/repos/iv-org/invidious,Grouping subscribtions by date,"As you probably know, YouTube sorts your subscribtions by date: 
* Recent ( < 2 days ago)
* This week
* This month ( > 1 week ago)

I think it would be nice to implement this feature.

P.S. Each category is separated from each other.
 
","Grouping subscribtions by date As you probably know, YouTube sorts your subscribtions by date: * Recent ( < 2 days ago) * This week * This month ( > 1 week ago) I think it would be nice to implement this feature. P.S. Each category is separated from each other. "
646840,646840,718971,https://api.github.com/repos/web-ridge/react-native-paper-dates/issues/48,1.0,2021-02-23T02:32:28Z,CONTRIBUTOR,https://api.github.com/repos/web-ridge/react-native-paper-dates,Disable/blur old dates,"It would be nice to have a boolean that doesn't allow you to click dates before today (i.e. a `minDate: new Date()`). It could then reduce the opacity of the hidden dates, so users know not to click them.","Disable/blur old dates It would be nice to have a boolean that doesn't allow you to click dates before today (i.e. a `minDate: new Date()`). It could then reduce the opacity of the hidden dates, so users know not to click them."
775815,775815,528047,https://api.github.com/repos/OpenWaterFoundation/owf-app-snodas-ng/issues/3,1.0,2021-03-22T20:59:58Z,NONE,https://api.github.com/repos/OpenWaterFoundation/owf-app-snodas-ng,Feedback on initial SNODAS application,"Here is feedback on the initial application.  I'm putting in one issue but issues can be split as appropriate. Some of these are cosmetic and addressing now will avoid having to re-comment on later.  Some of these changes will also demonstrate the value of Angular and updates to the app, rather than just making it appear exactly as before.

1. Some of the fonts on the right seem a bit ""skinny"".  The font used for the main menu is nice so I'd make them consistent.
2. Zoom is too drastic.  I recommend using fractional zoom increments similar to InfoMapper, but try it out to make sure it works well.
3. It is a bit distracting to see background text show through the data popup.  Maybe make it more opaque.
4. Would be nice to make the graph buttons fit on the page without scrolling for a normal-sized display (23""?).  Get rid of extra padding where possible.  Can probably get ***Current SNODAS Date*** to fit on one line by using smaller font.
5. Should a progress indicator be shown after a new date is selected?  It may be slower for some users.
6. Maybe make the animation more clearly a separate control, like adding a border around it?  Maybe move it to the bottom of the right panel since it is a secondary feature and picking date and basin are the primary interactions?  Or, maybe make tabs in the right panel with ""View Data"" and ""Animate"" (as long as the two use cases are separate).
7. Is the animation period selector constrained to the limits of the data?  It needs to be - otherwise people could pick bad dates.
8. Maybe show selected basin in a different color than mouseover highlight?  Yellow is often used for select/highlight but does not work as well on light-colored background.
9. Image viewer window works well.  However, it is not resizable so can the resize handle on the dialog be omitted?  Or, allow resize and make it work somehow.  Controlling the dialog behavior could be properties in the library code.  I'm interested in reviewing the properties only because I have done a lot of that type of naming over the years.  Such properties are also important for the code API and I am interested in whether `README.md` is being used to document for developers.
10. Nice that multiple graphs can be shown at the same time.  However, I could not open more than one SWE graph image at the same time.  If viewing multiple graphs, being able to resize would be nice.
11. README should describe which basins have test data.
12. **Need a way of pointing the application to the full dataset hosted on State's server.  This should maybe be the default?  Then use a URL query parameter or other way to switch to developer mode?  I need to be able to test full functionality with data that are current and available on [http://snodas.cdss.state.co.us/app/index.html](http://snodas.cdss.state.co.us/app/index.html)**
13. The graph buttons need to all show the images and be enabled.  Any initial work to implement interactive graphs can be a second update to the application once the basic functionality is in place.
14. Maybe add a label above buttons with ***SNODAS Data Graphs;*** and then remove the word ""SNODAS"" from all buttons in order to shorting labels.
15. Centered name and ID are a bit distracting.  Maybe left-justify the labels so things don't move around so much?
16. Select basin by typing has some odd behaviors:
    1. Shows random words (from other browser searches?) - should only use words in the names.
    2. I tried typing ""ft collins"" but after the `ft` it showed a list and entry area went away.  Is the entry area behind the popup list?  Does a space cause something to get selected?
17. Change the documentation to Markdown and use showdown library (has this been done)?  I can edit the content more easily if that is changed.
18. Data menu should be enabled as another Markdown that describes links.
19. Going to other menus and then back to ***Map*** resets the map to original settings.  Can it remember its state from before?
20. Add favicon.  This will need to be configurable because if we can convince the State to use the new version, it should probably use their current logo (see TSTool documentation).  I may try to see if we can jointly brand the product in this case.
21. Maybe change the map ***Current Date**** to ""Map Data Date***.  I think this is most relevant for the animation and in other cases would agree with the selected date.
22. Date selector should display dates in ISO 8601 format for consistency.  I try to use YYYY-MM-DD everywhere since it is computer friendly and matches data files.","Feedback on initial SNODAS application Here is feedback on the initial application. I'm putting in one issue but issues can be split as appropriate. Some of these are cosmetic and addressing now will avoid having to re-comment on later. Some of these changes will also demonstrate the value of Angular and updates to the app, rather than just making it appear exactly as before. 1. Some of the fonts on the right seem a bit ""skinny"". The font used for the main menu is nice so I'd make them consistent. 2. Zoom is too drastic. I recommend using fractional zoom increments similar to InfoMapper, but try it out to make sure it works well. 3. It is a bit distracting to see background text show through the data popup. Maybe make it more opaque. 4. Would be nice to make the graph buttons fit on the page without scrolling for a normal-sized display (23""?). Get rid of extra padding where possible. Can probably get ***Current SNODAS Date*** to fit on one line by using smaller font. 5. Should a progress indicator be shown after a new date is selected? It may be slower for some users. 6. Maybe make the animation more clearly a separate control, like adding a border around it? Maybe move it to the bottom of the right panel since it is a secondary feature and picking date and basin are the primary interactions? Or, maybe make tabs in the right panel with ""View Data"" and ""Animate"" (as long as the two use cases are separate). 7. Is the animation period selector constrained to the limits of the data? It needs to be - otherwise people could pick bad dates. 8. Maybe show selected basin in a different color than mouseover highlight? Yellow is often used for select/highlight but does not work as well on light-colored background. 9. Image viewer window works well. However, it is not resizable so can the resize handle on the dialog be omitted? Or, allow resize and make it work somehow. Controlling the dialog behavior could be properties in the library code. I'm interested in reviewing the properties only because I have done a lot of that type of naming over the years. Such properties are also important for the code API and I am interested in whether `README.md` is being used to document for developers. 10. Nice that multiple graphs can be shown at the same time. However, I could not open more than one SWE graph image at the same time. If viewing multiple graphs, being able to resize would be nice. 11. README should describe which basins have test data. 12. **Need a way of pointing the application to the full dataset hosted on State's server. This should maybe be the default? Then use a URL query parameter or other way to switch to developer mode? I need to be able to test full functionality with data that are current and available on [http://snodas.cdss.state.co.us/app/index.html](http://snodas.cdss.state.co.us/app/index.html)** 13. The graph buttons need to all show the images and be enabled. Any initial work to implement interactive graphs can be a second update to the application once the basic functionality is in place. 14. Maybe add a label above buttons with ***SNODAS Data Graphs;*** and then remove the word ""SNODAS"" from all buttons in order to shorting labels. 15. Centered name and ID are a bit distracting. Maybe left-justify the labels so things don't move around so much? 16. Select basin by typing has some odd behaviors: 1. Shows random words (from other browser searches?) - should only use words in the names. 2. I tried typing ""ft collins"" but after the `ft` it showed a list and entry area went away. Is the entry area behind the popup list? Does a space cause something to get selected? 17. Change the documentation to Markdown and use showdown library (has this been done)? I can edit the content more easily if that is changed. 18. Data menu should be enabled as another Markdown that describes links. 19. Going to other menus and then back to ***Map*** resets the map to original settings. Can it remember its state from before? 20. Add favicon. This will need to be configurable because if we can convince the State to use the new version, it should probably use their current logo (see TSTool documentation). I may try to see if we can jointly brand the product in this case. 21. Maybe change the map ***Current Date**** to ""Map Data Date***. I think this is most relevant for the animation and in other cases would agree with the selected date. 22. Date selector should display dates in ISO 8601 format for consistency. I try to use YYYY-MM-DD everywhere since it is computer friendly and matches data files."
492506,492506,547399,https://api.github.com/repos/LucasLarson/gunstage/issues/46,1.0,2021-01-25T20:34:51Z,OWNER,https://api.github.com/repos/LucasLarson/gunstage,remove double quotation marks where not suggested by ShellCheck,"ShellCheck doesnt care about quoting variable assignments like this one:
https://github.com/LucasLarson/gunstage/blob/9d7673ab5e7da354b7e18ace3c3a6732359651cb/bin/git-unstage#L20
Even when ShellChecks `--enable` is set to `all` and no matter if `--severity` is set to `style`, let alone `error`, removing the double quotes and running the following has a return value of `0` [_c.d._](https://en.wiktionary.org/wiki/Special:PermanentLink/60741237#Adverb), which is to say nowarnings or errors:
```sh
""$(command -v shellcheck)"" \
  --enable=all \
  --severity=style \
  --exclude="""" \
  --shell=sh \
  -- ./bin/git-unstage
```
---
An unsurprising warning would be:
> **In ./bin/git-unstage line 20:**
> `IFS=$(printf '\n\t')`
> `^--------------^` [SC2248](https://shellcheck.net/wiki/SC2248): Prefer double quoting even when variables dont contain specialcharacters.
>
> **Did you mean:**
> `IFS=""$(printf '\n\t')""`","remove double quotation marks where not suggested by ShellCheck ShellCheck doesnt care about quoting variable assignments like this one: https://github.com/LucasLarson/gunstage/blob/9d7673ab5e7da354b7e18ace3c3a6732359651cb/bin/git-unstage#L20 Even when ShellChecks `--enable` is set to `all` and no matter if `--severity` is set to `style`, let alone `error`, removing the double quotes and running the following has a return value of `0` [_c.d._](https://en.wiktionary.org/wiki/Special:PermanentLink/60741237#Adverb), which is to say nowarnings or errors: ```sh ""$(command -v shellcheck)"" \ --enable=all \ --severity=style \ --exclude="""" \ --shell=sh \ -- ./bin/git-unstage ``` --- An unsurprising warning would be: > **In ./bin/git-unstage line 20:** > `IFS=$(printf '\n\t')` > `^--------------^` [SC2248](https://shellcheck.net/wiki/SC2248): Prefer double quoting even when variables dont contain specialcharacters. > > **Did you mean:** > `IFS=""$(printf '\n\t')""`"
773184,773184,501743,https://api.github.com/repos/LHJE/war_or_peace_redux/issues/4,1.0,2021-01-29T22:01:06Z,OWNER,https://api.github.com/repos/LHJE/war_or_peace_redux,Add Player and Player Test,"Add these methods:
- [x] has_lost?",Add Player and Player Test Add these methods: - [x] has_lost?
546504,546504,607420,https://api.github.com/repos/Bambosh/unofficial-homestuck-collection/issues/38,1.0,2020-11-15T03:04:47Z,COLLABORATOR,https://api.github.com/repos/Bambosh/unofficial-homestuck-collection,Add button/key combination to refresh individual tabs,,Add button/key combination to refresh individual tabs 
642893,642893,714554,https://api.github.com/repos/t-erxleben/marbellous/issues/13,1.0,2021-04-29T13:16:41Z,OWNER,https://api.github.com/repos/t-erxleben/marbellous,Represent options,"Options (e.g. active color, background color, ...) need to be available in a convenient way.","Represent options Options (e.g. active color, background color, ...) need to be available in a convenient way."
496919,496919,552306,https://api.github.com/repos/oracle/visualvm/issues/274,0.0,2021-02-17T08:08:17Z,MEMBER,https://api.github.com/repos/oracle/visualvm,Logical value: '...' added to complete string,"If the length of the string for a logical value is exactly `DetailsUtils.MAX_ARRAY_LENGTH`, `...` are appended to string to mark it as truncated. See screenshot.
<img width=""474"" alt=""string"" src=""https://user-images.githubusercontent.com/22048069/108174236-795c5e00-70ff-11eb-896b-9ab595843bbe.png"">
","Logical value: '...' added to complete string If the length of the string for a logical value is exactly `DetailsUtils.MAX_ARRAY_LENGTH`, `...` are appended to string to mark it as truncated. See screenshot. <img width=""474"" alt=""string"" src=""https://user-images.githubusercontent.com/22048069/108174236-795c5e00-70ff-11eb-896b-9ab595843bbe.png""> "
315519,315519,350780,https://api.github.com/repos/unaio/una/issues/3140,1.0,2021-01-12T12:04:25Z,COLLABORATOR,https://api.github.com/repos/unaio/una," The ""upload"" button should not appear until a file is chosen.",t.20056060," The ""upload"" button should not appear until a file is chosen. t.20056060"
273424,273424,304075,https://api.github.com/repos/buidl-labs/crypto-code-school-inside-tezos/issues/188,1.0,2021-02-26T05:54:02Z,COLLABORATOR,https://api.github.com/repos/buidl-labs/crypto-code-school-inside-tezos,Sell & Withdraw cryptobot : Show warning in case balance is zero or insufficient,"**What's the motivation behind the feature? what problem does the feature intend to solve ?**
Show warning in case balance is zero or insufficient similar to `\transaction` in Sell & Withdraw from sell modal

**Describe the solution you'd like.**
![image](https://user-images.githubusercontent.com/49694914/109255516-23339d00-781a-11eb-9a33-f9964fb5e74e.png)
![image](https://user-images.githubusercontent.com/49694914/109255527-2b8bd800-781a-11eb-8262-70c1d1b08193.png)

cc @bhaskarSingh 
",Sell & Withdraw cryptobot : Show warning in case balance is zero or insufficient **What's the motivation behind the feature? what problem does the feature intend to solve ?** Show warning in case balance is zero or insufficient similar to `\transaction` in Sell & Withdraw from sell modal **Describe the solution you'd like.** ![image](https://user-images.githubusercontent.com/49694914/109255516-23339d00-781a-11eb-9a33-f9964fb5e74e.png) ![image](https://user-images.githubusercontent.com/49694914/109255527-2b8bd800-781a-11eb-8262-70c1d1b08193.png) cc @bhaskarSingh 
99081,99081,110105,https://api.github.com/repos/exasol/exasol-virtual-schema/issues/43,0.0,2021-02-12T10:36:52Z,COLLABORATOR,https://api.github.com/repos/exasol/exasol-virtual-schema,Something is wrong with ODRER BY clause in JOIN,"## Problem

I run across a strange issue - the same query returns the result rows in a different order when executing against Exasol Schema and Virtual schema. Looks like something is wrong with GROUP BY mapping. We need to investigate it.

## How to reproduce

OPEN SCHEMA SOURCE_SCHEMA;
CREATE OR REPLACE TABLE TL(""L1"" VARCHAR(5), ""L2"" VARCHAR(5));
CREATE OR REPLACE TABLE TR(""R1"" VARCHAR(5), ""R2"" VARCHAR(5), ""R3"" VARCHAR(5));
INSERT INTO TL VALUES('ON', 'L2_1');
INSERT INTO TL VALUES('ON', 'L2_2');

INSERT INTO TR VALUES('ON', 'R2_1', 'R3_1');
INSERT INTO TR VALUES('ON', 'R2_2', 'R3_2');

SELECT * FROM TR JOIN TL ON TL.L1 = TR.R1 ORDER BY R2;
SELECT * FROM TL JOIN TR ON TL.L1 = TR.R1 ORDER BY L2;
SELECT * FROM (SELECT * FROM TR JOIN TL ON TL.L1 = TR.R1 ORDER BY L2) nested JOIN TM ON TM.M1 = nested.R1 ORDER BY R2;

-- Virtual Schema

CREATE VIRTUAL SCHEMA MY_VIRTUAL_SCHEMA USING ADAPTER_SCHEMA.EXASOL_ADAPTER
WITH
CONNECTION_NAME = 'JDBC_CONNECTION'
SCHEMA_NAME = 'SOURCE_SCHEMA';

OPEN SCHEMA VIRTUAL_SCHEMA_WITHOUT_SELECT_LIST_PROJECTION_CAPABILITY;
SELECT * FROM (SELECT * FROM TR JOIN TL ON TL.L1 = TR.R1 ORDER BY L2) nested JOIN TM ON TM.M1 = nested.R1 ORDER BY R2;
EXPLAIN VIRTUAL SELECT * FROM (SELECT * FROM TR INNER JOIN TL ON TL.L1 = TR.R1 ORDER BY L2) nested INNER JOIN TM ON TM.M1 = nested.R1 ORDER BY R2;

Result against Exasol Schema:
![Against Exasol](https://user-images.githubusercontent.com/46891819/107757995-915e6700-6d26-11eb-9f98-2db4e89d49e7.png)

Result against Virtual SChema
![Against Virtual Schema](https://user-images.githubusercontent.com/46891819/107758011-97544800-6d26-11eb-9bd4-9635a4726ccd.png)

EXPLAIN VIRTUAL:
- IMPORT INTO (c1 VARCHAR(5) UTF8, c2 VARCHAR(5) UTF8, c3 VARCHAR(5) UTF8, c4 VARCHAR(5) UTF8) FROM JDBC AT JDBC_CONNECTION STATEMENT 'SELECT ""TM"".""M1"", ""TM"".""M2"", ""TM"".""M3"", ""TM"".""M4"" FROM ""SOURCE_SCHEMA"".""TM""'
- IMPORT INTO (c1 VARCHAR(5) UTF8, c2 VARCHAR(5) UTF8, c3 VARCHAR(5) UTF8, c4 VARCHAR(5) UTF8, c5 VARCHAR(5) UTF8) FROM JDBC AT JDBC_CONNECTION STATEMENT 'SELECT ""TR"".""R1"", ""TR"".""R2"", ""TR"".""R3"", ""TL"".""L1"", ""TL"".""L2"" FROM ""SOURCE_SCHEMA"".""TR"" INNER JOIN ""SOURCE_SCHEMA"".""TL"" ON ""TL"".""L1"" = ""TR"".""R1"" ORDER BY ""TL"".""L2""'
","Something is wrong with ODRER BY clause in JOIN ## Problem I run across a strange issue - the same query returns the result rows in a different order when executing against Exasol Schema and Virtual schema. Looks like something is wrong with GROUP BY mapping. We need to investigate it. ## How to reproduce OPEN SCHEMA SOURCE_SCHEMA; CREATE OR REPLACE TABLE TL(""L1"" VARCHAR(5), ""L2"" VARCHAR(5)); CREATE OR REPLACE TABLE TR(""R1"" VARCHAR(5), ""R2"" VARCHAR(5), ""R3"" VARCHAR(5)); INSERT INTO TL VALUES('ON', 'L2_1'); INSERT INTO TL VALUES('ON', 'L2_2'); INSERT INTO TR VALUES('ON', 'R2_1', 'R3_1'); INSERT INTO TR VALUES('ON', 'R2_2', 'R3_2'); SELECT * FROM TR JOIN TL ON TL.L1 = TR.R1 ORDER BY R2; SELECT * FROM TL JOIN TR ON TL.L1 = TR.R1 ORDER BY L2; SELECT * FROM (SELECT * FROM TR JOIN TL ON TL.L1 = TR.R1 ORDER BY L2) nested JOIN TM ON TM.M1 = nested.R1 ORDER BY R2; -- Virtual Schema CREATE VIRTUAL SCHEMA MY_VIRTUAL_SCHEMA USING ADAPTER_SCHEMA.EXASOL_ADAPTER WITH CONNECTION_NAME = 'JDBC_CONNECTION' SCHEMA_NAME = 'SOURCE_SCHEMA'; OPEN SCHEMA VIRTUAL_SCHEMA_WITHOUT_SELECT_LIST_PROJECTION_CAPABILITY; SELECT * FROM (SELECT * FROM TR JOIN TL ON TL.L1 = TR.R1 ORDER BY L2) nested JOIN TM ON TM.M1 = nested.R1 ORDER BY R2; EXPLAIN VIRTUAL SELECT * FROM (SELECT * FROM TR INNER JOIN TL ON TL.L1 = TR.R1 ORDER BY L2) nested INNER JOIN TM ON TM.M1 = nested.R1 ORDER BY R2; Result against Exasol Schema: ![Against Exasol](https://user-images.githubusercontent.com/46891819/107757995-915e6700-6d26-11eb-9f98-2db4e89d49e7.png) Result against Virtual SChema ![Against Virtual Schema](https://user-images.githubusercontent.com/46891819/107758011-97544800-6d26-11eb-9bd4-9635a4726ccd.png) EXPLAIN VIRTUAL: - IMPORT INTO (c1 VARCHAR(5) UTF8, c2 VARCHAR(5) UTF8, c3 VARCHAR(5) UTF8, c4 VARCHAR(5) UTF8) FROM JDBC AT JDBC_CONNECTION STATEMENT 'SELECT ""TM"".""M1"", ""TM"".""M2"", ""TM"".""M3"", ""TM"".""M4"" FROM ""SOURCE_SCHEMA"".""TM""' - IMPORT INTO (c1 VARCHAR(5) UTF8, c2 VARCHAR(5) UTF8, c3 VARCHAR(5) UTF8, c4 VARCHAR(5) UTF8, c5 VARCHAR(5) UTF8) FROM JDBC AT JDBC_CONNECTION STATEMENT 'SELECT ""TR"".""R1"", ""TR"".""R2"", ""TR"".""R3"", ""TL"".""L1"", ""TL"".""L2"" FROM ""SOURCE_SCHEMA"".""TR"" INNER JOIN ""SOURCE_SCHEMA"".""TL"" ON ""TL"".""L1"" = ""TR"".""R1"" ORDER BY ""TL"".""L2""' "
366954,366954,407921,https://api.github.com/repos/isar/isar/issues/86,1.0,2021-04-21T16:17:24Z,NONE,https://api.github.com/repos/isar/isar,return id when new record is put,"It would be nice if when creating a new record, it's id were returned:

```dart
int id = await contacts.put(newContact);
```

Today this is not possible because put returns void.

I feel that it is standard for api's and databases to offer an ability to have the id returned in some way or other when inserting a new record. Often the entire object is returned.

My use-case: When the user creates a new object, the app should open it's form. So I want to pass the id to the route.

**Version**
 - Platform: Android
 - Flutter version: 2.2.0-10.1.pre
 - Isar version: 0.4.0","return id when new record is put It would be nice if when creating a new record, it's id were returned: ```dart int id = await contacts.put(newContact); ``` Today this is not possible because put returns void. I feel that it is standard for api's and databases to offer an ability to have the id returned in some way or other when inserting a new record. Often the entire object is returned. My use-case: When the user creates a new object, the app should open it's form. So I want to pass the id to the route. **Version** - Platform: Android - Flutter version: 2.2.0-10.1.pre - Isar version: 0.4.0"
58556,58556,65100,https://api.github.com/repos/harshgoel05/another-portfolio/issues/17,1.0,2021-01-25T13:46:20Z,OWNER,https://api.github.com/repos/harshgoel05/another-portfolio,Contact section in Homepage,"# Expected Behavior

Need to add a Contact section in Homepage
",Contact section in Homepage # Expected Behavior Need to add a Contact section in Homepage 
176652,176652,196396,https://api.github.com/repos/ModernFlyouts-Community/ModernFlyouts/issues/544,0.0,2021-04-06T15:41:06Z,NONE,https://api.github.com/repos/ModernFlyouts-Community/ModernFlyouts,Bug:,"**Describe the bug:**
Non-working play/pause if music plays on Spotify. Non-working timeline rewind if music plays on Groove Music. Some problems with overlay. 

**To Reproduce:**
Steps to reproduce the behavior:
1. Go to Spotify or Groove Music
2. Play any track
3. Click on sound control keys 
3. Look at the ModernFlyouts' Flyout
4. Try to rewind track(If Groove) or play/pause(If Spotify)
5. See control bug
5. For overlay bug hold the cursor on any button on flyout
5. The annotation will be behind the flyout

**Screenshots:**
<img width=""960"" alt=""bug"" src=""https://user-images.githubusercontent.com/68125523/113710303-345eac00-96ec-11eb-9461-e83e344d96d5.png"">
<img width=""960"" alt=""bug1"" src=""https://user-images.githubusercontent.com/68125523/113710702-b7800200-96ec-11eb-8753-6eee3c15f57c.png"">
<img width=""960"" alt=""bug2"" src=""https://user-images.githubusercontent.com/68125523/113710903-f910ad00-96ec-11eb-983a-1109286317ba.png"">


**OS Version:**
 - Windows 10 Version: 20H2

**ModernFlyouts Version:**
 - Version: 0.9.1.0




**Additional context:**
<!-- Add any other info about the problem below this line. -->
","Bug: **Describe the bug:** Non-working play/pause if music plays on Spotify. Non-working timeline rewind if music plays on Groove Music. Some problems with overlay. **To Reproduce:** Steps to reproduce the behavior: 1. Go to Spotify or Groove Music 2. Play any track 3. Click on sound control keys 3. Look at the ModernFlyouts' Flyout 4. Try to rewind track(If Groove) or play/pause(If Spotify) 5. See control bug 5. For overlay bug hold the cursor on any button on flyout 5. The annotation will be behind the flyout **Screenshots:** <img width=""960"" alt=""bug"" src=""https://user-images.githubusercontent.com/68125523/113710303-345eac00-96ec-11eb-9461-e83e344d96d5.png""> <img width=""960"" alt=""bug1"" src=""https://user-images.githubusercontent.com/68125523/113710702-b7800200-96ec-11eb-8753-6eee3c15f57c.png""> <img width=""960"" alt=""bug2"" src=""https://user-images.githubusercontent.com/68125523/113710903-f910ad00-96ec-11eb-983a-1109286317ba.png""> **OS Version:** - Windows 10 Version: 20H2 **ModernFlyouts Version:** - Version: 0.9.1.0 **Additional context:** <!-- Add any other info about the problem below this line. --> "
718551,718551,798602,https://api.github.com/repos/xamarin/binding-tools-for-swift/issues/618,0.0,2021-03-17T15:24:02Z,CONTRIBUTOR,https://api.github.com/repos/xamarin/binding-tools-for-swift,SwiftInterfaceParser having trouble with local operators,"see
* UnicodeTests.UnicodeInOperatorName
* OperatorTests.SuperSimpleEnumTest
* OperatorTests.StructPrefixOpTest
* OperatorTests.StructPostfixOpTest
* OperatorTests.StructInfixOpTest
* OperatorTests.SimpleEnumPostfixOpTest
* OperatorTests.SimpleEnumInfixOpTest
* OperatorTests.OperatorSmokeTest3
* OperatorTests.OperatorSmokeTest2
* OperatorTests.OperatorSmokeTest1
* OperatorTests.OperatorSmokeTest0
* OperatorTests.OperatorCompositionNoInvoke
* OperatorTests.MultiplicationConflict
* OperatorTests.EnumInfixOpTest
* HomonymTests.TestOperatorHomonymSmokeTest",SwiftInterfaceParser having trouble with local operators see * UnicodeTests.UnicodeInOperatorName * OperatorTests.SuperSimpleEnumTest * OperatorTests.StructPrefixOpTest * OperatorTests.StructPostfixOpTest * OperatorTests.StructInfixOpTest * OperatorTests.SimpleEnumPostfixOpTest * OperatorTests.SimpleEnumInfixOpTest * OperatorTests.OperatorSmokeTest3 * OperatorTests.OperatorSmokeTest2 * OperatorTests.OperatorSmokeTest1 * OperatorTests.OperatorSmokeTest0 * OperatorTests.OperatorCompositionNoInvoke * OperatorTests.MultiplicationConflict * OperatorTests.EnumInfixOpTest * HomonymTests.TestOperatorHomonymSmokeTest
54293,54293,60400,https://api.github.com/repos/MagniteEngineering/fledge.polyfill/issues/52,1.0,2021-04-26T18:46:23Z,MEMBER,https://api.github.com/repos/MagniteEngineering/fledge.polyfill,create ad rendering implementation,"**Is your feature request related to a problem? Please describe.**
<!-- A clear and concise description of what the problem is. (e.g. I'm always frustrated when [...]) -->

Create an implementation of the Fledge specs that renders the winning ad's creative.

**Describe the solution you'd like**
<!-- A clear and concise description of what you want to happen -->

Create an `iframe` that takes in the results from a winning auction and renders it on a publisher's page at the specified HTML ID.  This should not be the actual winners' creative or render URL, but a token that can be used to look up the results from the dB.

**Describe alternatives you've considered (optional)**
<!-- A clear and concise description of any alternative solutions or features you've considered -->

N/A

**Additional context (optional)**
<!-- Add any other context or screenshots about the feature request here -->

Tech Spec: https://github.com/MagniteEngineering/fledge.polyfill/wiki/Technical-Specification:-Auctions#renderadbidbid","create ad rendering implementation **Is your feature request related to a problem? Please describe.** <!-- A clear and concise description of what the problem is. (e.g. I'm always frustrated when [...]) --> Create an implementation of the Fledge specs that renders the winning ad's creative. **Describe the solution you'd like** <!-- A clear and concise description of what you want to happen --> Create an `iframe` that takes in the results from a winning auction and renders it on a publisher's page at the specified HTML ID. This should not be the actual winners' creative or render URL, but a token that can be used to look up the results from the dB. **Describe alternatives you've considered (optional)** <!-- A clear and concise description of any alternative solutions or features you've considered --> N/A **Additional context (optional)** <!-- Add any other context or screenshots about the feature request here --> Tech Spec: https://github.com/MagniteEngineering/fledge.polyfill/wiki/Technical-Specification:-Auctions#renderadbidbid"
516032,516032,573472,https://api.github.com/repos/NVIDIA/NeMo/issues/1370,2.0,2020-10-29T13:48:17Z,NONE,https://api.github.com/repos/NVIDIA/NeMo,Inverse text normalization in NeMo,"**Describe your question**
Are you guys planing to add **Inverse text normalization** models in NeMo. Something [like this](https://docs.aws.amazon.com/transcribe/latest/dg/how-numbers.html).

If anyone have worked on this before can you share some resources where I can study about this.
Thanks :)",Inverse text normalization in NeMo **Describe your question** Are you guys planing to add **Inverse text normalization** models in NeMo. Something [like this](https://docs.aws.amazon.com/transcribe/latest/dg/how-numbers.html). If anyone have worked on this before can you share some resources where I can study about this. Thanks :)
719653,719653,799815,https://api.github.com/repos/Kartonagnick/tools-types/issues/49,1.0,2021-04-07T23:52:38Z,OWNER,https://api.github.com/repos/Kartonagnick/tools-types,is_const_data,"is_const_data
---

```
true, 筠剋龜 t 極筠畇逵勻剋筠 棘閨棘橘 戟筠龜鈞劇筠戟筠劇筠 畇逵戟戟筠
is_const_data<t>::value

is_const_data<char*>::value             // false
is_const_data<char* const>::value       // false

is_const_data<const char*>::value       // true
is_const_data<const char*const>::value  // true
```

剋逵戟:  
  - `槻逵-1` 筠逵剋龜鈞逵龜:  
    - [x] 畇棘閨逵勻剋筠劇 筠逵剋龜鈞逵龜  
    - [x] 畇棘閨逵勻剋筠劇 筠  
  - `槻逵-2` 閨棘克逵:  
    - [x] 極棘勻筠筠劇 閨棘克 戟逵 勻筠 克棘劇極龜剋棘逵  
    - [x] 鈞逵極棘剋戟筠劇 龜棘龜  
    - [x] 棘閨戟棘勻剋筠劇 逵閨剋龜  ","is_const_data is_const_data --- ``` true, 筠剋龜 t 極筠畇逵勻剋筠 棘閨棘橘 戟筠龜鈞劇筠戟筠劇筠 畇逵戟戟筠 is_const_data<t>::value is_const_data<char*>::value // false is_const_data<char* const>::value // false is_const_data<const char*>::value // true is_const_data<const char*const>::value // true ``` 剋逵戟: - `槻逵-1` 筠逵剋龜鈞逵龜: - [x] 畇棘閨逵勻剋筠劇 筠逵剋龜鈞逵龜 - [x] 畇棘閨逵勻剋筠劇 筠 - `槻逵-2` 閨棘克逵: - [x] 極棘勻筠筠劇 閨棘克 戟逵 勻筠 克棘劇極龜剋棘逵 - [x] 鈞逵極棘剋戟筠劇 龜棘龜 - [x] 棘閨戟棘勻剋筠劇 逵閨剋龜 "
694878,694878,772334,https://api.github.com/repos/laminas/laminas-db/issues/97,1.0,2020-01-16T19:28:44Z,MEMBER,https://api.github.com/repos/laminas/laminas-db,Postgresql indexes,"Add support for Index creation with PostgreSQL platform. 
$table = CreateTable();
$table->addConstraint(new Index())
crashed with invalid syntax error.  Same for AlterTable.

Can be considered as first step towards cleaning up #67 
Continuing to work on finding the rest of the incompatibilities, but not sure if submit one large PR with full PgSQL support or do smaller more review manageable parts at a time. But then cannot make PRs depend on one another so, unless told otherwise will continue adding more commits here.


---

Originally posted by @alextech at https://github.com/zendframework/zend-db/pull/163","Postgresql indexes Add support for Index creation with PostgreSQL platform. $table = CreateTable(); $table->addConstraint(new Index()) crashed with invalid syntax error. Same for AlterTable. Can be considered as first step towards cleaning up #67 Continuing to work on finding the rest of the incompatibilities, but not sure if submit one large PR with full PgSQL support or do smaller more review manageable parts at a time. But then cannot make PRs depend on one another so, unless told otherwise will continue adding more commits here. --- Originally posted by @alextech at https://github.com/zendframework/zend-db/pull/163"
249713,249713,277764,https://api.github.com/repos/jpreardon/good-morning-display/issues/48,0.0,2021-03-05T17:52:23Z,OWNER,https://api.github.com/repos/jpreardon/good-morning-display,Refactor express train icon code,"The code that renders the x trains in diamonds rather than circles is specific to a couple lines. There are other express trains though. Make it more flexible. 

While youre at it, fix the size and alignment of the express icons. Size of 1.25 rem seems to work as well as about .3 rem of left padding on the span. ","Refactor express train icon code The code that renders the x trains in diamonds rather than circles is specific to a couple lines. There are other express trains though. Make it more flexible. While youre at it, fix the size and alignment of the express icons. Size of 1.25 rem seems to work as well as about .3 rem of left padding on the span. "
740148,740148,171646,https://api.github.com/repos/bbc/simorgh/issues/8997,0.0,2021-03-22T08:26:23Z,CONTRIBUTOR,https://api.github.com/repos/bbc/simorgh,Update ATI Level 1 PS and GNL when exUK,"**Is your feature request related to a problem? Please describe.**

As a PS user
I don't want my data being tracked by GNL for commercial purposes 

**Background** 

If a user is within the UK we do not track them under GNL 
On our alephamp pages we send users to the correct location https://www.bbc.co.uk/news/amp/uk-england-suffolk-56321188

- For PS assets only 
- This is specific to AMP 
- No changes required for WS 

Google serves .com URLS for (all?) BBC Sport results, even for users in the UK. These pages assume users within the UK are not within the UK - we need to investigate and ensure this doesn't happen.

**ATI LEVEL 1 - exUK**

- Given a user is outside of the UK
- When they visit <service> on .com or .co.uk on .AMP pages
- ie. https://www.bbc.co.uk/news/uk-england-suffolk-56321188.amp or https://www.bbc.com/news/uk-england-suffolk-56321188.amp
- Then the ATI level 1 site is <level 1 exUK>

**ATI LEVEL 1 -  in UK**

- Given a user is inside of the UK
- When they visit <service> on .com or .co.uk .AMP 
- ie. https://www.bbc.co.uk/news/uk-england-suffolk-56321188.amp or https://www.bbc.com/news/uk-england-suffolk-56321188.amp
- Then the ATI level 1 site is <level 1 UK>

 
LEVEL 1 sites: https://confluence.dev.bbc.co.uk/pages/viewpage.action?pageId=175885338
service | level 1 UK | level 1 exUK
-- | -- | --
sport | SPORT_PS (598310) | SPORT_GNL (598308)
sport test | SPORT_PS_TEST (598311) | SPORT_GNL_TEST (598309)
news | NEWS_PS (598285) | NEWS_GNL (598287)
news test | NEWS_PS_TEST (598286) | NEWS_GNL_TEST (598288)
newsround | NEWSROUND (598293) | NEWSROUND (598293)
Newsround test | NEWSROUND_TEST (598294) | NEWSROUND_TEST (598294)
cymrufyw | NEWS_LANGUAGES_PS (598291) | NEWS_LANGUAGES_GNL (598289)
cymrufyw test | NEWS_LANGUAGES_PS_TEST (598292) | NEWS_LANGUAGES_GNL_TEST (598290)
naidheachdan | NEWS_LANGUAGES_PS (598291) | NEWS_LANGUAGES_GNL (598289)
naidheachdan test | NEWS_LANGUAGES_PS_TEST (598292) | NEWS_LANGUAGES_GNL_TEST (598290)


**Testing notes**
[Tester to complete]

Dev insight: Will Cypress tests be required or are unit tests sufficient? Will there be any potential regression? etc

- [x] This feature is expected to need manual testing.


**Additional context**
<img width=""1197"" alt=""Screenshot 2021-03-22 at 08 17 07"" src=""https://user-images.githubusercontent.com/22519682/111960918-41727d00-8ae8-11eb-9005-a38c3093e276.png"">
<img width=""1194"" alt=""Screenshot 2021-03-22 at 08 15 23"" src=""https://user-images.githubusercontent.com/22519682/111960929-47685e00-8ae8-11eb-87e2-bbbb4663fe19.png"">

","Update ATI Level 1 PS and GNL when exUK **Is your feature request related to a problem? Please describe.** As a PS user I don't want my data being tracked by GNL for commercial purposes **Background** If a user is within the UK we do not track them under GNL On our alephamp pages we send users to the correct location https://www.bbc.co.uk/news/amp/uk-england-suffolk-56321188 - For PS assets only - This is specific to AMP - No changes required for WS Google serves .com URLS for (all?) BBC Sport results, even for users in the UK. These pages assume users within the UK are not within the UK - we need to investigate and ensure this doesn't happen. **ATI LEVEL 1 - exUK** - Given a user is outside of the UK - When they visit <service> on .com or .co.uk on .AMP pages - ie. https://www.bbc.co.uk/news/uk-england-suffolk-56321188.amp or https://www.bbc.com/news/uk-england-suffolk-56321188.amp - Then the ATI level 1 site is <level 1 exUK> **ATI LEVEL 1 - in UK** - Given a user is inside of the UK - When they visit <service> on .com or .co.uk .AMP - ie. https://www.bbc.co.uk/news/uk-england-suffolk-56321188.amp or https://www.bbc.com/news/uk-england-suffolk-56321188.amp - Then the ATI level 1 site is <level 1 UK> LEVEL 1 sites: https://confluence.dev.bbc.co.uk/pages/viewpage.action?pageId=175885338 service | level 1 UK | level 1 exUK -- | -- | -- sport | SPORT_PS (598310) | SPORT_GNL (598308) sport test | SPORT_PS_TEST (598311) | SPORT_GNL_TEST (598309) news | NEWS_PS (598285) | NEWS_GNL (598287) news test | NEWS_PS_TEST (598286) | NEWS_GNL_TEST (598288) newsround | NEWSROUND (598293) | NEWSROUND (598293) Newsround test | NEWSROUND_TEST (598294) | NEWSROUND_TEST (598294) cymrufyw | NEWS_LANGUAGES_PS (598291) | NEWS_LANGUAGES_GNL (598289) cymrufyw test | NEWS_LANGUAGES_PS_TEST (598292) | NEWS_LANGUAGES_GNL_TEST (598290) naidheachdan | NEWS_LANGUAGES_PS (598291) | NEWS_LANGUAGES_GNL (598289) naidheachdan test | NEWS_LANGUAGES_PS_TEST (598292) | NEWS_LANGUAGES_GNL_TEST (598290) **Testing notes** [Tester to complete] Dev insight: Will Cypress tests be required or are unit tests sufficient? Will there be any potential regression? etc - [x] This feature is expected to need manual testing. **Additional context** <img width=""1197"" alt=""Screenshot 2021-03-22 at 08 17 07"" src=""https://user-images.githubusercontent.com/22519682/111960918-41727d00-8ae8-11eb-9005-a38c3093e276.png""> <img width=""1194"" alt=""Screenshot 2021-03-22 at 08 15 23"" src=""https://user-images.githubusercontent.com/22519682/111960929-47685e00-8ae8-11eb-87e2-bbbb4663fe19.png""> "
757185,757185,340753,https://api.github.com/repos/libsdl-org/SDL-1.2/issues/572,0.0,2021-02-10T21:20:59Z,COLLABORATOR,https://api.github.com/repos/libsdl-org/SDL-1.2,Calling SDL_SetVideoMode() will reset existing timers,"
# This bug report was migrated from our old Bugzilla tracker.

**Reported in version:** 1.2.14
**Reported for operating system, platform:** Linux, Other

# Comments on the original bug report:

On 2010-06-13 20:31:08 +0000, Alexei Svitkine wrote:

> My application does the following:
> 
> SDL_Init(SDL_INIT_VIDEO)
> SDL_SetVideoMode(...)
> ...
> SDL_Init(SDL_INIT_TIMER)
> SDL_AddTimer(...)
> ...
> SDL_SetVideoMode(...)
> 
> After the last call to SetVideoMode(), all my previously registered timers will be lost - and GDB tells me that the timer thread ends. It seems SDL_SetVideoMode() ends up calling SDL_Init(), which somehow re-initializes the timer stuff and losing everything that was registered.

On 2010-07-18 14:05:53 +0000, Alexei Svitkine wrote:

> Further testing revealed that this behaviour is cross-platform (MacOSX and Windows are also affected).

On 2011-02-04 14:31:39 +0000, Sam Lantinga wrote:

> This is fixed in SDL 1.3.  Previously the timers were coupled to the event loop.
> 
> Thanks!

","Calling SDL_SetVideoMode() will reset existing timers # This bug report was migrated from our old Bugzilla tracker. **Reported in version:** 1.2.14 **Reported for operating system, platform:** Linux, Other # Comments on the original bug report: On 2010-06-13 20:31:08 +0000, Alexei Svitkine wrote: > My application does the following: > > SDL_Init(SDL_INIT_VIDEO) > SDL_SetVideoMode(...) > ... > SDL_Init(SDL_INIT_TIMER) > SDL_AddTimer(...) > ... > SDL_SetVideoMode(...) > > After the last call to SetVideoMode(), all my previously registered timers will be lost - and GDB tells me that the timer thread ends. It seems SDL_SetVideoMode() ends up calling SDL_Init(), which somehow re-initializes the timer stuff and losing everything that was registered. On 2010-07-18 14:05:53 +0000, Alexei Svitkine wrote: > Further testing revealed that this behaviour is cross-platform (MacOSX and Windows are also affected). On 2011-02-04 14:31:39 +0000, Sam Lantinga wrote: > This is fixed in SDL 1.3. Previously the timers were coupled to the event loop. > > Thanks! "
79539,79539,88435,https://api.github.com/repos/glizzan/kybern/issues/69,0.0,2020-10-20T19:45:32Z,CONTRIBUTOR,https://api.github.com/repos/glizzan/kybern,Possible security issue,"In Firefox, via HY:

![image (1)](https://user-images.githubusercontent.com/1179362/96636412-45a52f00-12eb-11eb-96d1-c21257c27d27.png)
","Possible security issue In Firefox, via HY: ![image (1)](https://user-images.githubusercontent.com/1179362/96636412-45a52f00-12eb-11eb-96d1-c21257c27d27.png) "
793017,793017,699738,https://api.github.com/repos/DD2480-Group-11/litiengine/issues/15,1.0,2021-03-09T11:58:59Z,NONE,https://api.github.com/repos/DD2480-Group-11/litiengine,Add Integration of issue #12 and #13,"Integration of issue #12 and #13 into the editor. Part of https://github.com/gurkenlabs/litiengine/issues/321
UI option for export and import",Add Integration of issue #12 and #13 Integration of issue #12 and #13 into the editor. Part of https://github.com/gurkenlabs/litiengine/issues/321 UI option for export and import
548589,548589,609724,https://api.github.com/repos/neomjs/neo/issues/2193,1.0,2021-05-28T16:51:09Z,COLLABORATOR,https://api.github.com/repos/neomjs/neo,component.Base: cls setter => do not trigger an update in case we are in silent mode,,component.Base: cls setter => do not trigger an update in case we are in silent mode 
540816,540816,601103,https://api.github.com/repos/Piko-Piko-Pon-Taro/navict-app/issues/51,0.0,2021-05-06T05:36:36Z,COLLABORATOR,https://api.github.com/repos/Piko-Piko-Pon-Taro/navict-app,navict-recommenderⓦAPImap(async()=>{})ㅳｃ╉艅썬╉ゃ,,navict-recommenderⓦAPImap(async()=>{})ㅳｃ╉艅썬╉ゃ 
165500,165500,184008,https://api.github.com/repos/VikeLabs/clockwork/issues/75,1.0,2021-03-14T17:07:24Z,NONE,https://api.github.com/repos/VikeLabs/clockwork,Bookmarking course should save course to local storage,"When a user bookmarks a course, the course should be saved to [local browser storage](https://www.robinwieruch.de/local-storage-react) so the bookmarked courses can be persisted between browser sessions, without the user needing an account. It would be nice if there was a button to clear all bookmarked courses also developed for this issue. There should be an option to hide this button on the UI so we can turn it off in the staging env. Maybe the button would just go in the navbar for now.

Off the top of my head, a simple way to implement this would be to store an array of bookmarked courses in local storage. Each course in this array can be indexed on its term, subject, and code. ","Bookmarking course should save course to local storage When a user bookmarks a course, the course should be saved to [local browser storage](https://www.robinwieruch.de/local-storage-react) so the bookmarked courses can be persisted between browser sessions, without the user needing an account. It would be nice if there was a button to clear all bookmarked courses also developed for this issue. There should be an option to hide this button on the UI so we can turn it off in the staging env. Maybe the button would just go in the navbar for now. Off the top of my head, a simple way to implement this would be to store an array of bookmarked courses in local storage. Each course in this array can be indexed on its term, subject, and code. "
136118,136118,151303,https://api.github.com/repos/franko/lite-xl/issues/79,0.0,2021-03-05T14:00:18Z,NONE,https://api.github.com/repos/franko/lite-xl,"Plugin ""Console"" doesn't work","Unfortunately plugin ""Console"" doesn't work on lite-xl.
Did someone try to fix it for lite-xl?
Thanks! ","Plugin ""Console"" doesn't work Unfortunately plugin ""Console"" doesn't work on lite-xl. Did someone try to fix it for lite-xl? Thanks! "
49775,49775,55385,https://api.github.com/repos/fossasia/open-event-frontend/issues/5143,0.0,2020-09-25T02:58:34Z,MEMBER,https://api.github.com/repos/fossasia/open-event-frontend,"Wizard Step 1: Map not loading, Address field issues, public page only shows address in one line","The wizard step 1 location field has a few issues.
* Map is no longer loading even if enable
* Reset Map link deletes all data in address fields
* After saving and editing the form and reopening it the address fields only show up in the address line but on expansion they do not show up in the dedicated fields (stress, city, postcode, country)
* As a result the address on the public page also shows up in one line instead of different lines for name, street, city, country

Please fix these issues as part of moving the implementation to OpenStreetMap/Mapbox.
Take out the Google map code from the project and ensure there are no console errors.

![Screenshot from 2020-09-25 04-52-46](https://user-images.githubusercontent.com/1583873/94221542-9cd20280-feeb-11ea-9f4a-c4da6c4b418d.png)
![Screenshot from 2020-09-25 04-51-43](https://user-images.githubusercontent.com/1583873/94221549-9e9bc600-feeb-11ea-8aa7-12b5bac5fe07.png)

![Screenshot from 2020-09-25 04-57-48](https://user-images.githubusercontent.com/1583873/94221595-b8d5a400-feeb-11ea-8524-437b88ed6245.png)
","Wizard Step 1: Map not loading, Address field issues, public page only shows address in one line The wizard step 1 location field has a few issues. * Map is no longer loading even if enable * Reset Map link deletes all data in address fields * After saving and editing the form and reopening it the address fields only show up in the address line but on expansion they do not show up in the dedicated fields (stress, city, postcode, country) * As a result the address on the public page also shows up in one line instead of different lines for name, street, city, country Please fix these issues as part of moving the implementation to OpenStreetMap/Mapbox. Take out the Google map code from the project and ensure there are no console errors. ![Screenshot from 2020-09-25 04-52-46](https://user-images.githubusercontent.com/1583873/94221542-9cd20280-feeb-11ea-9f4a-c4da6c4b418d.png) ![Screenshot from 2020-09-25 04-51-43](https://user-images.githubusercontent.com/1583873/94221549-9e9bc600-feeb-11ea-8aa7-12b5bac5fe07.png) ![Screenshot from 2020-09-25 04-57-48](https://user-images.githubusercontent.com/1583873/94221595-b8d5a400-feeb-11ea-8524-437b88ed6245.png) "
174034,174034,193523,https://api.github.com/repos/wyskoj/midis2jam2/issues/11,0.0,2021-04-02T21:17:16Z,OWNER,https://api.github.com/repos/wyskoj/midis2jam2,Mallet shadows are broken,"For some reason, only sometimes mallet shadows won't appear properly.
![image](https://user-images.githubusercontent.com/31376393/113454749-f5bcaf00-93d6-11eb-841e-c95a0559cb89.png)
","Mallet shadows are broken For some reason, only sometimes mallet shadows won't appear properly. ![image](https://user-images.githubusercontent.com/31376393/113454749-f5bcaf00-93d6-11eb-841e-c95a0559cb89.png) "
362402,362402,402869,https://api.github.com/repos/rpav/c2ffi/issues/35,0.0,2016-06-18T16:16:39Z,NONE,https://api.github.com/repos/rpav/c2ffi,C2FFI Generates Invalid Macro File for GStreamer,"I'm trying to use cl-autowrap (and thus c2ffi) to generate wrappers for GStreamer 1.0. Unfortunately, c2ffi crashes with a segfault in the process of this. I'm not sure if this is due to a fault on my behalf or if the gstreamer headers are simply too complex to grok.

The cl-autowrap call I'm using is:

```
(autowrap:c-include
 ""/usr/include/gstreamer-0.10/gst/gst.h""
 :sysincludes '(""/usr/include/gstreamer-0.10""
                ""/usr/include/glib-2.0""
                ""/usr/lib/glib-2.0/include""
                ""/usr/include/libxml2"")
 :trace-c2ffi cl:T)
```

Which executes the following two c2ffi calls, the first of which succeeds, and the second of which produces a long, long stream of errors which presumably originate from Clang.

```
c2ffi /usr/include/gstreamer-1.0/gst/gst.h -D null -M /tmp/tmpP44I4E0Y.tmp -A x86_64-pc-linux-gnu -i /usr/include/gstreamer-1.0 -i /usr/include/glib-2.0 -i /usr/lib/gstreamer-1.0/include -i /usr/lib/glib-2.0/include
c2ffi /tmp/tmpP44I4E0Y.tmp -o ~/gst.x86_64-pc-linux-gnu.spec -A x86_64-pc-linux-gnu -i /usr/include/gstreamer-1.0 -i /usr/include/glib-2.0 -i /usr/lib/gstreamer-1.0/include -i /usr/lib/glib-2.0/include
```

Since the error output is so long I've [attached it](https://github.com/rpav/c2ffi/files/321842/a.txt). I'm running the latest Quicklisp cl-autowrap, freshly cloned c2ffi and compiled it with Clang 3.7.

Any pointers as to what I could do to get this working would be much appreciated.
","C2FFI Generates Invalid Macro File for GStreamer I'm trying to use cl-autowrap (and thus c2ffi) to generate wrappers for GStreamer 1.0. Unfortunately, c2ffi crashes with a segfault in the process of this. I'm not sure if this is due to a fault on my behalf or if the gstreamer headers are simply too complex to grok. The cl-autowrap call I'm using is: ``` (autowrap:c-include ""/usr/include/gstreamer-0.10/gst/gst.h"" :sysincludes '(""/usr/include/gstreamer-0.10"" ""/usr/include/glib-2.0"" ""/usr/lib/glib-2.0/include"" ""/usr/include/libxml2"") :trace-c2ffi cl:T) ``` Which executes the following two c2ffi calls, the first of which succeeds, and the second of which produces a long, long stream of errors which presumably originate from Clang. ``` c2ffi /usr/include/gstreamer-1.0/gst/gst.h -D null -M /tmp/tmpP44I4E0Y.tmp -A x86_64-pc-linux-gnu -i /usr/include/gstreamer-1.0 -i /usr/include/glib-2.0 -i /usr/lib/gstreamer-1.0/include -i /usr/lib/glib-2.0/include c2ffi /tmp/tmpP44I4E0Y.tmp -o ~/gst.x86_64-pc-linux-gnu.spec -A x86_64-pc-linux-gnu -i /usr/include/gstreamer-1.0 -i /usr/include/glib-2.0 -i /usr/lib/gstreamer-1.0/include -i /usr/lib/glib-2.0/include ``` Since the error output is so long I've [attached it](https://github.com/rpav/c2ffi/files/321842/a.txt). I'm running the latest Quicklisp cl-autowrap, freshly cloned c2ffi and compiled it with Clang 3.7. Any pointers as to what I could do to get this working would be much appreciated. "
315964,315964,351272,https://api.github.com/repos/helgoboss/realearn/issues/180,0.0,2021-02-26T10:15:44Z,OWNER,https://api.github.com/repos/helgoboss/realearn,"Fluctuating feedback for ""Selected track"" target",,"Fluctuating feedback for ""Selected track"" target "
320521,320521,356314,https://api.github.com/repos/austinhuang0131/barinsta/issues/79,1.0,2020-08-26T23:39:14Z,NONE,https://api.github.com/repos/austinhuang0131/barinsta,[FTR] DM voice support,"Its not showing tagged people and cant play DM audios... If it possible to add send voice message feature, I'll removed original Instagram app...
Share story,photo and videos I can do from browser but its not playing and sending voice messages...
Thanks for great work!","[FTR] DM voice support Its not showing tagged people and cant play DM audios... If it possible to add send voice message feature, I'll removed original Instagram app... Share story,photo and videos I can do from browser but its not playing and sending voice messages... Thanks for great work!"
370872,370872,412283,https://api.github.com/repos/FusionAuth/charts/issues/50,1.0,2021-05-12T06:58:48Z,CONTRIBUTOR,https://api.github.com/repos/FusionAuth/charts,Add extraVolumeMounts and extraVolumes to  store custom css ,"Hi,

I would like to be able to mount an additional volume on 
/usr/local/fusionauth/fusionauth-app/web/custom

If the Helm chart had extraVolumeMounts and extraVolumes I could do this.


example on values.yaml

```
extraVolumes: []
##  - name: custom-css-data
##    persistentVolumeClaim:
##      claimName: custom-css-data

extraVolumeMounts: []
##   - name: custom-css-data
##     mountPath: /usr/local/fusionauth/fusionauth-app/web/custom
```



","Add extraVolumeMounts and extraVolumes to store custom css Hi, I would like to be able to mount an additional volume on /usr/local/fusionauth/fusionauth-app/web/custom If the Helm chart had extraVolumeMounts and extraVolumes I could do this. example on values.yaml ``` extraVolumes: [] ## - name: custom-css-data ## persistentVolumeClaim: ## claimName: custom-css-data extraVolumeMounts: [] ## - name: custom-css-data ## mountPath: /usr/local/fusionauth/fusionauth-app/web/custom ``` "
81221,81221,90288,https://api.github.com/repos/nicehash/NiceHashQuickMiner/issues/8,1.0,2021-02-12T19:47:41Z,NONE,https://api.github.com/repos/nicehash/NiceHashQuickMiner,AMD GPUs support Please,I really think this is an awesome project you guys put together and I am hoping you will support AMD GPUs too.  If so please let us know.  Team Red would love to know.,AMD GPUs support Please I really think this is an awesome project you guys put together and I am hoping you will support AMD GPUs too. If so please let us know. Team Red would love to know.
44054,44054,49037,https://api.github.com/repos/srobo/astoria/issues/57,1.0,2021-05-12T17:36:55Z,MEMBER,https://api.github.com/repos/srobo/astoria,Add extra WiFi info to bundle format,"We need to be able to set and compare the following extra attributes:

- WiFi region (what are valid values for this?)
- WiFi Client / AP mode (i.e connect to arena)
- WiFi enabled / disabled - we may want to disable the wifi.

These are defined in the `Metadata` schema. 
https://github.com/srobo/astoria/blob/fbcf065436411cb37faa57f46ac37d6760daf4f7/astoria/common/messages/astmetad.py#L61

",Add extra WiFi info to bundle format We need to be able to set and compare the following extra attributes: - WiFi region (what are valid values for this?) - WiFi Client / AP mode (i.e connect to arena) - WiFi enabled / disabled - we may want to disable the wifi. These are defined in the `Metadata` schema. https://github.com/srobo/astoria/blob/fbcf065436411cb37faa57f46ac37d6760daf4f7/astoria/common/messages/astmetad.py#L61 
222060,222060,246939,https://api.github.com/repos/mint-lang/mint/issues/376,0.0,2021-02-23T03:40:56Z,CONTRIBUTOR,https://api.github.com/repos/mint-lang/mint,User friendly error messages for some crystal exceptions.,"If a user were to delete the `assets/head.html` file but not remove the `  ""application"": { ""head"": ""assets/head.html"",` entry in their `mint.json` file they'll be greeted with this stack trace:
```
Unhandled exception: Missing hash key: ""snippet"" (KeyError)
  from raise<KeyError>:NoReturn
  from Hash(String, Array(Mint::TypeChecker::Record | Mint::TypeChecker::Type | Mint::TypeChecker::Variable) | Array(String) | Mint::Ast::Node | Mint::TypeChecker::Record | Mint::TypeChecker::Type | Mint::TypeChecker::Variable | String | Tuple(Mint::Ast::Node, Int32))+@Hash(K, V)#[]<String>:(Array(Mint::TypeChecker::Record+ | Mint::TypeChecker::Type | Mint::TypeChecker::Variable) | Array(String) | Mint::Ast::Node+ | Mint::TypeChecker::Record+ | Mint::TypeChecker::Type | Mint::TypeChecker::Variable | String | Tuple(Mint::Ast::Node+, Int32))
  from Mint::Messages::MintJsonHeadNotExists#build:Array(Array(Mint::Message::Bold | Mint::Message::Code | Mint::Message::Text) | Mint::Message::Pre | Mint::Message::Snippet | Mint::Message::StringList | Mint::Message::Title | Mint::Message::Type | Mint::Message::TypeList)
  from Mint::Message+@Mint::Message#render<Mint::Render::Terminal>:IO+
  from Mint::Cli::SubCommands#invoke:parent<Array(Admiral::StringValue), Mint::Cli>:Nil
  from Mint::Cli#parse_and_run:Nil
  from __crystal_main
  from main
```

Which has the relevant exception `MintJsonHeadNotExists` burred there in the middle somewhere. I actually couldn't figure out what was going wrong and installed crystal, built mint from master, still had this problem, then searched around mint's codebase for a while until I found this https://github.com/mint-lang/mint/blob/master/src/mint_json.cr#L161 which led me to understanding this stack trace a little better.

Would it be possible to catch exceptions like these somewhere and display more user friendly error messages?

Something like:
```
Your mint.json file specifies extra head content at assets/head.html but that file doesn't exist.
Please create that file or remove the entry from mint.json
```


","User friendly error messages for some crystal exceptions. If a user were to delete the `assets/head.html` file but not remove the ` ""application"": { ""head"": ""assets/head.html"",` entry in their `mint.json` file they'll be greeted with this stack trace: ``` Unhandled exception: Missing hash key: ""snippet"" (KeyError) from raise<KeyError>:NoReturn from Hash(String, Array(Mint::TypeChecker::Record | Mint::TypeChecker::Type | Mint::TypeChecker::Variable) | Array(String) | Mint::Ast::Node | Mint::TypeChecker::Record | Mint::TypeChecker::Type | Mint::TypeChecker::Variable | String | Tuple(Mint::Ast::Node, Int32))+@Hash(K, V)#[]<String>:(Array(Mint::TypeChecker::Record+ | Mint::TypeChecker::Type | Mint::TypeChecker::Variable) | Array(String) | Mint::Ast::Node+ | Mint::TypeChecker::Record+ | Mint::TypeChecker::Type | Mint::TypeChecker::Variable | String | Tuple(Mint::Ast::Node+, Int32)) from Mint::Messages::MintJsonHeadNotExists#build:Array(Array(Mint::Message::Bold | Mint::Message::Code | Mint::Message::Text) | Mint::Message::Pre | Mint::Message::Snippet | Mint::Message::StringList | Mint::Message::Title | Mint::Message::Type | Mint::Message::TypeList) from Mint::Message+@Mint::Message#render<Mint::Render::Terminal>:IO+ from Mint::Cli::SubCommands#invoke:parent<Array(Admiral::StringValue), Mint::Cli>:Nil from Mint::Cli#parse_and_run:Nil from __crystal_main from main ``` Which has the relevant exception `MintJsonHeadNotExists` burred there in the middle somewhere. I actually couldn't figure out what was going wrong and installed crystal, built mint from master, still had this problem, then searched around mint's codebase for a while until I found this https://github.com/mint-lang/mint/blob/master/src/mint_json.cr#L161 which led me to understanding this stack trace a little better. Would it be possible to catch exceptions like these somewhere and display more user friendly error messages? Something like: ``` Your mint.json file specifies extra head content at assets/head.html but that file doesn't exist. Please create that file or remove the entry from mint.json ``` "
440709,440709,489945,https://api.github.com/repos/canada-ca/aia-eia-js/issues/616,0.0,2021-03-04T23:44:53Z,CONTRIBUTOR,https://api.github.com/repos/canada-ca/aia-eia-js,PDF duplicates project details,The PDF output duplicates the project between between section 2 and 3.,PDF duplicates project details The PDF output duplicates the project between between section 2 and 3.
630844,630844,701092,https://api.github.com/repos/12rambau/gwb/issues/32,0.0,2021-04-13T09:33:49Z,CONTRIBUTOR,https://api.github.com/repos/12rambau/gwb,downloads folder not showing,"In the GWB-APP module interface and after having clicked on the button: DOWNLOAD TEST DATASET: the two images are downloaded correctly in ~/downloads/. But in the next step, when clicking on the button SEARCH FILE, the directory ""downloads"" is not listed (also after clicking the reload button), so the example input images can not be selected this way.
![Screenshot 2021-04-13 at 11 31 15](https://user-images.githubusercontent.com/68806384/114531333-180ec200-9c4c-11eb-8e8e-dbc2778fc6c4.png)
  ","downloads folder not showing In the GWB-APP module interface and after having clicked on the button: DOWNLOAD TEST DATASET: the two images are downloaded correctly in ~/downloads/. But in the next step, when clicking on the button SEARCH FILE, the directory ""downloads"" is not listed (also after clicking the reload button), so the example input images can not be selected this way. ![Screenshot 2021-04-13 at 11 31 15](https://user-images.githubusercontent.com/68806384/114531333-180ec200-9c4c-11eb-8e8e-dbc2778fc6c4.png) "
706911,706911,785674,https://api.github.com/repos/dkbaffour777/work-day-scheduler/issues/1,1.0,2021-04-09T18:22:31Z,OWNER,https://api.github.com/repos/dkbaffour777/work-day-scheduler,Display time,"* Display the current day
* Display time blocks for standard business hours

",Display time * Display the current day * Display time blocks for standard business hours 
547849,547849,608918,https://api.github.com/repos/ClickHouse/ClickHouse/issues/21008,2.0,2021-02-20T14:40:23Z,NONE,https://api.github.com/repos/ClickHouse/ClickHouse,design table for customer,"hi team
I have a customer table like
```sql
create table customer (
storeId  String,
customerId String,
createDate UInt64,
updateDate UInt64,
type UInt8,
status UInt8,
birthDay UInt64,
date Date default toDate(createDate/1000)
) engine = MergeTree ...
```
I have more than 10000 stores and much more customers, I will query the customer with storeId or type but not createDate or some other date.

I'm confused how to design partition key for the table. I don't use date to query and the number of stores is to much.
And I can't use a single partition because of much data

Have any suggestions? thanks
","design table for customer hi team I have a customer table like ```sql create table customer ( storeId String, customerId String, createDate UInt64, updateDate UInt64, type UInt8, status UInt8, birthDay UInt64, date Date default toDate(createDate/1000) ) engine = MergeTree ... ``` I have more than 10000 stores and much more customers, I will query the customer with storeId or type but not createDate or some other date. I'm confused how to design partition key for the table. I don't use date to query and the number of stores is to much. And I can't use a single partition because of much data Have any suggestions? thanks "
634607,634607,705313,https://api.github.com/repos/cassandre-tech/cassandre-trading-bot/issues/561,1.0,2021-04-20T16:03:35Z,COLLABORATOR,https://api.github.com/repos/cassandre-tech/cassandre-trading-bot,Refactor Autoconfiguration,,Refactor Autoconfiguration 
757423,757423,343171,https://api.github.com/repos/wez/wezterm/issues/471,0.0,2021-02-09T20:20:21Z,NONE,https://api.github.com/repos/wez/wezterm,Arch AUR installation doesn't work,"## Describe the bug

Arch AUR pacakge `wezterm-bin` fails to install

## Environment (please complete the following information):

 - OS: EndeavourOS [Arch]

## To Reproduce

Steps to reproduce the behavior.

Execure following command to install `yay -Sy wezterm-bin`

```
:: Checking for conflicts...
:: Checking for inner conflicts...
[Aur:1]  wezterm-bin-20210203.095643.70a364eb-2

:: Downloaded PKGBUILD (1/1): wezterm-bin
  1 wezterm-bin                      (Build Files Exist)
==> Diffs to show?
==> [N]one [A]ll [Ab]ort [I]nstalled [No]tInstalled or (1 2 3, 1-3, ^4)
==> 
:: (1/1) Parsing SRCINFO: wezterm-bin
==> Making package: wezterm-bin 20210203.095643.70a364eb-2 (勻, 09-剋-2021 22:07:30 +0200)
==> Retrieving sources...
  -> Downloading wezterm...
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   661  100   661    0     0   1694      0 --:--:-- --:--:-- --:--:--  1694
100 29.1M  100 29.1M    0     0  3002k      0  0:00:09  0:00:09 --:--:-- 2866k
  -> Downloading LICENSE...
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
curl: (22) The requested URL returned error: 404
==> ERROR: Failure while downloading https://github.com/wez/wezterm/raw/master/LICENSE.md
    Aborting...
error downloading sources: wezterm-bin
```

","Arch AUR installation doesn't work ## Describe the bug Arch AUR pacakge `wezterm-bin` fails to install ## Environment (please complete the following information): - OS: EndeavourOS [Arch] ## To Reproduce Steps to reproduce the behavior. Execure following command to install `yay -Sy wezterm-bin` ``` :: Checking for conflicts... :: Checking for inner conflicts... [Aur:1] wezterm-bin-20210203.095643.70a364eb-2 :: Downloaded PKGBUILD (1/1): wezterm-bin 1 wezterm-bin (Build Files Exist) ==> Diffs to show? ==> [N]one [A]ll [Ab]ort [I]nstalled [No]tInstalled or (1 2 3, 1-3, ^4) ==> :: (1/1) Parsing SRCINFO: wezterm-bin ==> Making package: wezterm-bin 20210203.095643.70a364eb-2 (勻, 09-剋-2021 22:07:30 +0200) ==> Retrieving sources... -> Downloading wezterm... % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 100 661 100 661 0 0 1694 0 --:--:-- --:--:-- --:--:-- 1694 100 29.1M 100 29.1M 0 0 3002k 0 0:00:09 0:00:09 --:--:-- 2866k -> Downloading LICENSE... % Total % Received % Xferd Average Speed Time Time Time Current Dload Upload Total Spent Left Speed 0 0 0 0 0 0 0 0 --:--:-- --:--:-- --:--:-- 0 curl: (22) The requested URL returned error: 404 ==> ERROR: Failure while downloading https://github.com/wez/wezterm/raw/master/LICENSE.md Aborting... error downloading sources: wezterm-bin ``` "
249494,249494,277516,https://api.github.com/repos/IBM/kui/issues/6476,0.0,2021-01-04T22:24:46Z,MEMBER,https://api.github.com/repos/IBM/kui,new kubectl direct logic does not properly handle ECONNREFUSED,The error handling logic for some reason is 404 specific.,new kubectl direct logic does not properly handle ECONNREFUSED The error handling logic for some reason is 404 specific.
214109,214109,238093,https://api.github.com/repos/geopandas/geopandas/issues/1814,1.0,2021-02-03T16:31:46Z,NONE,https://api.github.com/repos/geopandas/geopandas,ENH: Expose dropna keyword in dissolve (Null values disappear),"#### Question about geopandas

## CODE
```py
import geopandas

shp = r""C:\Users\LEBPH5\Desktop\carte_a_jour\Donnees_test\histo_majf.shp""
outfc = r""C:\Users\LEBPH5\Desktop\carte_a_jour\Donnees_test\HISTO_MAJF_2018_Dissolved.shp""
fields = 'ORIGINE'

layer = geopandas.read_file(shp)
dissolved = layer.dissolve(by=fields)
dissolved.to_file(outfc, driver=""ESRI Shapefile"")
```

## PROBLEM
When I try to dissolve a shapefile by a field with some NULL values, the NULL values disappear in the result shapefile. 


## QUESTION

I want to keep the Null values in the result file and I want the Null values to be dissolved.
I found a method that work. I can calculate a string (example 'NA') for the Null values and after dissolve my shapefile. And after the dissolve, recalculate the value 'NA' to Null but it can be very long because I have large dataset to treat.

It's there a way to do it directly with geopandas? thank you





## IMAGES

![hist_maj_table](https://user-images.githubusercontent.com/59576399/106777357-ec030f00-6612-11eb-9ea9-3318abe2ea0f.JPG)
![HISTO_MAJF_2018_Dissolved_Table](https://user-images.githubusercontent.com/59576399/106777360-ec9ba580-6612-11eb-9fca-01048f6d1b56.JPG)
![Missing_null](https://user-images.githubusercontent.com/59576399/106777361-ec9ba580-6612-11eb-906e-e11079e8f4ee.JPG)

","ENH: Expose dropna keyword in dissolve (Null values disappear) #### Question about geopandas ## CODE ```py import geopandas shp = r""C:\Users\LEBPH5\Desktop\carte_a_jour\Donnees_test\histo_majf.shp"" outfc = r""C:\Users\LEBPH5\Desktop\carte_a_jour\Donnees_test\HISTO_MAJF_2018_Dissolved.shp"" fields = 'ORIGINE' layer = geopandas.read_file(shp) dissolved = layer.dissolve(by=fields) dissolved.to_file(outfc, driver=""ESRI Shapefile"") ``` ## PROBLEM When I try to dissolve a shapefile by a field with some NULL values, the NULL values disappear in the result shapefile. ## QUESTION I want to keep the Null values in the result file and I want the Null values to be dissolved. I found a method that work. I can calculate a string (example 'NA') for the Null values and after dissolve my shapefile. And after the dissolve, recalculate the value 'NA' to Null but it can be very long because I have large dataset to treat. It's there a way to do it directly with geopandas? thank you ## IMAGES ![hist_maj_table](https://user-images.githubusercontent.com/59576399/106777357-ec030f00-6612-11eb-9ea9-3318abe2ea0f.JPG) ![HISTO_MAJF_2018_Dissolved_Table](https://user-images.githubusercontent.com/59576399/106777360-ec9ba580-6612-11eb-9fca-01048f6d1b56.JPG) ![Missing_null](https://user-images.githubusercontent.com/59576399/106777361-ec9ba580-6612-11eb-906e-e11079e8f4ee.JPG) "
400781,400781,445456,https://api.github.com/repos/Axway-API-Management-Plus/apigateway-openlogging-elk/issues/88,0.0,2021-03-18T15:42:03Z,CONTRIBUTOR,https://api.github.com/repos/Axway-API-Management-Plus/apigateway-openlogging-elk,Playload not vissible for restricted users,"**Axway APIM-ELK version**
2.1.2

**API-Manager Version**
7.7-September 2020

**Expected behavior**
Restricted users should be able to see their payload information.

**Actual behavior**
A 403 is returned on the payload request for restricted users.",Playload not vissible for restricted users **Axway APIM-ELK version** 2.1.2 **API-Manager Version** 7.7-September 2020 **Expected behavior** Restricted users should be able to see their payload information. **Actual behavior** A 403 is returned on the payload request for restricted users.
597610,597610,664140,https://api.github.com/repos/W01fw00d/barbarians/issues/102,1.0,2021-05-09T02:25:45Z,OWNER,https://api.github.com/repos/W01fw00d/barbarians,Allow user to move soldiers using draggable,https://www.w3schools.com/tags/tryit.asp?filename=tryhtml5_global_draggable,Allow user to move soldiers using draggable https://www.w3schools.com/tags/tryit.asp?filename=tryhtml5_global_draggable
201199,201199,223714,https://api.github.com/repos/amcharts/amcharts4/issues/3295,2.0,2021-02-11T08:12:29Z,NONE,https://api.github.com/repos/amcharts/amcharts4,Chord diagram tooltip appears for deactivated groups,"**Bug description**
When moving the cursor over the connections between groups the tooltip appears for all of the possible combinations instead of just showing the connections between the still activated groups. It is difficult to find the desired tooltip between two groups when there are multiple combinations. 

<!---
A clear and concise description of what the bug is, as well as steps needed to reproduce it.

If you think posting a few lines of code would help do it. Otherwise, please consider going one step further by providing a working example. A live demo will make so much easier for the dev team to locate the bug and fix it faster.

For vanilla JavaScript examples use:
CodePen (https://codepen.io/)
jsFiddle (https://jsfiddle.net/)

For TypeScript/Angular/React use:
CodeSandbox (https://codesandbox.io/)
StackBlitz (https://stackblitz.com/).
-->

**Environment (if applicable)**

<!---
Provide details about your development environment where you think it might be useful. E.g.:

 - amCharts version
 - Browser and its version
 - Related frameworks and their versions [e.g. Angular, TypeScript, etc.]
-->

**Additional context**

<!---
Add any other context about the problem here.
-->
","Chord diagram tooltip appears for deactivated groups **Bug description** When moving the cursor over the connections between groups the tooltip appears for all of the possible combinations instead of just showing the connections between the still activated groups. It is difficult to find the desired tooltip between two groups when there are multiple combinations. <!--- A clear and concise description of what the bug is, as well as steps needed to reproduce it. If you think posting a few lines of code would help do it. Otherwise, please consider going one step further by providing a working example. A live demo will make so much easier for the dev team to locate the bug and fix it faster. For vanilla JavaScript examples use: CodePen (https://codepen.io/) jsFiddle (https://jsfiddle.net/) For TypeScript/Angular/React use: CodeSandbox (https://codesandbox.io/) StackBlitz (https://stackblitz.com/). --> **Environment (if applicable)** <!--- Provide details about your development environment where you think it might be useful. E.g.: - amCharts version - Browser and its version - Related frameworks and their versions [e.g. Angular, TypeScript, etc.] --> **Additional context** <!--- Add any other context about the problem here. --> "
343330,343330,381661,https://api.github.com/repos/infinyon/fluvio/issues/922,0.0,2021-04-04T04:01:03Z,COLLABORATOR,https://api.github.com/repos/infinyon/fluvio,SPU fail over result in over-duplicate of records,"## Steps to reproduce it:

Create cluster with 2 SPU:
```
$ fluvio cluster start --local --develop --spu 2
```

Create topic with 2 replica:
```
$ fluvio topic create test -r 2
```

Produce a simple message:
```
$ flvd produce test
> hello world
Ok!
^c
```

Message are properly replicated:
```
$ fluvio partition list
 TOPIC  PARTITION  LEADER  REPLICAS  RESOLUTION  HW  LEO  LSR  FOLLOWER OFFSETS 
 test   0          5001    [5002]    Online      1   1    1    [ReplicaStatus { spu: 5002, hw: 1, leo: 1 }]
```

Kill leader SPU:
```
$ ps -ef | grep fluvio
ubuntu    757737       1  0 03:57 pts/2    00:00:00 /home/ubuntu/fluvio/target/debug/fluvio cluster run sc
ubuntu    757747       1  0 03:57 pts/2    00:00:00 /home/ubuntu/fluvio/target/debug/fluvio cluster run spu -i 5001 -p 0.0.0.0:9010 -v 0.0.0.0:9011 --log-base-dir /tmp/fluvio
ubuntu    757759       1  0 03:57 pts/2    00:00:00 /home/ubuntu/fluvio/target/debug/fluvio cluster run spu -i 5002 -p 0.0.0.0:9020 -v 0.0.0.0:9021 --log-base-dir /tmp/fluvio
ubuntu    758282  723803  0 03:58 pts/10   00:00:00 grep --color=auto fluvio

$ kill -9 757747
```

Leader SPU is terminated:
```
$ fluvio cluster spu list
 ID    NAME             STATUS   TYPE      RACK  PUBLIC          PRIVATE 
 5001  custom-spu-5001  Offline  ""custom""   -    localhost:9010  localhost:9011 
 5002  custom-spu-5002  Online   ""custom""   -    localhost:9020  localhost:9021
```
But then records are over replicated:

```
$ fluvio partition list
 TOPIC  PARTITION  LEADER  REPLICAS  RESOLUTION  HW  LEO  LSR  FOLLOWER OFFSETS 
 test   0          5002    [5001]    Online      1   4    0    [ReplicaStatus { spu: 5001, hw: 1, leo: 1 }] 
```
","SPU fail over result in over-duplicate of records ## Steps to reproduce it: Create cluster with 2 SPU: ``` $ fluvio cluster start --local --develop --spu 2 ``` Create topic with 2 replica: ``` $ fluvio topic create test -r 2 ``` Produce a simple message: ``` $ flvd produce test > hello world Ok! ^c ``` Message are properly replicated: ``` $ fluvio partition list TOPIC PARTITION LEADER REPLICAS RESOLUTION HW LEO LSR FOLLOWER OFFSETS test 0 5001 [5002] Online 1 1 1 [ReplicaStatus { spu: 5002, hw: 1, leo: 1 }] ``` Kill leader SPU: ``` $ ps -ef | grep fluvio ubuntu 757737 1 0 03:57 pts/2 00:00:00 /home/ubuntu/fluvio/target/debug/fluvio cluster run sc ubuntu 757747 1 0 03:57 pts/2 00:00:00 /home/ubuntu/fluvio/target/debug/fluvio cluster run spu -i 5001 -p 0.0.0.0:9010 -v 0.0.0.0:9011 --log-base-dir /tmp/fluvio ubuntu 757759 1 0 03:57 pts/2 00:00:00 /home/ubuntu/fluvio/target/debug/fluvio cluster run spu -i 5002 -p 0.0.0.0:9020 -v 0.0.0.0:9021 --log-base-dir /tmp/fluvio ubuntu 758282 723803 0 03:58 pts/10 00:00:00 grep --color=auto fluvio $ kill -9 757747 ``` Leader SPU is terminated: ``` $ fluvio cluster spu list ID NAME STATUS TYPE RACK PUBLIC PRIVATE 5001 custom-spu-5001 Offline ""custom"" - localhost:9010 localhost:9011 5002 custom-spu-5002 Online ""custom"" - localhost:9020 localhost:9021 ``` But then records are over replicated: ``` $ fluvio partition list TOPIC PARTITION LEADER REPLICAS RESOLUTION HW LEO LSR FOLLOWER OFFSETS test 0 5002 [5001] Online 1 4 0 [ReplicaStatus { spu: 5001, hw: 1, leo: 1 }] ``` "
236467,236467,263012,https://api.github.com/repos/wsdfhjxc/virtual-desktop-bar/issues/55,0.0,2021-02-23T20:33:32Z,NONE,https://api.github.com/repos/wsdfhjxc/virtual-desktop-bar,Add/Remove desktop greyed out,"I'm using this on Debian Testing and latte-dock. For some reason the buttons `Remove Desktop` `Add Desktop` and `Remove Last Desktop` are greyed out and unusable. I just made sure it was updated to latest and reinstalled it, but no change.","Add/Remove desktop greyed out I'm using this on Debian Testing and latte-dock. For some reason the buttons `Remove Desktop` `Add Desktop` and `Remove Last Desktop` are greyed out and unusable. I just made sure it was updated to latest and reinstalled it, but no change."
283771,283771,315586,https://api.github.com/repos/motypes/eval-cso/issues/223,0.0,2021-03-22T15:14:31Z,COLLABORATOR,https://api.github.com/repos/motypes/eval-cso,Drop down for agents on Data Table  is omitted,"![Screenshot from 2021-03-22 17-59-30](https://user-images.githubusercontent.com/24989409/112011188-12d0c280-8b39-11eb-946a-75bef5698888.png)
Agent search options are commented  out for the code to work
![WhatsApp Image 2021-03-22 at 18 12 04](https://user-images.githubusercontent.com/24989409/112012427-3f390e80-8b3a-11eb-93a8-bc4287e441c3.jpeg)
",Drop down for agents on Data Table is omitted ![Screenshot from 2021-03-22 17-59-30](https://user-images.githubusercontent.com/24989409/112011188-12d0c280-8b39-11eb-946a-75bef5698888.png) Agent search options are commented out for the code to work ![WhatsApp Image 2021-03-22 at 18 12 04](https://user-images.githubusercontent.com/24989409/112012427-3f390e80-8b3a-11eb-93a8-bc4287e441c3.jpeg) 
570585,570585,634073,https://api.github.com/repos/E3SM-Project/E3SM/issues/3160,0.0,2019-08-28T16:14:19Z,CONTRIBUTOR,https://api.github.com/repos/E3SM-Project/E3SM,Bug in modal_aer_opt.F90,"In the MAM verification work, we (@jiansunpnnl @kaizhangpnl) find that in modal_aer_opt.F90 (https://github.com/E3SM-Project/E3SM/blob/master/components/cam/src/physics/cam/modal_aer_opt.F90), the marine organic aerosol (MOA) burden fields are initialized twice, but the MOA AOD properties are not initialized. This looks like a bug and needs to be fixed. 

#if ( defined MODAL_AERO_4MODE_MOM )
   burdenmom(:ncol)      = 0.0_r8
#elif ( defined MODAL_AERO_9MODE )
   burdenpoly(:ncol)     = 0.0_r8
   burdenprot(:ncol)     = 0.0_r8
   burdenlip(:ncol)      = 0.0_r8
#endif
   ssavis(1:ncol)        = 0.0_r8

   aodabsbc(:ncol)       = 0.0_r8 
   dustaod(:ncol)        = 0.0_r8
   so4aod(:ncol)         = 0.0_r8
   pomaod(:ncol)         = 0.0_r8
   soaaod(:ncol)         = 0.0_r8
   bcaod(:ncol)          = 0.0_r8
   seasaltaod(:ncol)     = 0.0_r8

**#if ( defined MODAL_AERO_4MODE_MOM )
   burdenmom(:ncol)      = 0.0_r8
#elif ( defined MODAL_AERO_9MODE )
   burdenpoly(:ncol)     = 0.0_r8
   burdenprot(:ncol)     = 0.0_r8
   burdenlip(:ncol)      = 0.0_r8
#endif**

","Bug in modal_aer_opt.F90 In the MAM verification work, we (@jiansunpnnl @kaizhangpnl) find that in modal_aer_opt.F90 (https://github.com/E3SM-Project/E3SM/blob/master/components/cam/src/physics/cam/modal_aer_opt.F90), the marine organic aerosol (MOA) burden fields are initialized twice, but the MOA AOD properties are not initialized. This looks like a bug and needs to be fixed. #if ( defined MODAL_AERO_4MODE_MOM ) burdenmom(:ncol) = 0.0_r8 #elif ( defined MODAL_AERO_9MODE ) burdenpoly(:ncol) = 0.0_r8 burdenprot(:ncol) = 0.0_r8 burdenlip(:ncol) = 0.0_r8 #endif ssavis(1:ncol) = 0.0_r8 aodabsbc(:ncol) = 0.0_r8 dustaod(:ncol) = 0.0_r8 so4aod(:ncol) = 0.0_r8 pomaod(:ncol) = 0.0_r8 soaaod(:ncol) = 0.0_r8 bcaod(:ncol) = 0.0_r8 seasaltaod(:ncol) = 0.0_r8 **#if ( defined MODAL_AERO_4MODE_MOM ) burdenmom(:ncol) = 0.0_r8 #elif ( defined MODAL_AERO_9MODE ) burdenpoly(:ncol) = 0.0_r8 burdenprot(:ncol) = 0.0_r8 burdenlip(:ncol) = 0.0_r8 #endif** "
411409,411409,457286,https://api.github.com/repos/jaxdb/jaxdb/issues/38,1.0,2021-05-12T15:41:39Z,CONTRIBUTOR,https://api.github.com/repos/jaxdb/jaxdb,Support INSERT ON CONFLICT DO NOTHING,,Support INSERT ON CONFLICT DO NOTHING 
647121,647121,719277,https://api.github.com/repos/Schmiddiii/Tubefeeder/issues/2,1.0,2021-04-10T19:18:42Z,NONE,https://api.github.com/repos/Schmiddiii/Tubefeeder,Using GTK3 Settings for font sizes,"Currently the base font sizes are hard coded; `n * pango::SCALE`.
It would be better to use the current GTK3 / session settings to scale the font based on user preferences.",Using GTK3 Settings for font sizes Currently the base font sizes are hard coded; `n * pango::SCALE`. It would be better to use the current GTK3 / session settings to scale the font based on user preferences.
462167,462167,513635,https://api.github.com/repos/dsccommunity/AzureDevOpsDsc/issues/12,1.0,2021-01-24T12:25:38Z,MEMBER,https://api.github.com/repos/dsccommunity/AzureDevOpsDsc,AzureDevOpsDsc: Enums should move out of prefix file,"Like 'Classes' enums should be single ps1 files with 1 enum definition per file. Compilation will put them in the main module psm1.
No needs for subfolders in enums. 

https://github.com/dsccommunity/AzureDevOpsDsc/blob/8d43d12989359b8facdf46d86011a34dfe787898/source/prefix.ps1#L13-L28

_As per https://github.com/dsccommunity/AzureDevOpsDsc/pull/7#issuecomment-729941083._",AzureDevOpsDsc: Enums should move out of prefix file Like 'Classes' enums should be single ps1 files with 1 enum definition per file. Compilation will put them in the main module psm1. No needs for subfolders in enums. https://github.com/dsccommunity/AzureDevOpsDsc/blob/8d43d12989359b8facdf46d86011a34dfe787898/source/prefix.ps1#L13-L28 _As per https://github.com/dsccommunity/AzureDevOpsDsc/pull/7#issuecomment-729941083._
733844,733844,109472,https://api.github.com/repos/backwardsEric/hengband/issues/7,1.0,2021-02-19T19:22:36Z,OWNER,https://api.github.com/repos/backwardsEric/hengband,3.0.0: English descriptions for the dragons/dragon-related from Skyrim,"The descriptions for these seem like they would benefit from some editing:

- Mirmulnir, the vanguard of Alduin
- Sahloknir, the hunter of illusion
- Odahviing, the betrayer of Alduin
- Delphine, the mortal enemy for the way of the voice
- Paarthurnax, the guru of the way of the voice
- Alduin, the World Eater
- Miraak, the first Dragon-soul Taker
- Harkon, the patriarch of Volkihar castle","3.0.0: English descriptions for the dragons/dragon-related from Skyrim The descriptions for these seem like they would benefit from some editing: - Mirmulnir, the vanguard of Alduin - Sahloknir, the hunter of illusion - Odahviing, the betrayer of Alduin - Delphine, the mortal enemy for the way of the voice - Paarthurnax, the guru of the way of the voice - Alduin, the World Eater - Miraak, the first Dragon-soul Taker - Harkon, the patriarch of Volkihar castle"
751372,751372,282013,https://api.github.com/repos/rapid7/metasploit-framework/issues/14510,0.0,2020-12-14T08:25:20Z,CONTRIBUTOR,https://api.github.com/repos/rapid7/metasploit-framework,cmd/unix/reverse_awk spins CPU after user exit,"While testing payloads for #14509 I noticed cmd/unix/reverse_awk spins CPU after user exit.

## Steps to reproduce

- `use payload/cmd/unix/reverse_awk`
- `generate -f raw`
- copy the command
- `to_handler`
- paste the command into a terminal somewhere
- interact with the session: `sessions -1`
- `id` or something to make sure it's real
- `exit` or ctrl-c
- see the session close

## Expected behavior

clean exit

## Current behavior

If you `exit`, the payload continues to call back. If you ctrl-c, it doesn't call back anymore but the process is still there. Either way, my fan spins up

## Metasploit version

Tested in #14509 as mentioned. Verified that the same issue exists on current master, 7b31d332dc4d9d4520f01c247950b26e135408bf
","cmd/unix/reverse_awk spins CPU after user exit While testing payloads for #14509 I noticed cmd/unix/reverse_awk spins CPU after user exit. ## Steps to reproduce - `use payload/cmd/unix/reverse_awk` - `generate -f raw` - copy the command - `to_handler` - paste the command into a terminal somewhere - interact with the session: `sessions -1` - `id` or something to make sure it's real - `exit` or ctrl-c - see the session close ## Expected behavior clean exit ## Current behavior If you `exit`, the payload continues to call back. If you ctrl-c, it doesn't call back anymore but the process is still there. Either way, my fan spins up ## Metasploit version Tested in #14509 as mentioned. Verified that the same issue exists on current master, 7b31d332dc4d9d4520f01c247950b26e135408bf "
387062,387062,430261,https://api.github.com/repos/openlawteam/tribute-ui/issues/310,1.0,2021-05-10T10:45:42Z,MEMBER,https://api.github.com/repos/openlawteam/tribute-ui,Off-Chain Voting: Get steps from Snapshot Hub,"(todo description)

- [x] `GET` steps by Merkle root from Snapshot Hub.
- [x] Check if off-chain vote proof was previously submitted in `OffchainOpRollupVotingSubmitResultAction`

Ref: https://docs.google.com/document/d/1KkvqoNVAWb9PPJdsay4Tpxxfig9Ts8iKj5z_Qa-IYzY/edit#heading=h.rsup8p6hq1ht",Off-Chain Voting: Get steps from Snapshot Hub (todo description) - [x] `GET` steps by Merkle root from Snapshot Hub. - [x] Check if off-chain vote proof was previously submitted in `OffchainOpRollupVotingSubmitResultAction` Ref: https://docs.google.com/document/d/1KkvqoNVAWb9PPJdsay4Tpxxfig9Ts8iKj5z_Qa-IYzY/edit#heading=h.rsup8p6hq1ht
427477,427477,475191,https://api.github.com/repos/kaaholst/test-issues/issues/227,0.0,2021-01-29T23:49:38Z,OWNER,https://api.github.com/repos/kaaholst/test-issues,Cannot Change CLI Port number,"```
What steps will reproduce the problem?
1.Use a squeezeserver that is running CLI on a port other than 9090
2.Try to connect from squeezer
3.

What is the expected output? What do you see instead?


What version of the product are you using? On what operating system?


Please provide any additional information below.
I just think that the CLI and web ports should be available in the setting. I have
to have my server run CLI on a different port,I use 9092, and therefore cannot use
Squeezer at all/
```

Original issue reported on code.google.com by `kenny.declan` on 2013-01-27 05:19:55
","Cannot Change CLI Port number ``` What steps will reproduce the problem? 1.Use a squeezeserver that is running CLI on a port other than 9090 2.Try to connect from squeezer 3. What is the expected output? What do you see instead? What version of the product are you using? On what operating system? Please provide any additional information below. I just think that the CLI and web ports should be available in the setting. I have to have my server run CLI on a different port,I use 9092, and therefore cannot use Squeezer at all/ ``` Original issue reported on code.google.com by `kenny.declan` on 2013-01-27 05:19:55 "
776870,776870,538559,https://api.github.com/repos/ghi-electronics/TinyCLR-Drivers/issues/163,0.0,2021-04-11T23:46:41Z,CONTRIBUTOR,https://api.github.com/repos/ghi-electronics/TinyCLR-Drivers,V2.1.0 Preview 4: Command 'Winc15x0Interface.GetFirmwareVersion();' before initialization crashes and makes board unresponsive,"I'm working with a FEZ Feather TinyCLR V2.1.0 Preview 4.
Mistakenly I used the command 'Winc15x0Interface.GetFirmwareVersion();' before the module was initialized. This crashes application and makes the board unresponsive over USB. Firmware had to be erased in LDR mode and firmware had to be updated.
After initialization of the WiFi module the command worked as expected.
Not a big thing but should perhaps be handled more gracefully.",V2.1.0 Preview 4: Command 'Winc15x0Interface.GetFirmwareVersion();' before initialization crashes and makes board unresponsive I'm working with a FEZ Feather TinyCLR V2.1.0 Preview 4. Mistakenly I used the command 'Winc15x0Interface.GetFirmwareVersion();' before the module was initialized. This crashes application and makes the board unresponsive over USB. Firmware had to be erased in LDR mode and firmware had to be updated. After initialization of the WiFi module the command worked as expected. Not a big thing but should perhaps be handled more gracefully.
612995,612995,681225,https://api.github.com/repos/Spine-project/SpineOpt.jl/issues/145,0.0,2021-02-07T18:42:22Z,NONE,https://api.github.com/repos/Spine-project/SpineOpt.jl,Link to docs dead,"In GitLab by @ererkka on Nov 15, 2018, 07:44

So, we got our very first [issue in GitHub](https://github.com/Spine-project/Spine-Model/issues/1)! Cool!

The link to Documentation in README.md does not work. This section:

>  ## Documentation
>
> Documentation is available [here](docs/build/index.md).

Same thing in both `dev` and `master`. Apaprently the build docs have not been checked in. Should they?","Link to docs dead In GitLab by @ererkka on Nov 15, 2018, 07:44 So, we got our very first [issue in GitHub](https://github.com/Spine-project/Spine-Model/issues/1)! Cool! The link to Documentation in README.md does not work. This section: > ## Documentation > > Documentation is available [here](docs/build/index.md). Same thing in both `dev` and `master`. Apaprently the build docs have not been checked in. Should they?"
788763,788763,657446,https://api.github.com/repos/shqke/impactfix/issues/2,0.0,2021-03-18T12:11:08Z,NONE,https://api.github.com/repos/shqke/impactfix,Faulty Windows build,"This extension really looks promising but my dedicated server suffers from random crashes once it gets installed. I am using SourceMod 1.10 if it helps. I also have these crash logs from Accelerator for further details:

> 0    server.dll + 0x27207
1    server.dll + 0x79252
2    0x1ab559fe
3    bintools.ext.dll!CallWrapper::Execute(void *,void *) [CallWrapper.cpp:144 + 0xb] 
4    impactfix.ext.2.l4d2.dll + 0x2870
5    server.dll + 0x356eab
6    server.dll + 0x2cf74a
7    server.dll + 0x2d061d
8    server.dll + 0x2d16b4
9    server.dll + 0x2d20a8
10    server.dll + 0xf8073
11    server.dll + 0xfb22f
12    server.dll + 0x2cefb4
13    server.dll + 0xf44fc
14    server.dll + 0x2358c6
15    server.dll + 0x2cd9ab
16    server.dll + 0x17e8bc
17    server.dll + 0x16dc65
18    server.dll + 0x23f264
19    server.dll + 0x30e92a
20    sdktools.ext.2.l4d2.dll!SourceHook_MFHCls_PlayerRunCmdHook::Func(CUserCmd *,IMoveHelper *) [hooks.cpp:50 + 0xab] 
21    server.dll + 0x17d2c6
22    server.dll + 0x38a049
23    server.dll + 0x144254
24    server.dll + 0xeddeb
25    sourcemod.2.l4d2.dll!SourceHook_FHCls_IServerGameDLLGameFramefalse::Func(bool) [sourcemod.cpp:54 + 0xa3] 
26    engine.dll + 0x124577
27    engine.dll + 0x1256b7
28    engine.dll + 0x18f398
29    engine.dll + 0x190c06
30    engine.dll + 0x191363
31    engine.dll + 0x1a0a2b
32    engine.dll + 0x1a0b7f
33    engine.dll + 0x1a0c24
34    engine.dll + 0x200cf4
35    engine.dll + 0x1fe311
36    dedicated.dll + 0x31ce
37    dedicated.dll + 0x3906
38    dedicated.dll + 0x27dae
39    dedicated.dll + 0x4976
40    srcds.exe + 0x11fd
41    srcds.exe + 0x1929
42    kernel32.dll!BaseThreadInitThunk + 0x19
43    ntdll.dll!__RtlUserThreadStart + 0x2f
44    ntdll.dll!_RtlUserThreadStart + 0x1b","Faulty Windows build This extension really looks promising but my dedicated server suffers from random crashes once it gets installed. I am using SourceMod 1.10 if it helps. I also have these crash logs from Accelerator for further details: > 0 server.dll + 0x27207 1 server.dll + 0x79252 2 0x1ab559fe 3 bintools.ext.dll!CallWrapper::Execute(void *,void *) [CallWrapper.cpp:144 + 0xb] 4 impactfix.ext.2.l4d2.dll + 0x2870 5 server.dll + 0x356eab 6 server.dll + 0x2cf74a 7 server.dll + 0x2d061d 8 server.dll + 0x2d16b4 9 server.dll + 0x2d20a8 10 server.dll + 0xf8073 11 server.dll + 0xfb22f 12 server.dll + 0x2cefb4 13 server.dll + 0xf44fc 14 server.dll + 0x2358c6 15 server.dll + 0x2cd9ab 16 server.dll + 0x17e8bc 17 server.dll + 0x16dc65 18 server.dll + 0x23f264 19 server.dll + 0x30e92a 20 sdktools.ext.2.l4d2.dll!SourceHook_MFHCls_PlayerRunCmdHook::Func(CUserCmd *,IMoveHelper *) [hooks.cpp:50 + 0xab] 21 server.dll + 0x17d2c6 22 server.dll + 0x38a049 23 server.dll + 0x144254 24 server.dll + 0xeddeb 25 sourcemod.2.l4d2.dll!SourceHook_FHCls_IServerGameDLLGameFramefalse::Func(bool) [sourcemod.cpp:54 + 0xa3] 26 engine.dll + 0x124577 27 engine.dll + 0x1256b7 28 engine.dll + 0x18f398 29 engine.dll + 0x190c06 30 engine.dll + 0x191363 31 engine.dll + 0x1a0a2b 32 engine.dll + 0x1a0b7f 33 engine.dll + 0x1a0c24 34 engine.dll + 0x200cf4 35 engine.dll + 0x1fe311 36 dedicated.dll + 0x31ce 37 dedicated.dll + 0x3906 38 dedicated.dll + 0x27dae 39 dedicated.dll + 0x4976 40 srcds.exe + 0x11fd 41 srcds.exe + 0x1929 42 kernel32.dll!BaseThreadInitThunk + 0x19 43 ntdll.dll!__RtlUserThreadStart + 0x2f 44 ntdll.dll!_RtlUserThreadStart + 0x1b"
450643,450643,500847,https://api.github.com/repos/sqlalchemy/sqlalchemy/issues/3357,0.0,2015-04-05T06:10:06Z,COLLABORATOR,https://api.github.com/repos/sqlalchemy/sqlalchemy,"clarify server-side vs. client-side isolation level, as there's no way to retrieve the AUTOCOMMIT setting from a connection w/o using default","**Migrated issue, originally created by Timothy Cardenas ([@trcarden](https://github.com/trcarden))**

Simply create a engine with isolation_level set to autocommit, connect, and compare the return value from get_isolation_level from the value returned from the psycopg2 connection. They do not match.

Example:

```
url='postgresql+psycopg2://me:pass@host/db'
engine = create_engine(
            url,
            encoding='utf8',
            pool_size=5,
            poolclass=QueuePool,
            isolation_level=""AUTOCOMMIT""
        )

with engine.connect() as connection:
  print(connection.get_isolation_level())  # => READ COMMITED
  print(connection.connection.isolation_level)  # => 0 (psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)
```

","clarify server-side vs. client-side isolation level, as there's no way to retrieve the AUTOCOMMIT setting from a connection w/o using default **Migrated issue, originally created by Timothy Cardenas ([@trcarden](https://github.com/trcarden))** Simply create a engine with isolation_level set to autocommit, connect, and compare the return value from get_isolation_level from the value returned from the psycopg2 connection. They do not match. Example: ``` url='postgresql+psycopg2://me:pass@host/db' engine = create_engine( url, encoding='utf8', pool_size=5, poolclass=QueuePool, isolation_level=""AUTOCOMMIT"" ) with engine.connect() as connection: print(connection.get_isolation_level()) # => READ COMMITED print(connection.connection.isolation_level) # => 0 (psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT) ``` "
210279,210279,233812,https://api.github.com/repos/az-digital/az_quickstart/issues/524,0.0,2021-02-19T19:14:08Z,MEMBER,https://api.github.com/repos/az-digital/az_quickstart,Ensure all Drupal dependencies are using specific version constraints,"## Problem/Motivation
We typically use specific version constraints In our az-digital/az_quicsktart repo's conmposer.json file, especially for Drupal dependencies in order to keep our builds deterministic (consistent with how they worked in D7).

### Describe the bug
Recently we've merged some changes that introduced non-specific version constraints for Drupal contrib modules (probably due to folks using `composer require` from the command line without specifying a specific version.

## Proposed resolution
We should audit the dependencies in our composer.json file to ensure we're using specific version constraints where possible.","Ensure all Drupal dependencies are using specific version constraints ## Problem/Motivation We typically use specific version constraints In our az-digital/az_quicsktart repo's conmposer.json file, especially for Drupal dependencies in order to keep our builds deterministic (consistent with how they worked in D7). ### Describe the bug Recently we've merged some changes that introduced non-specific version constraints for Drupal contrib modules (probably due to folks using `composer require` from the command line without specifying a specific version. ## Proposed resolution We should audit the dependencies in our composer.json file to ensure we're using specific version constraints where possible."
639107,639107,710321,https://api.github.com/repos/serverless/serverless/issues/8740,0.0,2021-01-11T10:11:35Z,MEMBER,https://api.github.com/repos/serverless/serverless,Fix AJV schema initialization time,"<!-- 截截 Acknowledge ALL below remarks -->
<!-- 截截 Request may not be processed if it doesn't meet outlined criteria -->

<!-- 截截 Search existing issues to avoid creating duplicates  -->
<!-- 截截 Plugin enhancements should be proposed at plugin repository, not here -->

<!-- 截截 Answer ALL required questions below -->

<!--
Q1: Describe the problem (use case) that needs to be solved
-->

### Use case description

After upgrading `ajv` from v6 to v7 (with #8703) we've observed a slower initialization of `serverless` command.
It appears that schema compilation ([`ajv.compile(schema)`](https://github.com/serverless/serverless/blob/b4fef7da64978433b88ee9fc8e9544e80608a387/lib/classes/ConfigSchemaHandler/index.js#L106) execution time for very same schema jumped from ca `0.15s` to `0.8s`.

It also affects our test runs which locally for me jumped from `13s` to `50s`

I believe we need to find a way to bring back previous performance or if that will appear as not easily doable revert back to v6

<!--
Q2: Propose a solution (e.g. provide configuration example)

Note: This is optional, remove this section if you do not wish to propose anything at this point
-->

### Proposed solution

After discussing it in a AJV tracker -> https://github.com/ajv-validator/ajv/issues/1386, it appears that solution could be to prepare a pre-compiled AJV instances for reuse (they're called ""standalone"" on AJV side, but they're [not really _standalone_](https://github.com/ajv-validator/ajv/issues/1386#issuecomment-756732512)).

As our schema is not fixed (may be extended by plugins) we cannot simply ship `serverless` with pre-generated AJV validate function, still assuming that generating _pre-compiled_ instance takes reasonable time (I didn't test it) we may take the approach in which we store it in users cache (`~/.serverless/artifact`) and reuse pre-compiled `validate` (per schema and AJV version) in all further `serverless` run.

##### Implementation proposal

1. Seclude AJV validate resolution logic (so https://github.com/serverless/serverless/blob/b4fef7da64978433b88ee9fc8e9544e80608a387/lib/classes/ConfigSchemaHandler/index.js#L101-L103 and https://github.com/serverless/serverless/blob/b4fef7da64978433b88ee9fc8e9544e80608a387/lib/classes/ConfigSchemaHandler/index.js#L106) into `lib/classes/ConfigSchemaHandler/resolve-ajv-validate.js` module
2. In `lib/classes/ConfigSchemaHandler/resolve-ajv-validate.js`  introduce an optimized `validate` function resolver:
   1. Calculate hash for received `schema` option (i think schema may host circular references, so we should probably add some prevention for that)
   2. Relying on [`lib/util/getEnsureArtifact.js`](https://github.com/serverless/serverless/blob/b4fef7da64978433b88ee9fc8e9544e80608a387/lib/utils/getEnsureArtifact.js) (for reference it's used e.g. here: https://github.com/serverless/serverless/blob/b4fef7da64978433b88ee9fc8e9544e80608a387/lib/plugins/aws/customResources/generateZip.js#L14) either reuse already generated `validate` method, or generate new one (following this instructions)
   
Additional notes:
- As produced `validate` function source code is not really _standalone_ (and may need access to `ajv` dependency) I believe we need to load it via [`require-from-string`](https://www.npmjs.com/package/require-from-string) with a made up `filename` which is located in context of `serverless` package - that way generated `validate` will have access to same dependencies as `serverless`
- We may consider (with other PR) refactor `getEnsureArtifact` so it directly resolves with memoized function, and not that it resolves with function which when invoked resolves with memoized function (I think this approach is not really needed as it was assumed and it just additionally confuses)
- We may consider to further optimize for this case, and use different variant of `getEnsureArtifact`, not one that uses different _folder_ per `serveless` version, but per `ajv` version (thanks to that, after upgrading `serverless`, users will not have `validate` rebuilt if underlying `ajv` was not upgraded) - and for that we may use some `getEnsureArtifact` generator that indeed returns function which returns a memoized function.



","Fix AJV schema initialization time <!-- 截截 Acknowledge ALL below remarks --> <!-- 截截 Request may not be processed if it doesn't meet outlined criteria --> <!-- 截截 Search existing issues to avoid creating duplicates --> <!-- 截截 Plugin enhancements should be proposed at plugin repository, not here --> <!-- 截截 Answer ALL required questions below --> <!-- Q1: Describe the problem (use case) that needs to be solved --> ### Use case description After upgrading `ajv` from v6 to v7 (with #8703) we've observed a slower initialization of `serverless` command. It appears that schema compilation ([`ajv.compile(schema)`](https://github.com/serverless/serverless/blob/b4fef7da64978433b88ee9fc8e9544e80608a387/lib/classes/ConfigSchemaHandler/index.js#L106) execution time for very same schema jumped from ca `0.15s` to `0.8s`. It also affects our test runs which locally for me jumped from `13s` to `50s` I believe we need to find a way to bring back previous performance or if that will appear as not easily doable revert back to v6 <!-- Q2: Propose a solution (e.g. provide configuration example) Note: This is optional, remove this section if you do not wish to propose anything at this point --> ### Proposed solution After discussing it in a AJV tracker -> https://github.com/ajv-validator/ajv/issues/1386, it appears that solution could be to prepare a pre-compiled AJV instances for reuse (they're called ""standalone"" on AJV side, but they're [not really _standalone_](https://github.com/ajv-validator/ajv/issues/1386#issuecomment-756732512)). As our schema is not fixed (may be extended by plugins) we cannot simply ship `serverless` with pre-generated AJV validate function, still assuming that generating _pre-compiled_ instance takes reasonable time (I didn't test it) we may take the approach in which we store it in users cache (`~/.serverless/artifact`) and reuse pre-compiled `validate` (per schema and AJV version) in all further `serverless` run. ##### Implementation proposal 1. Seclude AJV validate resolution logic (so https://github.com/serverless/serverless/blob/b4fef7da64978433b88ee9fc8e9544e80608a387/lib/classes/ConfigSchemaHandler/index.js#L101-L103 and https://github.com/serverless/serverless/blob/b4fef7da64978433b88ee9fc8e9544e80608a387/lib/classes/ConfigSchemaHandler/index.js#L106) into `lib/classes/ConfigSchemaHandler/resolve-ajv-validate.js` module 2. In `lib/classes/ConfigSchemaHandler/resolve-ajv-validate.js` introduce an optimized `validate` function resolver: 1. Calculate hash for received `schema` option (i think schema may host circular references, so we should probably add some prevention for that) 2. Relying on [`lib/util/getEnsureArtifact.js`](https://github.com/serverless/serverless/blob/b4fef7da64978433b88ee9fc8e9544e80608a387/lib/utils/getEnsureArtifact.js) (for reference it's used e.g. here: https://github.com/serverless/serverless/blob/b4fef7da64978433b88ee9fc8e9544e80608a387/lib/plugins/aws/customResources/generateZip.js#L14) either reuse already generated `validate` method, or generate new one (following this instructions) Additional notes: - As produced `validate` function source code is not really _standalone_ (and may need access to `ajv` dependency) I believe we need to load it via [`require-from-string`](https://www.npmjs.com/package/require-from-string) with a made up `filename` which is located in context of `serverless` package - that way generated `validate` will have access to same dependencies as `serverless` - We may consider (with other PR) refactor `getEnsureArtifact` so it directly resolves with memoized function, and not that it resolves with function which when invoked resolves with memoized function (I think this approach is not really needed as it was assumed and it just additionally confuses) - We may consider to further optimize for this case, and use different variant of `getEnsureArtifact`, not one that uses different _folder_ per `serveless` version, but per `ajv` version (thanks to that, after upgrading `serverless`, users will not have `validate` rebuilt if underlying `ajv` was not upgraded) - and for that we may use some `getEnsureArtifact` generator that indeed returns function which returns a memoized function. "
530622,530622,589774,https://api.github.com/repos/Tech-NYC/Sharity/issues/43,1.0,2021-04-14T13:28:39Z,CONTRIBUTOR,https://api.github.com/repos/Tech-NYC/Sharity,(feat) connect login and sign up to post information,,(feat) connect login and sign up to post information 
369217,369217,410449,https://api.github.com/repos/tvkitchen/appliances/issues/107,0.0,2021-04-24T01:25:46Z,MEMBER,https://api.github.com/repos/tvkitchen/appliances,Out of order text in SRTs,"## Task

#### Description
Captions seem to be coming in correctly, but the SRT generator is generating some characters out of order.

For example:

```
00:18:37,332 --> 00:21:30,488
COU>>LD BE.

00:18:37,332 --> 00:21:31,189
R>>EPORTER: AND IN FACT, SAID
```
 
When a raw output of the captions is:
 
```
>> COULD BE.
>> REPORTER: AND IN FACT, SAID
```

This probably just means something in the SRT appliance is not properly `await`-ing and it's resulting in a race condition.
 ","Out of order text in SRTs ## Task #### Description Captions seem to be coming in correctly, but the SRT generator is generating some characters out of order. For example: ``` 00:18:37,332 --> 00:21:30,488 COU>>LD BE. 00:18:37,332 --> 00:21:31,189 R>>EPORTER: AND IN FACT, SAID ``` When a raw output of the captions is: ``` >> COULD BE. >> REPORTER: AND IN FACT, SAID ``` This probably just means something in the SRT appliance is not properly `await`-ing and it's resulting in a race condition. "
270003,270003,300272,https://api.github.com/repos/thesobercoder/Graphite-UI/issues/32,0.0,2021-01-18T19:12:36Z,OWNER,https://api.github.com/repos/thesobercoder/Graphite-UI,"Make ""Home Screen 1"" template responsive","Make ""Home Screen 1"" template responsive

![Mobile](https://tailwindui.com/img/components/home-screens.01-full-width-with-sidebar-xs.png)","Make ""Home Screen 1"" template responsive Make ""Home Screen 1"" template responsive ![Mobile](https://tailwindui.com/img/components/home-screens.01-full-width-with-sidebar-xs.png)"
733993,733993,110746,https://api.github.com/repos/BoboTiG/ebook-reader-dict/issues/507,1.0,2021-01-05T23:58:38Z,OWNER,https://api.github.com/repos/BoboTiG/ebook-reader-dict,Add scripts to auto-update specific data,"Get back scripts from the wiki to auto-update specific data like langs for all locales, gramatica for PT, etc..
A ""manager"" script should be use to launch and create commits for each script.
","Add scripts to auto-update specific data Get back scripts from the wiki to auto-update specific data like langs for all locales, gramatica for PT, etc.. A ""manager"" script should be use to launch and create commits for each script. "
8686,8686,9688,https://api.github.com/repos/stripe/stripe-cli/issues/591,1.0,2021-02-11T02:52:02Z,NONE,https://api.github.com/repos/stripe/stripe-cli,Fire test events that have data on localhost,"### Problem
Would like to be able to fire a test event from the CLI on localhost that includes data.

### Feature
Triggering events via the CLI with included data fields

### Examples
Firing an invoice.paid event with a customer id so I can test how my backend is going to provision services for that payment. 
",Fire test events that have data on localhost ### Problem Would like to be able to fire a test event from the CLI on localhost that includes data. ### Feature Triggering events via the CLI with included data fields ### Examples Firing an invoice.paid event with a customer id so I can test how my backend is going to provision services for that payment. 
374907,374907,416750,https://api.github.com/repos/oroinc/crm/issues/231,0.0,2016-12-22T11:14:32Z,NONE,https://api.github.com/repos/oroinc/crm,Bug method addManyToOneRealtion in migration add a ManyToMany instead,"Hi Oro Team,

I have extend the task bundle with migration like it describe in this [link](https://www.orocrm.com/forums/topic/extend-task-bundle-using-migration-throw-error-when-try-to-create-task).

The method addManyToOneRelation seems to not work properly.","Bug method addManyToOneRealtion in migration add a ManyToMany instead Hi Oro Team, I have extend the task bundle with migration like it describe in this [link](https://www.orocrm.com/forums/topic/extend-task-bundle-using-migration-throw-error-when-try-to-create-task). The method addManyToOneRelation seems to not work properly."
134894,134894,149951,https://api.github.com/repos/nicehash/NiceHashMiner/issues/2042,1.0,2020-04-22T21:55:10Z,NONE,https://api.github.com/repos/nicehash/NiceHashMiner,Enhance notification for AMD cards to switch compute/graphic mode,"In v3.0.0.8 the notification to switch to compute mode is displayed on every NHM startup, even if the mode is already set to ""compute"".

There is a way to detect if any of the connected AMD cards does not have this option already set, by checking the Registry for the value of the KMD_EnableInternalLargePage == 2 for every video adapter in \HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Video\<GUID> keys.

Some example code of how this is checked/set/reset can even be found online: https://bitcointalk.org/index.php?topic=2815803.msg28908408#msg28908408

So this notification can even be modified to include the tool to set the option as well.","Enhance notification for AMD cards to switch compute/graphic mode In v3.0.0.8 the notification to switch to compute mode is displayed on every NHM startup, even if the mode is already set to ""compute"". There is a way to detect if any of the connected AMD cards does not have this option already set, by checking the Registry for the value of the KMD_EnableInternalLargePage == 2 for every video adapter in \HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Control\Video\<GUID> keys. Some example code of how this is checked/set/reset can even be found online: https://bitcointalk.org/index.php?topic=2815803.msg28908408#msg28908408 So this notification can even be modified to include the tool to set the option as well."
300047,300047,333603,https://api.github.com/repos/Siphon880gh/reprint/issues/15,1.0,2021-04-02T03:28:48Z,COLLABORATOR,https://api.github.com/repos/Siphon880gh/reprint,Create Mutations,"- add Reprint
- delete Reprint
- delete User
- edit User
- add Comment
- delete Comment
- favorite Reprint
- like Reprint
- follow User
- unfollow User",Create Mutations - add Reprint - delete Reprint - delete User - edit User - add Comment - delete Comment - favorite Reprint - like Reprint - follow User - unfollow User
198964,198964,221220,https://api.github.com/repos/logseq/logseq/issues/1028,0.0,2020-12-30T14:02:57Z,NONE,https://api.github.com/repos/logseq/logseq,Queries involving block properties with page references are not working,"**Describe the bug**
Queries filtering a block property with a page reference values does not filter correctly.

The equality check does not seem to equate a string of `[[something]]` in the query and the page reference stored in the block property.

**To Reproduce**
Steps to reproduce the behavior:
1. Go to the [block properties](https://logseq.github.io/page/block%20properties) page in the docs
2. Look at the results of the `My Books` query none are found

**Expected behavior**
The value of a block property should be filterable if its a page reference e.g. `[[something]]]` 
",Queries involving block properties with page references are not working **Describe the bug** Queries filtering a block property with a page reference values does not filter correctly. The equality check does not seem to equate a string of `[[something]]` in the query and the page reference stored in the block property. **To Reproduce** Steps to reproduce the behavior: 1. Go to the [block properties](https://logseq.github.io/page/block%20properties) page in the docs 2. Look at the results of the `My Books` query none are found **Expected behavior** The value of a block property should be filterable if its a page reference e.g. `[[something]]]` 
319682,319682,355388,https://api.github.com/repos/DenverCoder1/table2ascii/issues/2,1.0,2021-04-27T07:57:04Z,OWNER,https://api.github.com/repos/DenverCoder1/table2ascii,Create preset themes to choose from,"Many useful styles can be useful for outputting

Examples:

* Markdown

```
|  #  |  G  |  H  |  R  |  S  |
|-----|-----|-----|-----|-----|
| 1   |  60 |  70 |  50 |  60 |
| 2   |  50 |  30 |  80 |  60 |
| SUM | 110 | 100 | 110 | 120 |
```

* Single line

```
рррр
  #    G    H    R    S  
쇄쇄쇄쇄
 1     60   70   50   60 
 2     50   30   80   60 
 SUM  110  100  130  120 
닳닳닳닳
```

* Basic ASCII

```
+-----+-----+-----+-----+-----+
| #   | G   | H   | R   | S   |
+=====+=====+=====+=====+=====+
| 1   | 60  | 70  | 50  | 60  |
+-----+-----+-----+-----+-----+
| 2   | 50  | 30  | 80  | 60  |
+=====+=====+=====+=====+=====+
| SUM | 110 | 100 | 130 | 120 |
+-----+-----+-----+-----+-----+
```",Create preset themes to choose from Many useful styles can be useful for outputting Examples: * Markdown ``` | # | G | H | R | S | |-----|-----|-----|-----|-----| | 1 | 60 | 70 | 50 | 60 | | 2 | 50 | 30 | 80 | 60 | | SUM | 110 | 100 | 110 | 120 | ``` * Single line ``` рррр  #  G  H  R  S  쇄쇄쇄쇄  1  60  70  50  60   2  50  30  80  60   SUM  110  100  130  120  닳닳닳닳 ``` * Basic ASCII ``` +-----+-----+-----+-----+-----+ | # | G | H | R | S | +=====+=====+=====+=====+=====+ | 1 | 60 | 70 | 50 | 60 | +-----+-----+-----+-----+-----+ | 2 | 50 | 30 | 80 | 60 | +=====+=====+=====+=====+=====+ | SUM | 110 | 100 | 130 | 120 | +-----+-----+-----+-----+-----+ ```
726079,726079,31134,https://api.github.com/repos/nss-day-cohort-46/rare-server-tragic-trolls/issues/22,1.0,2021-04-26T14:43:42Z,NONE,https://api.github.com/repos/nss-day-cohort-46/rare-server-tragic-trolls,Delete a Comment,"
As a commenter I would like the ability to remove a Comment so that I have created so that I can prevent others from seeing it in the event that I regret what I said.

**Given** a user is vising the list of Comments  
**When** they select the `Delete` option  
**Then** they should be prompted to confirm the deletion  

**Given** the user wishes to confirm the delete  
**When** they the select the option to confirm  
**Then** the Comment should be removed from the system  
**And** the user should be directed back to the Comment list  

**Given** the user decides not to confirm the delete  
**When** they the select the option to reject confirmation  
**Then** the Comment should NOT be removed from the system  
**And** the user should be directed back to the Comment list  




",Delete a Comment As a commenter I would like the ability to remove a Comment so that I have created so that I can prevent others from seeing it in the event that I regret what I said. **Given** a user is vising the list of Comments **When** they select the `Delete` option **Then** they should be prompted to confirm the deletion **Given** the user wishes to confirm the delete **When** they the select the option to confirm **Then** the Comment should be removed from the system **And** the user should be directed back to the Comment list **Given** the user decides not to confirm the delete **When** they the select the option to reject confirmation **Then** the Comment should NOT be removed from the system **And** the user should be directed back to the Comment list 
391999,391999,435708,https://api.github.com/repos/patrikx3/onenote/issues/142,1.0,2021-04-29T08:11:03Z,NONE,https://api.github.com/repos/patrikx3/onenote,sort bookmarks alphabetically,Would be nice to have the feature to sort bookmarks by alphabetical order.,sort bookmarks alphabetically Would be nice to have the feature to sort bookmarks by alphabetical order.
342961,342961,381252,https://api.github.com/repos/munichpavel/clovek-ne-jezi-se/issues/45,1.0,2021-02-11T07:35:27Z,OWNER,https://api.github.com/repos/munichpavel/clovek-ne-jezi-se,Add code metrics,"Like cyclometic complexity, test coverage

Add and document usage (minimum: link to resources) of

- [x] Complexity with ~~[wily](https://github.com/tonybaloney/wily)~~ flake8 extension
- [x] Test coverage with ~~[coverage](https://coverage.readthedocs.io/)~~ flake8 extension","Add code metrics Like cyclometic complexity, test coverage Add and document usage (minimum: link to resources) of - [x] Complexity with ~~[wily](https://github.com/tonybaloney/wily)~~ flake8 extension - [x] Test coverage with ~~[coverage](https://coverage.readthedocs.io/)~~ flake8 extension"
577388,577388,641630,https://api.github.com/repos/BeamMW/beam-ui/issues/369,0.0,2020-11-26T09:38:15Z,NONE,https://api.github.com/repos/BeamMW/beam-ui,The wallet crashed when select create offer with dash\doge,"The wallet crashed when select create offer with dash\doge
![Screenshot_438](https://user-images.githubusercontent.com/50007056/100333918-31d4a300-2fe4-11eb-8b1d-a021abb624a7.png)
",The wallet crashed when select create offer with dash\doge The wallet crashed when select create offer with dash\doge ![Screenshot_438](https://user-images.githubusercontent.com/50007056/100333918-31d4a300-2fe4-11eb-8b1d-a021abb624a7.png) 
248590,248590,276492,https://api.github.com/repos/CatRass/SchlattCoin/issues/1,0.0,2021-03-11T10:54:01Z,NONE,https://api.github.com/repos/CatRass/SchlattCoin,"""Last Bought At"" and ""Last Sold at"" Glitch","If the user clicks buy or sell, despite no transaction occurring, the text that tells the user what their last buy or sell will still show a transaction.

I'd suggest adding a message or pop-up that tells the player ""Insufficient cash"" or ""Insufficient coins""","""Last Bought At"" and ""Last Sold at"" Glitch If the user clicks buy or sell, despite no transaction occurring, the text that tells the user what their last buy or sell will still show a transaction. I'd suggest adding a message or pop-up that tells the player ""Insufficient cash"" or ""Insufficient coins"""
535191,535191,594827,https://api.github.com/repos/Azure/autorest/issues/3859,0.0,2021-02-09T14:26:26Z,NONE,https://api.github.com/repos/Azure/autorest,Autorest 3.0.6371 suddenly switched to V3 csharp extension,"Hi everyone, 

I noticed a weird problem today on our Azure build pipeline. We generate a C# client for the portal that connect to our API and suddenly it broke without any changes from our side.

Looking at the logs, starting from the autorest_core@3.0.6371 version autorest decided that it will install the latest V3 beta C# package.

`Installing AutoRest extension '@autorest/csharp' (latest)`
`2021-02-09T12:27:19.6147547Z VERBOSE [1.53 s]: Installing @autorest/csharp, 3.0.0-beta.20210205.2`
`2021-02-09T12:27:20.8961919Z VERBOSE [2.83 s]: Package Install completed @autorest/csharp, 3.0.0-beta.20210205.2`
`2021-02-09T12:27:20.8966812Z    Installed AutoRest extension '@autorest/csharp' (latest->3.0.0-beta.20210205.2)`
`2021-02-09T12:27:20.9237783Z    Including extension configuration file 'file:///C:***@autorest_csharp@3.0.0-beta.20210205.2/node_modules/@autorest/csharp/readme.md'`
`2021-02-09T12:27:21.1647024Z    Installing AutoRest extension '@autorest/modelerfour' (4.15.456)`
`2021-02-09T12:27:22.3724773Z    Installed AutoRest extension '@autorest/modelerfour' (4.15.456->4.15.456)`
`2021-02-09T12:27:22.4366528Z    Including extension configuration file 'file:///C:***@autorest_modelerfour@4.15.456/node_modules/@autorest/modelerfour/readme.md'`

While with the previous version (autorest_core@3.0.6370) it correctly installs the V2 one

`2021-02-05T11:57:56.6248404Z    Installing AutoRest extension '@microsoft.azure/autorest.csharp' (~2.3.79)
2021-02-05T11:57:56.6297565Z VERBOSE [2.33 s]: Installing @microsoft.azure/autorest.csharp, 2.3.91
2021-02-05T11:58:05.7462022Z VERBOSE [11.45 s]: Package Install completed @microsoft.azure/autorest.csharp, 2.3.91
2021-02-05T11:58:05.7475395Z    Installed AutoRest extension '@microsoft.azure/autorest.csharp' (~2.3.79->2.3.91)
2021-02-05T11:58:05.7788449Z    Including extension configuration file 'file:///C:***@microsoft.azure_autorest.csharp@2.3.91/node_modules/@microsoft.azure/autorest.csharp/README.md'
2021-02-05T11:58:06.1273650Z    Installing AutoRest extension '@microsoft.azure/autorest.modeler' (2.3.55)
2021-02-05T11:58:07.6746872Z    Installed AutoRest extension '@microsoft.azure/autorest.modeler' (2.3.55->2.3.55)`

Does anyone else have a similar problem? The same thing happens to me locally.","Autorest 3.0.6371 suddenly switched to V3 csharp extension Hi everyone, I noticed a weird problem today on our Azure build pipeline. We generate a C# client for the portal that connect to our API and suddenly it broke without any changes from our side. Looking at the logs, starting from the autorest_core@3.0.6371 version autorest decided that it will install the latest V3 beta C# package. `Installing AutoRest extension '@autorest/csharp' (latest)` `2021-02-09T12:27:19.6147547Z VERBOSE [1.53 s]: Installing @autorest/csharp, 3.0.0-beta.20210205.2` `2021-02-09T12:27:20.8961919Z VERBOSE [2.83 s]: Package Install completed @autorest/csharp, 3.0.0-beta.20210205.2` `2021-02-09T12:27:20.8966812Z Installed AutoRest extension '@autorest/csharp' (latest->3.0.0-beta.20210205.2)` `2021-02-09T12:27:20.9237783Z Including extension configuration file 'file:///C:***@autorest_csharp@3.0.0-beta.20210205.2/node_modules/@autorest/csharp/readme.md'` `2021-02-09T12:27:21.1647024Z Installing AutoRest extension '@autorest/modelerfour' (4.15.456)` `2021-02-09T12:27:22.3724773Z Installed AutoRest extension '@autorest/modelerfour' (4.15.456->4.15.456)` `2021-02-09T12:27:22.4366528Z Including extension configuration file 'file:///C:***@autorest_modelerfour@4.15.456/node_modules/@autorest/modelerfour/readme.md'` While with the previous version (autorest_core@3.0.6370) it correctly installs the V2 one `2021-02-05T11:57:56.6248404Z Installing AutoRest extension '@microsoft.azure/autorest.csharp' (~2.3.79) 2021-02-05T11:57:56.6297565Z VERBOSE [2.33 s]: Installing @microsoft.azure/autorest.csharp, 2.3.91 2021-02-05T11:58:05.7462022Z VERBOSE [11.45 s]: Package Install completed @microsoft.azure/autorest.csharp, 2.3.91 2021-02-05T11:58:05.7475395Z Installed AutoRest extension '@microsoft.azure/autorest.csharp' (~2.3.79->2.3.91) 2021-02-05T11:58:05.7788449Z Including extension configuration file 'file:///C:***@microsoft.azure_autorest.csharp@2.3.91/node_modules/@microsoft.azure/autorest.csharp/README.md' 2021-02-05T11:58:06.1273650Z Installing AutoRest extension '@microsoft.azure/autorest.modeler' (2.3.55) 2021-02-05T11:58:07.6746872Z Installed AutoRest extension '@microsoft.azure/autorest.modeler' (2.3.55->2.3.55)` Does anyone else have a similar problem? The same thing happens to me locally."
450219,450219,500378,https://api.github.com/repos/pivotal/kpack/issues/664,0.0,2021-04-14T22:01:41Z,NONE,https://api.github.com/repos/pivotal/kpack,typo in tutorial,"This [line](https://github.com/pivotal/kpack/blame/master/docs/tutorial.md#L116) in the tutorial is very confusing: `The builder order will the order in which buildpacks are used in the builder.`

I think the line should read `The builder order will _determine_ the order in which buildpacks are used in the builder.`",typo in tutorial This [line](https://github.com/pivotal/kpack/blame/master/docs/tutorial.md#L116) in the tutorial is very confusing: `The builder order will the order in which buildpacks are used in the builder.` I think the line should read `The builder order will _determine_ the order in which buildpacks are used in the builder.`
312737,312737,347700,https://api.github.com/repos/crossplane/provider-azure/issues/232,0.0,2021-03-22T10:32:04Z,NONE,https://api.github.com/repos/crossplane/provider-azure,Storage Account unsuccessfully tries to disable Table Encryption,"### What happened?
Creating a storage account with all encryption services enabled results in a status message unable to Disable Table Encryption and fails to reconcile.

```
storage.AccountsClient#Update: Failure responding to request: StatusCode=400 -- Original Error: autorest/azure: Service returned an error. Status=400 Code=""FeatureNotSupportedForAccount"" Message=""Disabling Table Encryption is not supported for the account.""
```

This results in continuous failed calls to the Azure API


### How can we reproduce it?
Create a storage account like below - note all encryption services are `true`

```yaml
---
apiVersion: storage.azure.crossplane.io/v1alpha3
kind: Account
metadata:
  name: craigteststorageacc
spec:
  resourceGroupName: craig-test-rg
  storageAccountSpec:
    kind: Storage
    location: westeurope
    sku:
      name: Standard_LRS
      tier: Standard
    tags:
      application: crossplane
    properties:
      encryption:
        keySource: ""Microsoft.Storage""
        services:
          blob: true
          file: true
          table: true
          queue: true
  providerRef:
    name: azure-provider
  providerConfigRef:
    name: default
  deletionPolicy: Delete
  writeConnectionSecretToRef:
    namespace: craigtest
    name: storageaccount
```

`kubectl describe` the created account and observe the status message.

`kubectl get <storageaccount> -o yaml` and observe:

```yaml
    properties:
      encryption:
        keySource: Microsoft.Storage
        services:
          blob: true
          file: true
```

Note that table and queue encryption services are removed here. It seems Microsoft may have disabled the ability to set encryption for these services (it is enabled by default).

You should also see regular failing update calls in the activity log for the account:

![Screenshot 2021-03-22 at 11 45 31](https://user-images.githubusercontent.com/37695591/111978492-3af1fe80-8b04-11eb-8fb3-e25d9cc0b9fc.png)



### What environment did it happen in?
Crossplane version: 1.1
Provider version: 0.15
","Storage Account unsuccessfully tries to disable Table Encryption ### What happened? Creating a storage account with all encryption services enabled results in a status message unable to Disable Table Encryption and fails to reconcile. ``` storage.AccountsClient#Update: Failure responding to request: StatusCode=400 -- Original Error: autorest/azure: Service returned an error. Status=400 Code=""FeatureNotSupportedForAccount"" Message=""Disabling Table Encryption is not supported for the account."" ``` This results in continuous failed calls to the Azure API ### How can we reproduce it? Create a storage account like below - note all encryption services are `true` ```yaml --- apiVersion: storage.azure.crossplane.io/v1alpha3 kind: Account metadata: name: craigteststorageacc spec: resourceGroupName: craig-test-rg storageAccountSpec: kind: Storage location: westeurope sku: name: Standard_LRS tier: Standard tags: application: crossplane properties: encryption: keySource: ""Microsoft.Storage"" services: blob: true file: true table: true queue: true providerRef: name: azure-provider providerConfigRef: name: default deletionPolicy: Delete writeConnectionSecretToRef: namespace: craigtest name: storageaccount ``` `kubectl describe` the created account and observe the status message. `kubectl get <storageaccount> -o yaml` and observe: ```yaml properties: encryption: keySource: Microsoft.Storage services: blob: true file: true ``` Note that table and queue encryption services are removed here. It seems Microsoft may have disabled the ability to set encryption for these services (it is enabled by default). You should also see regular failing update calls in the activity log for the account: ![Screenshot 2021-03-22 at 11 45 31](https://user-images.githubusercontent.com/37695591/111978492-3af1fe80-8b04-11eb-8fb3-e25d9cc0b9fc.png) ### What environment did it happen in? Crossplane version: 1.1 Provider version: 0.15 "
330756,330756,367727,https://api.github.com/repos/myl7/mylmoe/issues/4,0.0,2021-02-19T14:43:44Z,OWNER,https://api.github.com/repos/myl7/mylmoe,Share list from ShareThis does not work,Maybe some misconfiguration?,Share list from ShareThis does not work Maybe some misconfiguration?
331145,331145,368145,https://api.github.com/repos/hashicorp/packer/issues/10271,0.0,2020-11-17T15:10:33Z,NONE,https://api.github.com/repos/hashicorp/packer,vsphere builder should use govmomi types to not violate API specifications,"The vsphere builder uses a custom type [HardwareConfig](https://github.com/hashicorp/packer/blob/8ffa0d20600daac37d207bf49198920941a97d9d/builder/vsphere/common/step_hardware.go#L15) (among others) instead of the govmomi sdk provided [VirtualMachineConfigSpec](https://pkg.go.dev/github.com/vmware/govmomi@v0.23.1/vim25/types#VirtualMachineConfigSpec).

The custom HardwareConfig type directly violates with the govmomi-sdk provided type `VirtualMachineConfigSpec`. For example, `VirtualMachineConfigSpec.NestedHV` is `nil` when not explicitly set. However, when `HardwareConfig.NestedHV` is not set it is `false` if unset and overwrites any `configuration_parameters` that perhaps activate that particular settings, such as `vhv.enable` (which is the key-value for the vmx file).


","vsphere builder should use govmomi types to not violate API specifications The vsphere builder uses a custom type [HardwareConfig](https://github.com/hashicorp/packer/blob/8ffa0d20600daac37d207bf49198920941a97d9d/builder/vsphere/common/step_hardware.go#L15) (among others) instead of the govmomi sdk provided [VirtualMachineConfigSpec](https://pkg.go.dev/github.com/vmware/govmomi@v0.23.1/vim25/types#VirtualMachineConfigSpec). The custom HardwareConfig type directly violates with the govmomi-sdk provided type `VirtualMachineConfigSpec`. For example, `VirtualMachineConfigSpec.NestedHV` is `nil` when not explicitly set. However, when `HardwareConfig.NestedHV` is not set it is `false` if unset and overwrites any `configuration_parameters` that perhaps activate that particular settings, such as `vhv.enable` (which is the key-value for the vmx file). "
324846,324846,361123,https://api.github.com/repos/npm/cli/issues/344,0.0,2019-11-08T05:12:13Z,MEMBER,https://api.github.com/repos/npm/cli,NPM CI ignores engine-strict,"
      Original bug ticket: [https://npm.community/t/10447](https://npm.community/t/10447)
      Originally filed: 2019-10-09T13:04:59.955Z",NPM CI ignores engine-strict Original bug ticket: [https://npm.community/t/10447](https://npm.community/t/10447) Originally filed: 2019-10-09T13:04:59.955Z
603295,603295,670453,https://api.github.com/repos/seanpm2001/SeansLifeArchive_Extras_Google-Drive/issues/3,1.0,2021-05-19T04:18:32Z,OWNER,https://api.github.com/repos/seanpm2001/SeansLifeArchive_Extras_Google-Drive,Not quite completed yet,"
***

# Not quite completed yet

I am getting close, but I have not fully prepared this project yet. Under `///Sean Walla Walla Drive/` there is still a lot to sort and upload.

***
","Not quite completed yet *** # Not quite completed yet I am getting close, but I have not fully prepared this project yet. Under `///Sean Walla Walla Drive/` there is still a lot to sort and upload. *** "
23881,23881,26599,https://api.github.com/repos/hs-furtwangen/Fakultatsblog-Digitale-Medien/issues/5,0.0,2018-04-06T21:45:04Z,NONE,https://api.github.com/repos/hs-furtwangen/Fakultatsblog-Digitale-Medien,Logo wird nicht korrekt Angezeigt,"Wenn man mit der Maus 체ber die Schrift geht, wird das Logo nicht permanent als ""Aktiv"" angezeigt.","Logo wird nicht korrekt Angezeigt Wenn man mit der Maus 체ber die Schrift geht, wird das Logo nicht permanent als ""Aktiv"" angezeigt."
212357,212357,236136,https://api.github.com/repos/JuriBurakov/flutter/issues/12,2.0,2021-02-11T16:18:06Z,OWNER,https://api.github.com/repos/JuriBurakov/flutter,**Cards**,"Cards can be added to your board to track the progress of issues and pull requests. You can also add note cards, like this one!","**Cards** Cards can be added to your board to track the progress of issues and pull requests. You can also add note cards, like this one!"
562032,562032,624599,https://api.github.com/repos/splashinn/api-mocking-with-jest/issues/471,1.0,2020-08-21T13:59:01Z,OWNER,https://api.github.com/repos/splashinn/api-mocking-with-jest,Upgrade type to version 2.1.0,"Libraries.io has found that there is a newer version of type that this project depends on.

More info: https://libraries.io/npm/type/2.1.0",Upgrade type to version 2.1.0 Libraries.io has found that there is a newer version of type that this project depends on. More info: https://libraries.io/npm/type/2.1.0
769676,769676,465853,https://api.github.com/repos/PatrickDelaney17/useful_scripts/issues/1,0.0,2021-05-29T18:47:41Z,OWNER,https://api.github.com/repos/PatrickDelaney17/useful_scripts,Update Script: pihole update check logic incorrect,"> known issue in logic, method needs to be reviewed line 55
","Update Script: pihole update check logic incorrect > known issue in logic, method needs to be reviewed line 55 "
36918,36918,41162,https://api.github.com/repos/topcoder-platform/taas-app/issues/18,0.0,2020-12-07T15:55:01Z,COLLABORATOR,https://api.github.com/repos/topcoder-platform/taas-app,Hide Overall Team Rating on My Teams page,"Overall rating UI element should not be displayed on the My Teams page during the version 1.0 release

![image](https://user-images.githubusercontent.com/6014049/101373163-a62c0380-387a-11eb-995c-a411f0dd831f.png)
",Hide Overall Team Rating on My Teams page Overall rating UI element should not be displayed on the My Teams page during the version 1.0 release ![image](https://user-images.githubusercontent.com/6014049/101373163-a62c0380-387a-11eb-995c-a411f0dd831f.png) 
773104,773104,500876,https://api.github.com/repos/opentelekomcloud/terraform-provider-opentelekomcloud/issues/1039,0.0,2021-04-30T04:04:40Z,CONTRIBUTOR,https://api.github.com/repos/opentelekomcloud/terraform-provider-opentelekomcloud,[ECS][IMPORT] opentelekomcloud_compute_instance_v2 seams to not work with multiple Subnet in VPC,"## Version
```bash
$ terraform --version
Terraform v0.15.0
on linux_amd64
+ provider registry.terraform.io/opentelekomcloud/opentelekomcloud v1.23.9
```
Import doesnt work with having a SINGLE interface on the ECS but having multiple VPC-Subnet in the VPC where I try to import it.

## Network
I have somethink like this as Network:
```hcl
resource ""opentelekomcloud_vpc_v1"" ""vpc_v1"" {
  name = var.vpc_name
  cidr = var.vpc_cidr
}

resource ""opentelekomcloud_vpc_subnet_v1"" ""subnet_1"" {
  name   = var.subnet_name_1
  cidr   = var.subnet_cidr_1
  vpc_id = opentelekomcloud_vpc_v1.vpc_v1.id

  gateway_ip    = var.subnet_gateway_ip_1
  ntp_addresses = ""10.100.0.33,10.100.0.34""
}

resource ""opentelekomcloud_vpc_subnet_v1"" ""subnet_2"" {
  name   = var.subnet_name_2
  cidr   = var.subnet_cidr_2
  vpc_id = opentelekomcloud_vpc_v1.vpc_v1.id

  gateway_ip    = var.subnet_gateway_ip_2
  ntp_addresses = ""10.100.0.33,10.100.0.34""
}

resource ""opentelekomcloud_vpc_subnet_v1"" ""subnet_3"" {
  name   = var.subnet_name_3
  cidr   = var.subnet_cidr_3
  vpc_id = opentelekomcloud_vpc_v1.vpc_v1.id

  gateway_ip    = var.subnet_gateway_ip_3
  ntp_addresses = ""10.100.0.33,10.100.0.34""
}
```
## ECS Instance
The instance looks like:
I double checked that the Instances is (for real) only connected to ONE network...
```hcl
resource ""opentelekomcloud_compute_instance_v2"" ""ecs_instance"" {
  name      = ""boot-from-volume""
  flavor_id = var.flavor_id
  key_pair  = var.key_pair
  image_id  = var.image_id

  network {
    id        = opentelekomcloud_vpc_subnet_v1.subnet_2.id
    fixed_ip_v4 = ""<fixed_ip_v4>""
  }

}
```

## Import try
@outcatcher 
```bash
$ terraform import opentelekomcloud_compute_instance_v2.ecs_instance xxxxxxxxxxxxxxx-yyyyyyyyyyyyyyy
opentelekomcloud_compute_instance_v2.ecs_instance: Importing from ID ""xxxxxxxxxxxxxxx-yyyyyyyyyyyyyyy""...
opentelekomcloud_compute_instance_v2.ecs_instance: Import prepared!
  Prepared opentelekomcloud_compute_instance_v2 for import
opentelekomcloud_compute_instance_v2.ecs_instance: Refreshing state... [id=xxxxxxxxxxxxxxx-yyyyyyyyyyyyyyy]

Error: Error trying to get network information from the Network API: More than one network found for name <ID of the VPC>
```
## API
API Response is like:
```
""networks"": [
{
  ""admin_state_up"": true,
  ""availability_zone_hints"": [],
  ""availability_zones"": [
    ""eu-de-01"",
    ""eu-de-02"",
    ""eu-de-03""
  ],
  ""created_at"": ""2021-04-27T13:32:35"",
  ""dns_domain"": ""eu-de.compute.internal."",
  ""id"": ""xxxxxxxxxxxxxxxxyyyyyyyyyyyyyyyyyyyyyyyy"",
  ""name"": ""zzzzzzzzzzzzzzyyyyyyyyyyyyyyyyyy"",
  ""port_security_enabled"": true,
  ""project_id"": ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"",
  ""provider:network_type"": ""vxlan"",
  ""router:external"": false,
  ""shared"": false,
  ""status"": ""ACTIVE"",
  ""subnets"": [
    ""zzzzzzzzzzzzzzzzzzzzzzz""
  ],
  ""tenant_id"": ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"",
  ""updated_at"": ""2021-04-27T13:32:35""
},
{
  ""admin_state_up"": true,
  ""availability_zone_hints"": [],
  ""availability_zones"": [
    ""eu-de-01"",
    ""eu-de-02"",
    ""eu-de-03""
  ],
  ""created_at"": ""2021-04-27T13:31:13"",
  ""dns_domain"": ""eu-de.compute.internal."",
  ""id"": ""nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn"",
  ""name"": ""zzzzzzzzzzzzzzyyyyyyyyyyyyyyyyyy"",
  ""port_security_enabled"": true,
  ""project_id"": ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"",
  ""provider:network_type"": ""vxlan"",
  ""router:external"": false,
  ""shared"": false,
  ""status"": ""ACTIVE"",
  ""subnets"": [
    ""gggggggggggggggggggggggggggggggggggggggg""
  ],
  ""tenant_id"": ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"",
  ""updated_at"": ""2021-04-27T13:31:13""
},
{
  ""admin_state_up"": true,
  ""availability_zone_hints"": [],
  ""availability_zones"": [
    ""eu-de-01"",
    ""eu-de-02"",
    ""eu-de-03""
  ],
  ""created_at"": ""2020-10-15T14:50:35"",
  ""dns_domain"": ""eu-de.compute.internal."",
  ""id"": ""mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm"",
  ""name"": ""zzzzzzzzzzzzzzyyyyyyyyyyyyyyyyyy"",
  ""port_security_enabled"": true,
  ""project_id"": ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"",
  ""provider:network_type"": ""vxlan"",
  ""router:external"": false,
  ""shared"": false,
  ""status"": ""ACTIVE"",
  ""subnets"": [
    ""fffffffffffffffffffffffffffffffffff""
  ],
  ""tenant_id"": ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"",
  ""updated_at"": ""2020-10-15T14:50:35""
}

etworks_links"": [
{
  ""href"": ""https://vpc.eu-de.otc.t-systems.com/v2.0/networks?limit=2000\u0026shared=False\u0026router:external=False\u0026name=zzzzzzzzzzzzzzyyyyyyyyyyyyyyyyyy\u0026provider:network_type=vxlan\u0026provider:network_type=geneve\u0026status=ACTIVE\u0026marker=xxxxxxxxxxxxxxxxyyyyyyyyyyyyyyyyyyyyyyyy\u0026page_reverse=true"",
  ""rel"": ""previous""
}
2021-04-30T05:51:22.613+0200 [DEBUG] provider.terraform-provider-opentelekomcloud_v1.23.9:   ]

```
_Originally posted by @Moep90 in https://github.com/opentelekomcloud/terraform-provider-opentelekomcloud/issues/1023#issuecomment-829789132_","[ECS][IMPORT] opentelekomcloud_compute_instance_v2 seams to not work with multiple Subnet in VPC ## Version ```bash $ terraform --version Terraform v0.15.0 on linux_amd64 + provider registry.terraform.io/opentelekomcloud/opentelekomcloud v1.23.9 ``` Import doesnt work with having a SINGLE interface on the ECS but having multiple VPC-Subnet in the VPC where I try to import it. ## Network I have somethink like this as Network: ```hcl resource ""opentelekomcloud_vpc_v1"" ""vpc_v1"" { name = var.vpc_name cidr = var.vpc_cidr } resource ""opentelekomcloud_vpc_subnet_v1"" ""subnet_1"" { name = var.subnet_name_1 cidr = var.subnet_cidr_1 vpc_id = opentelekomcloud_vpc_v1.vpc_v1.id gateway_ip = var.subnet_gateway_ip_1 ntp_addresses = ""10.100.0.33,10.100.0.34"" } resource ""opentelekomcloud_vpc_subnet_v1"" ""subnet_2"" { name = var.subnet_name_2 cidr = var.subnet_cidr_2 vpc_id = opentelekomcloud_vpc_v1.vpc_v1.id gateway_ip = var.subnet_gateway_ip_2 ntp_addresses = ""10.100.0.33,10.100.0.34"" } resource ""opentelekomcloud_vpc_subnet_v1"" ""subnet_3"" { name = var.subnet_name_3 cidr = var.subnet_cidr_3 vpc_id = opentelekomcloud_vpc_v1.vpc_v1.id gateway_ip = var.subnet_gateway_ip_3 ntp_addresses = ""10.100.0.33,10.100.0.34"" } ``` ## ECS Instance The instance looks like: I double checked that the Instances is (for real) only connected to ONE network... ```hcl resource ""opentelekomcloud_compute_instance_v2"" ""ecs_instance"" { name = ""boot-from-volume"" flavor_id = var.flavor_id key_pair = var.key_pair image_id = var.image_id network { id = opentelekomcloud_vpc_subnet_v1.subnet_2.id fixed_ip_v4 = ""<fixed_ip_v4>"" } } ``` ## Import try @outcatcher ```bash $ terraform import opentelekomcloud_compute_instance_v2.ecs_instance xxxxxxxxxxxxxxx-yyyyyyyyyyyyyyy opentelekomcloud_compute_instance_v2.ecs_instance: Importing from ID ""xxxxxxxxxxxxxxx-yyyyyyyyyyyyyyy""... opentelekomcloud_compute_instance_v2.ecs_instance: Import prepared! Prepared opentelekomcloud_compute_instance_v2 for import opentelekomcloud_compute_instance_v2.ecs_instance: Refreshing state... [id=xxxxxxxxxxxxxxx-yyyyyyyyyyyyyyy] Error: Error trying to get network information from the Network API: More than one network found for name <ID of the VPC> ``` ## API API Response is like: ``` ""networks"": [ { ""admin_state_up"": true, ""availability_zone_hints"": [], ""availability_zones"": [ ""eu-de-01"", ""eu-de-02"", ""eu-de-03"" ], ""created_at"": ""2021-04-27T13:32:35"", ""dns_domain"": ""eu-de.compute.internal."", ""id"": ""xxxxxxxxxxxxxxxxyyyyyyyyyyyyyyyyyyyyyyyy"", ""name"": ""zzzzzzzzzzzzzzyyyyyyyyyyyyyyyyyy"", ""port_security_enabled"": true, ""project_id"": ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"", ""provider:network_type"": ""vxlan"", ""router:external"": false, ""shared"": false, ""status"": ""ACTIVE"", ""subnets"": [ ""zzzzzzzzzzzzzzzzzzzzzzz"" ], ""tenant_id"": ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"", ""updated_at"": ""2021-04-27T13:32:35"" }, { ""admin_state_up"": true, ""availability_zone_hints"": [], ""availability_zones"": [ ""eu-de-01"", ""eu-de-02"", ""eu-de-03"" ], ""created_at"": ""2021-04-27T13:31:13"", ""dns_domain"": ""eu-de.compute.internal."", ""id"": ""nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn"", ""name"": ""zzzzzzzzzzzzzzyyyyyyyyyyyyyyyyyy"", ""port_security_enabled"": true, ""project_id"": ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"", ""provider:network_type"": ""vxlan"", ""router:external"": false, ""shared"": false, ""status"": ""ACTIVE"", ""subnets"": [ ""gggggggggggggggggggggggggggggggggggggggg"" ], ""tenant_id"": ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"", ""updated_at"": ""2021-04-27T13:31:13"" }, { ""admin_state_up"": true, ""availability_zone_hints"": [], ""availability_zones"": [ ""eu-de-01"", ""eu-de-02"", ""eu-de-03"" ], ""created_at"": ""2020-10-15T14:50:35"", ""dns_domain"": ""eu-de.compute.internal."", ""id"": ""mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm"", ""name"": ""zzzzzzzzzzzzzzyyyyyyyyyyyyyyyyyy"", ""port_security_enabled"": true, ""project_id"": ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"", ""provider:network_type"": ""vxlan"", ""router:external"": false, ""shared"": false, ""status"": ""ACTIVE"", ""subnets"": [ ""fffffffffffffffffffffffffffffffffff"" ], ""tenant_id"": ""xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"", ""updated_at"": ""2020-10-15T14:50:35"" } etworks_links"": [ { ""href"": ""https://vpc.eu-de.otc.t-systems.com/v2.0/networks?limit=2000\u0026shared=False\u0026router:external=False\u0026name=zzzzzzzzzzzzzzyyyyyyyyyyyyyyyyyy\u0026provider:network_type=vxlan\u0026provider:network_type=geneve\u0026status=ACTIVE\u0026marker=xxxxxxxxxxxxxxxxyyyyyyyyyyyyyyyyyyyyyyyy\u0026page_reverse=true"", ""rel"": ""previous"" } 2021-04-30T05:51:22.613+0200 [DEBUG] provider.terraform-provider-opentelekomcloud_v1.23.9: ] ``` _Originally posted by @Moep90 in https://github.com/opentelekomcloud/terraform-provider-opentelekomcloud/issues/1023#issuecomment-829789132_"
217212,217212,241542,https://api.github.com/repos/JeeMateTeam/JeeMate-Project/issues/1,1.0,2021-02-15T08:08:12Z,CONTRIBUTOR,https://api.github.com/repos/JeeMateTeam/JeeMate-Project,Favoris / Applications / raccourcis (챕cran d'acceuil),"Possibilit챕 d'ajouter en plus d'une application, un raccourcis 챕cran d'accueil.
Ex une page fullscreeen Chrome","Favoris / Applications / raccourcis (챕cran d'acceuil) Possibilit챕 d'ajouter en plus d'une application, un raccourcis 챕cran d'accueil. Ex une page fullscreeen Chrome"
665856,665856,740101,https://api.github.com/repos/devinit/ddw-analyst-ui/issues/399,1.0,2021-01-25T12:02:47Z,CONTRIBUTOR,https://api.github.com/repos/devinit/ddw-analyst-ui,Show feedback on making breaking changes to a query builder step,"e.g. With 2 steps, one a selected & the next one a filter, if the select step is edited to remove the column being filtered in step 2, a warning should at least be shown about this.","Show feedback on making breaking changes to a query builder step e.g. With 2 steps, one a selected & the next one a filter, if the select step is edited to remove the column being filtered in step 2, a warning should at least be shown about this."
133162,133162,147999,https://api.github.com/repos/GrapheneOS/os_issue_tracker/issues/410,0.0,2020-12-21T17:27:20Z,NONE,https://api.github.com/repos/GrapheneOS/os_issue_tracker,Face Unlock randomly got deleted,"Hi, recently I've been noticing that after switching from profiles, the face data would sometimes be deleted.

I'm using Pixel 4 XL with RQ1A.201205.008.2020.12.12.03. I have currently set up three profiles: administrator profile with face unlock added and the other two don't.

Any help would be appreciated, thanks!","Face Unlock randomly got deleted Hi, recently I've been noticing that after switching from profiles, the face data would sometimes be deleted. I'm using Pixel 4 XL with RQ1A.201205.008.2020.12.12.03. I have currently set up three profiles: administrator profile with face unlock added and the other two don't. Any help would be appreciated, thanks!"
144346,144346,160450,https://api.github.com/repos/satijalab/seurat/issues/3963,0.0,2021-01-22T14:00:07Z,NONE,https://api.github.com/repos/satijalab/seurat,SCTransform crashes R with large dataset?,"<!-- Briefly describe your problem and what output you expect. If you have a question, please use the analysis question template instead. -->
I am trying to run SCTransform on a large (200k cell dataset) and it crashes at 69% each time during the second step (getting residuals). This does not occur for other large datasets I have used (~120k cells) or for trial datasets, or with standard normalization methods. Any advice? 
<!-- Before posting an issue, ensure that the bug is reproducible by re-running the code that produced the issue in a new R session.-->
![image](https://user-images.githubusercontent.com/65360421/105499455-7fd9f000-5c8f-11eb-8950-7ba7ccda6d1a.png)

<!-- Please include a minimal reproducible code example. You can use the small test data included in Seurat (`pbmc_small`) to demonstrate the issue, or a public dataset (for example, a dataset available through SeuratData https://github.com/satijalab/seurat-data). If you cannot reproduce the issue using a public dataset, please still provide code that reproduces the issue on your data and we will try to address it. -->

<!-- Please include the output of `sessionInfo()` and your operating system in your issue. -->

```r
# insert reproducible example here
```
","SCTransform crashes R with large dataset? <!-- Briefly describe your problem and what output you expect. If you have a question, please use the analysis question template instead. --> I am trying to run SCTransform on a large (200k cell dataset) and it crashes at 69% each time during the second step (getting residuals). This does not occur for other large datasets I have used (~120k cells) or for trial datasets, or with standard normalization methods. Any advice? <!-- Before posting an issue, ensure that the bug is reproducible by re-running the code that produced the issue in a new R session.--> ![image](https://user-images.githubusercontent.com/65360421/105499455-7fd9f000-5c8f-11eb-8950-7ba7ccda6d1a.png) <!-- Please include a minimal reproducible code example. You can use the small test data included in Seurat (`pbmc_small`) to demonstrate the issue, or a public dataset (for example, a dataset available through SeuratData https://github.com/satijalab/seurat-data). If you cannot reproduce the issue using a public dataset, please still provide code that reproduces the issue on your data and we will try to address it. --> <!-- Please include the output of `sessionInfo()` and your operating system in your issue. --> ```r # insert reproducible example here ``` "
365834,365834,406679,https://api.github.com/repos/sminozhenko/OneMoreActionQueueFramework/issues/13,1.0,2021-01-10T13:35:39Z,OWNER,https://api.github.com/repos/sminozhenko/OneMoreActionQueueFramework,Implement manual mass processing from action queue,At the moment one action can be processed at a time. The batch processing option should be removed for manual processing.,Implement manual mass processing from action queue At the moment one action can be processed at a time. The batch processing option should be removed for manual processing.
175568,175568,195202,https://api.github.com/repos/brabbuss/swapi-challenge-fe/issues/4,1.0,2021-04-12T15:20:19Z,OWNER,https://api.github.com/repos/brabbuss/swapi-challenge-fe,Testing,"As a dev, I want to implement unit, integration testing at the least drawing on Jest/React Testing Library. As a stretch, full E2E with cypress.","Testing As a dev, I want to implement unit, integration testing at the least drawing on Jest/React Testing Library. As a stretch, full E2E with cypress."
477638,477638,530818,https://api.github.com/repos/jerosoler/Drawflow/issues/163,2.0,2021-04-27T11:58:55Z,NONE,https://api.github.com/repos/jerosoler/Drawflow,how to change input /output bubble to triangle shape,,how to change input /output bubble to triangle shape 
732445,732445,95014,https://api.github.com/repos/flybywiresim/a32nx/issues/3329,0.0,2021-02-04T09:04:54Z,NONE,https://api.github.com/repos/flybywiresim/a32nx,[BUG] Fail of engine 1 in descend ,"<!--  Do not delete this issue template!  -->
<!-- Issues that do not use the issue template are likely to be ignored and closed. -->


**Mod Version**
Master 2021/03/02

**Describe the bug**
When A/C in descend engine 1 failed with warning message.
FOB is enough on board.

**To Reproduce**
1. Go to descend
2. on the last half of descend eng. 1 failed
3. i tried it 5 times on different routes

**Expected behavior**
did not happen with vers. 0.52
**References**
see screenshot

**Additional context**
tried it in icing conditions also without

Is this a problem in the vanilla unmodded game?
Fly only vers 0.52 or master 

![Shutdown Eng1 descend](https://user-images.githubusercontent.com/74311635/106869409-2f6f8300-66d0-11eb-95c6-362ba4b32e62.JPG)


",[BUG] Fail of engine 1 in descend <!--  Do not delete this issue template!  --> <!-- Issues that do not use the issue template are likely to be ignored and closed. --> **Mod Version** Master 2021/03/02 **Describe the bug** When A/C in descend engine 1 failed with warning message. FOB is enough on board. **To Reproduce** 1. Go to descend 2. on the last half of descend eng. 1 failed 3. i tried it 5 times on different routes **Expected behavior** did not happen with vers. 0.52 **References** see screenshot **Additional context** tried it in icing conditions also without Is this a problem in the vanilla unmodded game? Fly only vers 0.52 or master ![Shutdown Eng1 descend](https://user-images.githubusercontent.com/74311635/106869409-2f6f8300-66d0-11eb-95c6-362ba4b32e62.JPG) 
349926,349926,389032,https://api.github.com/repos/mtreinish/stestr/issues/162,0.0,2018-04-14T02:17:43Z,OWNER,https://api.github.com/repos/mtreinish/stestr,test_return_code failure on windows,"### Issue description

When running the stestr unit tests in the test_return_codes module in a windows environment we encountered a failure in cleanup trying to remove the temporary directory created to setup the functional environment:

https://ci.appveyor.com/project/mtreinish/stestr/build/1.0.478/job/k9bm98380del4g2x

In case that link ever dies the trace back is:

```
==============================
Failed 1 tests - output below:
==============================
stestr.tests.test_return_codes.TestReturnCodes.test_until_failure_fails_from_func
---------------------------------------------------------------------------------

Captured traceback:
~~~~~~~~~~~~~~~~~~~
    b'Traceback (most recent call last):'
    b'  File ""C:\\projects\\stestr\\.tox\\py36\\lib\\shutil.py"", line 494, in rmtree'
    b'    return _rmtree_unsafe(path, onerror)'
    b'  File ""C:\\projects\\stestr\\.tox\\py36\\lib\\shutil.py"", line 393, in _rmtree_unsafe'
    b'    onerror(os.rmdir, path, sys.exc_info())'
    b'  File ""C:\\projects\\stestr\\.tox\\py36\\lib\\shutil.py"", line 391, in _rmtree_unsafe'
    b'    os.rmdir(path)'
    b""PermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\appveyor\\\\AppData\\\\Local\\\\Temp\\\\1\\\\stestr-unitriyexd7t'""
    b''
```

It looks like the subprocess stestr is still accessing the temporary directory, but it definitely should have exited by the time cleanup is running. So it's not clear why this is failing. It also passed the other 2 jobs on the appveyor build which run the same tests, just with different python versions.","test_return_code failure on windows ### Issue description When running the stestr unit tests in the test_return_codes module in a windows environment we encountered a failure in cleanup trying to remove the temporary directory created to setup the functional environment: https://ci.appveyor.com/project/mtreinish/stestr/build/1.0.478/job/k9bm98380del4g2x In case that link ever dies the trace back is: ``` ============================== Failed 1 tests - output below: ============================== stestr.tests.test_return_codes.TestReturnCodes.test_until_failure_fails_from_func --------------------------------------------------------------------------------- Captured traceback: ~~~~~~~~~~~~~~~~~~~ b'Traceback (most recent call last):' b' File ""C:\\projects\\stestr\\.tox\\py36\\lib\\shutil.py"", line 494, in rmtree' b' return _rmtree_unsafe(path, onerror)' b' File ""C:\\projects\\stestr\\.tox\\py36\\lib\\shutil.py"", line 393, in _rmtree_unsafe' b' onerror(os.rmdir, path, sys.exc_info())' b' File ""C:\\projects\\stestr\\.tox\\py36\\lib\\shutil.py"", line 391, in _rmtree_unsafe' b' os.rmdir(path)' b""PermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\appveyor\\\\AppData\\\\Local\\\\Temp\\\\1\\\\stestr-unitriyexd7t'"" b'' ``` It looks like the subprocess stestr is still accessing the temporary directory, but it definitely should have exited by the time cleanup is running. So it's not clear why this is failing. It also passed the other 2 jobs on the appveyor build which run the same tests, just with different python versions."
525969,525969,584575,https://api.github.com/repos/sorry-cypress/sorry-cypress/issues/230,0.0,2020-12-19T14:48:32Z,CONTRIBUTOR,https://api.github.com/repos/sorry-cypress/sorry-cypress,Reduce dashboard memory usage,"Just for curiosity i monitored the memory usage of the cypress docker setup and was a little bit surprised, seeing the dashboard using around 200-250MB, while all the other are fine with 50-60MB. From my understanding the dashboard is only serving the client application (aka static files) to the browsers. Normally one would expect this is a job, a simple nginx with 5MB usage can handle. As infrastructure costs is mostly related to memory usage for sorry-cypress I would like to ask, if there is a chance to reduce the memory usage.

Could you give some insights, what the dashboard docker service is actually doing?

I have searched for similar issues. There is only one (#46) mentioning the high memory usage, but basically dealing with another topic.

","Reduce dashboard memory usage Just for curiosity i monitored the memory usage of the cypress docker setup and was a little bit surprised, seeing the dashboard using around 200-250MB, while all the other are fine with 50-60MB. From my understanding the dashboard is only serving the client application (aka static files) to the browsers. Normally one would expect this is a job, a simple nginx with 5MB usage can handle. As infrastructure costs is mostly related to memory usage for sorry-cypress I would like to ask, if there is a chance to reduce the memory usage. Could you give some insights, what the dashboard docker service is actually doing? I have searched for similar issues. There is only one (#46) mentioning the high memory usage, but basically dealing with another topic. "
27821,27821,30990,https://api.github.com/repos/athal7/homebridge-hyundai-bluelink/issues/7,0.0,2021-02-23T23:52:53Z,NONE,https://api.github.com/repos/athal7/homebridge-hyundai-bluelink,[Hyundai] maxRange is undefined,"<!-- You must use the issue template below when submitting a bug -->

**Describe The Bug:**
This error pops up in the logs every time it checks. I've tried plugging in different values, swapping the order of maxRange and VIN so I could make sure there weren't linefeed/whitespace issues with the value, making it a string so I could append ""mi"" to it. Nothing works to remove the error. Other integer values in the config are fine. The only thing I get in homekit from the plugin is locks and on/off. Vehicle is a 2021 Kona EV.

**To Reproduce:**
This happens automatically with each check.

**Expected behavior:**
No error in logs. Charge level reported in HomeKit

**Logs:**

```
[2/23/2021, 2:01:53 PM] [Hyundai] maxRange is undefined
[2/23/2021, 2:11:54 PM] [Hyundai] maxRange is undefined
[2/23/2021, 2:21:53 PM] [Hyundai] maxRange is undefined
[2/23/2021, 2:31:53 PM] [Hyundai] maxRange is undefined
```

**Plugin Config:**

```json
{
            ""credentials"": {
                ""username"": ""[redacted]"",
                ""password"": ""[redacted]"",
                ""region"": ""US"",
                ""pin"": ""[redacted]""
            },
            ""vehicles"": [
                {
                    ""vin"": ""[redacted]"",
                    ""maxRange"": 258
                }
            ],
            ""remoteStart"": {
                ""cool"": false,
                ""heat"": false,
                ""defrost"": false,
                ""igniOnDuration"": 15
            },
            ""refreshInterval"": 600,
            ""platform"": ""Hyundai""
        }
```


**Environment:**

* **Plugin Version**: 1.2.11
* **Homebridge Version**: 1.3.1 and a few prior
* **Node.js Version**: 14.15.5
* **NPM Version**: 6.14.11
* **Operating System**: Debian Buster
","[Hyundai] maxRange is undefined <!-- You must use the issue template below when submitting a bug --> **Describe The Bug:** This error pops up in the logs every time it checks. I've tried plugging in different values, swapping the order of maxRange and VIN so I could make sure there weren't linefeed/whitespace issues with the value, making it a string so I could append ""mi"" to it. Nothing works to remove the error. Other integer values in the config are fine. The only thing I get in homekit from the plugin is locks and on/off. Vehicle is a 2021 Kona EV. **To Reproduce:** This happens automatically with each check. **Expected behavior:** No error in logs. Charge level reported in HomeKit **Logs:** ``` [2/23/2021, 2:01:53 PM] [Hyundai] maxRange is undefined [2/23/2021, 2:11:54 PM] [Hyundai] maxRange is undefined [2/23/2021, 2:21:53 PM] [Hyundai] maxRange is undefined [2/23/2021, 2:31:53 PM] [Hyundai] maxRange is undefined ``` **Plugin Config:** ```json { ""credentials"": { ""username"": ""[redacted]"", ""password"": ""[redacted]"", ""region"": ""US"", ""pin"": ""[redacted]"" }, ""vehicles"": [ { ""vin"": ""[redacted]"", ""maxRange"": 258 } ], ""remoteStart"": { ""cool"": false, ""heat"": false, ""defrost"": false, ""igniOnDuration"": 15 }, ""refreshInterval"": 600, ""platform"": ""Hyundai"" } ``` **Environment:** * **Plugin Version**: 1.2.11 * **Homebridge Version**: 1.3.1 and a few prior * **Node.js Version**: 14.15.5 * **NPM Version**: 6.14.11 * **Operating System**: Debian Buster "
513073,513073,570186,https://api.github.com/repos/sansoohan/team/issues/36,0.0,2021-03-01T13:40:23Z,OWNER,https://api.github.com/repos/sansoohan/team,Video Recording is not working,codec=h264 -> codecs=h264,Video Recording is not working codec=h264 -> codecs=h264
583746,583746,648682,https://api.github.com/repos/jerosoler/Drawflow/issues/83,2.0,2020-12-04T10:24:14Z,NONE,https://api.github.com/repos/jerosoler/Drawflow,Export Button ,Where is the  generated JSON file is downloaded ? ,Export Button Where is the generated JSON file is downloaded ? 
531433,531433,590655,https://api.github.com/repos/tree-sitter/tree-sitter/issues/778,0.0,2020-10-23T16:41:58Z,CONTRIBUTOR,https://api.github.com/repos/tree-sitter/tree-sitter,Multiple regex ranges slow parser generation down.,"The following grammar takes relative to its size a long time to generate.

```javascript
module.exports = grammar({
  name: 'sparql',

  rules: {
    pn_chars_base: $ => choice(
      /[A-Z]/,
      /[a-z]/,
      /[\u00C0-\u00D6]/,
      /[\u00D8-\u00F6]/,
      /[\u00F8-\u02FF]/,
      /[\u0370-\u037D]/,
      /[\u037F-\u1FFF]/,
      /[\u200C-\u200D]/,
      /[\u2070-\u218F]/,
      /[\u2C00-\u2FEF]/,
      /[\u3001-\uD7FF]/,
      /[\uF900-\uFDCF]/,
      /[\uFDF0-\uFFFD]/,
      /[\u{10000}-\u{EFFFF}]/u
    ),

    pn_chars_u: $ => choice(
      $.pn_chars_base,
      '_'
    ),
  }
})
```","Multiple regex ranges slow parser generation down. The following grammar takes relative to its size a long time to generate. ```javascript module.exports = grammar({ name: 'sparql', rules: { pn_chars_base: $ => choice( /[A-Z]/, /[a-z]/, /[\u00C0-\u00D6]/, /[\u00D8-\u00F6]/, /[\u00F8-\u02FF]/, /[\u0370-\u037D]/, /[\u037F-\u1FFF]/, /[\u200C-\u200D]/, /[\u2070-\u218F]/, /[\u2C00-\u2FEF]/, /[\u3001-\uD7FF]/, /[\uF900-\uFDCF]/, /[\uFDF0-\uFFFD]/, /[\u{10000}-\u{EFFFF}]/u ), pn_chars_u: $ => choice( $.pn_chars_base, '_' ), } }) ```"
741975,741975,189605,https://api.github.com/repos/AdguardTeam/AdguardForWindows/issues/3691,2.0,2021-02-12T15:30:34Z,NONE,https://api.github.com/repos/AdguardTeam/AdguardForWindows,AdGuard for Windows (App) do not support the $popup modifier,"Does AdGuard for Windows support this syntax? `||ref.gitadres.com^$popup` or this `
||adshort.media^$document,popup`? Websites which uses this kind of pop-up get closed/ blocked by the AdGuard AdBlocker Extension immediately when the pop-up is triggered but not with AdGuard App. With the AdGuard Windows app it requires an additional scriptlet rule or a HTML rule to block the particular pop-up. Moreover, I don't think it supports this syntax.
","AdGuard for Windows (App) do not support the $popup modifier Does AdGuard for Windows support this syntax? `||ref.gitadres.com^$popup` or this ` ||adshort.media^$document,popup`? Websites which uses this kind of pop-up get closed/ blocked by the AdGuard AdBlocker Extension immediately when the pop-up is triggered but not with AdGuard App. With the AdGuard Windows app it requires an additional scriptlet rule or a HTML rule to block the particular pop-up. Moreover, I don't think it supports this syntax. "
330111,330111,367002,https://api.github.com/repos/WWBN/AVideo/issues/5220,2.0,2021-05-26T13:45:02Z,CONTRIBUTOR,https://api.github.com/repos/WWBN/AVideo,Manage files via API,"Does platform have API available through which I could upload files and manage them?

Manage users with API?


",Manage files via API Does platform have API available through which I could upload files and manage them? Manage users with API? 
566192,566192,629199,https://api.github.com/repos/m4rs-mt/ILGPU/issues/400,2.0,2021-01-25T19:26:50Z,NONE,https://api.github.com/repos/m4rs-mt/ILGPU,10 sec delay after data transfer from CPU to GPU,"Hello.
I have in issues,  i have 3GB of data to load to GPU and i am doing it like this:

```
class SomeClass
{
   Context cntx = null;
   CudaAccelerator ca = null;
   Pix[,,] pix = null;
   public void f()
    {
        pix = new Pix[ImagesLen, ImgHeight, ImgWidth]; // in my case  Pix[166120, 286, 226] = 3Gb , and pix gives 3 byte 
        // Here code that fill pix array
        //  .........
        //Context and CudaAccelerator already loading and working 
        MemoryBuffer3D<Pix> mbpix = null;
        mbpix = ca.Allocate<Pix>(pix);    /// And the result is that , this function work too slow - 7 sec of 3 Gb data
    }
}
strct Pix  // struct Not a class 
{
   public byte r;
   public byte g;
   public byte b;
}
```
I think this is some kind problem, becase can;t that 3 gb trasfers about 10 sec
or possible i am Wrong.
Please Help...
","10 sec delay after data transfer from CPU to GPU Hello. I have in issues, i have 3GB of data to load to GPU and i am doing it like this: ``` class SomeClass { Context cntx = null; CudaAccelerator ca = null; Pix[,,] pix = null; public void f() { pix = new Pix[ImagesLen, ImgHeight, ImgWidth]; // in my case Pix[166120, 286, 226] = 3Gb , and pix gives 3 byte // Here code that fill pix array // ......... //Context and CudaAccelerator already loading and working MemoryBuffer3D<Pix> mbpix = null; mbpix = ca.Allocate<Pix>(pix); /// And the result is that , this function work too slow - 7 sec of 3 Gb data } } strct Pix // struct Not a class { public byte r; public byte g; public byte b; } ``` I think this is some kind problem, becase can;t that 3 gb trasfers about 10 sec or possible i am Wrong. Please Help... "
258491,258491,287479,https://api.github.com/repos/CyanLaser/CyanTrigger/issues/13,1.0,2021-04-21T01:14:52Z,OWNER,https://api.github.com/repos/CyanLaser/CyanTrigger,Save expanded Events and Actions,Clicking on a trigger always has all events expanded and all actions collapsed. Save which were last open.,Save expanded Events and Actions Clicking on a trigger always has all events expanded and all actions collapsed. Save which were last open.
469309,469309,521590,https://api.github.com/repos/origo-map/origo/issues/1090,0.0,2021-01-13T13:05:44Z,NONE,https://api.github.com/repos/origo-map/origo,Editor control not working as expected,"**Describe the bug**
Editor control not working as expected

**To Reproduce**
1. Test using examples/editor.html 
2. Deactivate editor using button should close toolbar.
3. Change layer in dropdown and try to draw using + button results in error in chromedevtools ""Uncaught TypeError: Cannot read property 'getSource' of undefined""","Editor control not working as expected **Describe the bug** Editor control not working as expected **To Reproduce** 1. Test using examples/editor.html 2. Deactivate editor using button should close toolbar. 3. Change layer in dropdown and try to draw using + button results in error in chromedevtools ""Uncaught TypeError: Cannot read property 'getSource' of undefined"""
558117,558117,620294,https://api.github.com/repos/BjerknesClimateDataCentre/QuinCe/issues/2041,0.0,2021-03-26T13:07:53Z,COLLABORATOR,https://api.github.com/repos/BjerknesClimateDataCentre/QuinCe,Do not include flushing values in export,Simon Stevin exports include the flushing values for xCO2 and xH2O. They should not.,Do not include flushing values in export Simon Stevin exports include the flushing values for xCO2 and xH2O. They should not.
435028,435028,483621,https://api.github.com/repos/jtcarlos/radiant-satisfaction/issues/1,1.0,2021-03-16T13:40:30Z,OWNER,https://api.github.com/repos/jtcarlos/radiant-satisfaction,app(feat): initialize gatsby react environment,Initialize boilerplate Gatsby ReactJS,app(feat): initialize gatsby react environment Initialize boilerplate Gatsby ReactJS
230698,230698,256546,https://api.github.com/repos/AmazonSR/ams/issues/57,1.0,2021-05-26T14:06:18Z,COLLABORATOR,https://api.github.com/repos/AmazonSR/ams,Rearrange and translate map controllers,Translate to pt-BR.,Rearrange and translate map controllers Translate to pt-BR.
63783,63783,70918,https://api.github.com/repos/xournalpp/xournalpp/issues/2464,0.0,2020-11-30T05:31:30Z,COLLABORATOR,https://api.github.com/repos/xournalpp/xournalpp,Invalid stroke width or image dimensions leading to disappearing selections and missing parts in pdf export,"**Affects versions :**
 - OS: doesn't matter, I guess
  - Which version of libgtk do you use: doesn't matter, I guess
 - Version of Xournal++: 1.0.18, 1.0.19, 1.1.0+dev (possibly others)
 - Installation method: doesn't matter, I guess

**Describe the bug**
Xournal++ sometimes stores `-NaN` as a stroke width (see #2372, #2168), which causes trouble using the selection tools (parts of the document disappear, the cursor update looks flawed, and exporting the pdf can make Xournal++ crash

Xournal++ also sometimes stores images with 0 width and height (and 0's as x and y-offsets) and strokes with all 0's as width, see [this file](https://files.gitter.im/5647729516b6c7089cbab6bf/UfoH/aula11.xopp) reported on the Gitter channel, which leads to similar misbehavior.

**To Reproduce**
It's not clear yet, how these strokes and images are created. Once they are created it's easy to reproduce following the steps described in #2372. 

**Expected behavior**
Width `-NaN` should not be possible. Such strokes should get filtered out immediately when they are created. Similarly for strokes with all 0's as width and images with 0 width and/or height. 

**Screenshots of Problem**
See #2372. 

**Additional context**
The problem with images of zero width and height may be related to undo operation. If you insert an image and undo its insertion, you will see the edit selection at the top left corner of the document with 0 width and height. I couldn't reproduce getting it saved in the xopp-file though.","Invalid stroke width or image dimensions leading to disappearing selections and missing parts in pdf export **Affects versions :** - OS: doesn't matter, I guess - Which version of libgtk do you use: doesn't matter, I guess - Version of Xournal++: 1.0.18, 1.0.19, 1.1.0+dev (possibly others) - Installation method: doesn't matter, I guess **Describe the bug** Xournal++ sometimes stores `-NaN` as a stroke width (see #2372, #2168), which causes trouble using the selection tools (parts of the document disappear, the cursor update looks flawed, and exporting the pdf can make Xournal++ crash Xournal++ also sometimes stores images with 0 width and height (and 0's as x and y-offsets) and strokes with all 0's as width, see [this file](https://files.gitter.im/5647729516b6c7089cbab6bf/UfoH/aula11.xopp) reported on the Gitter channel, which leads to similar misbehavior. **To Reproduce** It's not clear yet, how these strokes and images are created. Once they are created it's easy to reproduce following the steps described in #2372. **Expected behavior** Width `-NaN` should not be possible. Such strokes should get filtered out immediately when they are created. Similarly for strokes with all 0's as width and images with 0 width and/or height. **Screenshots of Problem** See #2372. **Additional context** The problem with images of zero width and height may be related to undo operation. If you insert an image and undo its insertion, you will see the edit selection at the top left corner of the document with 0 width and height. I couldn't reproduce getting it saved in the xopp-file though."
596619,596619,663043,https://api.github.com/repos/open-telemetry/opentelemetry-php/issues/222,1.0,2020-11-24T14:55:49Z,CONTRIBUTOR,https://api.github.com/repos/open-telemetry/opentelemetry-php,PHP Documentor,"We should create some autogenerated documentation.  

I'm going to propose that we use https://www.phpdoc.org/ but I'm also very open to suggestions on what to use for this autogenerated documentation.",PHP Documentor We should create some autogenerated documentation. I'm going to propose that we use https://www.phpdoc.org/ but I'm also very open to suggestions on what to use for this autogenerated documentation.
215318,215318,239428,https://api.github.com/repos/confluentinc/confluent-kafka-python/issues/874,0.0,2020-05-18T17:01:36Z,NONE,https://api.github.com/repos/confluentinc/confluent-kafka-python,"SIGSEGV, Objects/unicodeobject.c: No such file or directory. randomly on consumer re-connecting to broker","Description
===========
I have a consumer implemented like this:

`

	class KafkaReader:

		def __init__(self, topics: List[str], config: Dict, timeout: float = 1):
			self._consumer = Consumer(config)
			self._consumer.subscribe(topics)
			self._topics = topics
			self._timeout = timeout

		def read(self):
			while True:
				message = self._consumer.poll(timeout=self._timeout)
				if message is None:
					continue
				self._consumer.store_offsets(message)
				if message.error():
					logger.error(
						""Kafka error"", topic=message.topic(), error=message.error()
					)
					continue
				yield KafkaMessage(...)

`

It randomly fails with SIGSEGV when trying to re-connect to broker. I've captured the following log using gdb (edited for anonymization). It shows both successful re-connection and failure with segmentation fault.

`

 %7|1589814027.729|REBALANCE|rdkafka#consumer-1| [thrd:main]: Group ""kafka-group-id "" is rebalancing in state up (join-state started) with assignment: group is rebalancing        
 %7|1589814027.729|ASSIGN|rdkafka#consumer-1| [thrd:main]: Group ""kafka-group-id "": new assignment of 0 partition(s) in join state wait-revoke-rebalance_cb                        
 %7|1589814027.729|UNASSIGN|rdkafka#consumer-1| [thrd:main]: Group ""kafka-group-id "": unassigning 5 partition(s) (v6)                                                              
 %7|1589814027.729|JOIN|rdkafka#consumer-1| [thrd:main]: 10.61.32.88:9092/1004: Joining group ""kafka-group-id "" with 1 subscribed topic(s)                                         
 %7|1589814028.733|ASSIGN|rdkafka#consumer-1| [thrd:main]: Group ""kafka-group-id "": new assignment of 5 partition(s) in join state wait-assign-rebalance_cb                        
 %7|1589814028.734|OFFSET|rdkafka#consumer-1| [thrd:main]: GroupCoordinator/1004: Fetch committed offsets for 5/5 partition(s)                                                                   
 %7|1589814028.734|FETCH|rdkafka#consumer-1| [thrd:main]: Partition my.topic [0] start fetching at offset 176905                                           
 %7|1589814028.734|FETCH|rdkafka#consumer-1| [thrd:main]: Partition my.topic [1] start fetching at offset 177036                                           
 %7|1589814028.734|FETCH|rdkafka#consumer-1| [thrd:main]: Partition my.topic [2] start fetching at offset 183135                                           
 %7|1589814028.734|FETCH|rdkafka#consumer-1| [thrd:main]: Partition my.topic [3] start fetching at offset 175680                                           
 %7|1589814028.734|FETCH|rdkafka#consumer-1| [thrd:main]: Partition my.topic [4] start fetching at offset 177818                                           

*********************************** 

%7|1589815172.579|BROKERFAIL|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: failed: err: Local: Broker transport failure: (errno: Connection reset by peer)                                                                                                                                                                    
 %7|1589815172.579|STATE|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Broker changed state UP -> DOWN          
 %7|1589815172.579|REQERR|rdkafka#consumer-1| [thrd:main]: broker.test.com:9092/bootstrap: MetadataRequest failed: Local: Broker transport failure: actions Retry              
 %7|1589815172.579|STATE|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Broker changed state DOWN -> INIT        
 %7|1589815172.679|STATE|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Broker changed state INIT -> TRY_CONNECT                                                                                                                                                                                                                
 %7|1589815172.679|RETRY|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Moved 1 retry buffer(s) to output queue  
 %7|1589815173.579|CONNECT|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: broker in state TRY_CONNECT connecting                                                                                                                                                                                                                
 %7|1589815173.579|STATE|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Broker changed state TRY_CONNECT -> CONNECT                                                                                                                                                                                                             
 %7|1589815173.604|CONNECT|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Connecting to ipv4#127.0.0.1:9092 (plaintext) with socket 9 
 %7|1589815173.605|CONNECT|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Connected to ipv4#127.0.0.1:9092    
 %7|1589815173.605|CONNECTED|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Connected (#2)                       
 %7|1589815173.605|STATE|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Broker changed state CONNECT -> APIVERSION_QUERY                                                                                                                                                                                                        
 %7|1589815173.606|PROTOERR|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Protocol parse failure for ApiVersion v3 at 3/6 (rd_kafka_handle_ApiVersion:1911) (incorrect broker.version.fallback?)                                                                                                                               
 %7|1589815173.606|PROTOERR|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: ApiArrayCnt -1 out of range           
 %7|1589815173.606|APIVERSION|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: ApiVersionRequest v3 failed due to UNSUPPORTED_VERSION: retrying with v0                                                                                                                                                                           
 %7|1589815173.606|STATE|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Broker changed state APIVERSION_QUERY - > UP                                                                                                                                                                                                             
 %7|1589815776.829|REBALANCE|rdkafka#consumer-1| [thrd:main]: Group ""kafka-group-id "" is rebalancing in state up (join-state started) with assignment: group is rebalancing        
 %7|1589815776.829|ASSIGN|rdkafka#consumer-1| [thrd:main]: Group ""kafka-group-id "": new assignment of 0 partition(s) in join state wait-revoke-rebalance_cb                        
 %7|1589815776.829|UNASSIGN|rdkafka#consumer-1| [thrd:main]: Group ""kafka-group-id "": unassigning 5 partition(s) (v11)                                                             
 %7|1589815776.829|JOIN|rdkafka#consumer-1| [thrd:main]: 10.61.32.88:9092/1004: Joining group ""kafka-group-id "" with 1 subscribed topic(s)                                         
 %7|1589815776.831|ASSIGNOR|rdkafka#consumer-1| [thrd:main]: Group ""kafka-group-id "": ""range"" assignor run for 3 member(s)                                                         
 %7|1589815776.833|ASSIGN|rdkafka#consumer-1| [thrd:main]: Group ""kafka-group-id "": new assignment of 5 partition(s) in join state wait-assign-rebalance_cb                        
 %7|1589815776.833|OFFSET|rdkafka#consumer-1| [thrd:main]: GroupCoordinator/1004: Fetch committed offsets for 5/5 partition(s)                                                                   
 %7|1589815776.834|FETCH|rdkafka#consumer-1| [thrd:main]: Partition my.topic [0] start fetching at offset 176905                                           
 %7|1589815776.834|FETCH|rdkafka#consumer-1| [thrd:main]: Partition my.topic [1] start fetching at offset 177036                                           
 %7|1589815776.834|FETCH|rdkafka#consumer-1| [thrd:main]: Partition my.topic [2] start fetching at offset 183135                                           
 %7|1589815776.834|FETCH|rdkafka#consumer-1| [thrd:main]: Partition my.topic [3] start fetching at offset 175680                                           
 %7|1589815776.834|FETCH|rdkafka#consumer-1| [thrd:main]: Partition my.topic [4] start fetching at offset 177818                                          

***********************************                                         
 
%7|1589816373.600|BROKERFAIL|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: failed: err: Local: Broker transport failure: (errno: Connection reset by peer)                                                                                                                                                                    
 %7|1589816373.600|STATE|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Broker changed state UP -> DOWN          
 %7|1589816373.600|STATE|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Broker changed state DOWN -> INIT        
 3818    Objects/unicodeobject.c: No such file or directory.                                                                                                                                     
 Thread 1 ""python"" received signal SIGSEGV, Segmentation fault.                                                                                                                                  
 0x00007ffff7dc441a in PyUnicode_AsUTF8AndSize (unicode=0x0, psize=0x0)                                                                                                                          
     at Objects/unicodeobject.c:3818                                                                                                                                                             
 (gdb) quit   

`

Is there something that I have to configure additionally to avoid this failure?

Checklist
=========
Please provide the following information:

 - [x] confluent-kafka-python and librdkafka version (`confluent_kafka.version()` and `confluent_kafka.libversion()`):
""confluent_kafka.version(): ('1.4.0', 17039360)""
""confluent_kafka.libversion(): ('1.4.0', 17039615)""
 - [ ] Apache Kafka broker version:
 - [x] Client configuration: 
`

{
    ""bootstrap.servers"": ...,
    ""group.id"": ...,
    ""enable.auto.offset.store"": False,
    ""auto.offset.reset"": ""latest"",
    ""security.protocol"": ...,
    ""debug"": ""consumer,broker"",
}

`
 - [x] Operating system:
PRETTY_NAME=""Debian GNU/Linux 10 (buster)""
NAME=""Debian GNU/Linux""
VERSION_ID=""10""
VERSION=""10 (buster)""
VERSION_CODENAME=buster
ID=debian
 - [x] Provide client logs (with `'debug': '..'` as necessary)
 - [ ] Provide broker log excerpts
 - [ ] Critical issue

","SIGSEGV, Objects/unicodeobject.c: No such file or directory. randomly on consumer re-connecting to broker Description =========== I have a consumer implemented like this: ` class KafkaReader: def __init__(self, topics: List[str], config: Dict, timeout: float = 1): self._consumer = Consumer(config) self._consumer.subscribe(topics) self._topics = topics self._timeout = timeout def read(self): while True: message = self._consumer.poll(timeout=self._timeout) if message is None: continue self._consumer.store_offsets(message) if message.error(): logger.error( ""Kafka error"", topic=message.topic(), error=message.error() ) continue yield KafkaMessage(...) ` It randomly fails with SIGSEGV when trying to re-connect to broker. I've captured the following log using gdb (edited for anonymization). It shows both successful re-connection and failure with segmentation fault. ` %7|1589814027.729|REBALANCE|rdkafka#consumer-1| [thrd:main]: Group ""kafka-group-id "" is rebalancing in state up (join-state started) with assignment: group is rebalancing %7|1589814027.729|ASSIGN|rdkafka#consumer-1| [thrd:main]: Group ""kafka-group-id "": new assignment of 0 partition(s) in join state wait-revoke-rebalance_cb %7|1589814027.729|UNASSIGN|rdkafka#consumer-1| [thrd:main]: Group ""kafka-group-id "": unassigning 5 partition(s) (v6) %7|1589814027.729|JOIN|rdkafka#consumer-1| [thrd:main]: 10.61.32.88:9092/1004: Joining group ""kafka-group-id "" with 1 subscribed topic(s) %7|1589814028.733|ASSIGN|rdkafka#consumer-1| [thrd:main]: Group ""kafka-group-id "": new assignment of 5 partition(s) in join state wait-assign-rebalance_cb %7|1589814028.734|OFFSET|rdkafka#consumer-1| [thrd:main]: GroupCoordinator/1004: Fetch committed offsets for 5/5 partition(s) %7|1589814028.734|FETCH|rdkafka#consumer-1| [thrd:main]: Partition my.topic [0] start fetching at offset 176905 %7|1589814028.734|FETCH|rdkafka#consumer-1| [thrd:main]: Partition my.topic [1] start fetching at offset 177036 %7|1589814028.734|FETCH|rdkafka#consumer-1| [thrd:main]: Partition my.topic [2] start fetching at offset 183135 %7|1589814028.734|FETCH|rdkafka#consumer-1| [thrd:main]: Partition my.topic [3] start fetching at offset 175680 %7|1589814028.734|FETCH|rdkafka#consumer-1| [thrd:main]: Partition my.topic [4] start fetching at offset 177818 *********************************** %7|1589815172.579|BROKERFAIL|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: failed: err: Local: Broker transport failure: (errno: Connection reset by peer) %7|1589815172.579|STATE|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Broker changed state UP -> DOWN %7|1589815172.579|REQERR|rdkafka#consumer-1| [thrd:main]: broker.test.com:9092/bootstrap: MetadataRequest failed: Local: Broker transport failure: actions Retry %7|1589815172.579|STATE|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Broker changed state DOWN -> INIT %7|1589815172.679|STATE|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Broker changed state INIT -> TRY_CONNECT %7|1589815172.679|RETRY|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Moved 1 retry buffer(s) to output queue %7|1589815173.579|CONNECT|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: broker in state TRY_CONNECT connecting %7|1589815173.579|STATE|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Broker changed state TRY_CONNECT -> CONNECT %7|1589815173.604|CONNECT|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Connecting to ipv4#127.0.0.1:9092 (plaintext) with socket 9 %7|1589815173.605|CONNECT|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Connected to ipv4#127.0.0.1:9092 %7|1589815173.605|CONNECTED|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Connected (#2) %7|1589815173.605|STATE|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Broker changed state CONNECT -> APIVERSION_QUERY %7|1589815173.606|PROTOERR|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Protocol parse failure for ApiVersion v3 at 3/6 (rd_kafka_handle_ApiVersion:1911) (incorrect broker.version.fallback?) %7|1589815173.606|PROTOERR|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: ApiArrayCnt -1 out of range %7|1589815173.606|APIVERSION|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: ApiVersionRequest v3 failed due to UNSUPPORTED_VERSION: retrying with v0 %7|1589815173.606|STATE|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Broker changed state APIVERSION_QUERY - > UP %7|1589815776.829|REBALANCE|rdkafka#consumer-1| [thrd:main]: Group ""kafka-group-id "" is rebalancing in state up (join-state started) with assignment: group is rebalancing %7|1589815776.829|ASSIGN|rdkafka#consumer-1| [thrd:main]: Group ""kafka-group-id "": new assignment of 0 partition(s) in join state wait-revoke-rebalance_cb %7|1589815776.829|UNASSIGN|rdkafka#consumer-1| [thrd:main]: Group ""kafka-group-id "": unassigning 5 partition(s) (v11) %7|1589815776.829|JOIN|rdkafka#consumer-1| [thrd:main]: 10.61.32.88:9092/1004: Joining group ""kafka-group-id "" with 1 subscribed topic(s) %7|1589815776.831|ASSIGNOR|rdkafka#consumer-1| [thrd:main]: Group ""kafka-group-id "": ""range"" assignor run for 3 member(s) %7|1589815776.833|ASSIGN|rdkafka#consumer-1| [thrd:main]: Group ""kafka-group-id "": new assignment of 5 partition(s) in join state wait-assign-rebalance_cb %7|1589815776.833|OFFSET|rdkafka#consumer-1| [thrd:main]: GroupCoordinator/1004: Fetch committed offsets for 5/5 partition(s) %7|1589815776.834|FETCH|rdkafka#consumer-1| [thrd:main]: Partition my.topic [0] start fetching at offset 176905 %7|1589815776.834|FETCH|rdkafka#consumer-1| [thrd:main]: Partition my.topic [1] start fetching at offset 177036 %7|1589815776.834|FETCH|rdkafka#consumer-1| [thrd:main]: Partition my.topic [2] start fetching at offset 183135 %7|1589815776.834|FETCH|rdkafka#consumer-1| [thrd:main]: Partition my.topic [3] start fetching at offset 175680 %7|1589815776.834|FETCH|rdkafka#consumer-1| [thrd:main]: Partition my.topic [4] start fetching at offset 177818 *********************************** %7|1589816373.600|BROKERFAIL|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: failed: err: Local: Broker transport failure: (errno: Connection reset by peer) %7|1589816373.600|STATE|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Broker changed state UP -> DOWN %7|1589816373.600|STATE|rdkafka#consumer-1| [thrd:broker.test.com:9092/bootstrap]: broker.test.com:9092/bootstrap: Broker changed state DOWN -> INIT 3818 Objects/unicodeobject.c: No such file or directory. Thread 1 ""python"" received signal SIGSEGV, Segmentation fault. 0x00007ffff7dc441a in PyUnicode_AsUTF8AndSize (unicode=0x0, psize=0x0) at Objects/unicodeobject.c:3818 (gdb) quit ` Is there something that I have to configure additionally to avoid this failure? Checklist ========= Please provide the following information: - [x] confluent-kafka-python and librdkafka version (`confluent_kafka.version()` and `confluent_kafka.libversion()`): ""confluent_kafka.version(): ('1.4.0', 17039360)"" ""confluent_kafka.libversion(): ('1.4.0', 17039615)"" - [ ] Apache Kafka broker version: - [x] Client configuration: ` { ""bootstrap.servers"": ..., ""group.id"": ..., ""enable.auto.offset.store"": False, ""auto.offset.reset"": ""latest"", ""security.protocol"": ..., ""debug"": ""consumer,broker"", } ` - [x] Operating system: PRETTY_NAME=""Debian GNU/Linux 10 (buster)"" NAME=""Debian GNU/Linux"" VERSION_ID=""10"" VERSION=""10 (buster)"" VERSION_CODENAME=buster ID=debian - [x] Provide client logs (with `'debug': '..'` as necessary) - [ ] Provide broker log excerpts - [ ] Critical issue "
548425,548425,609549,https://api.github.com/repos/YTVanced/Vanced/issues/715,0.0,2021-04-28T01:40:33Z,NONE,https://api.github.com/repos/YTVanced/Vanced,[Bug] VANCED Does not respect the device's screen resolution.,"<!-- MANAGER/MICROG/VANCED MUSIC ISSUES DO NOT BELONG HERE, READ THE README FOR MORE INFO -->

**Bug description**
The ""MAX resolution"" option is set to off but Vanced just ignores to follow the device's screen resolution, thus listing resolutions that are higher than the phone's screen resolution, like 1440p and 2160p, while the phone's screen is 1080p.

**Variant**
Non-Root

**Vanced version**
15.43.32 - Build - 01.47.00

**Android version**
Android 10

**Device**
Samsung Galaxy S9

**Steps to Reproduce**
Steps to reproduce the error:
1. Turn off MAX resolution in the settings.
2. Play a video that is higher than your screen's resolution.


**Expected behavior**
When turning MAX resolution off, Vanced must follow the screen resolution of one's device and should only list video qualities that match the device's resolution, not higher, for example 720p video on 720p screen, 1080p video on 1080p screen, not 2160p on 720p screen, and so on...

- Note: _i'm not talking about the new YouTube quality preferences issue, that is something different, but i'm not sure if it could be linked to this_

![Capture 28_04_2021_03_16_08](https://user-images.githubusercontent.com/52612348/116331826-d5fb8980-a7d0-11eb-8974-77a3e8a87022.png)

- **The last 2 resolutions below should have been disabled/hidden.**

![Capture 28_04_2021_03_18_18](https://user-images.githubusercontent.com/52612348/116332004-37235d00-a7d1-11eb-8847-98227a81ae32.png)
","[Bug] VANCED Does not respect the device's screen resolution. <!-- MANAGER/MICROG/VANCED MUSIC ISSUES DO NOT BELONG HERE, READ THE README FOR MORE INFO --> **Bug description** The ""MAX resolution"" option is set to off but Vanced just ignores to follow the device's screen resolution, thus listing resolutions that are higher than the phone's screen resolution, like 1440p and 2160p, while the phone's screen is 1080p. **Variant** Non-Root **Vanced version** 15.43.32 - Build - 01.47.00 **Android version** Android 10 **Device** Samsung Galaxy S9 **Steps to Reproduce** Steps to reproduce the error: 1. Turn off MAX resolution in the settings. 2. Play a video that is higher than your screen's resolution. **Expected behavior** When turning MAX resolution off, Vanced must follow the screen resolution of one's device and should only list video qualities that match the device's resolution, not higher, for example 720p video on 720p screen, 1080p video on 1080p screen, not 2160p on 720p screen, and so on... - Note: _i'm not talking about the new YouTube quality preferences issue, that is something different, but i'm not sure if it could be linked to this_ ![Capture 28_04_2021_03_16_08](https://user-images.githubusercontent.com/52612348/116331826-d5fb8980-a7d0-11eb-8974-77a3e8a87022.png) - **The last 2 resolutions below should have been disabled/hidden.** ![Capture 28_04_2021_03_18_18](https://user-images.githubusercontent.com/52612348/116332004-37235d00-a7d1-11eb-8847-98227a81ae32.png) "
422667,422667,469829,https://api.github.com/repos/benawad/dogehouse/issues/1924,1.0,2021-04-09T17:29:30Z,COLLABORATOR,https://api.github.com/repos/benawad/dogehouse,Add bot detection,"@benawad what do you think?

Bots join directly using the API, so they don't have UI, hence no mouse movements, and human-like interaction with the page. So we can infer on the front end if someone is not a bot.

If a bot joins from something like Puppeteer, it's gonna have a UI, but we still can use libraries that can distinguish between human and bots

After we know it's a bot, maybe we can add some kind of badge next to its name, so people who join know that it's a bot. I think it's pretty helpful.","Add bot detection @benawad what do you think? Bots join directly using the API, so they don't have UI, hence no mouse movements, and human-like interaction with the page. So we can infer on the front end if someone is not a bot. If a bot joins from something like Puppeteer, it's gonna have a UI, but we still can use libraries that can distinguish between human and bots After we know it's a bot, maybe we can add some kind of badge next to its name, so people who join know that it's a bot. I think it's pretty helpful."
692756,692756,769945,https://api.github.com/repos/Knowinnovation/nexss/issues/30,1.0,2021-04-30T18:41:09Z,COLLABORATOR,https://api.github.com/repos/Knowinnovation/nexss,Add past meetings to archive,"Under Archive -> Past meetings add:

-Habitable Worlds 2021
-TRAPPIST Habitable Atmosphere Intercomparison (THAI) Workshop
-Technosignatures workshop
-Habitable Worlds 2017
-Workshop Without Walls: Impact of Exoplanetary Space Weather On Climate and Habitability
-Workshop Without Walls: Exoplanet Biosignatures",Add past meetings to archive Under Archive -> Past meetings add: -Habitable Worlds 2021 -TRAPPIST Habitable Atmosphere Intercomparison (THAI) Workshop -Technosignatures workshop -Habitable Worlds 2017 -Workshop Without Walls: Impact of Exoplanetary Space Weather On Climate and Habitability -Workshop Without Walls: Exoplanet Biosignatures
183593,183593,204098,https://api.github.com/repos/defold/defold/issues/3907,0.0,2019-05-27T05:35:30Z,CONTRIBUTOR,https://api.github.com/repos/defold/defold,Unexpected crash to desktop (DEFEDIT-1405),"The last week I have gotten a lot of CTD both home on my Windows machine and at work on OSX.

Here is the crash log thing from OSX, reportinging it here because I don't know (and care to go through it) to see if there is any info that shouldn't be shared.


2018-06-13 16:35:08 (Mattias.Hedberg)
Got the error in the screenshot after a crash, had to restart the editor to get rid of it,

This probably happens 4 times a day, more frequent when having two editors open.
2018-06-15 09:56:53 (Erik.Angelin)
Hi! We've seen the mac crash before, something in skylight/high sierra that has also affected other applications. About Windows though... could that be a separate issue? Do you have any more info on that crash? Can you find anything in the Event Viewer?
2018-07-23 14:14:05 (Mattias.Hedberg)
It have not happened on my Windows machine recently but I haven't been developing much on it either.

Anyway it keeps happening and is quite annoying as the project takes quite a while to open, attached a second log because why not.
2018-10-31 10:14:34 (Mattias.Hedberg)
Added a few more logs, I got it four times yesterday while working on a small project and always when writing code.","Unexpected crash to desktop (DEFEDIT-1405) The last week I have gotten a lot of CTD both home on my Windows machine and at work on OSX. Here is the crash log thing from OSX, reportinging it here because I don't know (and care to go through it) to see if there is any info that shouldn't be shared. 2018-06-13 16:35:08 (Mattias.Hedberg) Got the error in the screenshot after a crash, had to restart the editor to get rid of it, This probably happens 4 times a day, more frequent when having two editors open. 2018-06-15 09:56:53 (Erik.Angelin) Hi! We've seen the mac crash before, something in skylight/high sierra that has also affected other applications. About Windows though... could that be a separate issue? Do you have any more info on that crash? Can you find anything in the Event Viewer? 2018-07-23 14:14:05 (Mattias.Hedberg) It have not happened on my Windows machine recently but I haven't been developing much on it either. Anyway it keeps happening and is quite annoying as the project takes quite a while to open, attached a second log because why not. 2018-10-31 10:14:34 (Mattias.Hedberg) Added a few more logs, I got it four times yesterday while working on a small project and always when writing code."
98519,98519,109463,https://api.github.com/repos/msiemens/onenote.rs/issues/7,1.0,2021-02-27T11:54:04Z,OWNER,https://api.github.com/repos/msiemens/onenote.rs,Feature: Parse embed URL for images,E.g. for embedded YouTube videos etc.,Feature: Parse embed URL for images E.g. for embedded YouTube videos etc.
389745,389745,433218,https://api.github.com/repos/SerenityOS/serenity/issues/6125,0.0,2021-04-04T20:37:23Z,COLLABORATOR,https://api.github.com/repos/SerenityOS/serenity,DHCPClient: Only attempt to perform DHCP on connected interfaces,"Found when testing #6076, where a real NIC takes a while to report that the link is up (where userland has already finished loading). We attempt DHCP anyway and the packets are lost, requiring a manual restart of DHCPClient.","DHCPClient: Only attempt to perform DHCP on connected interfaces Found when testing #6076, where a real NIC takes a while to report that the link is up (where userland has already finished loading). We attempt DHCP anyway and the packets are lost, requiring a manual restart of DHCPClient."
734258,734258,113446,https://api.github.com/repos/JuliaEarth/GeoStats.jl/issues/40,1.0,2019-07-29T11:06:02Z,MEMBER,https://api.github.com/repos/JuliaEarth/GeoStats.jl,Introduce the notion of volumetric measurements,"The Kriging-based solvers implemented so far assume that the measurements have a fixed volume. This assumption is quite strong, and we need to generalize the implementations to achieve block Kriging.

First we need to generalize the spatial object types to include volumetric information. If anyone has suggestions on efficient data structures for representing spatial domains with volumes, please feel free to share. I am tempted to continue with types a la VTK. After that, we can start working on the Kriging-based solvers to incorporate these modifications.","Introduce the notion of volumetric measurements The Kriging-based solvers implemented so far assume that the measurements have a fixed volume. This assumption is quite strong, and we need to generalize the implementations to achieve block Kriging. First we need to generalize the spatial object types to include volumetric information. If anyone has suggestions on efficient data structures for representing spatial domains with volumes, please feel free to share. I am tempted to continue with types a la VTK. After that, we can start working on the Kriging-based solvers to incorporate these modifications."
343457,343457,381798,https://api.github.com/repos/amplitude/Amplitude-Node/issues/75,0.0,2021-02-03T00:46:22Z,NONE,https://api.github.com/repos/amplitude/Amplitude-Node,No insert_id and other critical properties?,"At https://developers.amplitude.com/docs/http-api-v2 it's clearly stated that you highly recommend always passing in a insert_id, yet the sdk does not support this property? It is not part of the typescript typings.

Similarly, lots of properties are missing, e.g. os_name, app_version, etc.","No insert_id and other critical properties? At https://developers.amplitude.com/docs/http-api-v2 it's clearly stated that you highly recommend always passing in a insert_id, yet the sdk does not support this property? It is not part of the typescript typings. Similarly, lots of properties are missing, e.g. os_name, app_version, etc."
61329,61329,68160,https://api.github.com/repos/WhiteVermouth/intellij-investor-dashboard/issues/11,0.0,2021-05-08T08:47:21Z,NONE,https://api.github.com/repos/WhiteVermouth/intellij-investor-dashboard,1.50 躍よ썸양ㅊ弱곁밧㏘鵝,,1.50 躍よ썸양ㅊ弱곁밧㏘鵝 
347404,347404,386211,https://api.github.com/repos/Nadybot/Nadybot/issues/76,1.0,2021-01-05T18:25:43Z,CONTRIBUTOR,https://api.github.com/repos/Nadybot/Nadybot,Provide an API endpoint to send messages to org/priv chat,,Provide an API endpoint to send messages to org/priv chat 
505097,505097,561401,https://api.github.com/repos/GiorgioBrux/nitro-sniper-enhanced/issues/34,0.0,2021-01-13T18:45:14Z,NONE,https://api.github.com/repos/GiorgioBrux/nitro-sniper-enhanced,Alt accounts appearing offline,"Alt accounts are appearing offline although i made sure that the status is on online. The accounts logs into the sniper perfectly.

Once it logs into the sniper it appears offline in discord",Alt accounts appearing offline Alt accounts are appearing offline although i made sure that the status is on online. The accounts logs into the sniper perfectly. Once it logs into the sniper it appears offline in discord
577659,577659,641926,https://api.github.com/repos/blynkkk/blynk-library/issues/517,0.0,2021-03-18T20:22:13Z,NONE,https://api.github.com/repos/blynkkk/blynk-library,SSL error 56,"Blynk library version: 0.6.1
IDE: PlatformIO
IDE version: [...]
Board type: ESP8266 (Wemos d1 mini)

### Scenario, steps to reproduce
I am trying to connect a ESP8266 to my own Blynkserver via SSL. The port is 19443.
`Blynk.config(""token"", ""10.1.2.3"", 19443);`

### Expected Result
The controller should connect.

### Actual Result
The connection fails with SSL error 56. Without SSL everything works as expected.

[18204] Current time: Thu Mar 18 20:19:47 2021  
[18204] Connecting to 10.1.2.3:19443  
[18310] SSL error: 56  
[21517] Current time: Thu Mar 18 20:19:50 2021  
[21517] Connecting to 10.1.2.3:19443  
[21608] SSL error: 56  ","SSL error 56 Blynk library version: 0.6.1 IDE: PlatformIO IDE version: [...] Board type: ESP8266 (Wemos d1 mini) ### Scenario, steps to reproduce I am trying to connect a ESP8266 to my own Blynkserver via SSL. The port is 19443. `Blynk.config(""token"", ""10.1.2.3"", 19443);` ### Expected Result The controller should connect. ### Actual Result The connection fails with SSL error 56. Without SSL everything works as expected. [18204] Current time: Thu Mar 18 20:19:47 2021 [18204] Connecting to 10.1.2.3:19443 [18310] SSL error: 56 [21517] Current time: Thu Mar 18 20:19:50 2021 [21517] Connecting to 10.1.2.3:19443 [21608] SSL error: 56 "
421582,421582,468622,https://api.github.com/repos/nopSolutions/nopCommerce/issues/5689,0.0,2021-05-16T20:08:19Z,NONE,https://api.github.com/repos/nopSolutions/nopCommerce,"Bug: Latest products never show up on page ""newproducts"" when setting is lower than ""new"" products","nopCommerce version: 
4.40.x

Issue: Order by Product.CreatedOn not working when result set is bigger than setting.

Steps to reproduce the problem: 
- Mark x products as New
- set _catalogSettings.NewProductsNumber lower than x
- go to page: ""newproducts""
- Latest products are not visible op page

Solution:
Add an extra ""orderby p.CreatedOnUtc descending"" to the query in ""GetProductsMarkedAsNewAsync"" in ProductService.cs line 694

Greetings,
Mo","Bug: Latest products never show up on page ""newproducts"" when setting is lower than ""new"" products nopCommerce version: 4.40.x Issue: Order by Product.CreatedOn not working when result set is bigger than setting. Steps to reproduce the problem: - Mark x products as New - set _catalogSettings.NewProductsNumber lower than x - go to page: ""newproducts"" - Latest products are not visible op page Solution: Add an extra ""orderby p.CreatedOnUtc descending"" to the query in ""GetProductsMarkedAsNewAsync"" in ProductService.cs line 694 Greetings, Mo"
251886,251886,280182,https://api.github.com/repos/sgtaziz/WebMessage/issues/87,1.0,2021-02-27T21:54:09Z,NONE,https://api.github.com/repos/sgtaziz/WebMessage,[Feature Request] [Client] Contact photos next to received messages in a group chat (and toggle for individual chats),,[Feature Request] [Client] Contact photos next to received messages in a group chat (and toggle for individual chats) 
84666,84666,94134,https://api.github.com/repos/Delgan/loguru/issues/425,2.0,2021-04-13T11:03:21Z,NONE,https://api.github.com/repos/Delgan/loguru,Terminate on ERROR level,"Hi,

I'm looking to log different levels for my application such as INFO and ERROR. 

When an ERROR is logged, I would like the application to terminate. Is there a way that loguru can handle this for me instead of checking the level manually and calling `exit()`?

Many Thanks.","Terminate on ERROR level Hi, I'm looking to log different levels for my application such as INFO and ERROR. When an ERROR is logged, I would like the application to terminate. Is there a way that loguru can handle this for me instead of checking the level manually and calling `exit()`? Many Thanks."
775865,775865,528608,https://api.github.com/repos/JolifantoBambla/vk-samples/issues/10,1.0,2021-03-11T09:31:30Z,OWNER,https://api.github.com/repos/JolifantoBambla/vk-samples,Sample: 12-init-frame-buffers,,Sample: 12-init-frame-buffers 
512224,512224,569246,https://api.github.com/repos/microsoft/CsWinRT/issues/309,1.0,2020-06-11T18:06:08Z,MEMBER,https://api.github.com/repos/microsoft/CsWinRT,Enable production (authoring) support of WinRT types,"This would replace the existing winmdexp tooling experience, to enable C# developers to define WinRT types (all kinds).  These types could be used internally by the app generating them, or externally from a packaged runtime component.  A source generator might be useful for reflecting on WinRT types as they're defined, and creating backing metadata and implementation.","Enable production (authoring) support of WinRT types This would replace the existing winmdexp tooling experience, to enable C# developers to define WinRT types (all kinds). These types could be used internally by the app generating them, or externally from a packaged runtime component. A source generator might be useful for reflecting on WinRT types as they're defined, and creating backing metadata and implementation."
571485,571485,635085,https://api.github.com/repos/opencadc/caom2workshop/issues/7,0.0,2020-10-15T21:21:17Z,NONE,https://api.github.com/repos/opencadc/caom2workshop,kftest2-modified,"description of this issue in jira
edit again in github",kftest2-modified description of this issue in jira edit again in github
640461,640461,711836,https://api.github.com/repos/narteysarso/staruml4-laravel/issues/7,1.0,2021-01-25T03:05:40Z,OWNER,https://api.github.com/repos/narteysarso/staruml4-laravel,Add support for laravel model relations,,Add support for laravel model relations 
207126,207126,230314,https://api.github.com/repos/Azure/aad-pod-identity/issues/922,0.0,2021-01-04T17:44:06Z,NONE,https://api.github.com/repos/Azure/aad-pod-identity,apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated,"**Have you**

- [x] Read [Troubleshooting Guide](../../docs/readmes/README.troubleshooting.md)
- [x] Read [Known Issues](../../docs/readmes/README.known-issues.md)
- [x] Searched on [GitHub issues](https://github.com/Azure/aad-pod-identity/issues)

**Describe the bug**
When installing aad-pod-identity the following warnings display:
```
W0104 17:14:45.789938    9304 warnings.go:67] apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition
W0104 17:14:45.789938    9304 warnings.go:67] apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition
W0104 17:14:45.806949    9304 warnings.go:67] apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition
W0104 17:14:45.807945    9304 warnings.go:67] apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition
W0104 17:14:47.915382    9304 warnings.go:67] apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition
W0104 17:14:47.946916    9304 warnings.go:67] apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition
W0104 17:14:47.981923    9304 warnings.go:67] apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition
W0104 17:14:48.017915    9304 warnings.go:67] apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition
```

**Steps To Reproduce**
1. Deploy aad-pod-identity using [instructions](https://azure.github.io/aad-pod-identity/docs/getting-started/installation). I used helm for installation but I imagine any method will incur the same problem.
2. Observe warning messages

**Expected behavior**
No warning messages about deprecated versions

**AAD Pod Identity version**
1.7.1

**Kubernetes version**
1.19.3

**Additional context**
I'd be happy to see about updating these yaml files to use the latest api and getting a PR raised but I'll need to time to get my head around the contributing guide  ","apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated **Have you** - [x] Read [Troubleshooting Guide](../../docs/readmes/README.troubleshooting.md) - [x] Read [Known Issues](../../docs/readmes/README.known-issues.md) - [x] Searched on [GitHub issues](https://github.com/Azure/aad-pod-identity/issues) **Describe the bug** When installing aad-pod-identity the following warnings display: ``` W0104 17:14:45.789938 9304 warnings.go:67] apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition W0104 17:14:45.789938 9304 warnings.go:67] apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition W0104 17:14:45.806949 9304 warnings.go:67] apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition W0104 17:14:45.807945 9304 warnings.go:67] apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition W0104 17:14:47.915382 9304 warnings.go:67] apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition W0104 17:14:47.946916 9304 warnings.go:67] apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition W0104 17:14:47.981923 9304 warnings.go:67] apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition W0104 17:14:48.017915 9304 warnings.go:67] apiextensions.k8s.io/v1beta1 CustomResourceDefinition is deprecated in v1.16+, unavailable in v1.22+; use apiextensions.k8s.io/v1 CustomResourceDefinition ``` **Steps To Reproduce** 1. Deploy aad-pod-identity using [instructions](https://azure.github.io/aad-pod-identity/docs/getting-started/installation). I used helm for installation but I imagine any method will incur the same problem. 2. Observe warning messages **Expected behavior** No warning messages about deprecated versions **AAD Pod Identity version** 1.7.1 **Kubernetes version** 1.19.3 **Additional context** I'd be happy to see about updating these yaml files to use the latest api and getting a PR raised but I'll need to time to get my head around the contributing guide  "
495361,495361,550582,https://api.github.com/repos/Azure/azure-iot-explorer/issues/371,2.0,2020-11-27T04:23:11Z,NONE,https://api.github.com/repos/Azure/azure-iot-explorer,[Feature request] Running Inside container,"Hello!

Is it possible to run it inside docker container and expose port 3000?
I've changed the run command to listen on all hosts and configured dev server to disable host check.
I can reach the web service inside the container from host, but as i can see the running instance inside the container cant connect to azure services, ""fetch failed""

Thanks!
Peter","[Feature request] Running Inside container Hello! Is it possible to run it inside docker container and expose port 3000? I've changed the run command to listen on all hosts and configured dev server to disable host check. I can reach the web service inside the container from host, but as i can see the running instance inside the container cant connect to azure services, ""fetch failed"" Thanks! Peter"
96424,96424,107161,https://api.github.com/repos/stryker-mutator/mutation-testing-elements/issues/891,1.0,2021-02-11T13:24:56Z,MEMBER,https://api.github.com/repos/stryker-mutator/mutation-testing-elements,"Add a ""statusReason"" field","We currently don't have a place to put the error message for an error mutant, or the failure message for killed mutants. That is a shame because it might help the user. In Stryker, we currently put this in the description, which I think is not nice at all.

![fit](https://media.giphy.com/media/xT5LMtelPNIy6yjdTO/giphy.gif)

Proposal:

add an optional `statusReason` string field. It _should_ have:
* The error message if the mutant status is error
* The failure message if the mutant is killed.

@Mobrockers @hugo-vrijswijk thoughts?","Add a ""statusReason"" field We currently don't have a place to put the error message for an error mutant, or the failure message for killed mutants. That is a shame because it might help the user. In Stryker, we currently put this in the description, which I think is not nice at all. ![fit](https://media.giphy.com/media/xT5LMtelPNIy6yjdTO/giphy.gif) Proposal: add an optional `statusReason` string field. It _should_ have: * The error message if the mutant status is error * The failure message if the mutant is killed. @Mobrockers @hugo-vrijswijk thoughts?"
512693,512693,569758,https://api.github.com/repos/lnbook/lnbook/issues/615,0.0,2021-01-31T22:30:34Z,CONTRIBUTOR,https://api.github.com/repos/lnbook/lnbook,Fix needed [c-lightning docker won't build],"**Describe the error**
docker build doesn't work
![image](https://user-images.githubusercontent.com/68111648/106400019-3ec6a600-641c-11eb-93ae-dc404b374f42.png)

**To Fix**
Updating the build instructions in the docker script

**Additional context**
Add any other context about the problem here.
",Fix needed [c-lightning docker won't build] **Describe the error** docker build doesn't work ![image](https://user-images.githubusercontent.com/68111648/106400019-3ec6a600-641c-11eb-93ae-dc404b374f42.png) **To Fix** Updating the build instructions in the docker script **Additional context** Add any other context about the problem here. 
766515,766515,434589,https://api.github.com/repos/bentoml/BentoML/issues/1464,0.0,2021-02-19T20:39:42Z,CONTRIBUTOR,https://api.github.com/repos/bentoml/BentoML,Unable to change prediction log format,"**Describe the bug**
<!--- A clear and concise description of what the bug is. -->

I've tried various methods to set `prediction_log_json_format`: 
- via env variable
- via a custom cfg file
- via the `bentoml config set`
- via the service itself with bentoml.config()

Some of them seem to work at least when looking at `bentoml config view-effective` but none actually give the expected log format.

**To Reproduce**

- `bentoml config set logging.prediction_log_json_format=""%%(service_name)s""` OR in the service itself via `bentoml.config().set('logging', 'prediction_log_json_format',  ""%%(service_name)s"")`
- `bentoml config view-effective`  should show that it is there
- run `bentoml serve-gunicorn --workers 1 MyService:latest --debug`
- send something through it (using swagger for my testing) and you'll see much more verbose logs (the full result etc)

It's worth mentioning that when you run in `debug` mode and you see the config, it doesn't show the one I set (default or otherwise)

**Expected behavior**
<!--- A clear and concise description of what you expected to happen. -->
Logs should be of the format I specify

**Screenshots/Logs**
<!--- 
If applicable, add screenshots, logs or error outputs to help explain your problem.

To give us more information for diagnosing the issue, make sure to enable debug logging:

Enable via environment variable, e.g.:
```
$ git clone git@github.com:bentoml/BentoML.git && cd bentoml
$ BENTOML__CORE__DEBUG=true python guides/quick-start/main.py
```

Or enable for all python sessions on current machine:
```bash
$ bentoml config set core.debug=true
$ python guides/quick-start/main.py
```

Or set debug logging in your Python code:
```python
import bentoml
import logging
bentoml.config().set('core', 'debug', 'true')
bentoml.configure_logging(logging.DEBUG)
```

For BentoML CLI commands, simply add the `--verbose` flag, e.g.:
```bash
bentoml get IrisClassifier --verbose
```

-->


**Environment:**
 - OS: CentOS7
 - Python Version: 3.7.9
 - BentoML Version: 0.11.0


**Additional context**
<!-- Add any other context about the problem here. e.g. links to related discussion. -->

The service itself is using `ImageInput` and `JsonOutput` if that matters

I've confirmed that in `https://github.com/bentoml/BentoML/blob/4c825fd359267ee333925514e144ef1b39e5f47e/bentoml/utils/log.py#L32` it sees the right format. 
","Unable to change prediction log format **Describe the bug** <!--- A clear and concise description of what the bug is. --> I've tried various methods to set `prediction_log_json_format`: - via env variable - via a custom cfg file - via the `bentoml config set` - via the service itself with bentoml.config() Some of them seem to work at least when looking at `bentoml config view-effective` but none actually give the expected log format. **To Reproduce** - `bentoml config set logging.prediction_log_json_format=""%%(service_name)s""` OR in the service itself via `bentoml.config().set('logging', 'prediction_log_json_format', ""%%(service_name)s"")` - `bentoml config view-effective` should show that it is there - run `bentoml serve-gunicorn --workers 1 MyService:latest --debug` - send something through it (using swagger for my testing) and you'll see much more verbose logs (the full result etc) It's worth mentioning that when you run in `debug` mode and you see the config, it doesn't show the one I set (default or otherwise) **Expected behavior** <!--- A clear and concise description of what you expected to happen. --> Logs should be of the format I specify **Screenshots/Logs** <!--- If applicable, add screenshots, logs or error outputs to help explain your problem. To give us more information for diagnosing the issue, make sure to enable debug logging: Enable via environment variable, e.g.: ``` $ git clone git@github.com:bentoml/BentoML.git && cd bentoml $ BENTOML__CORE__DEBUG=true python guides/quick-start/main.py ``` Or enable for all python sessions on current machine: ```bash $ bentoml config set core.debug=true $ python guides/quick-start/main.py ``` Or set debug logging in your Python code: ```python import bentoml import logging bentoml.config().set('core', 'debug', 'true') bentoml.configure_logging(logging.DEBUG) ``` For BentoML CLI commands, simply add the `--verbose` flag, e.g.: ```bash bentoml get IrisClassifier --verbose ``` --> **Environment:** - OS: CentOS7 - Python Version: 3.7.9 - BentoML Version: 0.11.0 **Additional context** <!-- Add any other context about the problem here. e.g. links to related discussion. --> The service itself is using `ImageInput` and `JsonOutput` if that matters I've confirmed that in `https://github.com/bentoml/BentoML/blob/4c825fd359267ee333925514e144ef1b39e5f47e/bentoml/utils/log.py#L32` it sees the right format. "
792972,792972,699371,https://api.github.com/repos/cornell-dti/idol/issues/17,1.0,2020-10-15T20:13:51Z,CONTRIBUTOR,https://api.github.com/repos/cornell-dti/idol,Mock Up Member Info Change Form UI ,"Design and mock up the form that allows a user to change their user information from the website (as seen here: https://www.cornelldti.org/team/).

We want the user to be able to:

- Change their about me description
- Update their past team work
- Update their role
- Add reference links (website, github, etc.)
- Edit basic info (Major, hometown, graduation date, etc.)","Mock Up Member Info Change Form UI Design and mock up the form that allows a user to change their user information from the website (as seen here: https://www.cornelldti.org/team/). We want the user to be able to: - Change their about me description - Update their past team work - Update their role - Add reference links (website, github, etc.) - Edit basic info (Major, hometown, graduation date, etc.)"
530057,530057,589136,https://api.github.com/repos/CLV-Java-Akademie-2021/hr-system/issues/10,1.0,2021-01-11T13:11:02Z,CONTRIBUTOR,https://api.github.com/repos/CLV-Java-Akademie-2021/hr-system,Vytvoen챠 endpointu pro vlo탑en챠 첬kolu,"Metoda: POST
Adresa: http://localhost:8080/api/task

Controller po큄le do servisn챠 vrstvy data (id spolenosti, n찼zev CZ, n찼zev EN) ze vstupu do servisn챠 vrstvy a zde je jen zaloguje.","Vytvoen챠 endpointu pro vlo탑en챠 첬kolu Metoda: POST Adresa: http://localhost:8080/api/task Controller po큄le do servisn챠 vrstvy data (id spolenosti, n찼zev CZ, n찼zev EN) ze vstupu do servisn챠 vrstvy a zde je jen zaloguje."
153271,153271,170390,https://api.github.com/repos/Tomo-9925/cnet/issues/41,0.0,2021-01-22T10:51:35Z,OWNER,https://api.github.com/repos/Tomo-9925/cnet,RAW썬긱岳▲UDP/TCP긱,"양UDP/TCP㎪긱孃ゃｃ닷ワ밧訝ⓦ⒲쇈뷩밧恙듐竊
竊녈ャRAW썬긱岳▲썸㎯竊鸚길닷RAW썬긱밧烏若烏恙誤竊",RAW썬긱岳▲UDP/TCP긱 양UDP/TCP㎪긱孃ゃｃ닷ワ밧訝ⓦ⒲쇈뷩밧恙듐竊 竊녈ャRAW썬긱岳▲썸㎯竊鸚길닷RAW썬긱밧烏若烏恙誤竊
666121,666121,740397,https://api.github.com/repos/shyim/shopware-docker/issues/89,0.0,2021-03-03T12:23:36Z,OWNER,https://api.github.com/repos/shyim/shopware-docker,swdc build does not work on 6.4 without errors,swdc build on a new project fails due admin build error,swdc build does not work on 6.4 without errors swdc build on a new project fails due admin build error
599529,599529,666259,https://api.github.com/repos/microsoft/botbuilder-dotnet/issues/4468,0.0,2020-08-17T19:53:04Z,NONE,https://api.github.com/repos/microsoft/botbuilder-dotnet,CloudAdapter and ConnectorClient Does Not Honor RetryPolicy,"## Version
4.9.4.0

## Describe the bug
When defining BotFrameworkOptions and you provide a ConnectorClientRetryPolicy the policy is not used by ConnectorClient produced by BotFrameworkAdapter.

## To Reproduce
Configure BotFrameworkOptions to provide RetryPolicy, or don't provide any policy (ServiceClient<T> offers a default policy)
Trigger some transient error like 429 when sending on a conversation uri.

## Expected behavior
429 is handled by default retry policy or by the policy you have provided.

## Additional context
This was introduced by #1382 
[Proxy support: ConnectorClient accepts custom http client and BotFrameworkAdapter passes httpClient over to clients](https://github.com/microsoft/botbuilder-dotnet/pull/1382/files)

The issue is further impacted because _httpClient is either a custom provided or DefaultHttpClient. Now since _httpClient is never null ConnectorClient will always use default client. Because client is provided ServiceClient has hooked up RetryPolicy to handlers that will never be called. This impacts anyone's ability to leverage designed approach to retry policy definition in ConnectorClient.

The only workaround is to provide HttpClient with desired handlers for retry and define on BotFrameworkOptions.","CloudAdapter and ConnectorClient Does Not Honor RetryPolicy ## Version 4.9.4.0 ## Describe the bug When defining BotFrameworkOptions and you provide a ConnectorClientRetryPolicy the policy is not used by ConnectorClient produced by BotFrameworkAdapter. ## To Reproduce Configure BotFrameworkOptions to provide RetryPolicy, or don't provide any policy (ServiceClient<T> offers a default policy) Trigger some transient error like 429 when sending on a conversation uri. ## Expected behavior 429 is handled by default retry policy or by the policy you have provided. ## Additional context This was introduced by #1382 [Proxy support: ConnectorClient accepts custom http client and BotFrameworkAdapter passes httpClient over to clients](https://github.com/microsoft/botbuilder-dotnet/pull/1382/files) The issue is further impacted because _httpClient is either a custom provided or DefaultHttpClient. Now since _httpClient is never null ConnectorClient will always use default client. Because client is provided ServiceClient has hooked up RetryPolicy to handlers that will never be called. This impacts anyone's ability to leverage designed approach to retry policy definition in ConnectorClient. The only workaround is to provide HttpClient with desired handlers for retry and define on BotFrameworkOptions."
80639,80639,89650,https://api.github.com/repos/AppliedEnergistics/Applied-Energistics-2/issues/4136,1.0,2019-08-28T10:26:49Z,NONE,https://api.github.com/repos/AppliedEnergistics/Applied-Energistics-2,Inverter card use in fluid storage config,"
**Describe the feature**
Adding an inverter card into the card slot when configuring fluid storage would invert the storage configuration from the default whitelist to blacklist behaviour.

**Reasons why it should be considered**
Storage cells allow this functionality. (Fuzzy cards, however, are a little redundant in fluid storage, unless that would facilitate compat)
Intuition and consistency with the above.

**Additional Context**
This is using rv6 stable-6; however there was no mention of this in the changelog/commit history. 
[Inverter card displayed compatibility](https://user-images.githubusercontent.com/46378533/63847224-44959d80-c985-11e9-9a58-1daa3481002e.png)

I was trying to set up a water/NOT water pair of fluid cells, only to realise that the inverter card is incompatible. It is understandable that the current implementation requires some creativity in importing infinite water sources, but doesn't seem intuitive when next to the item storage and cobble gens!
","Inverter card use in fluid storage config **Describe the feature** Adding an inverter card into the card slot when configuring fluid storage would invert the storage configuration from the default whitelist to blacklist behaviour. **Reasons why it should be considered** Storage cells allow this functionality. (Fuzzy cards, however, are a little redundant in fluid storage, unless that would facilitate compat) Intuition and consistency with the above. **Additional Context** This is using rv6 stable-6; however there was no mention of this in the changelog/commit history. [Inverter card displayed compatibility](https://user-images.githubusercontent.com/46378533/63847224-44959d80-c985-11e9-9a58-1daa3481002e.png) I was trying to set up a water/NOT water pair of fluid cells, only to realise that the inverter card is incompatible. It is understandable that the current implementation requires some creativity in importing infinite water sources, but doesn't seem intuitive when next to the item storage and cobble gens! "
479946,479946,533425,https://api.github.com/repos/ctuning/ck-env/issues/115,2.0,2021-03-23T17:15:01Z,NONE,https://api.github.com/repos/ctuning/ck-env,Questions Regarding Software Detection,"Hi all,

I am working on an autotuning project (called GPTune) for HPC applications. We are also interested in providing an automatation interface based on CK, which we call CK-GPTune, as an additional interface for GPTune.

I have two questions about the CK soft detection module:

- What would be a good way to detect software which is located in a very deep directory hierarchy? Increasing the limit_recursion_dir_search value adds more search time. Adding extra_search_dirs requires more human efforts (and different machines might have different paths). Can the ck-soft module have more default search directories depending on the type of software (e.g. including sys.path output as default search for Python modules?)?

- ""soft_file"" in software meta description: It seems both Linux and Mac use the ""soft_file"" name in the ""linux"" key in the meta description dictionary. If the software can have different names (or different file extension names) on Linux and Mac, what would be a good way to detect them?

Thank you,

Younghyun","Questions Regarding Software Detection Hi all, I am working on an autotuning project (called GPTune) for HPC applications. We are also interested in providing an automatation interface based on CK, which we call CK-GPTune, as an additional interface for GPTune. I have two questions about the CK soft detection module: - What would be a good way to detect software which is located in a very deep directory hierarchy? Increasing the limit_recursion_dir_search value adds more search time. Adding extra_search_dirs requires more human efforts (and different machines might have different paths). Can the ck-soft module have more default search directories depending on the type of software (e.g. including sys.path output as default search for Python modules?)? - ""soft_file"" in software meta description: It seems both Linux and Mac use the ""soft_file"" name in the ""linux"" key in the meta description dictionary. If the software can have different names (or different file extension names) on Linux and Mac, what would be a good way to detect them? Thank you, Younghyun"
249723,249723,277774,https://api.github.com/repos/coobird/thumbnailator/issues/115,1.0,2017-05-10T07:53:45Z,NONE,https://api.github.com/repos/coobird/thumbnailator,Request for aditional function of Thumbnails.asInputStream to make it's easier for storing into Mongodb GridFS,"## Expected behavior

For storing image data into Mongodb GridFS requiring an inputStream as input so it's not convenient for user to convert an outputStream (Thumbnails.toOutputStream(out)) into an inputStream manually by user.

So it's best to have an additional function Thumbnails.asInputStream() returns an inputStream.

- JDK vendor and version:
- Thumbnailator version: 0.4.8",Request for aditional function of Thumbnails.asInputStream to make it's easier for storing into Mongodb GridFS ## Expected behavior For storing image data into Mongodb GridFS requiring an inputStream as input so it's not convenient for user to convert an outputStream (Thumbnails.toOutputStream(out)) into an inputStream manually by user. So it's best to have an additional function Thumbnails.asInputStream() returns an inputStream. - JDK vendor and version: - Thumbnailator version: 0.4.8
132293,132293,147045,https://api.github.com/repos/PierreDespereaux/Keizaal/issues/90,0.0,2021-01-24T11:42:50Z,NONE,https://api.github.com/repos/PierreDespereaux/Keizaal,NPC missing in Markarth,"*Keizaal version
3.5.2

Describe the bug
Upon entering Markarth the first time, during the Forsworn attack the woman that is murdered is missing

To reproduce
Enter Markarth and wait for the scene to playout, a man will be sneaking with dagger in hand

Expected behavior
When the murder is happening, a women should be present

Screenshots
![20210124061229_1](https://user-images.githubusercontent.com/77921178/105629147-49c37a00-5e0f-11eb-9840-00dfed02cdf5.jpg)

Additional context
I am using Skyrim Unbound Reborn, and the Pit Fighter mods from optionals, not sure if this is what is causing the bug","NPC missing in Markarth *Keizaal version 3.5.2 Describe the bug Upon entering Markarth the first time, during the Forsworn attack the woman that is murdered is missing To reproduce Enter Markarth and wait for the scene to playout, a man will be sneaking with dagger in hand Expected behavior When the murder is happening, a women should be present Screenshots ![20210124061229_1](https://user-images.githubusercontent.com/77921178/105629147-49c37a00-5e0f-11eb-9840-00dfed02cdf5.jpg) Additional context I am using Skyrim Unbound Reborn, and the Pit Fighter mods from optionals, not sure if this is what is causing the bug"
732521,732521,95816,https://api.github.com/repos/AprilSylph/XKit-Rewritten/issues/116,0.0,2021-04-13T16:23:48Z,OWNER,https://api.github.com/repos/AprilSylph/XKit-Rewritten,Mutual Checker marks you as your own mutual,"eb0ad270964fb2454726448dd2560ad71ee01312 inadvertently removed the check for if the queried blog is the user's own blog. this should be easily fixed by setting
```js
following[myBlog] = Promise.resolve(false);
```
in the script's `main()` function.",Mutual Checker marks you as your own mutual eb0ad270964fb2454726448dd2560ad71ee01312 inadvertently removed the check for if the queried blog is the user's own blog. this should be easily fixed by setting ```js following[myBlog] = Promise.resolve(false); ``` in the script's `main()` function.
371854,371854,413378,https://api.github.com/repos/edemaine/coauthor/issues/507,1.0,2021-01-13T20:08:14Z,OWNER,https://api.github.com/repos/edemaine/coauthor,Protected/locked/restricted flag for messages,"In protected state, only authors and superusers can edit the message.

This is useful e.g. for solved problems, where we don't want students to accidentally become authors and thereby trigger access inheritance via #503.

Also prevents e.g. unminimizing hints.

Seems related to #351; perhaps this could be called a protected group (with a somewhat different interface). ","Protected/locked/restricted flag for messages In protected state, only authors and superusers can edit the message. This is useful e.g. for solved problems, where we don't want students to accidentally become authors and thereby trigger access inheritance via #503. Also prevents e.g. unminimizing hints. Seems related to #351; perhaps this could be called a protected group (with a somewhat different interface). "
258934,258934,287978,https://api.github.com/repos/AEFeinstein/mtg-familiar/issues/351,1.0,2018-01-21T19:47:58Z,NONE,https://api.github.com/repos/AEFeinstein/mtg-familiar,"Mana cost search looks at the entire string entered, not the individual symbols","When searching for a specific mana cost, it uses the entire string entered by the user, not each symbol individually as you'd expect. For example, searching for ""contains {4}{U}"" returns several cards, but ""contains {U}{4}"" returns nothing.","Mana cost search looks at the entire string entered, not the individual symbols When searching for a specific mana cost, it uses the entire string entered by the user, not each symbol individually as you'd expect. For example, searching for ""contains {4}{U}"" returns several cards, but ""contains {U}{4}"" returns nothing."
126651,126651,140738,https://api.github.com/repos/aavegotchi/aavegotchi-contracts/issues/47,1.0,2021-02-13T11:18:51Z,COLLABORATOR,https://api.github.com/repos/aavegotchi/aavegotchi-contracts,Add getUserERC721Listings and getUserAavegotchiListings functions,Currently there are no functions that allow reading listings from a specific user for ERC721s. We should implement these to aid with the frontend UI,Add getUserERC721Listings and getUserAavegotchiListings functions Currently there are no functions that allow reading listings from a specific user for ERC721s. We should implement these to aid with the frontend UI
479033,479033,532403,https://api.github.com/repos/nlowe/mousiki/issues/24,0.0,2021-04-03T07:04:54Z,OWNER,https://api.github.com/repos/nlowe/mousiki,Authentication Broke,"As of 2021-04-02 authentication appears broken:

```
panic: login: unexpected result 400 Bad Request:
{""message"":""Invalid username and/or password"",""errorCode"":0,""errorString"":""AUTH_INVALID_USERNAME_PASSWORD""}
```

Looking at the browser, three extra fields are set that appear to be SSO related:

* `OZ_DT`
* `OZ_SG`
* `OZ_TC`

It seems resilient to replays, just ripping the values from the login request from the web client doesn't work. Curiously, pianobar still works. Perhaps we can implement the partner login flow to obtain a token instead?","Authentication Broke As of 2021-04-02 authentication appears broken: ``` panic: login: unexpected result 400 Bad Request: {""message"":""Invalid username and/or password"",""errorCode"":0,""errorString"":""AUTH_INVALID_USERNAME_PASSWORD""} ``` Looking at the browser, three extra fields are set that appear to be SSO related: * `OZ_DT` * `OZ_SG` * `OZ_TC` It seems resilient to replays, just ripping the values from the login request from the web client doesn't work. Curiously, pianobar still works. Perhaps we can implement the partner login flow to obtain a token instead?"
265423,265423,295176,https://api.github.com/repos/TeamNewPipe/NewPipe/issues/5665,1.0,2021-02-22T04:32:27Z,NONE,https://api.github.com/repos/TeamNewPipe/NewPipe,Playlist/Queue Total Time,"<!-- IF YOU DON'T FILL IN THE TEMPLATE PROPERLY, YOUR ISSUE IS LIABLE TO BE CLOSED. If you feel tired/lazy right now, open your issue some other time. We'll wait. -->


<!-- The comments between these brackets won't show up in the submitted issue (as you can see in the Preview). -->

### Checklist
<!-- This checklist is COMPULSORY. The first box has been checked for you to show you how it is done. -->

- [x] I checked, but didn't find any duplicates (open OR closed) of this issue in the repo. <!-- Seriously, check. O_O -->
- [x] I have read the contribution guidelines given at https://github.com/TeamNewPipe/NewPipe/blob/HEAD/.github/CONTRIBUTING.md.
- [x] This issue contains only one feature request. I will open one issue for every feature I want to request.


#### Describe the feature you want
<!-- A clear and concise description of what you wish should happen.
Example: *I think it would be nice if you add feature Y which makes X possible.*

Optionally, also describe alternatives you've considered.
Example: *Z is also a good alternative. Not as good as Y, but at least...* or *I considered Z, but that didn't turn out to be a good idea because...* -->
A way to see how much total time there is queued or in the playlist.  It is a little tedious to do the head math, so it would be nice to see how long your playlist is.


#### Is your feature request related to a problem? Please describe it
<!-- A clear and concise description of what the problem is. Maybe the developers and the community could brainstorm and come up with a better solution to your problem. If they exist, link to related Issues and/or PRs for developers to keep track easier.
Example: *I want to do X, but there is no way to do it.* -->
No problem, just a common feature that feels lacking.
#### How will you/everyone benefit from this feature?
<!-- Convince us! How does it change your NewPipe experience and/or your life?
The better this paragraph is, the more likely a developer will think about working on it.
Example: *This feature will help us colonize the galaxy! -->
Studying for 45mins~5hrs but you don't have the playlist premade?  Just queue a bunch of your songs until the total reaches that total time.  Or, maybe you have a curated set of playlists for all the exact right lengths, eg. a 45min jog, and you want it to be that exact length of time.  But you don't want to do the head math every time you put a new list together, right?
","Playlist/Queue Total Time <!-- IF YOU DON'T FILL IN THE TEMPLATE PROPERLY, YOUR ISSUE IS LIABLE TO BE CLOSED. If you feel tired/lazy right now, open your issue some other time. We'll wait. --> <!-- The comments between these brackets won't show up in the submitted issue (as you can see in the Preview). --> ### Checklist <!-- This checklist is COMPULSORY. The first box has been checked for you to show you how it is done. --> - [x] I checked, but didn't find any duplicates (open OR closed) of this issue in the repo. <!-- Seriously, check. O_O --> - [x] I have read the contribution guidelines given at https://github.com/TeamNewPipe/NewPipe/blob/HEAD/.github/CONTRIBUTING.md. - [x] This issue contains only one feature request. I will open one issue for every feature I want to request. #### Describe the feature you want <!-- A clear and concise description of what you wish should happen. Example: *I think it would be nice if you add feature Y which makes X possible.* Optionally, also describe alternatives you've considered. Example: *Z is also a good alternative. Not as good as Y, but at least...* or *I considered Z, but that didn't turn out to be a good idea because...* --> A way to see how much total time there is queued or in the playlist. It is a little tedious to do the head math, so it would be nice to see how long your playlist is. #### Is your feature request related to a problem? Please describe it <!-- A clear and concise description of what the problem is. Maybe the developers and the community could brainstorm and come up with a better solution to your problem. If they exist, link to related Issues and/or PRs for developers to keep track easier. Example: *I want to do X, but there is no way to do it.* --> No problem, just a common feature that feels lacking. #### How will you/everyone benefit from this feature? <!-- Convince us! How does it change your NewPipe experience and/or your life? The better this paragraph is, the more likely a developer will think about working on it. Example: *This feature will help us colonize the galaxy! --> Studying for 45mins~5hrs but you don't have the playlist premade? Just queue a bunch of your songs until the total reaches that total time. Or, maybe you have a curated set of playlists for all the exact right lengths, eg. a 45min jog, and you want it to be that exact length of time. But you don't want to do the head math every time you put a new list together, right? "
536294,536294,596054,https://api.github.com/repos/microsoft/pxt-microbit/issues/3456,0.0,2020-10-21T16:47:25Z,COLLABORATOR,https://api.github.com/repos/microsoft/pxt-microbit,The Python class example does not compile,"**Describe the bug**
From: https://makecode.microbit.org/python/classes
```python
class Greeter:
    greeting = """"
    def __init__(self, message):
        self.greeting = message
    def greet(self):
        return ""Hello, "" + self.greeting

greeter = Greeter(""world"")
```

Throws the following errors:

```
Line 4: the field 'greeting' of 'Greeter' is static
Line 6: the field 'greeting' of 'Greeter' is static
```


**To Reproduce**
copy paste the code in the Python editor and see the error.

**Expected behavior**
Valid example that compiles correctly.

**Screenshots**
Add screenshots to help explain your problem. You can copy paste the screenshot in the github report. The .gif screen recording is very useful as well. 
![image](https://user-images.githubusercontent.com/29712657/96751629-55914180-13c5-11eb-92ca-a4be8a03a3cc.png)


**Desktop (please complete the following information):**
 - OS: macOs Mojave
 - Browser Chrome
 - Version 86


**Additional context**
Add any other context about the problem here.
","The Python class example does not compile **Describe the bug** From: https://makecode.microbit.org/python/classes ```python class Greeter: greeting = """" def __init__(self, message): self.greeting = message def greet(self): return ""Hello, "" + self.greeting greeter = Greeter(""world"") ``` Throws the following errors: ``` Line 4: the field 'greeting' of 'Greeter' is static Line 6: the field 'greeting' of 'Greeter' is static ``` **To Reproduce** copy paste the code in the Python editor and see the error. **Expected behavior** Valid example that compiles correctly. **Screenshots** Add screenshots to help explain your problem. You can copy paste the screenshot in the github report. The .gif screen recording is very useful as well. ![image](https://user-images.githubusercontent.com/29712657/96751629-55914180-13c5-11eb-92ca-a4be8a03a3cc.png) **Desktop (please complete the following information):** - OS: macOs Mojave - Browser Chrome - Version 86 **Additional context** Add any other context about the problem here. "
711975,711975,791291,https://api.github.com/repos/imaNNeoFighT/fl_chart/issues/95,0.0,2019-10-28T16:04:01Z,NONE,https://api.github.com/repos/imaNNeoFighT/fl_chart,Doesn't work on web,"It does not render correctly on the web. I know the web is only in technical preview so I didn't expect it to work but it would be nice if it did.

**Render on mobile (good)**
![image](https://user-images.githubusercontent.com/15237301/67772023-5cda7500-fa27-11e9-826f-ce361cc106f9.png)


**Render on web (bad)**
![Screen Shot 2019-10-28 at 11 01 46 AM](https://user-images.githubusercontent.com/15237301/67695108-900efc80-f972-11e9-8a66-1e7ef82a3bf9.png)
",Doesn't work on web It does not render correctly on the web. I know the web is only in technical preview so I didn't expect it to work but it would be nice if it did. **Render on mobile (good)** ![image](https://user-images.githubusercontent.com/15237301/67772023-5cda7500-fa27-11e9-826f-ce361cc106f9.png) **Render on web (bad)** ![Screen Shot 2019-10-28 at 11 01 46 AM](https://user-images.githubusercontent.com/15237301/67695108-900efc80-f972-11e9-8a66-1e7ef82a3bf9.png) 
391157,391157,434792,https://api.github.com/repos/argoproj/argo-rollouts/issues/1153,1.0,2021-05-09T19:19:42Z,NONE,https://api.github.com/repos/argoproj/argo-rollouts,Enable commiting the changes made by controllers back to Git - Improve GitOps support ,"# Summary

As a developer in GitOps team I would like to be able to track my cluster state in my GitOps repository.

I would like the controllers to make the changes to my cluster either: 

1) Indirectly by commiting the desired state back to my GitOps repository

Or

2) By commiting the state change back to my repository after making the changes in cluster. 


# Use Cases

An example use case would be management of blue-green deployment in declarative fashion. When I make a change to a rollout then the Service gets changed as well. Currently this is done by patching and leads to differences between  state described in GitOps repository and the state actually deployed into cluster. Tools which perform automatic synchronization would detect this and thus would undo the changes made by controller. 

---
<!-- Issue Author: Don't delete this message to encourage other users to support your issue! -->
**Message from the maintainers**:

Impacted by this bug? Give it a . We prioritize the issues with the most .",Enable commiting the changes made by controllers back to Git - Improve GitOps support # Summary As a developer in GitOps team I would like to be able to track my cluster state in my GitOps repository. I would like the controllers to make the changes to my cluster either: 1) Indirectly by commiting the desired state back to my GitOps repository Or 2) By commiting the state change back to my repository after making the changes in cluster. # Use Cases An example use case would be management of blue-green deployment in declarative fashion. When I make a change to a rollout then the Service gets changed as well. Currently this is done by patching and leads to differences between state described in GitOps repository and the state actually deployed into cluster. Tools which perform automatic synchronization would detect this and thus would undo the changes made by controller. --- <!-- Issue Author: Don't delete this message to encourage other users to support your issue! --> **Message from the maintainers**: Impacted by this bug? Give it a . We prioritize the issues with the most .
111336,111336,123756,https://api.github.com/repos/Villanite-Enterprises/VillaniteSite/issues/3,1.0,2021-02-14T00:23:38Z,COLLABORATOR,https://api.github.com/repos/Villanite-Enterprises/VillaniteSite,Switch to SASS/SCSS,"I'd like to swap over to SASS, but I also don't particularly know if using WebPack still falls in line with our goal to use no 3rd party tools. This will be up for debate.","Switch to SASS/SCSS I'd like to swap over to SASS, but I also don't particularly know if using WebPack still falls in line with our goal to use no 3rd party tools. This will be up for debate."
569241,569241,632606,https://api.github.com/repos/moneymanagerex/moneymanagerex/issues/2442,0.0,2020-04-29T22:25:54Z,CONTRIBUTOR,https://api.github.com/repos/moneymanagerex/moneymanagerex,Icon sizes restricted in MAC,"Icons size restricted
![鬼戟龜劇棘克 克逵戟逵 2020-04-30 勻 01 23 29](https://user-images.githubusercontent.com/6836805/80652810-6baaee80-8a81-11ea-9e3b-4cf9217168fc.png)


- Check OS
  - [ ] Windows
  - [x] Mac OSX
  - [ ] Linux 
-  Check MMEX version
  - [x] 1.3.x
  - [ ] 1.2.x
  - [ ] 1.1 or older
",Icon sizes restricted in MAC Icons size restricted ![鬼戟龜劇棘克 克逵戟逵 2020-04-30 勻 01 23 29](https://user-images.githubusercontent.com/6836805/80652810-6baaee80-8a81-11ea-9e3b-4cf9217168fc.png) - Check OS - [ ] Windows - [x] Mac OSX - [ ] Linux - Check MMEX version - [x] 1.3.x - [ ] 1.2.x - [ ] 1.1 or older 
314054,314054,349150,https://api.github.com/repos/BSData/The-9th-Age/issues/842,0.0,2021-01-03T17:26:49Z,COLLABORATOR,https://api.github.com/repos/BSData/The-9th-Age,HE: ootfh shield option,"When selecting a shield enchantment on OotFH mage, the program marks it as illegal.","HE: ootfh shield option When selecting a shield enchantment on OotFH mage, the program marks it as illegal."
718268,718268,798283,https://api.github.com/repos/puppetlabs/support-script-tooling/issues/3,0.0,2021-03-31T14:00:49Z,NONE,https://api.github.com/repos/puppetlabs/support-script-tooling,mlr: syntax error: unwrapped double quote at line 49078 for puppet-top-api-calls.sh,"## Describe the Bug
The script is expecting a set of data formatted in a particular way e.g. IP , Date, - , ... and when there is a block of data missing it will try to make transformations on the data probably based on positioning and throw an exception. The above error was produced as there was at least a line with a missing IP. 

## Expected Behavior
Script could validate data formatted as expected and provide option on the fly or less preferable ignore the line - bit dangerous as one may not have visibility of how much data has been left out in the analysis

## Steps to Reproduce
puppetserver-access log reference

For example,

Bad reference
```
- - [29/Mar/2021:01:25:43 +0200] ""GET /packages/2019.8.1/debian-8-amd64/dists/jessie/puppet6/binary-amd64/Packages.gz HTTP/1.1"" 416 0 ""-"" ""Debian APT-CURL/1.0 (1.0.9.8.6)"" 1 - -
```
versus good reference
```
10.0.0.238 - - [29/Mar/2021:01:25:43 +0200] ""GET /puppet/v3/file_metadata/modules/supervisor/supervisord.conf?links=manage&checksum_type=md5&source_permissions=ignore&environment=production HTTP/1.1"" 200 365 ""-"" ""Puppet/6.17.0 Ruby/2.5.8-p224 (x86_64-linux)"" 4 - 2
```

our file had 10 lines where the IP was missing. We opted for ignoring those lines by adding `| grep -E -v ""^ -"" ` to line 69 of `puppet-top-api-calls.sh` to read `""${read_cmd[@]}"" ""$file"" | grep -E -v ""^ -"" \`

## Environment
 - Version [e.g. 1.27.0]
 - Platform [e.g. Ubuntu 18.04]

## Additional Context
Add any other context about the problem here.
","mlr: syntax error: unwrapped double quote at line 49078 for puppet-top-api-calls.sh ## Describe the Bug The script is expecting a set of data formatted in a particular way e.g. IP , Date, - , ... and when there is a block of data missing it will try to make transformations on the data probably based on positioning and throw an exception. The above error was produced as there was at least a line with a missing IP. ## Expected Behavior Script could validate data formatted as expected and provide option on the fly or less preferable ignore the line - bit dangerous as one may not have visibility of how much data has been left out in the analysis ## Steps to Reproduce puppetserver-access log reference For example, Bad reference ``` - - [29/Mar/2021:01:25:43 +0200] ""GET /packages/2019.8.1/debian-8-amd64/dists/jessie/puppet6/binary-amd64/Packages.gz HTTP/1.1"" 416 0 ""-"" ""Debian APT-CURL/1.0 (1.0.9.8.6)"" 1 - - ``` versus good reference ``` 10.0.0.238 - - [29/Mar/2021:01:25:43 +0200] ""GET /puppet/v3/file_metadata/modules/supervisor/supervisord.conf?links=manage&checksum_type=md5&source_permissions=ignore&environment=production HTTP/1.1"" 200 365 ""-"" ""Puppet/6.17.0 Ruby/2.5.8-p224 (x86_64-linux)"" 4 - 2 ``` our file had 10 lines where the IP was missing. We opted for ignoring those lines by adding `| grep -E -v ""^ -"" ` to line 69 of `puppet-top-api-calls.sh` to read `""${read_cmd[@]}"" ""$file"" | grep -E -v ""^ -"" \` ## Environment - Version [e.g. 1.27.0] - Platform [e.g. Ubuntu 18.04] ## Additional Context Add any other context about the problem here. "
236903,236903,263502,https://api.github.com/repos/eisen-oxid/thermit/issues/34,0.0,2021-03-29T15:27:37Z,CONTRIBUTOR,https://api.github.com/repos/eisen-oxid/thermit,/users: Returns an array instead of a JSON object,,/users: Returns an array instead of a JSON object 
574638,574638,638570,https://api.github.com/repos/elastic/kibana/issues/9872,0.0,2017-01-14T19:02:02Z,CONTRIBUTOR,https://api.github.com/repos/elastic/kibana,Scroll bar obscures visualization resize corner on a long dashboard,"When the dashboard is longer than the screen size, it's hard to resize a visualization on the bottom right of the dashboard, because the overall dashboard scroll bar obscures the bottom right corner, which user must grab to resize. It can be very frustrating.

![resize_issue](https://cloud.githubusercontent.com/assets/933397/21957317/a5655d5a-da48-11e6-9426-9b5ab4bac2dd.gif)
","Scroll bar obscures visualization resize corner on a long dashboard When the dashboard is longer than the screen size, it's hard to resize a visualization on the bottom right of the dashboard, because the overall dashboard scroll bar obscures the bottom right corner, which user must grab to resize. It can be very frustrating. ![resize_issue](https://cloud.githubusercontent.com/assets/933397/21957317/a5655d5a-da48-11e6-9426-9b5ab4bac2dd.gif) "
428508,428508,476341,https://api.github.com/repos/jptrsn/ESP32-mqtt-room/issues/43,0.0,2021-03-04T10:29:07Z,NONE,https://api.github.com/repos/jptrsn/ESP32-mqtt-room,No devices are found,"**Describe the bug**
When doing scan, no devices are found.

**Configuration**
```
//Replace with your Wifi SSID; example: #define ssid ""MyWifi""
#define ssid ""WiFi""

//Replace with your Wifi password; example: #define password ""12345678""
#define password ""xxx""

//Replace with a human-friendly host name. Must not contain spaces or special characters and be unique on your network
#define hostname ""esp32_room_presence""

//Replace with your MQTT Broker address; example: #define mqttHost IPAddress(192, 168, 1, 195)
#define mqttHost IPAddress(192, 168, x, xx)

//Replace with your MQTT Broker port; example: #define mqttPort 1883
#define mqttPort 1883

//Replace with your MQTT Broker user; example: #define mqttUser ""homeassistant""
#define mqttUser ""xx""

//Replace with your MQTT Broker password; example: #define mqttPassword ""12345678""
#define mqttPassword ""xx""

//Replace with the room name where the node will be placed; example: #define room ""living-room""
#define room ""kabinet""

//Specify the LED pin. For most dev boards, this is GPIO2
#define LED_BUILTIN 2

// Logic level for turning the led on. Most boards use active low, meaning LED_ON should be set to 0
#define LED_ON 0

//Define the base topic for room detection. Usually ""room_presence""
#define channel ""room_presence""

//Define the topic for publishing availability
#define availabilityTopic ""presence_nodes/"" room

//Define the topic for publishing JSON attributes
#define telemetryTopic ""presence_nodes/"" hostname ""/tele""

// Define bluetooth scan parameters
#define scanInterval 5 // Define the interval in seconds between scans
#define singleScanTime 5 // Define the duration of a single scan in seconds
#define activeScan true // Active scan uses more power, but get results faster
#define bleScanInterval 0x80 // Used to determine antenna sharing between Bluetooth and WiFi. Do not modify unless you are confident you know what you're doing
#define bleScanWindow 0x10 // Used to determine antenna sharing between Bluetooth and WiFi. Do not modify unless you are confident you know what you're doing

// Maximum distance (in meters) to report. Devices that are calculated to be further than this distance in meters will not be reported
#define maxDistance 2

// MQTT topic for sensor values from HTU21D temperature and humidity sensor
//#define htuSensorTopic ""presence_nodes/"" hostname ""/sensor""


//List of allowed MAC Addresses for MQTT Publish. All others will be ignored.
//Feature is disabled by default.
#define allowedListCheck false
String allowedList[] = {""11223344aabb"", ""11223344aabb""};
uint32_t allowedListNumberOfItems = 2;
```


**Logs**
```
Scanning...     Scan done! Devices found: 0
devices_discovered: 0
devices_reported: 0
Telemetry sent
```

**Hardware Details**
I have ESP32S developer board. Two actually. On one I am running OpenMQTTGateway that detects all my Xiaomi temperature sensors. For this second one I plan to put it in one room in which I am working from home so I can have specific automation working when I am inside. I have put OpenMQTTGateway on the same ESP32 and it found devices so it is working. But with ESP32-mqtt-room it finds none.

I can see device in MQTT and state connected. So WiFi and MQTT connection is working fine. I can also see blue LED on ESP32 blinking when it says Scanning...

**To Reproduce**

Connect to USB power and check serial logs.

**Expected behavior**

I expect to find many devices inside the house. I have Beacon Simulator on phone and expect for it to detect it also.

**Screenshots**


**Additional context**

","No devices are found **Describe the bug** When doing scan, no devices are found. **Configuration** ``` //Replace with your Wifi SSID; example: #define ssid ""MyWifi"" #define ssid ""WiFi"" //Replace with your Wifi password; example: #define password ""12345678"" #define password ""xxx"" //Replace with a human-friendly host name. Must not contain spaces or special characters and be unique on your network #define hostname ""esp32_room_presence"" //Replace with your MQTT Broker address; example: #define mqttHost IPAddress(192, 168, 1, 195) #define mqttHost IPAddress(192, 168, x, xx) //Replace with your MQTT Broker port; example: #define mqttPort 1883 #define mqttPort 1883 //Replace with your MQTT Broker user; example: #define mqttUser ""homeassistant"" #define mqttUser ""xx"" //Replace with your MQTT Broker password; example: #define mqttPassword ""12345678"" #define mqttPassword ""xx"" //Replace with the room name where the node will be placed; example: #define room ""living-room"" #define room ""kabinet"" //Specify the LED pin. For most dev boards, this is GPIO2 #define LED_BUILTIN 2 // Logic level for turning the led on. Most boards use active low, meaning LED_ON should be set to 0 #define LED_ON 0 //Define the base topic for room detection. Usually ""room_presence"" #define channel ""room_presence"" //Define the topic for publishing availability #define availabilityTopic ""presence_nodes/"" room //Define the topic for publishing JSON attributes #define telemetryTopic ""presence_nodes/"" hostname ""/tele"" // Define bluetooth scan parameters #define scanInterval 5 // Define the interval in seconds between scans #define singleScanTime 5 // Define the duration of a single scan in seconds #define activeScan true // Active scan uses more power, but get results faster #define bleScanInterval 0x80 // Used to determine antenna sharing between Bluetooth and WiFi. Do not modify unless you are confident you know what you're doing #define bleScanWindow 0x10 // Used to determine antenna sharing between Bluetooth and WiFi. Do not modify unless you are confident you know what you're doing // Maximum distance (in meters) to report. Devices that are calculated to be further than this distance in meters will not be reported #define maxDistance 2 // MQTT topic for sensor values from HTU21D temperature and humidity sensor //#define htuSensorTopic ""presence_nodes/"" hostname ""/sensor"" //List of allowed MAC Addresses for MQTT Publish. All others will be ignored. //Feature is disabled by default. #define allowedListCheck false String allowedList[] = {""11223344aabb"", ""11223344aabb""}; uint32_t allowedListNumberOfItems = 2; ``` **Logs** ``` Scanning... Scan done! Devices found: 0 devices_discovered: 0 devices_reported: 0 Telemetry sent ``` **Hardware Details** I have ESP32S developer board. Two actually. On one I am running OpenMQTTGateway that detects all my Xiaomi temperature sensors. For this second one I plan to put it in one room in which I am working from home so I can have specific automation working when I am inside. I have put OpenMQTTGateway on the same ESP32 and it found devices so it is working. But with ESP32-mqtt-room it finds none. I can see device in MQTT and state connected. So WiFi and MQTT connection is working fine. I can also see blue LED on ESP32 blinking when it says Scanning... **To Reproduce** Connect to USB power and check serial logs. **Expected behavior** I expect to find many devices inside the house. I have Beacon Simulator on phone and expect for it to detect it also. **Screenshots** **Additional context** "
370474,370474,411850,https://api.github.com/repos/pretix/pretix/issues/1644,1.0,2020-04-15T23:54:46Z,CONTRIBUTOR,https://api.github.com/repos/pretix/pretix,Feature Request: Timezone display offset,it would be great if the timezone offset to UTC would be displayed in the dropdown menu. ,Feature Request: Timezone display offset it would be great if the timezone offset to UTC would be displayed in the dropdown menu. 
406605,406605,451953,https://api.github.com/repos/microsoftgraph/msgraph-sdk-java/issues/758,2.0,2021-05-13T19:35:53Z,NONE,https://api.github.com/repos/microsoftgraph/msgraph-sdk-java,Save Microsoft GraphAPI OutlookItem response as eml,"<!-- Read me before you submit this issue

First off, thank you for taking the time to open this issue! We do appreciate it. Please bear with us if we don't get to this right away.

If this is a question about the Microsoft Graph service API, or a question about how to use this SDK, please post your question to StackOverflow with the [microsoftgraph] tag.
https://stackoverflow.com/questions/tagged/microsoft-graph

This repo is for the Microsoft Graph Java SDK. Issues opened in this repo should only target this SDK.

Before you open this issue, did you:
- Search the issues to determine whether someone already opened this issue?
- Search StackOverflow for an answer?
- Capture the repro steps and gather the information requested in the steps below to reproduce your scenario?
- Review the samples under github.com/microsoftgraph? They can help for some scenarios.
- Take a look at the functional tests in this repo? They may have an example for you. See the [functional tests](https://github.com/microsoftgraph/msgraph-sdk-java/tree/master/src/test/java/com/microsoft/graph/functional)

Please provide the following before submitting this issue:
- Expected behavior. Please provide **links to the specific [Microsoft Graph documentation](https://developer.microsoft.com/en-us/graph/docs/concepts/overview)** you used to determine the expected behavior. 
- Actual behavior. Provide error codes, stack information, and a [Fiddler](http://www.telerik.com/fiddler) capture of the request and response (please remove personally identifiable information before posting).
- Steps to reproduce the behavior. Include your code, IDE versions, client library versions, and any other information that might be helpful to understand your scenario.
-->

### Expected behavior
ItemAttachment does not return contentBytes byte[] data for .msg and .eml file types in the following version.
 ```
   //Microsoft graph API dependencies
compile group: 'com.microsoft.graph', name: 'microsoft-graph', version: '3.0.0'

```
### Actual behavior. 
Data contentBytes byte[] is empty.


### Steps to reproduce the behavior
Attach a .msg to email. Then try to get the byte[] data.

Our scenario: We need to save the .msg attachment into a local drive. 
Unfortunately content bytes is not available for this ItemAttachment response for .msg/.eml file types.

I was able to use the following call and get Mime response.

`https://graph.microsoft.com/v1.0/me/messages/<MessageID>/attachments/<AttachmentId>/$value
`
![image](https://user-images.githubusercontent.com/81188855/118177521-6a343600-b3f8-11eb-8104-976d744d1406.png)

**Question:** How do I save this response to an eml outlook file? I tried renaming the result to .eml/.msg but nothing worked. Any third party libraries are there?

Note I was able to save attachment present inside by converting to bytes.
`byte [] result = Base64.getMimeDecoder().decode(bytes);
`



 
[AB#9469](https://microsoftgraph.visualstudio.com/0985d294-5762-4bc2-a565-161ef349ca3e/_workitems/edit/9469)","Save Microsoft GraphAPI OutlookItem response as eml <!-- Read me before you submit this issue First off, thank you for taking the time to open this issue! We do appreciate it. Please bear with us if we don't get to this right away. If this is a question about the Microsoft Graph service API, or a question about how to use this SDK, please post your question to StackOverflow with the [microsoftgraph] tag. https://stackoverflow.com/questions/tagged/microsoft-graph This repo is for the Microsoft Graph Java SDK. Issues opened in this repo should only target this SDK. Before you open this issue, did you: - Search the issues to determine whether someone already opened this issue? - Search StackOverflow for an answer? - Capture the repro steps and gather the information requested in the steps below to reproduce your scenario? - Review the samples under github.com/microsoftgraph? They can help for some scenarios. - Take a look at the functional tests in this repo? They may have an example for you. See the [functional tests](https://github.com/microsoftgraph/msgraph-sdk-java/tree/master/src/test/java/com/microsoft/graph/functional) Please provide the following before submitting this issue: - Expected behavior. Please provide **links to the specific [Microsoft Graph documentation](https://developer.microsoft.com/en-us/graph/docs/concepts/overview)** you used to determine the expected behavior. - Actual behavior. Provide error codes, stack information, and a [Fiddler](http://www.telerik.com/fiddler) capture of the request and response (please remove personally identifiable information before posting). - Steps to reproduce the behavior. Include your code, IDE versions, client library versions, and any other information that might be helpful to understand your scenario. --> ### Expected behavior ItemAttachment does not return contentBytes byte[] data for .msg and .eml file types in the following version. ``` //Microsoft graph API dependencies compile group: 'com.microsoft.graph', name: 'microsoft-graph', version: '3.0.0' ``` ### Actual behavior. Data contentBytes byte[] is empty. ### Steps to reproduce the behavior Attach a .msg to email. Then try to get the byte[] data. Our scenario: We need to save the .msg attachment into a local drive. Unfortunately content bytes is not available for this ItemAttachment response for .msg/.eml file types. I was able to use the following call and get Mime response. `https://graph.microsoft.com/v1.0/me/messages/<MessageID>/attachments/<AttachmentId>/$value ` ![image](https://user-images.githubusercontent.com/81188855/118177521-6a343600-b3f8-11eb-8104-976d744d1406.png) **Question:** How do I save this response to an eml outlook file? I tried renaming the result to .eml/.msg but nothing worked. Any third party libraries are there? Note I was able to save attachment present inside by converting to bytes. `byte [] result = Base64.getMimeDecoder().decode(bytes); ` [AB#9469](https://microsoftgraph.visualstudio.com/0985d294-5762-4bc2-a565-161ef349ca3e/_workitems/edit/9469)"
752029,752029,288810,https://api.github.com/repos/vert-x3/vertx-web/issues/1862,0.0,2021-02-07T18:14:46Z,MEMBER,https://api.github.com/repos/vert-x3/vertx-web,WebClientSession should be annotated with VertxGen,Related to https://github.com/smallrye/smallrye-reactive-utils/issues/244.,WebClientSession should be annotated with VertxGen Related to https://github.com/smallrye/smallrye-reactive-utils/issues/244.
538828,538828,598875,https://api.github.com/repos/outline/outline/issues/1972,0.0,2021-03-21T21:32:36Z,NONE,https://api.github.com/repos/outline/outline,Release v0.54.0 migrate authentication on Self hosted installation doesn't work ,"Hi folks, 

First I want to say thank you to the maintainers for Outline as a Product which is great and also for the rest of the community.

Let me explain my issue, I was trying to migrate from version 0.53.1 to 0.54.0

**Outline (please complete the following information):**
- Install: Self-hosted [Heroku]
- Version:v0.54.0

The deploy process works in Heroku, without problems, but the applications crash, and I can't go back because the structure change and the code for version 0.53.1 don't match or work with the new structure.

When I try to run the migrations script

```node /build/server/scripts/20210226232041-migrate-authentication.js``` I got the following errors from script https://github.com/outline/outline/blob/main/server/scripts/20210226232041-migrate-authentication.js#L82:

```
serviceId 106629815691052806096 exists, for user b96ac88d-4478-4f8c-922c-dd3e4923095a
serviceId 113585736485673695751 exists, for user 80957855-e3a4-4c79-befa-16ff7f537209
serviceId 107846379410345019507 exists, for user 5685d228-c1f5-4914-8d48-00fac4a5c39e
serviceId 108101704821184916968 exists, for user 31300843-4b11-4ab4-bbfc-920e94fe5e78
serviceId 108145562443761770376 exists, for user 445caffd-80b8-4fdb-8a42-d416e38b0669
serviceId 100191673069030564446 exists, for user 24366da3-bc7f-4668-8022-df07595a1f07
serviceId 100782390040942005075 exists, for user 2f06b39a-20c7-46c8-911c-1f07b6807cf1
serviceId 100040180475101280608 exists, for user f10248db-80d4-4fec-b42e-91114a8aa916
serviceId 101211108413811319250 exists, for user d8b8fcde-70cc-45e2-9f74-49a8944c63c5
serviceId 104915645889588925961 exists, for user b48ab57c-5c29-4cd0-96e3-bbcea570f193
serviceId 109491887471551654945 exists, for user 2b065672-d485-4283-9100-396f7d4c4e4f
serviceId 113869810578869235647 exists, for user ae2e095c-8a08-4e83-bb0f-c2503506c2e2
serviceId 115787818327594248153 exists, for user 6a599c20-c987-4b08-8e11-40add4c2aad9
serviceId 100773526721550001032 exists, for user d14f98bf-5ba1-4b95-bcd2-88c4f9e56532
serviceId 108691919391177770035 exists, for user c890e6ab-efff-447b-95f9-ccf9fdbd1992
serviceId 102633264003690699696 exists, for user c44b6b91-9a01-4b3c-9533-69ce1e255704
serviceId 100522360778330628641 exists, for user 89b94e69-c6f8-4224-b2d9-33b1c96d18e7
serviceId 118231132886780399171 exists, for user 028a5e25-5976-462f-821c-df65df2360b3
serviceId 103353208725638633085 exists, for user 4a48cf73-eb1e-4b22-8869-e37be93e6372
serviceId 112927085706118264879 exists, for user 98e97fed-e5d3-4269-8de9-1216cfacaf2e
serviceId 118041341268606120386 exists, for user af6fb909-712b-4b51-8737-67f1c1493559
serviceId U01162V8WP2 exists, for user e35eb779-7859-4338-a2b8-f77f71f2393a
serviceId 105438400528728289170 exists, for user 35cf2566-cef8-4cb4-b2bd-ca7ef7caee80
serviceId U010V4C0L90 exists, for user f1bb10dd-1974-455d-a1d9-c41ea7c5ea5f
serviceId 113526147248043396307 exists, for user 96915cbf-39c2-45c9-bd03-b4f5af76e36d
serviceId 112199957567161430754 exists, for user 7973193d-a830-4daf-b464-781c530d69ba
serviceId 105395398007756494254 exists, for user c1914b64-89b7-4bf0-9f7e-da78d63450bb
serviceId 113476596128161323892 exists, for user 5f5bf586-b5ee-4b0f-9061-db2607ebc70f
serviceId 114089765459615606253 exists, for user e24ce685-baaf-4218-a8b3-342701e01763
serviceId 102096236174812806449 exists, for user 61f05212-dea2-4afe-b643-3908f1eaf6ca
serviceId 111784240398498739232 exists, for user ef9810da-e78d-4cd3-81cb-59de249bc029
serviceId 116886058898576909921 exists, for user 28860a47-1b49-4657-9fd7-850b6db0c276
serviceId 108634152313243551967 exists, for user aed0895c-9c29-4fd7-9c1d-d41b7e5789c2
serviceId 115790323136424322263 exists, for user e69dd388-be62-4ad8-8cd1-fbe9a3c481fa
serviceId 109153449628150257705 exists, for user 7786f0f7-6f93-4939-b4fd-34b5a2fa1129
serviceId 109383022281266071816 exists, for user 27d36f05-2fe0-449e-b99a-96a192d6b083
serviceId U01ADL5CWKZ exists, for user cf27ada8-ca0d-4e11-8590-f9ed40a1550a
serviceId 116173797824765342008 exists, for user f512f2a6-5b46-41ed-9ea2-06870c983206
serviceId 117766188067413906761 exists, for user 772dd0f3-16bf-426c-8d84-fe1bf017e6fe
serviceId 105502235995801400102 exists, for user cbd9c2ea-29f8-4227-aecc-a58573960d84
serviceId 106425073990517401483 exists, for user a5ddd892-3811-47f3-8935-cba260e52ac2
serviceId 110597281146721635381 exists, for user 808ef35e-2932-4cd2-be0b-1a33be84692b
serviceId 101543505976130818404 exists, for user b8de24ca-1619-47e6-8160-19877eda2b24
serviceId 115072305537751910995 exists, for user 1cf67847-39b0-4e06-af5b-121ed7b1c00d
```

Checking the script code looks like, the migration wasn't completed and maybe that is why the app crash?

I am using Google authentication.

Any ideas about how I could push back the database structure or how to fix the issues with the services?

Thanks in advance for your help




","Release v0.54.0 migrate authentication on Self hosted installation doesn't work Hi folks, First I want to say thank you to the maintainers for Outline as a Product which is great and also for the rest of the community. Let me explain my issue, I was trying to migrate from version 0.53.1 to 0.54.0 **Outline (please complete the following information):** - Install: Self-hosted [Heroku] - Version:v0.54.0 The deploy process works in Heroku, without problems, but the applications crash, and I can't go back because the structure change and the code for version 0.53.1 don't match or work with the new structure. When I try to run the migrations script ```node /build/server/scripts/20210226232041-migrate-authentication.js``` I got the following errors from script https://github.com/outline/outline/blob/main/server/scripts/20210226232041-migrate-authentication.js#L82: ``` serviceId 106629815691052806096 exists, for user b96ac88d-4478-4f8c-922c-dd3e4923095a serviceId 113585736485673695751 exists, for user 80957855-e3a4-4c79-befa-16ff7f537209 serviceId 107846379410345019507 exists, for user 5685d228-c1f5-4914-8d48-00fac4a5c39e serviceId 108101704821184916968 exists, for user 31300843-4b11-4ab4-bbfc-920e94fe5e78 serviceId 108145562443761770376 exists, for user 445caffd-80b8-4fdb-8a42-d416e38b0669 serviceId 100191673069030564446 exists, for user 24366da3-bc7f-4668-8022-df07595a1f07 serviceId 100782390040942005075 exists, for user 2f06b39a-20c7-46c8-911c-1f07b6807cf1 serviceId 100040180475101280608 exists, for user f10248db-80d4-4fec-b42e-91114a8aa916 serviceId 101211108413811319250 exists, for user d8b8fcde-70cc-45e2-9f74-49a8944c63c5 serviceId 104915645889588925961 exists, for user b48ab57c-5c29-4cd0-96e3-bbcea570f193 serviceId 109491887471551654945 exists, for user 2b065672-d485-4283-9100-396f7d4c4e4f serviceId 113869810578869235647 exists, for user ae2e095c-8a08-4e83-bb0f-c2503506c2e2 serviceId 115787818327594248153 exists, for user 6a599c20-c987-4b08-8e11-40add4c2aad9 serviceId 100773526721550001032 exists, for user d14f98bf-5ba1-4b95-bcd2-88c4f9e56532 serviceId 108691919391177770035 exists, for user c890e6ab-efff-447b-95f9-ccf9fdbd1992 serviceId 102633264003690699696 exists, for user c44b6b91-9a01-4b3c-9533-69ce1e255704 serviceId 100522360778330628641 exists, for user 89b94e69-c6f8-4224-b2d9-33b1c96d18e7 serviceId 118231132886780399171 exists, for user 028a5e25-5976-462f-821c-df65df2360b3 serviceId 103353208725638633085 exists, for user 4a48cf73-eb1e-4b22-8869-e37be93e6372 serviceId 112927085706118264879 exists, for user 98e97fed-e5d3-4269-8de9-1216cfacaf2e serviceId 118041341268606120386 exists, for user af6fb909-712b-4b51-8737-67f1c1493559 serviceId U01162V8WP2 exists, for user e35eb779-7859-4338-a2b8-f77f71f2393a serviceId 105438400528728289170 exists, for user 35cf2566-cef8-4cb4-b2bd-ca7ef7caee80 serviceId U010V4C0L90 exists, for user f1bb10dd-1974-455d-a1d9-c41ea7c5ea5f serviceId 113526147248043396307 exists, for user 96915cbf-39c2-45c9-bd03-b4f5af76e36d serviceId 112199957567161430754 exists, for user 7973193d-a830-4daf-b464-781c530d69ba serviceId 105395398007756494254 exists, for user c1914b64-89b7-4bf0-9f7e-da78d63450bb serviceId 113476596128161323892 exists, for user 5f5bf586-b5ee-4b0f-9061-db2607ebc70f serviceId 114089765459615606253 exists, for user e24ce685-baaf-4218-a8b3-342701e01763 serviceId 102096236174812806449 exists, for user 61f05212-dea2-4afe-b643-3908f1eaf6ca serviceId 111784240398498739232 exists, for user ef9810da-e78d-4cd3-81cb-59de249bc029 serviceId 116886058898576909921 exists, for user 28860a47-1b49-4657-9fd7-850b6db0c276 serviceId 108634152313243551967 exists, for user aed0895c-9c29-4fd7-9c1d-d41b7e5789c2 serviceId 115790323136424322263 exists, for user e69dd388-be62-4ad8-8cd1-fbe9a3c481fa serviceId 109153449628150257705 exists, for user 7786f0f7-6f93-4939-b4fd-34b5a2fa1129 serviceId 109383022281266071816 exists, for user 27d36f05-2fe0-449e-b99a-96a192d6b083 serviceId U01ADL5CWKZ exists, for user cf27ada8-ca0d-4e11-8590-f9ed40a1550a serviceId 116173797824765342008 exists, for user f512f2a6-5b46-41ed-9ea2-06870c983206 serviceId 117766188067413906761 exists, for user 772dd0f3-16bf-426c-8d84-fe1bf017e6fe serviceId 105502235995801400102 exists, for user cbd9c2ea-29f8-4227-aecc-a58573960d84 serviceId 106425073990517401483 exists, for user a5ddd892-3811-47f3-8935-cba260e52ac2 serviceId 110597281146721635381 exists, for user 808ef35e-2932-4cd2-be0b-1a33be84692b serviceId 101543505976130818404 exists, for user b8de24ca-1619-47e6-8160-19877eda2b24 serviceId 115072305537751910995 exists, for user 1cf67847-39b0-4e06-af5b-121ed7b1c00d ``` Checking the script code looks like, the migration wasn't completed and maybe that is why the app crash? I am using Google authentication. Any ideas about how I could push back the database structure or how to fix the issues with the services? Thanks in advance for your help "
556561,556561,618542,https://api.github.com/repos/marcosdosea/GestaoEscolar/issues/189,1.0,2021-02-15T23:20:07Z,COLLABORATOR,https://api.github.com/repos/marcosdosea/GestaoEscolar,Traduzir e organizar a tela de autentica챌찾o,A op챌찾o de autentica챌찾o ainda est찼 no lugar errado e as telas em ingl챗s.,Traduzir e organizar a tela de autentica챌찾o A op챌찾o de autentica챌찾o ainda est찼 no lugar errado e as telas em ingl챗s.
647377,647377,719567,https://api.github.com/repos/nilearn/nilearn/issues/2733,1.0,2021-03-17T21:22:12Z,NONE,https://api.github.com/repos/nilearn/nilearn,plotting.view_markers marker_labels,"I have been using `plotting.view_markers` for some time and really like the ability to define marker_color. I am wondering if it's possible to add marker_label as well?

### Benefits to the change
I think many users would find this helpful, especially when plotting many points at one time. In our use case, we are displaying depth electrode contacts for epilepsy patients and having each contact point labelled would be a benefit to our clinicians.

```python
import matplotlib.pyplot as plt
from nilearn import plotting

labels = #string label for each electrode contact
groups = #of implanted electrodes
n_members = #of contacts for each electrode

cmap = plt.get_cmap('rainbow')
colors=np.repeat(cmap(np.linspace(0, 1, len(groups))), n_members, axis=0)

html_view = plotting.view_markers(coordinates, marker_size=5.0, marker_color=colors, marker_labels=labels)
```
","plotting.view_markers marker_labels I have been using `plotting.view_markers` for some time and really like the ability to define marker_color. I am wondering if it's possible to add marker_label as well? ### Benefits to the change I think many users would find this helpful, especially when plotting many points at one time. In our use case, we are displaying depth electrode contacts for epilepsy patients and having each contact point labelled would be a benefit to our clinicians. ```python import matplotlib.pyplot as plt from nilearn import plotting labels = #string label for each electrode contact groups = #of implanted electrodes n_members = #of contacts for each electrode cmap = plt.get_cmap('rainbow') colors=np.repeat(cmap(np.linspace(0, 1, len(groups))), n_members, axis=0) html_view = plotting.view_markers(coordinates, marker_size=5.0, marker_color=colors, marker_labels=labels) ``` "
310384,310384,345102,https://api.github.com/repos/OPCFoundation/UA-.NETStandard/issues/1322,2.0,2021-03-14T23:57:38Z,NONE,https://api.github.com/repos/OPCFoundation/UA-.NETStandard,Add address space at runtime,"Hello, is there any way to add a new  address space  and  add nodes to the new address space at runtime dynamically ? ","Add address space at runtime Hello, is there any way to add a new address space and add nodes to the new address space at runtime dynamically ? "
171348,171348,190524,https://api.github.com/repos/Mephiles/torntools_extension/issues/297,0.0,2020-12-09T14:30:08Z,OWNER,https://api.github.com/repos/Mephiles/torntools_extension,[BUG] Clear targets button,"**Describe the bug**
Clear targets button not working correctly, function might be broken.
","[BUG] Clear targets button **Describe the bug** Clear targets button not working correctly, function might be broken. "
194533,194533,216324,https://api.github.com/repos/divnix/devos/issues/169,1.0,2021-03-15T17:03:53Z,COLLABORATOR,https://api.github.com/repos/divnix/devos,Pass 'self' to lib,"For os.mkPkgs and os.mkPackages, self is passed to them as a function argument. But why not just pass self to lib/default.nix and make it available for all lib functions? 
So you can just call `os.mkPkgs` without any arguments. And `os.mkPackages` can just be passed `pkgs`.","Pass 'self' to lib For os.mkPkgs and os.mkPackages, self is passed to them as a function argument. But why not just pass self to lib/default.nix and make it available for all lib functions? So you can just call `os.mkPkgs` without any arguments. And `os.mkPackages` can just be passed `pkgs`."
527769,527769,586594,https://api.github.com/repos/matrix-org/sygnal/issues/189,1.0,2021-03-29T21:48:15Z,MEMBER,https://api.github.com/repos/matrix-org/sygnal,"Tox should default to current python, not py37","Right now our tox.ini (and docs) default to `py37`... we should replace this with just `py` which means to use the same version of Python which invoked tox.

This would make testing more convenient for folks on py38, py39, etc.","Tox should default to current python, not py37 Right now our tox.ini (and docs) default to `py37`... we should replace this with just `py` which means to use the same version of Python which invoked tox. This would make testing more convenient for folks on py38, py39, etc."
248944,248944,276900,https://api.github.com/repos/keystonejs/keystone/issues/1166,0.0,2019-05-15T07:24:50Z,CONTRIBUTOR,https://api.github.com/repos/keystonejs/keystone,user_is_null check does not work,"query should not return users that are null

```
  fragment EventData on Event {
    id
    name
    startTime
    description
    themeColor
    talks {
      id
      name
      speakers {
        id
        name
        image {
          publicUrl
        }
      }
    }
  }


  query GetEventDetails($event: ID!) {
    Event(where: { id: $event }) {
      ...EventData
      talks {
        speakers {
          image {
            publicUrl
          }
        }
      }
    }
    allRsvps(where: { event: { id: $event }, user_is_null: false }) {
      user {
        image {
          publicUrl
        }
      }
    }
  }
```

result 

```
{
  ""data"": {
    ""Event"": {
      ""id"": ""5b72d3b3f9f3b900046995c3"",
      ""name"": ""SydJS: Directions"",
      ""startTime"": ""2018-08-15T18:00:00.000+10:00"",
      ""description"": ""description"",
      ""themeColor"": ""#5B52DE"",
      ""talks"": [
        {
          ""id"": ""5b72d5d4f9f3b900046995c8"",
          ""name"": ""Hiring Juniors"",
          ""speakers"": []
        },
        {
          ""id"": ""5b72d6b9f9f3b900046995c9"",
          ""name"": ""Atomic, presentational, reusable, functional components: UI architecture in the age of design systems"",
          ""speakers"": [
            {
              ""id"": ""53e596745ada0302000b29ca"",
              ""name"": ""isabel brison"",
              ""image"": {
                ""publicUrl"": ""https://res.cloudinary.com/sydjs/image/upload/v1407555563/tkkfjwknpxr4a00yzbxw.png""
              }
            }
          ]
        },
        {
          ""id"": ""5b72d729f9f3b900046995cb"",
          ""name"": ""Performant, accessible animations with CSS & a dash of JavaScript"",
          ""speakers"": []
        }
      ]
    },
    ""allRsvps"": [
      {
        ""user"": {
          ""image"": {
            ""publicUrl"": ""https://res.cloudinary.com/sydjs/image/upload/v1386195796/rn5l6lwobdz9wxdayvai.jpg""
          }
        }
      },
      {
        ""user"": {
          ""image"": {
            ""publicUrl"": null
          }
        }
      },
      {
        ""user"": null
      },
      {
        ""user"": {
          ""image"": {
            ""publicUrl"": null
          }
        }
      },
      {
        ""user"": null
      },
```","user_is_null check does not work query should not return users that are null ``` fragment EventData on Event { id name startTime description themeColor talks { id name speakers { id name image { publicUrl } } } } query GetEventDetails($event: ID!) { Event(where: { id: $event }) { ...EventData talks { speakers { image { publicUrl } } } } allRsvps(where: { event: { id: $event }, user_is_null: false }) { user { image { publicUrl } } } } ``` result ``` { ""data"": { ""Event"": { ""id"": ""5b72d3b3f9f3b900046995c3"", ""name"": ""SydJS: Directions"", ""startTime"": ""2018-08-15T18:00:00.000+10:00"", ""description"": ""description"", ""themeColor"": ""#5B52DE"", ""talks"": [ { ""id"": ""5b72d5d4f9f3b900046995c8"", ""name"": ""Hiring Juniors"", ""speakers"": [] }, { ""id"": ""5b72d6b9f9f3b900046995c9"", ""name"": ""Atomic, presentational, reusable, functional components: UI architecture in the age of design systems"", ""speakers"": [ { ""id"": ""53e596745ada0302000b29ca"", ""name"": ""isabel brison"", ""image"": { ""publicUrl"": ""https://res.cloudinary.com/sydjs/image/upload/v1407555563/tkkfjwknpxr4a00yzbxw.png"" } } ] }, { ""id"": ""5b72d729f9f3b900046995cb"", ""name"": ""Performant, accessible animations with CSS & a dash of JavaScript"", ""speakers"": [] } ] }, ""allRsvps"": [ { ""user"": { ""image"": { ""publicUrl"": ""https://res.cloudinary.com/sydjs/image/upload/v1386195796/rn5l6lwobdz9wxdayvai.jpg"" } } }, { ""user"": { ""image"": { ""publicUrl"": null } } }, { ""user"": null }, { ""user"": { ""image"": { ""publicUrl"": null } } }, { ""user"": null }, ```"
727701,727701,47048,https://api.github.com/repos/wasmCloud/wash/issues/44,1.0,2020-12-18T15:30:01Z,CONTRIBUTOR,https://api.github.com/repos/wasmCloud/wash,REPL asynchronous calls block user input and REPL drawing,"When using the REPL, many commands involve a command interface request that is asynchronous and immediately `await`ed for the timeout specified, or until the function is finished executing. A good example of one of these calls that takes a long time is `start provider wascc.azurecr.io/redis:v0.9.2 --timeout 30`, which takes up to 30 seconds to download, verify, auction and schedule a provider on a `wasmcloud-host` instance. When any call like this takes over 3 seconds, the REPL appears ""frozen"" as no more logs are allowed to display and no user input is recognized until after the call completes.

To combat a similar issue with the host blocking operations, I've refactored the REPL host to start in its own thread and await events there. This works great to allow the host to run without blocking the REPL, but these long standing `await`ed calls are still blocking the execution of the REPL.

Without exactly knowing the difficulty or code mess that may ensue (with ownership and closures) a naive solution here may be to send each `await` call into its own thread and set up the `log_to_output` function to instead be something that receives channel messages so that results can be `await`ed in the background while the user can continue to execute other commands.","REPL asynchronous calls block user input and REPL drawing When using the REPL, many commands involve a command interface request that is asynchronous and immediately `await`ed for the timeout specified, or until the function is finished executing. A good example of one of these calls that takes a long time is `start provider wascc.azurecr.io/redis:v0.9.2 --timeout 30`, which takes up to 30 seconds to download, verify, auction and schedule a provider on a `wasmcloud-host` instance. When any call like this takes over 3 seconds, the REPL appears ""frozen"" as no more logs are allowed to display and no user input is recognized until after the call completes. To combat a similar issue with the host blocking operations, I've refactored the REPL host to start in its own thread and await events there. This works great to allow the host to run without blocking the REPL, but these long standing `await`ed calls are still blocking the execution of the REPL. Without exactly knowing the difficulty or code mess that may ensue (with ownership and closures) a naive solution here may be to send each `await` call into its own thread and set up the `log_to_output` function to instead be something that receives channel messages so that results can be `await`ed in the background while the user can continue to execute other commands."
464032,464032,515695,https://api.github.com/repos/the-parkers/playGround/issues/14,1.0,2021-05-11T15:37:29Z,CONTRIBUTOR,https://api.github.com/repos/the-parkers/playGround,Save Data From The Api ,Duplicate data received from the API to the database ,Save Data From The Api Duplicate data received from the API to the database 
156864,156864,174401,https://api.github.com/repos/vircadia/vircadia/issues/554,0.0,2020-07-18T19:06:44Z,COLLABORATOR,https://api.github.com/repos/vircadia/vircadia,links that open in new window show standard page,"When clicking a link that opens in a new window in the embedded browser, it does open a new window but shows the standard page rather than the page that it was supposed to open.

This happens when you click on ""Become a Patron"" on http://ctrlaltstudio.com/vircadia for example.","links that open in new window show standard page When clicking a link that opens in a new window in the embedded browser, it does open a new window but shows the standard page rather than the page that it was supposed to open. This happens when you click on ""Become a Patron"" on http://ctrlaltstudio.com/vircadia for example."
406427,406427,451756,https://api.github.com/repos/ionic-team/capacitor/issues/3990,1.0,2020-12-23T21:09:33Z,MEMBER,https://api.github.com/repos/ionic-team/capacitor,Provide default index.html when `webDir` is not found,"Most apps using Capacitor are using webpack (via Angular CLI, react-scripts, etc) or similar build system, which means the `webDir` directory is a generated asset, not typically committed to source control. Fresh checkouts that run `sync` end up with this error:

```
 npx cap sync
[error] Could not find the web assets directory: /Users/dan/git/capacitor-testapp/build.
        Please create it and make sure it has an index.html file. You can change the path of this directory in
        capacitor.config.ts (webDir option). You may need to compile the web assets for your app (typically npm run
        build).
        More info: https://capacitorjs.com/docs/v3/basics/workflow#sync-your-project
```

Additionally, the Angular CLI (and possibly others) _remove_ the webDir folder by default when using `ng serve`. This is possible because webpack-dev-server serves assets from memory, not the filesystem.

We can improve the developer experience by providing a default `index.html` for Capacitor to use during `sync`, which would get copied into the native platform resources and shown in the device with instructions for building their app and re-running `sync`. When using livereload, the default `index.html` wouldn't be seen--it would load their app from the dev server.","Provide default index.html when `webDir` is not found Most apps using Capacitor are using webpack (via Angular CLI, react-scripts, etc) or similar build system, which means the `webDir` directory is a generated asset, not typically committed to source control. Fresh checkouts that run `sync` end up with this error: ```  npx cap sync [error] Could not find the web assets directory: /Users/dan/git/capacitor-testapp/build. Please create it and make sure it has an index.html file. You can change the path of this directory in capacitor.config.ts (webDir option). You may need to compile the web assets for your app (typically npm run build). More info: https://capacitorjs.com/docs/v3/basics/workflow#sync-your-project ``` Additionally, the Angular CLI (and possibly others) _remove_ the webDir folder by default when using `ng serve`. This is possible because webpack-dev-server serves assets from memory, not the filesystem. We can improve the developer experience by providing a default `index.html` for Capacitor to use during `sync`, which would get copied into the native platform resources and shown in the device with instructions for building their app and re-running `sync`. When using livereload, the default `index.html` wouldn't be seen--it would load their app from the dev server."
53939,53939,60014,https://api.github.com/repos/microsoft/accessibility-insights-windows/issues/1122,0.0,2021-05-06T11:23:18Z,NONE,https://api.github.com/repos/microsoft/accessibility-insights-windows,[BUG] AccessibilityInsights1.1 and inspect.exe show different BoundingRectangle for notepad.exe's MenuItemControl in DPI scale mode,"Hi
My OS is Windows 10 19042.928 Home Edition.
I have 2 1080P monitors, let me name them A and B.
The rect of A is (0,0,1920,1080) and the rect of B is (1920,0,3840,1080).
A is 100% DPI and B is 150% DPI.
I run notepad.exe, put it in screen B and set notepad window maximize.
Then I use AccessibilityInsights.exe 1.1 and inspect.exe 7.2 to get Notepad controls' BoundingRectangle.
AccessibilityInsights.exe and inspect.exe show the same BoundingRectangle for notepad's EditControl,
but different BoundingRectangle for notepad's MenuItemControl.

![uiauto-notepad](https://user-images.githubusercontent.com/5846696/117288916-9868c180-ae9e-11eb-978f-c9241c5cc164.png)

For the same MenuItemControl,
AccessibilityInsights.exe gets 2117,23,2168,42.
Inspect.exe gets 2215,34,2292,63

Note that:
1920+(2117-1920) * 1.5 = 2215.5
23 * 1.5 = 34.5
1920+(2168-1920) * 1.5 = 2292
42 * 1.5 = 63
![uiauto-notepad4](https://user-images.githubusercontent.com/5846696/117288954-a6b6dd80-ae9e-11eb-9984-1d505cfbd16d.png)

Inspect can get the correct physical BoundingRectangle for the MenuItemControl and MenuBarControl while AccessibilityInsights gets logical positions.

Why AccessibilityInsights.exe and inspect.exe behave differently only for a part of Notepad's controls?

**Expected behavior**
AccessibilityInsights should behave the same as Inspect.
","[BUG] AccessibilityInsights1.1 and inspect.exe show different BoundingRectangle for notepad.exe's MenuItemControl in DPI scale mode Hi My OS is Windows 10 19042.928 Home Edition. I have 2 1080P monitors, let me name them A and B. The rect of A is (0,0,1920,1080) and the rect of B is (1920,0,3840,1080). A is 100% DPI and B is 150% DPI. I run notepad.exe, put it in screen B and set notepad window maximize. Then I use AccessibilityInsights.exe 1.1 and inspect.exe 7.2 to get Notepad controls' BoundingRectangle. AccessibilityInsights.exe and inspect.exe show the same BoundingRectangle for notepad's EditControl, but different BoundingRectangle for notepad's MenuItemControl. ![uiauto-notepad](https://user-images.githubusercontent.com/5846696/117288916-9868c180-ae9e-11eb-978f-c9241c5cc164.png) For the same MenuItemControl, AccessibilityInsights.exe gets 2117,23,2168,42. Inspect.exe gets 2215,34,2292,63 Note that: 1920+(2117-1920) * 1.5 = 2215.5 23 * 1.5 = 34.5 1920+(2168-1920) * 1.5 = 2292 42 * 1.5 = 63 ![uiauto-notepad4](https://user-images.githubusercontent.com/5846696/117288954-a6b6dd80-ae9e-11eb-9984-1d505cfbd16d.png) Inspect can get the correct physical BoundingRectangle for the MenuItemControl and MenuBarControl while AccessibilityInsights gets logical positions. Why AccessibilityInsights.exe and inspect.exe behave differently only for a part of Notepad's controls? **Expected behavior** AccessibilityInsights should behave the same as Inspect. "
249101,249101,277073,https://api.github.com/repos/FACT-Finder-Web-Components/shopware5-plugin/issues/18,1.0,2020-09-18T09:16:08Z,COLLABORATOR,https://api.github.com/repos/FACT-Finder-Web-Components/shopware5-plugin,Implement recommandation on product pages,,Implement recommandation on product pages 
442770,442770,492195,https://api.github.com/repos/Grizzelbee/ioBroker.mielecloudservice/issues/29,1.0,2020-08-24T08:54:48Z,NONE,https://api.github.com/repos/Grizzelbee/ioBroker.mielecloudservice,Ressource Data,"Hello,

is it somehow possible to get the ressource data like used water oder energy as a datapoint?

thanks
Christian","Ressource Data Hello, is it somehow possible to get the ressource data like used water oder energy as a datapoint? thanks Christian"
678308,678308,753858,https://api.github.com/repos/felixbrucker/chia-dashboard-satellite/issues/41,0.0,2021-05-14T18:58:36Z,NONE,https://api.github.com/repos/felixbrucker/chia-dashboard-satellite,Repeated ERROR in debug.log,"**Describe the bug**
Whenever I start chia on macOS I start getting the following error repeatedly one after the other, in debug.log. Otherwise, chia seems to be working fine.

**To Reproduce**
Steps to reproduce the behavior:
1. launch chia on macOS Big Sur
2. Open log under /Users/<username>/.chia/debug.log

**Expected behavior**
I assume the ERROR should not happen

**Screenshots**
Thousands of repeated errors, here's the error text:
2021-05-14T13:43:19.654 daemon __main__                   : ERROR    Unexpected exception trying to send to websocket: code = 1006 (connection closed abnormally [internal]), no reason Traceback (most recent call last):
  File ""/Users/*redacted*/chia-blockchain/venv/lib/python3.9/site-packages/websockets/protocol.py"", line 827, in transfer_data
    message = await self.read_message()
  File ""/Users/*redacted*/chia-blockchain/venv/lib/python3.9/site-packages/websockets/protocol.py"", line 895, in read_message
    frame = await self.read_data_frame(max_size=self.max_size)
  File ""/Users/*redacted*/chia-blockchain/venv/lib/python3.9/site-packages/websockets/protocol.py"", line 971, in read_data_frame
    frame = await self.read_frame(max_size)
  File ""/Users/*redacted*/chia-blockchain/venv/lib/python3.9/site-packages/websockets/protocol.py"", line 1047, in read_frame
    frame = await Frame.read(
  File ""/Users/*redacted*/chia-blockchain/venv/lib/python3.9/site-packages/websockets/framing.py"", line 105, in read
    data = await reader(2)
  File ""/usr/local/Cellar/python@3.9/3.9.5/Frameworks/Python.framework/Versions/3.9/lib/python3.9/asyncio/streams.py"", line 721, in readexactly
    raise exceptions.IncompleteReadError(incomplete, n)
asyncio.exceptions.IncompleteReadError: 0 bytes read on a total of 2 expected bytes

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""/Users/*redacted*/chia-blockchain/chia-blockchain-gui/../chia/daemon/server.py"", line 187, in safe_handle
    await socket.send(response)
  File ""/Users/*redacted*/chia-blockchain/venv/lib/python3.9/site-packages/websockets/protocol.py"", line 555, in send
    await self.ensure_open()
  File ""/Users/*redacted*/chia-blockchain/venv/lib/python3.9/site-packages/websockets/protocol.py"", line 803, in ensure_open
    raise self.connection_closed_exc()
websockets.exceptions.ConnectionClosedError: code = 1006 (connection closed abnormally [internal]), no reason

**System (please complete the following information):**
 - OS: macOS Big Sur 11.3.1
 - NodeJs Version: 16.1.0
 - Chia version: 1.6.0

**Additional context**
Chia in general seems to be working fine. Maybe I can ignore this error? This was happening with previous versions of chia and npm, this didn't begin with the latest versions. I replaced the actual user with *redacted* in the error text above.
","Repeated ERROR in debug.log **Describe the bug** Whenever I start chia on macOS I start getting the following error repeatedly one after the other, in debug.log. Otherwise, chia seems to be working fine. **To Reproduce** Steps to reproduce the behavior: 1. launch chia on macOS Big Sur 2. Open log under /Users/<username>/.chia/debug.log **Expected behavior** I assume the ERROR should not happen **Screenshots** Thousands of repeated errors, here's the error text: 2021-05-14T13:43:19.654 daemon __main__ : ERROR Unexpected exception trying to send to websocket: code = 1006 (connection closed abnormally [internal]), no reason Traceback (most recent call last): File ""/Users/*redacted*/chia-blockchain/venv/lib/python3.9/site-packages/websockets/protocol.py"", line 827, in transfer_data message = await self.read_message() File ""/Users/*redacted*/chia-blockchain/venv/lib/python3.9/site-packages/websockets/protocol.py"", line 895, in read_message frame = await self.read_data_frame(max_size=self.max_size) File ""/Users/*redacted*/chia-blockchain/venv/lib/python3.9/site-packages/websockets/protocol.py"", line 971, in read_data_frame frame = await self.read_frame(max_size) File ""/Users/*redacted*/chia-blockchain/venv/lib/python3.9/site-packages/websockets/protocol.py"", line 1047, in read_frame frame = await Frame.read( File ""/Users/*redacted*/chia-blockchain/venv/lib/python3.9/site-packages/websockets/framing.py"", line 105, in read data = await reader(2) File ""/usr/local/Cellar/python@3.9/3.9.5/Frameworks/Python.framework/Versions/3.9/lib/python3.9/asyncio/streams.py"", line 721, in readexactly raise exceptions.IncompleteReadError(incomplete, n) asyncio.exceptions.IncompleteReadError: 0 bytes read on a total of 2 expected bytes The above exception was the direct cause of the following exception: Traceback (most recent call last): File ""/Users/*redacted*/chia-blockchain/chia-blockchain-gui/../chia/daemon/server.py"", line 187, in safe_handle await socket.send(response) File ""/Users/*redacted*/chia-blockchain/venv/lib/python3.9/site-packages/websockets/protocol.py"", line 555, in send await self.ensure_open() File ""/Users/*redacted*/chia-blockchain/venv/lib/python3.9/site-packages/websockets/protocol.py"", line 803, in ensure_open raise self.connection_closed_exc() websockets.exceptions.ConnectionClosedError: code = 1006 (connection closed abnormally [internal]), no reason **System (please complete the following information):** - OS: macOS Big Sur 11.3.1 - NodeJs Version: 16.1.0 - Chia version: 1.6.0 **Additional context** Chia in general seems to be working fine. Maybe I can ignore this error? This was happening with previous versions of chia and npm, this didn't begin with the latest versions. I replaced the actual user with *redacted* in the error text above. "
84178,84178,93593,https://api.github.com/repos/0vercl0k/sic/issues/2,0.0,2021-02-14T05:35:50Z,OWNER,https://api.github.com/repos/0vercl0k/sic,Fix race in IRP_MJ_DEVICE_CONTROL,The `sic` driver has been basically designed to handle one client at a time; the accesses to the global state are not synchronized and as a result two thread could execute the `IRP_MJ_DEVICE_CONTROL` callback which would probably lead to memory corruptions of some sort.,Fix race in IRP_MJ_DEVICE_CONTROL The `sic` driver has been basically designed to handle one client at a time; the accesses to the global state are not synchronized and as a result two thread could execute the `IRP_MJ_DEVICE_CONTROL` callback which would probably lead to memory corruptions of some sort.
354002,354002,393577,https://api.github.com/repos/certbot/certbot/issues/8686,2.0,2021-02-25T02:33:06Z,NONE,https://api.github.com/repos/certbot/certbot,OSError ctypes.util.find_library() did not manage to locate a library called 'sndfile' 鹽뷸깹얍 'sndfile'竊python2.7   pip install SoundFile==0.9.0.post1 餓뜻ι竊,,OSError ctypes.util.find_library() did not manage to locate a library called 'sndfile' 鹽뷸깹얍 'sndfile'竊python2.7 pip install SoundFile==0.9.0.post1 餓뜻ι竊 
299769,299769,333296,https://api.github.com/repos/LinkedEarth/Pyleoclim_util/issues/111,1.0,2020-10-29T22:47:03Z,COLLABORATOR,https://api.github.com/repos/LinkedEarth/Pyleoclim_util,Add filter function through the UI,"**Is your feature request related to a problem? Please describe.**
Access to filtering function in pyleoclim.utils through the UI

**Describe the solution you'd like**
Add filtering methods to the Series and MultipleSeries object


",Add filter function through the UI **Is your feature request related to a problem? Please describe.** Access to filtering function in pyleoclim.utils through the UI **Describe the solution you'd like** Add filtering methods to the Series and MultipleSeries object 
88091,88091,97910,https://api.github.com/repos/opis/json-schema/issues/43,0.0,2019-07-27T14:45:51Z,NONE,https://api.github.com/repos/opis/json-schema,"Can't handle validating an object property called ""default""","If a schema of type `object` specifies a property called `default`, refs cannot be resolved.  This is present in the latest master commit (1986851).

Here's a minimal schema to demonstrate this behavior:

```json
{
  ""$schema"": ""http://json-schema.org/draft-07/schema#"",
  ""$id"": ""https://test.test/data/schema/test.json"",
  ""title"": ""Test schema"",
  ""type"": ""object"",
  ""properties"": {
    ""name"": {
      ""type"": ""string"",
      ""minLength"": 1
    },
    ""identifier"": {
      ""$ref"": ""types/identifier.json""
    },
    ""default"": {
      ""$ref"": ""types/default.json""
    }
  }
}
```

This will validate against a valid file if the `default` property's constraints are inlined.  However, with the ref, it will fail with `Opis\JsonSchema\Exception\SchemaNotFoundException : Schema 'types/default.json' was not found or could not be loaded`.

In both cases, the ref to `types/identifier.json` is resolved properly.  Changing the name of the `default` property to `is_default` works around this problem, but I'd rather not have to change the data format because of this.

I can't find anything in the JSON schema draft-07 spec that says `default` is not a valid property name, although maybe I'm missing something?","Can't handle validating an object property called ""default"" If a schema of type `object` specifies a property called `default`, refs cannot be resolved. This is present in the latest master commit (1986851). Here's a minimal schema to demonstrate this behavior: ```json { ""$schema"": ""http://json-schema.org/draft-07/schema#"", ""$id"": ""https://test.test/data/schema/test.json"", ""title"": ""Test schema"", ""type"": ""object"", ""properties"": { ""name"": { ""type"": ""string"", ""minLength"": 1 }, ""identifier"": { ""$ref"": ""types/identifier.json"" }, ""default"": { ""$ref"": ""types/default.json"" } } } ``` This will validate against a valid file if the `default` property's constraints are inlined. However, with the ref, it will fail with `Opis\JsonSchema\Exception\SchemaNotFoundException : Schema 'types/default.json' was not found or could not be loaded`. In both cases, the ref to `types/identifier.json` is resolved properly. Changing the name of the `default` property to `is_default` works around this problem, but I'd rather not have to change the data format because of this. I can't find anything in the JSON schema draft-07 spec that says `default` is not a valid property name, although maybe I'm missing something?"
123701,123701,137462,https://api.github.com/repos/Kozaky/RK-Front/issues/39,0.0,2020-06-26T18:37:58Z,OWNER,https://api.github.com/repos/Kozaky/RK-Front,Images Do Not Fit,"Some images do not fit right in the carousel when creating Reklamas:

![Screenshot 2020-06-26 at 20 36 42](https://user-images.githubusercontent.com/19823300/85890020-d7dd7080-b7ec-11ea-94b2-d6b99cbe010d.png)
 ",Images Do Not Fit Some images do not fit right in the carousel when creating Reklamas: ![Screenshot 2020-06-26 at 20 36 42](https://user-images.githubusercontent.com/19823300/85890020-d7dd7080-b7ec-11ea-94b2-d6b99cbe010d.png) 
135246,135246,150335,https://api.github.com/repos/benawad/dogehouse/issues/2315,0.0,2021-04-25T17:12:40Z,COLLABORATOR,https://api.github.com/repos/benawad/dogehouse,the leave button overflows,"![Screenshot_20210425-221054](https://user-images.githubusercontent.com/38838675/116002472-51afd780-a613-11eb-8701-114de247456a.png)
",the leave button overflows ![Screenshot_20210425-221054](https://user-images.githubusercontent.com/38838675/116002472-51afd780-a613-11eb-8701-114de247456a.png) 
460173,460173,511429,https://api.github.com/repos/HarshCasper/Rotten-Scripts/issues/576,1.0,2020-12-06T18:07:27Z,CONTRIBUTOR,https://api.github.com/repos/HarshCasper/Rotten-Scripts,A trained model for Music Genre Classification,"**Is your feature request related to a problem? Please describe.**
A pre-trained model for music genre classification is not tough to find. A good model for music genre classification is like a needle in haystack.

**Describe the solution you'd like**
After working on Music classification for more than a year, I believe I can come up with a really good model. I will be using  Benchmark dataset, `GTZAN`, `Emotify` for example, Python offers TF, Keras and most importantly  `pyaudioanalysis` so i think Python is the best choice.

**Describe alternatives you've considered**
There are multiple models available, but either they are now old, they are using old algos like `SVM`, or old variants of Neighbours. 

**Additional context**
","A trained model for Music Genre Classification **Is your feature request related to a problem? Please describe.** A pre-trained model for music genre classification is not tough to find. A good model for music genre classification is like a needle in haystack. **Describe the solution you'd like** After working on Music classification for more than a year, I believe I can come up with a really good model. I will be using Benchmark dataset, `GTZAN`, `Emotify` for example, Python offers TF, Keras and most importantly `pyaudioanalysis` so i think Python is the best choice. **Describe alternatives you've considered** There are multiple models available, but either they are now old, they are using old algos like `SVM`, or old variants of Neighbours. **Additional context** "
686009,686009,762416,https://api.github.com/repos/ECE493W2021T3/eVoter/issues/34,1.0,2021-03-18T00:34:56Z,CONTRIBUTOR,https://api.github.com/repos/ECE493W2021T3/eVoter,Setup Routing and Database service,"[//]: # (These are comments and are used for reference and will not show up in the issue)

**Description:**
Routing and Database service should respond to Frontend requests. This issue should stay open until the end of the project to keep update with new requests.

[//]: # (A clear and concise description of what you want to happen.)
Service shall evolve with different stages:
- Fake Data works only as one place holder
- MongoDB
- MongoDB + Blockchain

**Related Issues or Functional Requirement(s):**

[//]: # (Ex. #<issue id>. Moreover, please add the appropriate FR label.)
All issues related with Database, redirecting pages. Since this is one very low level issue, related issues are not listed.

**Related WBS Block Number(s):**

[//]: # (Ex. [1.1], [1.2], etc.)
Same as above.

**Additional context:**

[//]: # (Add any other context or screenshots about the feature request here.)
This issue only includes BlockchainDB as one service, detailed implementation of BlockchainDB should be covered in other issues.
This service aims to provide service to Frontend without interruption through transitions from Fake Data to MongoDB and from MongoDB to MongoDB+Blockchain.
","Setup Routing and Database service [//]: # (These are comments and are used for reference and will not show up in the issue) **Description:** Routing and Database service should respond to Frontend requests. This issue should stay open until the end of the project to keep update with new requests. [//]: # (A clear and concise description of what you want to happen.) Service shall evolve with different stages: - Fake Data works only as one place holder - MongoDB - MongoDB + Blockchain **Related Issues or Functional Requirement(s):** [//]: # (Ex. #<issue id>. Moreover, please add the appropriate FR label.) All issues related with Database, redirecting pages. Since this is one very low level issue, related issues are not listed. **Related WBS Block Number(s):** [//]: # (Ex. [1.1], [1.2], etc.) Same as above. **Additional context:** [//]: # (Add any other context or screenshots about the feature request here.) This issue only includes BlockchainDB as one service, detailed implementation of BlockchainDB should be covered in other issues. This service aims to provide service to Frontend without interruption through transitions from Fake Data to MongoDB and from MongoDB to MongoDB+Blockchain. "
758924,758924,358511,https://api.github.com/repos/GraciaMoulisKevin/Thovin/issues/48,1.0,2021-04-30T13:31:25Z,COLLABORATOR,https://api.github.com/repos/GraciaMoulisKevin/Thovin,Add margin top on deliverer status parameters,"Step to reproduce:
1. Log as deliverer
2. Go on parameters
3. Open status parameters

Here a marge in top is needed",Add margin top on deliverer status parameters Step to reproduce: 1. Log as deliverer 2. Go on parameters 3. Open status parameters Here a marge in top is needed
576169,576169,640286,https://api.github.com/repos/Sekooly/SUPABASE/issues/98,0.0,2021-05-18T07:37:22Z,OWNER,https://api.github.com/repos/Sekooly/SUPABASE,All챕ger les get_resultat,"Tous les appels api doivent utiliser:
- la pagination (limit 10, offset 10)
- le cache (d챔s qu'on a un r챕sultat, on met en cache)","All챕ger les get_resultat Tous les appels api doivent utiliser: - la pagination (limit 10, offset 10) - le cache (d챔s qu'on a un r챕sultat, on met en cache)"
409533,409533,455200,https://api.github.com/repos/libsdl-org/SDL/issues/748,0.0,2021-02-10T22:45:18Z,COLLABORATOR,https://api.github.com/repos/libsdl-org/SDL,SDL2 freeze when render video with directx9 in win7,"
# This bug report was migrated from our old Bugzilla tracker.

**Reported in version:** HG 2.0
**Reported for operating system, platform:** Windows 7, x86

# Comments on the original bug report:

On 2013-01-30 01:51:47 +0000, Rex Lu wrote:

> when i play an video with sdl2, it played the video normally in serveral seconds. But then the video freeze and block forerver.
> I debug in the SDL2 function, i found that when D3D_RenderPresent calling IDirect3DDevice9_Present, sdl2 block and never return back.
> I have installed the directX 9 Sdk(June 2010)

On 2013-02-02 06:42:20 +0000, Philipp Wiesemann wrote:

> Similar and more to bug bug # 1705.

On 2013-04-23 16:07:31 +0000, Gabriel Jacobo wrote:

> 
> 
> *** This bug has been marked as a duplicate of bug 1705 ***

","SDL2 freeze when render video with directx9 in win7 # This bug report was migrated from our old Bugzilla tracker. **Reported in version:** HG 2.0 **Reported for operating system, platform:** Windows 7, x86 # Comments on the original bug report: On 2013-01-30 01:51:47 +0000, Rex Lu wrote: > when i play an video with sdl2, it played the video normally in serveral seconds. But then the video freeze and block forerver. > I debug in the SDL2 function, i found that when D3D_RenderPresent calling IDirect3DDevice9_Present, sdl2 block and never return back. > I have installed the directX 9 Sdk(June 2010) On 2013-02-02 06:42:20 +0000, Philipp Wiesemann wrote: > Similar and more to bug bug # 1705. On 2013-04-23 16:07:31 +0000, Gabriel Jacobo wrote: > > > *** This bug has been marked as a duplicate of bug 1705 *** "
260091,260091,289264,https://api.github.com/repos/porter-dev/porter/issues/242,1.0,2021-01-22T19:26:25Z,COLLABORATOR,https://api.github.com/repos/porter-dev/porter,make aws + gcp provisioning regions selectable via dropdown,,make aws + gcp provisioning regions selectable via dropdown 
391818,391818,435511,https://api.github.com/repos/acien/acien.github.io/issues/1,1.0,2021-04-12T23:35:00Z,OWNER,https://api.github.com/repos/acien/acien.github.io,Fix Search,Make search get results when you hit enter.,Fix Search Make search get results when you hit enter.
555891,555891,617784,https://api.github.com/repos/CoinAlpha/hummingbot/issues/2596,0.0,2020-11-10T13:50:01Z,NONE,https://api.github.com/repos/CoinAlpha/hummingbot,[BUG] hanging orders remain on the book after a derivatives position is closed,"**Describe the bug**
In the current implementation of Binance perpetual connector, when using One-Way position mode, the hanging orders remain open on both sides even after the position is closed. Since there is no inventory to skew/manage in derivatives, all the hanging orders should be closed as soon as the position is closed or there should be a way to actively manage them when a position is open.

**Steps To Reproduce**
This works in any configuration as long as One-Way (Non hedge) mode is enabled and hanging orders are in use.

**Release version**
dev-0.33.0","[BUG] hanging orders remain on the book after a derivatives position is closed **Describe the bug** In the current implementation of Binance perpetual connector, when using One-Way position mode, the hanging orders remain open on both sides even after the position is closed. Since there is no inventory to skew/manage in derivatives, all the hanging orders should be closed as soon as the position is closed or there should be a way to actively manage them when a position is open. **Steps To Reproduce** This works in any configuration as long as One-Way (Non hedge) mode is enabled and hanging orders are in use. **Release version** dev-0.33.0"
358361,358361,398394,https://api.github.com/repos/airctic/icevision/issues/809,0.0,2021-04-21T06:56:20Z,NONE,https://api.github.com/repos/airctic/icevision,Some traces of cv2 remain,"##  Bug
In 0.7.0 cv2 has been removed yet a couple of traces remain https://github.com/airctic/icevision/search?q=cv2

This may cause import errors",Some traces of cv2 remain ##  Bug In 0.7.0 cv2 has been removed yet a couple of traces remain https://github.com/airctic/icevision/search?q=cv2 This may cause import errors
474588,474588,527444,https://api.github.com/repos/department-of-veterans-affairs/va.gov-team/issues/22150,0.0,2021-03-25T15:50:01Z,COLLABORATOR,https://api.github.com/repos/department-of-veterans-affairs/va.gov-team,Liquid Template Unit Tester - There appears to be a bug when creating a filename for the saved html file,"## Issue Description
There appears to be a bug when creating the `html` filename from the given `liquid` template path. This was reported by Michael Pelz-Sherman:

Michael Pelz-Sherman  2:04 PM
The name of the file is coming out as just `number.html`. It would be great if it used the name of the test or something instead, sorta like how jest does snapshots.

Holden Hinkle  3:11 PM
Looking at your code, the `html` file should be called `phone-number.html` Its being saved as `number.html`? If so, thats a bug

I spoke with Michael. In addition to fixing this bug, we want to add a string that represents a fixture's name after the liquid template name to the `html` filename. This value will be passed in as an argument to `renderHTML()`.

Example:
Given the `liquid` file path: `src/site/layouts/health_care_region_page.drupal.liquid`

And a string representing a fixture: `noLabelLocationName`

The resulting `html` filename will be:
`health_care_region.noLabelLocationName.html`

---
## Tasks
- [x] Fix bug when generating html file name
- [x] Allow dev to optionally pass in a string representing the fixture name

## Acceptance Criteria
- [x] Correct html filename will be created when no optional 'fixture name' string is passed in
- [x] Correct html filename will be created when optional 'fixture name' string is passed in
","Liquid Template Unit Tester - There appears to be a bug when creating a filename for the saved html file ## Issue Description There appears to be a bug when creating the `html` filename from the given `liquid` template path. This was reported by Michael Pelz-Sherman: Michael Pelz-Sherman 2:04 PM The name of the file is coming out as just `number.html`. It would be great if it used the name of the test or something instead, sorta like how jest does snapshots. Holden Hinkle 3:11 PM Looking at your code, the `html` file should be called `phone-number.html` Its being saved as `number.html`? If so, thats a bug I spoke with Michael. In addition to fixing this bug, we want to add a string that represents a fixture's name after the liquid template name to the `html` filename. This value will be passed in as an argument to `renderHTML()`. Example: Given the `liquid` file path: `src/site/layouts/health_care_region_page.drupal.liquid` And a string representing a fixture: `noLabelLocationName` The resulting `html` filename will be: `health_care_region.noLabelLocationName.html` --- ## Tasks - [x] Fix bug when generating html file name - [x] Allow dev to optionally pass in a string representing the fixture name ## Acceptance Criteria - [x] Correct html filename will be created when no optional 'fixture name' string is passed in - [x] Correct html filename will be created when optional 'fixture name' string is passed in "
713217,713217,792659,https://api.github.com/repos/pnsn/squacapi/issues/156,1.0,2020-09-15T23:51:35Z,CONTRIBUTOR,https://api.github.com/repos/pnsn/squacapi,"Add alarms class, serializers and views","class Alarms
channel_group_id (fk to channel_group)
user_id (fk to user)
interval_type varchar (hour/day)
interval_count (int) 
","Add alarms class, serializers and views class Alarms channel_group_id (fk to channel_group) user_id (fk to user) interval_type varchar (hour/day) interval_count (int) "
26155,26155,29144,https://api.github.com/repos/antvis/G6/issues/2876,0.0,2021-05-06T06:47:39Z,NONE,https://api.github.com/repos/antvis/G6,"detectDirectedCycle,detectAllCycles is not a function","- [ ] I have searched the [issues](https://github.com/antvis/g6/issues) of this repository and believe that this is not a duplicate.

### Reproduction link
[![Edit on CodeSandbox](https://codesandbox.io/static/img/play-codesandbox.svg)](https://codesandbox.io/s/loving-yalow-mwneu?file=/index.js)

### Steps to reproduce
凉detectDirectedCycle竊detectAllCycles 嶸力㎩뜹경ι

| Environment | Info |
|---|---|
| g6 | 4.2.7 |
| System | - |
| Browser | - |


<!-- generated by antv-issue-helper. DO NOT REMOVE -->","detectDirectedCycle,detectAllCycles is not a function - [ ] I have searched the [issues](https://github.com/antvis/g6/issues) of this repository and believe that this is not a duplicate. ### Reproduction link [![Edit on CodeSandbox](https://codesandbox.io/static/img/play-codesandbox.svg)](https://codesandbox.io/s/loving-yalow-mwneu?file=/index.js) ### Steps to reproduce 凉detectDirectedCycle竊detectAllCycles 嶸力㎩뜹경ι | Environment | Info | |---|---| | g6 | 4.2.7 | | System | - | | Browser | - | <!-- generated by antv-issue-helper. DO NOT REMOVE -->"
150143,150143,166901,https://api.github.com/repos/Naereen/notebooks/issues/21,2.0,2018-12-12T12:33:32Z,OWNER,https://api.github.com/repos/Naereen/notebooks,"A Python notebook showing a prototype of French keyboard supporting ""inclusive writing""","I was discussing with a friend, and realized that I started a few months ago to write, *as much as possible*, my French text messages using an [inclusive writing](https://www.ecriture-inclusive.fr/). For example:

> Tu vas voir tes amis ?  Tu vas voir tes ami-e-s ?

Ideally, I would like my keyboard to suggest me words like this.
But I'm not an Android programmer, and I don't have time to learn this (right now).
So instead, I want to write a Python notebook to showcase the following feature:

- If the keyboard suggests a word, like ""amis"" above, automatically decide if it's a name that should/could be written in an inclusive form,
- And for words that can have inclusive form, automatically compute it : ""amis""  ""ami-e-s"".

Warning: there is so many exceptions, like ""chevaux"" is ""cheval"" at plurals, but feminine is ""jument"" so instead of ""chevaux-ales"" you write ""chevaux/juments"". Quite hard to be perfect in an automated way.","A Python notebook showing a prototype of French keyboard supporting ""inclusive writing"" I was discussing with a friend, and realized that I started a few months ago to write, *as much as possible*, my French text messages using an [inclusive writing](https://www.ecriture-inclusive.fr/). For example: > Tu vas voir tes amis ?  Tu vas voir tes ami-e-s ? Ideally, I would like my keyboard to suggest me words like this. But I'm not an Android programmer, and I don't have time to learn this (right now). So instead, I want to write a Python notebook to showcase the following feature: - If the keyboard suggests a word, like ""amis"" above, automatically decide if it's a name that should/could be written in an inclusive form, - And for words that can have inclusive form, automatically compute it : ""amis""  ""ami-e-s"". Warning: there is so many exceptions, like ""chevaux"" is ""cheval"" at plurals, but feminine is ""jument"" so instead of ""chevaux-ales"" you write ""chevaux/juments"". Quite hard to be perfect in an automated way."
422195,422195,469296,https://api.github.com/repos/zephyrproject-rtos/zephyr/issues/17571,1.0,2019-07-16T13:22:01Z,COLLABORATOR,https://api.github.com/repos/zephyrproject-rtos/zephyr,mempool is expensive for cyclic use,"**Is your enhancement proposal related to a problem? Please describe.**
There is one issue with Zephyr heap allocator which we will be fighting soon. If you application is iteratively allocating and deallocating multiple small chunks of data the process of breaking and recombining blocks is REALLY expensive. 
E.g.
```
/* heap is free - no allocations */
while (true) {
   /* wait for signal */
   chunk = k_malloc(16); /* makes heap break down through all levels to give this chunk */
   process_chunk(chunk); /* simplified processing - you can imagine N events created at this moment that will be freed before cycle ends */
   free(chunk); /* makes heap recombine itself up to the top */
   /* no allocations on heap at this moment */
}
```


My understanding is that the idea behind implementing it this way was to avoid fragmenation. It could be a problem if some chunks are allocated for long periods of time. However I would expect something like that in a PC application not in embedded where all long-lived buffers and data are statically allocated in RAM.
The real problem is however that for iterative allocating of data (e.g. on upcoming event) Zephyr has to break down entire heap before giving the chunk. Later when event is served it will recombine the heap back leading to drastic waste of CPU time.

**Describe the solution you'd like**
Have a possibility to disable block recombination unless explicitly needed.

**Describe alternatives you've considered**
One can grab a small chunk of memory and never release it. This way you can force some blocks to remain broken and ready for allocation.

**Additional context**
N/A
",mempool is expensive for cyclic use **Is your enhancement proposal related to a problem? Please describe.** There is one issue with Zephyr heap allocator which we will be fighting soon. If you application is iteratively allocating and deallocating multiple small chunks of data the process of breaking and recombining blocks is REALLY expensive. E.g. ``` /* heap is free - no allocations */ while (true) { /* wait for signal */ chunk = k_malloc(16); /* makes heap break down through all levels to give this chunk */ process_chunk(chunk); /* simplified processing - you can imagine N events created at this moment that will be freed before cycle ends */ free(chunk); /* makes heap recombine itself up to the top */ /* no allocations on heap at this moment */ } ``` My understanding is that the idea behind implementing it this way was to avoid fragmenation. It could be a problem if some chunks are allocated for long periods of time. However I would expect something like that in a PC application not in embedded where all long-lived buffers and data are statically allocated in RAM. The real problem is however that for iterative allocating of data (e.g. on upcoming event) Zephyr has to break down entire heap before giving the chunk. Later when event is served it will recombine the heap back leading to drastic waste of CPU time. **Describe the solution you'd like** Have a possibility to disable block recombination unless explicitly needed. **Describe alternatives you've considered** One can grab a small chunk of memory and never release it. This way you can force some blocks to remain broken and ready for allocation. **Additional context** N/A 
229014,229014,254677,https://api.github.com/repos/Ylianst/MeshCentral/issues/2149,2.0,2021-01-08T03:18:25Z,NONE,https://api.github.com/repos/Ylianst/MeshCentral,login page does not load,"Hosted on my own server, auto-update is enabled.
I can SSH in.
Was on v 0.7.39, did a manual upgrade to 0.7.44

Still no luck getting the login page to load","login page does not load Hosted on my own server, auto-update is enabled. I can SSH in. Was on v 0.7.39, did a manual upgrade to 0.7.44 Still no luck getting the login page to load"
13131,13131,14627,https://api.github.com/repos/Kentsuuu93/kokija.tiko2020.trade/issues/20,0.0,2021-01-30T22:04:53Z,COLLABORATOR,https://api.github.com/repos/Kentsuuu93/kokija.tiko2020.trade,Yhteystiedot eiv채t asetu pystysuunnassa asianmukaisesti,"Yhteystiedot n채ht채v채sti pyrkii keskittym채채n samalla grid-rivill채 olevan kappaleen kanssa. T채m채 n채kyy erityisen hyvin kapeassa n채kym채ss채
![screenshot](https://i.imgur.com/f1Oeg3S.png)
Tarkoituksena oli saada yhteystiedot asettumaan omassa grid-osiossaan j채rkev채sti alkamaan suoraan otsikon j채lkeen. Yritin t채t채 korjata, mutta en meinannut l철yt채채 CSS-s채채nt철채, joka t채m채n korjaisi.","Yhteystiedot eiv채t asetu pystysuunnassa asianmukaisesti Yhteystiedot n채ht채v채sti pyrkii keskittym채채n samalla grid-rivill채 olevan kappaleen kanssa. T채m채 n채kyy erityisen hyvin kapeassa n채kym채ss채 ![screenshot](https://i.imgur.com/f1Oeg3S.png) Tarkoituksena oli saada yhteystiedot asettumaan omassa grid-osiossaan j채rkev채sti alkamaan suoraan otsikon j채lkeen. Yritin t채t채 korjata, mutta en meinannut l철yt채채 CSS-s채채nt철채, joka t채m채n korjaisi."
658710,658710,732178,https://api.github.com/repos/ncavasin/paw/issues/10,1.0,2021-05-21T00:08:37Z,OWNER,https://api.github.com/repos/ncavasin/paw,ALL - Agregar un div en display:none para notificar debajo del <header>,,ALL - Agregar un div en display:none para notificar debajo del <header> 
240224,240224,267193,https://api.github.com/repos/TomokiMiyauci/fonction/issues/18,1.0,2021-04-28T15:07:41Z,OWNER,https://api.github.com/repos/TomokiMiyauci/fonction,I want to test function interface,,I want to test function interface 
466965,466965,518981,https://api.github.com/repos/pythongssapi/requests-gssapi/issues/2,1.0,2017-11-22T22:09:19Z,MEMBER,https://api.github.com/repos/pythongssapi/requests-gssapi,Implement multilegged auth draft,"There's a proposed HTTP extension for supporting SPNEGO auth with more than one round trip in HTTPS: https://github.com/MikeBishop/http-misc-extensions/blob/master/draft-montenegro-httpauth-multilegged-auth.md

We should think about implementing this.,","Implement multilegged auth draft There's a proposed HTTP extension for supporting SPNEGO auth with more than one round trip in HTTPS: https://github.com/MikeBishop/http-misc-extensions/blob/master/draft-montenegro-httpauth-multilegged-auth.md We should think about implementing this.,"
286533,286533,318645,https://api.github.com/repos/axelekwall/axelekwall/issues/48,1.0,2021-04-15T14:22:58Z,OWNER,https://api.github.com/repos/axelekwall/axelekwall,Optimize image loading,To get better performance and make use of the next/image features that are available the sizes of images should be better declared.,Optimize image loading To get better performance and make use of the next/image features that are available the sizes of images should be better declared.
724392,724392,14598,https://api.github.com/repos/colorlessenergy/placeholder-image/issues/5,1.0,2021-01-31T17:54:27Z,OWNER,https://api.github.com/repos/colorlessenergy/placeholder-image,add a button to download the canvas as an image,,add a button to download the canvas as an image 
529760,529760,588810,https://api.github.com/repos/ifrn-pdcorp/sea/issues/61,1.0,2020-12-29T13:38:01Z,COLLABORATOR,https://api.github.com/repos/ifrn-pdcorp/sea,[FRONT] - Cria챌찾o das notifica챌천es no formul찼rio de Evento,Nessa issue deve ser implementada as notifica챌천es no formul찼rio de Evento.,[FRONT] - Cria챌찾o das notifica챌천es no formul찼rio de Evento Nessa issue deve ser implementada as notifica챌천es no formul찼rio de Evento.
138112,138112,153523,https://api.github.com/repos/nuxt/vite/issues/33,0.0,2021-02-27T12:30:21Z,NONE,https://api.github.com/repos/nuxt/vite,typescript broken with plugin,"### Version
nuxt-vite: 0.0.8
nuxt: 2.15.2

### Configuration

```js
buildModules: [
    [
      'nuxt-vite',
      '@nuxt/typescript-build',
      {
        typeCheck: {
          typescript: {
            memoryLimit: 8000,
            extensions: {
              vue: true,
            },
          },
        },
      },
    ],
    'nuxt-typed-vuex',
  ],
```

### Description

The error happens in file where I import @nuxt/types like import { Plugin } from '@nuxt/types';
","typescript broken with plugin ### Version nuxt-vite: 0.0.8 nuxt: 2.15.2 ### Configuration ```js buildModules: [ [ 'nuxt-vite', '@nuxt/typescript-build', { typeCheck: { typescript: { memoryLimit: 8000, extensions: { vue: true, }, }, }, }, ], 'nuxt-typed-vuex', ], ``` ### Description The error happens in file where I import @nuxt/types like import { Plugin } from '@nuxt/types'; "
47230,47230,52570,https://api.github.com/repos/VGavara/ArduinoTB6612FNG/issues/12,0.0,2021-01-28T11:08:12Z,OWNER,https://api.github.com/repos/VGavara/ArduinoTB6612FNG,Spinner must properly handle speed equal to zero,"Now a `SpinPoint.speed` equal to zero in a `SpinMap` means stating an invalid speed value to the `Motor` class, since `Motor` rejects this value.

The `Spinner` class must be upgraded to stop the motor when a speed equal to zero is reached. The documentation must be properly upgraded.","Spinner must properly handle speed equal to zero Now a `SpinPoint.speed` equal to zero in a `SpinMap` means stating an invalid speed value to the `Motor` class, since `Motor` rejects this value. The `Spinner` class must be upgraded to stop the motor when a speed equal to zero is reached. The documentation must be properly upgraded."
766325,766325,432579,https://api.github.com/repos/desh2608/spyder/issues/2,1.0,2021-03-07T17:33:52Z,OWNER,https://api.github.com/repos/desh2608/spyder,Output formatting,"* Currently the CLI output is not formatted well, especially with the `--per-file` option. Improve this using [tabulate](https://github.com/astanin/python-tabulate) package.
* Display absolute error times (like md-eval)","Output formatting * Currently the CLI output is not formatted well, especially with the `--per-file` option. Improve this using [tabulate](https://github.com/astanin/python-tabulate) package. * Display absolute error times (like md-eval)"
33144,33144,36933,https://api.github.com/repos/pi19v-group-dynamics/Poke-n-Conquer/issues/14,1.0,2021-03-18T21:25:54Z,COLLABORATOR,https://api.github.com/repos/pi19v-group-dynamics/Poke-n-Conquer,叫剋龜 spritebatching,"### 棘閨剋筠劇逵
龜 龜棘勻逵戟龜龜 均極極 極逵橘棘勻 筠筠鈞 `ren_flush` 勻筠 龜筠劇筠 龜鈞棘閨逵菌筠戟龜 畇棘剋菌戟 龜劇筠 棘畇戟 龜  菌筠 勻龜畇龜劇 棘閨剋逵, 棘 棘筠戟 棘均逵戟龜龜勻逵筠 勻棘鈞劇棘菌戟棘龜 逵克棘均棘 劇筠棘畇逵 龜棘勻逵戟龜.
逵菌畇橘 `ren_batch_t` 棘鈞剋逵筠 棘剋克棘 畇龜戟逵劇龜筠克龜, 棘均棘 劇棘菌戟棘 龜鈞閨筠菌逵.

### 筠筠戟龜筠
棘閨逵勻龜 勻棘劇棘菌戟棘 畇棘閨逵勻剋 勻劇筠筠  極棘鈞龜筠橘 龜鈞棘閨逵菌筠戟龜 筠 勻龜畇龜劇 棘閨剋逵.
鈞閨逵勻龜 棘 勻畇筠剋筠戟龜 極逵劇龜 極棘畇 克逵菌畇橘 克鈞筠劇極剋  `ren_batch_t`.","叫剋龜 spritebatching ### 棘閨剋筠劇逵 龜 龜棘勻逵戟龜龜 均極極 極逵橘棘勻 筠筠鈞 `ren_flush` 勻筠 龜筠劇筠 龜鈞棘閨逵菌筠戟龜 畇棘剋菌戟 龜劇筠 棘畇戟 龜  菌筠 勻龜畇龜劇 棘閨剋逵, 棘 棘筠戟 棘均逵戟龜龜勻逵筠 勻棘鈞劇棘菌戟棘龜 逵克棘均棘 劇筠棘畇逵 龜棘勻逵戟龜. 逵菌畇橘 `ren_batch_t` 棘鈞剋逵筠 棘剋克棘 畇龜戟逵劇龜筠克龜, 棘均棘 劇棘菌戟棘 龜鈞閨筠菌逵. ### 筠筠戟龜筠 棘閨逵勻龜 勻棘劇棘菌戟棘 畇棘閨逵勻剋 勻劇筠筠  極棘鈞龜筠橘 龜鈞棘閨逵菌筠戟龜 筠 勻龜畇龜劇 棘閨剋逵. 鈞閨逵勻龜 棘 勻畇筠剋筠戟龜 極逵劇龜 極棘畇 克逵菌畇橘 克鈞筠劇極剋 `ren_batch_t`."
281978,281978,313588,https://api.github.com/repos/anas-didi95/rn-image-scanner/issues/3,1.0,2021-02-22T12:51:39Z,OWNER,https://api.github.com/repos/anas-didi95/rn-image-scanner,Configure env variable,,Configure env variable 
292575,292575,325349,https://api.github.com/repos/Informatievlaanderen/GIPOD/issues/123,2.0,2020-09-26T13:16:46Z,NONE,https://api.github.com/repos/Informatievlaanderen/GIPOD,"Ontbrekend ""consequence"" op zone gerefereerd door GrondwerkZone","
TL;DR: Bug of feature request... er ontbreekt logisch gezien een ""consequence"" op de zone (direct) gerefereerd door GrondwerkZone.

Voor de hinderpremie ben ik alleen geinteresseerd in het uitlezen van gegevens, niet in het opladen in GIPOD.

Voor een eerste fase wil ik ongeveer een zelfde extract halen uit GIPOD2 als nu uit de huidige GIPOD. Ik ben geinteresseerd in GrondwerkZones met duur van meer dan 30 dagen, eerste categorie, status concreet gepland/in uitvoering, locaties: alles op de weg.

In de huidige GIPOD vragen we een lijst van (laatste) veranderingen in werkopdrachten en we krijgen een blok informatie (met status, duur, categorie en locatie) terug per veranderde opdracht, elk met 1 gipodid.

In GIPOD2 zitten HinderZones extra in, maar die heb ik in eerste fase eigenlijk niet nodig. Dus ik vraag alle laatste veranderingen in ""public domain occupancies"" op, ik kan duration ervan berekenen (start en stop zijn ingevuld, duration blijkbaar niet) en selecteren op de status en category ervan. Nu, voor ""locations"" (of wat dat vervangt), zou ik over ""hasConsequence"" moeten gaan naar MobileHindrance, en daar ""consequence"" nemen op de MobileHindranceZone ervan.
Dan heb ik wel de ""consequence"" van de MobileHindranceZone, maar eigenlijk niet de ""consequence"" van de GrondwerkZone. Ik kan me inbeelden dat er een verschillend gevolg/consequence is van een inname als van de bijbehorende hinderzone: de inname zelf is bv helemaal afgesloten terwijl de rest van de straat hinder heeft maar niet afgesloten is.

Het zou logischer zijn om ook een consequence te hangen aan de zone direct gerefereerd in de GrondwerkZone (en bij uitbreiding bij alle public domain occupancies). Het zou ook het aantal REST calls verminderen.

---

Het linken over MobileHindrances geeft nog wat andere problemen... wat als er meerdere MobileHindrances zijn per PublicDomainOccupancy, en/of meerdere zones voor een 1 HinderZone. Welke consequence is van toepassing voor zo'n Public Occupancy.
Als ik alle veranderingen wil capteren moet ik waarschijnlijk ook nog de lijst opvragen van veranderde MobileHindrances, en dan gaan kijken naar de PublicDomainOccupancies waar ze een gevolg van zijn. omdat MobileHindrances kunnen veranderen zonder dat de PublicDomainOccupancy ervan verandert: iemand die bv enkel de consequence van een MobileHindrance aanpast. 
","Ontbrekend ""consequence"" op zone gerefereerd door GrondwerkZone TL;DR: Bug of feature request... er ontbreekt logisch gezien een ""consequence"" op de zone (direct) gerefereerd door GrondwerkZone. Voor de hinderpremie ben ik alleen geinteresseerd in het uitlezen van gegevens, niet in het opladen in GIPOD. Voor een eerste fase wil ik ongeveer een zelfde extract halen uit GIPOD2 als nu uit de huidige GIPOD. Ik ben geinteresseerd in GrondwerkZones met duur van meer dan 30 dagen, eerste categorie, status concreet gepland/in uitvoering, locaties: alles op de weg. In de huidige GIPOD vragen we een lijst van (laatste) veranderingen in werkopdrachten en we krijgen een blok informatie (met status, duur, categorie en locatie) terug per veranderde opdracht, elk met 1 gipodid. In GIPOD2 zitten HinderZones extra in, maar die heb ik in eerste fase eigenlijk niet nodig. Dus ik vraag alle laatste veranderingen in ""public domain occupancies"" op, ik kan duration ervan berekenen (start en stop zijn ingevuld, duration blijkbaar niet) en selecteren op de status en category ervan. Nu, voor ""locations"" (of wat dat vervangt), zou ik over ""hasConsequence"" moeten gaan naar MobileHindrance, en daar ""consequence"" nemen op de MobileHindranceZone ervan. Dan heb ik wel de ""consequence"" van de MobileHindranceZone, maar eigenlijk niet de ""consequence"" van de GrondwerkZone. Ik kan me inbeelden dat er een verschillend gevolg/consequence is van een inname als van de bijbehorende hinderzone: de inname zelf is bv helemaal afgesloten terwijl de rest van de straat hinder heeft maar niet afgesloten is. Het zou logischer zijn om ook een consequence te hangen aan de zone direct gerefereerd in de GrondwerkZone (en bij uitbreiding bij alle public domain occupancies). Het zou ook het aantal REST calls verminderen. --- Het linken over MobileHindrances geeft nog wat andere problemen... wat als er meerdere MobileHindrances zijn per PublicDomainOccupancy, en/of meerdere zones voor een 1 HinderZone. Welke consequence is van toepassing voor zo'n Public Occupancy. Als ik alle veranderingen wil capteren moet ik waarschijnlijk ook nog de lijst opvragen van veranderde MobileHindrances, en dan gaan kijken naar de PublicDomainOccupancies waar ze een gevolg van zijn. omdat MobileHindrances kunnen veranderen zonder dat de PublicDomainOccupancy ervan verandert: iemand die bv enkel de consequence van een MobileHindrance aanpast. "
136616,136616,151855,https://api.github.com/repos/travispamaral/travisamaral.com/issues/5,0.0,2021-02-07T22:25:46Z,OWNER,https://api.github.com/repos/travispamaral/travisamaral.com,Copy change request | travis.amaral@shopify.com,"From: travis.amaral@shopify.com
Relevant URLs
http://google.com",Copy change request | travis.amaral@shopify.com From: travis.amaral@shopify.com Relevant URLs http://google.com
182254,182254,202601,https://api.github.com/repos/YigtyORG/TakymLib/issues/19,1.0,2021-05-26T15:17:44Z,MEMBER,https://api.github.com/repos/YigtyORG/TakymLib,GitHub Wiki  docs ｃсゃャ듐㏂멥γ쇈ャⓦ瓦썲,#5 ラｃ,GitHub Wiki  docs ｃсゃャ듐㏂멥γ쇈ャⓦ瓦썲 #5 ラｃ
627455,627455,697304,https://api.github.com/repos/ichiro-its/housou/issues/11,1.0,2021-04-08T07:46:11Z,CONTRIBUTOR,https://api.github.com/repos/ichiro-its/housou,Add Support to Filter Address,"Add support to enable/disable communication to broadcast address, and add support to use custom addresses during communication.","Add Support to Filter Address Add support to enable/disable communication to broadcast address, and add support to use custom addresses during communication."
521065,521065,579111,https://api.github.com/repos/msuzen/looper/issues/7,1.0,2020-06-09T17:23:39Z,OWNER,https://api.github.com/repos/msuzen/looper, conditional average treatment effect (CATE) ,"CATE papers; main ones.

CV : https://usaito.github.io/files/ICML2020_CFCV.pdf", conditional average treatment effect (CATE) CATE papers; main ones. CV : https://usaito.github.io/files/ICML2020_CFCV.pdf
760399,760399,373355,https://api.github.com/repos/openthread/ot-br-posix/issues/817,0.0,2021-04-28T04:58:28Z,MEMBER,https://api.github.com/repos/openthread/ot-br-posix,[github-actions] meshcop test fails intermittently,"[logs_7747.zip](https://github.com/openthread/ot-br-posix/files/6389182/logs_7747.zip)

```
otbr-agent[19504]: Set state callback: OK
otbr-agent[19504]: stop Thread Border Agent
otbr-agent[19504]: Initialize OpenThread Border Router Agent: OK
otbr-agent[19504]: dbus error (null): (null)
otbr-agent[19504]: InitializeListenFd error bind : Address already in use
otbr-agent[19504]: FAILED InitializeListenFd:158 - otbr rest server init error
+ pidof otbr-agent
+ die 'AGENT: failed to start'
+ exit_message='AGENT: failed to start'
+ echo ' *** ERROR: AGENT: failed to start'
 *** ERROR: AGENT: failed to start
+ exit 1
+ test_teardown
+ readonly EXIT_CODE=1
+ EXIT_CODE=1
+ write_syslog 'EXIT 1 - output logs'
+ logger -s -p syslog.alert 'OPENTHREAD_TEST: EXIT 1 - output logs'
<41>Apr 28 04:21:27 runner: OPENTHREAD_TEST: EXIT 1 - output logs
+ sudo pkill -f otbr-agent
+ sudo pkill -f otbr-web
+ sudo pkill -f commissioner-cli
+ sudo pkill -f ot-cli-ftd
+ wait
+ [[ 1 != 1 ]]
+ echo 'EXIT 1: MESSAGE: AGENT: failed to start'
EXIT 1: MESSAGE: AGENT: failed to start
+ exit 1
Error: Process completed with exit code 1.
```",[github-actions] meshcop test fails intermittently [logs_7747.zip](https://github.com/openthread/ot-br-posix/files/6389182/logs_7747.zip) ``` otbr-agent[19504]: Set state callback: OK otbr-agent[19504]: stop Thread Border Agent otbr-agent[19504]: Initialize OpenThread Border Router Agent: OK otbr-agent[19504]: dbus error (null): (null) otbr-agent[19504]: InitializeListenFd error bind : Address already in use otbr-agent[19504]: FAILED InitializeListenFd:158 - otbr rest server init error + pidof otbr-agent + die 'AGENT: failed to start' + exit_message='AGENT: failed to start' + echo ' *** ERROR: AGENT: failed to start' *** ERROR: AGENT: failed to start + exit 1 + test_teardown + readonly EXIT_CODE=1 + EXIT_CODE=1 + write_syslog 'EXIT 1 - output logs' + logger -s -p syslog.alert 'OPENTHREAD_TEST: EXIT 1 - output logs' <41>Apr 28 04:21:27 runner: OPENTHREAD_TEST: EXIT 1 - output logs + sudo pkill -f otbr-agent + sudo pkill -f otbr-web + sudo pkill -f commissioner-cli + sudo pkill -f ot-cli-ftd + wait + [[ 1 != 1 ]] + echo 'EXIT 1: MESSAGE: AGENT: failed to start' EXIT 1: MESSAGE: AGENT: failed to start + exit 1 Error: Process completed with exit code 1. ```
452379,452379,502781,https://api.github.com/repos/we-are-number-1/yumble/issues/141,0.0,2021-03-18T10:18:00Z,CONTRIBUTOR,https://api.github.com/repos/we-are-number-1/yumble,[BUG] Modify createSession & createPreferences on backend,"1. Go to https://yumble.xyz
2. Click on create game
3. Inspect mongoDB and view Session object
4. See that Session contains no body or session code. 
5. Session needs to have a useful body sent to the payload and both api are called at the same time.  Only one api needs to be called after create game is hit and session should look like this straight afterwards.
{
  ""_id"": ""123hiy1y781e2y7"",
  ""isFinished"": false,
  ""preferences"": {
    ""location"": """",
    ""distance"": 0,
    ""cuisines"": [],
    ""price"": []
  },
  ""results"": {
    ""restaurants"": []
  }
}

Additional context:
API contracts need to be upheld especially when checking if PR's meet the same functionality as detailed in their api contracts. API in the future need to be designed with robustness, scalability and future modifiability in mind for any future potential updates for this project.  ","[BUG] Modify createSession & createPreferences on backend 1. Go to https://yumble.xyz 2. Click on create game 3. Inspect mongoDB and view Session object 4. See that Session contains no body or session code. 5. Session needs to have a useful body sent to the payload and both api are called at the same time. Only one api needs to be called after create game is hit and session should look like this straight afterwards. { ""_id"": ""123hiy1y781e2y7"", ""isFinished"": false, ""preferences"": { ""location"": """", ""distance"": 0, ""cuisines"": [], ""price"": [] }, ""results"": { ""restaurants"": [] } } Additional context: API contracts need to be upheld especially when checking if PR's meet the same functionality as detailed in their api contracts. API in the future need to be designed with robustness, scalability and future modifiability in mind for any future potential updates for this project. "
32141,32141,35813,https://api.github.com/repos/storybookjs/storybook/issues/14941,0.0,2021-05-14T18:56:38Z,NONE,https://api.github.com/repos/storybookjs/storybook,Error running storybook 6 with angular 11,"**Describe the bug**
Error similiar to the closed issue an year ago  #11630
After instalation, when runninng storybook gives the following output.
Tested on ubuntu 20.04 and it works well with the same package versions (angular and storybook)

```
npm run storybook
 
 
> teststorybook@0.0.0 storybook
> npm run docs:json && start-storybook -p 6006


> teststorybook@0.0.0 docs:json
> compodoc -p ./tsconfig.json -e json -d .




1.1.11

TypeScript version used by Compodoc : 2.9.1

TypeScript version of current project : 4.1.5

Node.js version : v15.14.0

Operating system : Windows 10

[15:07:23] No configuration file found, switching to CLI flags.
[15:07:23] Using tsconfig file : D:\Projetos\story\teststorybook\tsconfig.json
[15:07:23] Including      : D:\Projetos\story\teststorybook\.browserslistrc
[15:07:23] Including      : D:\Projetos\story\teststorybook\.editorconfig
[15:07:23] Including      : D:\Projetos\story\teststorybook\.gitignore
[15:07:23] Including      : D:\Projetos\story\teststorybook\angular.json
[15:07:23] Including      : D:\Projetos\story\teststorybook\karma.conf.js
[15:07:23] Including      : D:\Projetos\story\teststorybook\README.md
[15:07:23] Including      : D:\Projetos\story\teststorybook\package.json
[15:07:23] Including      : D:\Projetos\story\teststorybook\package-lock.json
[15:07:23] Including      : D:\Projetos\story\teststorybook\tsconfig.app.json
[15:07:23] Including      : D:\Projetos\story\teststorybook\tsconfig.json
[15:07:23] Including      : D:\Projetos\story\teststorybook\tsconfig.spec.json
[15:07:23] Including      : D:\Projetos\story\teststorybook\tslint.json
[15:07:23] Including      : D:\Projetos\story\teststorybook\e2e\protractor.conf.js
[15:07:23] Including      : D:\Projetos\story\teststorybook\e2e\tsconfig.json
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\favicon.ico
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\main.ts
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\index.html
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\polyfills.ts
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\styles.sass
[15:07:23] Including      : D:\Projetos\story\teststorybook\.storybook\main.js
[15:07:23] Including      : D:\Projetos\story\teststorybook\.storybook\preview.js
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\test.ts
[15:07:23] Including      : D:\Projetos\story\teststorybook\.storybook\tsconfig.json
[15:07:23] Ignoring       : D:\Projetos\story\teststorybook\.storybook\typings.d.ts
[15:07:23] Ignoring       : D:\Projetos\story\teststorybook\e2e\src\app.e2e-spec.ts
[15:07:23] Including      : D:\Projetos\story\teststorybook\e2e\src\app.po.ts
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\app\app-routing.module.ts
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\app\app.component.html
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\app\app.component.sass
[15:07:23] Ignoring       : D:\Projetos\story\teststorybook\src\app\app.component.spec.ts
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\app\app.component.ts
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\app\app.module.ts
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\assets\.gitkeep
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\environments\environment.prod.ts
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\environments\environment.ts
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\stories\button.component.ts
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\stories\button.css
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\stories\Button.stories.ts
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\stories\header.component.ts
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\stories\header.css
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\stories\Header.stories.ts
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\stories\Introduction.stories.mdx
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\stories\page.component.ts
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\stories\page.css
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\stories\Page.stories.ts
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\stories\assets\code-brackets.svg
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\stories\assets\colors.svg
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\stories\assets\comments.svg
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\stories\assets\direction.svg
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\stories\assets\flow.svg
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\stories\assets\plugin.svg
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\stories\assets\repo.svg
[15:07:23] Including      : D:\Projetos\story\teststorybook\src\stories\assets\stackalt.svg
[15:07:23] Searching package.json file
[15:07:23] package.json file found
[15:07:23] Processing package.json dependencies
[15:07:23] Searching README.md, CHANGELOG.md, CONTRIBUTING.md, LICENSE.md, TODO.md files
[15:07:23] README.md file found
[15:07:23] Error during D:\Projetos\story\teststorybook\CHANGELOG read
[15:07:23] Continuing without CHANGELOG.md file
[15:07:23] Error during D:\Projetos\story\teststorybook\CONTRIBUTING read
[15:07:23] Continuing without CONTRIBUTING.md file
[15:07:23] Error during D:\Projetos\story\teststorybook\LICENSE read
[15:07:23] Continuing without LICENSE.md file
[15:07:23] Error during D:\Projetos\story\teststorybook\TODO read
[15:07:23] Continuing without TODO.md file
[15:07:23] Get dependencies data
[15:07:23] parsing        : D:/Projetos/story/teststorybook/src/main.ts
[15:07:23] parsing        : D:/Projetos/story/teststorybook/src/polyfills.ts
[15:07:23] parsing        : D:/Projetos/story/teststorybook/src/test.ts
[15:07:23] parsing        : D:/Projetos/story/teststorybook/e2e/src/app.po.ts
[15:07:23] found          : AppPage
[15:07:23] parsing        : D:/Projetos/story/teststorybook/src/app/app-routing.module.ts
[15:07:23] Analysing routes definitions and clean them if necessary
[15:07:23] found          : AppRoutingModule
[15:07:23]                : - imports:
[15:07:23]                :     - RouterModule
[15:07:23]                : - exports:
[15:07:23]                :     - RouterModule
[15:07:23] parsing        : D:/Projetos/story/teststorybook/src/app/app.component.ts
[15:07:23] found          : AppComponent
[15:07:23] parsing        : D:/Projetos/story/teststorybook/src/app/app.module.ts
[15:07:23] found          : AppModule
[15:07:23]                : - imports:
[15:07:23]                :     - BrowserModule
[15:07:23]                :     - AppRoutingModule
[15:07:23]                : - declarations:
[15:07:23]                :     - AppComponent
[15:07:23]                : - bootstrap:
[15:07:23]                :     - AppComponent
[15:07:23] parsing        : D:/Projetos/story/teststorybook/src/environments/environment.prod.ts
[15:07:23] parsing        : D:/Projetos/story/teststorybook/src/environments/environment.ts
[15:07:23] parsing        : D:/Projetos/story/teststorybook/src/stories/button.component.ts
[15:07:23] found          : ButtonComponent
[15:07:23] parsing        : D:/Projetos/story/teststorybook/src/stories/Button.stories.ts
[15:07:23] parsing        : D:/Projetos/story/teststorybook/src/stories/header.component.ts
[15:07:23] found          : HeaderComponent
[15:07:23] parsing        : D:/Projetos/story/teststorybook/src/stories/Header.stories.ts
[15:07:23] parsing        : D:/Projetos/story/teststorybook/src/stories/page.component.ts
[15:07:23] found          : PageComponent
[15:07:23] parsing        : D:/Projetos/story/teststorybook/src/stories/Page.stories.ts
[15:07:23] -------------------
[15:07:24] Project statistics
[15:07:24] - files      : 50
[15:07:24] - module     : 2
[15:07:24] - component  : 4
[15:07:24] - class      : 1
[15:07:24] -------------------
[15:07:24] Prepare components
[15:07:24]  AppComponent has a templateUrl, include it
[15:07:24]  AppComponent has styleUrls, include them
[15:07:24]  ButtonComponent has styleUrls, include them
[15:07:24]  HeaderComponent has styleUrls, include them
[15:07:24]  PageComponent has styleUrls, include them
[15:07:24] Prepare modules
[15:07:24] Process routes
[15:07:24] Prepare classes
[15:07:24] Prepare miscellaneous
[15:07:24] Process documentation coverage report
[15:07:24] Generating documentation in export format json
[15:07:24] Documentation generated in ./ in 1.32 seconds
info @storybook/angular v6.2.9
info
info => Loading presets
info => Loading 1 config file in ""D:\Projetos\story\teststorybook\.storybook""
info => Loading 7 other files in ""D:\Projetos\story\teststorybook\.storybook""
info => Adding stories defined in ""D:\Projetos\story\teststorybook\.storybook\main.js""
info => Using prebuilt manager
info => Found custom tsconfig.json
info => Using implicit CSS loaders
WARN Unable to close preview build!
ERR! SyntaxError: Invalid regular expression: /%Notepad++%/: Nothing to repeat
ERR!     at new RegExp (<anonymous>)
ERR!     at D:\Projetos\story\teststorybook\node_modules\@storybook\core-common\dist\cjs\utils\template.js:20:24
ERR!     at Array.reduce (<anonymous>)
ERR!     at interpolate (D:\Projetos\story\teststorybook\node_modules\@storybook\core-common\dist\cjs\utils\template.js:19:31)
ERR!     at getManagerHeadTemplate (D:\Projetos\story\teststorybook\node_modules\@storybook\core-common\dist\cjs\utils\template.js:63:10)
ERR!     at _default (D:\Projetos\story\teststorybook\node_modules\@storybook\core-server\dist\cjs\manager\manager-webpack.config.js:61:99)
ERR!     at async Object.start (D:\Projetos\story\teststorybook\node_modules\@storybook\core-server\dist\cjs\manager\builder.js:94:16)
ERR!     at async Promise.all (index 1)
ERR!     at async storybookDevServer (D:\Projetos\story\teststorybook\node_modules\@storybook\core-server\dist\cjs\dev-server.js:103:28)
ERR!     at async buildDevStandalone (D:\Projetos\story\teststorybook\node_modules\@storybook\core-server\dist\cjs\build-dev.js:107:31)
ERR!     at async Object.buildDev (D:\Projetos\story\teststorybook\node_modules\@storybook\core-server\dist\cjs\build-dev.js:147:5)
ERR!  SyntaxError: Invalid regular expression: /%Notepad++%/: Nothing to repeat
ERR!     at new RegExp (<anonymous>)
ERR!     at D:\Projetos\story\teststorybook\node_modules\@storybook\core-common\dist\cjs\utils\template.js:20:24
ERR!     at Array.reduce (<anonymous>)
ERR!     at interpolate (D:\Projetos\story\teststorybook\node_modules\@storybook\core-common\dist\cjs\utils\template.js:19:31)
ERR!     at getManagerHeadTemplate (D:\Projetos\story\teststorybook\node_modules\@storybook\core-common\dist\cjs\utils\template.js:63:10)
ERR!     at _default (D:\Projetos\story\teststorybook\node_modules\@storybook\core-server\dist\cjs\manager\manager-webpack.config.js:61:99)
ERR!     at async Object.start (D:\Projetos\story\teststorybook\node_modules\@storybook\core-server\dist\cjs\manager\builder.js:94:16)
ERR!     at async Promise.all (index 1)
ERR!     at async storybookDevServer (D:\Projetos\story\teststorybook\node_modules\@storybook\core-server\dist\cjs\dev-server.js:103:28)
ERR!     at async buildDevStandalone (D:\Projetos\story\teststorybook\node_modules\@storybook\core-server\dist\cjs\build-dev.js:107:31)
ERR!     at async Object.buildDev (D:\Projetos\story\teststorybook\node_modules\@storybook\core-server\dist\cjs\build-dev.js:147:5)

WARN Broken build, fix the error above.
WARN You may need to refresh the browser.

```
**System**
```
>npx sb@next info

Environment Info:

  System:
    OS: Windows 10 10.0.19042
    CPU: (4) x64 Intel(R) Xeon(R) CPU E3-1220 V2 @ 3.10GHz
  Binaries:
    Node: 15.14.0 - C:\Program Files\nodejs\node.EXE
    Yarn: 2.4.1 - C:\Program Files\nodejs\yarn.CMD
    npm: 7.7.6 - C:\Program Files\nodejs\npm.CMD
  Browsers:
    Edge: Spartan (44.19041.964.0), Chromium (90.0.818.62)
  npmPackages:
    @storybook/addon-actions: ^6.3.0-alpha.27 => 6.3.0-alpha.27
    @storybook/addon-docs: ^6.3.0-alpha.27 => 6.3.0-alpha.27
    @storybook/addon-essentials: ^6.3.0-alpha.27 => 6.3.0-alpha.27
    @storybook/addon-links: ^6.3.0-alpha.27 => 6.3.0-alpha.27
    @storybook/angular: ^6.3.0-alpha.27 => 6.3.0-alpha.27
    @storybook/builder-webpack5: ^6.3.0-alpha.27 => 6.3.0-alpha.27

```
** Repository for test:**
https://github.com/danilomr12/storybookangular11.git

","Error running storybook 6 with angular 11 **Describe the bug** Error similiar to the closed issue an year ago #11630 After instalation, when runninng storybook gives the following output. Tested on ubuntu 20.04 and it works well with the same package versions (angular and storybook) ``` npm run storybook > teststorybook@0.0.0 storybook > npm run docs:json && start-storybook -p 6006 > teststorybook@0.0.0 docs:json > compodoc -p ./tsconfig.json -e json -d . 1.1.11 TypeScript version used by Compodoc : 2.9.1 TypeScript version of current project : 4.1.5 Node.js version : v15.14.0 Operating system : Windows 10 [15:07:23] No configuration file found, switching to CLI flags. [15:07:23] Using tsconfig file : D:\Projetos\story\teststorybook\tsconfig.json [15:07:23] Including : D:\Projetos\story\teststorybook\.browserslistrc [15:07:23] Including : D:\Projetos\story\teststorybook\.editorconfig [15:07:23] Including : D:\Projetos\story\teststorybook\.gitignore [15:07:23] Including : D:\Projetos\story\teststorybook\angular.json [15:07:23] Including : D:\Projetos\story\teststorybook\karma.conf.js [15:07:23] Including : D:\Projetos\story\teststorybook\README.md [15:07:23] Including : D:\Projetos\story\teststorybook\package.json [15:07:23] Including : D:\Projetos\story\teststorybook\package-lock.json [15:07:23] Including : D:\Projetos\story\teststorybook\tsconfig.app.json [15:07:23] Including : D:\Projetos\story\teststorybook\tsconfig.json [15:07:23] Including : D:\Projetos\story\teststorybook\tsconfig.spec.json [15:07:23] Including : D:\Projetos\story\teststorybook\tslint.json [15:07:23] Including : D:\Projetos\story\teststorybook\e2e\protractor.conf.js [15:07:23] Including : D:\Projetos\story\teststorybook\e2e\tsconfig.json [15:07:23] Including : D:\Projetos\story\teststorybook\src\favicon.ico [15:07:23] Including : D:\Projetos\story\teststorybook\src\main.ts [15:07:23] Including : D:\Projetos\story\teststorybook\src\index.html [15:07:23] Including : D:\Projetos\story\teststorybook\src\polyfills.ts [15:07:23] Including : D:\Projetos\story\teststorybook\src\styles.sass [15:07:23] Including : D:\Projetos\story\teststorybook\.storybook\main.js [15:07:23] Including : D:\Projetos\story\teststorybook\.storybook\preview.js [15:07:23] Including : D:\Projetos\story\teststorybook\src\test.ts [15:07:23] Including : D:\Projetos\story\teststorybook\.storybook\tsconfig.json [15:07:23] Ignoring : D:\Projetos\story\teststorybook\.storybook\typings.d.ts [15:07:23] Ignoring : D:\Projetos\story\teststorybook\e2e\src\app.e2e-spec.ts [15:07:23] Including : D:\Projetos\story\teststorybook\e2e\src\app.po.ts [15:07:23] Including : D:\Projetos\story\teststorybook\src\app\app-routing.module.ts [15:07:23] Including : D:\Projetos\story\teststorybook\src\app\app.component.html [15:07:23] Including : D:\Projetos\story\teststorybook\src\app\app.component.sass [15:07:23] Ignoring : D:\Projetos\story\teststorybook\src\app\app.component.spec.ts [15:07:23] Including : D:\Projetos\story\teststorybook\src\app\app.component.ts [15:07:23] Including : D:\Projetos\story\teststorybook\src\app\app.module.ts [15:07:23] Including : D:\Projetos\story\teststorybook\src\assets\.gitkeep [15:07:23] Including : D:\Projetos\story\teststorybook\src\environments\environment.prod.ts [15:07:23] Including : D:\Projetos\story\teststorybook\src\environments\environment.ts [15:07:23] Including : D:\Projetos\story\teststorybook\src\stories\button.component.ts [15:07:23] Including : D:\Projetos\story\teststorybook\src\stories\button.css [15:07:23] Including : D:\Projetos\story\teststorybook\src\stories\Button.stories.ts [15:07:23] Including : D:\Projetos\story\teststorybook\src\stories\header.component.ts [15:07:23] Including : D:\Projetos\story\teststorybook\src\stories\header.css [15:07:23] Including : D:\Projetos\story\teststorybook\src\stories\Header.stories.ts [15:07:23] Including : D:\Projetos\story\teststorybook\src\stories\Introduction.stories.mdx [15:07:23] Including : D:\Projetos\story\teststorybook\src\stories\page.component.ts [15:07:23] Including : D:\Projetos\story\teststorybook\src\stories\page.css [15:07:23] Including : D:\Projetos\story\teststorybook\src\stories\Page.stories.ts [15:07:23] Including : D:\Projetos\story\teststorybook\src\stories\assets\code-brackets.svg [15:07:23] Including : D:\Projetos\story\teststorybook\src\stories\assets\colors.svg [15:07:23] Including : D:\Projetos\story\teststorybook\src\stories\assets\comments.svg [15:07:23] Including : D:\Projetos\story\teststorybook\src\stories\assets\direction.svg [15:07:23] Including : D:\Projetos\story\teststorybook\src\stories\assets\flow.svg [15:07:23] Including : D:\Projetos\story\teststorybook\src\stories\assets\plugin.svg [15:07:23] Including : D:\Projetos\story\teststorybook\src\stories\assets\repo.svg [15:07:23] Including : D:\Projetos\story\teststorybook\src\stories\assets\stackalt.svg [15:07:23] Searching package.json file [15:07:23] package.json file found [15:07:23] Processing package.json dependencies [15:07:23] Searching README.md, CHANGELOG.md, CONTRIBUTING.md, LICENSE.md, TODO.md files [15:07:23] README.md file found [15:07:23] Error during D:\Projetos\story\teststorybook\CHANGELOG read [15:07:23] Continuing without CHANGELOG.md file [15:07:23] Error during D:\Projetos\story\teststorybook\CONTRIBUTING read [15:07:23] Continuing without CONTRIBUTING.md file [15:07:23] Error during D:\Projetos\story\teststorybook\LICENSE read [15:07:23] Continuing without LICENSE.md file [15:07:23] Error during D:\Projetos\story\teststorybook\TODO read [15:07:23] Continuing without TODO.md file [15:07:23] Get dependencies data [15:07:23] parsing : D:/Projetos/story/teststorybook/src/main.ts [15:07:23] parsing : D:/Projetos/story/teststorybook/src/polyfills.ts [15:07:23] parsing : D:/Projetos/story/teststorybook/src/test.ts [15:07:23] parsing : D:/Projetos/story/teststorybook/e2e/src/app.po.ts [15:07:23] found : AppPage [15:07:23] parsing : D:/Projetos/story/teststorybook/src/app/app-routing.module.ts [15:07:23] Analysing routes definitions and clean them if necessary [15:07:23] found : AppRoutingModule [15:07:23] : - imports: [15:07:23] : - RouterModule [15:07:23] : - exports: [15:07:23] : - RouterModule [15:07:23] parsing : D:/Projetos/story/teststorybook/src/app/app.component.ts [15:07:23] found : AppComponent [15:07:23] parsing : D:/Projetos/story/teststorybook/src/app/app.module.ts [15:07:23] found : AppModule [15:07:23] : - imports: [15:07:23] : - BrowserModule [15:07:23] : - AppRoutingModule [15:07:23] : - declarations: [15:07:23] : - AppComponent [15:07:23] : - bootstrap: [15:07:23] : - AppComponent [15:07:23] parsing : D:/Projetos/story/teststorybook/src/environments/environment.prod.ts [15:07:23] parsing : D:/Projetos/story/teststorybook/src/environments/environment.ts [15:07:23] parsing : D:/Projetos/story/teststorybook/src/stories/button.component.ts [15:07:23] found : ButtonComponent [15:07:23] parsing : D:/Projetos/story/teststorybook/src/stories/Button.stories.ts [15:07:23] parsing : D:/Projetos/story/teststorybook/src/stories/header.component.ts [15:07:23] found : HeaderComponent [15:07:23] parsing : D:/Projetos/story/teststorybook/src/stories/Header.stories.ts [15:07:23] parsing : D:/Projetos/story/teststorybook/src/stories/page.component.ts [15:07:23] found : PageComponent [15:07:23] parsing : D:/Projetos/story/teststorybook/src/stories/Page.stories.ts [15:07:23] ------------------- [15:07:24] Project statistics [15:07:24] - files : 50 [15:07:24] - module : 2 [15:07:24] - component : 4 [15:07:24] - class : 1 [15:07:24] ------------------- [15:07:24] Prepare components [15:07:24] AppComponent has a templateUrl, include it [15:07:24] AppComponent has styleUrls, include them [15:07:24] ButtonComponent has styleUrls, include them [15:07:24] HeaderComponent has styleUrls, include them [15:07:24] PageComponent has styleUrls, include them [15:07:24] Prepare modules [15:07:24] Process routes [15:07:24] Prepare classes [15:07:24] Prepare miscellaneous [15:07:24] Process documentation coverage report [15:07:24] Generating documentation in export format json [15:07:24] Documentation generated in ./ in 1.32 seconds info @storybook/angular v6.2.9 info info => Loading presets info => Loading 1 config file in ""D:\Projetos\story\teststorybook\.storybook"" info => Loading 7 other files in ""D:\Projetos\story\teststorybook\.storybook"" info => Adding stories defined in ""D:\Projetos\story\teststorybook\.storybook\main.js"" info => Using prebuilt manager info => Found custom tsconfig.json info => Using implicit CSS loaders WARN Unable to close preview build! ERR! SyntaxError: Invalid regular expression: /%Notepad++%/: Nothing to repeat ERR! at new RegExp (<anonymous>) ERR! at D:\Projetos\story\teststorybook\node_modules\@storybook\core-common\dist\cjs\utils\template.js:20:24 ERR! at Array.reduce (<anonymous>) ERR! at interpolate (D:\Projetos\story\teststorybook\node_modules\@storybook\core-common\dist\cjs\utils\template.js:19:31) ERR! at getManagerHeadTemplate (D:\Projetos\story\teststorybook\node_modules\@storybook\core-common\dist\cjs\utils\template.js:63:10) ERR! at _default (D:\Projetos\story\teststorybook\node_modules\@storybook\core-server\dist\cjs\manager\manager-webpack.config.js:61:99) ERR! at async Object.start (D:\Projetos\story\teststorybook\node_modules\@storybook\core-server\dist\cjs\manager\builder.js:94:16) ERR! at async Promise.all (index 1) ERR! at async storybookDevServer (D:\Projetos\story\teststorybook\node_modules\@storybook\core-server\dist\cjs\dev-server.js:103:28) ERR! at async buildDevStandalone (D:\Projetos\story\teststorybook\node_modules\@storybook\core-server\dist\cjs\build-dev.js:107:31) ERR! at async Object.buildDev (D:\Projetos\story\teststorybook\node_modules\@storybook\core-server\dist\cjs\build-dev.js:147:5) ERR! SyntaxError: Invalid regular expression: /%Notepad++%/: Nothing to repeat ERR! at new RegExp (<anonymous>) ERR! at D:\Projetos\story\teststorybook\node_modules\@storybook\core-common\dist\cjs\utils\template.js:20:24 ERR! at Array.reduce (<anonymous>) ERR! at interpolate (D:\Projetos\story\teststorybook\node_modules\@storybook\core-common\dist\cjs\utils\template.js:19:31) ERR! at getManagerHeadTemplate (D:\Projetos\story\teststorybook\node_modules\@storybook\core-common\dist\cjs\utils\template.js:63:10) ERR! at _default (D:\Projetos\story\teststorybook\node_modules\@storybook\core-server\dist\cjs\manager\manager-webpack.config.js:61:99) ERR! at async Object.start (D:\Projetos\story\teststorybook\node_modules\@storybook\core-server\dist\cjs\manager\builder.js:94:16) ERR! at async Promise.all (index 1) ERR! at async storybookDevServer (D:\Projetos\story\teststorybook\node_modules\@storybook\core-server\dist\cjs\dev-server.js:103:28) ERR! at async buildDevStandalone (D:\Projetos\story\teststorybook\node_modules\@storybook\core-server\dist\cjs\build-dev.js:107:31) ERR! at async Object.buildDev (D:\Projetos\story\teststorybook\node_modules\@storybook\core-server\dist\cjs\build-dev.js:147:5) WARN Broken build, fix the error above. WARN You may need to refresh the browser. ``` **System** ``` >npx sb@next info Environment Info: System: OS: Windows 10 10.0.19042 CPU: (4) x64 Intel(R) Xeon(R) CPU E3-1220 V2 @ 3.10GHz Binaries: Node: 15.14.0 - C:\Program Files\nodejs\node.EXE Yarn: 2.4.1 - C:\Program Files\nodejs\yarn.CMD npm: 7.7.6 - C:\Program Files\nodejs\npm.CMD Browsers: Edge: Spartan (44.19041.964.0), Chromium (90.0.818.62) npmPackages: @storybook/addon-actions: ^6.3.0-alpha.27 => 6.3.0-alpha.27 @storybook/addon-docs: ^6.3.0-alpha.27 => 6.3.0-alpha.27 @storybook/addon-essentials: ^6.3.0-alpha.27 => 6.3.0-alpha.27 @storybook/addon-links: ^6.3.0-alpha.27 => 6.3.0-alpha.27 @storybook/angular: ^6.3.0-alpha.27 => 6.3.0-alpha.27 @storybook/builder-webpack5: ^6.3.0-alpha.27 => 6.3.0-alpha.27 ``` ** Repository for test:** https://github.com/danilomr12/storybookangular11.git "
368936,368936,410133,https://api.github.com/repos/R-Mielamud/homepage/issues/7,1.0,2021-01-13T09:15:17Z,OWNER,https://api.github.com/repos/R-Mielamud/homepage,鬼克剋逵龜 畇棘畇逵克棘勻 戟棘劇逵橘戟 閨剋棘克龜,"棘菌戟逵 鈞棘閨龜龜 筠鈞劇筠 劇筠戟 棘劇逵剋戟龜劇, 畇棘畇逵勻龜 畇棘畇逵克棘勻 閨剋棘克龜, 克 劇 克棘龜戟 戟棘劇逵, 逵剋筠 極棘畇逵  勻 ""棘鈞勻逵菌逵剋戟橘"" 棘劇. 逵極龜克剋逵畇, 棘 極棘畇棘閨逵  戟筠 極棘畇棘閨逵, 龜剋戟  剋逵閨克 棘棘戟龜, 極筠筠剋克 戟逵勻龜克勻 龜 棘閨, 戟棘均逵克逵 逵閨棘 菌 戟筠逵克龜勻戟 劇棘畇剋, 棘棘. 逵棘 戟逵極龜逵龜 克棘戟筠戟 逵克棘均棘 閨剋棘克 逵戟筠, 戟菌 極棘龜戟逵龜 勻筠克, 閨棘 橘棘均棘 棘鈞劇龜 勻極剋龜勻逵龜劇 戟逵 棘鈞劇筠戟戟 筠剋筠劇筠戟勻 戟逵 棘戟.","鬼克剋逵龜 畇棘畇逵克棘勻 戟棘劇逵橘戟 閨剋棘克龜 棘菌戟逵 鈞棘閨龜龜 筠鈞劇筠 劇筠戟 棘劇逵剋戟龜劇, 畇棘畇逵勻龜 畇棘畇逵克棘勻 閨剋棘克龜, 克 劇 克棘龜戟 戟棘劇逵, 逵剋筠 極棘畇逵  勻 ""棘鈞勻逵菌逵剋戟橘"" 棘劇. 逵極龜克剋逵畇, 棘 極棘畇棘閨逵  戟筠 極棘畇棘閨逵, 龜剋戟  剋逵閨克 棘棘戟龜, 極筠筠剋克 戟逵勻龜克勻 龜 棘閨, 戟棘均逵克逵 逵閨棘 菌 戟筠逵克龜勻戟 劇棘畇剋, 棘棘. 逵棘 戟逵極龜逵龜 克棘戟筠戟 逵克棘均棘 閨剋棘克 逵戟筠, 戟菌 極棘龜戟逵龜 勻筠克, 閨棘 橘棘均棘 棘鈞劇龜 勻極剋龜勻逵龜劇 戟逵 棘鈞劇筠戟戟 筠剋筠劇筠戟勻 戟逵 棘戟."
778589,778589,555319,https://api.github.com/repos/MicrosoftDocs/feedback/issues/2789,1.0,2020-05-26T07:27:17Z,NONE,https://api.github.com/repos/MicrosoftDocs/feedback,[Question] Windows 10 IoT Dead?,"Hi,

is Windows 10 IoT dead? According to the docs it was last updated 2018.
Does not work on RPi4 unfortuantely. ","[Question] Windows 10 IoT Dead? Hi, is Windows 10 IoT dead? According to the docs it was last updated 2018. Does not work on RPi4 unfortuantely. "
596864,596864,663308,https://api.github.com/repos/ansible/ansible/issues/73926,0.0,2021-03-16T18:09:49Z,CONTRIBUTOR,https://api.github.com/repos/ansible/ansible,Massive overhead of hosts templating for every host of every task,"### Summary

Executing a playbook with many hosts, there is massive overhead in checking whether the hosts list is a pattern, see for yourself on this callgrind graph:

![grafik](https://user-images.githubusercontent.com/3154871/111359016-4a4bf480-868b-11eb-8c8f-55b6a6a10bd7.png)

https://github.com/ansible/ansible/blob/da60525610a384bb04833b1c6429d9db6a87ef64/lib/ansible/vars/manager.py#L490

That check has quadratic runtime with the number of hosts - with a lot of hosts, commenting that check out reduces runtime manyfold.

### Issue Type

Bug Report

### Component Name

variable manager

### Ansible Version

2.10.5, devel

### OS / Environment

Ubuntu

### Steps to Reproduce

```yaml
- hosts: localhost
  tasks:
    - set_fact:
        extra_tasks: true # compute it
        hosts: ""{{ [an, array, with, 5100, computed, hosts] }}""

- hosts: ""{{ hostvars.localhost.hosts }}""
  vars:
    extra_tasks: ""{{ hostvars.localhost.do_extra_tasks }}""
  tasks:
   # some more tasks here
    - name: Execute extra tasks
      command: /bin/true # example
      when: extra_tasks
```

### Expected Results

Execute in tens of seconds.

### Actual Results

Take over 5 minutes to execute.","Massive overhead of hosts templating for every host of every task ### Summary Executing a playbook with many hosts, there is massive overhead in checking whether the hosts list is a pattern, see for yourself on this callgrind graph: ![grafik](https://user-images.githubusercontent.com/3154871/111359016-4a4bf480-868b-11eb-8c8f-55b6a6a10bd7.png) https://github.com/ansible/ansible/blob/da60525610a384bb04833b1c6429d9db6a87ef64/lib/ansible/vars/manager.py#L490 That check has quadratic runtime with the number of hosts - with a lot of hosts, commenting that check out reduces runtime manyfold. ### Issue Type Bug Report ### Component Name variable manager ### Ansible Version 2.10.5, devel ### OS / Environment Ubuntu ### Steps to Reproduce ```yaml - hosts: localhost tasks: - set_fact: extra_tasks: true # compute it hosts: ""{{ [an, array, with, 5100, computed, hosts] }}"" - hosts: ""{{ hostvars.localhost.hosts }}"" vars: extra_tasks: ""{{ hostvars.localhost.do_extra_tasks }}"" tasks: # some more tasks here - name: Execute extra tasks command: /bin/true # example when: extra_tasks ``` ### Expected Results Execute in tens of seconds. ### Actual Results Take over 5 minutes to execute."
161861,161861,179949,https://api.github.com/repos/yarnpkg/berry/issues/2768,0.0,2021-04-16T11:01:35Z,CONTRIBUTOR,https://api.github.com/repos/yarnpkg/berry,[Bug] Yarn link doesn't work with node-modules linker,"- [ ] I'd be willing to implement a fix

**Describe the bug**

Yarn link doesn't work with the node-modules linker. When I use

```
yarn link ~/projects/ui-lib;
```

yarn sets

```
 ""resolutions"": {
    ""ui-lib"": ""portal:~/projects/ui-lib""
  }
```

and it leads to this error:

```
 YN0001:  Error: Assertion failed: Cannot process a path that isn't part of the requested prefix (/Users/v7rulnik/projects/ui-lib/node_modules/lodash isn't within /Users/v7rulnik/projects/main-project)
```

It doesn't work because portals supported only inside the project directory according to https://github.com/yarnpkg/berry/pull/2481




**To Reproduce**

1. Set `nodeLinker: node-modules`
2. Run `yarn link ~/some-project`


**Environment if relevant (please complete the following information):**

 - OS: MacOs
 - Node version 14.15.4
 - Yarn version 3.0.0-rc.2.git.20210415.hash-2cb5fb1b

**Additional context**

`yarn link` ran successful with yarn 2.4.1, but as I understand it doesn't support portals.","[Bug] Yarn link doesn't work with node-modules linker - [ ] I'd be willing to implement a fix **Describe the bug** Yarn link doesn't work with the node-modules linker. When I use ``` yarn link ~/projects/ui-lib; ``` yarn sets ``` ""resolutions"": { ""ui-lib"": ""portal:~/projects/ui-lib"" } ``` and it leads to this error: ```  YN0001:  Error: Assertion failed: Cannot process a path that isn't part of the requested prefix (/Users/v7rulnik/projects/ui-lib/node_modules/lodash isn't within /Users/v7rulnik/projects/main-project) ``` It doesn't work because portals supported only inside the project directory according to https://github.com/yarnpkg/berry/pull/2481 **To Reproduce** 1. Set `nodeLinker: node-modules` 2. Run `yarn link ~/some-project` **Environment if relevant (please complete the following information):** - OS: MacOs - Node version 14.15.4 - Yarn version 3.0.0-rc.2.git.20210415.hash-2cb5fb1b **Additional context** `yarn link` ran successful with yarn 2.4.1, but as I understand it doesn't support portals."
269039,269039,299196,https://api.github.com/repos/libsdl-org/SDL/issues/2389,0.0,2021-02-11T00:35:07Z,COLLABORATOR,https://api.github.com/repos/libsdl-org/SDL,Can't set minimal size (message box appears instead) if maximal size wasn't declared (i.e. unlimited),"
# This bug report was migrated from our old Bugzilla tracker.

**Reported in version:** HG 2.1
**Reported for operating system, platform:** Linux, All

# Comments on the original bug report:

On 2017-02-02 08:34:24 +0000, Vitaly Novichkov wrote:

> After this revision https://hg.libsdl.org/SDL/rev/7f08396c7581 I always getting a warning about minimal size larger maximal size.
> 
> What I did:
> - Created window (hidden) with specified size (800x600)
> - called SDL_SetWindowMinimumSize() to set 800x600 as minimal size (but keep maximal size be unlimited)
> 
> I think the check must be skipped if minimal/maximal sizes are unlimited and check if opposite size is set.

On 2017-02-02 08:42:12 +0000, Sam Lantinga wrote:

> Fixed, thanks!
> https://hg.libsdl.org/SDL/rev/a15188ff9537

","Can't set minimal size (message box appears instead) if maximal size wasn't declared (i.e. unlimited) # This bug report was migrated from our old Bugzilla tracker. **Reported in version:** HG 2.1 **Reported for operating system, platform:** Linux, All # Comments on the original bug report: On 2017-02-02 08:34:24 +0000, Vitaly Novichkov wrote: > After this revision https://hg.libsdl.org/SDL/rev/7f08396c7581 I always getting a warning about minimal size larger maximal size. > > What I did: > - Created window (hidden) with specified size (800x600) > - called SDL_SetWindowMinimumSize() to set 800x600 as minimal size (but keep maximal size be unlimited) > > I think the check must be skipped if minimal/maximal sizes are unlimited and check if opposite size is set. On 2017-02-02 08:42:12 +0000, Sam Lantinga wrote: > Fixed, thanks! > https://hg.libsdl.org/SDL/rev/a15188ff9537 "
666943,666943,741301,https://api.github.com/repos/pjrinaldi/wombatforensics/issues/122,1.0,2015-03-14T19:24:42Z,OWNER,https://api.github.com/repos/pjrinaldi/wombatforensics,Add more ewf information to TSK,"Original [issue 123](https://code.google.com/p/wombatforensics/issues/detail?id=123) created by pjrinaldi on 2014-08-11T21:58:59.000Z:

Add more information that is extracted/recorded from the EWF library. Just need to reference the libewf.h include file. From there I just need to get a libewf handle so i can call the respectively defined functions:
# define libewf_handle_get_utf8_header_value_case_number( handle, value, value_size, error ) \

```
    libewf_handle_get_utf8_header_value( handle, (uint8_t *) &quot;case_number&quot;, 11, value, value_size, error )
```

/\* Retrieves the header value description
- Returns 1 if successful, 0 if value not present or -1 on error
  */
  #define libewf_handle_get_utf8_header_value_description( handle, value, value_size, error ) \
      libewf_handle_get_utf8_header_value( handle, (uint8_t *) &quot;description&quot;, 11, value, value_size, error ).

with these, I can get all the file format information. have to decide where to add this to the TSK and then try to commit this information back to them.
","Add more ewf information to TSK Original [issue 123](https://code.google.com/p/wombatforensics/issues/detail?id=123) created by pjrinaldi on 2014-08-11T21:58:59.000Z: Add more information that is extracted/recorded from the EWF library. Just need to reference the libewf.h include file. From there I just need to get a libewf handle so i can call the respectively defined functions: # define libewf_handle_get_utf8_header_value_case_number( handle, value, value_size, error ) \ ``` libewf_handle_get_utf8_header_value( handle, (uint8_t *) &quot;case_number&quot;, 11, value, value_size, error ) ``` /\* Retrieves the header value description - Returns 1 if successful, 0 if value not present or -1 on error */ #define libewf_handle_get_utf8_header_value_description( handle, value, value_size, error ) \ libewf_handle_get_utf8_header_value( handle, (uint8_t *) &quot;description&quot;, 11, value, value_size, error ). with these, I can get all the file format information. have to decide where to add this to the TSK and then try to commit this information back to them. "
657190,657190,730500,https://api.github.com/repos/varchenkojulia1/homepage/issues/7,2.0,2021-05-04T12:21:08Z,OWNER,https://api.github.com/repos/varchenkojulia1/homepage,鬼棘逵勻龜 畇棘極棘剋戟龜筠剋戟筠 龜戟棘劇逵龜棘戟戟筠 閨剋棘克龜,"棘菌戟棘 畇筠剋逵 筠鈞劇筠 劇筠戟筠筠 棘劇逵剋戟劇, 畇棘閨逵勻龜勻 畇棘極棘剋戟龜筠剋戟筠 閨剋棘克龜, 克棘棘筠 棘畇筠菌逵 極棘剋筠鈞戟 龜戟棘劇逵龜, 戟棘 極棘畇逵 筠 勻 ""逵鈞勻剋筠克逵筠剋戟棘橘"" 棘劇筠. 逵極龜劇筠, 棘 戟逵勻龜 龜 戟筠 戟逵勻龜, 龜剋戟筠 龜 剋逵閨筠 棘棘戟, 極筠筠筠戟 戟逵勻克棘勻 龜剋龜 棘閨閨龜, 龜戟棘均逵龜克逵 龜剋龜 菌筠 龜戟筠逵克龜勻戟筠 劇棘畇剋龜, 龜 .極. 鬼棘龜 戟逵極龜逵 克棘戟筠戟 逵克棘均棘 閨剋棘克逵 逵戟筠, 筠劇 戟逵龜戟逵 勻筠克, 極棘棘劇 棘 筠均棘 逵鈞劇筠 閨畇 勻剋龜 戟逵 逵鈞劇筠筠戟龜筠 剋筠劇筠戟棘勻 戟逵 逵戟龜筠.","鬼棘逵勻龜 畇棘極棘剋戟龜筠剋戟筠 龜戟棘劇逵龜棘戟戟筠 閨剋棘克龜 棘菌戟棘 畇筠剋逵 筠鈞劇筠 劇筠戟筠筠 棘劇逵剋戟劇, 畇棘閨逵勻龜勻 畇棘極棘剋戟龜筠剋戟筠 閨剋棘克龜, 克棘棘筠 棘畇筠菌逵 極棘剋筠鈞戟 龜戟棘劇逵龜, 戟棘 極棘畇逵 筠 勻 ""逵鈞勻剋筠克逵筠剋戟棘橘"" 棘劇筠. 逵極龜劇筠, 棘 戟逵勻龜 龜 戟筠 戟逵勻龜, 龜剋戟筠 龜 剋逵閨筠 棘棘戟, 極筠筠筠戟 戟逵勻克棘勻 龜剋龜 棘閨閨龜, 龜戟棘均逵龜克逵 龜剋龜 菌筠 龜戟筠逵克龜勻戟筠 劇棘畇剋龜, 龜 .極. 鬼棘龜 戟逵極龜逵 克棘戟筠戟 逵克棘均棘 閨剋棘克逵 逵戟筠, 筠劇 戟逵龜戟逵 勻筠克, 極棘棘劇 棘 筠均棘 逵鈞劇筠 閨畇 勻剋龜 戟逵 逵鈞劇筠筠戟龜筠 剋筠劇筠戟棘勻 戟逵 逵戟龜筠."
756043,756043,329155,https://api.github.com/repos/microsoft/azuredatastudio/issues/15007,0.0,2021-04-06T21:14:42Z,CONTRIBUTOR,https://api.github.com/repos/microsoft/azuredatastudio,Bump SQL Server Guide package version in ADS,"- Azure Data Studio Version:
Version: 1.28.0-rc1
Commit: 124f7ca887bb12e8b0054e3a707404cdedf6b688
Date: 2021-04-05T20:28:22.005Z
VS Code: 1.51.0
Electron: 9.4.3
Chrome: 83.0.4103.122
Node.js: 12.14.1
V8: 8.3.110.13-electron.0
OS: Darwin x64 20.3.0
",Bump SQL Server Guide package version in ADS - Azure Data Studio Version: Version: 1.28.0-rc1 Commit: 124f7ca887bb12e8b0054e3a707404cdedf6b688 Date: 2021-04-05T20:28:22.005Z VS Code: 1.51.0 Electron: 9.4.3 Chrome: 83.0.4103.122 Node.js: 12.14.1 V8: 8.3.110.13-electron.0 OS: Darwin x64 20.3.0 
147640,147640,164110,https://api.github.com/repos/JoshClose/CsvHelper/issues/1654,0.0,2021-01-19T05:46:28Z,NONE,https://api.github.com/repos/JoshClose/CsvHelper,Performance drop down when I update to version 21,"**Describe the bug**
I updated the nuget from version 12.1.1 to version 21.0.2. I find the write performance is very bad. For 7000 records the v12 take less than 1 seconds, but v21 take 23 seconds.

**To Reproduce**
Steps to reproduce the behavior:
1. Set ShouldQuote = (s, context) => true for the config 
2. Pass CultureInfo.InvariantCulture as Culture parameters

**Expected behavior**
The performance should be faster than v12

","Performance drop down when I update to version 21 **Describe the bug** I updated the nuget from version 12.1.1 to version 21.0.2. I find the write performance is very bad. For 7000 records the v12 take less than 1 seconds, but v21 take 23 seconds. **To Reproduce** Steps to reproduce the behavior: 1. Set ShouldQuote = (s, context) => true for the config 2. Pass CultureInfo.InvariantCulture as Culture parameters **Expected behavior** The performance should be faster than v12 "
129336,129336,143749,https://api.github.com/repos/Property-Search-Engine/client-facing-server/issues/8,1.0,2021-02-09T10:22:29Z,MEMBER,https://api.github.com/repos/Property-Search-Engine/client-facing-server,Let clients search properties by city & filters,We would just need to make a call to the Admin Server for this,Let clients search properties by city & filters We would just need to make a call to the Admin Server for this
241616,241616,268739,https://api.github.com/repos/josuemtzmo/EKE_SST_trends/issues/6,1.0,2021-01-09T00:18:22Z,COLLABORATOR,https://api.github.com/repos/josuemtzmo/EKE_SST_trends,Suggestions for notebooks that reproduce figures,"In the notebooks, e.g., 
https://github.com/josuemtzmo/EKE_SST_trends/blob/master/Kinetic_Energy_maps.ipynb
it should be nice to do the following:

- when you load the `xarray.Dataset` to print it out so people can see its dimensions, length of `time` axis and what not.
- when you convert units also also change the `xarray` properties to reflect that, see e.g., `trends = ( dataset_trends.trend * 10*365 ).sel(lat=slice(-60,60)) # Trends per day multiplied by 3650 days to report per decade.` 
-  btw, the line above does 2 things: converts units and makes a selection; this creates confusion to a novice user... Let's help the future generations of students who will struggle to reproduce Josue et al 2021 :)","Suggestions for notebooks that reproduce figures In the notebooks, e.g., https://github.com/josuemtzmo/EKE_SST_trends/blob/master/Kinetic_Energy_maps.ipynb it should be nice to do the following: - when you load the `xarray.Dataset` to print it out so people can see its dimensions, length of `time` axis and what not. - when you convert units also also change the `xarray` properties to reflect that, see e.g., `trends = ( dataset_trends.trend * 10*365 ).sel(lat=slice(-60,60)) # Trends per day multiplied by 3650 days to report per decade.` - btw, the line above does 2 things: converts units and makes a selection; this creates confusion to a novice user... Let's help the future generations of students who will struggle to reproduce Josue et al 2021 :)"
712170,712170,791514,https://api.github.com/repos/neo-project/neo-express/issues/129,1.0,2021-04-29T00:02:47Z,MEMBER,https://api.github.com/repos/neo-project/neo-express,"if two different wallets create a contract with the same name, neoxp contract storage ContractName fails with `An item with the same key has already been added. Key: ContractName`",,"if two different wallets create a contract with the same name, neoxp contract storage ContractName fails with `An item with the same key has already been added. Key: ContractName` "
621030,621030,690170,https://api.github.com/repos/newrelic-experimental/newrelic-entity-cmdb-ci-sync/issues/22,1.0,2021-03-30T01:47:23Z,NONE,https://api.github.com/repos/newrelic-experimental/newrelic-entity-cmdb-ci-sync,Backstage Newrelic and ServiceNow Processor,"Cool project, not sure if you heard of Backstage but just wanted to share that this would make two great processors for backstage where you would be able to ingest and sync data from Newrelic, ServiceNow along with the already prebuilt processors: GitHub, Gitlab, Bitbucket, Active Directory/LDAP, MicrosoftGraphAPI, AWS ... can check them out here: https://github.com/backstage/backstage/tree/master/plugins/catalog-backend/src/ingestion/processors

Processors- https://backstage.io/docs/features/software-catalog/configuration#processors

Cheers!

[NOTE]: # ( ^^ Provide a general summary of the request in the title above. ^^ )

## Summary

[NOTE]: # ( Provide a brief overview of what the new feature is all about. )

## Desired Behavior

[NOTE]: # ( Tell us how the new feature should work. Be specific. )
[TIP]:  # ( Do NOT give us access or passwords to your New Relic account or API keys! )

## Possible Solution

[NOTE]: # ( Not required. Suggest how to implement the addition or change. )

## Additional context

[TIP]:  # ( Why does this feature matter to you? What unique circumstances do you have? )
","Backstage Newrelic and ServiceNow Processor Cool project, not sure if you heard of Backstage but just wanted to share that this would make two great processors for backstage where you would be able to ingest and sync data from Newrelic, ServiceNow along with the already prebuilt processors: GitHub, Gitlab, Bitbucket, Active Directory/LDAP, MicrosoftGraphAPI, AWS ... can check them out here: https://github.com/backstage/backstage/tree/master/plugins/catalog-backend/src/ingestion/processors Processors- https://backstage.io/docs/features/software-catalog/configuration#processors Cheers! [NOTE]: # ( ^^ Provide a general summary of the request in the title above. ^^ ) ## Summary [NOTE]: # ( Provide a brief overview of what the new feature is all about. ) ## Desired Behavior [NOTE]: # ( Tell us how the new feature should work. Be specific. ) [TIP]: # ( Do NOT give us access or passwords to your New Relic account or API keys! ) ## Possible Solution [NOTE]: # ( Not required. Suggest how to implement the addition or change. ) ## Additional context [TIP]: # ( Why does this feature matter to you? What unique circumstances do you have? ) "
213356,213356,237250,https://api.github.com/repos/assimbly/gateway/issues/474,0.0,2021-03-06T08:32:28Z,OWNER,https://api.github.com/repos/assimbly/gateway,Stats don't work,In the alpha the stats don't work (nothing is showed and an error shows in the log,Stats don't work In the alpha the stats don't work (nothing is showed and an error shows in the log
562889,562889,625550,https://api.github.com/repos/badasintended/slotlink/issues/72,0.0,2021-02-08T18:01:47Z,NONE,https://api.github.com/repos/badasintended/slotlink,Server crash when open re,"**Setup**
- Minecraft: 1.16.5
- Fabric API: 0.30.0
- slotlink: 2.2.0

**Problem**
[crash-2021-02-08_17.59.00-server.txt](https://github.com/badasintended/slotlink/files/5945754/crash-2021-02-08_17.59.00-server.txt)
",Server crash when open re **Setup** - Minecraft: 1.16.5 - Fabric API: 0.30.0 - slotlink: 2.2.0 **Problem** [crash-2021-02-08_17.59.00-server.txt](https://github.com/badasintended/slotlink/files/5945754/crash-2021-02-08_17.59.00-server.txt) 
436833,436833,485632,https://api.github.com/repos/bryntum/support/issues/2716,0.0,2021-04-21T10:51:27Z,MEMBER,https://api.github.com/repos/bryntum/support,Support for async finalization of RowReorder drag operation,"```       
 const result = await me.validate(event);
```
[Forum post](https://www.bryntum.com/forum/viewtopic.php?f=52&t=17281&p=85743#p85743)

Hi, 

Is it possible to show a popup confirmation before applying Vertical Drag?
We have added the below code to the advanced demo: (https://bryntum.com/examples/gantt/advanced/)


```
import { MessageDialog } from '../../build/gantt.module.js?449267';

```

And for the gantt configs, under features, we have added the below code:

```
rowReorder: {
    listeners: {
        async gridRowBeforeDropFinalize(source) {
            source.context.async = true;
            const
            result        = await MessageDialog.confirm({
                title   : 'Please confirm',
                message : 'Allow this operation?'
            });

        // true to accept the changes or false to reject them
        source.context.finalize(result === MessageDialog.yesButton);
    }                
},
},

```

The change goes through irrespective of the option selected.
Any thoughts / suggestions?

Thanks,
Nagaraju","Support for async finalization of RowReorder drag operation ``` const result = await me.validate(event); ``` [Forum post](https://www.bryntum.com/forum/viewtopic.php?f=52&t=17281&p=85743#p85743) Hi, Is it possible to show a popup confirmation before applying Vertical Drag? We have added the below code to the advanced demo: (https://bryntum.com/examples/gantt/advanced/) ``` import { MessageDialog } from '../../build/gantt.module.js?449267'; ``` And for the gantt configs, under features, we have added the below code: ``` rowReorder: { listeners: { async gridRowBeforeDropFinalize(source) { source.context.async = true; const result = await MessageDialog.confirm({ title : 'Please confirm', message : 'Allow this operation?' }); // true to accept the changes or false to reject them source.context.finalize(result === MessageDialog.yesButton); } }, }, ``` The change goes through irrespective of the option selected. Any thoughts / suggestions? Thanks, Nagaraju"
535499,535499,595170,https://api.github.com/repos/jazzband/django-configurations/issues/278,1.0,2021-02-01T16:39:45Z,NONE,https://api.github.com/repos/jazzband/django-configurations,Make new releases on github,"I found myself moving away from using django-configurations over 2020, because every time I looked at the front page of the repo, I saw:

![image](https://user-images.githubusercontent.com/163359/106488757-a65f0e80-6479-11eb-95b9-a109d3157ff3.png)

I tend towards avoidance of libraries that don't get much maintenance, and this kept tripping me up!","Make new releases on github I found myself moving away from using django-configurations over 2020, because every time I looked at the front page of the repo, I saw: ![image](https://user-images.githubusercontent.com/163359/106488757-a65f0e80-6479-11eb-95b9-a109d3157ff3.png) I tend towards avoidance of libraries that don't get much maintenance, and this kept tripping me up!"
505254,505254,561574,https://api.github.com/repos/thematters/matters-web/issues/1836,0.0,2021-03-01T09:59:58Z,CONTRIBUTOR,https://api.github.com/repos/thematters/matters-web,Adjust size and cropped dimension of Circle cover,,Adjust size and cropped dimension of Circle cover 
624797,624797,694354,https://api.github.com/repos/SoftEng701-Group5/assignment1/issues/204,0.0,2021-03-24T06:02:08Z,CONTRIBUTOR,https://api.github.com/repos/SoftEng701-Group5/assignment1,Close sort by list on Task Board,"When a selection is made by clicking an option in the sort by list on the task board, the list doesn't automatically close. It also doesn't close when somewhere else on the screen is clicked. ","Close sort by list on Task Board When a selection is made by clicking an option in the sort by list on the task board, the list doesn't automatically close. It also doesn't close when somewhere else on the screen is clicked. "
140358,140358,156005,https://api.github.com/repos/gpuweb/gpuweb/issues/1443,2.0,2021-02-17T21:45:00Z,NONE,https://api.github.com/repos/gpuweb/gpuweb,Does this work on Linux because I can't really get it to work,See: https://bugzilla.mozilla.org/show_bug.cgi?id=1693398,Does this work on Linux because I can't really get it to work See: https://bugzilla.mozilla.org/show_bug.cgi?id=1693398
217281,217281,241617,https://api.github.com/repos/hashicorp/terraform-provider-google/issues/8322,1.0,2021-01-28T09:36:06Z,NONE,https://api.github.com/repos/hashicorp/terraform-provider-google,google_compute_instance_group is missing subnetwork field,"<!--- Please leave this line, it helps our automation: [issue-type:enhancement] --->
<!--- Please keep this note for the community --->

### Community Note

* Please vote on this issue by adding a  [reaction](https://blog.github.com/2016-03-10-add-reactions-to-pull-requests-issues-and-comments/) to the original issue to help the community and maintainers prioritize this request
* Please do not leave ""+1"" or ""me too"" comments, they generate extra noise for issue followers and do not help prioritize the request
* If you are interested in working on this issue or have submitted a pull request, please leave a comment. If the issue is assigned to the ""modular-magician"" user, it is either in the process of being autogenerated, or is planned to be autogenerated soon. If the issue is assigned to a user, that user is claiming responsibility for the issue. If the issue is assigned to ""hashibot"", a community member has claimed the issue already.

<!--- Thank you for keeping this note for the community --->

### Description

<!--- Please leave a helpful description of the feature request here. Including use cases and why it would help you is a great way to convince maintainers to spend time on it. --->
The subnetwork-parameter is missing for this resource, as per the API-description: https://cloud.google.com/compute/docs/reference/rest/v1/instanceGroups/insert

### New or Affected Resource(s)

<!--- Please list the new or affected resources and data sources. --->

* google_compute_instance_group

### Potential Terraform Configuration

<!--- Information about code formatting: https://help.github.com/articles/basic-writing-and-formatting-syntax/#quoting-code --->

```tf
resource ""google_compute_instance_group"" ""http"" {
  name        = ""mygroup""
  network     = ""mynet""
  subnetwork = ""mysubnet""
  zone        = ""us-central-1-a""
  named_port {
    name = ""http""
    port = 80
  }
}
```

### References

<!---
Information about referencing Github Issues: https://help.github.com/articles/basic-writing-and-formatting-syntax/#referencing-issues-and-pull-requests

Are there any other GitHub issues (open or closed) or pull requests that should be linked here? Vendor blog posts or documentation?
--->

* #0000
","google_compute_instance_group is missing subnetwork field <!--- Please leave this line, it helps our automation: [issue-type:enhancement] ---> <!--- Please keep this note for the community ---> ### Community Note * Please vote on this issue by adding a  [reaction](https://blog.github.com/2016-03-10-add-reactions-to-pull-requests-issues-and-comments/) to the original issue to help the community and maintainers prioritize this request * Please do not leave ""+1"" or ""me too"" comments, they generate extra noise for issue followers and do not help prioritize the request * If you are interested in working on this issue or have submitted a pull request, please leave a comment. If the issue is assigned to the ""modular-magician"" user, it is either in the process of being autogenerated, or is planned to be autogenerated soon. If the issue is assigned to a user, that user is claiming responsibility for the issue. If the issue is assigned to ""hashibot"", a community member has claimed the issue already. <!--- Thank you for keeping this note for the community ---> ### Description <!--- Please leave a helpful description of the feature request here. Including use cases and why it would help you is a great way to convince maintainers to spend time on it. ---> The subnetwork-parameter is missing for this resource, as per the API-description: https://cloud.google.com/compute/docs/reference/rest/v1/instanceGroups/insert ### New or Affected Resource(s) <!--- Please list the new or affected resources and data sources. ---> * google_compute_instance_group ### Potential Terraform Configuration <!--- Information about code formatting: https://help.github.com/articles/basic-writing-and-formatting-syntax/#quoting-code ---> ```tf resource ""google_compute_instance_group"" ""http"" { name = ""mygroup"" network = ""mynet"" subnetwork = ""mysubnet"" zone = ""us-central-1-a"" named_port { name = ""http"" port = 80 } } ``` ### References <!--- Information about referencing Github Issues: https://help.github.com/articles/basic-writing-and-formatting-syntax/#referencing-issues-and-pull-requests Are there any other GitHub issues (open or closed) or pull requests that should be linked here? Vendor blog posts or documentation? ---> * #0000 "
611886,611886,679983,https://api.github.com/repos/microsoft/vscode/issues/122407,0.0,2021-04-27T17:24:39Z,MEMBER,https://api.github.com/repos/microsoft/vscode,Can't Ctrl+Enter to execute notebook cell,"Testing #122263

Maybe I'm missing something (since I don't think I usually ctrl+enter to run notebook cells), but I can't seem to get ctrl+enter to run my cells. It either just does a normal enter if I'm focused on the code within the cell, or creates a new cell if I focus outside of it. See gif below.

![recording (13)](https://user-images.githubusercontent.com/25310137/116284996-8e2e2100-a742-11eb-80ab-9e489bb82f82.gif)

If I've missed something/this is user error, please feel free to close.
","Can't Ctrl+Enter to execute notebook cell Testing #122263 Maybe I'm missing something (since I don't think I usually ctrl+enter to run notebook cells), but I can't seem to get ctrl+enter to run my cells. It either just does a normal enter if I'm focused on the code within the cell, or creates a new cell if I focus outside of it. See gif below. ![recording (13)](https://user-images.githubusercontent.com/25310137/116284996-8e2e2100-a742-11eb-80ab-9e489bb82f82.gif) If I've missed something/this is user error, please feel free to close. "
74729,74729,83090,https://api.github.com/repos/Daimler/sechub/issues/496,0.0,2020-12-17T14:18:36Z,CONTRIBUTOR,https://api.github.com/repos/Daimler/sechub,Flakey test `RoutesTest.java`,"In Java 11 and 15 the RoutesTest.java sometimes does not work and sometimes does work. It behaves flakey.

~~~
com.daimler.sechub.test.RoutesTest > routes_assigned_to_right_roles FAILED
    java.util.ConcurrentModificationException at RoutesTest.java:144
~~~

---
<sup>Jeremias Eppler <jeremias.eppler@daimler.com>, Daimler TSS GmbH, [imprint](https://github.com/Daimler/daimler-foss/blob/master/LEGAL_IMPRINT.md)</sup>","Flakey test `RoutesTest.java` In Java 11 and 15 the RoutesTest.java sometimes does not work and sometimes does work. It behaves flakey. ~~~ com.daimler.sechub.test.RoutesTest > routes_assigned_to_right_roles FAILED java.util.ConcurrentModificationException at RoutesTest.java:144 ~~~ --- <sup>Jeremias Eppler <jeremias.eppler@daimler.com>, Daimler TSS GmbH, [imprint](https://github.com/Daimler/daimler-foss/blob/master/LEGAL_IMPRINT.md)</sup>"
513574,513574,570735,https://api.github.com/repos/maldwg/shares/issues/4,1.0,2021-02-16T21:22:53Z,OWNER,https://api.github.com/repos/maldwg/shares,Datenbank anbinden,,Datenbank anbinden 
220201,220201,244878,https://api.github.com/repos/pimcore/pimcore/issues/8586,0.0,2021-03-26T15:42:19Z,COLLABORATOR,https://api.github.com/repos/pimcore/pimcore,UrlSlug broken in Classification store,"UrlSlug does not implement ResourcePersistenceAwareInterface

see https://github.com/pimcore/pimcore/blob/1bf4518a42e4b33c31f6ab0203ac575db39e7c79/models/DataObject/Classificationstore.php#L203",UrlSlug broken in Classification store UrlSlug does not implement ResourcePersistenceAwareInterface see https://github.com/pimcore/pimcore/blob/1bf4518a42e4b33c31f6ab0203ac575db39e7c79/models/DataObject/Classificationstore.php#L203
627718,627718,697596,https://api.github.com/repos/spelunky-fyi/Playlunky/issues/6,0.0,2021-03-09T19:45:20Z,NONE,https://api.github.com/repos/spelunky-fyi/Playlunky,char_character_full sticker issues,"when loading a char_character_full via playlunky, everything works as expected, however, autogenerated stickers for other characters no longer work, making me a tad bit confused as to which characters i have installed or not. Thanks for all of your amazing work!","char_character_full sticker issues when loading a char_character_full via playlunky, everything works as expected, however, autogenerated stickers for other characters no longer work, making me a tad bit confused as to which characters i have installed or not. Thanks for all of your amazing work!"
103685,103685,115219,https://api.github.com/repos/junwoo1519/portfolio/issues/3,1.0,2021-02-18T13:24:36Z,OWNER,https://api.github.com/repos/junwoo1519/portfolio,about section 異媛,,about section 異媛 
467959,467959,520087,https://api.github.com/repos/Romitou/MongoSK/issues/17,1.0,2021-02-06T16:59:51Z,NONE,https://api.github.com/repos/Romitou/MongoSK,Sort Collection Expression/Effect,"An expression in which you can sort a collection and get the result, this would be very useful for getting top players depending on a certain index and value.

Example Syntax: `[mongo] sort collection %collection% by %string% from (highest to lowest|lowest to highest)`
Example Usage: 
````
set {_sort::*} to sort collection {_collection} by ""balance"" from highest to lowest
loop 3 times:
    send ""%loop-value%. %{_sort::%loop-value%}%"" to {_player}","Sort Collection Expression/Effect An expression in which you can sort a collection and get the result, this would be very useful for getting top players depending on a certain index and value. Example Syntax: `[mongo] sort collection %collection% by %string% from (highest to lowest|lowest to highest)` Example Usage: ```` set {_sort::*} to sort collection {_collection} by ""balance"" from highest to lowest loop 3 times: send ""%loop-value%. %{_sort::%loop-value%}%"" to {_player}"
798922,798922,758459,https://api.github.com/repos/baking-bad/pytezos/issues/161,0.0,2021-03-02T09:00:24Z,COLLABORATOR,https://api.github.com/repos/baking-bad/pytezos,activate_account fails with not informative message when local node is not ready,"```
>>> pytezos.activate_account().autofill().sign()

---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
<ipython-input-3-2e38160b4e63> in <module>
----> 1 pytezos.activate_account().autofill().sign()

~/git/pytezos/pytezos/jupyter.py in __call__(self, *args, **kwargs)
     62 
     63                 def __call__(self, *args, **kwargs):
---> 64                     return method(self.class_instance, *args, **kwargs)
     65 
     66                 def __repr__(self):

~/git/pytezos/pytezos/operation/group.py in autofill(self, gas_reserve, counter, branch_offset)
    175         :rtype: OperationGroup
    176         """"""
--> 177         opg = self.fill(counter=counter, branch_offset=branch_offset)
    178         opg_with_metadata = opg.run()
    179         if not OperationResult.is_applied(opg_with_metadata):

~/git/pytezos/pytezos/jupyter.py in __call__(self, *args, **kwargs)
     62 
     63                 def __call__(self, *args, **kwargs):
---> 64                     return method(self.class_instance, *args, **kwargs)
     65 
     66                 def __repr__(self):

~/git/pytezos/pytezos/operation/group.py in fill(self, counter, branch_offset)
     99         assert 0 < branch_offset < 60, f'branch offset has to be in range (0, 60)'
    100         chain_id = self.chain_id or self.context.get_chain_id()
--> 101         branch = self.branch or self.shell.blocks[-branch_offset].hash()
    102         protocol = self.protocol or self.shell.head.header()['protocol']
    103         source = self.key.public_key_hash()

~/git/pytezos/pytezos/rpc/protocol.py in __getitem__(self, block_id)
     72 
     73         if isinstance(block_id, int) and block_id < 0:
---> 74             head_level = self._get_block('head').level()
     75             block_id = max(0, head_level + block_id)
     76 

~/git/pytezos/pytezos/jupyter.py in __call__(self, *args, **kwargs)
     62 
     63                 def __call__(self, *args, **kwargs):
---> 64                     return method(self.class_instance, *args, **kwargs)
     65 
     66                 def __repr__(self):

~/git/pytezos/pytezos/rpc/protocol.py in level(self)
    134         """""" Get level for this block from metadata.
    135         """"""
--> 136         return self.metadata()['level']['level']
    137 
    138     def cycle(self) -> int:

KeyError: 'level'

```","activate_account fails with not informative message when local node is not ready ``` >>> pytezos.activate_account().autofill().sign() --------------------------------------------------------------------------- KeyError Traceback (most recent call last) <ipython-input-3-2e38160b4e63> in <module> ----> 1 pytezos.activate_account().autofill().sign() ~/git/pytezos/pytezos/jupyter.py in __call__(self, *args, **kwargs) 62 63 def __call__(self, *args, **kwargs): ---> 64 return method(self.class_instance, *args, **kwargs) 65 66 def __repr__(self): ~/git/pytezos/pytezos/operation/group.py in autofill(self, gas_reserve, counter, branch_offset) 175 :rtype: OperationGroup 176 """""" --> 177 opg = self.fill(counter=counter, branch_offset=branch_offset) 178 opg_with_metadata = opg.run() 179 if not OperationResult.is_applied(opg_with_metadata): ~/git/pytezos/pytezos/jupyter.py in __call__(self, *args, **kwargs) 62 63 def __call__(self, *args, **kwargs): ---> 64 return method(self.class_instance, *args, **kwargs) 65 66 def __repr__(self): ~/git/pytezos/pytezos/operation/group.py in fill(self, counter, branch_offset) 99 assert 0 < branch_offset < 60, f'branch offset has to be in range (0, 60)' 100 chain_id = self.chain_id or self.context.get_chain_id() --> 101 branch = self.branch or self.shell.blocks[-branch_offset].hash() 102 protocol = self.protocol or self.shell.head.header()['protocol'] 103 source = self.key.public_key_hash() ~/git/pytezos/pytezos/rpc/protocol.py in __getitem__(self, block_id) 72 73 if isinstance(block_id, int) and block_id < 0: ---> 74 head_level = self._get_block('head').level() 75 block_id = max(0, head_level + block_id) 76 ~/git/pytezos/pytezos/jupyter.py in __call__(self, *args, **kwargs) 62 63 def __call__(self, *args, **kwargs): ---> 64 return method(self.class_instance, *args, **kwargs) 65 66 def __repr__(self): ~/git/pytezos/pytezos/rpc/protocol.py in level(self) 134 """""" Get level for this block from metadata. 135 """""" --> 136 return self.metadata()['level']['level'] 137 138 def cycle(self) -> int: KeyError: 'level' ```"
34742,34742,38729,https://api.github.com/repos/kjcain/libtask/issues/4,1.0,2021-02-03T14:47:08Z,OWNER,https://api.github.com/repos/kjcain/libtask,initial testing,implementing an initial version of tests,initial testing implementing an initial version of tests
723656,723656,7166,https://api.github.com/repos/panther-labs/panther/issues/281,1.0,2020-02-25T22:16:30Z,MEMBER,https://api.github.com/repos/panther-labs/panther,Apply Rules/Policies on Specific Account/Log Sources,"### Describe the ideal solution

Allow rules and policies to be applied against certain accounts or log sources. This provides a filtering mechanism that doesn't have to be explicitly written out in the analysis logic.

### Describe your use cases

Avoid detections in non-production accounts

### How frequently would you use such a feature

Daily!

### Describe alternatives you have considered

The alternative is writing the logic into the Python function body

### References

None
",Apply Rules/Policies on Specific Account/Log Sources ### Describe the ideal solution Allow rules and policies to be applied against certain accounts or log sources. This provides a filtering mechanism that doesn't have to be explicitly written out in the analysis logic. ### Describe your use cases Avoid detections in non-production accounts ### How frequently would you use such a feature Daily! ### Describe alternatives you have considered The alternative is writing the logic into the Python function body ### References None 
478458,478458,531741,https://api.github.com/repos/Codeinwp/feedzy-rss-feeds/issues/536,0.0,2021-04-26T09:26:52Z,NONE,https://api.github.com/repos/Codeinwp/feedzy-rss-feeds,custom fields name and value not saved,"### Description:
<!-- Describe the bug in a clear and concise way. -->
After creating the custom fields, neither name nor value is saved in the import settings after you re-open it again 

### How to reproduce:
<!-- Describe the steps needed to reproduce this. -->
1. Create an import job
2. Add custom fields 
3. Save it and try to edit it again

### Expected behaviour:
The custom field should save the field name and its value

### Current behaviour:
The custom field is not saved 

### Reference:
<!-- Screenshots and links that show the bug -->
Screencast: https://vertis.d.pr/qdJuue

### Technical info
* WordPress version: 5.7.1
* Plugin version: 3.6.2","custom fields name and value not saved ### Description: <!-- Describe the bug in a clear and concise way. --> After creating the custom fields, neither name nor value is saved in the import settings after you re-open it again ### How to reproduce: <!-- Describe the steps needed to reproduce this. --> 1. Create an import job 2. Add custom fields 3. Save it and try to edit it again ### Expected behaviour: The custom field should save the field name and its value ### Current behaviour: The custom field is not saved ### Reference: <!-- Screenshots and links that show the bug --> Screencast: https://vertis.d.pr/qdJuue ### Technical info * WordPress version: 5.7.1 * Plugin version: 3.6.2"
788686,788686,656794,https://api.github.com/repos/FlashHit/VEXT-Mods/issues/3,1.0,2021-01-07T06:50:22Z,OWNER,https://api.github.com/repos/FlashHit/VEXT-Mods,Adjust fov to client settings ,,Adjust fov to client settings 
336059,336059,373582,https://api.github.com/repos/Mi-Lan/dxDaoBlog/issues/2,1.0,2021-01-13T19:08:23Z,NONE,https://api.github.com/repos/Mi-Lan/dxDaoBlog,Configure categories with required information,"As far as formatting of categories, we are ready to move along with implementation. I do not expect these to be final, but rather close to it - and I would like to start formatting and including relevant information shortly.

Attached is a [link to show the desired categories](https://www.figma.com/file/GJHVXRV1s4VRhwgNOM8bNu/Book-Basic-Layout?node-id=0%3A1), and below I have included the raw text as well as notes regarding their implementation.

>**DXdao**

>Governance 截
>REP
>Daotalk
>Snapshot
>Alchemy

>Products 
>Swapr
>Roadmap
>Website http://swapr.eth.link/#/swap
>Omen
>Market Resolution Rules
>Roadmap
>Website https://omen.eth.link/#/liquidity
>Mesa
>Website https://mesa.eth.link/
>Rails
>Website https://rails.eth.link/
>Other

>DXD

>FAQ 

>Contributor Hub
>Our Philosophy
>Open Positions and Bounties
>Employment
>Worker Compensation
>Worker Proposals
>Performance and Career Development
>Vacation and Holidays
>Discrimination and Harassment
>Decentralized Communication Technologies 
>Standards of Conduct

>Meetings

>Branding Assets 

>Get Connected
>Website https://dxdao.eth.link/#/
>Twitter https://twitter.com/Dxdao_
>Discord https://discord.gg/4QXEJQkvHH
>Medium https://dxdao.medium.com/
>Etherscan https://etherscan.io/token/0xa1d65E8fB6e87b60FECCBc582F7f97804B725521
>Telegram https://t.me/dxDAO
>Forum https://daotalk.org/c/dx-dao/15



Quick notes,

1. ""DXdao"" is the largest category, but it doesn't make sense to expand/minimize this. Having it as a serperate ""welcome"" page will be the route we take. 

2. Blue text under ""get connected"" would act as links, these will be non-expandable and directly take you to the noted social. (The proper links are included in the above raw text)

3. ""Website"" under each respective product will likely end up similar to the get connected tab, where there are many external links with no internal information. I have input only website for the time being, and when we are near completion any additional links can be added.

4. Indents are internal categories (EG, Governance can be clicked on for its information, or expanded. REP Daotalk Snapshot and Alchemy would all be found after expanding the Governance tab.) 


If anything here is at all confusing just ask and I can explain in more detail or hop in a quick call.

","Configure categories with required information As far as formatting of categories, we are ready to move along with implementation. I do not expect these to be final, but rather close to it - and I would like to start formatting and including relevant information shortly. Attached is a [link to show the desired categories](https://www.figma.com/file/GJHVXRV1s4VRhwgNOM8bNu/Book-Basic-Layout?node-id=0%3A1), and below I have included the raw text as well as notes regarding their implementation. >**DXdao** >Governance 截 >REP >Daotalk >Snapshot >Alchemy >Products >Swapr >Roadmap >Website http://swapr.eth.link/#/swap >Omen >Market Resolution Rules >Roadmap >Website https://omen.eth.link/#/liquidity >Mesa >Website https://mesa.eth.link/ >Rails >Website https://rails.eth.link/ >Other >DXD >FAQ >Contributor Hub >Our Philosophy >Open Positions and Bounties >Employment >Worker Compensation >Worker Proposals >Performance and Career Development >Vacation and Holidays >Discrimination and Harassment >Decentralized Communication Technologies >Standards of Conduct >Meetings >Branding Assets >Get Connected >Website https://dxdao.eth.link/#/ >Twitter https://twitter.com/Dxdao_ >Discord https://discord.gg/4QXEJQkvHH >Medium https://dxdao.medium.com/ >Etherscan https://etherscan.io/token/0xa1d65E8fB6e87b60FECCBc582F7f97804B725521 >Telegram https://t.me/dxDAO >Forum https://daotalk.org/c/dx-dao/15 Quick notes, 1. ""DXdao"" is the largest category, but it doesn't make sense to expand/minimize this. Having it as a serperate ""welcome"" page will be the route we take. 2. Blue text under ""get connected"" would act as links, these will be non-expandable and directly take you to the noted social. (The proper links are included in the above raw text) 3. ""Website"" under each respective product will likely end up similar to the get connected tab, where there are many external links with no internal information. I have input only website for the time being, and when we are near completion any additional links can be added. 4. Indents are internal categories (EG, Governance can be clicked on for its information, or expanded. REP Daotalk Snapshot and Alchemy would all be found after expanding the Governance tab.) If anything here is at all confusing just ask and I can explain in more detail or hop in a quick call. "
742172,742172,191507,https://api.github.com/repos/DumbDogDiner/StickySurvival/issues/5,1.0,2021-02-23T20:56:40Z,COLLABORATOR,https://api.github.com/repos/DumbDogDiner/StickySurvival,(feat): Event Support,"## Implemented Events
- TributeAddEvent
  *tested with*
  - `/sg join`

- TributeRemoveEvent
  *tested with*
  - player death
  - player disconnect
  - `/sg leave`
 
 
 ## Future To-Dos
 
 - [ ] Shuffle event calls around so we can make them cancellable",(feat): Event Support ## Implemented Events - TributeAddEvent *tested with* - `/sg join` - TributeRemoveEvent *tested with* - player death - player disconnect - `/sg leave` ## Future To-Dos - [ ] Shuffle event calls around so we can make them cancellable
333146,333146,370354,https://api.github.com/repos/pollen-robotics/Luos-modules/issues/22,1.0,2021-02-15T10:12:31Z,MEMBER,https://api.github.com/repos/pollen-robotics/Luos-modules,Add message for dynamixel detection,,Add message for dynamixel detection 
125202,125202,139132,https://api.github.com/repos/UndefinedOffset/eclipse-silverstripedt/issues/80,0.0,2019-08-27T13:20:31Z,OWNER,https://api.github.com/repos/UndefinedOffset/eclipse-silverstripedt,Language library includes the current project,Looks like the language library for SilverStripe 4 is including the current project when it really shouldn't.,Language library includes the current project Looks like the language library for SilverStripe 4 is including the current project when it really shouldn't.
486085,486085,540232,https://api.github.com/repos/eclipsesource/jsonforms/issues/1697,0.0,2021-02-18T08:48:38Z,CONTRIBUTOR,https://api.github.com/repos/eclipsesource/jsonforms,'Required' validation errors within anyOf/oneOf are incorrectly filtered,"**Describe the bug**
You have an `anyOf` or `oneOf` block in your schema that contains a schema describing an `object` with `required` properties.
If such a required property is not set, the validation error will not be displayed on the corresponding control.
This is the case because the error is incorrectly filtered in [packages/core/src/reducers/core.ts](https://github.com/eclipsesource/jsonforms/blob/master/packages/core/src/reducers/core.ts).
The `errorsAt` method filters all errors that are contained in an `anyOf` or `oneOf` and whose `parentSchema` does not match the property's schema. This is the case for `required` because it is defined on the property parent object's schema.

**To Reproduce**
Edit the `oneOf` example to have required properties, run the example (e.g. in material), and remove one of the required properties' values. You'd expect to see an error but nothing is shown.

**Expected behavior**
The `required` error is not filtered.

**Possible fix**
In `errorsAt` check for errors with keyword `required` and never filter them.","'Required' validation errors within anyOf/oneOf are incorrectly filtered **Describe the bug** You have an `anyOf` or `oneOf` block in your schema that contains a schema describing an `object` with `required` properties. If such a required property is not set, the validation error will not be displayed on the corresponding control. This is the case because the error is incorrectly filtered in [packages/core/src/reducers/core.ts](https://github.com/eclipsesource/jsonforms/blob/master/packages/core/src/reducers/core.ts). The `errorsAt` method filters all errors that are contained in an `anyOf` or `oneOf` and whose `parentSchema` does not match the property's schema. This is the case for `required` because it is defined on the property parent object's schema. **To Reproduce** Edit the `oneOf` example to have required properties, run the example (e.g. in material), and remove one of the required properties' values. You'd expect to see an error but nothing is shown. **Expected behavior** The `required` error is not filtered. **Possible fix** In `errorsAt` check for errors with keyword `required` and never filter them."
261370,261370,290688,https://api.github.com/repos/pavedroad-io/roadctl/issues/114,0.0,2020-11-24T18:03:18Z,CONTRIBUTOR,https://api.github.com/repos/pavedroad-io/roadctl,Remove darwin/386 builds from template Makefiles,32 bit macOS no longer supported as of go 1.15,Remove darwin/386 builds from template Makefiles 32 bit macOS no longer supported as of go 1.15
199982,199982,222364,https://api.github.com/repos/Caeli-technologies/rotary_nl_rye/issues/9,0.0,2021-05-05T18:17:12Z,MEMBER,https://api.github.com/repos/Caeli-technologies/rotary_nl_rye,firebase_analytics iOS not working,"**Describe the bug**
apple doesn't allow firebase_analytics yet. so we will wait with adding it



**Smartphone:**
 - Device: Iphone 12 Pro Max
 - OS:  iOS14.5

**Additional context**
Add any other context about the problem here.
",firebase_analytics iOS not working **Describe the bug** apple doesn't allow firebase_analytics yet. so we will wait with adding it **Smartphone:** - Device: Iphone 12 Pro Max - OS: iOS14.5 **Additional context** Add any other context about the problem here. 
513384,513384,570527,https://api.github.com/repos/rstudio/rstudio/issues/6825,0.0,2020-05-07T00:09:01Z,NONE,https://api.github.com/repos/rstudio/rstudio,"New file names repeat (Untitled1, Untitled1, etc.) when the 1st file is torn from the source pane of the main IDE window before the creation of the 2nd file.","<!--
IMPORTANT: Please fill out this template fully! Failure to do so will result in the issue being closed automatically.

This issue tracker is for bugs and feature requests in the RStudio IDE. If you're having trouble with R itself or an R package, see https://www.r-project.org/help.html, and if you want to ask a question rather than report a bug, go to https://community.rstudio.com/. Finally, if you use RStudio Server Pro, get in touch with our Pro support team at support@rstudio.com.
-->

### System details

    RStudio Edition : Desktop
    RStudio Version : Version 1.3.957-1
    OS Version      : Windows 10 Pro
    R Version       : 3.6.3

### Steps to reproduce the problem

1. Open the IDE > open a new R Script file.
2. Tear the file from the source pane into its own RStudio Source Editor window.
3. Open a new R Script file.

### Describe the problem in detail
The new file will be named Untitled1 as will the 1st file created and then torn from the source pane. Had the two files been created in the source pane of the main IDE window, one would be named Untitled1 and the other Untitled2.
![NamingIncrementation](https://user-images.githubusercontent.com/62304541/81240327-bc17d400-8fcc-11ea-8ef0-5e0740df17e9.PNG)


### Describe the behavior you expected
New file names continue to increment even when one of the files is in its own source editor window.

<!-- 
Please keep the below portion in your issue, and check `[x]` the applicable boxes.
-->

- [x] I have read the guide to submitting good bug reports at https://github.com/rstudio/rstudio/wiki/Writing-Good-Bug-Reports . 
- [x] I have installed the latest version of RStudio and confirmed that the issue still persists.
- [ ] If I am reporting a RStudio crash, I have included a diagnostics report. https://support.rstudio.com/hc/en-us/articles/200321257-Running-a-Diagnostics-Report
- [x] I have done my best to include a minimal, self-contained set of instructions for consistently reproducing the issue.

","New file names repeat (Untitled1, Untitled1, etc.) when the 1st file is torn from the source pane of the main IDE window before the creation of the 2nd file. <!-- IMPORTANT: Please fill out this template fully! Failure to do so will result in the issue being closed automatically. This issue tracker is for bugs and feature requests in the RStudio IDE. If you're having trouble with R itself or an R package, see https://www.r-project.org/help.html, and if you want to ask a question rather than report a bug, go to https://community.rstudio.com/. Finally, if you use RStudio Server Pro, get in touch with our Pro support team at support@rstudio.com. --> ### System details RStudio Edition : Desktop RStudio Version : Version 1.3.957-1 OS Version : Windows 10 Pro R Version : 3.6.3 ### Steps to reproduce the problem 1. Open the IDE > open a new R Script file. 2. Tear the file from the source pane into its own RStudio Source Editor window. 3. Open a new R Script file. ### Describe the problem in detail The new file will be named Untitled1 as will the 1st file created and then torn from the source pane. Had the two files been created in the source pane of the main IDE window, one would be named Untitled1 and the other Untitled2. ![NamingIncrementation](https://user-images.githubusercontent.com/62304541/81240327-bc17d400-8fcc-11ea-8ef0-5e0740df17e9.PNG) ### Describe the behavior you expected New file names continue to increment even when one of the files is in its own source editor window. <!-- Please keep the below portion in your issue, and check `[x]` the applicable boxes. --> - [x] I have read the guide to submitting good bug reports at https://github.com/rstudio/rstudio/wiki/Writing-Good-Bug-Reports . - [x] I have installed the latest version of RStudio and confirmed that the issue still persists. - [ ] If I am reporting a RStudio crash, I have included a diagnostics report. https://support.rstudio.com/hc/en-us/articles/200321257-Running-a-Diagnostics-Report - [x] I have done my best to include a minimal, self-contained set of instructions for consistently reproducing the issue. "
748550,748550,254550,https://api.github.com/repos/lnjim/tpgitesgi/issues/5,1.0,2021-02-04T17:22:38Z,COLLABORATOR,https://api.github.com/repos/lnjim/tpgitesgi,Compl챕tion du CSS (1),"Compl챕ter le fichier style : 
- STEPS",Compl챕tion du CSS (1) Compl챕ter le fichier style : - STEPS
237845,237845,264556,https://api.github.com/repos/scalameta/nvim-metals/issues/107,0.0,2021-03-11T14:07:23Z,MEMBER,https://api.github.com/repos/scalameta/nvim-metals,Test output is showing color codes,"**Describe the bug**

When using the `nvim-dap` integration to test, the output in the DAP-REPL shows the color codes. There is currently no way to turn this off when using using Bloop, and the same happens when using sbt.

**To Reproduce** Steps to reproduce the behavior:

1. Integrate with nvim-dap
2. Run a test
3. Look at the output in the DAP-REPL
4. See the following

## With Bloop

<img width=""637"" alt=""Screenshot 2021-03-11 at 15 02 48"" src=""https://user-images.githubusercontent.com/13974112/110799302-50049d00-827b-11eb-9701-a2b4846d7366.png"">

## With sbt

<img width=""637"" alt=""Screenshot 2021-03-11 at 15 05 07"" src=""https://user-images.githubusercontent.com/13974112/110799324-5561e780-827b-11eb-82fc-f2d79d6f3789.png"">

**Expected behavior**

There should be a way to turn color off

**Additional context**

- There is an upstream ticket for this in Bloop: https://github.com/scalacenter/bloop/issues/1478
- [x] I need to check to see if there is a way to turn this off when using sbt BSP

**Search terms**

DAP output
","Test output is showing color codes **Describe the bug** When using the `nvim-dap` integration to test, the output in the DAP-REPL shows the color codes. There is currently no way to turn this off when using using Bloop, and the same happens when using sbt. **To Reproduce** Steps to reproduce the behavior: 1. Integrate with nvim-dap 2. Run a test 3. Look at the output in the DAP-REPL 4. See the following ## With Bloop <img width=""637"" alt=""Screenshot 2021-03-11 at 15 02 48"" src=""https://user-images.githubusercontent.com/13974112/110799302-50049d00-827b-11eb-9701-a2b4846d7366.png""> ## With sbt <img width=""637"" alt=""Screenshot 2021-03-11 at 15 05 07"" src=""https://user-images.githubusercontent.com/13974112/110799324-5561e780-827b-11eb-82fc-f2d79d6f3789.png""> **Expected behavior** There should be a way to turn color off **Additional context** - There is an upstream ticket for this in Bloop: https://github.com/scalacenter/bloop/issues/1478 - [x] I need to check to see if there is a way to turn this off when using sbt BSP **Search terms** DAP output "
725548,725548,25992,https://api.github.com/repos/Svesh1-800/web-notes/issues/4,1.0,2021-01-25T07:42:16Z,OWNER,https://api.github.com/repos/Svesh1-800/web-notes,叫閨逵 筠剋筠克棘 極龜 勻閨棘筠 克逵筠均棘龜龜,,叫閨逵 筠剋筠克棘 極龜 勻閨棘筠 克逵筠均棘龜龜 
314729,314729,349900,https://api.github.com/repos/ytdl-org/youtube-dl/issues/29041,2.0,2021-05-14T15:23:12Z,NONE,https://api.github.com/repos/ytdl-org/youtube-dl,Introducing a new feature to YouTubeDL CLI,"<!--

######################################################################
  WARNING!
  IGNORING THE FOLLOWING TEMPLATE WILL RESULT IN ISSUE CLOSED AS INCOMPLETE
######################################################################

-->


## Checklist

<!--
Carefully read and work through this check list in order to prevent the most common mistakes and misuse of youtube-dl:
- Look through the README (http://yt-dl.org/readme) and FAQ (http://yt-dl.org/faq) for similar questions
- Search the bugtracker for similar questions: http://yt-dl.org/search-issues
- Finally, put x into all relevant boxes (like this [x])
-->

- [x] I'm asking a question
- [x] I've looked through the README and FAQ for similar questions
- [x] I've searched the bugtracker for similar questions including closed ones


## Question

<!--
Ask your question in an arbitrary form. Please make sure it's worded well enough to be understood, see https://github.com/ytdl-org/youtube-dl#is-the-description-of-the-issue-itself-sufficient.
-->

Hello there @dstftw , 

I want to develop a new feature in command-line interface by introducing a new option argument for formatting date for the output template.

This is to clarify/inquire whether a new branch needs to be checked out (after forking the repo) by naming it as my extractor.

But since the feature will be introduced irrespective of the extractor, should it be followed as written in the **Developer Instructions** section of the README. 

Please suggest.

Thanks
Swetank (@shortthirdman)","Introducing a new feature to YouTubeDL CLI <!-- ###################################################################### WARNING! IGNORING THE FOLLOWING TEMPLATE WILL RESULT IN ISSUE CLOSED AS INCOMPLETE ###################################################################### --> ## Checklist <!-- Carefully read and work through this check list in order to prevent the most common mistakes and misuse of youtube-dl: - Look through the README (http://yt-dl.org/readme) and FAQ (http://yt-dl.org/faq) for similar questions - Search the bugtracker for similar questions: http://yt-dl.org/search-issues - Finally, put x into all relevant boxes (like this [x]) --> - [x] I'm asking a question - [x] I've looked through the README and FAQ for similar questions - [x] I've searched the bugtracker for similar questions including closed ones ## Question <!-- Ask your question in an arbitrary form. Please make sure it's worded well enough to be understood, see https://github.com/ytdl-org/youtube-dl#is-the-description-of-the-issue-itself-sufficient. --> Hello there @dstftw , I want to develop a new feature in command-line interface by introducing a new option argument for formatting date for the output template. This is to clarify/inquire whether a new branch needs to be checked out (after forking the repo) by naming it as my extractor. But since the feature will be introduced irrespective of the extractor, should it be followed as written in the **Developer Instructions** section of the README. Please suggest. Thanks Swetank (@shortthirdman)"
461181,461181,512550,https://api.github.com/repos/FreeTubeApp/FreeTube/issues/692,1.0,2020-10-19T10:34:24Z,NONE,https://api.github.com/repos/FreeTubeApp/FreeTube,Change comments font size,"**Is your feature request related to a usage problem (not a bug)? Please describe.**
The comments font size is pretty small and barely readable. I'd like to be able to change their size.

**Describe the solution you'd like to see implemented**
A parameter allowing users to change the font size.
",Change comments font size **Is your feature request related to a usage problem (not a bug)? Please describe.** The comments font size is pretty small and barely readable. I'd like to be able to change their size. **Describe the solution you'd like to see implemented** A parameter allowing users to change the font size. 
760434,760434,373740,https://api.github.com/repos/X1las/catformer/issues/34,0.0,2021-05-17T10:49:47Z,OWNER,https://api.github.com/repos/X1las/catformer,Fixes,"
- [x] Level: Fix positions of objects

- [x] Level: Last platform needs to be higher

- [x] Objects: Fix worm going under blocks it's not supposed to

- [x] Menu: Illegal character fix in new player name
",Fixes - [x] Level: Fix positions of objects - [x] Level: Last platform needs to be higher - [x] Objects: Fix worm going under blocks it's not supposed to - [x] Menu: Illegal character fix in new player name 
726737,726737,37373,https://api.github.com/repos/codeforjapan/decidim-cfj/issues/11,1.0,2020-10-19T13:05:32Z,NONE,https://api.github.com/repos/codeforjapan/decidim-cfj,HTML욍겹鵝욜ⓦャㅳ,"## 밧屋녕눗 / Details of Improvement
- 嶸←삯㏂ゃ⒲ャ╉HTML욍겹鵝욜ⓦ㎯ャ

## 밤ゃ쇈녈룔㎯ゃ / Screenshot

## 孃誤밤삥 / Expected behavior
- 嶸←담㎫삣縕쇈餓ゃ⒲烏

## 野얕괌ㅳ녈밤욍녈 / Instances
<!-- ⒲▲멥㎯밧겼ゃⓦ밤닷겼ε╉ -->
- ㅵ躍
",HTML욍겹鵝욜ⓦャㅳ ## 밧屋녕눗 / Details of Improvement - 嶸←삯㏂ゃ⒲ャ╉HTML욍겹鵝욜ⓦ㎯ャ ## 밤ゃ쇈녈룔㎯ゃ / Screenshot ## 孃誤밤삥 / Expected behavior - 嶸←담㎫삣縕쇈餓ゃ⒲烏 ## 野얕괌ㅳ녈밤욍녈 / Instances <!-- ⒲▲멥㎯밧겼ゃⓦ밤닷겼ε╉ --> - ㅵ躍 
221200,221200,245984,https://api.github.com/repos/vtex-apps/store-discussion/issues/563,0.0,2021-03-27T20:22:16Z,NONE,https://api.github.com/repos/vtex-apps/store-discussion,Getting INTERNAL_SERVER_ERROR while implementing list-context.product-list,"**Describe the bug**
I am getting a 400 error while implementing the product-list-context that says that the store is not active.

**To Reproduce**
1. Add the dependencies in the manifest
2. call the block in the home.json:
`
  ""store.home"": {
    ""blocks"": [
      ""list-context.image-list#home"",
      ""list-context.product-list#demo1"",
      ""flex-layout.row#promotional-info"",
      ""flex-layout.row#banner-home"",
      ""flex-layout.row#banner-brands"",
      ""flex-layout.row#newsletter""
    ]
  },`

2. Declare the block in the shelf.jsonc:
`{
  ""product-summary.shelf#demo1"": {
    ""children"": [
      ""product-summary-name"",
      ""product-rating-inline"",
      ""product-summary-space"",
      ""product-summary-price"",
      ""product-summary-buy-button""
    ]
  },
  ""list-context.product-list#demo1"": {
    ""blocks"": [
      ""product-summary.shelf#demo1""
    ],
    ""children"": [
      ""slider-layout#demo-products""
    ],
    ""props"": {
      ""category"": ""2""
    }
  },
  ""slider-layout#demo-products"": {
    ""props"": {
      ""itemsPerPage"": {
        ""desktop"": 1,
        ""tablet"": 1,
        ""phone"": 1
      },
      ""blockClass"": ""shelf-container""
    }
  }
}`

**Expected behavior**
A shelf on related products

**Screenshots**
![image](https://user-images.githubusercontent.com/36748003/112733835-f65dcd00-8f20-11eb-8b47-bb43170c6ef6.png)

","Getting INTERNAL_SERVER_ERROR while implementing list-context.product-list **Describe the bug** I am getting a 400 error while implementing the product-list-context that says that the store is not active. **To Reproduce** 1. Add the dependencies in the manifest 2. call the block in the home.json: ` ""store.home"": { ""blocks"": [ ""list-context.image-list#home"", ""list-context.product-list#demo1"", ""flex-layout.row#promotional-info"", ""flex-layout.row#banner-home"", ""flex-layout.row#banner-brands"", ""flex-layout.row#newsletter"" ] },` 2. Declare the block in the shelf.jsonc: `{ ""product-summary.shelf#demo1"": { ""children"": [ ""product-summary-name"", ""product-rating-inline"", ""product-summary-space"", ""product-summary-price"", ""product-summary-buy-button"" ] }, ""list-context.product-list#demo1"": { ""blocks"": [ ""product-summary.shelf#demo1"" ], ""children"": [ ""slider-layout#demo-products"" ], ""props"": { ""category"": ""2"" } }, ""slider-layout#demo-products"": { ""props"": { ""itemsPerPage"": { ""desktop"": 1, ""tablet"": 1, ""phone"": 1 }, ""blockClass"": ""shelf-container"" } } }` **Expected behavior** A shelf on related products **Screenshots** ![image](https://user-images.githubusercontent.com/36748003/112733835-f65dcd00-8f20-11eb-8b47-bb43170c6ef6.png) "
737217,737217,142949,https://api.github.com/repos/assimbly/gateway/issues/468,1.0,2021-02-23T12:35:03Z,OWNER,https://api.github.com/repos/assimbly/gateway,Support for dynamic to endpoint,Make it possible to use dynamic endpoint (toD) when configured in the URI,Support for dynamic to endpoint Make it possible to use dynamic endpoint (toD) when configured in the URI
603779,603779,670995,https://api.github.com/repos/goodwithtech/dockle/issues/82,0.0,2020-11-22T02:43:30Z,CONTRIBUTOR,https://api.github.com/repos/goodwithtech/dockle,image on docker hub is EOL: This OS version is no longer supported by the distribution: alpine 3.9.6,"**Description**
This OS version is no longer supported by the distribution: alpine 3.9.6
2020-11-22T02:37:50.916Z	WARN	The vulnerability detection may be insufficient because security updates are not provided
...
Run docker run aquasec/trivy:latest --cache-dir /var/lib/trivy --exit-code 1 --no-progress $IMAGE:v0.3.1
Digest: sha256:37af346e8b0100035df20f330c49f96cccfd809ddb0ab2d3ca26bbb781e1d81f
Status: Downloaded newer image for aquasec/trivy:latest
2020-11-22T02:37:48.724Z	INFO	Need to update DB
2020-11-22T02:37:48.724Z	INFO	Downloading DB...
2020-11-22T02:37:50.916Z	INFO	Detecting Alpine vulnerabilities...
2020-11-22T02:37:50.916Z	WARN	This OS version is no longer supported by the distribution: alpine 3.9.6
2020-11-22T02:37:50.916Z	WARN	The vulnerability detection may be insufficient because security updates are not provided

goodwithtech/dockle:v0.3.1 (alpine 3.9.6)
=========================================
Total: 2 (UNKNOWN: 2, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 0)

+------------+------------------+----------+-------------------+---------------+-------+
|  LIBRARY   | VULNERABILITY ID | SEVERITY | INSTALLED VERSION | FIXED VERSION | TITLE |
+------------+------------------+----------+-------------------+---------------+-------+
| musl       | CVE-2020-28928   | UNKNOWN  | 1.1.20-r5         | 1.1.20-r6     |       |
+------------+                  +          +                   +               +-------+
| musl-utils |                  |          |                   |               |       |
+------------+------------------+----------+-------------------+---------------+-------+
Error: Process completed with exit code 1.
```
","image on docker hub is EOL: This OS version is no longer supported by the distribution: alpine 3.9.6 **Description** This OS version is no longer supported by the distribution: alpine 3.9.6 2020-11-22T02:37:50.916Z WARN The vulnerability detection may be insufficient because security updates are not provided ... Run docker run aquasec/trivy:latest --cache-dir /var/lib/trivy --exit-code 1 --no-progress $IMAGE:v0.3.1 Digest: sha256:37af346e8b0100035df20f330c49f96cccfd809ddb0ab2d3ca26bbb781e1d81f Status: Downloaded newer image for aquasec/trivy:latest 2020-11-22T02:37:48.724Z INFO Need to update DB 2020-11-22T02:37:48.724Z INFO Downloading DB... 2020-11-22T02:37:50.916Z INFO Detecting Alpine vulnerabilities... 2020-11-22T02:37:50.916Z WARN This OS version is no longer supported by the distribution: alpine 3.9.6 2020-11-22T02:37:50.916Z WARN The vulnerability detection may be insufficient because security updates are not provided goodwithtech/dockle:v0.3.1 (alpine 3.9.6) ========================================= Total: 2 (UNKNOWN: 2, LOW: 0, MEDIUM: 0, HIGH: 0, CRITICAL: 0) +------------+------------------+----------+-------------------+---------------+-------+ | LIBRARY | VULNERABILITY ID | SEVERITY | INSTALLED VERSION | FIXED VERSION | TITLE | +------------+------------------+----------+-------------------+---------------+-------+ | musl | CVE-2020-28928 | UNKNOWN | 1.1.20-r5 | 1.1.20-r6 | | +------------+ + + + +-------+ | musl-utils | | | | | | +------------+------------------+----------+-------------------+---------------+-------+ Error: Process completed with exit code 1. ``` "
486551,486551,540743,https://api.github.com/repos/pandas-dev/pandas/issues/39398,0.0,2021-01-25T15:18:39Z,NONE,https://api.github.com/repos/pandas-dev/pandas,BUG: `DateTimeIndex + DateTimeIndex.freq` giving incorrect result if timezone is set.,"- [x] I have checked that this issue has not already been reported.

- [x] I have confirmed this bug exists on the latest version of pandas.

- [ ] (optional) I have confirmed this bug exists on the master branch of pandas.

---
#### Code Sample, a copy-pastable example

```python
import pandas as pd
i = pd.date_range('2020-03-27', freq='D', periods=4, tz='Europe/Berlin')
i2 = i + i.freq
i2.freq = 'D' # ValueError: Inferred frequency None from passed values does not conform to passed frequency D
```

#### Problem description

`i` is as expected.
```
DatetimeIndex(['2020-03-27 00:00:00+01:00', '2020-03-28 00:00:00+01:00',
               '2020-03-29 00:00:00+01:00', '2020-03-30 00:00:00+02:00'],
              dtype='datetime64[ns, Europe/Berlin]', freq='D') #good
```
but `i2` has two issues: 
```
DatetimeIndex(['2020-03-29 00:00:00+01:00', '2020-03-30 01:00:00+02:00',
               '2020-03-31 00:00:00+02:00', '2020-04-01 00:00:00+02:00'],
              dtype='datetime64[ns, Europe/Berlin]', freq='D') 
#issue: 2020-03-30 timestamp not at midnight
#issue: i2 has attribute `freq='D'`, but pd.infer_freq returns None
```

#### Expected Output

`i2` to be 
```
DatetimeIndex(['2020-03-29 00:00:00+01:00', '2020-03-30 00:00:00+02:00',
               '2020-03-31 00:00:00+02:00', '2020-04-01 00:00:00+02:00'],
              dtype='datetime64[ns, Europe/Berlin]', freq='D') 
```
(`2020-03-30 00:00:00+02:00` is only change),
with `i2.freq` not returning `None`

#### Related
May be related to [#38243](https://github.com/pandas-dev/pandas/issues/38243)

#### Output of ``pd.show_versions()``

<details>

INSTALLED VERSIONS
------------------
commit           : 3e89b4c4b1580aa890023fc550774e63d499da25
python           : 3.8.5.final.0
python-bits      : 64
OS               : Windows
OS-release       : 10
Version          : 10.0.18362
machine          : AMD64
processor        : Intel64 Family 6 Model 158 Stepping 10, GenuineIntel
byteorder        : little
LC_ALL           : None
LANG             : en
LOCALE           : de_DE.cp1252

pandas           : 1.2.0
numpy            : 1.19.5
pytz             : 2020.5
dateutil         : 2.8.1
pip              : 20.3.3
setuptools       : 51.1.2.post20210112
Cython           : None
pytest           : 6.2.1
hypothesis       : None
sphinx           : 3.4.3
blosc            : None
feather          : None
xlsxwriter       : None
lxml.etree       : None
html5lib         : None
pymysql          : None
psycopg2         : None
jinja2           : 2.11.2
IPython          : 7.12.0
pandas_datareader: None
bs4              : None
bottleneck       : None
fsspec           : None
fastparquet      : None
gcsfs            : None
matplotlib       : 3.3.3
numexpr          : None
odfpy            : None
openpyxl         : None
pandas_gbq       : None
pyarrow          : None
pyxlsb           : None
s3fs             : None
scipy            : 1.6.0
sqlalchemy       : 1.3.22
tables           : None
tabulate         : None
xarray           : None
xlrd             : None
xlwt             : None
numba            : None
</details>
","BUG: `DateTimeIndex + DateTimeIndex.freq` giving incorrect result if timezone is set. - [x] I have checked that this issue has not already been reported. - [x] I have confirmed this bug exists on the latest version of pandas. - [ ] (optional) I have confirmed this bug exists on the master branch of pandas. --- #### Code Sample, a copy-pastable example ```python import pandas as pd i = pd.date_range('2020-03-27', freq='D', periods=4, tz='Europe/Berlin') i2 = i + i.freq i2.freq = 'D' # ValueError: Inferred frequency None from passed values does not conform to passed frequency D ``` #### Problem description `i` is as expected. ``` DatetimeIndex(['2020-03-27 00:00:00+01:00', '2020-03-28 00:00:00+01:00', '2020-03-29 00:00:00+01:00', '2020-03-30 00:00:00+02:00'], dtype='datetime64[ns, Europe/Berlin]', freq='D') #good ``` but `i2` has two issues: ``` DatetimeIndex(['2020-03-29 00:00:00+01:00', '2020-03-30 01:00:00+02:00', '2020-03-31 00:00:00+02:00', '2020-04-01 00:00:00+02:00'], dtype='datetime64[ns, Europe/Berlin]', freq='D') #issue: 2020-03-30 timestamp not at midnight #issue: i2 has attribute `freq='D'`, but pd.infer_freq returns None ``` #### Expected Output `i2` to be ``` DatetimeIndex(['2020-03-29 00:00:00+01:00', '2020-03-30 00:00:00+02:00', '2020-03-31 00:00:00+02:00', '2020-04-01 00:00:00+02:00'], dtype='datetime64[ns, Europe/Berlin]', freq='D') ``` (`2020-03-30 00:00:00+02:00` is only change), with `i2.freq` not returning `None` #### Related May be related to [#38243](https://github.com/pandas-dev/pandas/issues/38243) #### Output of ``pd.show_versions()`` <details> INSTALLED VERSIONS ------------------ commit : 3e89b4c4b1580aa890023fc550774e63d499da25 python : 3.8.5.final.0 python-bits : 64 OS : Windows OS-release : 10 Version : 10.0.18362 machine : AMD64 processor : Intel64 Family 6 Model 158 Stepping 10, GenuineIntel byteorder : little LC_ALL : None LANG : en LOCALE : de_DE.cp1252 pandas : 1.2.0 numpy : 1.19.5 pytz : 2020.5 dateutil : 2.8.1 pip : 20.3.3 setuptools : 51.1.2.post20210112 Cython : None pytest : 6.2.1 hypothesis : None sphinx : 3.4.3 blosc : None feather : None xlsxwriter : None lxml.etree : None html5lib : None pymysql : None psycopg2 : None jinja2 : 2.11.2 IPython : 7.12.0 pandas_datareader: None bs4 : None bottleneck : None fsspec : None fastparquet : None gcsfs : None matplotlib : 3.3.3 numexpr : None odfpy : None openpyxl : None pandas_gbq : None pyarrow : None pyxlsb : None s3fs : None scipy : 1.6.0 sqlalchemy : 1.3.22 tables : None tabulate : None xarray : None xlrd : None xlwt : None numba : None </details> "
6089,6089,6796,https://api.github.com/repos/avatar-project/avatar-public-issues/issues/3,0.0,2020-09-08T20:10:14Z,NONE,https://api.github.com/repos/avatar-project/avatar-public-issues,鬼筠逵剋逵 勻筠克逵 戟逵 棘戟閨棘畇龜戟均筠,"棘龜剋: 戟逵逵龜 棘龜棘勻逵
叫棘橘勻棘 :Xiaomi Mi A3
棘均逵劇劇戟棘筠 棘克菌筠戟龜筠: Android 10

珪逵均龜:
1. 棘畇 (鬼叫) 
2. 鬼龜戟棘戟龜鈞逵龜  Google (極棘極龜)
3. 戟閨棘畇龜戟均

+極棘勻筠龜 極戟克逵龜 龜 均逵劇劇逵龜克 戟逵 龜鈞棘閨逵菌筠戟龜龜
",鬼筠逵剋逵 勻筠克逵 戟逵 棘戟閨棘畇龜戟均筠 棘龜剋: 戟逵逵龜 棘龜棘勻逵 叫棘橘勻棘 :Xiaomi Mi A3 棘均逵劇劇戟棘筠 棘克菌筠戟龜筠: Android 10 珪逵均龜: 1. 棘畇 (鬼叫) 2. 鬼龜戟棘戟龜鈞逵龜  Google (極棘極龜) 3. 戟閨棘畇龜戟均 +極棘勻筠龜 極戟克逵龜 龜 均逵劇劇逵龜克 戟逵 龜鈞棘閨逵菌筠戟龜龜 
215859,215859,240025,https://api.github.com/repos/executablebooks/sphinx-tabs/issues/108,1.0,2021-03-08T21:10:49Z,NONE,https://api.github.com/repos/executablebooks/sphinx-tabs,Automatically adjust plotly figure width ,"**Is your feature request related to a problem? Please describe.**

When I change the browser width the plot for the current tab is adjusted, but when I change tabs the plots for the other tabs will not be automatically adjusted and I have to manually do that in the figure 'reset axes':

**Describe the solution you'd like**

Plot width is automatically adjusted when I change tabs.

**Describe alternatives you've considered**

-

**Additional context**

GIF showing the current behavior:
![sphinx-panels-plotly](https://user-images.githubusercontent.com/18506378/110381831-ca91aa80-8038-11eb-858d-4616d1c00baf.gif)


","Automatically adjust plotly figure width **Is your feature request related to a problem? Please describe.** When I change the browser width the plot for the current tab is adjusted, but when I change tabs the plots for the other tabs will not be automatically adjusted and I have to manually do that in the figure 'reset axes': **Describe the solution you'd like** Plot width is automatically adjusted when I change tabs. **Describe alternatives you've considered** - **Additional context** GIF showing the current behavior: ![sphinx-panels-plotly](https://user-images.githubusercontent.com/18506378/110381831-ca91aa80-8038-11eb-858d-4616d1c00baf.gif) "
746980,746980,239158,https://api.github.com/repos/Mandeep08punia/just-experimenting/issues/4,0.0,2021-01-08T16:43:26Z,OWNER,https://api.github.com/repos/Mandeep08punia/just-experimenting,just adding one more issue,issue added,just adding one more issue issue added
530846,530846,590028,https://api.github.com/repos/sman591/homebridge-lg-thinq-ac/issues/68,0.0,2021-04-06T16:36:47Z,NONE,https://api.github.com/repos/sman591/homebridge-lg-thinq-ac,errors after update version 1.10,"LG Air Conditioner Model:LG standard inverter type 12
model in accessory's settings: RAC_056905_WW

[06/04/2021, 18:00:39] [homebridge-lg-thinq-ac] This plugin generated a warning from the characteristic 'Heating Threshold Temperature': characteristic value expected valid finite number and received ""undefined"" (undefined). See https://git.io/JtMGR for more info.
[06/04/2021, 18:00:52] [LgThinqAirConditioner] SwingModeCharacteristic: Warning: Your A/C unit supports variable swing settings, but this is not supported by Homekit. Ignoring desired swing setting.","errors after update version 1.10 LG Air Conditioner Model:LG standard inverter type 12 model in accessory's settings: RAC_056905_WW [06/04/2021, 18:00:39] [homebridge-lg-thinq-ac] This plugin generated a warning from the characteristic 'Heating Threshold Temperature': characteristic value expected valid finite number and received ""undefined"" (undefined). See https://git.io/JtMGR for more info. [06/04/2021, 18:00:52] [LgThinqAirConditioner] SwingModeCharacteristic: Warning: Your A/C unit supports variable swing settings, but this is not supported by Homekit. Ignoring desired swing setting."
21271,21271,23662,https://api.github.com/repos/TsubakiBotPad/pad-cogs/issues/700,1.0,2021-02-02T06:02:12Z,COLLABORATOR,https://api.github.com/repos/TsubakiBotPad/pad-cogs,Add support to negate name/fluff tokens,test case: `^id -uy wardens` brings up justine,Add support to negate name/fluff tokens test case: `^id -uy wardens` brings up justine
70095,70095,77909,https://api.github.com/repos/Bytespeicher/space-status/issues/26,0.0,2017-02-13T09:09:36Z,NONE,https://api.github.com/repos/Bytespeicher/space-status,Bug: special temperatures like 0.8 degrees makes json fail,"On friday night will playing with our space api, we noticed this bug. Some how the leading zero get lost and the json fails. The 'aussen' temperatures was 0.8 degrees. Maybe @hipposen can give some more technical informations.","Bug: special temperatures like 0.8 degrees makes json fail On friday night will playing with our space api, we noticed this bug. Some how the leading zero get lost and the json fails. The 'aussen' temperatures was 0.8 degrees. Maybe @hipposen can give some more technical informations."
591967,591967,657873,https://api.github.com/repos/openwhyd/openwhyd/issues/441,0.0,2021-01-31T20:06:33Z,MEMBER,https://api.github.com/repos/openwhyd/openwhyd,Can't follow user,"**To Reproduce**
Steps to reproduce the behavior:

1. Go to https://openwhyd.org/u/6016705008ced3543d21bb2f
2. Click on ""follow"" => nothing happens, except an error in the JavaScript console:

```
GET https://openwhyd.org/api/follow?action=insert&tId=6016705008ced3543d21bb2f&_=1612123540712 => 404
```


<bountysource-plugin>

---
Want to back this issue? **[Post a bounty on it!](https://www.bountysource.com/issues/96325840-can-t-follow-user?utm_campaign=plugin&utm_content=tracker%2F41430033&utm_medium=issues&utm_source=github)** We accept bounties via [Bountysource](https://www.bountysource.com/?utm_campaign=plugin&utm_content=tracker%2F41430033&utm_medium=issues&utm_source=github).
</bountysource-plugin>","Can't follow user **To Reproduce** Steps to reproduce the behavior: 1. Go to https://openwhyd.org/u/6016705008ced3543d21bb2f 2. Click on ""follow"" => nothing happens, except an error in the JavaScript console: ``` GET https://openwhyd.org/api/follow?action=insert&tId=6016705008ced3543d21bb2f&_=1612123540712 => 404 ``` <bountysource-plugin> --- Want to back this issue? **[Post a bounty on it!](https://www.bountysource.com/issues/96325840-can-t-follow-user?utm_campaign=plugin&utm_content=tracker%2F41430033&utm_medium=issues&utm_source=github)** We accept bounties via [Bountysource](https://www.bountysource.com/?utm_campaign=plugin&utm_content=tracker%2F41430033&utm_medium=issues&utm_source=github). </bountysource-plugin>"
119647,119647,132952,https://api.github.com/repos/keylase/nvidia-patch/issues/355,1.0,2020-12-31T00:30:05Z,NONE,https://api.github.com/repos/keylase/nvidia-patch,New driver support (version 460.89),"**Please provide details about your environment (please complete the following information)**
- Nvidia driver version: 460.89
- GPU Model: GTX 1080
- OS: Windows 10 64bit
- [x] I'm willing to participate in testing of new patch version

This was pushed out on 15/12/2020 seems to be a game ready driver for Quake 2 RTX any chance of support.",New driver support (version 460.89) **Please provide details about your environment (please complete the following information)** - Nvidia driver version: 460.89 - GPU Model: GTX 1080 - OS: Windows 10 64bit - [x] I'm willing to participate in testing of new patch version This was pushed out on 15/12/2020 seems to be a game ready driver for Quake 2 RTX any chance of support.
87551,87551,97324,https://api.github.com/repos/opengeospatial/teamengine/issues/397,1.0,2019-04-18T12:56:28Z,CONTRIBUTOR,https://api.github.com/repos/opengeospatial/teamengine,Enhance REST API by a technical response with information about the ets ,"To enable external or other ets the integration of a test suite we should enhance the REST API by a more technical  view. 

## Overview of all available test suites
 * http://cite.opengeospatial.org/te2/rest/suites/
 * with Content-Type `application/xml`
 * should return a well-formed and valid (schema must be created) xml document listing the available test suites 

## Overview of all available test suites
 * http://cite.opengeospatial.org/te2/rest/suites/wfs20
 * with Content-Type `application/xml`
 * should return a well-formed and valid (schema must be created) xml document listing the parameters of the wfs20 REST API",Enhance REST API by a technical response with information about the ets To enable external or other ets the integration of a test suite we should enhance the REST API by a more technical view. ## Overview of all available test suites * http://cite.opengeospatial.org/te2/rest/suites/ * with Content-Type `application/xml` * should return a well-formed and valid (schema must be created) xml document listing the available test suites ## Overview of all available test suites * http://cite.opengeospatial.org/te2/rest/suites/wfs20 * with Content-Type `application/xml` * should return a well-formed and valid (schema must be created) xml document listing the parameters of the wfs20 REST API
747911,747911,248122,https://api.github.com/repos/TeamWeathy/WeathyServer/issues/46,0.0,2021-01-12T16:58:54Z,CONTRIBUTOR,https://api.github.com/repos/TeamWeathy/WeathyServer,Clothes API  id濡 諛濡 ,"# Clothes API  id 諛

###  user id媛 щ",Clothes API  id濡 諛濡  # Clothes API  id 諛 ###  user id媛 щ
259286,259286,288375,https://api.github.com/repos/sk1project/sk1-wx/issues/270,1.0,2021-01-04T11:14:39Z,OWNER,https://api.github.com/repos/sk1project/sk1-wx,Implement Position context panel,"Patch example provided by Michael Schorcht.
[position.zip](https://github.com/sk1project/sk1-wx/files/5764355/position.zip)
",Implement Position context panel Patch example provided by Michael Schorcht. [position.zip](https://github.com/sk1project/sk1-wx/files/5764355/position.zip) 
787791,787791,648283,https://api.github.com/repos/mc738/FUtil/issues/5,1.0,2020-10-19T20:22:53Z,OWNER,https://api.github.com/repos/mc738/FUtil,Add Serialization,"Add `Serialization`, F# idiomatic wrappers around various formats include:

* `Json`
* `Xml`

Waiting on this:

* mc738/FBlob#22
","Add Serialization Add `Serialization`, F# idiomatic wrappers around various formats include: * `Json` * `Xml` Waiting on this: * mc738/FBlob#22 "
529710,529710,588754,https://api.github.com/repos/mui-org/material-ui/issues/24170,1.0,2020-09-21T09:09:29Z,CONTRIBUTOR,https://api.github.com/repos/mui-org/material-ui,[TimePicker] Cursor doesn't change on desktop,"<!-- Provide a general summary of the issue in the Title above -->
Hey there, not sure if this should be fixed right away in v3 or hold off until v4...

When I hover a day in the datepicker my mouse changes to a cursor, because I can click it (naturally, right)
But then in the time picker it does not when I hover the hours/minutes.

<!--
  Thank you very much for contributing to Material-UI by creating an issue! ㅿ
  To avoid duplicate issues we ask you to check off the following list.
-->

<!-- Checked checkbox should look like this: [x] -->

- [x] The issue is present in the latest release.
- [x] I have searched the [issues](https://github.com/mui-org/material-ui-pickers/issues) of this repository and believe that this is not a duplicate.

## Current Behavior 

<!-- Describe what happens instead of the expected behavior. -->
No change of cursor when hovering the time indicators

The gif is slow from transforming it from .mov (as this is not supported by Gitlab) see link below to watch the video in real time.
<img src=""https://i.imgur.com/OHq8V43.gif"" width=""400"" />

## Expected Behavior 

<!-- Describe what should happen. -->
Mouse would change to  when hovering something clickable - at least the indicators

## Steps to Reproduce 

<!--
  Provide a link to a live example (you can use codesandbox.io) and an unambiguous set of steps to reproduce this bug.
  Include code to reproduce, if relevant (which it most likely is).

  You should use the official codesandbox template as a starting point: https://codesandbox.io/s/material-ui-date-picker-ppt05

  Issues without some form of live example have a longer response time.
-->

Steps:

1. Go to https://material-ui-pickers.dev/demo/datetime-picker
2. Click any of the demos to bring up the datepicker and choose a date
3. See that the mouse doesn't change for neither hours nor minutes when hovering

## Context 

<!--
  What are you trying to accomplish? How has this issue affected you?
  Providing context helps us come up with a solution that is most useful in the real world.
-->

That I find kind of misleading, because I can click there, and the cursor should indicate it. I know I can also click in between two indications to get a specific minute between let's say 5 and 10 - so this might be a deliberate choice to not let the user think that only 5 or 10 is possible, but then I'd rather make everything the pointer cursor   than nothing...  

## Your Environment 

UX issue, environment thus not relevant.
<!--
  Include as many relevant details about the environment with which you experienced the bug.
  If you encounter issues with typescript please include version and tsconfig.
-->


","[TimePicker] Cursor doesn't change on desktop <!-- Provide a general summary of the issue in the Title above --> Hey there, not sure if this should be fixed right away in v3 or hold off until v4... When I hover a day in the datepicker my mouse changes to a cursor, because I can click it (naturally, right) But then in the time picker it does not when I hover the hours/minutes. <!-- Thank you very much for contributing to Material-UI by creating an issue! ㅿ To avoid duplicate issues we ask you to check off the following list. --> <!-- Checked checkbox should look like this: [x] --> - [x] The issue is present in the latest release. - [x] I have searched the [issues](https://github.com/mui-org/material-ui-pickers/issues) of this repository and believe that this is not a duplicate. ## Current Behavior  <!-- Describe what happens instead of the expected behavior. --> No change of cursor when hovering the time indicators The gif is slow from transforming it from .mov (as this is not supported by Gitlab) see link below to watch the video in real time. <img src=""https://i.imgur.com/OHq8V43.gif"" width=""400"" /> ## Expected Behavior  <!-- Describe what should happen. --> Mouse would change to  when hovering something clickable - at least the indicators ## Steps to Reproduce  <!-- Provide a link to a live example (you can use codesandbox.io) and an unambiguous set of steps to reproduce this bug. Include code to reproduce, if relevant (which it most likely is). You should use the official codesandbox template as a starting point: https://codesandbox.io/s/material-ui-date-picker-ppt05 Issues without some form of live example have a longer response time. --> Steps: 1. Go to https://material-ui-pickers.dev/demo/datetime-picker 2. Click any of the demos to bring up the datepicker and choose a date 3. See that the mouse doesn't change for neither hours nor minutes when hovering ## Context  <!-- What are you trying to accomplish? How has this issue affected you? Providing context helps us come up with a solution that is most useful in the real world. --> That I find kind of misleading, because I can click there, and the cursor should indicate it. I know I can also click in between two indications to get a specific minute between let's say 5 and 10 - so this might be a deliberate choice to not let the user think that only 5 or 10 is possible, but then I'd rather make everything the pointer cursor  than nothing... ## Your Environment  UX issue, environment thus not relevant. <!-- Include as many relevant details about the environment with which you experienced the bug. If you encounter issues with typescript please include version and tsconfig. --> "
398445,398445,442855,https://api.github.com/repos/weather-gov/api/issues/71,0.0,2020-06-24T20:58:57Z,NONE,https://api.github.com/repos/weather-gov/api,Stale/outdated gridpoint and zone forecasts from some Akamai servers,"On some requests to gridpoint and/or zone forecasts like:

https://api.weather.gov/gridpoints/MTR/97,101/forecast
https://api.weather.gov/zones/forecast/CAZ513/forecast

very old/stale data will be returned from Akamai servers.
Currently, it seems to be happening with responses from 23.200.224.17, and 184.84.228.8 but intermittently.

A response from 23.200.224.17 for https://api.weather.gov/gridpoints/MTR/97,101/forecast returned headers of
```
HTTP/1.1 200 OK
Server: nginx/1.16.1
Content-Type: application/ld+json
Last-Modified: Wed, 01 Jul 2020 01:00:00 GMT
Access-Control-Allow-Origin: *
Access-Control-Allow-Headers: Feature-Flags
X-Request-ID: 659ede63-d703-4419-b770-262a40c700ce
X-Correlation-ID: 659ede63-d703-4419-b770-262a40c700ce
X-Server-ID: vm-lnx-nids-apiapp6.ncep.noaa.gov
Cache-Control: public, max-age=883, s-maxage=3600
Expires: Wed, 24 Jun 2020 20:59:18 GMT
Date: Wed, 24 Jun 2020 20:44:35 GMT
Content-Length: 9164
Connection: keep-alive
Vary: Accept,Feature-Flags,Accept-Language
Strict-Transport-Security: max-age=31536000 ; includeSubDomains ; preload
```
and the data was 23:43:12 (h:m:s) old at the time.

A followon query to https://api.weather.gov/zones/forecast/CAZ513/forecast answered by 23.200.224.17 returned headers of
```
HTTP/1.1 200 OK
Server: nginx/1.16.1
Content-Type: application/ld+json
Access-Control-Allow-Origin: *
Access-Control-Allow-Headers: Feature-Flags
X-Request-ID: 486634f2-df51-45e9-a5f6-ab7311ce5e84
X-Correlation-ID: 486634f2-df51-45e9-a5f6-ab7311ce5e84
X-Server-ID: vm-bldr-nids-apiapp1.ncep.noaa.gov
Cache-Control: public, max-age=216, s-maxage=120
Expires: Wed, 24 Jun 2020 20:48:11 GMT
Date: Wed, 24 Jun 2020 20:44:35 GMT
Content-Length: 3328
Connection: keep-alive
Vary: Accept,Feature-Flags,Accept-Language
Strict-Transport-Security: max-age=31536000 ; includeSubDomains ; preload
```
and actual data that had updated: at 127:43:35 (h:m:s) old.

It appears that not all the Akamai cache servers are regularly refreshing the gridpoint and/or forecast zone forecasts.


","Stale/outdated gridpoint and zone forecasts from some Akamai servers On some requests to gridpoint and/or zone forecasts like: https://api.weather.gov/gridpoints/MTR/97,101/forecast https://api.weather.gov/zones/forecast/CAZ513/forecast very old/stale data will be returned from Akamai servers. Currently, it seems to be happening with responses from 23.200.224.17, and 184.84.228.8 but intermittently. A response from 23.200.224.17 for https://api.weather.gov/gridpoints/MTR/97,101/forecast returned headers of ``` HTTP/1.1 200 OK Server: nginx/1.16.1 Content-Type: application/ld+json Last-Modified: Wed, 01 Jul 2020 01:00:00 GMT Access-Control-Allow-Origin: * Access-Control-Allow-Headers: Feature-Flags X-Request-ID: 659ede63-d703-4419-b770-262a40c700ce X-Correlation-ID: 659ede63-d703-4419-b770-262a40c700ce X-Server-ID: vm-lnx-nids-apiapp6.ncep.noaa.gov Cache-Control: public, max-age=883, s-maxage=3600 Expires: Wed, 24 Jun 2020 20:59:18 GMT Date: Wed, 24 Jun 2020 20:44:35 GMT Content-Length: 9164 Connection: keep-alive Vary: Accept,Feature-Flags,Accept-Language Strict-Transport-Security: max-age=31536000 ; includeSubDomains ; preload ``` and the data was 23:43:12 (h:m:s) old at the time. A followon query to https://api.weather.gov/zones/forecast/CAZ513/forecast answered by 23.200.224.17 returned headers of ``` HTTP/1.1 200 OK Server: nginx/1.16.1 Content-Type: application/ld+json Access-Control-Allow-Origin: * Access-Control-Allow-Headers: Feature-Flags X-Request-ID: 486634f2-df51-45e9-a5f6-ab7311ce5e84 X-Correlation-ID: 486634f2-df51-45e9-a5f6-ab7311ce5e84 X-Server-ID: vm-bldr-nids-apiapp1.ncep.noaa.gov Cache-Control: public, max-age=216, s-maxage=120 Expires: Wed, 24 Jun 2020 20:48:11 GMT Date: Wed, 24 Jun 2020 20:44:35 GMT Content-Length: 3328 Connection: keep-alive Vary: Accept,Feature-Flags,Accept-Language Strict-Transport-Security: max-age=31536000 ; includeSubDomains ; preload ``` and actual data that had updated: at 127:43:35 (h:m:s) old. It appears that not all the Akamai cache servers are regularly refreshing the gridpoint and/or forecast zone forecasts. "
696273,696273,773865,https://api.github.com/repos/htmlprogrammist/unified-state-exam/issues/10,0.0,2021-05-10T21:28:26Z,OWNER,https://api.github.com/repos/htmlprogrammist/unified-state-exam,Variants/statgrad-ov-03-21/19-21.py,"筠 勻極棘剋戟筠 逵剋均棘龜劇. 龜 棘畇戟棘 龜剋棘 戟筠 棘勻極逵畇逵筠

* 棘勻筠龜 逵戟逵剋龜鈞, 棘戟棘 剋龜  龜劇勻棘剋 勻 龜劇勻棘剋 勻 畇筠剋逵剋 (劇棘菌戟棘 極棘 克剋  龜 克剋 勻 畇筠剋逵 龜鈞 畇均棘橘 極棘均逵劇劇)
* 鬼畇筠剋逵 勻筠龜  Excel'e劇","Variants/statgrad-ov-03-21/19-21.py 筠 勻極棘剋戟筠 逵剋均棘龜劇. 龜 棘畇戟棘 龜剋棘 戟筠 棘勻極逵畇逵筠 * 棘勻筠龜 逵戟逵剋龜鈞, 棘戟棘 剋龜  龜劇勻棘剋 勻 龜劇勻棘剋 勻 畇筠剋逵剋 (劇棘菌戟棘 極棘 克剋  龜 克剋 勻 畇筠剋逵 龜鈞 畇均棘橘 極棘均逵劇劇) * 鬼畇筠剋逵 勻筠龜  Excel'e劇"
317303,317303,352765,https://api.github.com/repos/thescientist13/gallinago/issues/15,1.0,2021-04-22T21:47:51Z,OWNER,https://api.github.com/repos/thescientist13/gallinago,gallinago deleting entire setup directory proving to be a bit problematic,"## Type of Change
- [ ] New Feature Request
- [ ] Improvement / Suggestion
- [ ] Documentation
- [x] Bug
- [ ] Other (please clarify below)

## Summary
After playing around with this in Greenwood, I think having Gallinago [deleting the setup _directory_](https://github.com/thescientist13/gallinago/blob/0.2.1/src/lib/runner.js#L92) in `teardown` may be a bit too aggressive / greedy and in that case, was also deleting our spec file because it was all located in the same directory we were trying to use gallinago in.... woops ㄶ 

## Details
I think instead Gallinago should...
1. Only delete any `setupFiles` it was provided
1. Optionally, if other files / directories are provided (like fixtures), we can help delete those too

But basically, we should just go deleting anything we feel like.  

> _I think although this could be seen as a bug, safer handling of this should be consider a minor version bump.  Perhaps in the future we can add more ergonomic cleanup flags, but let's base that on usage and use cases._","gallinago deleting entire setup directory proving to be a bit problematic ## Type of Change - [ ] New Feature Request - [ ] Improvement / Suggestion - [ ] Documentation - [x] Bug - [ ] Other (please clarify below) ## Summary After playing around with this in Greenwood, I think having Gallinago [deleting the setup _directory_](https://github.com/thescientist13/gallinago/blob/0.2.1/src/lib/runner.js#L92) in `teardown` may be a bit too aggressive / greedy and in that case, was also deleting our spec file because it was all located in the same directory we were trying to use gallinago in.... woops ㄶ ## Details I think instead Gallinago should... 1. Only delete any `setupFiles` it was provided 1. Optionally, if other files / directories are provided (like fixtures), we can help delete those too But basically, we should just go deleting anything we feel like. > _I think although this could be seen as a bug, safer handling of this should be consider a minor version bump. Perhaps in the future we can add more ergonomic cleanup flags, but let's base that on usage and use cases._"
503705,503705,559862,https://api.github.com/repos/gtasa-savegame-editor/gtasa-savegame-editor/issues/75,0.0,2021-02-07T01:30:41Z,MEMBER,https://api.github.com/repos/gtasa-savegame-editor/gtasa-savegame-editor,outdated .deb metadata,"The `.deb` file is using outdated dependencies. 

```
dpkg: dependency problems prevent configuration of gtasa-savegame-editor:
 gtasa-savegame-editor depends on openjdk-8-jre; however:
  Package openjdk-8-jre is not installed.
```",outdated .deb metadata The `.deb` file is using outdated dependencies. ``` dpkg: dependency problems prevent configuration of gtasa-savegame-editor: gtasa-savegame-editor depends on openjdk-8-jre; however: Package openjdk-8-jre is not installed. ```
245434,245434,272979,https://api.github.com/repos/staxrip/staxrip/issues/541,0.0,2021-02-24T07:32:38Z,COLLABORATOR,https://api.github.com/repos/staxrip/staxrip,APPS > MEDIAINFO FOLDER feature throws an error if characters [ ] are in one file's name,"**Describe the bug**

if running **Mediainfo Folder** feature on a folder where there is a file with ""[ ""character or ""]"" character or Turkish characters (probably the Turkish i) then Mediainfo Folder throws an error and stops reading files afterwards (but the windows doesn't crash)

However, if there are no such characters, but other Arabic, french special characters etc, there is NO PROBLEM.

Also Mediainfo FILE reads the same file with the problematic characters correctly.

Maybe similar to a recent issue found with Turkish i.

","APPS > MEDIAINFO FOLDER feature throws an error if characters [ ] are in one file's name **Describe the bug** if running **Mediainfo Folder** feature on a folder where there is a file with ""[ ""character or ""]"" character or Turkish characters (probably the Turkish i) then Mediainfo Folder throws an error and stops reading files afterwards (but the windows doesn't crash) However, if there are no such characters, but other Arabic, french special characters etc, there is NO PROBLEM. Also Mediainfo FILE reads the same file with the problematic characters correctly. Maybe similar to a recent issue found with Turkish i. "
170498,170498,189571,https://api.github.com/repos/thorian93/ansible-role-firewall/issues/2,1.0,2020-08-14T06:34:05Z,OWNER,https://api.github.com/repos/thorian93/ansible-role-firewall,Make flushing of iptables configurable,Add option to choose whether firewall should be managed completely or to let existing rule stay e.g. fail2ban or docker.,Make flushing of iptables configurable Add option to choose whether firewall should be managed completely or to let existing rule stay e.g. fail2ban or docker.
514074,514074,571293,https://api.github.com/repos/i-Cell-Mobilsoft-Open-Source/coffee/issues/134,0.0,2021-02-02T14:46:27Z,MEMBER,https://api.github.com/repos/i-Cell-Mobilsoft-Open-Source/coffee,Redis stream konzumerek nem tudnak ujra letrejonni ha Redis ujra indul,"Redis stream konzumerek nem tudnak ujra letrejonni ha Redis ujra indul. Mivel a redis nem persistent modban megy ha eltunnek a letrejott streamek es csoportok, ezeket nem tudja ujra letrehozni","Redis stream konzumerek nem tudnak ujra letrejonni ha Redis ujra indul Redis stream konzumerek nem tudnak ujra letrejonni ha Redis ujra indul. Mivel a redis nem persistent modban megy ha eltunnek a letrejott streamek es csoportok, ezeket nem tudja ujra letrehozni"
548841,548841,610003,https://api.github.com/repos/10up/ElasticPress/issues/1500,2.0,2019-09-26T11:14:30Z,NONE,https://api.github.com/repos/10up/ElasticPress,Partial / Fuzzy Search Results,"Hello all,

so relatively new to ES and EP. I installed it on a WooCommerce site and all is working really well so thanks a lot! However, I wish I could somehow make sure queries with spelling errors and partial terms could work. For example: 

One page is called ""Fachkataster"" but searching ""Kataster"" does not result in any matches.

I looked around but wasn't able to find out how to achieve this. Elasticpress is installed locally.

Thanks","Partial / Fuzzy Search Results Hello all, so relatively new to ES and EP. I installed it on a WooCommerce site and all is working really well so thanks a lot! However, I wish I could somehow make sure queries with spelling errors and partial terms could work. For example: One page is called ""Fachkataster"" but searching ""Kataster"" does not result in any matches. I looked around but wasn't able to find out how to achieve this. Elasticpress is installed locally. Thanks"
474061,474061,526870,https://api.github.com/repos/tneotia/html-editor-enhanced/issues/40,2.0,2021-05-13T11:13:08Z,NONE,https://api.github.com/repos/tneotia/html-editor-enhanced,How can I remove the toolbar particular option ,"How can I remove this option below in Image from the editor toolbar 

![IMG-20210513-WA0004](https://user-images.githubusercontent.com/59816309/118118146-2b0ee080-b40a-11eb-9fae-61b91f9d0c79.jpg)
",How can I remove the toolbar particular option How can I remove this option below in Image from the editor toolbar ![IMG-20210513-WA0004](https://user-images.githubusercontent.com/59816309/118118146-2b0ee080-b40a-11eb-9fae-61b91f9d0c79.jpg) 
429027,429027,476931,https://api.github.com/repos/carlafcf/PGP/issues/1,1.0,2021-03-24T23:51:24Z,OWNER,https://api.github.com/repos/carlafcf/PGP,Precisa adicionar fun챌천es  calculadora,"Soma
Subtra챌찾o",Precisa adicionar fun챌천es  calculadora Soma Subtra챌찾o
750328,750328,271883,https://api.github.com/repos/jarun/nnn/issues/843,0.0,2021-01-23T22:10:35Z,NONE,https://api.github.com/repos/jarun/nnn,Pressing 'l' (moving right) on a file breaks nnn and shell,"#### Environment details (Put `x` in the checkbox along with the information)

[x] Operating System: Artix Linux
[x] Desktop Environment: N/A, xorg-server
[x] Terminal Emulator: alacritty
[x] Shell: sh
[x] Custom desktop opener (if applicable): N/A
[x] Program options used: N/A
[x] Configuration options set: N/A
[x] Issue exists on `nnn` master: yes

#### Exact steps to reproduce the issue
Start nnn.
Hover over a non-directory file.
Press 'l'
Navigation becomes difficult.

This seems to happen when hovering over most files, but not all.
Pressing 'l' multiple times worsens the problem.
This issue does not occur when running nnn in a tty.","Pressing 'l' (moving right) on a file breaks nnn and shell #### Environment details (Put `x` in the checkbox along with the information) [x] Operating System: Artix Linux [x] Desktop Environment: N/A, xorg-server [x] Terminal Emulator: alacritty [x] Shell: sh [x] Custom desktop opener (if applicable): N/A [x] Program options used: N/A [x] Configuration options set: N/A [x] Issue exists on `nnn` master: yes #### Exact steps to reproduce the issue Start nnn. Hover over a non-directory file. Press 'l' Navigation becomes difficult. This seems to happen when hovering over most files, but not all. Pressing 'l' multiple times worsens the problem. This issue does not occur when running nnn in a tty."
115340,115340,128176,https://api.github.com/repos/Stephan-S/FS19_AutoDrive/issues/1565,2.0,2020-08-05T09:02:00Z,NONE,https://api.github.com/repos/Stephan-S/FS19_AutoDrive,Project Stopped?,"Sorry.

I understand that the project is stopped?
Stefan hasn't shown up for over three months. There is no progress in updates either.

I don't swear. I'm worried if something bad happened to Stefan or other developers. Covid could have negatively affected the situation. This would not be desirable.",Project Stopped? Sorry. I understand that the project is stopped? Stefan hasn't shown up for over three months. There is no progress in updates either. I don't swear. I'm worried if something bad happened to Stefan or other developers. Covid could have negatively affected the situation. This would not be desirable.
239995,239995,266948,https://api.github.com/repos/carla-simulator/carla/issues/3946,2.0,2021-03-03T11:26:51Z,NONE,https://api.github.com/repos/carla-simulator/carla,XODR into Carla Simulator,"Hi,
I'm have a map in a .xodr extension, I'm trying my best to upload it to Carla Simulator but end up in some problems such as:
ModuleNotFoundError: No module named 'carla'
When copying the folder into de \PythonAPI\util, I have this messsage:
AttributeError: module 'carla' has no attribute 'Client'
I'm getting all these messages by following the guide: https://carla.readthedocs.io/en/latest/adv_opendrive/
and the youtube video: https://www.youtube.com/watch?v=U25GhofVV1Q
Official information from Carla Simulator, can please somebody share their experience or help me solve this problem?
Thank you in advance
","XODR into Carla Simulator Hi, I'm have a map in a .xodr extension, I'm trying my best to upload it to Carla Simulator but end up in some problems such as: ModuleNotFoundError: No module named 'carla' When copying the folder into de \PythonAPI\util, I have this messsage: AttributeError: module 'carla' has no attribute 'Client' I'm getting all these messages by following the guide: https://carla.readthedocs.io/en/latest/adv_opendrive/ and the youtube video: https://www.youtube.com/watch?v=U25GhofVV1Q Official information from Carla Simulator, can please somebody share their experience or help me solve this problem? Thank you in advance "
283503,283503,315278,https://api.github.com/repos/OpenLiberty/open-liberty/issues/12215,0.0,2020-05-16T07:53:46Z,CONTRIBUTOR,https://api.github.com/repos/OpenLiberty/open-liberty,Path of jvm.options file in shared directory should not depend on ${WLP_INSTALL_DIR},"According to the [documentation](https://openliberty.io/docs/ref/config/), `jvm.options` is read first from `${wlp.user.dir}/shared/jvm.options`. However, It is actually read from `${WLP_INSTALL_DIR}/usr/shared/jvm.options`:

https://github.com/OpenLiberty/open-liberty/blob/bf9b94dde3344d4ea11df0fddc595dd99a394e42/dev/com.ibm.ws.kernel.boot.ws-server/publish/bin/server#L657

https://github.com/OpenLiberty/open-liberty/blob/bf9b94dde3344d4ea11df0fddc595dd99a394e42/dev/com.ibm.ws.kernel.boot.ws-server/publish/bin/server.bat#L571

The problem is that when we use custom `${wlp.user.dir}`, the `server` script does not read `jvm.options` from the shared directory.

","Path of jvm.options file in shared directory should not depend on ${WLP_INSTALL_DIR} According to the [documentation](https://openliberty.io/docs/ref/config/), `jvm.options` is read first from `${wlp.user.dir}/shared/jvm.options`. However, It is actually read from `${WLP_INSTALL_DIR}/usr/shared/jvm.options`: https://github.com/OpenLiberty/open-liberty/blob/bf9b94dde3344d4ea11df0fddc595dd99a394e42/dev/com.ibm.ws.kernel.boot.ws-server/publish/bin/server#L657 https://github.com/OpenLiberty/open-liberty/blob/bf9b94dde3344d4ea11df0fddc595dd99a394e42/dev/com.ibm.ws.kernel.boot.ws-server/publish/bin/server.bat#L571 The problem is that when we use custom `${wlp.user.dir}`, the `server` script does not read `jvm.options` from the shared directory. "
254605,254605,283183,https://api.github.com/repos/lemunozm/message-io/issues/61,1.0,2021-03-20T13:29:41Z,OWNER,https://api.github.com/repos/lemunozm/message-io,Node API: focused on increase performance.,"### Problem
To read a message, you use:
```rust
let (mut network, mut events) = Network::split();
network.listen(Transport::FramedTcp, ""0.0.0.0:0"").unwrap();
loop {
    match events.receive() {
        NetEvent::Message(endpoint, data) => { /* data has been copied here */ },
        _ => (),
    }
}

```
Although the current API is quite simple, it has a drawback: in order to pass messages into the `EventQueue`, you need to perform a copy of that message. This is why the signature of the `NetEvent::Message<Endpoint, Vec<u8>>` has an allocated vector instead of a reference like `&[u8]`. This copy is necessary because once you send data into the queue, the lifetime of the referenced data is lost. The internal socket buffer can be overwritten with a new incoming message before you read the previous one. 

To avoid this issue you can avoid sending the data into `EventQueue` in order to process the message directly from the `AdapterEvent` which signature reference the internal input buffer: `AdapterEvent::Data(Endpoint, &[u8])`. You can archieve this using the `Network::new()` constructor:
```rust
let mut network = Network::new(|adapter_event| {
    match adapter_event { 
        AdapterEvent::Data(endpoint, data) => { /* data direclty from adapter*/ },
        _ => (),
    }
});
network.listen(Transport::FramedTcp, ""0.0.0.0:0"").unwrap();
```

Although this works with the desired performance, it reduces the API usage, for example:
- How I can send a message just after read it?. I can not access to the `Network` instance in its own callback, so I need to push this ""action"" as an event and send it into an `EventQueue` to read it out of the callback, in the `EventQueue` loop, and then call `Network::send()` properly.
- If I want to send some signal based on the message read, I need an `EventQueue`.

These problems forced you to divide your application logic, offuscating the code: some events will be processed in the Network callback and other events will be processed in the EventQueue loop:
```rust
let events = EventQueue::new();
let sender = events.sender().clone();
let mut network = Network::new(move |adapter_event| {
    match adapter_event { 
        AdapterEvent::Data(endpoint, data) => { 
           // data directly from adapter
          let response = process_data(data);
          // Here I can not send by the network, I need to perform this action out of the callback.
          sender.send(UserEvent::SendResponse(endpoint, response));
        },
        _ => (),
    }
});

network.listen(Transport::FramedTcp, ""0.0.0.0:0"").unwrap();

loop {
    match events.receive() {
        UserEvent::SendResponse(endpoint, response) => { 
              network.send(endpoint, response);
        },
        _ => (),
    }
}
```

### Solution

To solve this problem, and allow the user to process all their events only in the callback, it is needed some additions:
- Add `network` in the own Network callback.
- Add to the `network` the possibility to react to timer signals, to avoid completely the use of an `EventQueue`.
- Allow natively two types of events, network events, and custom signal events.

#### Example 1
Signals as part of the network.

```rust
enum UserSignal {
    Tick(usize),
    Close,
    // other signals
}

let node = Network::new(|network, event|{
   match event { 
        NetEvent::Data(endpoint, data) => { 
              // data direclty from adapter
              network.send(endpoint, data);
              network.self_signal(UserSignal::Tick(1), Duration::from_millis(50));
        },
       NetEvent::Signal(signal) => match signal {
             UserSignal::Tick => { /* send other signal, call network action, etc... */ }
             UserSignal::Close => network.stop(), // The callback never be called again.
        }
       NetEvent::Connected(..) => (),
       NetEvent::Disconnected(..) => (),
    }
});
network.listen(Transport::FramedTcp, ""0.0.0.0:0"").unwrap();
network.self_signal(Close, Duration::from_secs(3));
network.wait_to_close();
// You still can make any network call and send signals outside the callback.
```

#### Example 2
**Node** concept: the node, contains network, signals and handles the internal thread . The node can be used inside and outside the callback.

```rust
enum UserSignal {
    Tick(usize),
    Close,
    // other signals
}

let node = Node::new(|node, event| {
   match event { 
        Event::Network(net_event) => match net_event {
             NetEvent::Data(endpoint, data) => { 
                 // data direclty from adapter
                 node.network.send(endpoint, data);
                 node.signals.send(UserSignal::Tick(1), Duration::from_millis(50));
             },
            NetEvent::Connected(..) => (),
            NetEvent::Disconnected(..) => (),
        }
        Event::Signal(signal) => match signal {
             UserSignal::Tick => { /* send other signal, call network action, etc... */ }
             UserSIgnal::Close => node.stop()
        }
    }
});
// In this moment the node is already running.
node.network.listen(Transport::FramedTcp, ""0.0.0.0:0"").unwrap();
node.signals.send(UserSignal::Close, Duration::from_secs(3));
node.await(); //waiting until the node be stoped.
// You still can make any network call and send signals outside the callback.
```
```rust
// ... 
let node = Node::new(...);
node.network.listen(Transport::FramedTcp, ""0.0.0.0:0"").unwrap();
std::thread::sleep(Duration::from_secs(3));
node.stop();
```
#### Example 3 **candidate**
Split node into a `NodeHandler` and a `NodeListener`. The handler manages the network, signals and can stop the internal thread. The NodeListener dispatch received events. The NodeHandler can be used both, inside and outside the callback.

```rust
enum UserSignal {
    Tick(usize),
    Close,
    // other signals
}

let (handler, listener) = Node::split();
node.network.listen(Transport::FramedTcp, ""0.0.0.0:0"").unwrap();
node.signals.send(UserSignal::Close, Duration::from_secs(3));
let node_task = listener.fo_each(|event| {
   match event { 
        NodeEvent::Network(net_event) => match net_event {
             NetEvent::Data(endpoint, data) => { 
                 // data direclty from adapter
                 node.network.send(endpoint, data);
                 node.signals.send(UserSignal::Tick(1), Duration::from_millis(50));
             },
            NetEvent::Connected(..) => (),
            NetEvent::Disconnected(..) => (),
        }
        NodeEvent::Signal(signal) => match signal {
             UserSignal::Tick => { /* send other signal, call network action, etc... */ }
             UserSIgnal::Close => node.stop()
        }
    }
});
// In this moment the node is already running.
// You can still make any network call and send signals outside the callback.
node.network.listen(Transport::Udp, ""0.0.0.0:0"").unwrap();
node.signals.send(UserSignal::Tick, Duration::from_secs(1));
drop(node_task); //waits until node.stop() be called.
```","Node API: focused on increase performance. ### Problem To read a message, you use: ```rust let (mut network, mut events) = Network::split(); network.listen(Transport::FramedTcp, ""0.0.0.0:0"").unwrap(); loop { match events.receive() { NetEvent::Message(endpoint, data) => { /* data has been copied here */ }, _ => (), } } ``` Although the current API is quite simple, it has a drawback: in order to pass messages into the `EventQueue`, you need to perform a copy of that message. This is why the signature of the `NetEvent::Message<Endpoint, Vec<u8>>` has an allocated vector instead of a reference like `&[u8]`. This copy is necessary because once you send data into the queue, the lifetime of the referenced data is lost. The internal socket buffer can be overwritten with a new incoming message before you read the previous one. To avoid this issue you can avoid sending the data into `EventQueue` in order to process the message directly from the `AdapterEvent` which signature reference the internal input buffer: `AdapterEvent::Data(Endpoint, &[u8])`. You can archieve this using the `Network::new()` constructor: ```rust let mut network = Network::new(|adapter_event| { match adapter_event { AdapterEvent::Data(endpoint, data) => { /* data direclty from adapter*/ }, _ => (), } }); network.listen(Transport::FramedTcp, ""0.0.0.0:0"").unwrap(); ``` Although this works with the desired performance, it reduces the API usage, for example: - How I can send a message just after read it?. I can not access to the `Network` instance in its own callback, so I need to push this ""action"" as an event and send it into an `EventQueue` to read it out of the callback, in the `EventQueue` loop, and then call `Network::send()` properly. - If I want to send some signal based on the message read, I need an `EventQueue`. These problems forced you to divide your application logic, offuscating the code: some events will be processed in the Network callback and other events will be processed in the EventQueue loop: ```rust let events = EventQueue::new(); let sender = events.sender().clone(); let mut network = Network::new(move |adapter_event| { match adapter_event { AdapterEvent::Data(endpoint, data) => { // data directly from adapter let response = process_data(data); // Here I can not send by the network, I need to perform this action out of the callback. sender.send(UserEvent::SendResponse(endpoint, response)); }, _ => (), } }); network.listen(Transport::FramedTcp, ""0.0.0.0:0"").unwrap(); loop { match events.receive() { UserEvent::SendResponse(endpoint, response) => { network.send(endpoint, response); }, _ => (), } } ``` ### Solution To solve this problem, and allow the user to process all their events only in the callback, it is needed some additions: - Add `network` in the own Network callback. - Add to the `network` the possibility to react to timer signals, to avoid completely the use of an `EventQueue`. - Allow natively two types of events, network events, and custom signal events. #### Example 1 Signals as part of the network. ```rust enum UserSignal { Tick(usize), Close, // other signals } let node = Network::new(|network, event|{ match event { NetEvent::Data(endpoint, data) => { // data direclty from adapter network.send(endpoint, data); network.self_signal(UserSignal::Tick(1), Duration::from_millis(50)); }, NetEvent::Signal(signal) => match signal { UserSignal::Tick => { /* send other signal, call network action, etc... */ } UserSignal::Close => network.stop(), // The callback never be called again. } NetEvent::Connected(..) => (), NetEvent::Disconnected(..) => (), } }); network.listen(Transport::FramedTcp, ""0.0.0.0:0"").unwrap(); network.self_signal(Close, Duration::from_secs(3)); network.wait_to_close(); // You still can make any network call and send signals outside the callback. ``` #### Example 2 **Node** concept: the node, contains network, signals and handles the internal thread . The node can be used inside and outside the callback. ```rust enum UserSignal { Tick(usize), Close, // other signals } let node = Node::new(|node, event| { match event { Event::Network(net_event) => match net_event { NetEvent::Data(endpoint, data) => { // data direclty from adapter node.network.send(endpoint, data); node.signals.send(UserSignal::Tick(1), Duration::from_millis(50)); }, NetEvent::Connected(..) => (), NetEvent::Disconnected(..) => (), } Event::Signal(signal) => match signal { UserSignal::Tick => { /* send other signal, call network action, etc... */ } UserSIgnal::Close => node.stop() } } }); // In this moment the node is already running. node.network.listen(Transport::FramedTcp, ""0.0.0.0:0"").unwrap(); node.signals.send(UserSignal::Close, Duration::from_secs(3)); node.await(); //waiting until the node be stoped. // You still can make any network call and send signals outside the callback. ``` ```rust // ... let node = Node::new(...); node.network.listen(Transport::FramedTcp, ""0.0.0.0:0"").unwrap(); std::thread::sleep(Duration::from_secs(3)); node.stop(); ``` #### Example 3 **candidate** Split node into a `NodeHandler` and a `NodeListener`. The handler manages the network, signals and can stop the internal thread. The NodeListener dispatch received events. The NodeHandler can be used both, inside and outside the callback. ```rust enum UserSignal { Tick(usize), Close, // other signals } let (handler, listener) = Node::split(); node.network.listen(Transport::FramedTcp, ""0.0.0.0:0"").unwrap(); node.signals.send(UserSignal::Close, Duration::from_secs(3)); let node_task = listener.fo_each(|event| { match event { NodeEvent::Network(net_event) => match net_event { NetEvent::Data(endpoint, data) => { // data direclty from adapter node.network.send(endpoint, data); node.signals.send(UserSignal::Tick(1), Duration::from_millis(50)); }, NetEvent::Connected(..) => (), NetEvent::Disconnected(..) => (), } NodeEvent::Signal(signal) => match signal { UserSignal::Tick => { /* send other signal, call network action, etc... */ } UserSIgnal::Close => node.stop() } } }); // In this moment the node is already running. // You can still make any network call and send signals outside the callback. node.network.listen(Transport::Udp, ""0.0.0.0:0"").unwrap(); node.signals.send(UserSignal::Tick, Duration::from_secs(1)); drop(node_task); //waits until node.stop() be called. ```"
105481,105481,117228,https://api.github.com/repos/Wissance/TaxesCalculator/issues/1,1.0,2020-12-23T19:23:52Z,MEMBER,https://api.github.com/repos/Wissance/TaxesCalculator,極龜劇龜鈞逵龜 戟逵剋棘均棘勻 (閨筠鈞 棘畇戟龜克棘勻),"極棘剋鈞 逵 勻棘畇筠: https://vc.ru/finance/123510-instrukciya-dlya-ip-na-usn-platezhi-otchetnost
戟筠棘閨棘畇龜劇棘 逵龜逵 棘極龜劇龜鈞龜棘勻逵戟戟 極剋逵 戟逵剋棘均棘勻 劇筠戟筠戟戟 戟逵 逵棘勻筠 勻鈞戟棘",極龜劇龜鈞逵龜 戟逵剋棘均棘勻 (閨筠鈞 棘畇戟龜克棘勻) 極棘剋鈞 逵 勻棘畇筠: https://vc.ru/finance/123510-instrukciya-dlya-ip-na-usn-platezhi-otchetnost 戟筠棘閨棘畇龜劇棘 逵龜逵 棘極龜劇龜鈞龜棘勻逵戟戟 極剋逵 戟逵剋棘均棘勻 劇筠戟筠戟戟 戟逵 逵棘勻筠 勻鈞戟棘
628675,628675,698666,https://api.github.com/repos/VottusCode/Pastte/issues/22,1.0,2021-03-06T22:27:10Z,OWNER,https://api.github.com/repos/VottusCode/Pastte,feat: Implement CodeJar,https://github.com/antonmedv/codejar#getting-started,feat: Implement CodeJar https://github.com/antonmedv/codejar#getting-started
381767,381767,424386,https://api.github.com/repos/alauda/ng-monaco-editor/issues/2,1.0,2018-11-22T05:04:16Z,CONTRIBUTOR,https://api.github.com/repos/alauda/ng-monaco-editor,allow CodeColorizeDirective to rerender when content changed,,allow CodeColorizeDirective to rerender when content changed 
676733,676733,752121,https://api.github.com/repos/Qiskit/qiskit-terra/issues/5803,0.0,2021-02-06T14:58:20Z,CONTRIBUTOR,https://api.github.com/repos/Qiskit/qiskit-terra,num_qubits() for DictStateFn is inefficient,"To get the number of qubits, a list of all keys in the dictionary is constructed. But, only the length of the first key is used. Constructing the entire list is wasteful.

https://github.com/Qiskit/qiskit-terra/blob/c3b2d7acb80fa89043e6f38efb501275ec296616/qiskit/opflow/state_fns/dict_state_fn.py#L82

This code should work:
```python
len(next(iter(self.primitive)))
```

`%timeit` shows that the latter is faster even when the dict contains only two keys.

- **Qiskit Terra version**:  123d829ac, Feb 3 master




","num_qubits() for DictStateFn is inefficient To get the number of qubits, a list of all keys in the dictionary is constructed. But, only the length of the first key is used. Constructing the entire list is wasteful. https://github.com/Qiskit/qiskit-terra/blob/c3b2d7acb80fa89043e6f38efb501275ec296616/qiskit/opflow/state_fns/dict_state_fn.py#L82 This code should work: ```python len(next(iter(self.primitive))) ``` `%timeit` shows that the latter is faster even when the dict contains only two keys. - **Qiskit Terra version**: 123d829ac, Feb 3 master "
754833,754833,316658,https://api.github.com/repos/Kitware/vtk-js/issues/206,2.0,2017-04-23T18:26:20Z,NONE,https://api.github.com/repos/Kitware/vtk-js,"Clip, slice, contour and streamline filters","Is it possible to use clip, slice, contour and streamline filters with the current implementation? What will I have to do if not?","Clip, slice, contour and streamline filters Is it possible to use clip, slice, contour and streamline filters with the current implementation? What will I have to do if not?"
760471,760471,374253,https://api.github.com/repos/getgrav/grav-plugin-simplesearch/issues/192,2.0,2020-09-18T09:10:57Z,NONE,https://api.github.com/repos/getgrav/grav-plugin-simplesearch,opt-out by setting  simplesearch: process to false does not seem to work,"Header of my page
```
simplesearch:
    process: false
```
Cleared all caching. Page still shows up in search [result](https://lrp-netwerk.pkn.nl/search/query:mendix%208)",opt-out by setting simplesearch: process to false does not seem to work Header of my page ``` simplesearch: process: false ``` Cleared all caching. Page still shows up in search [result](https://lrp-netwerk.pkn.nl/search/query:mendix%208)
271098,271098,301487,https://api.github.com/repos/luca16s/GameSaveManager/issues/54,0.0,2021-01-07T23:34:47Z,OWNER,https://api.github.com/repos/luca16s/GameSaveManager,Erro ao selecionar item none no Jogo,"**Describe the bug**
Na tela de jogos, ao clicar na combo em um jogo e ap처s voltar para o item 'NONE' a aplica챌찾o quebra.

**Expected behavior**
A textbox deve ficar em branco.","Erro ao selecionar item none no Jogo **Describe the bug** Na tela de jogos, ao clicar na combo em um jogo e ap처s voltar para o item 'NONE' a aplica챌찾o quebra. **Expected behavior** A textbox deve ficar em branco."
603582,603582,670776,https://api.github.com/repos/rectorphp/rector/issues/5083,0.0,2021-01-04T08:56:16Z,CONTRIBUTOR,https://api.github.com/repos/rectorphp/rector,Call to undefined function Symfony\Component\DependencyInjection\Loader\Configurator\service(),"# Bug Report

<!-- First, thank you for reporting a bug. That takes time and we appreciate that! -->

| Subject        | Details                                                         |
| :------------- | :---------------------------------------------------------------|
| Rector version | rector/rector:latest             |
| Installed as   | dockerimage                          |

<!-- Please describe your problem here. -->
```
貫 docker run -it --rm --entrypoint bash -v %CD%:/project rector/rector:latest
root@440c45a4a3fb:/project# cd legacy-app
root@440c45a4a3fb:/project/legacy-app# which rector
/rector/bin/rector
root@440c45a4a3fb:/project/legacy-app# rector process . --dry-run -vvvv


 [ERROR] Call to undefined function Symfony\Component\DependencyInjection\Loader\Configurator\service()


root@440c45a4a3fb:/project/legacy-app# rector --version


 [ERROR] Call to undefined function Symfony\Component\DependencyInjection\Loader\Configurator\service()

```

```
<?php

declare(strict_types=1);

use Rector\Core\Configuration\Option;
use Rector\Php74\Rector\Property\TypedPropertyRector;
use Rector\Set\ValueObject\SetList;
use Symfony\Component\DependencyInjection\Loader\Configurator\ContainerConfigurator;

return static function (ContainerConfigurator $containerConfigurator): void {
    // get parameters
    $parameters = $containerConfigurator->parameters();

    // Define what rule sets will be applied
    $parameters->set(Option::SETS, [
        'php72',
    ]);

    // get services (needed for register a single rule)
    // $services = $containerConfigurator->services();

    // register a single rule
    // $services->set(TypedPropertyRector::class);
};

```

## Minimal PHP Code Causing Issue

No idea where to start the debug. It seems that rector does not output stacktrace for its exceptions even with `-vvv`

## Expected Behaviour

This does not happen :) 
","Call to undefined function Symfony\Component\DependencyInjection\Loader\Configurator\service() # Bug Report <!-- First, thank you for reporting a bug. That takes time and we appreciate that! --> | Subject | Details | | :------------- | :---------------------------------------------------------------| | Rector version | rector/rector:latest | | Installed as | dockerimage | <!-- Please describe your problem here. --> ``` 貫 docker run -it --rm --entrypoint bash -v %CD%:/project rector/rector:latest root@440c45a4a3fb:/project# cd legacy-app root@440c45a4a3fb:/project/legacy-app# which rector /rector/bin/rector root@440c45a4a3fb:/project/legacy-app# rector process . --dry-run -vvvv [ERROR] Call to undefined function Symfony\Component\DependencyInjection\Loader\Configurator\service() root@440c45a4a3fb:/project/legacy-app# rector --version [ERROR] Call to undefined function Symfony\Component\DependencyInjection\Loader\Configurator\service() ``` ``` <?php declare(strict_types=1); use Rector\Core\Configuration\Option; use Rector\Php74\Rector\Property\TypedPropertyRector; use Rector\Set\ValueObject\SetList; use Symfony\Component\DependencyInjection\Loader\Configurator\ContainerConfigurator; return static function (ContainerConfigurator $containerConfigurator): void { // get parameters $parameters = $containerConfigurator->parameters(); // Define what rule sets will be applied $parameters->set(Option::SETS, [ 'php72', ]); // get services (needed for register a single rule) // $services = $containerConfigurator->services(); // register a single rule // $services->set(TypedPropertyRector::class); }; ``` ## Minimal PHP Code Causing Issue No idea where to start the debug. It seems that rector does not output stacktrace for its exceptions even with `-vvv` ## Expected Behaviour This does not happen :) "
73854,73854,82125,https://api.github.com/repos/Speedspencer/MashedPotato/issues/18,0.0,2021-02-02T19:36:12Z,NONE,https://api.github.com/repos/Speedspencer/MashedPotato,[Bug] 仙錫㏅른錫꿋릎錫錫仙錫錫仙仙錫□仙錫錫닮錫□錫뜩錫,仙錫㏅른錫꿋릎錫錫仙錫錫仙仙錫仙錫錫닮仙錫□仙錫錫닮錫□錫뜩錫 (仙錫□仙錫仙 afk ),[Bug] 仙錫㏅른錫꿋릎錫錫仙錫錫仙仙錫□仙錫錫닮錫□錫뜩錫 仙錫㏅른錫꿋릎錫錫仙錫錫仙仙錫仙錫錫닮仙錫□仙錫錫닮錫□錫뜩錫 (仙錫□仙錫仙 afk )
758415,758415,353437,https://api.github.com/repos/JakubSokolowski/calc-web/issues/82,1.0,2021-01-06T17:44:05Z,OWNER,https://api.github.com/repos/JakubSokolowski/calc-web,Add translation for operations and their algorithm,"Currently it is the hardcoded enum string for op/alg, change it to proper translation key","Add translation for operations and their algorithm Currently it is the hardcoded enum string for op/alg, change it to proper translation key"
613136,613136,681380,https://api.github.com/repos/fenegroni/hellotddworld/issues/2,1.0,2021-04-07T12:19:59Z,OWNER,https://api.github.com/repos/fenegroni/hellotddworld,"Test charcount as a command, not a function","Improving on #1 to with ideas from chapter 11 section 2.2 ""Testing a Command""

- [x] Implement test for echo
- [x] Implement test for charcount as a command
- [x] review use of bytearray or io.Writer/Reader","Test charcount as a command, not a function Improving on #1 to with ideas from chapter 11 section 2.2 ""Testing a Command"" - [x] Implement test for echo - [x] Implement test for charcount as a command - [x] review use of bytearray or io.Writer/Reader"
388327,388327,431671,https://api.github.com/repos/windicss/svelte-windicss-preprocess/issues/25,1.0,2021-02-23T09:55:42Z,MEMBER,https://api.github.com/repos/windicss/svelte-windicss-preprocess,Include support for windicss 2.2,"for changes see https://github.com/windicss/windicss/discussions/101

- [x] update packages
- [ ] update readme
- [x] include examples",Include support for windicss 2.2 for changes see https://github.com/windicss/windicss/discussions/101 - [x] update packages - [ ] update readme - [x] include examples
37508,37508,41806,https://api.github.com/repos/opendatacam/opendatacam/issues/377,2.0,2021-03-05T14:55:05Z,NONE,https://api.github.com/repos/opendatacam/opendatacam,Performance Problems with Jetson Nano,"Hello,

I repeatedly have performance problems using the Jetson Nano. 

The demo video runs, but I notice huge fluctuations in the FPS. The values differ from 1-2 PFS, 4-5 FPS to 11 FPS, while the setup remains unchanged.

I wasn쨈t able to find the reason for these fluctuations so far.

Is there already a similar problem known or can you think of a solution to my problem?

Thank you in advance!
","Performance Problems with Jetson Nano Hello, I repeatedly have performance problems using the Jetson Nano. The demo video runs, but I notice huge fluctuations in the FPS. The values differ from 1-2 PFS, 4-5 FPS to 11 FPS, while the setup remains unchanged. I wasn쨈t able to find the reason for these fluctuations so far. Is there already a similar problem known or can you think of a solution to my problem? Thank you in advance! "
743570,743570,205514,https://api.github.com/repos/NosWings/bug-reports/issues/709,0.0,2020-11-07T12:48:40Z,NONE,https://api.github.com/repos/NosWings/bug-reports,[BUG]Bad Warehouse placement in miniland (?),"![image](https://user-images.githubusercontent.com/46578788/98441628-d8253b00-20ff-11eb-8bc6-b2309d7a6370.png)
This looks a bit wrong. I think the warehouse should be one line to the front, no? ","[BUG]Bad Warehouse placement in miniland (?) ![image](https://user-images.githubusercontent.com/46578788/98441628-d8253b00-20ff-11eb-8bc6-b2309d7a6370.png) This looks a bit wrong. I think the warehouse should be one line to the front, no? "
663779,663779,737799,https://api.github.com/repos/pytroll/trollflow2/issues/103,0.0,2021-02-09T11:03:44Z,MEMBER,https://api.github.com/repos/pytroll/trollflow2,Dpath isn't maintained anymore,"The dpath dependency isn't maintained anymore. We need to remove it or find a replacement.
https://github.com/akesterson/dpath-python/issues/136

",Dpath isn't maintained anymore The dpath dependency isn't maintained anymore. We need to remove it or find a replacement. https://github.com/akesterson/dpath-python/issues/136 
708264,708264,787170,https://api.github.com/repos/ctrachte/Datepicker.js/issues/125,0.0,2021-05-24T18:41:29Z,OWNER,https://api.github.com/repos/ctrachte/Datepicker.js,Preset menu warnings when presetMenu is off,"Need to add the following logic to all instances where preset menu is created

```
        if (this.presetMenu) {
            this.drawPresetMenu();
            this.closePresetMenu();
        }
```",Preset menu warnings when presetMenu is off Need to add the following logic to all instances where preset menu is created ``` if (this.presetMenu) { this.drawPresetMenu(); this.closePresetMenu(); } ```
131298,131298,145945,https://api.github.com/repos/react-navigation/react-navigation/issues/9561,0.0,2021-05-07T04:32:35Z,NONE,https://api.github.com/repos/react-navigation/react-navigation,how to make single screens of stack header  invisible ??,"**Current Behavior**

- What code are you running and what is happening?
- Include a screenshot or video if it makes sense.

**Expected Behavior**

- What do you expect should be happening?
- Include a screenshot or video if it makes sense.

**How to reproduce**

- You must provide a way to reproduce the problem. If you are having an issue with your machine or build tools, the issue belongs on another repository as that is outside of the scope of React Navigation.
- Either re-create the bug on [Snack](https://snack.expo.io) or link to a GitHub repository with code that reproduces the bug.
- Explain how to run the example app and any steps that we need to take to reproduce the issue from the example app.
- Keep the repro code as simple as possible, with the minimum amount of code required to repro the issue.
- Before reporting an issue, make sure you are on latest version of the package.

**Your Environment**

| software                       | version |
| ------------------------------ | ------- |
| iOS or Android                 |
| @react-navigation/native       |
| @react-navigation/stack        |
| react-native-gesture-handler   |
| react-native-safe-area-context |
| react-native-screens           |
| react-native                   |
| expo                           |
| node                           |
| npm or yarn                    |
","how to make single screens of stack header invisible ?? **Current Behavior** - What code are you running and what is happening? - Include a screenshot or video if it makes sense. **Expected Behavior** - What do you expect should be happening? - Include a screenshot or video if it makes sense. **How to reproduce** - You must provide a way to reproduce the problem. If you are having an issue with your machine or build tools, the issue belongs on another repository as that is outside of the scope of React Navigation. - Either re-create the bug on [Snack](https://snack.expo.io) or link to a GitHub repository with code that reproduces the bug. - Explain how to run the example app and any steps that we need to take to reproduce the issue from the example app. - Keep the repro code as simple as possible, with the minimum amount of code required to repro the issue. - Before reporting an issue, make sure you are on latest version of the package. **Your Environment** | software | version | | ------------------------------ | ------- | | iOS or Android | | @react-navigation/native | | @react-navigation/stack | | react-native-gesture-handler | | react-native-safe-area-context | | react-native-screens | | react-native | | expo | | node | | npm or yarn | "
645062,645062,716984,https://api.github.com/repos/devouring-algorithm-ds/algorithm-study-s1/issues/12,0.0,2021-03-07T03:22:51Z,CONTRIBUTOR,https://api.github.com/repos/devouring-algorithm-ds/algorithm-study-s1,removeFront removeBack,"@cottonpup 

 肄瑜 ㅽ硫 ㅻ媛 ⑸. `removeFront`瑜 `removeBack`쇰 諛轅 留李ш吏濡 媛 ㅻ媛 諛⑸.  洹몃곗 媛대ㆀ⑩삘

```js
const { LinkedList } = require('./singlyLinkedList');

class Main {
  static main() {
    const sll = new LinkedList();
 
    // 1 -> 2 -> 3 -> 4
    sll.insertFront(2);
    sll.insertFront(1);
    sll.insertBack(3);
    sll.insertBack(4);

    console.log(sll.get(0)); // 1
    console.log(sll.get(1)); // 2
    console.log(sll.get(2)); // 3
    console.log(sll.get(3)); // 4

    sll.removeFront(); 
    sll.removeFront();
    sll.removeFront();
    sll.removeFront();
    sll.removeFront(); // ㅻ

  }
}

Main.main();
```",removeFront removeBack @cottonpup  肄瑜 ㅽ硫 ㅻ媛 ⑸. `removeFront`瑜 `removeBack`쇰 諛轅 留李ш吏濡 媛 ㅻ媛 諛⑸.  洹몃곗 媛대ㆀ⑩삘 ```js const { LinkedList } = require('./singlyLinkedList'); class Main { static main() { const sll = new LinkedList(); // 1 -> 2 -> 3 -> 4 sll.insertFront(2); sll.insertFront(1); sll.insertBack(3); sll.insertBack(4); console.log(sll.get(0)); // 1 console.log(sll.get(1)); // 2 console.log(sll.get(2)); // 3 console.log(sll.get(3)); // 4 sll.removeFront(); sll.removeFront(); sll.removeFront(); sll.removeFront(); sll.removeFront(); // ㅻ } } Main.main(); ```
701403,701403,779552,https://api.github.com/repos/egortrue/NeVK/issues/47,0.0,2021-03-30T20:30:35Z,COLLABORATOR,https://api.github.com/repos/egortrue/NeVK,Fix texture bug ,"![image](https://user-images.githubusercontent.com/971543/113052492-e0197080-91af-11eb-9f88-4b0f33023e29.png)
",Fix texture bug ![image](https://user-images.githubusercontent.com/971543/113052492-e0197080-91af-11eb-9f88-4b0f33023e29.png) 
606318,606318,673820,https://api.github.com/repos/nicoSix/Ardent/issues/15,0.0,2021-04-13T14:54:10Z,NONE,https://api.github.com/repos/nicoSix/Ardent,failed to create a new Component,"https://ardent.ovh/app/architecture/6eb91788-432c-4cab-bdac-0307ccdc4f1d

```
TypeError: e.name[0] is undefined
    i BaseComponentsInput.js:12
    pn BaseComponentsInput.js:11
    React 12
        Qa
        Os
        gl
        ml
        sl
        Xi
        unstable_runWithPriority
        Yi
        Xi
        Ki
        N
        Xt
react-dom.production.min.js:209:194
    React 16
        is
        callback
        ma
        us
        wl
        unstable_runWithPriority
        Yi
        xl
        sl
        Xi
        unstable_runWithPriority
        Yi
        Xi
        Ki
        N
        Xt
Uncaught TypeError: e.name[0] is undefined
    i BaseComponentsInput.js:12
    pn BaseComponentsInput.js:11
    React 12
        Qa
        Os
        gl
        ml
        sl
        Xi
        unstable_runWithPriority
        Yi
        Xi
        Ki
        N
        Xt
BaseComponentsInput.js:12:24
    i BaseComponentsInput.js:12
    map self-hosted:221
    pn BaseComponentsInput.js:11
    React 5
    sl self-hosted:1224
    React 7
    bind_applyFunctionN self-hosted:1375
    Xt self-hosted:1338
```",failed to create a new Component https://ardent.ovh/app/architecture/6eb91788-432c-4cab-bdac-0307ccdc4f1d ``` TypeError: e.name[0] is undefined i BaseComponentsInput.js:12 pn BaseComponentsInput.js:11 React 12 Qa Os gl ml sl Xi unstable_runWithPriority Yi Xi Ki N Xt react-dom.production.min.js:209:194 React 16 is callback ma us wl unstable_runWithPriority Yi xl sl Xi unstable_runWithPriority Yi Xi Ki N Xt Uncaught TypeError: e.name[0] is undefined i BaseComponentsInput.js:12 pn BaseComponentsInput.js:11 React 12 Qa Os gl ml sl Xi unstable_runWithPriority Yi Xi Ki N Xt BaseComponentsInput.js:12:24 i BaseComponentsInput.js:12 map self-hosted:221 pn BaseComponentsInput.js:11 React 5 sl self-hosted:1224 React 7 bind_applyFunctionN self-hosted:1375 Xt self-hosted:1338 ```
250498,250498,278635,https://api.github.com/repos/microsoft/MCW-Securing-Azure-IoT-solutions/issues/11,1.0,2020-06-02T23:47:58Z,NONE,https://api.github.com/repos/microsoft/MCW-Securing-Azure-IoT-solutions,Update Title,"Securing the IoT end to end sounds super odd. Please rename to something like ""Securing IoT Edge to Cloud end to end""","Update Title Securing the IoT end to end sounds super odd. Please rename to something like ""Securing IoT Edge to Cloud end to end"""
651778,651778,724528,https://api.github.com/repos/Delwddrylliwr/cartolan/issues/128,1.0,2021-05-11T05:33:08Z,OWNER,https://api.github.com/repos/Delwddrylliwr/cartolan,Win message should differentiate score margin Vs exhausted tiles,,Win message should differentiate score margin Vs exhausted tiles 
355626,355626,395360,https://api.github.com/repos/audacity/audacity/issues/805,0.0,2021-04-14T01:35:17Z,NONE,https://api.github.com/repos/audacity/audacity,"Windows 10.0.19042.867, Audacity 3.0.0 GUI does not respond to any input ","**Describe the bug**
Open Audacity, perform some operations, click menus or buttons or use shortcut keys, it is very likely that the GUI interface does not respond to any input. Check the task manager, Audacity is not dead, right-click on the taskbar to close, Audacity will still pop up Save the modification dialog, but still does not respond to any input 

**To Reproduce**
Steps to reproduce the behavior:
1. run audacity
2. some operations, etc click menu, click buttons, use shortcut key
3. audacity don't respond any input

**Expected behavior**
Audacity works normally 

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Additional information (please complete the following information):**
 - OS:Windows 10.0.19042.867
 - Version: Audacity 3.0.0

**Additional context**
It is easier to reproduce the problem by using shortcut keys ","Windows 10.0.19042.867, Audacity 3.0.0 GUI does not respond to any input **Describe the bug** Open Audacity, perform some operations, click menus or buttons or use shortcut keys, it is very likely that the GUI interface does not respond to any input. Check the task manager, Audacity is not dead, right-click on the taskbar to close, Audacity will still pop up Save the modification dialog, but still does not respond to any input **To Reproduce** Steps to reproduce the behavior: 1. run audacity 2. some operations, etc click menu, click buttons, use shortcut key 3. audacity don't respond any input **Expected behavior** Audacity works normally **Screenshots** If applicable, add screenshots to help explain your problem. **Additional information (please complete the following information):** - OS:Windows 10.0.19042.867 - Version: Audacity 3.0.0 **Additional context** It is easier to reproduce the problem by using shortcut keys "
216176,216176,240388,https://api.github.com/repos/TheCraiggers/Pathfinder-Discord-Bot/issues/11,0.0,2020-01-12T14:46:06Z,OWNER,https://api.github.com/repos/TheCraiggers/Pathfinder-Discord-Bot,Cached images for lookups aren't getting deleted,"Images should be deleted once they are sent to Discord, but they're not.","Cached images for lookups aren't getting deleted Images should be deleted once they are sent to Discord, but they're not."
159216,159216,177013,https://api.github.com/repos/JohnWoods11/fishv3/issues/8,1.0,2021-03-09T04:17:34Z,OWNER,https://api.github.com/repos/JohnWoods11/fishv3,Create session,Initialize and navigate to new session from the home screen,Create session Initialize and navigate to new session from the home screen
296902,296902,330160,https://api.github.com/repos/tendermint/liquidity/issues/228,1.0,2021-04-20T11:38:02Z,COLLABORATOR,https://api.github.com/repos/tendermint/liquidity,Requested test scripts to test out the liquidity module interface,"## Description

From the QA, they think it would be nice to have some sample scripts to test out the liquidity module interface.

> The test scripts are used to test the liquidity module interface, and to see if the messages can be executed. These are for reference. 

## What scripts are nice to have?

The below scripts are some sample scripts that I think it is nice to have for new developers to test out the liquidity module. 
What do you think @dongsam ? If there is any specific script that you or QA team thinks it is nice to have, feel free to provide some feedback / suggestion.

### Scripts for transactions

A script to create liquidity pools
A script that requests deposits to the exist pools
A script that requests withdrawals from the exist pools
A script that requests swaps from the exist pool
A script that creates 3 different pools and makes deposits, withdrawals, and swaps from the pools

### Scripts for queries

A script to query pools
A script to query deposits
A script to query withdraws
A script to query swaps
...


____

#### For Admin Use

- [ ] Not duplicate issue
- [ ] Appropriate labels applied
- [ ] Appropriate contributors tagged
- [ ] Contributor assigned/self-assigned
","Requested test scripts to test out the liquidity module interface ## Description From the QA, they think it would be nice to have some sample scripts to test out the liquidity module interface. > The test scripts are used to test the liquidity module interface, and to see if the messages can be executed. These are for reference. ## What scripts are nice to have? The below scripts are some sample scripts that I think it is nice to have for new developers to test out the liquidity module. What do you think @dongsam ? If there is any specific script that you or QA team thinks it is nice to have, feel free to provide some feedback / suggestion. ### Scripts for transactions A script to create liquidity pools A script that requests deposits to the exist pools A script that requests withdrawals from the exist pools A script that requests swaps from the exist pool A script that creates 3 different pools and makes deposits, withdrawals, and swaps from the pools ### Scripts for queries A script to query pools A script to query deposits A script to query withdraws A script to query swaps ... ____ #### For Admin Use - [ ] Not duplicate issue - [ ] Appropriate labels applied - [ ] Appropriate contributors tagged - [ ] Contributor assigned/self-assigned "
500560,500560,556370,https://api.github.com/repos/deshaw/pyflyby/issues/133,0.0,2021-03-04T23:04:33Z,MEMBER,https://api.github.com/repos/deshaw/pyflyby,Re-export Bug,"Given this code in `foo.py`:
```
from os import path

__all__ = ['path']
```
Verified by ` python -c 'from foo import path; print(path.basename(""/bar/baz""))'`, `tidy-imports` suggests this change which breaks the module:
```
-from os import path
+from __future__ import absolute_import, division, print_function
+
 
 __all__ = ['path']
```","Re-export Bug Given this code in `foo.py`: ``` from os import path __all__ = ['path'] ``` Verified by ` python -c 'from foo import path; print(path.basename(""/bar/baz""))'`, `tidy-imports` suggests this change which breaks the module: ``` -from os import path +from __future__ import absolute_import, division, print_function + __all__ = ['path'] ```"
659972,659972,733568,https://api.github.com/repos/Kethku/neovide/issues/426,0.0,2021-01-01T17:35:29Z,NONE,https://api.github.com/repos/Kethku/neovide,Build doesn't work on an Intel mac,"```
base  rustup show
Default host: x86_64-apple-darwin
rustup home:  /Users/yy/.rustup

stable-x86_64-apple-darwin (default)
rustc 1.49.0 (e1884a8e3 2020-12-29)
```

I'm not sure whether this is related to https://github.com/Kethku/neovide/issues/409 but I got the following error from `cargo build --release` with an Intel iMac:

```
error: linking with `cc` failed: exit code: 1
  |
  = note: ""cc"" ""-m64"" ""-arch"" ""x86_64"" ""-L"" ""/Users/yy/.rustup/toolchains/stable-x86_64-apple-darwin/lib/rustlib/x86_64-apple-darwin/lib"" ""/Users/yy/software/neovide/target/release/deps/neovide.which-e37c194c3e9a3524.which.cwtc7pwv-cgu.0.rcgu.o.rcgu.o"" ""-o"" ""/Users/yy/software/neovide/target/release/deps/neovide"" ""-Wl,-dead_strip"" ""-nodefaultlibs"" ""-L"" ""/Users/yy/software/neovide/target/release/deps"" ""-L"" ""/Users/yy/software/neovide/target/release/build/skia-bindings-07961357d04eeb84/out/skia"" ""-L"" ""/Users/yy/anaconda3/lib"" ""-L"" ""/Users/yy/software/neovide/target/release/build/sdl2-sys-33325c637ec0b9ae/out/lib"" ""-L"" ""/Users/yy/.rustup/toolchains/stable-x86_64-apple-darwin/lib/rustlib/x86_64-apple-darwin/lib"" ""/var/folders/7k/shrpr_hs4vj3h3_6khzmdr040000gn/T/rustcqGJZMU/libsdl2_sys-335719c97480f704.rlib"" ""/var/folders/7k/shrpr_hs4vj3h3_6khzmdr040000gn/T/rustcqGJZMU/libskia_bindings-0ac3890000f3290b.rlib"" ""/Users/yy/.rustup/toolchains/stable-x86_64-apple-darwin/lib/rustlib/x86_64-apple-darwin/lib/libcompiler_builtins-e7cd9f0beed2fc0f.rlib"" ""-lharfbuzz"" ""-framework"" ""CoreText"" ""-framework"" ""CoreText"" ""-framework"" ""CoreText"" ""-framework"" ""CoreText"" ""-framework"" ""CoreText"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreFoundation"" ""-framework"" ""Cocoa"" ""-framework"" ""IOKit"" ""-framework"" ""Carbon"" ""-framework"" ""ForceFeedback"" ""-framework"" ""CoreVideo"" ""-framework"" ""CoreAudio"" ""-framework"" ""AudioToolbox"" ""-liconv"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreFoundation"" ""-lSystem"" ""-framework"" ""CoreVideo"" ""-framework"" ""AppKit"" ""-framework"" ""AppKit"" ""-framework"" ""Foundation"" ""-framework"" ""Foundation"" ""-framework"" ""QuartzCore"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreFoundation"" ""-lSystem"" ""-lobjc"" ""-lc++"" ""-framework"" ""ApplicationServices"" ""-lSystem"" ""-lresolv"" ""-lc"" ""-lm""
  = note: Undefined symbols for architecture x86_64:
            ""_iconv"", referenced from:
                _SDL_iconv_REAL in libsdl2_sys-335719c97480f704.rlib(SDL_iconv.c.o)
                _SDL_iconv_string_REAL in libsdl2_sys-335719c97480f704.rlib(SDL_iconv.c.o)
               (maybe you meant: _SDL_iconv_close_REAL, _SDL_iconv_open , _SDL_iconv_open_REAL , _SDL_iconv , _SDL_iconv_string_REAL , _SDL_iconv_string , _SDL_iconv_REAL , _SDL_iconv_close )
            ""_iconv_close"", referenced from:
                _SDL_iconv_close_REAL in libsdl2_sys-335719c97480f704.rlib(SDL_iconv.c.o)
                _SDL_iconv_string_REAL in libsdl2_sys-335719c97480f704.rlib(SDL_iconv.c.o)
               (maybe you meant: _SDL_iconv_close_REAL, _SDL_iconv_close )
            ""_iconv_open"", referenced from:
                _SDL_iconv_open_REAL in libsdl2_sys-335719c97480f704.rlib(SDL_iconv.c.o)
                _SDL_iconv_string_REAL in libsdl2_sys-335719c97480f704.rlib(SDL_iconv.c.o)
               (maybe you meant: _SDL_iconv_open, _SDL_iconv_open_REAL )
          ld: symbol(s) not found for architecture x86_64
          clang: error: linker command failed with exit code 1 (use -v to see invocation)


error: aborting due to previous error; 5 warnings emitted

error: could not compile `neovide`
```

","Build doesn't work on an Intel mac ``` base  rustup show Default host: x86_64-apple-darwin rustup home: /Users/yy/.rustup stable-x86_64-apple-darwin (default) rustc 1.49.0 (e1884a8e3 2020-12-29) ``` I'm not sure whether this is related to https://github.com/Kethku/neovide/issues/409 but I got the following error from `cargo build --release` with an Intel iMac: ``` error: linking with `cc` failed: exit code: 1 | = note: ""cc"" ""-m64"" ""-arch"" ""x86_64"" ""-L"" ""/Users/yy/.rustup/toolchains/stable-x86_64-apple-darwin/lib/rustlib/x86_64-apple-darwin/lib"" ""/Users/yy/software/neovide/target/release/deps/neovide.which-e37c194c3e9a3524.which.cwtc7pwv-cgu.0.rcgu.o.rcgu.o"" ""-o"" ""/Users/yy/software/neovide/target/release/deps/neovide"" ""-Wl,-dead_strip"" ""-nodefaultlibs"" ""-L"" ""/Users/yy/software/neovide/target/release/deps"" ""-L"" ""/Users/yy/software/neovide/target/release/build/skia-bindings-07961357d04eeb84/out/skia"" ""-L"" ""/Users/yy/anaconda3/lib"" ""-L"" ""/Users/yy/software/neovide/target/release/build/sdl2-sys-33325c637ec0b9ae/out/lib"" ""-L"" ""/Users/yy/.rustup/toolchains/stable-x86_64-apple-darwin/lib/rustlib/x86_64-apple-darwin/lib"" ""/var/folders/7k/shrpr_hs4vj3h3_6khzmdr040000gn/T/rustcqGJZMU/libsdl2_sys-335719c97480f704.rlib"" ""/var/folders/7k/shrpr_hs4vj3h3_6khzmdr040000gn/T/rustcqGJZMU/libskia_bindings-0ac3890000f3290b.rlib"" ""/Users/yy/.rustup/toolchains/stable-x86_64-apple-darwin/lib/rustlib/x86_64-apple-darwin/lib/libcompiler_builtins-e7cd9f0beed2fc0f.rlib"" ""-lharfbuzz"" ""-framework"" ""CoreText"" ""-framework"" ""CoreText"" ""-framework"" ""CoreText"" ""-framework"" ""CoreText"" ""-framework"" ""CoreText"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreFoundation"" ""-framework"" ""Cocoa"" ""-framework"" ""IOKit"" ""-framework"" ""Carbon"" ""-framework"" ""ForceFeedback"" ""-framework"" ""CoreVideo"" ""-framework"" ""CoreAudio"" ""-framework"" ""AudioToolbox"" ""-liconv"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreFoundation"" ""-lSystem"" ""-framework"" ""CoreVideo"" ""-framework"" ""AppKit"" ""-framework"" ""AppKit"" ""-framework"" ""Foundation"" ""-framework"" ""Foundation"" ""-framework"" ""QuartzCore"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreGraphics"" ""-framework"" ""CoreFoundation"" ""-lSystem"" ""-lobjc"" ""-lc++"" ""-framework"" ""ApplicationServices"" ""-lSystem"" ""-lresolv"" ""-lc"" ""-lm"" = note: Undefined symbols for architecture x86_64: ""_iconv"", referenced from: _SDL_iconv_REAL in libsdl2_sys-335719c97480f704.rlib(SDL_iconv.c.o) _SDL_iconv_string_REAL in libsdl2_sys-335719c97480f704.rlib(SDL_iconv.c.o) (maybe you meant: _SDL_iconv_close_REAL, _SDL_iconv_open , _SDL_iconv_open_REAL , _SDL_iconv , _SDL_iconv_string_REAL , _SDL_iconv_string , _SDL_iconv_REAL , _SDL_iconv_close ) ""_iconv_close"", referenced from: _SDL_iconv_close_REAL in libsdl2_sys-335719c97480f704.rlib(SDL_iconv.c.o) _SDL_iconv_string_REAL in libsdl2_sys-335719c97480f704.rlib(SDL_iconv.c.o) (maybe you meant: _SDL_iconv_close_REAL, _SDL_iconv_close ) ""_iconv_open"", referenced from: _SDL_iconv_open_REAL in libsdl2_sys-335719c97480f704.rlib(SDL_iconv.c.o) _SDL_iconv_string_REAL in libsdl2_sys-335719c97480f704.rlib(SDL_iconv.c.o) (maybe you meant: _SDL_iconv_open, _SDL_iconv_open_REAL ) ld: symbol(s) not found for architecture x86_64 clang: error: linker command failed with exit code 1 (use -v to see invocation) error: aborting due to previous error; 5 warnings emitted error: could not compile `neovide` ``` "
719856,719856,800040,https://api.github.com/repos/icosta-cci/society-app/issues/14,1.0,2021-04-07T04:04:21Z,COLLABORATOR,https://api.github.com/repos/icosta-cci/society-app,Task: Endpoint to upload an image aadhar and pan of renter,,Task: Endpoint to upload an image aadhar and pan of renter 
567858,567858,631053,https://api.github.com/repos/avargas20/git_web_practice/issues/1,0.0,2021-02-06T17:09:55Z,NONE,https://api.github.com/repos/avargas20/git_web_practice,ISSUE 1: Correcci처n de p찼ginas 5 y 3,"### Identificador de correcci처n: `FIX1` 

### Errores a corregir: 
- En `pagina5.html`.  La imagen y el t챠tulo de la p찼gina no corresponden. 
- En `pagina3.html`.  El link a la p찼gina siguiente apunta a una direcci처n equivocada.  

### Soluciones:
 - En `pagina5.html`, cambiar la ruta de la imagen con id `imagen5` por `../imagenes/BD5.gif` y el texto del t챠tulo con id `titulo5` por `Mi quinta p찼gina HTML`. 
- En `pagina3.html`, cambiar el link de navegaci처n con id `enlace3` por `pagina4.html` y colocarle el nombre correcto `Mi cuarta p찼gina HTML`.","ISSUE 1: Correcci처n de p찼ginas 5 y 3 ### Identificador de correcci처n: `FIX1` ### Errores a corregir: - En `pagina5.html`. La imagen y el t챠tulo de la p찼gina no corresponden. - En `pagina3.html`. El link a la p찼gina siguiente apunta a una direcci처n equivocada. ### Soluciones: - En `pagina5.html`, cambiar la ruta de la imagen con id `imagen5` por `../imagenes/BD5.gif` y el texto del t챠tulo con id `titulo5` por `Mi quinta p찼gina HTML`. - En `pagina3.html`, cambiar el link de navegaci처n con id `enlace3` por `pagina4.html` y colocarle el nombre correcto `Mi cuarta p찼gina HTML`."
225804,225804,251116,https://api.github.com/repos/rancher/harvester/issues/543,0.0,2021-03-22T07:21:08Z,MEMBER,https://api.github.com/repos/rancher/harvester,[BUG] Minio pods stuck in terminating status with FailedMount errors,"**Describe the bug**
<!-- A clear and concise description of what the bug is. -->

**To Reproduce**
Does not reproduce consistently

Env1: 
Deploy a three-node Harvester cluster(8c8G+4c4G*2)  and observed two minIO pods in Terminating status before any operations.

QA Env2:
A three-node Harvester cluster(4c8G+2c4G*2)
Was testing vm creation, backup & restore stuff, and all minIO pods are terminating after leaving the env untouched in two days.

**Log**
![image](https://user-images.githubusercontent.com/5697937/111953333-6cc58e00-8b21-11eb-9d1b-4e52314b6c6a.png)
![image](https://user-images.githubusercontent.com/5697937/111953353-73540580-8b21-11eb-97e1-f949e31f3637.png)



**Environment:**
 - Harvester ISO version: master-85a12ff7-head
 - Installation Mode: ISO

**Additional context**

Initially saw these events of the pod:
```
Events:
  Type     Reason                  Age                    From                     Message
  ----     ------                  ----                   ----                     -------
  Normal   Scheduled               6m46s                  default-scheduler        Successfully assigned harvester-system/minio-3 to node2
  Warning  FailedAttachVolume      6m46s                  attachdetach-controller  Multi-Attach error for volume ""pvc-54e95af3-c232-4b40-868a-f4186cf48eeb"" Volume is already exclusively attached to one node and can't be attached to another
  Warning  FailedAttachVolume      6m34s                  attachdetach-controller  AttachVolume.Attach failed for volume ""pvc-54e95af3-c232-4b40-868a-f4186cf48eeb"" : rpc error: code = Internal desc = Bad response statusCode [500]. Status [500 Internal Server Error]. Body: [code=Server Error, detail=, message=unable to attach volume pvc-54e95af3-c232-4b40-868a-f4186cf48eeb to node2: cannot attach volume pvc-54e95af3-c232-4b40-868a-f4186cf48eeb with image longhornio/longhorn-engine:v1.1.1-preview1 because the engine image longhornio/longhorn-engine:v1.1.1-preview1 is not deployed on the replicas' nodes or the node that the volume is going to attach to] from [http://longhorn-backend:9500/v1/volumes/pvc-54e95af3-c232-4b40-868a-f4186cf48eeb?action=attach]
  Warning  FailedAttachVolume      6m19s (x5 over 6m35s)  attachdetach-controller  AttachVolume.Attach failed for volume ""pvc-54e95af3-c232-4b40-868a-f4186cf48eeb"" : rpc error: code = Internal desc = Bad response statusCode [500]. Status [500 Internal Server Error]. Body: [message=unable to attach volume pvc-54e95af3-c232-4b40-868a-f4186cf48eeb to node2: cannot attach volume pvc-54e95af3-c232-4b40-868a-f4186cf48eeb with image longhornio/longhorn-engine:v1.1.1-preview1 because the engine image longhornio/longhorn-engine:v1.1.1-preview1 is not deployed on the replicas' nodes or the node that the volume is going to attach to, code=Server Error, detail=] from [http://longhorn-backend:9500/v1/volumes/pvc-54e95af3-c232-4b40-868a-f4186cf48eeb?action=attach]
  Normal   SuccessfulAttachVolume  6m3s                   attachdetach-controller  AttachVolume.Attach succeeded for volume ""pvc-54e95af3-c232-4b40-868a-f4186cf48eeb""
  Normal   Pulled                  5m40s                  kubelet                  Container image ""minio/minio:RELEASE.2020-11-19T23-48-16Z"" already present on machine
  Normal   Created                 5m39s                  kubelet                  Created container minio
  Normal   Started                 5m39s                  kubelet                  Started container minio
  Warning  FailedMount             3m33s (x8 over 4m39s)  kubelet                  MountVolume.SetUp failed for volume ""pvc-54e95af3-c232-4b40-868a-f4186cf48eeb"" : rpc error: code = InvalidArgument desc = Volume pvc-54e95af3-c232-4b40-868a-f4186cf48eeb hasn't been attached yet
  Warning  FailedMount             2m43s                  kubelet                  Unable to attach or mount volumes: unmounted volumes=[export], unattached volumes=[export minio-token-8kmj5]: timed out waiting for the condition
  Normal   Killing                 2m43s                  kubelet                  Stopping container minio
  Warning  FailedMount             27s (x2 over 2m29s)    kubelet                  MountVolume.SetUp failed for volume ""pvc-54e95af3-c232-4b40-868a-f4186cf48eeb"" : applyFSGroup failed for vol pvc-54e95af3-c232-4b40-868a-f4186cf48eeb: readdirent: input/output error
```

After some period of time, the events become the following:
```
Events:
  Type     Reason       Age                      From     Message
  ----     ------       ----                     ----     -------
  Warning  FailedMount  3m21s (x113 over 3h51m)  kubelet  MountVolume.WaitForAttach failed for volume ""pvc-1d8e1441-e920-4244-a623-213a199eee4f"" : volume pvc-1d8e1441-e920-4244-a623-213a199eee4f has GET error for volume attachment csi-8dbc8fa64707edb04a7b8b738e43243ade89c93d7250582fc47ef8e83b1773b5: volumeattachments.storage.k8s.io ""csi-8dbc8fa64707edb04a7b8b738e43243ade89c93d7250582fc47ef8e83b1773b5"" is forbidden: User ""system:node:node2"" cannot get resource ""volumeattachments"" in API group ""storage.k8s.io"" at the cluster scope: no relationship found between node 'node2' and this object
```","[BUG] Minio pods stuck in terminating status with FailedMount errors **Describe the bug** <!-- A clear and concise description of what the bug is. --> **To Reproduce** Does not reproduce consistently Env1: Deploy a three-node Harvester cluster(8c8G+4c4G*2) and observed two minIO pods in Terminating status before any operations. QA Env2: A three-node Harvester cluster(4c8G+2c4G*2) Was testing vm creation, backup & restore stuff, and all minIO pods are terminating after leaving the env untouched in two days. **Log** ![image](https://user-images.githubusercontent.com/5697937/111953333-6cc58e00-8b21-11eb-9d1b-4e52314b6c6a.png) ![image](https://user-images.githubusercontent.com/5697937/111953353-73540580-8b21-11eb-97e1-f949e31f3637.png) **Environment:** - Harvester ISO version: master-85a12ff7-head - Installation Mode: ISO **Additional context** Initially saw these events of the pod: ``` Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 6m46s default-scheduler Successfully assigned harvester-system/minio-3 to node2 Warning FailedAttachVolume 6m46s attachdetach-controller Multi-Attach error for volume ""pvc-54e95af3-c232-4b40-868a-f4186cf48eeb"" Volume is already exclusively attached to one node and can't be attached to another Warning FailedAttachVolume 6m34s attachdetach-controller AttachVolume.Attach failed for volume ""pvc-54e95af3-c232-4b40-868a-f4186cf48eeb"" : rpc error: code = Internal desc = Bad response statusCode [500]. Status [500 Internal Server Error]. Body: [code=Server Error, detail=, message=unable to attach volume pvc-54e95af3-c232-4b40-868a-f4186cf48eeb to node2: cannot attach volume pvc-54e95af3-c232-4b40-868a-f4186cf48eeb with image longhornio/longhorn-engine:v1.1.1-preview1 because the engine image longhornio/longhorn-engine:v1.1.1-preview1 is not deployed on the replicas' nodes or the node that the volume is going to attach to] from [http://longhorn-backend:9500/v1/volumes/pvc-54e95af3-c232-4b40-868a-f4186cf48eeb?action=attach] Warning FailedAttachVolume 6m19s (x5 over 6m35s) attachdetach-controller AttachVolume.Attach failed for volume ""pvc-54e95af3-c232-4b40-868a-f4186cf48eeb"" : rpc error: code = Internal desc = Bad response statusCode [500]. Status [500 Internal Server Error]. Body: [message=unable to attach volume pvc-54e95af3-c232-4b40-868a-f4186cf48eeb to node2: cannot attach volume pvc-54e95af3-c232-4b40-868a-f4186cf48eeb with image longhornio/longhorn-engine:v1.1.1-preview1 because the engine image longhornio/longhorn-engine:v1.1.1-preview1 is not deployed on the replicas' nodes or the node that the volume is going to attach to, code=Server Error, detail=] from [http://longhorn-backend:9500/v1/volumes/pvc-54e95af3-c232-4b40-868a-f4186cf48eeb?action=attach] Normal SuccessfulAttachVolume 6m3s attachdetach-controller AttachVolume.Attach succeeded for volume ""pvc-54e95af3-c232-4b40-868a-f4186cf48eeb"" Normal Pulled 5m40s kubelet Container image ""minio/minio:RELEASE.2020-11-19T23-48-16Z"" already present on machine Normal Created 5m39s kubelet Created container minio Normal Started 5m39s kubelet Started container minio Warning FailedMount 3m33s (x8 over 4m39s) kubelet MountVolume.SetUp failed for volume ""pvc-54e95af3-c232-4b40-868a-f4186cf48eeb"" : rpc error: code = InvalidArgument desc = Volume pvc-54e95af3-c232-4b40-868a-f4186cf48eeb hasn't been attached yet Warning FailedMount 2m43s kubelet Unable to attach or mount volumes: unmounted volumes=[export], unattached volumes=[export minio-token-8kmj5]: timed out waiting for the condition Normal Killing 2m43s kubelet Stopping container minio Warning FailedMount 27s (x2 over 2m29s) kubelet MountVolume.SetUp failed for volume ""pvc-54e95af3-c232-4b40-868a-f4186cf48eeb"" : applyFSGroup failed for vol pvc-54e95af3-c232-4b40-868a-f4186cf48eeb: readdirent: input/output error ``` After some period of time, the events become the following: ``` Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedMount 3m21s (x113 over 3h51m) kubelet MountVolume.WaitForAttach failed for volume ""pvc-1d8e1441-e920-4244-a623-213a199eee4f"" : volume pvc-1d8e1441-e920-4244-a623-213a199eee4f has GET error for volume attachment csi-8dbc8fa64707edb04a7b8b738e43243ade89c93d7250582fc47ef8e83b1773b5: volumeattachments.storage.k8s.io ""csi-8dbc8fa64707edb04a7b8b738e43243ade89c93d7250582fc47ef8e83b1773b5"" is forbidden: User ""system:node:node2"" cannot get resource ""volumeattachments"" in API group ""storage.k8s.io"" at the cluster scope: no relationship found between node 'node2' and this object ```"
787412,787412,644523,https://api.github.com/repos/imr-framework/pypulseq/issues/47,0.0,2021-04-13T15:30:15Z,CONTRIBUTOR,https://api.github.com/repos/imr-framework/pypulseq,Return values of make_xxx_pulse functions,"Since https://github.com/imr-framework/pypulseq/commit/7542b39630c1c4cefc6eb5ded3ddb290a54e487c the make-pulse-functions like _make_sinc_pulse.py_ and _make_gauss_pulse.py_ return a different number of variables as before when using `return_gz = False`. 

For compatibility with previous versions I suggest to return Nones for _gz_ and _gzr_ as it was the case before the release of v1.3.1. However, I think using the _return_gz' flag instead of the try block is a good idea and I suggest to change the return lines only. For example the _make_sinc_pulse.py_ could be modified to:

```    
if return_gz:
    return rf, gz, gzr
else:
    return rf, None, None
```

This would also solve issue https://github.com/imr-framework/pypulseq/issues/46


Let me know if I should include this in the PRs for issue https://github.com/imr-framework/pypulseq/issues/46 and issue https://github.com/imr-framework/pypulseq/issues/48.","Return values of make_xxx_pulse functions Since https://github.com/imr-framework/pypulseq/commit/7542b39630c1c4cefc6eb5ded3ddb290a54e487c the make-pulse-functions like _make_sinc_pulse.py_ and _make_gauss_pulse.py_ return a different number of variables as before when using `return_gz = False`. For compatibility with previous versions I suggest to return Nones for _gz_ and _gzr_ as it was the case before the release of v1.3.1. However, I think using the _return_gz' flag instead of the try block is a good idea and I suggest to change the return lines only. For example the _make_sinc_pulse.py_ could be modified to: ``` if return_gz: return rf, gz, gzr else: return rf, None, None ``` This would also solve issue https://github.com/imr-framework/pypulseq/issues/46 Let me know if I should include this in the PRs for issue https://github.com/imr-framework/pypulseq/issues/46 and issue https://github.com/imr-framework/pypulseq/issues/48."
413304,413304,459396,https://api.github.com/repos/centhoang/GithubIntro/issues/2,1.0,2021-03-20T10:15:36Z,OWNER,https://api.github.com/repos/centhoang/GithubIntro,Please add walnuts to your Shopping List,"**I want walnuts**
![Ep3eNDiUYAAGRCE](https://user-images.githubusercontent.com/45512245/111866391-b9815b80-899f-11eb-9b6c-c1df1fb66ee5.jpg)
",Please add walnuts to your Shopping List **I want walnuts** ![Ep3eNDiUYAAGRCE](https://user-images.githubusercontent.com/45512245/111866391-b9815b80-899f-11eb-9b6c-c1df1fb66ee5.jpg) 
386262,386262,429376,https://api.github.com/repos/ZupIT/charlescd/issues/978,0.0,2021-03-09T22:44:08Z,CONTRIBUTOR,https://api.github.com/repos/ZupIT/charlescd,Code Style step at Compass Github Actions doesn't work with forked branches,"**Describe the bug**
This step exists in Compass and is about to exist in Hermes and Gate as well, to check the code style:

```
- name: Code Style
        uses: docker://morphy/revive-action:v1
        with:
          config: ./compass/revive.toml
          path: ""./compass/...""
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
```

When opening a PR from a fork I realized that this step was breaking.
This GITHUB_TOKEN is the problem, when trying to take the fork branch, the step breaks, because it does not have access to the key.

**To Reproduce**
Steps to reproduce the behavior:
1. Create a fork of ZupIT/charlescd
2. Make a change at Compass module.
3. Commit, push and open a Pull Request
4. Wait Github actions to run
5. See error
","Code Style step at Compass Github Actions doesn't work with forked branches **Describe the bug** This step exists in Compass and is about to exist in Hermes and Gate as well, to check the code style: ``` - name: Code Style uses: docker://morphy/revive-action:v1 with: config: ./compass/revive.toml path: ""./compass/..."" env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }} ``` When opening a PR from a fork I realized that this step was breaking. This GITHUB_TOKEN is the problem, when trying to take the fork branch, the step breaks, because it does not have access to the key. **To Reproduce** Steps to reproduce the behavior: 1. Create a fork of ZupIT/charlescd 2. Make a change at Compass module. 3. Commit, push and open a Pull Request 4. Wait Github actions to run 5. See error "
769566,769566,464805,https://api.github.com/repos/namtranase/generative_model_biosignal/issues/7,1.0,2020-12-04T13:32:26Z,COLLABORATOR,https://api.github.com/repos/namtranase/generative_model_biosignal,Review validation file,"- [x]  Check calculate hr and rr function and finding why hr = rr 

- [x]  Train model with data after noise filter (T sensie's order)

- [ ]  When rr calculating func seems right, test with trained model. Also try validating with RMS, PRD

- [ ]  Answer some questions of T sensei: how the updating process with Gradient work; how to choose number of LSTM cell, kernel size,... (or base on what); with the given formula for loss why using cross entropy.
","Review validation file - [x] Check calculate hr and rr function and finding why hr = rr - [x] Train model with data after noise filter (T sensie's order) - [ ] When rr calculating func seems right, test with trained model. Also try validating with RMS, PRD - [ ] Answer some questions of T sensei: how the updating process with Gradient work; how to choose number of LSTM cell, kernel size,... (or base on what); with the given formula for loss why using cross entropy. "
187101,187101,208061,https://api.github.com/repos/cli/cli/issues/3370,0.0,2021-04-07T08:08:15Z,NONE,https://api.github.com/repos/cli/cli,gh pr update (or push) command is missing,"### Describe the bug

One of the most useful command line operations for maintainers is to download an incomplete PR locally, fix it and update it.

This is a very common operation where original OP may forgot to finish it, or he is not able to do so. Very simple changes can be performed directly in the web interface as GitHub allow maintainers to modify open pull requests.

Still, while downloading a pr locally as very simple via `gh pr checkout 123`, there is no command for pushing your changes back.

Keep in mind that I am talking about pull requests created by occasional contributors, so all of them are coming from forks. Using `git push` does not work as you will get a error.

### Steps to reproduce the behavior

1. download a pull request made from a fork using gh pr checkout 123
2. make a fix to it (add new commit)
3. try to upload/push it...

### Expected vs actual behavior

Provide a command that would allow someone to upload a change. If it is not possible to configure git itself to make it work via a simple `git push`, gh should provide a similar command to push an updated pr.

That is not a a permission issue because same user is allowed to perform that when using the web interface.

### Logs
```
$ git push --force-with-lease -u origin HEAD:

remote: Resolving deltas: 100% (12/12), completed with 4 local objects.
remote: This repository moved. Please use the new location:
remote:   git@github.com:ansible-community/ansible-lint.git
remote:
remote: Create a pull request for 'bug/meta-change-from-default' on GitHub by visiting:
remote:      https://github.com/ansible-community/ansible-lint/pull/new/bug/meta-change-from-default
remote:
remote: GitHub found 1 vulnerability on ansible-community/ansible-lint's default branch (1 high). To find out more, visit:
remote:      https://github.com/ansible-community/ansible-lint/security/dependabot/docs/requirements.txt/urllib3/open
remote:
To github.com:ansible/ansible-lint.git
 * [new branch]      HEAD -> bug/meta-change-from-default
Branch 'bug/meta-change-from-default' set up to track remote branch 'bug/meta-change-from-default' from 'origin'.

Creating pull request for ansible:bug/meta-change-from-default into master in ansible-community/ansible-lint

pull request create failed: GraphQL error: Head sha can't be blank, Base sha can't be blank, Head repository can't be blank, No commits between ansible-community:master and ansible:bug/meta-change-from-default, Head ref must be a branch, not all refs are readable
```

I received this after adding a new commit to a pull request downloaded using `git pr checkout 123`.

Please do provide CLI users with an option to upload/refresh/push changes to pull-request made by others on their projects. That is a very common use-case and the workaround of closing the original PR and creating a feature branch is confusing for everyone involved.

For example Gerrit does cover this use-case very well, where people can easily update reviews from the cli.","gh pr update (or push) command is missing ### Describe the bug One of the most useful command line operations for maintainers is to download an incomplete PR locally, fix it and update it. This is a very common operation where original OP may forgot to finish it, or he is not able to do so. Very simple changes can be performed directly in the web interface as GitHub allow maintainers to modify open pull requests. Still, while downloading a pr locally as very simple via `gh pr checkout 123`, there is no command for pushing your changes back. Keep in mind that I am talking about pull requests created by occasional contributors, so all of them are coming from forks. Using `git push` does not work as you will get a error. ### Steps to reproduce the behavior 1. download a pull request made from a fork using gh pr checkout 123 2. make a fix to it (add new commit) 3. try to upload/push it... ### Expected vs actual behavior Provide a command that would allow someone to upload a change. If it is not possible to configure git itself to make it work via a simple `git push`, gh should provide a similar command to push an updated pr. That is not a a permission issue because same user is allowed to perform that when using the web interface. ### Logs ``` $ git push --force-with-lease -u origin HEAD: remote: Resolving deltas: 100% (12/12), completed with 4 local objects. remote: This repository moved. Please use the new location: remote: git@github.com:ansible-community/ansible-lint.git remote: remote: Create a pull request for 'bug/meta-change-from-default' on GitHub by visiting: remote: https://github.com/ansible-community/ansible-lint/pull/new/bug/meta-change-from-default remote: remote: GitHub found 1 vulnerability on ansible-community/ansible-lint's default branch (1 high). To find out more, visit: remote: https://github.com/ansible-community/ansible-lint/security/dependabot/docs/requirements.txt/urllib3/open remote: To github.com:ansible/ansible-lint.git * [new branch] HEAD -> bug/meta-change-from-default Branch 'bug/meta-change-from-default' set up to track remote branch 'bug/meta-change-from-default' from 'origin'. Creating pull request for ansible:bug/meta-change-from-default into master in ansible-community/ansible-lint pull request create failed: GraphQL error: Head sha can't be blank, Base sha can't be blank, Head repository can't be blank, No commits between ansible-community:master and ansible:bug/meta-change-from-default, Head ref must be a branch, not all refs are readable ``` I received this after adding a new commit to a pull request downloaded using `git pr checkout 123`. Please do provide CLI users with an option to upload/refresh/push changes to pull-request made by others on their projects. That is a very common use-case and the workaround of closing the original PR and creating a feature branch is confusing for everyone involved. For example Gerrit does cover this use-case very well, where people can easily update reviews from the cli."
556544,556544,618525,https://api.github.com/repos/Lospitao/inRoadsCourse/issues/4,1.0,2021-02-16T15:49:43Z,OWNER,https://api.github.com/repos/Lospitao/inRoadsCourse,"When a user enters the app, he can see a top navbar which includes login and registration if user is not logged/registered yet, and settings, notifications, and logout if he is already fully anthenticated",,"When a user enters the app, he can see a top navbar which includes login and registration if user is not logged/registered yet, and settings, notifications, and logout if he is already fully anthenticated "
565896,565896,628869,https://api.github.com/repos/ArneBachmann/tagsplorer/issues/66,0.0,2017-07-03T14:23:39Z,OWNER,https://api.github.com/repos/ArneBachmann/tagsplorer,"on Windows, don쨈t find same folder twice normalized and original",,"on Windows, don쨈t find same folder twice normalized and original "
405883,405883,451146,https://api.github.com/repos/mobends/MoBends/issues/207,0.0,2021-04-12T05:09:14Z,NONE,https://api.github.com/repos/mobends/MoBends,Armor clipping ,"**Describe the bug**
A clear and concise description of what the bug is.

**To Reproduce**
Steps to reproduce the behavior:
1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error

**Expected behavior**
A clear and concise description of what you expected to happen.

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Context (please complete the following information):**
 - Minecraft version: [e.g. 1.12.2]
 - Mo' Bends version [e.g. 1.0.0, 1.0.0-beta]
 - Other installed mods [e.g. Optifine]

**Additional context**
Add any other context about the problem here.
Armor is clipping through the player and is not animated with the player model","Armor clipping **Describe the bug** A clear and concise description of what the bug is. **To Reproduce** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected behavior** A clear and concise description of what you expected to happen. **Screenshots** If applicable, add screenshots to help explain your problem. **Context (please complete the following information):** - Minecraft version: [e.g. 1.12.2] - Mo' Bends version [e.g. 1.0.0, 1.0.0-beta] - Other installed mods [e.g. Optifine] **Additional context** Add any other context about the problem here. Armor is clipping through the player and is not animated with the player model"
780035,780035,570432,https://api.github.com/repos/Puharesource/TitleManager/issues/288,0.0,2020-07-31T00:03:22Z,NONE,https://api.github.com/repos/Puharesource/TitleManager,Scoreboard objective already exists - Disconnects players,"Players get disconnected completely at random while using Waterfall and Paper. No errors in the paper console but this error in Waterfall.

https://pastebin.com/8n00BjMN

Hard to reproduce, happens at random. 

Running waterfall-365

and

![image](https://user-images.githubusercontent.com/13859025/88985962-8f244600-d2c9-11ea-84a2-d715c08f0d7d.png)
","Scoreboard objective already exists - Disconnects players Players get disconnected completely at random while using Waterfall and Paper. No errors in the paper console but this error in Waterfall. https://pastebin.com/8n00BjMN Hard to reproduce, happens at random. Running waterfall-365 and ![image](https://user-images.githubusercontent.com/13859025/88985962-8f244600-d2c9-11ea-84a2-d715c08f0d7d.png) "
518531,518531,576260,https://api.github.com/repos/mikependon/RepoDB/issues/787,2.0,2021-03-14T04:06:37Z,NONE,https://api.github.com/repos/mikependon/RepoDB,Does Postgresql support querying on enums in non-raw form?,"I'm trying to use Postgresql enums (database first) in my project but it tosses an error. Am I doing something wrong or is this not supported?
My webapi get looks like this:
```
[HttpGet]
public IEnumerable<Person> Get()
{
    var ConnectionString = ""Host=localhost;Username=postgres;Password=postgres;Database=test"";
    using (var connection = new NpgsqlConnection(ConnectionString))
    {
        var name2 = connection.Query<Person>(e => e.Gender == Gender.Male);
        return name2;
    }
}
```

Here's the error:
System.InvalidCastException: Can't write CLR type TestApi.Data.Gender with handler type TextHandler
   at lambda_method8(Closure , NpgsqlTypeHandler , Object , NpgsqlLengthCache& , NpgsqlParameter )
   at Npgsql.TypeHandling.NpgsqlTypeHandler`1.ValidateObjectAndGetLength(Object value, NpgsqlLengthCache& lengthCache, NpgsqlParameter parameter)
   at Npgsql.NpgsqlParameter.ValidateAndGetLength()
   at Npgsql.NpgsqlCommand.ValidateParameters(ConnectorTypeMapper typeMapper)
   at Npgsql.NpgsqlCommand.ExecuteReader(CommandBehavior behavior, Boolean async, CancellationToken cancellationToken)
   at Npgsql.NpgsqlCommand.ExecuteReader(CommandBehavior behavior, Boolean async, CancellationToken cancellationToken)
   at Npgsql.NpgsqlCommand.ExecuteReader(CommandBehavior behavior)
   at Npgsql.NpgsqlCommand.ExecuteDbDataReader(CommandBehavior behavior)
   at System.Data.Common.DbCommand.ExecuteReader()
   at RepoDb.DbConnectionExtension.ExecuteQueryInternalForType[TResult](IDbConnection connection, String commandText, Object param, Nullable`1 commandType, String cacheKey, Nullable`1 cacheItemExpiration, Nullable`1 commandTimeout, IDbTransaction transaction, ICache cache, String tableName, Boolean skipCommandArrayParametersCheck)
   at RepoDb.DbConnectionExtension.ExecuteQueryInternal[TResult](IDbConnection connection, String commandText, Object param, Nullable`1 commandType, String cacheKey, Nullable`1 cacheItemExpiration, Nullable`1 commandTimeout, IDbTransaction transaction, ICache cache, String tableName, Boolean skipCommandArrayParametersCheck)
   at RepoDb.DbConnectionExtension.QueryInternalBase[TEntity](IDbConnection connection, String tableName, QueryGroup where, IEnumerable`1 fields, IEnumerable`1 orderBy, Nullable`1 top, String hints, String cacheKey, Nullable`1 cacheItemExpiration, Nullable`1 commandTimeout, IDbTransaction transaction, ICache cache, ITrace trace, IStatementBuilder statementBuilder)
   at RepoDb.DbConnectionExtension.QueryInternal[TEntity](IDbConnection connection, String tableName, QueryGroup where, IEnumerable`1 fields, IEnumerable`1 orderBy, Nullable`1 top, String hints, String cacheKey, Nullable`1 cacheItemExpiration, Nullable`1 commandTimeout, IDbTransaction transaction, ICache cache, ITrace trace, IStatementBuilder statementBuilder)
   at RepoDb.DbConnectionExtension.Query[TEntity](IDbConnection connection, Expression`1 where, IEnumerable`1 fields, IEnumerable`1 orderBy, Nullable`1 top, String hints, String cacheKey, Nullable`1 cacheItemExpiration, Nullable`1 commandTimeout, IDbTransaction transaction, ICache cache, ITrace trace, IStatementBuilder statementBuilder)
   at TestApi.Controllers.WeatherForecastController.Get() in C:\Users\glori\source\repos\TestApi\TestApi\Controllers\WeatherForecastController.cs:line 39
   at lambda_method2(Closure , Object , Object[] )
   at Microsoft.AspNetCore.Mvc.Infrastructure.ActionMethodExecutor.SyncObjectResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, Object controller, Object[] arguments)
   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.InvokeActionMethodAsync()
   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)
   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.InvokeNextActionFilterAsync()
--- End of stack trace from previous location ---
   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Rethrow(ActionExecutedContextSealed context)
   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted)
   at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.InvokeInnerFilterAsync()
--- End of stack trace from previous location ---
   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeFilterPipelineAsync>g__Awaited|19_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted)
   at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeAsync>g__Awaited|17_0(ResourceInvoker invoker, Task task, IDisposable scope)
   at Microsoft.AspNetCore.Routing.EndpointMiddleware.<Invoke>g__AwaitRequestTask|6_0(Endpoint endpoint, Task requestTask, ILogger logger)
   at Microsoft.AspNetCore.Authorization.AuthorizationMiddleware.Invoke(HttpContext context)
   at Swashbuckle.AspNetCore.SwaggerUI.SwaggerUIMiddleware.Invoke(HttpContext httpContext)
   at Swashbuckle.AspNetCore.Swagger.SwaggerMiddleware.Invoke(HttpContext httpContext, ISwaggerProvider swaggerProvider)
   at Microsoft.AspNetCore.Diagnostics.DeveloperExceptionPageMiddleware.Invoke(HttpContext context)


I'm trying to use a class similar to the example in the postgresql page on RepoDB just to see if I can get this working (using a WebApi project):
```
namespace TestApi.Data
{
    public enum Gender
    {
        Male,
        Female
    }
}

namespace TestApi.Data
{
    public class Person
    {
        public long Id { get; set; }
        public string Name { get; set; }
        public int Age { get; set; }
        public Gender Gender { get; set; }
    }
}
```
The other change I've done is I have this in Configuration because I want enums to return their string value instead of int:
```
services.AddControllers().AddJsonOptions(opts =>
{
    opts.JsonSerializerOptions.Converters.Add(new JsonStringEnumConverter());
});
```

Side note: I did get this working but would like to use the non-raw form if possible:

```
[HttpGet]
public IEnumerable<Person> Get()
{
    var ConnectionString = ""Host=localhost;Username=postgres;Password=postgres;Database=test"";
    using (var connection = new NpgsqlConnection(ConnectionString))
    {
        var gender = Gender.Male;
        var sql = $""SELECT * FROM \""Person\"" WHERE \""Gender\"" = '{gender}';"";
        var name = connection.ExecuteQuery<Person>(sql);
        return name;
    }
}
```","Does Postgresql support querying on enums in non-raw form? I'm trying to use Postgresql enums (database first) in my project but it tosses an error. Am I doing something wrong or is this not supported? My webapi get looks like this: ``` [HttpGet] public IEnumerable<Person> Get() { var ConnectionString = ""Host=localhost;Username=postgres;Password=postgres;Database=test""; using (var connection = new NpgsqlConnection(ConnectionString)) { var name2 = connection.Query<Person>(e => e.Gender == Gender.Male); return name2; } } ``` Here's the error: System.InvalidCastException: Can't write CLR type TestApi.Data.Gender with handler type TextHandler at lambda_method8(Closure , NpgsqlTypeHandler , Object , NpgsqlLengthCache& , NpgsqlParameter ) at Npgsql.TypeHandling.NpgsqlTypeHandler`1.ValidateObjectAndGetLength(Object value, NpgsqlLengthCache& lengthCache, NpgsqlParameter parameter) at Npgsql.NpgsqlParameter.ValidateAndGetLength() at Npgsql.NpgsqlCommand.ValidateParameters(ConnectorTypeMapper typeMapper) at Npgsql.NpgsqlCommand.ExecuteReader(CommandBehavior behavior, Boolean async, CancellationToken cancellationToken) at Npgsql.NpgsqlCommand.ExecuteReader(CommandBehavior behavior, Boolean async, CancellationToken cancellationToken) at Npgsql.NpgsqlCommand.ExecuteReader(CommandBehavior behavior) at Npgsql.NpgsqlCommand.ExecuteDbDataReader(CommandBehavior behavior) at System.Data.Common.DbCommand.ExecuteReader() at RepoDb.DbConnectionExtension.ExecuteQueryInternalForType[TResult](IDbConnection connection, String commandText, Object param, Nullable`1 commandType, String cacheKey, Nullable`1 cacheItemExpiration, Nullable`1 commandTimeout, IDbTransaction transaction, ICache cache, String tableName, Boolean skipCommandArrayParametersCheck) at RepoDb.DbConnectionExtension.ExecuteQueryInternal[TResult](IDbConnection connection, String commandText, Object param, Nullable`1 commandType, String cacheKey, Nullable`1 cacheItemExpiration, Nullable`1 commandTimeout, IDbTransaction transaction, ICache cache, String tableName, Boolean skipCommandArrayParametersCheck) at RepoDb.DbConnectionExtension.QueryInternalBase[TEntity](IDbConnection connection, String tableName, QueryGroup where, IEnumerable`1 fields, IEnumerable`1 orderBy, Nullable`1 top, String hints, String cacheKey, Nullable`1 cacheItemExpiration, Nullable`1 commandTimeout, IDbTransaction transaction, ICache cache, ITrace trace, IStatementBuilder statementBuilder) at RepoDb.DbConnectionExtension.QueryInternal[TEntity](IDbConnection connection, String tableName, QueryGroup where, IEnumerable`1 fields, IEnumerable`1 orderBy, Nullable`1 top, String hints, String cacheKey, Nullable`1 cacheItemExpiration, Nullable`1 commandTimeout, IDbTransaction transaction, ICache cache, ITrace trace, IStatementBuilder statementBuilder) at RepoDb.DbConnectionExtension.Query[TEntity](IDbConnection connection, Expression`1 where, IEnumerable`1 fields, IEnumerable`1 orderBy, Nullable`1 top, String hints, String cacheKey, Nullable`1 cacheItemExpiration, Nullable`1 commandTimeout, IDbTransaction transaction, ICache cache, ITrace trace, IStatementBuilder statementBuilder) at TestApi.Controllers.WeatherForecastController.Get() in C:\Users\glori\source\repos\TestApi\TestApi\Controllers\WeatherForecastController.cs:line 39 at lambda_method2(Closure , Object , Object[] ) at Microsoft.AspNetCore.Mvc.Infrastructure.ActionMethodExecutor.SyncObjectResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, Object controller, Object[] arguments) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.InvokeActionMethodAsync() at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.InvokeNextActionFilterAsync() --- End of stack trace from previous location --- at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Rethrow(ActionExecutedContextSealed context) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.Next(State& next, Scope& scope, Object& state, Boolean& isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ControllerActionInvoker.InvokeInnerFilterAsync() --- End of stack trace from previous location --- at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeFilterPipelineAsync>g__Awaited|19_0(ResourceInvoker invoker, Task lastTask, State next, Scope scope, Object state, Boolean isCompleted) at Microsoft.AspNetCore.Mvc.Infrastructure.ResourceInvoker.<InvokeAsync>g__Awaited|17_0(ResourceInvoker invoker, Task task, IDisposable scope) at Microsoft.AspNetCore.Routing.EndpointMiddleware.<Invoke>g__AwaitRequestTask|6_0(Endpoint endpoint, Task requestTask, ILogger logger) at Microsoft.AspNetCore.Authorization.AuthorizationMiddleware.Invoke(HttpContext context) at Swashbuckle.AspNetCore.SwaggerUI.SwaggerUIMiddleware.Invoke(HttpContext httpContext) at Swashbuckle.AspNetCore.Swagger.SwaggerMiddleware.Invoke(HttpContext httpContext, ISwaggerProvider swaggerProvider) at Microsoft.AspNetCore.Diagnostics.DeveloperExceptionPageMiddleware.Invoke(HttpContext context) I'm trying to use a class similar to the example in the postgresql page on RepoDB just to see if I can get this working (using a WebApi project): ``` namespace TestApi.Data { public enum Gender { Male, Female } } namespace TestApi.Data { public class Person { public long Id { get; set; } public string Name { get; set; } public int Age { get; set; } public Gender Gender { get; set; } } } ``` The other change I've done is I have this in Configuration because I want enums to return their string value instead of int: ``` services.AddControllers().AddJsonOptions(opts => { opts.JsonSerializerOptions.Converters.Add(new JsonStringEnumConverter()); }); ``` Side note: I did get this working but would like to use the non-raw form if possible: ``` [HttpGet] public IEnumerable<Person> Get() { var ConnectionString = ""Host=localhost;Username=postgres;Password=postgres;Database=test""; using (var connection = new NpgsqlConnection(ConnectionString)) { var gender = Gender.Male; var sql = $""SELECT * FROM \""Person\"" WHERE \""Gender\"" = '{gender}';""; var name = connection.ExecuteQuery<Person>(sql); return name; } } ```"
46093,46093,51307,https://api.github.com/repos/RMPR/atbswp/issues/27,0.0,2020-08-11T01:43:02Z,NONE,https://api.github.com/repos/RMPR/atbswp,Load/Save/Compile not working with the v0.1 release,"<!--

######################################################################
  WARNING!
  IGNORING THE FOLLOWING TEMPLATE WILL RESULT IN ISSUE CLOSED AS INCOMPLETE
######################################################################

-->


## Checklist

<!--
Carefully read and work through this list in order to prevent the most common mistakes and misuse of atbswp:
- First of, make sure you are using the latest release of atbswp. 
- Search the bugtracker for similar issues: https://github.com/rmpr/atbswp/issues. DO NOT post duplicates.
- Put x into all relevant boxes (like this [x])
-->
- [x] I use the latest release of atbswp
- [ ] The issue is not existing yet

## Verbose log

<!-- Provide the content of /tmp/atbswp-DD-MM-YYYY or if using Windows %tmp%\atbswp-DD-MM-YYYY -->

```
Gtk:ERROR:../../../../gtk/gtkiconhelper.c:494:ensure_surface_for_gicon: assertion failed (error == NULL): Failed to load /usr/share/icons/Faba/16x16/status/image-missing.svg: Unable to load image-loading module: /usr/lib/x86_64-linux-gnu/gdk-pixbuf-2.0/2.10.0/loaders/libpixbufloader-svg.so: /lib/x86_64-linux-gnu/librsvg-2.so.2: undefined symbol: cairo_font_options_get_variations (gdk-pixbuf-error-quark, 5)
Aborted (core dumped)

```

## Miscellaneous information

### Operating System
Ubuntu 20.04

### Desktop Environment/Window Manager
Budgie

### Python version
Python 3.8.2

## Description

<!--
Provide an explanation of your issue in an arbitrary form. Please make sure the description is worded well enough to be understood.
Or post a screencast of the issue.
-->

Load, save, and compile cause atbswp to crash
","Load/Save/Compile not working with the v0.1 release <!-- ###################################################################### WARNING! IGNORING THE FOLLOWING TEMPLATE WILL RESULT IN ISSUE CLOSED AS INCOMPLETE ###################################################################### --> ## Checklist <!-- Carefully read and work through this list in order to prevent the most common mistakes and misuse of atbswp: - First of, make sure you are using the latest release of atbswp. - Search the bugtracker for similar issues: https://github.com/rmpr/atbswp/issues. DO NOT post duplicates. - Put x into all relevant boxes (like this [x]) --> - [x] I use the latest release of atbswp - [ ] The issue is not existing yet ## Verbose log <!-- Provide the content of /tmp/atbswp-DD-MM-YYYY or if using Windows %tmp%\atbswp-DD-MM-YYYY --> ``` Gtk:ERROR:../../../../gtk/gtkiconhelper.c:494:ensure_surface_for_gicon: assertion failed (error == NULL): Failed to load /usr/share/icons/Faba/16x16/status/image-missing.svg: Unable to load image-loading module: /usr/lib/x86_64-linux-gnu/gdk-pixbuf-2.0/2.10.0/loaders/libpixbufloader-svg.so: /lib/x86_64-linux-gnu/librsvg-2.so.2: undefined symbol: cairo_font_options_get_variations (gdk-pixbuf-error-quark, 5) Aborted (core dumped) ``` ## Miscellaneous information ### Operating System Ubuntu 20.04 ### Desktop Environment/Window Manager Budgie ### Python version Python 3.8.2 ## Description <!-- Provide an explanation of your issue in an arbitrary form. Please make sure the description is worded well enough to be understood. Or post a screencast of the issue. --> Load, save, and compile cause atbswp to crash "
523616,523616,581944,https://api.github.com/repos/CareHomeHub/CareHomePlatform/issues/5,1.0,2021-02-16T00:58:49Z,CONTRIBUTOR,https://api.github.com/repos/CareHomeHub/CareHomePlatform,Create Travis CI YML file,,Create Travis CI YML file 
274300,274300,305058,https://api.github.com/repos/wardsquid/journal/issues/124,0.0,2021-01-07T16:29:24Z,CONTRIBUTOR,https://api.github.com/repos/wardsquid/journal,Signing into a second account from same device causes caching issues,"Steps to recreate: 
1) Sign into an existing account A
2) Sign out
3) Sign in again to a new account B
4) Bug: displays info from account A even though you are signed into account B

",Signing into a second account from same device causes caching issues Steps to recreate: 1) Sign into an existing account A 2) Sign out 3) Sign in again to a new account B 4) Bug: displays info from account A even though you are signed into account B 
586611,586611,651869,https://api.github.com/repos/niece1/airinsider/issues/54,1.0,2020-12-16T21:58:44Z,OWNER,https://api.github.com/repos/niece1/airinsider,Search UI,Create search UI,Search UI Create search UI
714383,714383,793964,https://api.github.com/repos/hasii2011/PyArcadeStarTrek/issues/5,1.0,2021-04-25T20:55:45Z,OWNER,https://api.github.com/repos/hasii2011/PyArcadeStarTrek,Change subviews to not import GameView,"Both of the Galaxy View and the LR Scan View should be changed to use a callback;  
The callback switches us back to the game view",Change subviews to not import GameView Both of the Galaxy View and the LR Scan View should be changed to use a callback; The callback switches us back to the game view
275614,275614,306521,https://api.github.com/repos/cmus/cmus/issues/637,0.0,2017-02-10T18:13:53Z,NONE,https://api.github.com/repos/cmus/cmus,format string with two levels of conditions and long format key does not allow width specifier,"`cmus --version`:
cmus v2.8.0-rc0

Its me again with another string format issue. :) I found that I cannot specify a width for an item if it is
- within two levels of conditions and
- a long keyword, i.e. one that uses braces

I.o.w., the following format strings work:
`:set format_trackwin=%{?date?%{?date?%{date}}}`
`:set format_trackwin=%{?date?%{?date?%4y}}`

But this does not, even though it should be identical to the last one mentioned above:
`:set format_trackwin=%{?date?%{?date?%4{date}}}`","format string with two levels of conditions and long format key does not allow width specifier `cmus --version`: cmus v2.8.0-rc0 Its me again with another string format issue. :) I found that I cannot specify a width for an item if it is - within two levels of conditions and - a long keyword, i.e. one that uses braces I.o.w., the following format strings work: `:set format_trackwin=%{?date?%{?date?%{date}}}` `:set format_trackwin=%{?date?%{?date?%4y}}` But this does not, even though it should be identical to the last one mentioned above: `:set format_trackwin=%{?date?%{?date?%4{date}}}`"
574037,574037,637915,https://api.github.com/repos/cgwire/kitsu/issues/687,2.0,2021-04-21T09:01:30Z,NONE,https://api.github.com/repos/cgwire/kitsu,Kitsu Player counter does not respect mixed content,"If I try to upload to preview mixed content like video and images the player counter does not show total number of elements properly. 
For example if I upload 1 video file and 4 images at the same time the counter in Kitsu Player will show ""1"" for video omitting  total number of elements (but ""2/5"" for second image, ""3/5"" and so on - which is correct behavior).
Here is a gif demonstrating the issue
![issue](https://user-images.githubusercontent.com/13551109/115526722-01461c00-a299-11eb-8e3b-122d5b3b0308.gif)

","Kitsu Player counter does not respect mixed content If I try to upload to preview mixed content like video and images the player counter does not show total number of elements properly. For example if I upload 1 video file and 4 images at the same time the counter in Kitsu Player will show ""1"" for video omitting total number of elements (but ""2/5"" for second image, ""3/5"" and so on - which is correct behavior). Here is a gif demonstrating the issue ![issue](https://user-images.githubusercontent.com/13551109/115526722-01461c00-a299-11eb-8e3b-122d5b3b0308.gif) "
776891,776891,538763,https://api.github.com/repos/Siteimprove/alfa/issues/524,0.0,2020-11-04T14:09:13Z,COLLABORATOR,https://api.github.com/repos/Siteimprove/alfa,`isVisible()` does not account for text hidden via `text-indent`,"`isVisible()` returns `true` for the following case:

```html
<style>
  .hidden {
    overflow: hidden;
    white-space: nowrap;
    text-indent: 100%;
  }
</style>

<div class=""hidden"">This text is hidden</div>
```

#532 is needed for this.

- [ ] Follow up on DEV-10828.
- [ ] Follow up on DEV-10887.","`isVisible()` does not account for text hidden via `text-indent` `isVisible()` returns `true` for the following case: ```html <style> .hidden { overflow: hidden; white-space: nowrap; text-indent: 100%; } </style> <div class=""hidden"">This text is hidden</div> ``` #532 is needed for this. - [ ] Follow up on DEV-10828. - [ ] Follow up on DEV-10887."
275868,275868,306797,https://api.github.com/repos/microsoft/azure-pipelines-tasks/issues/13845,2.0,2020-11-05T14:31:01Z,NONE,https://api.github.com/repos/microsoft/azure-pipelines-tasks,DockerHostEndpoint for Docker@2 Task,"Why has that setting been removed from the Docker task?
Our self-hosted agents are docker instances, so they can't use the docker build command and our only way for now is using Docker@1 and accessing the docker host.

## Required Information

Entering this information will route you directly to the right team and expedite traction.

*Type*: Question

**Enter Task Name**: Docker@2

## Environment
- Server DevOps on-prem
    
    - If using TFS on-premises, provide the version: Dev18.M170.6

- Agent - Hosted or Private:  private docker images

    - If using private agent, provide the OS of the machine running the agent and the agent version: Ubuntu 18.04 and Windows Agents

## Issue Description
Docker Host not available in Agents running as Docker Containers","DockerHostEndpoint for Docker@2 Task Why has that setting been removed from the Docker task? Our self-hosted agents are docker instances, so they can't use the docker build command and our only way for now is using Docker@1 and accessing the docker host. ## Required Information Entering this information will route you directly to the right team and expedite traction. *Type*: Question **Enter Task Name**: Docker@2 ## Environment - Server DevOps on-prem - If using TFS on-premises, provide the version: Dev18.M170.6 - Agent - Hosted or Private: private docker images - If using private agent, provide the OS of the machine running the agent and the agent version: Ubuntu 18.04 and Windows Agents ## Issue Description Docker Host not available in Agents running as Docker Containers"
521030,521030,579073,https://api.github.com/repos/remkop/picocli/issues/1301,2.0,2021-01-08T14:58:15Z,NONE,https://api.github.com/repos/remkop/picocli,Best way to support ''--lines=[+]NUM' ?,"Hi there,

Thanks again for making picocli. So I developed a small too with similar options to tail, and I didn't found a straightforward
way to express an option like this : 

```
Mandatory arguments to long options are mandatory for short options too.
  -c, --bytes=[+]NUM       output the last NUM bytes; or use -c +NUM to.
                             output starting with byte NUM of each file
  -f, --follow[={name|descriptor}]
                           output appended data as the file grows;
                             an absent option argument means 'descriptor'
  -F                       same as --follow=name --retry
  -n, --lines=[+]NUM       output the last NUM lines, instead of the last 10;  <<===
                             or use -n +NUM to output starting with line NUM
```

Programmatically I can handle the optional plus, if it is a string, but I wonder if it's possible to do that easily within the logic of picocli ?

By the way my project is there : https://github.com/bric3/drain-java
The command line parsing is still quite dumb as I focused on other aspects but I will eventually commit to make it better and leveraging more picocli.","Best way to support ''--lines=[+]NUM' ? Hi there, Thanks again for making picocli. So I developed a small too with similar options to tail, and I didn't found a straightforward way to express an option like this : ``` Mandatory arguments to long options are mandatory for short options too. -c, --bytes=[+]NUM output the last NUM bytes; or use -c +NUM to. output starting with byte NUM of each file -f, --follow[={name|descriptor}] output appended data as the file grows; an absent option argument means 'descriptor' -F same as --follow=name --retry -n, --lines=[+]NUM output the last NUM lines, instead of the last 10; <<=== or use -n +NUM to output starting with line NUM ``` Programmatically I can handle the optional plus, if it is a string, but I wonder if it's possible to do that easily within the logic of picocli ? By the way my project is there : https://github.com/bric3/drain-java The command line parsing is still quite dumb as I focused on other aspects but I will eventually commit to make it better and leveraging more picocli."
694734,694734,772176,https://api.github.com/repos/Minecraft-Eternal/MC-Eternal-1.12/issues/139,0.0,2021-05-02T23:13:18Z,NONE,https://api.github.com/repos/Minecraft-Eternal/MC-Eternal-1.12,The game opens loads 3 steps in and crashes.,"**Describe the bug**
A clear and concise description of what the bug is.

**Version of MC Eternal**
Which version of the mod pack are you on?

**To Reproduce**
Steps to reproduce the behavior:
1. Go to '...'
2. Click on '....'
3. Scroll down to '....'
4. See error

**Expected behavior**
A clear and concise description of what you expected to happen.

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Additional context**
Add any other context about the problem here.
","The game opens loads 3 steps in and crashes. **Describe the bug** A clear and concise description of what the bug is. **Version of MC Eternal** Which version of the mod pack are you on? **To Reproduce** Steps to reproduce the behavior: 1. Go to '...' 2. Click on '....' 3. Scroll down to '....' 4. See error **Expected behavior** A clear and concise description of what you expected to happen. **Screenshots** If applicable, add screenshots to help explain your problem. **Additional context** Add any other context about the problem here. "
540753,540753,601034,https://api.github.com/repos/OCA/pos/issues/635,2.0,2021-05-05T11:24:45Z,MEMBER,https://api.github.com/repos/OCA/pos,RFC: pos_order_return continuity,"With the current state of the art of `pos_order_mgmt`, which already supports returns and even uses the same field names for related refunded orders I'm not sure about the need of this module anymore.

What do you think? @dalonsod @legalsylvain @pedrobaeza @kirca @ivantodorovich 

TT27219","RFC: pos_order_return continuity With the current state of the art of `pos_order_mgmt`, which already supports returns and even uses the same field names for related refunded orders I'm not sure about the need of this module anymore. What do you think? @dalonsod @legalsylvain @pedrobaeza @kirca @ivantodorovich TT27219"
796103,796103,729481,https://api.github.com/repos/jdb78/pytorch-forecasting/issues/478,2.0,2021-05-01T20:38:13Z,NONE,https://api.github.com/repos/jdb78/pytorch-forecasting,Question: Understanding the X and y TimeSeriesDataSet produces,"I know this issue doesn't really comply with the draft but this isn't really about a bug, rather the methodology.

I am pretty new at time series forecasting and trying to understand encoder/decoder networks. I understand that I give a set of values for say `t-4`, `t-3`, `t-2`, `t-1` and `t` to forecast `t+1` and `t+2` but I don't understand why we also put `t+1` and `t+2` to the `X`.

For instance, in this tutorial, [https://pytorch-forecasting.readthedocs.io/en/latest/tutorials/building.html#passing-data](https://pytorch-forecasting.readthedocs.io/en/latest/tutorials/building.html#passing-data), when I also use `target_normalizer=None`, all values in `y`, `X['decoder_cont']` and `X['decoder_target']` becomes same. Why do we pass the output we aim to the network? Could you please refer me to a reading or briefly explain the rationale here?","Question: Understanding the X and y TimeSeriesDataSet produces I know this issue doesn't really comply with the draft but this isn't really about a bug, rather the methodology. I am pretty new at time series forecasting and trying to understand encoder/decoder networks. I understand that I give a set of values for say `t-4`, `t-3`, `t-2`, `t-1` and `t` to forecast `t+1` and `t+2` but I don't understand why we also put `t+1` and `t+2` to the `X`. For instance, in this tutorial, [https://pytorch-forecasting.readthedocs.io/en/latest/tutorials/building.html#passing-data](https://pytorch-forecasting.readthedocs.io/en/latest/tutorials/building.html#passing-data), when I also use `target_normalizer=None`, all values in `y`, `X['decoder_cont']` and `X['decoder_target']` becomes same. Why do we pass the output we aim to the network? Could you please refer me to a reading or briefly explain the rationale here?"
601344,601344,668295,https://api.github.com/repos/d-fischer/twitch/issues/216,0.0,2021-02-02T03:35:30Z,CONTRIBUTOR,https://api.github.com/repos/d-fischer/twitch,EventSub: TypeError for splitting algoAndSignature when the header is missing,"## Bug Report

If a call to the endpoint is missing the `twitch-eventsub-message-signature` header, the program exits.

```js
/home/alca/projects/eventsub-demo/node_modules/twitch-eventsub/lib/Subscriptions/EventSubSubscription.js:49
        var _a = tslib_1.__read(algoAndSignature.split('=', 2), 2), algorithm = _a[0], signature = _a[1];
                                                 ^
TypeError: Cannot read property 'split' of undefined
    at EventSubChannelFollowSubscription.EventSubSubscription._verifyData (/home/alca/projects/eventsub-demo/node_modules/twitch-eventsub/lib/Subscriptions/EventSubSubscription.js:49:50)
    at EventSubListener.<anonymous> (/home/alca/projects/eventsub-demo/node_modules/twitch-eventsub/lib/EventSubListener.js:650:49)
    at step (/home/alca/projects/eventsub-demo/node_modules/tslib/tslib.js:143:27)
    at Object.next (/home/alca/projects/eventsub-demo/node_modules/tslib/tslib.js:124:57)
    at fulfilled (/home/alca/projects/eventsub-demo/node_modules/tslib/tslib.js:114:62)
    at processTicksAndRejections (node:internal/process/task_queues:94:5)
```

### Code

Create an EventSub listener.
```ts
import { ApiClient } from 'twitch';
import { ClientCredentialsAuthProvider } from 'twitch-auth';
import { EventSubListener, SomeAdapter } from 'twitch-eventsub';

const authProvider = new ClientCredentialsAuthProvider(process.env.CLIENT_ID, process.env.CLIENT_SECRET);
const apiClient = new ApiClient({ authProvider });
const adapter = new SomeAdapter(/* ... */);
const eventSubListener = new EventSubListener(apiClient, adapter, process.env.EVENTSUB_SECRET);
eventSubListener.listen(process.env.PORT);

eventSubListener.subscribeToChannelFollowEvents('7676884', () => {});
```

Use something to send a request to the listener.

For example, the twitch-cli:
```
twitch event trigger follow -F http://localhost:$PORT/channel.follow.7676884
```

### Expected behavior

The request should be dropped.

### Actual Behavior

The process exits.

### Environment

- Version: 4.4.7
- Node version: 15.7.0
- Operating system: Ubuntu 4.15.0-134-generic","EventSub: TypeError for splitting algoAndSignature when the header is missing ## Bug Report If a call to the endpoint is missing the `twitch-eventsub-message-signature` header, the program exits. ```js /home/alca/projects/eventsub-demo/node_modules/twitch-eventsub/lib/Subscriptions/EventSubSubscription.js:49 var _a = tslib_1.__read(algoAndSignature.split('=', 2), 2), algorithm = _a[0], signature = _a[1]; ^ TypeError: Cannot read property 'split' of undefined at EventSubChannelFollowSubscription.EventSubSubscription._verifyData (/home/alca/projects/eventsub-demo/node_modules/twitch-eventsub/lib/Subscriptions/EventSubSubscription.js:49:50) at EventSubListener.<anonymous> (/home/alca/projects/eventsub-demo/node_modules/twitch-eventsub/lib/EventSubListener.js:650:49) at step (/home/alca/projects/eventsub-demo/node_modules/tslib/tslib.js:143:27) at Object.next (/home/alca/projects/eventsub-demo/node_modules/tslib/tslib.js:124:57) at fulfilled (/home/alca/projects/eventsub-demo/node_modules/tslib/tslib.js:114:62) at processTicksAndRejections (node:internal/process/task_queues:94:5) ``` ### Code Create an EventSub listener. ```ts import { ApiClient } from 'twitch'; import { ClientCredentialsAuthProvider } from 'twitch-auth'; import { EventSubListener, SomeAdapter } from 'twitch-eventsub'; const authProvider = new ClientCredentialsAuthProvider(process.env.CLIENT_ID, process.env.CLIENT_SECRET); const apiClient = new ApiClient({ authProvider }); const adapter = new SomeAdapter(/* ... */); const eventSubListener = new EventSubListener(apiClient, adapter, process.env.EVENTSUB_SECRET); eventSubListener.listen(process.env.PORT); eventSubListener.subscribeToChannelFollowEvents('7676884', () => {}); ``` Use something to send a request to the listener. For example, the twitch-cli: ``` twitch event trigger follow -F http://localhost:$PORT/channel.follow.7676884 ``` ### Expected behavior The request should be dropped. ### Actual Behavior The process exits. ### Environment - Version: 4.4.7 - Node version: 15.7.0 - Operating system: Ubuntu 4.15.0-134-generic"
139515,139515,155060,https://api.github.com/repos/ctoec/data-collection/issues/1061,0.0,2021-01-15T13:37:37Z,MEMBER,https://api.github.com/repos/ctoec/data-collection,GET /children?siteMap=true returns 500,"```TypeError: Cannot read property 'siteName' of null```

enrollments w/out site will cause this query to fail ",GET /children?siteMap=true returns 500 ```TypeError: Cannot read property 'siteName' of null``` enrollments w/out site will cause this query to fail 
264147,264147,293779,https://api.github.com/repos/milvus-io/milvus/issues/4808,0.0,2021-03-14T10:25:35Z,NONE,https://api.github.com/repos/milvus-io/milvus,the example links is gone,"Hi Team,

When I try to read https://github.com/milvus-io/pymilvus/blob/1.0.1/examples/example.py, it returns 404, could you please kindly check?

Thanks in advance!
","the example links is gone Hi Team, When I try to read https://github.com/milvus-io/pymilvus/blob/1.0.1/examples/example.py, it returns 404, could you please kindly check? Thanks in advance! "
133220,133220,148064,https://api.github.com/repos/MJurczak-PMarchut/remote-measurement-station/issues/1,1.0,2021-01-03T09:59:54Z,OWNER,https://api.github.com/repos/MJurczak-PMarchut/remote-measurement-station,Independent timebase required,"Independent timebase with at least 10us accuracy required
32bit timer preffered ",Independent timebase required Independent timebase with at least 10us accuracy required 32bit timer preffered 
244387,244387,271810,https://api.github.com/repos/CakeML/cakeml/issues/825,0.0,2021-04-25T17:40:40Z,CONTRIBUTOR,https://api.github.com/repos/CakeML/cakeml,Negative floating point literals are those of C,"The use of sscanf in the FFI to handle floating-point literal parsing means that ~42.0 in ML syntax gets translated to the wrong number.

val d = Double.fromString ""~42.0"";
val _ = print (""~42.0 ----> ""^Double.toString d^""\n"");

val d = Double.fromString ""-42.0"";
val _ = print (""-42.0 ----> ""^Double.toString d^""\n"");
","Negative floating point literals are those of C The use of sscanf in the FFI to handle floating-point literal parsing means that ~42.0 in ML syntax gets translated to the wrong number. val d = Double.fromString ""~42.0""; val _ = print (""~42.0 ----> ""^Double.toString d^""\n""); val d = Double.fromString ""-42.0""; val _ = print (""-42.0 ----> ""^Double.toString d^""\n""); "
612102,612102,680232,https://api.github.com/repos/bossbuwi/itlog/issues/11,1.0,2021-04-02T12:09:50Z,OWNER,https://api.github.com/repos/bossbuwi/itlog,Organize the calendar tab.,"The calendar tab is messy. Tables are resizing like crazy, the calendar is in an awkward position and the event details are just an eye sore. The tab is working just fine but there should be something that could be improved upon in order to have a cleaner and more elegant interface and UX.
_This is subjective so it is a low priority issue._","Organize the calendar tab. The calendar tab is messy. Tables are resizing like crazy, the calendar is in an awkward position and the event details are just an eye sore. The tab is working just fine but there should be something that could be improved upon in order to have a cleaner and more elegant interface and UX. _This is subjective so it is a low priority issue._"
776787,776787,537725,https://api.github.com/repos/Max-ChenFei/FreeImage-CMake/issues/4,2.0,2021-04-12T13:58:19Z,OWNER,https://api.github.com/repos/Max-ChenFei/FreeImage-CMake,"TIFFReadDirectory: Warning, Unknown field with tag, TIFFFieldWithTag: Internal error, unknown tag","FreeImage and FreeImage plus works fine on Windows.
However, I meet some issues on ubuntu. 

Firstly, install **libfreeimageplus-dev** on ubuntu via 
`Sudo apt-get install libfreeimageplus-dev on Linux`.

load TIFF image
```
fipImage fimg(FIT_FLOAT);
fimg.load(lpszMultiPage2);
```
some warining as follows:
```
TIFFReadDirectory: Warning, Unknown field with tag 50838 (0xc696) encountered.
TIFFReadDirectory: Warning, Unknown field with tag 50839 (0xc697) encountered.
TIFFFieldWithTag: Internal error, unknown tag 0x829a.
TIFFFieldWithTag: Internal error, unknown tag 0x829d.
TIFFFieldWithTag: Internal error, unknown tag 0x8822.
TIFFFieldWithTag: Internal error, unknown tag 0x8824.
TIFFFieldWithTag: Internal error, unknown tag 0x8827.
TIFFFieldWithTag: Internal error, unknown tag 0x8828.
TIFFFieldWithTag: Internal error, unknown tag 0x9000.
TIFFFieldWithTag: Internal error, unknown tag 0x9003.
TIFFFieldWithTag: Internal error, unknown tag 0x9004.
TIFFFieldWithTag: Internal error, unknown tag 0x9101.
TIFFFieldWithTag: Internal error, unknown tag 0x9102.
TIFFFieldWithTag: Internal error, unknown tag 0x9201.
TIFFFieldWithTag: Internal error, unknown tag 0x9202.
TIFFFieldWithTag: Internal error, unknown tag 0x9203.
TIFFFieldWithTag: Internal error, unknown tag 0x9204.
TIFFFieldWithTag: Internal error, unknown tag 0x9205.
TIFFFieldWithTag: Internal error, unknown tag 0x9206.
TIFFFieldWithTag: Internal error, unknown tag 0x9207.
TIFFFieldWithTag: Internal error, unknown tag 0x9208.
TIFFFieldWithTag: Internal error, unknown tag 0x9209.
TIFFFieldWithTag: Internal error, unknown tag 0x920a.
TIFFFieldWithTag: Internal error, unknown tag 0x9214.
TIFFFieldWithTag: Internal error, unknown tag 0x927c.
TIFFFieldWithTag: Internal error, unknown tag 0x9286.
TIFFFieldWithTag: Internal error, unknown tag 0x9290.
TIFFFieldWithTag: Internal error, unknown tag 0x9291.
TIFFFieldWithTag: Internal error, unknown tag 0x9292.
TIFFFieldWithTag: Internal error, unknown tag 0xa000.
TIFFFieldWithTag: Internal error, unknown tag 0xa001.
TIFFFieldWithTag: Internal error, unknown tag 0xa002.
TIFFFieldWithTag: Internal error, unknown tag 0xa003.
TIFFFieldWithTag: Internal error, unknown tag 0xa004.
TIFFFieldWithTag: Internal error, unknown tag 0xa20b.
TIFFFieldWithTag: Internal error, unknown tag 0xa20c.
TIFFFieldWithTag: Internal error, unknown tag 0xa20e.
TIFFFieldWithTag: Internal error, unknown tag 0xa20f.
TIFFFieldWithTag: Internal error, unknown tag 0xa210.
TIFFFieldWithTag: Internal error, unknown tag 0xa214.
TIFFFieldWithTag: Internal error, unknown tag 0xa215.
TIFFFieldWithTag: Internal error, unknown tag 0xa217.
TIFFFieldWithTag: Internal error, unknown tag 0xa300.
TIFFFieldWithTag: Internal error, unknown tag 0xa301.
TIFFFieldWithTag: Internal error, unknown tag 0xa302.
TIFFFieldWithTag: Internal error, unknown tag 0xa401.
TIFFFieldWithTag: Internal error, unknown tag 0xa402.
TIFFFieldWithTag: Internal error, unknown tag 0xa403.
TIFFFieldWithTag: Internal error, unknown tag 0xa404.
TIFFFieldWithTag: Internal error, unknown tag 0xa405.
TIFFFieldWithTag: Internal error, unknown tag 0xa406.
TIFFFieldWithTag: Internal error, unknown tag 0xa407.
TIFFFieldWithTag: Internal error, unknown tag 0xa408.
TIFFFieldWithTag: Internal error, unknown tag 0xa409.
TIFFFieldWithTag: Internal error, unknown tag 0xa40a.
TIFFFieldWithTag: Internal error, unknown tag 0xa40b.
TIFFFieldWithTag: Internal error, unknown tag 0xa40c.
TIFFFieldWithTag: Internal error, unknown tag 0xa407.
TIFFFieldWithTag: Internal error, unknown tag 0xa407.
TIFFFieldWithTag: Internal error, unknown tag 0xa420.
```
save TIFF image
```
fipImage fimg(FIT_FLOAT, image->getResolution().x, image->getResolution().y, 32);
fimg.load(lpszMultiPage2);
```
error happened:
`symbol lookup error:......`


Secondly,  build the FreeImage from source code
1. download source code  from offical [website](https://freeimage.sourceforge.io/). 
2. follow the README.linux inside FreeImage folder.
> Installation
>------------
>Note: You will need to have root privileges in order to install the library in the /usr/lib directory.
>The installation process is as simple as this : 
>1) Enter the FreeImage directory
>2) Build the distribution : 
>make
>make install
>3) Clean all files produced during the build process
>make clean

>Compiling FreeImagePlus
>-----------------------
>FreeImagePlus is a C++ wrapper for FreeImage. 
>To compile FreeImage as a C++ library, follow these steps : 
>1) Enter the FreeImage directory
>2) Build the distribution : 
>make -f Makefile.fip
>make -f Makefile.fip install
>3) Clean all files produced during the build process
>make -f Makefile.fip clean

Some warning and errors happed when saving and loading the TIFF images","TIFFReadDirectory: Warning, Unknown field with tag, TIFFFieldWithTag: Internal error, unknown tag FreeImage and FreeImage plus works fine on Windows. However, I meet some issues on ubuntu. Firstly, install **libfreeimageplus-dev** on ubuntu via `Sudo apt-get install libfreeimageplus-dev on Linux`. load TIFF image ``` fipImage fimg(FIT_FLOAT); fimg.load(lpszMultiPage2); ``` some warining as follows: ``` TIFFReadDirectory: Warning, Unknown field with tag 50838 (0xc696) encountered. TIFFReadDirectory: Warning, Unknown field with tag 50839 (0xc697) encountered. TIFFFieldWithTag: Internal error, unknown tag 0x829a. TIFFFieldWithTag: Internal error, unknown tag 0x829d. TIFFFieldWithTag: Internal error, unknown tag 0x8822. TIFFFieldWithTag: Internal error, unknown tag 0x8824. TIFFFieldWithTag: Internal error, unknown tag 0x8827. TIFFFieldWithTag: Internal error, unknown tag 0x8828. TIFFFieldWithTag: Internal error, unknown tag 0x9000. TIFFFieldWithTag: Internal error, unknown tag 0x9003. TIFFFieldWithTag: Internal error, unknown tag 0x9004. TIFFFieldWithTag: Internal error, unknown tag 0x9101. TIFFFieldWithTag: Internal error, unknown tag 0x9102. TIFFFieldWithTag: Internal error, unknown tag 0x9201. TIFFFieldWithTag: Internal error, unknown tag 0x9202. TIFFFieldWithTag: Internal error, unknown tag 0x9203. TIFFFieldWithTag: Internal error, unknown tag 0x9204. TIFFFieldWithTag: Internal error, unknown tag 0x9205. TIFFFieldWithTag: Internal error, unknown tag 0x9206. TIFFFieldWithTag: Internal error, unknown tag 0x9207. TIFFFieldWithTag: Internal error, unknown tag 0x9208. TIFFFieldWithTag: Internal error, unknown tag 0x9209. TIFFFieldWithTag: Internal error, unknown tag 0x920a. TIFFFieldWithTag: Internal error, unknown tag 0x9214. TIFFFieldWithTag: Internal error, unknown tag 0x927c. TIFFFieldWithTag: Internal error, unknown tag 0x9286. TIFFFieldWithTag: Internal error, unknown tag 0x9290. TIFFFieldWithTag: Internal error, unknown tag 0x9291. TIFFFieldWithTag: Internal error, unknown tag 0x9292. TIFFFieldWithTag: Internal error, unknown tag 0xa000. TIFFFieldWithTag: Internal error, unknown tag 0xa001. TIFFFieldWithTag: Internal error, unknown tag 0xa002. TIFFFieldWithTag: Internal error, unknown tag 0xa003. TIFFFieldWithTag: Internal error, unknown tag 0xa004. TIFFFieldWithTag: Internal error, unknown tag 0xa20b. TIFFFieldWithTag: Internal error, unknown tag 0xa20c. TIFFFieldWithTag: Internal error, unknown tag 0xa20e. TIFFFieldWithTag: Internal error, unknown tag 0xa20f. TIFFFieldWithTag: Internal error, unknown tag 0xa210. TIFFFieldWithTag: Internal error, unknown tag 0xa214. TIFFFieldWithTag: Internal error, unknown tag 0xa215. TIFFFieldWithTag: Internal error, unknown tag 0xa217. TIFFFieldWithTag: Internal error, unknown tag 0xa300. TIFFFieldWithTag: Internal error, unknown tag 0xa301. TIFFFieldWithTag: Internal error, unknown tag 0xa302. TIFFFieldWithTag: Internal error, unknown tag 0xa401. TIFFFieldWithTag: Internal error, unknown tag 0xa402. TIFFFieldWithTag: Internal error, unknown tag 0xa403. TIFFFieldWithTag: Internal error, unknown tag 0xa404. TIFFFieldWithTag: Internal error, unknown tag 0xa405. TIFFFieldWithTag: Internal error, unknown tag 0xa406. TIFFFieldWithTag: Internal error, unknown tag 0xa407. TIFFFieldWithTag: Internal error, unknown tag 0xa408. TIFFFieldWithTag: Internal error, unknown tag 0xa409. TIFFFieldWithTag: Internal error, unknown tag 0xa40a. TIFFFieldWithTag: Internal error, unknown tag 0xa40b. TIFFFieldWithTag: Internal error, unknown tag 0xa40c. TIFFFieldWithTag: Internal error, unknown tag 0xa407. TIFFFieldWithTag: Internal error, unknown tag 0xa407. TIFFFieldWithTag: Internal error, unknown tag 0xa420. ``` save TIFF image ``` fipImage fimg(FIT_FLOAT, image->getResolution().x, image->getResolution().y, 32); fimg.load(lpszMultiPage2); ``` error happened: `symbol lookup error:......` Secondly, build the FreeImage from source code 1. download source code from offical [website](https://freeimage.sourceforge.io/). 2. follow the README.linux inside FreeImage folder. > Installation >------------ >Note: You will need to have root privileges in order to install the library in the /usr/lib directory. >The installation process is as simple as this : >1) Enter the FreeImage directory >2) Build the distribution : >make >make install >3) Clean all files produced during the build process >make clean >Compiling FreeImagePlus >----------------------- >FreeImagePlus is a C++ wrapper for FreeImage. >To compile FreeImage as a C++ library, follow these steps : >1) Enter the FreeImage directory >2) Build the distribution : >make -f Makefile.fip >make -f Makefile.fip install >3) Clean all files produced during the build process >make -f Makefile.fip clean Some warning and errors happed when saving and loading the TIFF images"
673212,673212,748210,https://api.github.com/repos/03one02one/CSBasic/issues/18,1.0,2021-04-27T01:50:05Z,OWNER,https://api.github.com/repos/03one02one/CSBasic,switch 議곌굔臾,,switch 議곌굔臾 
284369,284369,316265,https://api.github.com/repos/WatkingStudio/HurzixAdventure/issues/56,1.0,2021-03-22T17:27:38Z,OWNER,https://api.github.com/repos/WatkingStudio/HurzixAdventure,KeyManager Fixes,"**Brief Description**
Fix the following issues in the KeyManager class

**Checklist**
- [x] Rearrange Class Functions/Variables
- [x] Add Function Comments
- [x] Line 27 - Add brackets to these if-statements

**Detailed Description**
*If further detail is required for this issue please provide it here*

**Additional Info**
*If there is any additional information required put it here*
",KeyManager Fixes **Brief Description** Fix the following issues in the KeyManager class **Checklist** - [x] Rearrange Class Functions/Variables - [x] Add Function Comments - [x] Line 27 - Add brackets to these if-statements **Detailed Description** *If further detail is required for this issue please provide it here* **Additional Info** *If there is any additional information required put it here* 
688902,688902,765648,https://api.github.com/repos/studieverenigingid/i.d-Website/issues/136,1.0,2021-01-13T15:34:24Z,CONTRIBUTOR,https://api.github.com/repos/studieverenigingid/i.d-Website,Move ticket overview to profile page,"bought tickets are displayed on a random page now, that should be integrated with the profile page","Move ticket overview to profile page bought tickets are displayed on a random page now, that should be integrated with the profile page"
82750,82750,91994,https://api.github.com/repos/NoteGramBot/NoteGram/issues/12,1.0,2021-03-01T00:02:00Z,NONE,https://api.github.com/repos/NoteGramBot/NoteGram,[Propuesta] Crear una issue por cada hito del curso,"He pensado que podr챠a ser buena idea crear una issue y a챰adirla al kanban principal del proyecto por cada hito del curso, as챠 podr챠an discutirse en 챕sta todos los aspectos del hito en s챠, tener claro el '쩔qu챕 hay que hacer?' y nos permitir챠a marcar como cerrado el issue cuando se hayan completado todas las tareas asociadas, reabrirlo en caso de que surgieran nuevas cosas que hacer respecto de ese issue y en general tener una visi처n clara de nuestro progreso y del 'backlog' del curso.","[Propuesta] Crear una issue por cada hito del curso He pensado que podr챠a ser buena idea crear una issue y a챰adirla al kanban principal del proyecto por cada hito del curso, as챠 podr챠an discutirse en 챕sta todos los aspectos del hito en s챠, tener claro el '쩔qu챕 hay que hacer?' y nos permitir챠a marcar como cerrado el issue cuando se hayan completado todas las tareas asociadas, reabrirlo en caso de que surgieran nuevas cosas que hacer respecto de ese issue y en general tener una visi처n clara de nuestro progreso y del 'backlog' del curso."
568737,568737,632054,https://api.github.com/repos/ivanvinski/devbout/issues/64,1.0,2021-02-07T12:17:29Z,OWNER,https://api.github.com/repos/ivanvinski/devbout,Refactor devbout plugin,"Remove duplication and keep it simple.

## Tasks

* [x] Refactor projects slicing to API instance
* [x] Simplify `devbout` plugin API instance",Refactor devbout plugin Remove duplication and keep it simple. ## Tasks * [x] Refactor projects slicing to API instance * [x] Simplify `devbout` plugin API instance
415417,415417,461757,https://api.github.com/repos/chan-sccp/chan-sccp/issues/567,0.0,2021-02-13T13:34:18Z,NONE,https://api.github.com/repos/chan-sccp/chan-sccp,[spurious issue] FRACK! / res_agi / hangup / segfault,"Asterisk crashes with ERROR[24577][C-00000058]: pbx_variables.c:1084 pbx_builtin_setvar_helper: FRACK!, Failed assertion bad magic number 0x0 for object 0x7fc4d0020330 (0) 

**Reproduction Steps:**

1. End call via hang up on a Cisco 7975 on commit 16fd7da


**chan-sccp version:** (include revision and/or branch if relevant)

4.3.3 develop - 16fd7da 

**asterisk version:** (include revision and/or branch if relevant)

16.15.1

**Expected behavior:**

Not crashing :) 

**Observed behavior:**

Appears that when a 7975 hangs up a call, this is the last bit of the Asterisk CLI trace before a crash: 
```
    -- SEPF09E630FF5D1: is Onhook (buttonIndex: 0, callid: 0)
  == SEPF09E630FF5D1: Ending call SCCP/404-00000071 (state:CONNECTED)
    -- SEPF09E630FF5D1: Sending hangupRequest to Call SCCP/404-00000071 (state: CONNECTED)
  == MixMonitor close filestream (mixed)
[2021-02-12 15:59:11] WARNING[13049][C-00000058]: channel.c:2282 ast_channel_destructor: PBX may not have been terminated properly on 'SCCP/404-00000071'
  == End MixMonitor Recording SCCP/404-00000071
    -- QualityStats: MLQK=4.5000;MLQKav=4.4433;MLQKmn=3.9155;MLQKmx=4.5000;ICR=0.0000;CCR=0.0016;ICRmx=0.0434;CS=11;SCS=3;MLQKvr=0.95
    -- SEPF09E630FF5D1: Call Statistics:
       [
         Last Call        : CallID: 113 Packets sent: 9854 rcvd: 9834 lost: 1 jitter: 0 latency: 0
         Last Quality     : MLQK=4.5000;MLQKav=4.4433;MLQKmn=3.9155;MLQKmx=4.5000;MLQKvr=0.95|ICR=0.0000;CCR=0.0016;ICRmx=0.0434|CS=11;SCS=3
         Mean Statistics  : #Calls: 16 Packets sent: 3409 rcvd: 3395 lost: 0 jitter: 0 latency: 0
         Mean Quality     : MLQK=3.3476;MLQKav=3.3150;MLQKmn=3.1784;MLQKmx=4.5000;MLQKvr=0.95|ICR=0.0024;CCR=0.0030;ICRmx=0.0434|CS=2;SCS=0
       ]
    -- <>AGI Script agi://127.0.0.1/sangomacrm.agi completed, returning 0
[2021-02-12 15:59:11] ERROR[24577][C-00000058]: pbx_variables.c:1084 pbx_builtin_setvar_helper: FRACK!, Failed assertion bad magic number 0x0 for object 0x7fc4d0020330 (0)
[2021-02-12 15:59:11] ERROR[24577][C-00000058]:   Got 17 backtrace records
# 0: /usr/sbin/asterisk(__ast_assert_failed+0x84) [0x5c4eb5]
# 1: /usr/sbin/asterisk() [0x45ef13]
# 2: /usr/sbin/asterisk(__ao2_lock+0x64) [0x45ef79]
# 3: /usr/sbin/asterisk(pbx_builtin_setvar_helper+0x111) [0x54a367]
# 4: /usr/lib64/asterisk/modules/res_agi.so(+0x11011) [0x7fc489d5f011]
# 5: /usr/lib64/asterisk/modules/res_agi.so(+0x110d6) [0x7fc489d5f0d6]
# 6: /usr/sbin/asterisk(pbx_exec+0x11c) [0x54025a]
# 7: /usr/sbin/asterisk() [0x52bc5c]
# 8: /usr/sbin/asterisk(ast_spawn_extension+0x64) [0x52fa68]
# 9: /usr/lib64/asterisk/modules/app_stack.so(+0x5429) [0x7fc4ba1cd429]
#10: /usr/sbin/asterisk(ast_app_exec_sub+0xb9) [0x4429c1]
#11: /usr/sbin/asterisk(ast_pbx_hangup_handler_run+0x173) [0x545a4b]
#12: /usr/sbin/asterisk() [0x531a5b]
#13: /usr/sbin/asterisk() [0x531ef9]
#14: /usr/sbin/asterisk() [0x5c2226]
#15: /lib64/libpthread.so.0(+0x7ea5) [0x7fc4db861ea5]
#16: /lib64/libc.so.6(clone+0x6d) [0x7fc4da9008dd] 
```

**Addition / Optional Information:**
- Problem started happening recently, didn't happen in an older version of Chan-SCCP: Yes
- Problem can be reliably reproduced, doesn't happen randomly: No - seems to occur every few hours, but not consistently 
- Platform:
  - Linode cloud PBX 
  - 64-bit
  - 4GB RAM 
  - 1 core on AMD EPYC 7601 
  - Sangoma Linux (based on CentOS)

- Direct Contact information: andy.bradford.cms@gmail.com
- Log Files [trace_crash_16fd7da.txt](https://github.com/chan-sccp/chan-sccp/files/5975726/trace_crash_16fd7da.txt)
- Comments: [Other Information]


","[spurious issue] FRACK! / res_agi / hangup / segfault Asterisk crashes with ERROR[24577][C-00000058]: pbx_variables.c:1084 pbx_builtin_setvar_helper: FRACK!, Failed assertion bad magic number 0x0 for object 0x7fc4d0020330 (0) **Reproduction Steps:** 1. End call via hang up on a Cisco 7975 on commit 16fd7da **chan-sccp version:** (include revision and/or branch if relevant) 4.3.3 develop - 16fd7da **asterisk version:** (include revision and/or branch if relevant) 16.15.1 **Expected behavior:** Not crashing :) **Observed behavior:** Appears that when a 7975 hangs up a call, this is the last bit of the Asterisk CLI trace before a crash: ``` -- SEPF09E630FF5D1: is Onhook (buttonIndex: 0, callid: 0) == SEPF09E630FF5D1: Ending call SCCP/404-00000071 (state:CONNECTED) -- SEPF09E630FF5D1: Sending hangupRequest to Call SCCP/404-00000071 (state: CONNECTED) == MixMonitor close filestream (mixed) [2021-02-12 15:59:11] WARNING[13049][C-00000058]: channel.c:2282 ast_channel_destructor: PBX may not have been terminated properly on 'SCCP/404-00000071' == End MixMonitor Recording SCCP/404-00000071 -- QualityStats: MLQK=4.5000;MLQKav=4.4433;MLQKmn=3.9155;MLQKmx=4.5000;ICR=0.0000;CCR=0.0016;ICRmx=0.0434;CS=11;SCS=3;MLQKvr=0.95 -- SEPF09E630FF5D1: Call Statistics: [ Last Call : CallID: 113 Packets sent: 9854 rcvd: 9834 lost: 1 jitter: 0 latency: 0 Last Quality : MLQK=4.5000;MLQKav=4.4433;MLQKmn=3.9155;MLQKmx=4.5000;MLQKvr=0.95|ICR=0.0000;CCR=0.0016;ICRmx=0.0434|CS=11;SCS=3 Mean Statistics : #Calls: 16 Packets sent: 3409 rcvd: 3395 lost: 0 jitter: 0 latency: 0 Mean Quality : MLQK=3.3476;MLQKav=3.3150;MLQKmn=3.1784;MLQKmx=4.5000;MLQKvr=0.95|ICR=0.0024;CCR=0.0030;ICRmx=0.0434|CS=2;SCS=0 ] -- <>AGI Script agi://127.0.0.1/sangomacrm.agi completed, returning 0 [2021-02-12 15:59:11] ERROR[24577][C-00000058]: pbx_variables.c:1084 pbx_builtin_setvar_helper: FRACK!, Failed assertion bad magic number 0x0 for object 0x7fc4d0020330 (0) [2021-02-12 15:59:11] ERROR[24577][C-00000058]: Got 17 backtrace records # 0: /usr/sbin/asterisk(__ast_assert_failed+0x84) [0x5c4eb5] # 1: /usr/sbin/asterisk() [0x45ef13] # 2: /usr/sbin/asterisk(__ao2_lock+0x64) [0x45ef79] # 3: /usr/sbin/asterisk(pbx_builtin_setvar_helper+0x111) [0x54a367] # 4: /usr/lib64/asterisk/modules/res_agi.so(+0x11011) [0x7fc489d5f011] # 5: /usr/lib64/asterisk/modules/res_agi.so(+0x110d6) [0x7fc489d5f0d6] # 6: /usr/sbin/asterisk(pbx_exec+0x11c) [0x54025a] # 7: /usr/sbin/asterisk() [0x52bc5c] # 8: /usr/sbin/asterisk(ast_spawn_extension+0x64) [0x52fa68] # 9: /usr/lib64/asterisk/modules/app_stack.so(+0x5429) [0x7fc4ba1cd429] #10: /usr/sbin/asterisk(ast_app_exec_sub+0xb9) [0x4429c1] #11: /usr/sbin/asterisk(ast_pbx_hangup_handler_run+0x173) [0x545a4b] #12: /usr/sbin/asterisk() [0x531a5b] #13: /usr/sbin/asterisk() [0x531ef9] #14: /usr/sbin/asterisk() [0x5c2226] #15: /lib64/libpthread.so.0(+0x7ea5) [0x7fc4db861ea5] #16: /lib64/libc.so.6(clone+0x6d) [0x7fc4da9008dd] ``` **Addition / Optional Information:** - Problem started happening recently, didn't happen in an older version of Chan-SCCP: Yes - Problem can be reliably reproduced, doesn't happen randomly: No - seems to occur every few hours, but not consistently - Platform: - Linode cloud PBX - 64-bit - 4GB RAM - 1 core on AMD EPYC 7601 - Sangoma Linux (based on CentOS) - Direct Contact information: andy.bradford.cms@gmail.com - Log Files [trace_crash_16fd7da.txt](https://github.com/chan-sccp/chan-sccp/files/5975726/trace_crash_16fd7da.txt) - Comments: [Other Information] "
95742,95742,106418,https://api.github.com/repos/folio-org/folio-analytics/issues/375,0.0,2021-03-12T11:54:06Z,CONTRIBUTOR,https://api.github.com/repos/folio-org/folio-analytics,Use transactions amounts for ERM inventory cost query,,Use transactions amounts for ERM inventory cost query 
425490,425490,472969,https://api.github.com/repos/DocCyblade/squirrelpak-mc12/issues/35,1.0,2021-01-29T13:55:52Z,OWNER,https://api.github.com/repos/DocCyblade/squirrelpak-mc12,Changes to immersiveengineering.cfg,"Below are changes made:

Railgun should be awesome, lets make it so number one.... or two 

```
        # The base amount of Flux consumed per shot by the Railgun
        # Min: 1
        # Max: 2147483647
        # Default: 800
        I:railgun_consumption=1600

        # A modifier for the damage of all projectiles fired by the Railgun
        # Min: 0.001
        # Max: 1.7976931348623157E308
        # Default: 1.0
        D:railgun_damage=2.0


```","Changes to immersiveengineering.cfg Below are changes made: Railgun should be awesome, lets make it so number one.... or two ``` # The base amount of Flux consumed per shot by the Railgun # Min: 1 # Max: 2147483647 # Default: 800 I:railgun_consumption=1600 # A modifier for the damage of all projectiles fired by the Railgun # Min: 0.001 # Max: 1.7976931348623157E308 # Default: 1.0 D:railgun_damage=2.0 ```"
756756,756756,336646,https://api.github.com/repos/McFlyboy/Touhou-Launcher/issues/40,1.0,2021-04-22T22:35:33Z,OWNER,https://api.github.com/repos/McFlyboy/Touhou-Launcher,Implement Launch Random Game feature,Call LaunchGame for a random game,Implement Launch Random Game feature Call LaunchGame for a random game
558302,558302,620493,https://api.github.com/repos/2101capstone/interviewPrep/issues/52,1.0,2021-03-29T18:53:44Z,CONTRIBUTOR,https://api.github.com/repos/2101capstone/interviewPrep,Facial Map on/off toggle button,"- [ ] Be able to turn on and off face map 
- [ ]  for both recording and no recording",Facial Map on/off toggle button - [ ] Be able to turn on and off face map - [ ] for both recording and no recording
298781,298781,332205,https://api.github.com/repos/Sage/carbon/issues/3850,0.0,2021-03-22T15:55:49Z,MEMBER,https://api.github.com/repos/Sage/carbon,FlatTable - height issue,"### Current behaviour

When `hasStickyHead` is added to FlatTable, a `height: 100%` is added to a table, this causes the following issue based on layout decisions:

![Screenshot 2021-03-22 at 15 53 46](https://user-images.githubusercontent.com/2411024/112018837-d3997600-8b26-11eb-8f8c-bfcad35ca4ea.png)

code:

![Screenshot 2021-03-22 at 15 55 27](https://user-images.githubusercontent.com/2411024/112019141-0fccd680-8b27-11eb-9628-74e5513683b7.png)

### Expected behaviour

Either the table should have an adequate background/borders or a max-height: 100% option, rather than height:100%

### Suggested solution(s)

Allow the option of either using max-height:100%, or if height: 100% is used then we need correct background and border styling and not a transparent gap.","FlatTable - height issue ### Current behaviour When `hasStickyHead` is added to FlatTable, a `height: 100%` is added to a table, this causes the following issue based on layout decisions: ![Screenshot 2021-03-22 at 15 53 46](https://user-images.githubusercontent.com/2411024/112018837-d3997600-8b26-11eb-8f8c-bfcad35ca4ea.png) code: ![Screenshot 2021-03-22 at 15 55 27](https://user-images.githubusercontent.com/2411024/112019141-0fccd680-8b27-11eb-9628-74e5513683b7.png) ### Expected behaviour Either the table should have an adequate background/borders or a max-height: 100% option, rather than height:100% ### Suggested solution(s) Allow the option of either using max-height:100%, or if height: 100% is used then we need correct background and border styling and not a transparent gap."
112617,112617,125173,https://api.github.com/repos/Przemyslaw5/cinema-reservation/issues/10,0.0,2021-03-01T06:37:36Z,COLLABORATOR,https://api.github.com/repos/Przemyslaw5/cinema-reservation,Fix path in frontend,"When I wont to open https://cinema-reservation.theliver.pl/movies directly in browser, then I have 404.","Fix path in frontend When I wont to open https://cinema-reservation.theliver.pl/movies directly in browser, then I have 404."
646557,646557,718660,https://api.github.com/repos/ioBroker/ioBroker.js-controller/issues/1333,2.0,2021-05-03T13:23:05Z,NONE,https://api.github.com/repos/ioBroker/ioBroker.js-controller,Object common read / write Parameter (write=false) f체hrt kein Beschreiben des Wertes aus.,"Mit der neuen Version 3.3.7 habe ich ein anderes Verhalten als mit der 3.2
Wenn ich im Object unter common write = false setze , l채sst sich nicht immer der Wert setzen den der Adapter setzen will. Seltsamerweise sind dies Werte die der Adapter auf 0 setzen will.
Wenn also vorher 30 drin stand und der Adapter (mit setstate (...,ack)) den Wert auf 0 setzen will , bleiben die 30 stehen und auch die Update Time ist dann die vom Wert 30.
(common / min ist 0 und common / max ist 100)

{
  ""from"": ""system.adapter.resol.0"",
  ""user"": ""system.user.admin"",
  ""ts"": 1620048450021,
  ""common"": {
    ""name"": ""Drehzahl Relais"",
    ""type"": ""number"",
    ""unit"": ""%"",
    ""role"": ""level.volume"",
    ""min"": 0,
    ""max"": 100,
    ""read"": true,
    ""write"": false   <-- dies f체hrt zum nicht Setzen des Wertes ;  ""write"": true funktioniert
  },
  ""native"": {},
  ""acl"": {
    ""object"": 1636,
    ""owner"": ""system.user.admin"",
    ""ownerGroup"": ""system.group.administrator"",
    ""state"": 1636
  },
  ""_id"": ""resol.0.0011210010.4385.000010112110010001210"",
  ""type"": ""state""
}

Ist der common / write parameter nicht so gedacht, da zwar das System (Adapter) reinschreiben darf, aber der Anwender nicht ?","Object common read / write Parameter (write=false) f체hrt kein Beschreiben des Wertes aus. Mit der neuen Version 3.3.7 habe ich ein anderes Verhalten als mit der 3.2 Wenn ich im Object unter common write = false setze , l채sst sich nicht immer der Wert setzen den der Adapter setzen will. Seltsamerweise sind dies Werte die der Adapter auf 0 setzen will. Wenn also vorher 30 drin stand und der Adapter (mit setstate (...,ack)) den Wert auf 0 setzen will , bleiben die 30 stehen und auch die Update Time ist dann die vom Wert 30. (common / min ist 0 und common / max ist 100) { ""from"": ""system.adapter.resol.0"", ""user"": ""system.user.admin"", ""ts"": 1620048450021, ""common"": { ""name"": ""Drehzahl Relais"", ""type"": ""number"", ""unit"": ""%"", ""role"": ""level.volume"", ""min"": 0, ""max"": 100, ""read"": true, ""write"": false <-- dies f체hrt zum nicht Setzen des Wertes ; ""write"": true funktioniert }, ""native"": {}, ""acl"": { ""object"": 1636, ""owner"": ""system.user.admin"", ""ownerGroup"": ""system.group.administrator"", ""state"": 1636 }, ""_id"": ""resol.0.0011210010.4385.000010112110010001210"", ""type"": ""state"" } Ist der common / write parameter nicht so gedacht, da zwar das System (Adapter) reinschreiben darf, aber der Anwender nicht ?"
273662,273662,304340,https://api.github.com/repos/fsi-tue/ppi/issues/12,0.0,2021-01-12T09:09:09Z,COLLABORATOR,https://api.github.com/repos/fsi-tue/ppi,Filter by username doens't work,"Affects: logevents.php
The filter by username filter doesn't work.",Filter by username doens't work Affects: logevents.php The filter by username filter doesn't work.
404705,404705,449824,https://api.github.com/repos/libsdl-org/SDL/issues/1438,0.0,2021-02-10T23:34:06Z,COLLABORATOR,https://api.github.com/repos/libsdl-org/SDL,Crashes due to the non thread-safe SDL_malloc/SDL_free on Windows,"
# This bug report was migrated from our old Bugzilla tracker.

These attachments are available in the static archive:

* [Example to reproduce the crash (sdl_mem_crash.c, text/plain, 2014-04-13 10:17:46 +0000, 889 bytes)](https://bugzilla.libsdl.org/attachment.cgi?id=1618)

**Reported in version:** 2.0.3
**Reported for operating system, platform:** Windows 8, x86_64

# Comments on the original bug report:

On 2014-04-13 10:17:46 +0000, Pavlo Ilin wrote:

> Created attachment 1618
> Example to reproduce the crash
> 
> Windows implementation of SDL_malloc/SDL_free/etc. uses dlmalloc instead of CRT malloc. Current settings of dlmalloc are not thread-safe, so it's dangerous to allocate/free memory simultaneously in the separate threads. SDL itself and some libraries like SDL_mixer actually depend on this feature.
> 
> Attached is a short example, which reproduces the crash. Usually, crash looks like this: ""Unhandled exception at 0x6C7B543D (SDL2.dll) in sdl_mem_crash.exe: 0xC0000005: Access violation reading location 0x00000004""
> I used MS Visual Studio 2013 and SDL2-devel-2.0.3-VC x86 library. Debug builds of my test application are more prone to the crash. 
> 
> I tried to compile my own version of the SDL library with changes in the SDL_malloc.c: 
> 1) Enabling HAVE_MALLOC and use of the CRT memory allocator fixes the problem.
> 2) Setting USE_LOCKS also fixes the problem, but, as the flag's description says:
> 
> > When USE_LOCKS is defined, each public call to malloc, free,
> > etc is surrounded with either a pthread mutex or a win32
> > spinlock (depending on WIN32). This is not especially fast, and
> > can be a major bottleneck.  It is designed only to provide
> > minimal protection in concurrent environments, and to provide a
> > basis for extensions.  If you are using malloc in a concurrent
> > program, consider instead using ptmalloc, which is derived from
> > a version of this malloc.
> 
> Current implementation of SDL_malloc for Windows was introduced in 2006. I'm amazed, that no one have reported this issue.

On 2014-04-18 04:50:00 +0000, Sam Lantinga wrote:

> That is amazing that nobody else has reported this. I think we'll look into ptmalloc, since we want to avoid a C runtime dependency. Thanks!

On 2014-04-18 04:59:17 +0000, Sam Lantinga wrote:

> For future reference, a version of ptmalloc with a license we can use is available here:
> http://www.malloc.de/

On 2014-04-18 06:28:24 +0000, Pavlo Ilin wrote:

> Latest version of ptmalloc3 is released 2006 and based on dlmalloc 2.8.3 (same as in SDL).  ptmalloc would be probably the easiest to integrate, because it should be the closest relative of dlmalloc. But there are a lot of good allocators. May be it's worth to consider them.
> 
> Doug Lea in his latest dlmalloc 2.8.6 also mentions nedmalloc as a possible substitute (http://www.nedprod.com/programs/portable/nedmalloc and https://github.com/ned14/nedmalloc). Nedmalloc claims to be slightly better than ptmalloc3.
> 
> jemalloc can be other replacement (http://www.canonware.com/jemalloc/ and https://github.com/jemalloc/jemalloc/). Looks like it is a default allocator in FreeBSD and was used quite successfully in Firefox, Facebook, and Blender.
> 
> Both projects were alive in the last years.

On 2014-05-09 18:57:15 +0000, Keith O'Conor wrote:

> FYI, I had a crash when cleaning up SDL threads that I debugged and came to the same conclusion as Pavlo - see the discussion thread at http://forums.libsdl.org/viewtopic.php?p=43411 that also has sample code to repro the crash (although Pavlo's is a better example).
> 
> I was also surprised that this hasn't come up before now, and only found this bug now when I went to log it myself. Strange timing, nothing for 6 years and then twice in one month!

On 2014-05-10 18:35:19 +0000, Sam Lantinga wrote:

> This bug is taken care of for a while, until someone has time to investigate the other malloc() implementations.
> https://hg.libsdl.org/SDL/rev/3b1ed6708ce9
> 
> Thanks!

","Crashes due to the non thread-safe SDL_malloc/SDL_free on Windows # This bug report was migrated from our old Bugzilla tracker. These attachments are available in the static archive: * [Example to reproduce the crash (sdl_mem_crash.c, text/plain, 2014-04-13 10:17:46 +0000, 889 bytes)](https://bugzilla.libsdl.org/attachment.cgi?id=1618) **Reported in version:** 2.0.3 **Reported for operating system, platform:** Windows 8, x86_64 # Comments on the original bug report: On 2014-04-13 10:17:46 +0000, Pavlo Ilin wrote: > Created attachment 1618 > Example to reproduce the crash > > Windows implementation of SDL_malloc/SDL_free/etc. uses dlmalloc instead of CRT malloc. Current settings of dlmalloc are not thread-safe, so it's dangerous to allocate/free memory simultaneously in the separate threads. SDL itself and some libraries like SDL_mixer actually depend on this feature. > > Attached is a short example, which reproduces the crash. Usually, crash looks like this: ""Unhandled exception at 0x6C7B543D (SDL2.dll) in sdl_mem_crash.exe: 0xC0000005: Access violation reading location 0x00000004"" > I used MS Visual Studio 2013 and SDL2-devel-2.0.3-VC x86 library. Debug builds of my test application are more prone to the crash. > > I tried to compile my own version of the SDL library with changes in the SDL_malloc.c: > 1) Enabling HAVE_MALLOC and use of the CRT memory allocator fixes the problem. > 2) Setting USE_LOCKS also fixes the problem, but, as the flag's description says: > > > When USE_LOCKS is defined, each public call to malloc, free, > > etc is surrounded with either a pthread mutex or a win32 > > spinlock (depending on WIN32). This is not especially fast, and > > can be a major bottleneck. It is designed only to provide > > minimal protection in concurrent environments, and to provide a > > basis for extensions. If you are using malloc in a concurrent > > program, consider instead using ptmalloc, which is derived from > > a version of this malloc. > > Current implementation of SDL_malloc for Windows was introduced in 2006. I'm amazed, that no one have reported this issue. On 2014-04-18 04:50:00 +0000, Sam Lantinga wrote: > That is amazing that nobody else has reported this. I think we'll look into ptmalloc, since we want to avoid a C runtime dependency. Thanks! On 2014-04-18 04:59:17 +0000, Sam Lantinga wrote: > For future reference, a version of ptmalloc with a license we can use is available here: > http://www.malloc.de/ On 2014-04-18 06:28:24 +0000, Pavlo Ilin wrote: > Latest version of ptmalloc3 is released 2006 and based on dlmalloc 2.8.3 (same as in SDL). ptmalloc would be probably the easiest to integrate, because it should be the closest relative of dlmalloc. But there are a lot of good allocators. May be it's worth to consider them. > > Doug Lea in his latest dlmalloc 2.8.6 also mentions nedmalloc as a possible substitute (http://www.nedprod.com/programs/portable/nedmalloc and https://github.com/ned14/nedmalloc). Nedmalloc claims to be slightly better than ptmalloc3. > > jemalloc can be other replacement (http://www.canonware.com/jemalloc/ and https://github.com/jemalloc/jemalloc/). Looks like it is a default allocator in FreeBSD and was used quite successfully in Firefox, Facebook, and Blender. > > Both projects were alive in the last years. On 2014-05-09 18:57:15 +0000, Keith O'Conor wrote: > FYI, I had a crash when cleaning up SDL threads that I debugged and came to the same conclusion as Pavlo - see the discussion thread at http://forums.libsdl.org/viewtopic.php?p=43411 that also has sample code to repro the crash (although Pavlo's is a better example). > > I was also surprised that this hasn't come up before now, and only found this bug now when I went to log it myself. Strange timing, nothing for 6 years and then twice in one month! On 2014-05-10 18:35:19 +0000, Sam Lantinga wrote: > This bug is taken care of for a while, until someone has time to investigate the other malloc() implementations. > https://hg.libsdl.org/SDL/rev/3b1ed6708ce9 > > Thanks! "
76769,76769,85358,https://api.github.com/repos/argoproj/argo-cd/issues/5519,0.0,2021-02-15T12:07:48Z,MEMBER,https://api.github.com/repos/argoproj/argo-cd,CLI should not display empty tool version fields from server,"Checklist:

* [x] I've searched in the docs and FAQ for my answer: https://bit.ly/argocd-faq.
* [x] I've included steps to reproduce the bug.
* [x] I've pasted the output of `argocd version`.

**Describe the bug**

With 1.8.4, we have disabled the output of installation specific version information to unauthenticated consumers of the version endpoint. However, this looks funny when using `argocd version` and not being authenticated.

**To Reproduce**

Run `argocd version` with an unauthenticated client:

```
argocd: v1.8.4+28aea3d
  BuildDate: 2021-02-05T17:54:42Z
  GitCommit: 28aea3dfdede00443b52cc584814d80e8f896200
  GitTreeState: clean
  GoVersion: go1.14.12
  Compiler: gc
  Platform: linux/amd64
argocd-server: v1.8.4+28aea3d
  BuildDate: 
  GitCommit: 
  GitTreeState: 
  GoVersion: 
  Compiler: 
  Platform: 
  Ksonnet Version: 
  Kustomize Version: 
  Helm Version: 
  Kubectl Version: 
  Jsonnet Version: 
```
**Expected behavior**

The CLI should detect the empty version information and not display the rows at all.

**Version**

Affects 1.8.4 and 1.7.12

","CLI should not display empty tool version fields from server Checklist: * [x] I've searched in the docs and FAQ for my answer: https://bit.ly/argocd-faq. * [x] I've included steps to reproduce the bug. * [x] I've pasted the output of `argocd version`. **Describe the bug** With 1.8.4, we have disabled the output of installation specific version information to unauthenticated consumers of the version endpoint. However, this looks funny when using `argocd version` and not being authenticated. **To Reproduce** Run `argocd version` with an unauthenticated client: ``` argocd: v1.8.4+28aea3d BuildDate: 2021-02-05T17:54:42Z GitCommit: 28aea3dfdede00443b52cc584814d80e8f896200 GitTreeState: clean GoVersion: go1.14.12 Compiler: gc Platform: linux/amd64 argocd-server: v1.8.4+28aea3d BuildDate: GitCommit: GitTreeState: GoVersion: Compiler: Platform: Ksonnet Version: Kustomize Version: Helm Version: Kubectl Version: Jsonnet Version: ``` **Expected behavior** The CLI should detect the empty version information and not display the rows at all. **Version** Affects 1.8.4 and 1.7.12 "
245132,245132,272636,https://api.github.com/repos/LaserSrl/Laser.Orchard.Platform/issues/14,0.0,2020-10-28T08:13:46Z,NONE,https://api.github.com/repos/LaserSrl/Laser.Orchard.Platform,Laser.Orchard.UsersExtensions/AKUserActions/RegisterSSL: Riferimento a un oggetto non impostato su un'istanza di oggetto.,"retro steps:
- register new user with Laser.Orchard.UsersExtensions/AKUserActions/RegisterSSL API

Collection Postman to test
[https://lasersrl-my.sharepoint.com/:u:/g/personal/patrick_negretto_laser-group_com/ES0rzswpx0RKu-qqf9_DoCsBIrVfWwQYbjxZijrALXYEQQ?e=0bJoGW](url)

The response is 500 with this error on HTML page

`[NullReferenceException: Riferimento a un oggetto non impostato su un&#39;istanza di oggetto.]
   System.Web.Mvc.DefaultModelBinder.BindProperty(ControllerContext controllerContext, ModelBindingContext bindingContext, PropertyDescriptor propertyDescriptor) +1180
   System.Web.Mvc.DefaultModelBinder.BindProperties(ControllerContext controllerContext, ModelBindingContext bindingContext) +143
   System.Web.Mvc.DefaultModelBinder.BindComplexElementalModel(ControllerContext controllerContext, ModelBindingContext bindingContext, Object model) +63
   System.Web.Mvc.DefaultModelBinder.BindComplexModel(ControllerContext controllerContext, ModelBindingContext bindingContext) +1739
   System.Web.Mvc.DefaultModelBinder.UpdateCollection(ControllerContext controllerContext, ModelBindingContext bindingContext, Type elementType) +605
   System.Web.Mvc.DefaultModelBinder.BindComplexModel(ControllerContext controllerContext, ModelBindingContext bindingContext) +1716
   System.Web.Mvc.DefaultModelBinder.GetPropertyValue(ControllerContext controllerContext, ModelBindingContext bindingContext, PropertyDescriptor propertyDescriptor, IModelBinder propertyBinder) +31
   System.Web.Mvc.DefaultModelBinder.BindProperty(ControllerContext controllerContext, ModelBindingContext bindingContext, PropertyDescriptor propertyDescriptor) +483
   System.Web.Mvc.DefaultModelBinder.BindProperties(ControllerContext controllerContext, ModelBindingContext bindingContext) +143
   System.Web.Mvc.DefaultModelBinder.BindComplexElementalModel(ControllerContext controllerContext, ModelBindingContext bindingContext, Object model) +63
   System.Web.Mvc.DefaultModelBinder.BindComplexModel(ControllerContext controllerContext, ModelBindingContext bindingContext) +1739
   System.Web.Mvc.ControllerActionInvoker.GetParameterValue(ControllerContext controllerContext, ParameterDescriptor parameterDescriptor) +459
   System.Web.Mvc.ControllerActionInvoker.GetParameterValues(ControllerContext controllerContext, ActionDescriptor actionDescriptor) +136
   System.Web.Mvc.Async.&lt;&gt;c__DisplayClass21.&lt;BeginInvokeAction&gt;b__19(AsyncCallback asyncCallback, Object asyncState) +1151
   System.Web.Mvc.Async.WrappedAsyncResultBase`1.Begin(AsyncCallback callback, Object state, Int32 timeout) +166
   System.Web.Mvc.Async.AsyncControllerActionInvoker.BeginInvokeAction(ControllerContext controllerContext, String actionName, AsyncCallback callback, Object state) +463
   System.Web.Mvc.Controller.&lt;BeginExecuteCore&gt;b__1c(AsyncCallback asyncCallback, Object asyncState, ExecuteCoreState innerState) +42
   System.Web.Mvc.Async.WrappedAsyncVoid`1.CallBeginDelegate(AsyncCallback callback, Object callbackState) +73
   System.Web.Mvc.Async.WrappedAsyncResultBase`1.Begin(AsyncCallback callback, Object state, Int32 timeout) +166
   System.Web.Mvc.Controller.BeginExecuteCore(AsyncCallback callback, Object state) +906
   System.Web.Mvc.Async.WrappedAsyncResultBase`1.Begin(AsyncCallback callback, Object state, Int32 timeout) +166
   System.Web.Mvc.Controller.BeginExecute(RequestContext requestContext, AsyncCallback callback, Object state) +711
   System.Web.Mvc.MvcHandler.&lt;BeginProcessRequest&gt;b__4(AsyncCallback asyncCallback, Object asyncState, ProcessRequestState innerState) +93
   System.Web.Mvc.Async.WrappedAsyncVoid`1.CallBeginDelegate(AsyncCallback callback, Object callbackState) +73
   System.Web.Mvc.Async.WrappedAsyncResultBase`1.Begin(AsyncCallback callback, Object state, Int32 timeout) +166
   System.Web.Mvc.MvcHandler.BeginProcessRequest(HttpContextBase httpContext, AsyncCallback callback, Object state) +502
   System.Threading.Tasks.TaskFactory`1.FromAsyncImpl(Func`4 beginMethod, Func`2 endFunction, Action`1 endAction, TArg1 arg1, Object state, TaskCreationOptions creationOptions) +824
   Orchard.Mvc.Routes.&lt;&lt;ProcessRequestAsync&gt;b__0&gt;d.MoveNext() +294
   System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() +31
   System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) +60
   Orchard.Owin.&lt;&lt;UseOrchard&gt;b__0_0&gt;d.MoveNext() +323
   System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() +31
   System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) +60
   Orchard.SecureSocketsLayer.Services.&lt;&lt;GetOwinMiddlewares&gt;b__8_1&gt;d.MoveNext() +516
   System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() +31
   System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) +60
   Orchard.Mvc.Routes.&lt;ProcessRequestAsync&gt;d__5.MoveNext() +582
   System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() +31
   System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) +60
   System.Web.TaskAsyncHelper.EndTask(IAsyncResult ar) +64
   System.Web.CallHandlerExecutionStep.System.Web.HttpApplication.IExecutionStep.Execute() +602
   System.Web.HttpApplication.ExecuteStepImpl(IExecutionStep step) +195
   System.Web.HttpApplication.ExecuteStep(IExecutionStep step, Boolean&amp; completedSynchronously) +128`","Laser.Orchard.UsersExtensions/AKUserActions/RegisterSSL: Riferimento a un oggetto non impostato su un'istanza di oggetto. retro steps: - register new user with Laser.Orchard.UsersExtensions/AKUserActions/RegisterSSL API Collection Postman to test [https://lasersrl-my.sharepoint.com/:u:/g/personal/patrick_negretto_laser-group_com/ES0rzswpx0RKu-qqf9_DoCsBIrVfWwQYbjxZijrALXYEQQ?e=0bJoGW](url) The response is 500 with this error on HTML page `[NullReferenceException: Riferimento a un oggetto non impostato su un&#39;istanza di oggetto.] System.Web.Mvc.DefaultModelBinder.BindProperty(ControllerContext controllerContext, ModelBindingContext bindingContext, PropertyDescriptor propertyDescriptor) +1180 System.Web.Mvc.DefaultModelBinder.BindProperties(ControllerContext controllerContext, ModelBindingContext bindingContext) +143 System.Web.Mvc.DefaultModelBinder.BindComplexElementalModel(ControllerContext controllerContext, ModelBindingContext bindingContext, Object model) +63 System.Web.Mvc.DefaultModelBinder.BindComplexModel(ControllerContext controllerContext, ModelBindingContext bindingContext) +1739 System.Web.Mvc.DefaultModelBinder.UpdateCollection(ControllerContext controllerContext, ModelBindingContext bindingContext, Type elementType) +605 System.Web.Mvc.DefaultModelBinder.BindComplexModel(ControllerContext controllerContext, ModelBindingContext bindingContext) +1716 System.Web.Mvc.DefaultModelBinder.GetPropertyValue(ControllerContext controllerContext, ModelBindingContext bindingContext, PropertyDescriptor propertyDescriptor, IModelBinder propertyBinder) +31 System.Web.Mvc.DefaultModelBinder.BindProperty(ControllerContext controllerContext, ModelBindingContext bindingContext, PropertyDescriptor propertyDescriptor) +483 System.Web.Mvc.DefaultModelBinder.BindProperties(ControllerContext controllerContext, ModelBindingContext bindingContext) +143 System.Web.Mvc.DefaultModelBinder.BindComplexElementalModel(ControllerContext controllerContext, ModelBindingContext bindingContext, Object model) +63 System.Web.Mvc.DefaultModelBinder.BindComplexModel(ControllerContext controllerContext, ModelBindingContext bindingContext) +1739 System.Web.Mvc.ControllerActionInvoker.GetParameterValue(ControllerContext controllerContext, ParameterDescriptor parameterDescriptor) +459 System.Web.Mvc.ControllerActionInvoker.GetParameterValues(ControllerContext controllerContext, ActionDescriptor actionDescriptor) +136 System.Web.Mvc.Async.&lt;&gt;c__DisplayClass21.&lt;BeginInvokeAction&gt;b__19(AsyncCallback asyncCallback, Object asyncState) +1151 System.Web.Mvc.Async.WrappedAsyncResultBase`1.Begin(AsyncCallback callback, Object state, Int32 timeout) +166 System.Web.Mvc.Async.AsyncControllerActionInvoker.BeginInvokeAction(ControllerContext controllerContext, String actionName, AsyncCallback callback, Object state) +463 System.Web.Mvc.Controller.&lt;BeginExecuteCore&gt;b__1c(AsyncCallback asyncCallback, Object asyncState, ExecuteCoreState innerState) +42 System.Web.Mvc.Async.WrappedAsyncVoid`1.CallBeginDelegate(AsyncCallback callback, Object callbackState) +73 System.Web.Mvc.Async.WrappedAsyncResultBase`1.Begin(AsyncCallback callback, Object state, Int32 timeout) +166 System.Web.Mvc.Controller.BeginExecuteCore(AsyncCallback callback, Object state) +906 System.Web.Mvc.Async.WrappedAsyncResultBase`1.Begin(AsyncCallback callback, Object state, Int32 timeout) +166 System.Web.Mvc.Controller.BeginExecute(RequestContext requestContext, AsyncCallback callback, Object state) +711 System.Web.Mvc.MvcHandler.&lt;BeginProcessRequest&gt;b__4(AsyncCallback asyncCallback, Object asyncState, ProcessRequestState innerState) +93 System.Web.Mvc.Async.WrappedAsyncVoid`1.CallBeginDelegate(AsyncCallback callback, Object callbackState) +73 System.Web.Mvc.Async.WrappedAsyncResultBase`1.Begin(AsyncCallback callback, Object state, Int32 timeout) +166 System.Web.Mvc.MvcHandler.BeginProcessRequest(HttpContextBase httpContext, AsyncCallback callback, Object state) +502 System.Threading.Tasks.TaskFactory`1.FromAsyncImpl(Func`4 beginMethod, Func`2 endFunction, Action`1 endAction, TArg1 arg1, Object state, TaskCreationOptions creationOptions) +824 Orchard.Mvc.Routes.&lt;&lt;ProcessRequestAsync&gt;b__0&gt;d.MoveNext() +294 System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() +31 System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) +60 Orchard.Owin.&lt;&lt;UseOrchard&gt;b__0_0&gt;d.MoveNext() +323 System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() +31 System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) +60 Orchard.SecureSocketsLayer.Services.&lt;&lt;GetOwinMiddlewares&gt;b__8_1&gt;d.MoveNext() +516 System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() +31 System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) +60 Orchard.Mvc.Routes.&lt;ProcessRequestAsync&gt;d__5.MoveNext() +582 System.Runtime.ExceptionServices.ExceptionDispatchInfo.Throw() +31 System.Runtime.CompilerServices.TaskAwaiter.HandleNonSuccessAndDebuggerNotification(Task task) +60 System.Web.TaskAsyncHelper.EndTask(IAsyncResult ar) +64 System.Web.CallHandlerExecutionStep.System.Web.HttpApplication.IExecutionStep.Execute() +602 System.Web.HttpApplication.ExecuteStepImpl(IExecutionStep step) +195 System.Web.HttpApplication.ExecuteStep(IExecutionStep step, Boolean&amp; completedSynchronously) +128`"
101215,101215,112471,https://api.github.com/repos/trinodb/trino/issues/6464,0.0,2020-12-29T17:19:00Z,NONE,https://api.github.com/repos/trinodb/trino,"SQL Server ""Expected zero to one elements, but found multiple""","SQL Query fails with a simple select * from to any table on the database.
Also tried multiple instances of SQL Server.

![imagen](https://user-images.githubusercontent.com/4541969/103301749-015f9a80-49d0-11eb-9314-1488fdd2a4d3.png)

There is no error when the table it's empty:

![imagen](https://user-images.githubusercontent.com/4541969/103301735-fad12300-49cf-11eb-89cc-98399b7d198f.png)


Trino:
```
java.lang.IllegalStateException: Expected zero to one elements, but found multiple
	at org.jdbi.v3.core.result.ResultIterable.findOne(ResultIterable.java:163)
	at io.prestosql.plugin.sqlserver.SqlServerClient.getTableDataCompression(SqlServerClient.java:437)
	at io.prestosql.plugin.sqlserver.SqlServerClient.getTableProperties(SqlServerClient.java:378)
	at io.prestosql.plugin.jdbc.ForwardingJdbcClient.getTableProperties(ForwardingJdbcClient.java:288)
	at io.prestosql.plugin.jdbc.jmx.StatisticsAwareJdbcClient.getTableProperties(StatisticsAwareJdbcClient.java:305)
	at io.prestosql.plugin.jdbc.CachingJdbcClient.getTableProperties(CachingJdbcClient.java:365)
	at io.prestosql.plugin.jdbc.CachingJdbcClient.getTableProperties(CachingJdbcClient.java:365)
	at io.prestosql.plugin.jdbc.JdbcMetadata.getTableMetadata(JdbcMetadata.java:344)
	at io.prestosql.metadata.MetadataManager.getTableMetadata(MetadataManager.java:508)
	at io.prestosql.sql.analyzer.StatementAnalyzer$Visitor.visitTable(StatementAnalyzer.java:1231)
	at io.prestosql.sql.analyzer.StatementAnalyzer$Visitor.visitTable(StatementAnalyzer.java:329)
	at io.prestosql.sql.tree.Table.accept(Table.java:53)
	at io.prestosql.sql.tree.AstVisitor.process(AstVisitor.java:27)
	at io.prestosql.sql.analyzer.StatementAnalyzer$Visitor.process(StatementAnalyzer.java:346)
	at io.prestosql.sql.analyzer.StatementAnalyzer$Visitor.analyzeFrom(StatementAnalyzer.java:2529)
	at io.prestosql.sql.analyzer.StatementAnalyzer$Visitor.visitQuerySpecification(StatementAnalyzer.java:1553)
	at io.prestosql.sql.analyzer.StatementAnalyzer$Visitor.visitQuerySpecification(StatementAnalyzer.java:329)
	at io.prestosql.sql.tree.QuerySpecification.accept(QuerySpecification.java:144)
	at io.prestosql.sql.tree.AstVisitor.process(AstVisitor.java:27)
	at io.prestosql.sql.analyzer.StatementAnalyzer$Visitor.process(StatementAnalyzer.java:346)
	at io.prestosql.sql.analyzer.StatementAnalyzer$Visitor.process(StatementAnalyzer.java:356)
	at io.prestosql.sql.analyzer.StatementAnalyzer$Visitor.visitQuery(StatementAnalyzer.java:1061)
	at io.prestosql.sql.analyzer.StatementAnalyzer$Visitor.visitQuery(StatementAnalyzer.java:329)
	at io.prestosql.sql.tree.Query.accept(Query.java:107)
	at io.prestosql.sql.tree.AstVisitor.process(AstVisitor.java:27)
	at io.prestosql.sql.analyzer.StatementAnalyzer$Visitor.process(StatementAnalyzer.java:346)
	at io.prestosql.sql.analyzer.StatementAnalyzer.analyze(StatementAnalyzer.java:315)
	at io.prestosql.sql.analyzer.Analyzer.analyze(Analyzer.java:91)
	at io.prestosql.sql.analyzer.Analyzer.analyze(Analyzer.java:83)
	at io.prestosql.execution.SqlQueryExecution.analyze(SqlQueryExecution.java:263)
	at io.prestosql.execution.SqlQueryExecution.<init>(SqlQueryExecution.java:186)
	at io.prestosql.execution.SqlQueryExecution$SqlQueryExecutionFactory.createQueryExecution(SqlQueryExecution.java:768)
	at io.prestosql.dispatcher.LocalDispatchQueryFactory.lambda$createDispatchQuery$0(LocalDispatchQueryFactory.java:129)
	at io.prestosql.$gen.Presto_350____20211229_170343_2.call(Unknown Source)
	at com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:125)
	at com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:69)
	at com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:78)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:834)
```","SQL Server ""Expected zero to one elements, but found multiple"" SQL Query fails with a simple select * from to any table on the database. Also tried multiple instances of SQL Server. ![imagen](https://user-images.githubusercontent.com/4541969/103301749-015f9a80-49d0-11eb-9314-1488fdd2a4d3.png) There is no error when the table it's empty: ![imagen](https://user-images.githubusercontent.com/4541969/103301735-fad12300-49cf-11eb-89cc-98399b7d198f.png) Trino: ``` java.lang.IllegalStateException: Expected zero to one elements, but found multiple at org.jdbi.v3.core.result.ResultIterable.findOne(ResultIterable.java:163) at io.prestosql.plugin.sqlserver.SqlServerClient.getTableDataCompression(SqlServerClient.java:437) at io.prestosql.plugin.sqlserver.SqlServerClient.getTableProperties(SqlServerClient.java:378) at io.prestosql.plugin.jdbc.ForwardingJdbcClient.getTableProperties(ForwardingJdbcClient.java:288) at io.prestosql.plugin.jdbc.jmx.StatisticsAwareJdbcClient.getTableProperties(StatisticsAwareJdbcClient.java:305) at io.prestosql.plugin.jdbc.CachingJdbcClient.getTableProperties(CachingJdbcClient.java:365) at io.prestosql.plugin.jdbc.CachingJdbcClient.getTableProperties(CachingJdbcClient.java:365) at io.prestosql.plugin.jdbc.JdbcMetadata.getTableMetadata(JdbcMetadata.java:344) at io.prestosql.metadata.MetadataManager.getTableMetadata(MetadataManager.java:508) at io.prestosql.sql.analyzer.StatementAnalyzer$Visitor.visitTable(StatementAnalyzer.java:1231) at io.prestosql.sql.analyzer.StatementAnalyzer$Visitor.visitTable(StatementAnalyzer.java:329) at io.prestosql.sql.tree.Table.accept(Table.java:53) at io.prestosql.sql.tree.AstVisitor.process(AstVisitor.java:27) at io.prestosql.sql.analyzer.StatementAnalyzer$Visitor.process(StatementAnalyzer.java:346) at io.prestosql.sql.analyzer.StatementAnalyzer$Visitor.analyzeFrom(StatementAnalyzer.java:2529) at io.prestosql.sql.analyzer.StatementAnalyzer$Visitor.visitQuerySpecification(StatementAnalyzer.java:1553) at io.prestosql.sql.analyzer.StatementAnalyzer$Visitor.visitQuerySpecification(StatementAnalyzer.java:329) at io.prestosql.sql.tree.QuerySpecification.accept(QuerySpecification.java:144) at io.prestosql.sql.tree.AstVisitor.process(AstVisitor.java:27) at io.prestosql.sql.analyzer.StatementAnalyzer$Visitor.process(StatementAnalyzer.java:346) at io.prestosql.sql.analyzer.StatementAnalyzer$Visitor.process(StatementAnalyzer.java:356) at io.prestosql.sql.analyzer.StatementAnalyzer$Visitor.visitQuery(StatementAnalyzer.java:1061) at io.prestosql.sql.analyzer.StatementAnalyzer$Visitor.visitQuery(StatementAnalyzer.java:329) at io.prestosql.sql.tree.Query.accept(Query.java:107) at io.prestosql.sql.tree.AstVisitor.process(AstVisitor.java:27) at io.prestosql.sql.analyzer.StatementAnalyzer$Visitor.process(StatementAnalyzer.java:346) at io.prestosql.sql.analyzer.StatementAnalyzer.analyze(StatementAnalyzer.java:315) at io.prestosql.sql.analyzer.Analyzer.analyze(Analyzer.java:91) at io.prestosql.sql.analyzer.Analyzer.analyze(Analyzer.java:83) at io.prestosql.execution.SqlQueryExecution.analyze(SqlQueryExecution.java:263) at io.prestosql.execution.SqlQueryExecution.<init>(SqlQueryExecution.java:186) at io.prestosql.execution.SqlQueryExecution$SqlQueryExecutionFactory.createQueryExecution(SqlQueryExecution.java:768) at io.prestosql.dispatcher.LocalDispatchQueryFactory.lambda$createDispatchQuery$0(LocalDispatchQueryFactory.java:129) at io.prestosql.$gen.Presto_350____20211229_170343_2.call(Unknown Source) at com.google.common.util.concurrent.TrustedListenableFutureTask$TrustedFutureInterruptibleTask.runInterruptibly(TrustedListenableFutureTask.java:125) at com.google.common.util.concurrent.InterruptibleTask.run(InterruptibleTask.java:69) at com.google.common.util.concurrent.TrustedListenableFutureTask.run(TrustedListenableFutureTask.java:78) at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) at java.base/java.lang.Thread.run(Thread.java:834) ```"
488885,488885,543338,https://api.github.com/repos/DavBfr/dart_pdf/issues/544,1.0,2021-01-30T16:19:03Z,NONE,https://api.github.com/repos/DavBfr/dart_pdf,add the ability to embed audio and video files,"**Is your feature request related to a problem? Please describe.**
<!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] -->
PDF files can embed audio an video files. I didn't find a way to do that with this package. 

**Describe the solution you'd like**
<!-- A clear and concise description of what you want to happen. -->
Add the ability to embed audio and video files.

**Describe alternatives you've considered**
<!-- A clear and concise description of any alternative solutions or features you've considered. -->
Not generating PDF but zipped htlm+media files but that's way less usable in many cases. 

**Additional context**
",add the ability to embed audio and video files **Is your feature request related to a problem? Please describe.** <!-- A clear and concise description of what the problem is. Ex. I'm always frustrated when [...] --> PDF files can embed audio an video files. I didn't find a way to do that with this package. **Describe the solution you'd like** <!-- A clear and concise description of what you want to happen. --> Add the ability to embed audio and video files. **Describe alternatives you've considered** <!-- A clear and concise description of any alternative solutions or features you've considered. --> Not generating PDF but zipped htlm+media files but that's way less usable in many cases. **Additional context** 
434072,434072,482564,https://api.github.com/repos/fwupd/fwupd/issues/3177,2.0,2021-04-23T10:25:02Z,CONTRIBUTOR,https://api.github.com/repos/fwupd/fwupd,What is the difference between --offline and --no-reboot-check?,"**Describe the question**
Reading the documentation, I'm not sure I understand the difference between `fwupdmgr --offline` and `fwupdmgr --no-reboot-check`.

```
       --offline
              Schedule installation for next reboot when possible
       --no-reboot-check
              Do not check for reboot after update
```

Is the following table correct?

| Flag | Install changes immediately | Install changes at reboot | Prompt user to reboot |
| --- | --- | --- | --- |
| [none] | :heavy_check_mark: | :x: | :heavy_check_mark: |
| `--offline` | :x: | :heavy_check_mark: | :x: |
| `--no-reboot-check` | :heavy_check_mark: | :x: | :x: |

**fwupd version information**
```shell
$ fwupdmgr --version
client version: 1.4.5
compile-time dependency versions
        gusb:   0.3.4
        efivar: 37
daemon version: 1.4.5
```
","What is the difference between --offline and --no-reboot-check? **Describe the question** Reading the documentation, I'm not sure I understand the difference between `fwupdmgr --offline` and `fwupdmgr --no-reboot-check`. ``` --offline Schedule installation for next reboot when possible --no-reboot-check Do not check for reboot after update ``` Is the following table correct? | Flag | Install changes immediately | Install changes at reboot | Prompt user to reboot | | --- | --- | --- | --- | | [none] | :heavy_check_mark: | :x: | :heavy_check_mark: | | `--offline` | :x: | :heavy_check_mark: | :x: | | `--no-reboot-check` | :heavy_check_mark: | :x: | :x: | **fwupd version information** ```shell $ fwupdmgr --version client version: 1.4.5 compile-time dependency versions gusb: 0.3.4 efivar: 37 daemon version: 1.4.5 ``` "
494226,494226,549315,https://api.github.com/repos/s-knibbs/dataclasses-jsonschema/issues/153,1.0,2021-01-24T16:21:57Z,OWNER,https://api.github.com/repos/s-knibbs/dataclasses-jsonschema,Support PEP 604 types,"[Mypy 0.800](https://mypy-lang.blogspot.com/2021/01/mypy-0800-released.html) now supports [PEP 604](https://www.python.org/dev/peps/pep-0604/). To make use of this here for python < 3.10, we'd need to re-implement `get_type_hints` from the typing module and use an ast transformation to turn this:

```python
str | int | None
```

into this:

```python
typing.Union[str, int, NoneType]
```","Support PEP 604 types [Mypy 0.800](https://mypy-lang.blogspot.com/2021/01/mypy-0800-released.html) now supports [PEP 604](https://www.python.org/dev/peps/pep-0604/). To make use of this here for python < 3.10, we'd need to re-implement `get_type_hints` from the typing module and use an ast transformation to turn this: ```python str | int | None ``` into this: ```python typing.Union[str, int, NoneType] ```"
44682,44682,49740,https://api.github.com/repos/Software-For-Love/software-for-love-site/issues/16,0.0,2021-03-14T21:45:33Z,CONTRIBUTOR,https://api.github.com/repos/Software-For-Love/software-for-love-site,"Change all mentions of ""Non-Profits"" to ""Organizations""",,"Change all mentions of ""Non-Profits"" to ""Organizations"" "
548428,548428,609553,https://api.github.com/repos/YTVanced/Vanced/issues/706,0.0,2021-04-27T13:22:28Z,NONE,https://api.github.com/repos/YTVanced/Vanced,[Bug] cannot connect with update your google play service message,"**Bug description**
cannot casting to chromcast with google tv, with update your google play service message

**Variant**
Non-Root

**Vanced version**
16.14.34 - Build - 01.50.01

**Android version**
Android 10, 11

**Device**
Samsung Galaxy S10e
Blackshark 2
Xiaomi redmi 5 plus


**Steps to Reproduce**
Steps to reproduce the error:
1. install vanced
2. casting to chromecast(this time working well)
3. close vanced(not to go home)
4. casting to chromecast again
5. cannot connect with message","[Bug] cannot connect with update your google play service message **Bug description** cannot casting to chromcast with google tv, with update your google play service message **Variant** Non-Root **Vanced version** 16.14.34 - Build - 01.50.01 **Android version** Android 10, 11 **Device** Samsung Galaxy S10e Blackshark 2 Xiaomi redmi 5 plus **Steps to Reproduce** Steps to reproduce the error: 1. install vanced 2. casting to chromecast(this time working well) 3. close vanced(not to go home) 4. casting to chromecast again 5. cannot connect with message"
208539,208539,231888,https://api.github.com/repos/oap-project/native-sql-engine/issues/119,1.0,2021-02-20T07:08:51Z,COLLABORATOR,https://api.github.com/repos/oap-project/native-sql-engine,consolidate batch size,"need to use batch size passed from configuration in whole stage codegen/hashagg kernel
",consolidate batch size need to use batch size passed from configuration in whole stage codegen/hashagg kernel 
669090,669090,743661,https://api.github.com/repos/winterwolf/typedobject/issues/1,1.0,2021-02-20T16:30:59Z,OWNER,https://api.github.com/repos/winterwolf/typedobject,Improve member checking,"- [x] Move methods `isTypeOf` and `isMemberOf` from `Object` to `Assist`
- [x] Create method `Object:is`, doing the same as `Object:assert`, but return boolean instead of throwing error
- [x] Add possibility for `:assert()` and `:is()` to select between `""any""`, `""all""` and `""not""` logical modes (default is `""any""`)
- [x] Mode `""member""` should be default
- [x] Test and debug
- [x] Update documentation
- [x] Release version 2.1","Improve member checking - [x] Move methods `isTypeOf` and `isMemberOf` from `Object` to `Assist` - [x] Create method `Object:is`, doing the same as `Object:assert`, but return boolean instead of throwing error - [x] Add possibility for `:assert()` and `:is()` to select between `""any""`, `""all""` and `""not""` logical modes (default is `""any""`) - [x] Mode `""member""` should be default - [x] Test and debug - [x] Update documentation - [x] Release version 2.1"
435133,435133,483736,https://api.github.com/repos/pmndrs/react-spring/issues/895,0.0,2020-01-08T15:25:16Z,NONE,https://api.github.com/repos/pmndrs/react-spring,Unexpected jump on textarea scroll events within a ParallaxLayer,"##  Bug Report

When you start typing content in a textarea within a ParallaxLayer (not the first one), and enter enough breaklines so the textarea's scrollbar shows, a jump happens towards the top of the page. 

## To Reproduce

Steps to reproduce the behavior:
1) Enter content with enough breaklines to trigger the textarea's scroll bar.

## Expected behavior

No jump. Nothing should happen to the main scrollbar.

## Link to repro (highly encouraged)

[![Edit unruffled-lewin-kcc54](https://codesandbox.io/static/img/play-codesandbox.svg)](https://codesandbox.io/s/unruffled-lewin-kcc54?fontsize=14&hidenavigation=1&theme=dark)

## Environment

- `react-spring` v8.x.x
- `react` v16.8.x (or `react-native` v0.58.x)
","Unexpected jump on textarea scroll events within a ParallaxLayer ##  Bug Report When you start typing content in a textarea within a ParallaxLayer (not the first one), and enter enough breaklines so the textarea's scrollbar shows, a jump happens towards the top of the page. ## To Reproduce Steps to reproduce the behavior: 1) Enter content with enough breaklines to trigger the textarea's scroll bar. ## Expected behavior No jump. Nothing should happen to the main scrollbar. ## Link to repro (highly encouraged) [![Edit unruffled-lewin-kcc54](https://codesandbox.io/static/img/play-codesandbox.svg)](https://codesandbox.io/s/unruffled-lewin-kcc54?fontsize=14&hidenavigation=1&theme=dark) ## Environment - `react-spring` v8.x.x - `react` v16.8.x (or `react-native` v0.58.x) "
625405,625405,695032,https://api.github.com/repos/Tanaguru/tanaguru2020-engine/issues/61,0.0,2021-04-20T09:12:31Z,NONE,https://api.github.com/repos/Tanaguru/tanaguru2020-engine,Z챕ro anomalies remont챕es,"J'ai fait tourner un audit de sc챕nario qui devrait auditer 5 pages. 
J'obtiens des messages d'erreur dans l'historique de l'audit et le r챕sultat des pages audit챕es indique 0 anomalies, comme s'il n'avait pas pu auditer les pages. 
Note: les pages semblent bien charg챕es en revanche car on a bien la miniature de la page pour chaque page. 

URL de l'audit:
https://dev.tanaguru.com/#/audits/408

","Z챕ro anomalies remont챕es J'ai fait tourner un audit de sc챕nario qui devrait auditer 5 pages. J'obtiens des messages d'erreur dans l'historique de l'audit et le r챕sultat des pages audit챕es indique 0 anomalies, comme s'il n'avait pas pu auditer les pages. Note: les pages semblent bien charg챕es en revanche car on a bien la miniature de la page pour chaque page. URL de l'audit: https://dev.tanaguru.com/#/audits/408 "
534383,534383,593942,https://api.github.com/repos/davidepalladino/Air-Analyzer/issues/69,1.0,2021-02-17T08:58:12Z,OWNER,https://api.github.com/repos/davidepalladino/Air-Analyzer,Creare AddFragment,,Creare AddFragment 
181825,181825,202131,https://api.github.com/repos/kevinhenneigh/JmesJemsSite/issues/82,1.0,2021-03-16T22:55:16Z,COLLABORATOR,https://api.github.com/repos/kevinhenneigh/JmesJemsSite,Edit ArtworkController,Fix edit http get and http post to allow for the editing of uploaded images.,Edit ArtworkController Fix edit http get and http post to allow for the editing of uploaded images.
8355,8355,9313,https://api.github.com/repos/charlesbel/Microsoft-Rewards-Farmer/issues/71,0.0,2021-04-10T01:22:50Z,NONE,https://api.github.com/repos/charlesbel/Microsoft-Rewards-Farmer,[BUG] Errors when using vpn,"With nordvpn, idk why, my internet always stop working when using it, maybe this is the reason

**Error Log**

```
C:\Users\Lucas\Desktop\Microsoft-Rewards-Farmer-master>ms_rewards_farmer.py
[91m
             
      
        
        
                   
                         [00m
[95m        by Charles Bel (@charlesbel)               version 1.1
[00m
Traceback (most recent call last):
  File ""C:\Python39\lib\site-packages\urllib3\connection.py"", line 169, in _new_
conn
    conn = connection.create_connection(
  File ""C:\Python39\lib\site-packages\urllib3\util\connection.py"", line 73, in c
reate_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
  File ""C:\Python39\lib\socket.py"", line 953, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Python39\lib\site-packages\urllib3\connectionpool.py"", line 699, in u
rlopen
    httplib_response = self._make_request(
  File ""C:\Python39\lib\site-packages\urllib3\connectionpool.py"", line 382, in _
make_request
    self._validate_conn(conn)
  File ""C:\Python39\lib\site-packages\urllib3\connectionpool.py"", line 1010, in
_validate_conn
    conn.connect()
  File ""C:\Python39\lib\site-packages\urllib3\connection.py"", line 353, in conne
ct
    conn = self._new_conn()
  File ""C:\Python39\lib\site-packages\urllib3\connection.py"", line 181, in _new_
conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection objec
t at 0x0000005D64B1F6D0>: Failed to establish a new connection: [Errno 11001] ge
taddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Python39\lib\site-packages\requests\adapters.py"", line 439, in send
    resp = conn.urlopen(
  File ""C:\Python39\lib\site-packages\urllib3\connectionpool.py"", line 755, in u
rlopen
    retries = retries.increment(
  File ""C:\Python39\lib\site-packages\urllib3\util\retry.py"", line 574, in incre
ment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='ipapi.co', port=443)
: Max retries exceeded with url: /json/ (Caused by NewConnectionError('<urllib3.
connection.HTTPSConnection object at 0x0000005D64B1F6D0>: Failed to establish a
new connection: [Errno 11001] getaddrinfo failed'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Lucas\Desktop\Microsoft-Rewards-Farmer-master\ms_rewards_farmer
.py"", line 729, in <module>
    LANG, GEO, TZ = getCCodeLangAndOffset()
  File ""C:\Users\Lucas\Desktop\Microsoft-Rewards-Farmer-master\ms_rewards_farmer
.py"", line 200, in getCCodeLangAndOffset
    nfo = ipapi.location()
  File ""C:\Python39\lib\site-packages\ipapi\ipapi.py"", line 76, in location
    resp = get(url, headers=headers, **options)
  File ""C:\Python39\lib\site-packages\requests\api.py"", line 76, in get
    return request('get', url, params=params, **kwargs)
  File ""C:\Python39\lib\site-packages\requests\api.py"", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File ""C:\Python39\lib\site-packages\requests\sessions.py"", line 542, in reques
t
    resp = self.send(prep, **send_kwargs)
  File ""C:\Python39\lib\site-packages\requests\sessions.py"", line 655, in send
    r = adapter.send(request, **kwargs)
  File ""C:\Python39\lib\site-packages\requests\adapters.py"", line 516, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='ipapi.co', port=4
43): Max retries exceeded with url: /json/ (Caused by NewConnectionError('<urlli
b3.connection.HTTPSConnection object at 0x0000005D64B1F6D0>: Failed to establish
 a new connection: [Errno 11001] getaddrinfo failed'))

C:\Users\Lucas\Desktop\Microsoft-Rewards-Farmer-master>ms_rewards_farmer.py
[91m
             
      
        
        
                   
                         [00m
[95m        by Charles Bel (@charlesbel)               version 1.1

DevTools listening on ws://127.0.0.1:30960/devtools/browser/2be5414c-6d6d-456e-a
71c-541bfc6d4abd
[LOGIN] Logging-in...
Traceback (most recent call last):
  File ""C:\Users\Lucas\Desktop\Microsoft-Rewards-Farmer-master\ms_rewards_farmer
.py"", line 754, in <module>
    login(browser, account['username'], account['password'])
  File ""C:\Users\Lucas\Desktop\Microsoft-Rewards-Farmer-master\ms_rewards_farmer
.py"", line 41, in login
    waitUntilVisible(browser, By.ID, 'loginHeader', 10)
  File ""C:\Users\Lucas\Desktop\Microsoft-Rewards-Farmer-master\ms_rewards_farmer
.py"", line 146, in waitUntilVisible
    WebDriverWait(browser, time_to_wait).until(ec.visibility_of_element_located(
(by_, selector)))
  File ""C:\Python39\lib\site-packages\selenium\webdriver\support\wait.py"", line
80, in until
    raise TimeoutException(message, screen, stacktrace)
selenium.common.exceptions.TimeoutException: Message:


C:\Users\Lucas\Desktop\Microsoft-Rewards-Farmer-master>ms_rewards_farmer.py
[91m
             
      
        
        
                   
                         [00m
[95m        by Charles Bel (@charlesbel)               version 1.1
[00m
Traceback (most recent call last):
  File ""C:\Python39\lib\site-packages\urllib3\connection.py"", line 169, in _new_
conn
    conn = connection.create_connection(
  File ""C:\Python39\lib\site-packages\urllib3\util\connection.py"", line 96, in c
reate_connection
    raise err
  File ""C:\Python39\lib\site-packages\urllib3\util\connection.py"", line 86, in c
reate_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] Nenhuma conex찾o p척de ser feita porque a
 m찼quina de destino as recusou ativamente

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Python39\lib\site-packages\urllib3\connectionpool.py"", line 699, in u
rlopen
    httplib_response = self._make_request(
  File ""C:\Python39\lib\site-packages\urllib3\connectionpool.py"", line 382, in _
make_request
    self._validate_conn(conn)
  File ""C:\Python39\lib\site-packages\urllib3\connectionpool.py"", line 1010, in
_validate_conn
    conn.connect()
  File ""C:\Python39\lib\site-packages\urllib3\connection.py"", line 353, in conne
ct
    conn = self._new_conn()
  File ""C:\Python39\lib\site-packages\urllib3\connection.py"", line 181, in _new_
conn
    raise NewConnectionError(
urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection objec
t at 0x000000B123DFF6D0>: Failed to establish a new connection: [WinError 10061]
 Nenhuma conex찾o p척de ser feita porque a m찼quina de destino as recusou ativament
e

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Python39\lib\site-packages\requests\adapters.py"", line 439, in send
    resp = conn.urlopen(
  File ""C:\Python39\lib\site-packages\urllib3\connectionpool.py"", line 755, in u
rlopen
    retries = retries.increment(
  File ""C:\Python39\lib\site-packages\urllib3\util\retry.py"", line 574, in incre
ment
    raise MaxRetryError(_pool, url, error or ResponseError(cause))
urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='ipapi.co', port=443)
: Max retries exceeded with url: /json/ (Caused by NewConnectionError('<urllib3.
connection.HTTPSConnection object at 0x000000B123DFF6D0>: Failed to establish a
new connection: [WinError 10061] Nenhuma conex찾o p척de ser feita porque a m찼quina
 de destino as recusou ativamente'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Lucas\Desktop\Microsoft-Rewards-Farmer-master\ms_rewards_farmer
.py"", line 729, in <module>
    LANG, GEO, TZ = getCCodeLangAndOffset()
  File ""C:\Users\Lucas\Desktop\Microsoft-Rewards-Farmer-master\ms_rewards_farmer
.py"", line 200, in getCCodeLangAndOffset
    nfo = ipapi.location()
  File ""C:\Python39\lib\site-packages\ipapi\ipapi.py"", line 76, in location
    resp = get(url, headers=headers, **options)
  File ""C:\Python39\lib\site-packages\requests\api.py"", line 76, in get
    return request('get', url, params=params, **kwargs)
  File ""C:\Python39\lib\site-packages\requests\api.py"", line 61, in request
    return session.request(method=method, url=url, **kwargs)
  File ""C:\Python39\lib\site-packages\requests\sessions.py"", line 542, in reques
t
    resp = self.send(prep, **send_kwargs)
  File ""C:\Python39\lib\site-packages\requests\sessions.py"", line 655, in send
    r = adapter.send(request, **kwargs)
  File ""C:\Python39\lib\site-packages\requests\adapters.py"", line 516, in send
    raise ConnectionError(e, request=request)
requests.exceptions.ConnectionError: HTTPSConnectionPool(host='ipapi.co', port=4
43): Max retries exceeded with url: /json/ (Caused by NewConnectionError('<urlli
b3.connection.HTTPSConnection object at 0x000000B123DFF6D0>: Failed to establish
 a new connection: [WinError 10061] Nenhuma conex찾o p척de ser feita porque a m찼qu
ina de destino as recusou ativamente'))
```

The problem is because i have not good vpn","[BUG] Errors when using vpn With nordvpn, idk why, my internet always stop working when using it, maybe this is the reason **Error Log** ``` C:\Users\Lucas\Desktop\Microsoft-Rewards-Farmer-master>ms_rewards_farmer.py [91m                                     [00m [95m by Charles Bel (@charlesbel) version 1.1 [00m Traceback (most recent call last): File ""C:\Python39\lib\site-packages\urllib3\connection.py"", line 169, in _new_ conn conn = connection.create_connection( File ""C:\Python39\lib\site-packages\urllib3\util\connection.py"", line 73, in c reate_connection for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM): File ""C:\Python39\lib\socket.py"", line 953, in getaddrinfo for res in _socket.getaddrinfo(host, port, family, type, proto, flags): socket.gaierror: [Errno 11001] getaddrinfo failed During handling of the above exception, another exception occurred: Traceback (most recent call last): File ""C:\Python39\lib\site-packages\urllib3\connectionpool.py"", line 699, in u rlopen httplib_response = self._make_request( File ""C:\Python39\lib\site-packages\urllib3\connectionpool.py"", line 382, in _ make_request self._validate_conn(conn) File ""C:\Python39\lib\site-packages\urllib3\connectionpool.py"", line 1010, in _validate_conn conn.connect() File ""C:\Python39\lib\site-packages\urllib3\connection.py"", line 353, in conne ct conn = self._new_conn() File ""C:\Python39\lib\site-packages\urllib3\connection.py"", line 181, in _new_ conn raise NewConnectionError( urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection objec t at 0x0000005D64B1F6D0>: Failed to establish a new connection: [Errno 11001] ge taddrinfo failed During handling of the above exception, another exception occurred: Traceback (most recent call last): File ""C:\Python39\lib\site-packages\requests\adapters.py"", line 439, in send resp = conn.urlopen( File ""C:\Python39\lib\site-packages\urllib3\connectionpool.py"", line 755, in u rlopen retries = retries.increment( File ""C:\Python39\lib\site-packages\urllib3\util\retry.py"", line 574, in incre ment raise MaxRetryError(_pool, url, error or ResponseError(cause)) urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='ipapi.co', port=443) : Max retries exceeded with url: /json/ (Caused by NewConnectionError('<urllib3. connection.HTTPSConnection object at 0x0000005D64B1F6D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')) During handling of the above exception, another exception occurred: Traceback (most recent call last): File ""C:\Users\Lucas\Desktop\Microsoft-Rewards-Farmer-master\ms_rewards_farmer .py"", line 729, in <module> LANG, GEO, TZ = getCCodeLangAndOffset() File ""C:\Users\Lucas\Desktop\Microsoft-Rewards-Farmer-master\ms_rewards_farmer .py"", line 200, in getCCodeLangAndOffset nfo = ipapi.location() File ""C:\Python39\lib\site-packages\ipapi\ipapi.py"", line 76, in location resp = get(url, headers=headers, **options) File ""C:\Python39\lib\site-packages\requests\api.py"", line 76, in get return request('get', url, params=params, **kwargs) File ""C:\Python39\lib\site-packages\requests\api.py"", line 61, in request return session.request(method=method, url=url, **kwargs) File ""C:\Python39\lib\site-packages\requests\sessions.py"", line 542, in reques t resp = self.send(prep, **send_kwargs) File ""C:\Python39\lib\site-packages\requests\sessions.py"", line 655, in send r = adapter.send(request, **kwargs) File ""C:\Python39\lib\site-packages\requests\adapters.py"", line 516, in send raise ConnectionError(e, request=request) requests.exceptions.ConnectionError: HTTPSConnectionPool(host='ipapi.co', port=4 43): Max retries exceeded with url: /json/ (Caused by NewConnectionError('<urlli b3.connection.HTTPSConnection object at 0x0000005D64B1F6D0>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')) C:\Users\Lucas\Desktop\Microsoft-Rewards-Farmer-master>ms_rewards_farmer.py [91m                                     [00m [95m by Charles Bel (@charlesbel) version 1.1 DevTools listening on ws://127.0.0.1:30960/devtools/browser/2be5414c-6d6d-456e-a 71c-541bfc6d4abd [LOGIN] Logging-in... Traceback (most recent call last): File ""C:\Users\Lucas\Desktop\Microsoft-Rewards-Farmer-master\ms_rewards_farmer .py"", line 754, in <module> login(browser, account['username'], account['password']) File ""C:\Users\Lucas\Desktop\Microsoft-Rewards-Farmer-master\ms_rewards_farmer .py"", line 41, in login waitUntilVisible(browser, By.ID, 'loginHeader', 10) File ""C:\Users\Lucas\Desktop\Microsoft-Rewards-Farmer-master\ms_rewards_farmer .py"", line 146, in waitUntilVisible WebDriverWait(browser, time_to_wait).until(ec.visibility_of_element_located( (by_, selector))) File ""C:\Python39\lib\site-packages\selenium\webdriver\support\wait.py"", line 80, in until raise TimeoutException(message, screen, stacktrace) selenium.common.exceptions.TimeoutException: Message: C:\Users\Lucas\Desktop\Microsoft-Rewards-Farmer-master>ms_rewards_farmer.py [91m                                     [00m [95m by Charles Bel (@charlesbel) version 1.1 [00m Traceback (most recent call last): File ""C:\Python39\lib\site-packages\urllib3\connection.py"", line 169, in _new_ conn conn = connection.create_connection( File ""C:\Python39\lib\site-packages\urllib3\util\connection.py"", line 96, in c reate_connection raise err File ""C:\Python39\lib\site-packages\urllib3\util\connection.py"", line 86, in c reate_connection sock.connect(sa) ConnectionRefusedError: [WinError 10061] Nenhuma conex찾o p척de ser feita porque a m찼quina de destino as recusou ativamente During handling of the above exception, another exception occurred: Traceback (most recent call last): File ""C:\Python39\lib\site-packages\urllib3\connectionpool.py"", line 699, in u rlopen httplib_response = self._make_request( File ""C:\Python39\lib\site-packages\urllib3\connectionpool.py"", line 382, in _ make_request self._validate_conn(conn) File ""C:\Python39\lib\site-packages\urllib3\connectionpool.py"", line 1010, in _validate_conn conn.connect() File ""C:\Python39\lib\site-packages\urllib3\connection.py"", line 353, in conne ct conn = self._new_conn() File ""C:\Python39\lib\site-packages\urllib3\connection.py"", line 181, in _new_ conn raise NewConnectionError( urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPSConnection objec t at 0x000000B123DFF6D0>: Failed to establish a new connection: [WinError 10061] Nenhuma conex찾o p척de ser feita porque a m찼quina de destino as recusou ativament e During handling of the above exception, another exception occurred: Traceback (most recent call last): File ""C:\Python39\lib\site-packages\requests\adapters.py"", line 439, in send resp = conn.urlopen( File ""C:\Python39\lib\site-packages\urllib3\connectionpool.py"", line 755, in u rlopen retries = retries.increment( File ""C:\Python39\lib\site-packages\urllib3\util\retry.py"", line 574, in incre ment raise MaxRetryError(_pool, url, error or ResponseError(cause)) urllib3.exceptions.MaxRetryError: HTTPSConnectionPool(host='ipapi.co', port=443) : Max retries exceeded with url: /json/ (Caused by NewConnectionError('<urllib3. connection.HTTPSConnection object at 0x000000B123DFF6D0>: Failed to establish a new connection: [WinError 10061] Nenhuma conex찾o p척de ser feita porque a m찼quina de destino as recusou ativamente')) During handling of the above exception, another exception occurred: Traceback (most recent call last): File ""C:\Users\Lucas\Desktop\Microsoft-Rewards-Farmer-master\ms_rewards_farmer .py"", line 729, in <module> LANG, GEO, TZ = getCCodeLangAndOffset() File ""C:\Users\Lucas\Desktop\Microsoft-Rewards-Farmer-master\ms_rewards_farmer .py"", line 200, in getCCodeLangAndOffset nfo = ipapi.location() File ""C:\Python39\lib\site-packages\ipapi\ipapi.py"", line 76, in location resp = get(url, headers=headers, **options) File ""C:\Python39\lib\site-packages\requests\api.py"", line 76, in get return request('get', url, params=params, **kwargs) File ""C:\Python39\lib\site-packages\requests\api.py"", line 61, in request return session.request(method=method, url=url, **kwargs) File ""C:\Python39\lib\site-packages\requests\sessions.py"", line 542, in reques t resp = self.send(prep, **send_kwargs) File ""C:\Python39\lib\site-packages\requests\sessions.py"", line 655, in send r = adapter.send(request, **kwargs) File ""C:\Python39\lib\site-packages\requests\adapters.py"", line 516, in send raise ConnectionError(e, request=request) requests.exceptions.ConnectionError: HTTPSConnectionPool(host='ipapi.co', port=4 43): Max retries exceeded with url: /json/ (Caused by NewConnectionError('<urlli b3.connection.HTTPSConnection object at 0x000000B123DFF6D0>: Failed to establish a new connection: [WinError 10061] Nenhuma conex찾o p척de ser feita porque a m찼qu ina de destino as recusou ativamente')) ``` The problem is because i have not good vpn"
681974,681974,757949,https://api.github.com/repos/distribworks/dkron/issues/913,1.0,2021-03-05T20:48:35Z,CONTRIBUTOR,https://api.github.com/repos/distribworks/dkron,Allow to show more than 25 jobs per pages,"On the jobs page we can select the ""Rows per page"". The current options are 5, 10 and 25.
It would be nice to add 50 and 100 for instance, for when you have a lot of jobs.

**Additional context**
I checked the code to try to add it myself, but was not successful :disappointed: ","Allow to show more than 25 jobs per pages On the jobs page we can select the ""Rows per page"". The current options are 5, 10 and 25. It would be nice to add 50 and 100 for instance, for when you have a lot of jobs. **Additional context** I checked the code to try to add it myself, but was not successful :disappointed: "
606878,606878,674438,https://api.github.com/repos/johannesjo/super-productivity/issues/277,1.0,2020-01-10T12:02:09Z,NONE,https://api.github.com/repos/johannesjo/super-productivity,"Custom day time range, day end hour","Hi!

I could not find a setting that's quite common in similar apps - custom day end hour. For now it counts a day as finished based on 00:00 to 23:59 I quess. 

My schedule is shifted forward in time, I wake up late and go to bed late, so my ""day"" is more like starts at 13:00 and ends at 04:00 roughly. This messes app's calculations up, as it starts counting time towards the next astrological day, though logically I'd like it to count it to my current 'logical' day, if that makes sense","Custom day time range, day end hour Hi! I could not find a setting that's quite common in similar apps - custom day end hour. For now it counts a day as finished based on 00:00 to 23:59 I quess. My schedule is shifted forward in time, I wake up late and go to bed late, so my ""day"" is more like starts at 13:00 and ends at 04:00 roughly. This messes app's calculations up, as it starts counting time towards the next astrological day, though logically I'd like it to count it to my current 'logical' day, if that makes sense"
8121,8121,9052,https://api.github.com/repos/alefragnani/vscode-bookmarks/issues/393,0.0,2021-02-17T17:03:08Z,NONE,https://api.github.com/repos/alefragnani/vscode-bookmarks,Bookmark toggle doesn't work if document doesn't change,"All went well until yesterday, I use F2+Space after to toggle a bookmark, and it used to work perfectly.
Now I have to change something on the document to activate the bookmark.
It doesn't do more with direct command, same symptom.

Was in VSC 1.51, update to 1.53.2 to fix the problem, doesn't change anything.
And one thing I remark : 
![image](https://user-images.githubusercontent.com/6932869/108239611-602ccf00-714a-11eb-9c4b-ee314308cf5b.png)
","Bookmark toggle doesn't work if document doesn't change All went well until yesterday, I use F2+Space after to toggle a bookmark, and it used to work perfectly. Now I have to change something on the document to activate the bookmark. It doesn't do more with direct command, same symptom. Was in VSC 1.51, update to 1.53.2 to fix the problem, doesn't change anything. And one thing I remark : ![image](https://user-images.githubusercontent.com/6932869/108239611-602ccf00-714a-11eb-9c4b-ee314308cf5b.png) "
16976,16976,18913,https://api.github.com/repos/urapadmin/kiosk/issues/619,0.0,2020-05-12T22:44:11Z,COLLABORATOR,https://api.github.com/repos/urapadmin/kiosk,khpp server so consistently upset I think something is wrong,"For the second day in a row I am running into constant problems with the khpp server getting stuck and being unable to calculate searches in the file repository. I am on the ustp server at the same time (both 0.7.2) and the exact same requests there work in light speed (ie ""locus relation photos""). I never seem to have to click in the upper left corner for USTP, and for KHPP it more often than not does not result in actually resetting things to where the search works. I then close the browser window and open a new one and still not responding. (I never seem to have any trouble getting to workstations, or getting to the file repository. The pain comes when asking it to search in the file repository. And it is not always, and not consistent, as in there is no search that always fails nor any search that always works that I have discovered yet.)","khpp server so consistently upset I think something is wrong For the second day in a row I am running into constant problems with the khpp server getting stuck and being unable to calculate searches in the file repository. I am on the ustp server at the same time (both 0.7.2) and the exact same requests there work in light speed (ie ""locus relation photos""). I never seem to have to click in the upper left corner for USTP, and for KHPP it more often than not does not result in actually resetting things to where the search works. I then close the browser window and open a new one and still not responding. (I never seem to have any trouble getting to workstations, or getting to the file repository. The pain comes when asking it to search in the file repository. And it is not always, and not consistent, as in there is no search that always fails nor any search that always works that I have discovered yet.)"
601941,601941,668955,https://api.github.com/repos/ivylabs/suitecrm-analytics/issues/80,0.0,2020-08-26T09:55:57Z,MEMBER,https://api.github.com/repos/ivylabs/suitecrm-analytics,Recent Function not working during initial install,"The function that returns the recently opened files for the portal UI will not work if the user has never logged in and opened a file before. This is likely because the recents response from the server is an empty string until it is populated with at least one solution file after which it becomes an array which we are able to parse.

We need to check that the response and parse the string if its empty
",Recent Function not working during initial install The function that returns the recently opened files for the portal UI will not work if the user has never logged in and opened a file before. This is likely because the recents response from the server is an empty string until it is populated with at least one solution file after which it becomes an array which we are able to parse. We need to check that the response and parse the string if its empty 
111939,111939,124423,https://api.github.com/repos/DragoonKite/taskmaster-pro/issues/4,1.0,2021-01-04T23:04:28Z,OWNER,https://api.github.com/repos/DragoonKite/taskmaster-pro,Add due date handling,"- Add a calendar datepicker for setting due dates.
- Conditionally highlight tasks that are near/overdue.",Add due date handling - Add a calendar datepicker for setting due dates. - Conditionally highlight tasks that are near/overdue.
265285,265285,295022,https://api.github.com/repos/ElusionPDX/Ze3o-Reports/issues/68,0.0,2021-05-21T07:54:29Z,NONE,https://api.github.com/repos/ElusionPDX/Ze3o-Reports,Can't walk into Digital Den,"Was taken to Digital Den to buy a phone and you cant walk past the front door. It opens but its like an invisible wall is there.

**To Reproduce**
Steps to reproduce the behavior:
1. Go to Digital Den
2. Try to walk through door
3. Door opens but no entry

**Expected behavior**
I thought i was able to walk through the door to buy a phone.

**Screenshots**
If applicable, add screenshots to help explain your problem.

**Desktop (please complete the following information):**
 - OS: [e.g. iOS]
 - GPU: [e.g. gtx1060]
 - CPU: [e.g. FX8350]


**Additional context**
Add any other context about the problem here.
","Can't walk into Digital Den Was taken to Digital Den to buy a phone and you cant walk past the front door. It opens but its like an invisible wall is there. **To Reproduce** Steps to reproduce the behavior: 1. Go to Digital Den 2. Try to walk through door 3. Door opens but no entry **Expected behavior** I thought i was able to walk through the door to buy a phone. **Screenshots** If applicable, add screenshots to help explain your problem. **Desktop (please complete the following information):** - OS: [e.g. iOS] - GPU: [e.g. gtx1060] - CPU: [e.g. FX8350] **Additional context** Add any other context about the problem here. "
510443,510443,567279,https://api.github.com/repos/IntroToCode/Spring21_Recipes_Codemates5/issues/3,1.0,2021-03-30T03:09:07Z,CONTRIBUTOR,https://api.github.com/repos/IntroToCode/Spring21_Recipes_Codemates5,Dinner Issue,"##  Discussion topic
Issues for Dinner   쏙  

##  Potential issues

- What recipe do we want?
- How many servings should we have?
- What ingredients and equipment are needed?
- What are the preparation steps?

##  People to consult

Outside of the project team, we will look to outside sources (food websites, etc.) to determine an appropriate recipe idea.

##  Details

_Acceptance Criteria_
The enhancement issue will be considered Closed Complete once:

- The recipe has been decided, documented, and merged.
- Each team ember committed to the Pull Requests
- At least two people have approved each Pull Request using the reviews feature
","Dinner Issue ##  Discussion topic Issues for Dinner   쏙  ##  Potential issues - What recipe do we want? - How many servings should we have? - What ingredients and equipment are needed? - What are the preparation steps? ##  People to consult Outside of the project team, we will look to outside sources (food websites, etc.) to determine an appropriate recipe idea. ##  Details _Acceptance Criteria_ The enhancement issue will be considered Closed Complete once: - The recipe has been decided, documented, and merged. - Each team ember committed to the Pull Requests - At least two people have approved each Pull Request using the reviews feature "
802285,802285,791935,https://api.github.com/repos/usnistgov/OSCAL/issues/786,2.0,2020-11-05T19:53:35Z,NONE,https://api.github.com/repos/usnistgov/OSCAL,"Differences between ""Component"" object in ""System Security Plan"" Model vs ""Component Definition"" Model","{Please enter your question.}
I'm not sure if this is intentional, but the properties described for the ""Component"" object differ slightly based on the context it's being referenced in. 

See the following two links:
https://pages.nist.gov/OSCAL/documentation/schema/implementation-layer/component/json-schema/#oscal-component-json_component
https://pages.nist.gov/OSCAL/documentation/schema/implementation-layer/ssp/json-schema/#component

Either way isn't a problem for me.

Regards,
Todd","Differences between ""Component"" object in ""System Security Plan"" Model vs ""Component Definition"" Model {Please enter your question.} I'm not sure if this is intentional, but the properties described for the ""Component"" object differ slightly based on the context it's being referenced in. See the following two links: https://pages.nist.gov/OSCAL/documentation/schema/implementation-layer/component/json-schema/#oscal-component-json_component https://pages.nist.gov/OSCAL/documentation/schema/implementation-layer/ssp/json-schema/#component Either way isn't a problem for me. Regards, Todd"
188118,188118,209193,https://api.github.com/repos/capnkirok/Inventory-Pets/issues/376,0.0,2021-01-01T06:54:31Z,NONE,https://api.github.com/repos/capnkirok/Inventory-Pets,Banana Pet Server Crash,"`Inventory Pets v2.0.9`
[`Pokecube AIO v3.5.1`](https://www.curseforge.com/minecraft/mc-mods/pokecube-aoi)
`Minecraft v1.16.4`
`Forge v35.1.28`

If another entity picks up the Banana Pet, the server crashes. The crash happens if pokecube is installed and the config setting `vanilla_pokemobs` in `pokecube_common.toml` is set to `true`. In my case, the crash occured when a piglin picked up the banana pet that I had tagged with `minecraft:piglin_loved`
[Crash Report](https://gist.github.com/WenXin20/0f39795447e4909ebd840aa1cf12c889)","Banana Pet Server Crash `Inventory Pets v2.0.9` [`Pokecube AIO v3.5.1`](https://www.curseforge.com/minecraft/mc-mods/pokecube-aoi) `Minecraft v1.16.4` `Forge v35.1.28` If another entity picks up the Banana Pet, the server crashes. The crash happens if pokecube is installed and the config setting `vanilla_pokemobs` in `pokecube_common.toml` is set to `true`. In my case, the crash occured when a piglin picked up the banana pet that I had tagged with `minecraft:piglin_loved` [Crash Report](https://gist.github.com/WenXin20/0f39795447e4909ebd840aa1cf12c889)"
77022,77022,85633,https://api.github.com/repos/ashishpapanai/chessJS/issues/57,1.0,2021-01-05T14:39:15Z,OWNER,https://api.github.com/repos/ashishpapanai/chessJS,Adding timer for creating time controlled variants in the game. ,"With the evolution of chess different variants have come up and are recognised by FIDE. ChessJS is expected to add these time control with the help of contributors. 

Needed time controls: 

- [ ] Classical: No time control or 30 minutes with 20-second increment after each move for either side.
- [ ] Rapid: 15 mins with 10 seconds increment after each move for either side. 
- [ ] Blitz: 5 mins with 10 seconds increment after each move for either side. 
- [ ] Bullet: 2 mins with 10 seconds increment after each move for either side. 

The game will end after the timer of any side runs out and the side with time left on the clock will be declared as the winner. 

The timer needs to be displayed to both the user at the top right corner of the board for black and bottom right for the white pieces. ",Adding timer for creating time controlled variants in the game. With the evolution of chess different variants have come up and are recognised by FIDE. ChessJS is expected to add these time control with the help of contributors. Needed time controls: - [ ] Classical: No time control or 30 minutes with 20-second increment after each move for either side. - [ ] Rapid: 15 mins with 10 seconds increment after each move for either side. - [ ] Blitz: 5 mins with 10 seconds increment after each move for either side. - [ ] Bullet: 2 mins with 10 seconds increment after each move for either side. The game will end after the timer of any side runs out and the side with time left on the clock will be declared as the winner. The timer needs to be displayed to both the user at the top right corner of the board for black and bottom right for the white pieces. 
779702,779702,566919,https://api.github.com/repos/Tencent/bk-bcs/issues/782,0.0,2021-02-25T02:23:28Z,CONTRIBUTOR,https://api.github.com/repos/Tencent/bk-bcs,bk-bscp empty strategy values bug,should not ignore bk-bscp empty values in strategy.,bk-bscp empty strategy values bug should not ignore bk-bscp empty values in strategy.
348411,348411,387339,https://api.github.com/repos/nav-gov-hu/Online-Invoice/issues/791,2.0,2021-03-02T09:43:36Z,NONE,https://api.github.com/repos/nav-gov-hu/Online-Invoice,[Q&A] softwareId,"Az API le챠r찼sban a k챕r챕sek fejl챕c챕ben k철telez mezk챕nt szerepel a softwareId, vagyis a ""A sz찼ml찼z처 program azonos챠t처ja"". Ez pontosan milyen azonos챠t처 챕s hogyan lehet hozz찼jutni egy ilyenhez?","[Q&A] softwareId Az API le챠r찼sban a k챕r챕sek fejl챕c챕ben k철telez mezk챕nt szerepel a softwareId, vagyis a ""A sz찼ml찼z처 program azonos챠t처ja"". Ez pontosan milyen azonos챠t처 챕s hogyan lehet hozz찼jutni egy ilyenhez?"
744350,744350,212772,https://api.github.com/repos/microsoft/vscode/issues/116870,0.0,2021-02-17T19:22:30Z,NONE,https://api.github.com/repos/microsoft/vscode,VSCode integrated terminal text overlap,"<!-- 截截 Do Not Delete This! bug_report_template 截截 -->
<!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ -->
<!--  Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions -->
<!--  Search existing issues to avoid creating duplicates. -->
<!-- ㎦ Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ -->
<!--  Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. -->

# System

CPUs | Intel(R) Xeon(R) W-2140B CPU @ 3.20GHz (16 x 3200)
-- | --
GPU Status | 2d_canvas: enabled gpu_compositing: enabled metal: disabled_off multiple_raster_threads: enabled_on oop_rasterization: enabled opengl: enabled_on protected_video_decode: unavailable_off rasterization: enabled skia_renderer: disabled_off_ok video_decode: enabled webgl: enabled webgl2: enabled
Load (avg) | 4, 4, 3
Memory (System) | 64.00GB (15.64GB free)
Process Argv | --crash-reporter-id a89ac4a4-a92a-483e-9532-9b18b01d1b98
Screen Reader | no
VM | 0%

# Extensions

Extension | Author (truncated) | Version
-- | -- | --
codespaces | Git | 0.7.2
remote-containers | ms- | 0.160.0
vim | vsc | 1.18.9
codespaces | Git | 0.7.2
vscode-pull-request-github | Git | 0.23.1

# Steps to Reproduce:

In Codespaces (but don't think it's the cause) the integrated terminal text can overlap.

If you resize VSCode to a smaller screen size and type in the integrated terminal you'll have the text that keeps showing up on the same line (eventually erasing the promt and other text).

<img width=""1409"" alt=""Screen Shot 2021-02-17 at 2 18 30 PM"" src=""https://user-images.githubusercontent.com/7839202/108256452-8f801380-712b-11eb-83c1-347c421f8142.png"">

<!--  Launch with `code --disable-extensions` to check. -->
Does this issue occur when all extensions are disabled?: Yes

<!--  If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. -->
<!--  Issues caused by an extension need to be reported direct to the extension publisher. The 'Help > Report Issue' dialog can assist with this. -->
","VSCode integrated terminal text overlap <!-- 截截 Do Not Delete This! bug_report_template 截截 --> <!-- Please read our Rules of Conduct: https://opensource.microsoft.com/codeofconduct/ --> <!--  Read our guide about submitting issues: https://github.com/microsoft/vscode/wiki/Submitting-Bugs-and-Suggestions --> <!--  Search existing issues to avoid creating duplicates. --> <!-- ㎦ Test using the latest Insiders build to see if your issue has already been fixed: https://code.visualstudio.com/insiders/ --> <!--  Instead of creating your report here, use 'Report Issue' from the 'Help' menu in VS Code to pre-fill useful information. --> # System CPUs | Intel(R) Xeon(R) W-2140B CPU @ 3.20GHz (16 x 3200) -- | -- GPU Status | 2d_canvas: enabled gpu_compositing: enabled metal: disabled_off multiple_raster_threads: enabled_on oop_rasterization: enabled opengl: enabled_on protected_video_decode: unavailable_off rasterization: enabled skia_renderer: disabled_off_ok video_decode: enabled webgl: enabled webgl2: enabled Load (avg) | 4, 4, 3 Memory (System) | 64.00GB (15.64GB free) Process Argv | --crash-reporter-id a89ac4a4-a92a-483e-9532-9b18b01d1b98 Screen Reader | no VM | 0% # Extensions Extension | Author (truncated) | Version -- | -- | -- codespaces | Git | 0.7.2 remote-containers | ms- | 0.160.0 vim | vsc | 1.18.9 codespaces | Git | 0.7.2 vscode-pull-request-github | Git | 0.23.1 # Steps to Reproduce: In Codespaces (but don't think it's the cause) the integrated terminal text can overlap. If you resize VSCode to a smaller screen size and type in the integrated terminal you'll have the text that keeps showing up on the same line (eventually erasing the promt and other text). <img width=""1409"" alt=""Screen Shot 2021-02-17 at 2 18 30 PM"" src=""https://user-images.githubusercontent.com/7839202/108256452-8f801380-712b-11eb-83c1-347c421f8142.png""> <!--  Launch with `code --disable-extensions` to check. --> Does this issue occur when all extensions are disabled?: Yes <!--  If you answered No above, use 'Help: Start Extension Bisect' from Command Palette to try to identify the cause. --> <!--  Issues caused by an extension need to be reported direct to the extension publisher. The 'Help > Report Issue' dialog can assist with this. --> "
337280,337280,374931,https://api.github.com/repos/Clamb94/StableApproach/issues/21,1.0,2021-04-15T06:41:25Z,OWNER,https://api.github.com/repos/Clamb94/StableApproach,"Add option to have ""non-critical"" requirements",Not all requirements should cause a UNSTABLE condition,"Add option to have ""non-critical"" requirements Not all requirements should cause a UNSTABLE condition"
794278,794278,711885,https://api.github.com/repos/kurrycat2004/MpkMod/issues/6,1.0,2020-11-04T21:38:58Z,OWNER,https://api.github.com/repos/kurrycat2004/MpkMod,Recording,"Record inputs as macro when record mode is activated.
(reset when tped?)",Recording Record inputs as macro when record mode is activated. (reset when tped?)
687366,687366,763922,https://api.github.com/repos/leeper/rio/issues/226,1.0,2019-09-23T14:26:59Z,CONTRIBUTOR,https://api.github.com/repos/leeper/rio,Several tweaks ,"Please specify whether your issue is about:

 - [ ] a possible bug
 - [ ] a question about package functionality
 - [x] a suggested code or documentation change, improvement to the code, or feature request

This is a ticket for several tiny changes and each PR will reference this ticket if that's okay?

1.  ~~As per [the conversation accompanying #222](/leeper/rio/pull/222#issuecomment-533807284) I propose to add a `rio.Rproj` file to automatically enforce line endings (newline), encoding (UTF-8), and tabs (4 spaces, convert to spaces).~~
2.  ~~A test in PR #222 returns a warning, which is its intended behavior. So I ought to wrap that in `testthat::expect_warning()` which I found out about while working on the ODS import.~~
3. ~~`testthat` still gives `Failure: Import from (European-style) CSV with semicolon separator (@test_format_csv.R#32) is.numeric(iris_imported[[""Sepal.Length""]]) isn't true.`.  If I'm the first to get to it, I'll be happy to take a look and if I understand the problem, fix it.~~ (someone else seems to have fixed it one way or another, not seeing the failure anumore)
4. A slightly inconsistent warning message in `.import.rio_xlsx()`:  `path` argument gets ignored, but that one isn't warned about.
5. ~~... I thought I noticed a couple of others but can't remember them right now. When they come back to me I'll add them. :-)~~","Several tweaks Please specify whether your issue is about: - [ ] a possible bug - [ ] a question about package functionality - [x] a suggested code or documentation change, improvement to the code, or feature request This is a ticket for several tiny changes and each PR will reference this ticket if that's okay? 1. ~~As per [the conversation accompanying #222](/leeper/rio/pull/222#issuecomment-533807284) I propose to add a `rio.Rproj` file to automatically enforce line endings (newline), encoding (UTF-8), and tabs (4 spaces, convert to spaces).~~ 2. ~~A test in PR #222 returns a warning, which is its intended behavior. So I ought to wrap that in `testthat::expect_warning()` which I found out about while working on the ODS import.~~ 3. ~~`testthat` still gives `Failure: Import from (European-style) CSV with semicolon separator (@test_format_csv.R#32) is.numeric(iris_imported[[""Sepal.Length""]]) isn't true.`. If I'm the first to get to it, I'll be happy to take a look and if I understand the problem, fix it.~~ (someone else seems to have fixed it one way or another, not seeing the failure anumore) 4. A slightly inconsistent warning message in `.import.rio_xlsx()`: `path` argument gets ignored, but that one isn't warned about. 5. ~~... I thought I noticed a couple of others but can't remember them right now. When they come back to me I'll add them. :-)~~"
712059,712059,791391,https://api.github.com/repos/blockframes/blockframes/issues/5330,0.0,2021-03-22T10:23:26Z,COLLABORATOR,https://api.github.com/repos/blockframes/blockframes,MF: On launching the app a blank page gets displayed at the start,"
![image](https://user-images.githubusercontent.com/8731418/111975432-9af99c80-8b26-11eb-894f-da46ca1df99a.png)

I see that the Google Map script is time outing at my end. So it could be cause of blank screen.

We could see if async/defer of the script can improve the first paint here.",MF: On launching the app a blank page gets displayed at the start ![image](https://user-images.githubusercontent.com/8731418/111975432-9af99c80-8b26-11eb-894f-da46ca1df99a.png) I see that the Google Map script is time outing at my end. So it could be cause of blank screen. We could see if async/defer of the script can improve the first paint here.
111449,111449,123878,https://api.github.com/repos/bincrafters/community/issues/1347,0.0,2021-01-19T19:00:09Z,NONE,https://api.github.com/repos/bincrafters/community,qt/5.15.2@bincrafters/stable: failed to download sources,"<!-- 
  Please don't forget to update the issue title.
  Include all applicable information to help us reproduce your problem.
-->

### Package and Environment Details (include every applicable attribute)
  * Package Name/Version: **qt/5.15.2@bincrafters/stable**
  * Operating System+version: **any**
  * Conan version: **conan 1.32.1**


### Conan profile (output of `conan profile show default` or `conan profile show <profile>` if custom profile is in use)
```
[settings]
arch=x86_64
arch_build=x86_64
build_type=Debug
compiler=gcc
compiler.libcxx=libstdc++11
compiler.version=9.3
os=Linux
os_build=Linux
[options]
*:fPIC=True
[build_requires]
[env]

```


### Steps to reproduce (Include if Applicable)
conan install qt/5.15.2@bincrafters/stable  --build outdated


### Logs (Include/Attach if Applicable)
<details><summary>Click to expand log</summary>

```
qt/5.15.2@bincrafters/stable: WARN: Trying to remove corrupted source folder
qt/5.15.2@bincrafters/stable: WARN: This can take a while for big packages
qt/5.15.2@bincrafters/stable: Configuring sources in /home/andrei/.conan/data/qt/5.15.2/bincrafters/stable/source
./reb	
ERROR: Error downloading file https://download.qt.io/archive/qt/5.15/5.15.2/single/qt-everywhere-src-5.15.2.tar.xz: 'HTTPSConnectionPool(host='download.qt.io', port=443): Max retries exceeded with url: /archive/qt/5.15/5.15.2/single/qt-everywhere-src-5.15.2.tar.xz (Caused by ReadTimeoutError(""HTTPSConnectionPool(host='download.qt.io', port=443): Read timed out. (read timeout=60.0)""))'
Waiting 5 seconds to retry...
ERROR: qt/5.15.2@bincrafters/stable: Error in source() method, line 360
	tools.get(**self.conan_data[""sources""][self.version])
	ConanException: Error downloading file https://download.qt.io/archive/qt/5.15/5.15.2/single/qt-everywhere-src-5.15.2.tar.xz: 'HTTPSConnectionPool(host='download.qt.io', port=443): Max retries exceeded with url: /archive/qt/5.15/5.15.2/single/qt-everywhere-src-5.15.2.tar.xz (Caused by ReadTimeoutError(""HTTPSConnectionPool(host='download.qt.io', port=443): Read timed out. (read timeout=60.0)""))'

```

</details>
","qt/5.15.2@bincrafters/stable: failed to download sources <!-- Please don't forget to update the issue title. Include all applicable information to help us reproduce your problem. --> ### Package and Environment Details (include every applicable attribute) * Package Name/Version: **qt/5.15.2@bincrafters/stable** * Operating System+version: **any** * Conan version: **conan 1.32.1** ### Conan profile (output of `conan profile show default` or `conan profile show <profile>` if custom profile is in use) ``` [settings] arch=x86_64 arch_build=x86_64 build_type=Debug compiler=gcc compiler.libcxx=libstdc++11 compiler.version=9.3 os=Linux os_build=Linux [options] *:fPIC=True [build_requires] [env] ``` ### Steps to reproduce (Include if Applicable) conan install qt/5.15.2@bincrafters/stable --build outdated ### Logs (Include/Attach if Applicable) <details><summary>Click to expand log</summary> ``` qt/5.15.2@bincrafters/stable: WARN: Trying to remove corrupted source folder qt/5.15.2@bincrafters/stable: WARN: This can take a while for big packages qt/5.15.2@bincrafters/stable: Configuring sources in /home/andrei/.conan/data/qt/5.15.2/bincrafters/stable/source ./reb ERROR: Error downloading file https://download.qt.io/archive/qt/5.15/5.15.2/single/qt-everywhere-src-5.15.2.tar.xz: 'HTTPSConnectionPool(host='download.qt.io', port=443): Max retries exceeded with url: /archive/qt/5.15/5.15.2/single/qt-everywhere-src-5.15.2.tar.xz (Caused by ReadTimeoutError(""HTTPSConnectionPool(host='download.qt.io', port=443): Read timed out. (read timeout=60.0)""))' Waiting 5 seconds to retry... ERROR: qt/5.15.2@bincrafters/stable: Error in source() method, line 360 tools.get(**self.conan_data[""sources""][self.version]) ConanException: Error downloading file https://download.qt.io/archive/qt/5.15/5.15.2/single/qt-everywhere-src-5.15.2.tar.xz: 'HTTPSConnectionPool(host='download.qt.io', port=443): Max retries exceeded with url: /archive/qt/5.15/5.15.2/single/qt-everywhere-src-5.15.2.tar.xz (Caused by ReadTimeoutError(""HTTPSConnectionPool(host='download.qt.io', port=443): Read timed out. (read timeout=60.0)""))' ``` </details> "
249711,249711,277760,https://api.github.com/repos/simplicy-io/eurc-eth/issues/11,1.0,2021-02-22T11:12:22Z,CONTRIBUTOR,https://api.github.com/repos/simplicy-io/eurc-eth,Feature: Add Binance Chain (BEP20) compatibility and testing,"**Is your feature request related to a problem? Please describe.**
Make sure this contract is compatible with Binance Chain and the ability to swap tokens in Binance

**Describe the solution you'd like**
Add [IBEP20](https://docs.binance.org/smart-chain/developer/IBEP20.sol)

",Feature: Add Binance Chain (BEP20) compatibility and testing **Is your feature request related to a problem? Please describe.** Make sure this contract is compatible with Binance Chain and the ability to swap tokens in Binance **Describe the solution you'd like** Add [IBEP20](https://docs.binance.org/smart-chain/developer/IBEP20.sol) 
172606,172606,191915,https://api.github.com/repos/dkgv/pinpoint/issues/100,1.0,2021-05-04T15:50:13Z,OWNER,https://api.github.com/repos/dkgv/pinpoint,ALT+Select option for results,"For example, open file location directly via ALT+Select","ALT+Select option for results For example, open file location directly via ALT+Select"
174439,174439,193968,https://api.github.com/repos/amannn/action-semantic-pull-request/issues/78,0.0,2021-01-19T08:16:15Z,OWNER,https://api.github.com/repos/amannn/action-semantic-pull-request,"When `subjectPatternError` is configured, the action can not succeed",Due to a missing condition before the error is thrown,"When `subjectPatternError` is configured, the action can not succeed Due to a missing condition before the error is thrown"
329276,329276,366055,https://api.github.com/repos/ufersa/plataforma-sabia/issues/853,0.0,2021-02-24T12:36:21Z,CONTRIBUTOR,https://api.github.com/repos/ufersa/plataforma-sabia,Banco de Ideias est찼 inacess챠vel,Quando acessado por http://plataformasabia.com/ideas-bank ocorre um erro 400.,Banco de Ideias est찼 inacess챠vel Quando acessado por http://plataformasabia.com/ideas-bank ocorre um erro 400.
479592,479592,533030,https://api.github.com/repos/danStich/shadia/issues/50,0.0,2021-01-05T21:40:09Z,OWNER,https://api.github.com/repos/danStich/shadia,Transient dynamics resulting from simStartingPop(),There are some odd transient dynamics occurring as a result of the new routine used to simulate the starting population.,Transient dynamics resulting from simStartingPop() There are some odd transient dynamics occurring as a result of the new routine used to simulate the starting population.
673160,673160,748153,https://api.github.com/repos/realness-online/web/issues/30,1.0,2021-03-12T02:34:54Z,MEMBER,https://api.github.com/repos/realness-online/web,The feed should announces when someone changes their avatar,,The feed should announces when someone changes their avatar 
774219,774219,512104,https://api.github.com/repos/da3nil/aigul-shop/issues/18,1.0,2021-05-31T04:12:23Z,OWNER,https://api.github.com/repos/da3nil/aigul-shop,"克棘戟克龜 剋筠勻逵 棘 克逵筠均棘龜橘, png 克逵龜戟克逵. 鬼畇筠剋逵橘 極棘克逵 鈞逵均剋克",,"克棘戟克龜 剋筠勻逵 棘 克逵筠均棘龜橘, png 克逵龜戟克逵. 鬼畇筠剋逵橘 極棘克逵 鈞逵均剋克 "
176784,176784,196549,https://api.github.com/repos/ikvk/imap_tools/issues/95,2.0,2021-01-31T11:38:10Z,NONE,https://api.github.com/repos/ikvk/imap_tools,PEP 561 compliance,"Could you make this library PEP 561 compliant so I can use it with mypy?
See https://mypy.readthedocs.io/en/latest/running_mypy.html#missing-type-hints-for-third-party-library.",PEP 561 compliance Could you make this library PEP 561 compliant so I can use it with mypy? See https://mypy.readthedocs.io/en/latest/running_mypy.html#missing-type-hints-for-third-party-library.
150335,150335,167113,https://api.github.com/repos/PoolC/Haribo/issues/11,1.0,2021-02-22T08:08:02Z,CONTRIBUTOR,https://api.github.com/repos/PoolC/Haribo,Admin - 濡 愿由 댁,"##  ㅻ

Admin - 濡 愿由 댁 援ы



##  泥댄щ━ㅽ

> 援ы댁쇳 댁 泥댄щ━ㅽ

<img width=""734"" alt=""녁녁듄メａ 2021-02-22 ⒰ 5 07 43"" src=""https://user-images.githubusercontent.com/48787170/108679870-7bc01d00-7530-11eb-881d-b714bef2cf71.png"">
","Admin - 濡 愿由 댁 ##  ㅻ Admin - 濡 愿由 댁 援ы ##  泥댄щ━ㅽ > 援ы댁쇳 댁 泥댄щ━ㅽ <img width=""734"" alt=""녁녁듄メａ 2021-02-22 ⒰ 5 07 43"" src=""https://user-images.githubusercontent.com/48787170/108679870-7bc01d00-7530-11eb-881d-b714bef2cf71.png""> "
690324,690324,767223,https://api.github.com/repos/turbot/steampipe-mod-gcp-compliance/issues/7,1.0,2021-05-20T06:45:24Z,NONE,https://api.github.com/repos/turbot/steampipe-mod-gcp-compliance,Add CIS v1.2.0 section 2 docs,"**Is your feature request related to a problem? Please describe.**
CIS section 2 benchmark and controls should have supporting documents.

**Describe the solution you'd like**
Add documents for section 2 benchmark and controls.

**Describe alternatives you've considered**
N/A

**Additional context**
Add any other context or screenshots about the feature request here.
",Add CIS v1.2.0 section 2 docs **Is your feature request related to a problem? Please describe.** CIS section 2 benchmark and controls should have supporting documents. **Describe the solution you'd like** Add documents for section 2 benchmark and controls. **Describe alternatives you've considered** N/A **Additional context** Add any other context or screenshots about the feature request here. 
765066,765066,419875,https://api.github.com/repos/neovim/neovim/issues/14089,0.0,2021-03-10T00:30:45Z,MEMBER,https://api.github.com/repos/neovim/neovim,CursorLineNr colors diff filler lines,"<!-- Before reporting: search existing issues and check the FAQ. -->

- `nvim --version`: e355cc8cc5c131e6df429107f321dd4a80c05065
- `vim -u DEFAULTS` (version: ) yes 

### Steps to reproduce using `nvim -u NORC`

Gotta find a way to reproduce but basically LineNr and diff mode/filler lines results in an incorrect highlight result.
![2021-02-24_16-55](https://user-images.githubusercontent.com/886074/110556913-c3a18f80-813f-11eb-83c1-1897548adea3.png)

Reminder for myself but anyone feel free to pick it up.

### Actual behaviour
CursorLineNr colors diff filler lines.

### Expected behaviour
CursorLineNr only colors the current line

",CursorLineNr colors diff filler lines <!-- Before reporting: search existing issues and check the FAQ. --> - `nvim --version`: e355cc8cc5c131e6df429107f321dd4a80c05065 - `vim -u DEFAULTS` (version: ) yes ### Steps to reproduce using `nvim -u NORC` Gotta find a way to reproduce but basically LineNr and diff mode/filler lines results in an incorrect highlight result. ![2021-02-24_16-55](https://user-images.githubusercontent.com/886074/110556913-c3a18f80-813f-11eb-83c1-1897548adea3.png) Reminder for myself but anyone feel free to pick it up. ### Actual behaviour CursorLineNr colors diff filler lines. ### Expected behaviour CursorLineNr only colors the current line 
392112,392112,435834,https://api.github.com/repos/lix229/UnityRuntimeImport/issues/12,2.0,2021-02-26T18:19:53Z,NONE,https://api.github.com/repos/lix229/UnityRuntimeImport,Animation Editor Uncaught TypeError: keyFrameList[0] is undefined,"In Firefox. 
Load Animation Editor. 
Immediately hit remove frame.

Console spits out Uncaught TypeError: keyFrameList[0] is undefined.",Animation Editor Uncaught TypeError: keyFrameList[0] is undefined In Firefox. Load Animation Editor. Immediately hit remove frame. Console spits out Uncaught TypeError: keyFrameList[0] is undefined.
124799,124799,138690,https://api.github.com/repos/nicehash/NiceHashQuickMiner/issues/48,2.0,2021-02-17T23:55:10Z,NONE,https://api.github.com/repos/nicehash/NiceHashQuickMiner,[question] ETHlargementPill ,Any future release maybe including pill?,[question] ETHlargementPill Any future release maybe including pill?
697729,697729,775476,https://api.github.com/repos/vokseverk/Vokseverk.ColorSelector/issues/1,1.0,2021-02-20T13:49:48Z,MEMBER,https://api.github.com/repos/vokseverk/Vokseverk.ColorSelector,Add descriptive text to the property editor,"Something along the lines of:

```
""Input a valid CSS hex color: [             ] - or choose one of these presets: [  ] [  ] [  ]""
```

## Tasks

- [x] Add `<localize>` directives to view
- [x] Add `Lang` folder
- [x] Add `en-US.xml` + `en-GB.xml` (color vs. colour)
- [x] Add `da.xml`

Reference: https://our.umbraco.com/documentation/Extending/Packages/Language-Files-For-Packages/
","Add descriptive text to the property editor Something along the lines of: ``` ""Input a valid CSS hex color: [ ] - or choose one of these presets: [ ] [ ] [ ]"" ``` ## Tasks - [x] Add `<localize>` directives to view - [x] Add `Lang` folder - [x] Add `en-US.xml` + `en-GB.xml` (color vs. colour) - [x] Add `da.xml` Reference: https://our.umbraco.com/documentation/Extending/Packages/Language-Files-For-Packages/ "
435796,435796,484478,https://api.github.com/repos/stefan-niedermann/nextcloud-notes/issues/1020,1.0,2021-01-05T14:01:08Z,OWNER,https://api.github.com/repos/stefan-niedermann/nextcloud-notes, Update formatting section ,"- [x] Add [images from FAQ](https://github.com/stefan-niedermann/nextcloud-notes/blob/master/FAQ.md#why-arent-there-any-buttons-to-apply-formatting) for context based formatting
- [x] Add samples for tables
- [x] Add samples for images", Update formatting section - [x] Add [images from FAQ](https://github.com/stefan-niedermann/nextcloud-notes/blob/master/FAQ.md#why-arent-there-any-buttons-to-apply-formatting) for context based formatting - [x] Add samples for tables - [x] Add samples for images
386974,386974,430164,https://api.github.com/repos/lancelote/clean-docker/issues/1,1.0,2021-05-16T20:55:21Z,OWNER,https://api.github.com/repos/lancelote/clean-docker,Proper CLI with click,,Proper CLI with click 
627003,627003,696808,https://api.github.com/repos/Mephiles/torntools_2/issues/92,0.0,2020-12-15T10:41:50Z,COLLABORATOR,https://api.github.com/repos/Mephiles/torntools_2,Last action in popup resulting in the popup closing when it opens to the bottom.,Last action in popup resulting in the popup closing when it opens to the bottom.,Last action in popup resulting in the popup closing when it opens to the bottom. Last action in popup resulting in the popup closing when it opens to the bottom.
343341,343341,381672,https://api.github.com/repos/ModernFlyouts-Community/ModernFlyouts/issues/607,0.0,2021-05-05T10:57:41Z,NONE,https://api.github.com/repos/ModernFlyouts-Community/ModernFlyouts,Bug  top bar not hide automatically:,I used modern flyouts months but from yesterday after the windows update. when I volume/brightness increase/decrease it not hide it stay visible. I also reset it but not fix it. top bar visibility is set to auto-hide mode.,Bug top bar not hide automatically: I used modern flyouts months but from yesterday after the windows update. when I volume/brightness increase/decrease it not hide it stay visible. I also reset it but not fix it. top bar visibility is set to auto-hide mode.
333170,333170,370379,https://api.github.com/repos/BlockResearchGroup/compas-RV2/issues/180,1.0,2020-07-01T13:32:45Z,CONTRIBUTOR,https://api.github.com/repos/BlockResearchGroup/compas-RV2,2D scale vertices,add to modify force diagram,2D scale vertices add to modify force diagram
424951,424951,472362,https://api.github.com/repos/flexion/ef-cms/issues/7584,0.0,2021-01-15T20:47:22Z,COLLABORATOR,https://api.github.com/repos/flexion/ef-cms,BUG: Electronic signatures not viewable in PDF preview,"**Describe the Bug**
When a party is eFiling a document that has been electronically signed, the eSignature does not display in the PDF previewer modal, so they are not sure whether it will be there when filed.  Note:  It does actually show on the filed version, but it's causing a lot of uncertainty on the part of the filer.

**Business Impact/Reason for Severity**

**In which environment did you see this bug?**
Court's prod

**Who were you logged in as?**
IRS reported

**What were you doing when you discovered this bug? (Using the application, demoing, smoke tests, testing other functionality, etc.)**

**To Reproduce**
Steps to reproduce the behavior:
1. Log in as IRS attorney
2. Attempt to file a PDF that has been electronically signed. Sample: [https://app.zenhub.com/files/152320868/15f57d3a-c3a5-43d6-b400-138fc425101d/download](https://app.zenhub.com/files/152320868/15f57d3a-c3a5-43d6-b400-138fc425101d/download)
3. Note that the eSignature does not appear on the document when viewed in the PDF viewer on the ""Review Your Filing"" screen

**Expected Behavior**
Electronic signature is visible in PDF viewer

**Actual Behavior**
IRS attorney trying to eFile a document that was eSigned did not see signature on PDF when reviewing before filing:
![image.png](https://images.zenhubusercontent.com/5bbfb4d092b88e6ddb8b0e3d/0c14c3ff-f9ad-4fe8-b95a-e6c661986103).

Once filed, the electronic signature does appear on the PDF:
![image.png](https://images.zenhubusercontent.com/5bbfb4d092b88e6ddb8b0e3d/c0b4f446-d0f6-4e11-89a0-9b571cab37e9)

**Desktop (please complete the following information):**
Edge Version:   87.0.664.41 (Official build) (64-bit)
Abode info: ![image.png](https://images.zenhubusercontent.com/5bbfb4d092b88e6ddb8b0e3d/63a12e61-647b-4c48-9784-bc8ab8ab55ba)

**Smartphone (please complete the following information):**
 - Device: [e.g. iPhone6]
 - OS: [e.g. iOS8.1]
 - Browser [e.g. stock browser, safari]
 - Version [e.g. 22]

**Cause of Bug, If Known**


**Process for Logging a Bug:**
* Complete the above information
* Add a severity tag (Critical, High Severity, Medium Severity or Low Severity). See below for priority definition. 

**Severity Definition:**
* Critical Defect
Blocks entire system's or modules functionality
No workarounds available
Testing cannot proceed further without bug being fixed.

* High-severity Defect
Affects key functionality of an application
There's a workaround, but not obvious or easy
App behaves in a way that is strongly different from the one stated in the requirements

* Medium-severity Defect
A minor function does not behave in a way stated in the requirements.
Workaround is available and easy

* Low-severity Defect
Mostly related to an applications UI
Doesn't need a workaround, because it doesn't impact functionality

**FOR ENGINEERING TEAM ONLY**
Bug Resolution Steps:
 - [x] Determine why the bug wasn't caught by a test. 
 - [x] Determine if an automated test needs to fixed, expanded or created. If unsure, bring in others to discuss.
 - [x] Determine if a manual test needs to be fixed, expanded or created. If unsure, bring in others to discuss.
 - [x] If needed, automated test is created.
 - [x] If needed, manual test is created.
 - [x] Reason for bug has been documented.
 - [x] Fix has been deployed to dev environment.
 - [x] Fix has been deployed to the Flexion prod environment.
 - [x] Bug has been tested in Flexion prod environment (UX or Engineering).
","BUG: Electronic signatures not viewable in PDF preview **Describe the Bug** When a party is eFiling a document that has been electronically signed, the eSignature does not display in the PDF previewer modal, so they are not sure whether it will be there when filed. Note: It does actually show on the filed version, but it's causing a lot of uncertainty on the part of the filer. **Business Impact/Reason for Severity** **In which environment did you see this bug?** Court's prod **Who were you logged in as?** IRS reported **What were you doing when you discovered this bug? (Using the application, demoing, smoke tests, testing other functionality, etc.)** **To Reproduce** Steps to reproduce the behavior: 1. Log in as IRS attorney 2. Attempt to file a PDF that has been electronically signed. Sample: [https://app.zenhub.com/files/152320868/15f57d3a-c3a5-43d6-b400-138fc425101d/download](https://app.zenhub.com/files/152320868/15f57d3a-c3a5-43d6-b400-138fc425101d/download) 3. Note that the eSignature does not appear on the document when viewed in the PDF viewer on the ""Review Your Filing"" screen **Expected Behavior** Electronic signature is visible in PDF viewer **Actual Behavior** IRS attorney trying to eFile a document that was eSigned did not see signature on PDF when reviewing before filing: ![image.png](https://images.zenhubusercontent.com/5bbfb4d092b88e6ddb8b0e3d/0c14c3ff-f9ad-4fe8-b95a-e6c661986103). Once filed, the electronic signature does appear on the PDF: ![image.png](https://images.zenhubusercontent.com/5bbfb4d092b88e6ddb8b0e3d/c0b4f446-d0f6-4e11-89a0-9b571cab37e9) **Desktop (please complete the following information):** Edge Version: 87.0.664.41 (Official build) (64-bit) Abode info: ![image.png](https://images.zenhubusercontent.com/5bbfb4d092b88e6ddb8b0e3d/63a12e61-647b-4c48-9784-bc8ab8ab55ba) **Smartphone (please complete the following information):** - Device: [e.g. iPhone6] - OS: [e.g. iOS8.1] - Browser [e.g. stock browser, safari] - Version [e.g. 22] **Cause of Bug, If Known** **Process for Logging a Bug:** * Complete the above information * Add a severity tag (Critical, High Severity, Medium Severity or Low Severity). See below for priority definition. **Severity Definition:** * Critical Defect Blocks entire system's or modules functionality No workarounds available Testing cannot proceed further without bug being fixed. * High-severity Defect Affects key functionality of an application There's a workaround, but not obvious or easy App behaves in a way that is strongly different from the one stated in the requirements * Medium-severity Defect A minor function does not behave in a way stated in the requirements. Workaround is available and easy * Low-severity Defect Mostly related to an applications UI Doesn't need a workaround, because it doesn't impact functionality **FOR ENGINEERING TEAM ONLY** Bug Resolution Steps: - [x] Determine why the bug wasn't caught by a test. - [x] Determine if an automated test needs to fixed, expanded or created. If unsure, bring in others to discuss. - [x] Determine if a manual test needs to be fixed, expanded or created. If unsure, bring in others to discuss. - [x] If needed, automated test is created. - [x] If needed, manual test is created. - [x] Reason for bug has been documented. - [x] Fix has been deployed to dev environment. - [x] Fix has been deployed to the Flexion prod environment. - [x] Bug has been tested in Flexion prod environment (UX or Engineering). "
214279,214279,238282,https://api.github.com/repos/gravitational/next/issues/142,0.0,2021-03-17T19:56:26Z,NONE,https://api.github.com/repos/gravitational/next,Broken Link,"Reporting a broken link on the following page: https://goteleport.com/docs/architecture/users/
Broken link: https://goteleport.com/enterprise/introduction/  Show a 404

![image](https://user-images.githubusercontent.com/407237/111529982-05be6880-8720-11eb-8b4b-424f0346c579.png)
",Broken Link Reporting a broken link on the following page: https://goteleport.com/docs/architecture/users/ Broken link: https://goteleport.com/enterprise/introduction/ Show a 404 ![image](https://user-images.githubusercontent.com/407237/111529982-05be6880-8720-11eb-8b4b-424f0346c579.png) 
711555,711555,790822,https://api.github.com/repos/hashicorp/terraform/issues/27723,0.0,2021-02-09T20:19:15Z,NONE,https://api.github.com/repos/hashicorp/terraform,Panic/TF Crash with terraform_remote_state and Azure Variable Group,"Experiencing a TF crash when passing variables with TF_VAR_x in an Azure DevOps variable group. Crash does not occur when including the TF_VARS_x variables directly in the pipeline. This is only happening with the teraform_remote_state provider


### Terraform Version
<!---
Run `terraform version` to show the version, and paste the result between the ``` marks below.

If you are not running the latest version of Terraform, please try upgrading because your issue may have already been fixed.
-->

```
0.14.6
```


### Debug Output
https://gist.github.com/ryanfields-8451/e55985224e179a1d4ae262fed2e06d31 

### Steps to Reproduce

1. `terraform init`
2. `terraform apply`

### Additional Context
This is only happening when passing the remote statefile config parameters as environment variables in an Azure Devops variable group. If the environment variables are each declared in the pipeline rather than the group the pipeline is successful. 

### References
Similar to #27511
","Panic/TF Crash with terraform_remote_state and Azure Variable Group Experiencing a TF crash when passing variables with TF_VAR_x in an Azure DevOps variable group. Crash does not occur when including the TF_VARS_x variables directly in the pipeline. This is only happening with the teraform_remote_state provider ### Terraform Version <!--- Run `terraform version` to show the version, and paste the result between the ``` marks below. If you are not running the latest version of Terraform, please try upgrading because your issue may have already been fixed. --> ``` 0.14.6 ``` ### Debug Output https://gist.github.com/ryanfields-8451/e55985224e179a1d4ae262fed2e06d31 ### Steps to Reproduce 1. `terraform init` 2. `terraform apply` ### Additional Context This is only happening when passing the remote statefile config parameters as environment variables in an Azure Devops variable group. If the environment variables are each declared in the pipeline rather than the group the pipeline is successful. ### References Similar to #27511 "
607413,607413,675021,https://api.github.com/repos/gpsyrou/Text_Analysis_of_Consumer_Reviews/issues/48,1.0,2021-04-27T18:21:47Z,OWNER,https://api.github.com/repos/gpsyrou/Text_Analysis_of_Consumer_Reviews,Create function to compute bigrams,"Create function to calculate the bigrams for a specific document (text). This will later be used for plotting, as well as used as an input in other algorithms.","Create function to compute bigrams Create function to calculate the bigrams for a specific document (text). This will later be used for plotting, as well as used as an input in other algorithms."
631344,631344,701657,https://api.github.com/repos/plantnet/gbif-dl/issues/16,1.0,2020-12-13T11:08:15Z,MEMBER,https://api.github.com/repos/plantnet/gbif-dl,add dependabot,,add dependabot 
741368,741368,183677,https://api.github.com/repos/tachiyomiorg/tachiyomi/issues/5035,0.0,2021-05-07T00:32:25Z,NONE,https://api.github.com/repos/tachiyomiorg/tachiyomi,[Bug] <Android 6.x no longer supported when checking for updates>,"**PLEASE READ THIS**

I acknowledge that:

- I have updated:
  - To the latest version of the app (stable is v0.10.12)
  - All extensions
- I have tried the troubleshooting guide: https://tachiyomi.org/help/guides/troubleshooting-problems/
- If this is an issue with an extension, that I should be opening an issue in https://github.com/tachiyomiorg/tachiyomi-extensions
- I have searched the existing issues and this is new ticket **NOT** a duplicate or related to another open issue
- I will fill out the title and the information in this template

Note that the issue will be automatically closed if you do not fill out the title or requested information.

## Device information
* Tachiyomi version: Stable v0.10.12
* Android version: 6.0.1
* Device: LG Nexus 5

## Steps to reproduce
1. About>Check for updates

### Expected behavior
it should say ""No new updates available""
 
### Actual behavior
It says my Android version (6.0.1) is no longer supported. As far as I know only 5.x has been dropped. 

## Other details
On the latest preview r3346 I still get the usual ""No new updates available"" prompt.","[Bug] <Android 6.x no longer supported when checking for updates> **PLEASE READ THIS** I acknowledge that: - I have updated: - To the latest version of the app (stable is v0.10.12) - All extensions - I have tried the troubleshooting guide: https://tachiyomi.org/help/guides/troubleshooting-problems/ - If this is an issue with an extension, that I should be opening an issue in https://github.com/tachiyomiorg/tachiyomi-extensions - I have searched the existing issues and this is new ticket **NOT** a duplicate or related to another open issue - I will fill out the title and the information in this template Note that the issue will be automatically closed if you do not fill out the title or requested information. ## Device information * Tachiyomi version: Stable v0.10.12 * Android version: 6.0.1 * Device: LG Nexus 5 ## Steps to reproduce 1. About>Check for updates ### Expected behavior it should say ""No new updates available"" ### Actual behavior It says my Android version (6.0.1) is no longer supported. As far as I know only 5.x has been dropped. ## Other details On the latest preview r3346 I still get the usual ""No new updates available"" prompt."
269006,269006,299158,https://api.github.com/repos/libsdl-org/SDL/issues/2365,1.0,2021-02-11T00:33:33Z,COLLABORATOR,https://api.github.com/repos/libsdl-org/SDL,clarify SDL_LockTexture() description,"
# This bug report was migrated from our old Bugzilla tracker.

**Reported in version:** HG 2.1
**Reported for operating system, platform:** All, All

# Comments on the original bug report:

On 2017-01-10 14:22:14 +0000, Stas Sergeev wrote:

> SDL_LockTexture() can be passed the rectangle to lock,
> instead of the entire texture. It is however unclear from
> the description how the memory pointed to by the 'pixels'
> pointer will then be organized. Will it still be the memory
> of the entire texture, with the ""permission"" for user to
> only write to the specified rectangle, or will it be the
> smaller buffer representing just the rectangle itself?
> 
> It would be nice to update the documentation to describe
> that. Also I wonder if passing the rect is a desirable
> thing to do, or is it slow and should be avoided?

On 2017-08-11 18:00:42 +0000, Sam Lantinga wrote:

> It's the smaller buffer representing just the rectangle itself, and you should be sure to respect the pitch parameter.
> 
> That's what the documentation says:
> *  \param pixels    This is filled in with a pointer to the locked pixels, appropriately offset by the locked area.
> 
> Do you have any suggestions on how to word that so it's more clear?

On 2017-08-11 21:22:53 +0000, Stas Sergeev wrote:

> Thanks, it now does indeed look pretty clear.
> Either I missed something, or maybe the text
> was different back when I opened this ticket...

On 2017-08-12 01:06:15 +0000, Sam Lantinga wrote:

> Okay, thanks for confirming!

","clarify SDL_LockTexture() description # This bug report was migrated from our old Bugzilla tracker. **Reported in version:** HG 2.1 **Reported for operating system, platform:** All, All # Comments on the original bug report: On 2017-01-10 14:22:14 +0000, Stas Sergeev wrote: > SDL_LockTexture() can be passed the rectangle to lock, > instead of the entire texture. It is however unclear from > the description how the memory pointed to by the 'pixels' > pointer will then be organized. Will it still be the memory > of the entire texture, with the ""permission"" for user to > only write to the specified rectangle, or will it be the > smaller buffer representing just the rectangle itself? > > It would be nice to update the documentation to describe > that. Also I wonder if passing the rect is a desirable > thing to do, or is it slow and should be avoided? On 2017-08-11 18:00:42 +0000, Sam Lantinga wrote: > It's the smaller buffer representing just the rectangle itself, and you should be sure to respect the pitch parameter. > > That's what the documentation says: > * \param pixels This is filled in with a pointer to the locked pixels, appropriately offset by the locked area. > > Do you have any suggestions on how to word that so it's more clear? On 2017-08-11 21:22:53 +0000, Stas Sergeev wrote: > Thanks, it now does indeed look pretty clear. > Either I missed something, or maybe the text > was different back when I opened this ticket... On 2017-08-12 01:06:15 +0000, Sam Lantinga wrote: > Okay, thanks for confirming! "
733744,733744,108412,https://api.github.com/repos/myspaghetti/macos-virtualbox/issues/384,1.0,2021-01-14T17:08:38Z,NONE,https://api.github.com/repos/myspaghetti/macos-virtualbox,support for MinGW/MSYS2,"hi,
can you support
https://www.msys2.org/
?

It is quite lighter than Cygwin, but has the necessary dependancy basic packages.
$ pacman -S coreutils wget gzip unzip
$ macos-guest-virtualbox.sh
I tryed to launch the shell, both in MSYS2 and in MinGW, but it is stuck immediately.
I will try to debug what happen and report here
","support for MinGW/MSYS2 hi, can you support https://www.msys2.org/ ? It is quite lighter than Cygwin, but has the necessary dependancy basic packages. $ pacman -S coreutils wget gzip unzip $ macos-guest-virtualbox.sh I tryed to launch the shell, both in MSYS2 and in MinGW, but it is stuck immediately. I will try to debug what happen and report here "
270248,270248,300545,https://api.github.com/repos/Uniswap/uniswap-interface/issues/1350,0.0,2021-03-31T08:26:32Z,NONE,https://api.github.com/repos/Uniswap/uniswap-interface,qubcoins.world and MetaMask problem. Need help.,"qubcoins.world and MetaMask problem. Need help.

Can not withdraw or unstake my coins.

https://etherscan.io/tx/0x913d14fdf605188ad51fb408b190070c830c36f000ce4e4d13b5bc0d1ede8c14

https://ibb.co/VvJbCVB
https://ibb.co/2PcStJB
https://ibb.co/ByD4M0f
https://ibb.co/4TgZLGR
https://ibb.co/qMV13LJ

Help please!",qubcoins.world and MetaMask problem. Need help. qubcoins.world and MetaMask problem. Need help. Can not withdraw or unstake my coins. https://etherscan.io/tx/0x913d14fdf605188ad51fb408b190070c830c36f000ce4e4d13b5bc0d1ede8c14 https://ibb.co/VvJbCVB https://ibb.co/2PcStJB https://ibb.co/ByD4M0f https://ibb.co/4TgZLGR https://ibb.co/qMV13LJ Help please!
231479,231479,257426,https://api.github.com/repos/PESData/awardFindR/issues/11,0.0,2021-01-20T04:31:20Z,CONTRIBUTOR,https://api.github.com/repos/PESData/awardFindR,ophil searches break at deduplication because of missing id,"```
> data <- awardFindR(keywords=""qualitative"", sources = c(""ophil""), from = ""2011-01-01"")

Grabbing url: https://www.openphilanthropy.org/giving/grants?keys=""qualitative""
Error in `[<-.data.frame`(`*tmp*`, awards$id == duplicates$id[n], , value = list( : 
  missing values are not allowed in subscripted assignments of data frames

```","ophil searches break at deduplication because of missing id ``` > data <- awardFindR(keywords=""qualitative"", sources = c(""ophil""), from = ""2011-01-01"") Grabbing url: https://www.openphilanthropy.org/giving/grants?keys=""qualitative"" Error in `[<-.data.frame`(`*tmp*`, awards$id == duplicates$id[n], , value = list( : missing values are not allowed in subscripted assignments of data frames ```"
14179,14179,15789,https://api.github.com/repos/pucherot/Pi.Alert/issues/26,1.0,2021-01-14T08:04:09Z,NONE,https://api.github.com/repos/pucherot/Pi.Alert,"Remember ""Show XXX entries"" dropdown value or change default to larger than 10","My preferred view (for this and PiHole) is always ""show 100 entries"" so I know I'm seeing all entries in the result table below and never see pagination. PiAlert doesn't seem to remember this chosen value when navigating through different PiAlert URL's or on initial load. 

Can this value be remembered or a larger default (eg. 100) be used? ","Remember ""Show XXX entries"" dropdown value or change default to larger than 10 My preferred view (for this and PiHole) is always ""show 100 entries"" so I know I'm seeing all entries in the result table below and never see pagination. PiAlert doesn't seem to remember this chosen value when navigating through different PiAlert URL's or on initial load. Can this value be remembered or a larger default (eg. 100) be used? "
619197,619197,688112,https://api.github.com/repos/SpoonLabs/sorald/issues/346,1.0,2021-01-28T14:41:47Z,COLLABORATOR,https://api.github.com/repos/SpoonLabs/sorald,Optimize the GreedyBestFitScanner,"It currently scans the entire model, while in reality it only needs to scan the compilation units in which we've detected violations.","Optimize the GreedyBestFitScanner It currently scans the entire model, while in reality it only needs to scan the compilation units in which we've detected violations."
746036,746036,229797,https://api.github.com/repos/libsdl-org/SDL/issues/3889,0.0,2021-02-11T02:11:00Z,COLLABORATOR,https://api.github.com/repos/libsdl-org/SDL,RFC: Automatically fall back to non-udev joystick detection in Flatpak or pressure-vessel container,"
# This bug report was migrated from our old Bugzilla tracker.

These attachments are available in the static archive:

* [joystick: Don't use udev in Flatpak or pressure-vessel container (0001-joystick-Don-t-use-udev-in-Flatpak-or-pressure-vesse.patch, text/plain, 2020-11-19 17:43:39 +0000, 1959 bytes)](https://bugzilla.libsdl.org/attachment.cgi?id=4530)

**Reported in version:** HG 2.1
**Reported for operating system, platform:** Linux, x86_64

# Comments on the original bug report:

On 2020-11-19 17:42:55 +0000, Simon McVittie wrote:

> Another follow-up for Bug # 5337.
> 
> We can't expect udev change-notification to work reliably in containers, for the reasons discussed on Bug # 5337.
> 
> Flatpak provides an official way to detect that you're inside a Flatpak container (test whether the file /.flatpak-info exists), so perhaps it would make sense for SDL to move to the inotify code path automatically in that case?
> 
> Similarly, Steam's pressure-vessel container tool, as used for the Steam Linux Runtime containers, can be detected by probing /run/pressure-vessel.

On 2020-11-19 17:43:39 +0000, Simon McVittie wrote:

> Created attachment 4530
> joystick: Don't use udev in Flatpak or pressure-vessel container
> 
> 
> Flatpak[1] and pressure-vessel[2] are known to use user namespaces,
> therefore udev event notification via netlink won't work reliably.
> Both frameworks provide a filesystem API that libraries can use to
> detect them. Do that, and automatically fall back from udev-based
> device discovery to the inotify-based fallback introduced in Bug # 5337.
> 
> [1] <https://flatpak.org/>
> [2] <https://gitlab.steamos.cloud/steamrt/steam-runtime-tools/-/tree/master/pressure-vessel>

On 2020-11-24 05:11:10 +0000, Sam Lantinga wrote:

> Looks good, thanks!
> https://hg.libsdl.org/SDL/rev/5a0fa9b6d4bf

","RFC: Automatically fall back to non-udev joystick detection in Flatpak or pressure-vessel container # This bug report was migrated from our old Bugzilla tracker. These attachments are available in the static archive: * [joystick: Don't use udev in Flatpak or pressure-vessel container (0001-joystick-Don-t-use-udev-in-Flatpak-or-pressure-vesse.patch, text/plain, 2020-11-19 17:43:39 +0000, 1959 bytes)](https://bugzilla.libsdl.org/attachment.cgi?id=4530) **Reported in version:** HG 2.1 **Reported for operating system, platform:** Linux, x86_64 # Comments on the original bug report: On 2020-11-19 17:42:55 +0000, Simon McVittie wrote: > Another follow-up for Bug # 5337. > > We can't expect udev change-notification to work reliably in containers, for the reasons discussed on Bug # 5337. > > Flatpak provides an official way to detect that you're inside a Flatpak container (test whether the file /.flatpak-info exists), so perhaps it would make sense for SDL to move to the inotify code path automatically in that case? > > Similarly, Steam's pressure-vessel container tool, as used for the Steam Linux Runtime containers, can be detected by probing /run/pressure-vessel. On 2020-11-19 17:43:39 +0000, Simon McVittie wrote: > Created attachment 4530 > joystick: Don't use udev in Flatpak or pressure-vessel container > > > Flatpak[1] and pressure-vessel[2] are known to use user namespaces, > therefore udev event notification via netlink won't work reliably. > Both frameworks provide a filesystem API that libraries can use to > detect them. Do that, and automatically fall back from udev-based > device discovery to the inotify-based fallback introduced in Bug # 5337. > > [1] <https://flatpak.org/> > [2] <https://gitlab.steamos.cloud/steamrt/steam-runtime-tools/-/tree/master/pressure-vessel> On 2020-11-24 05:11:10 +0000, Sam Lantinga wrote: > Looks good, thanks! > https://hg.libsdl.org/SDL/rev/5a0fa9b6d4bf "
738862,738862,159082,https://api.github.com/repos/TesseractCoding/NeoAlgo-Docs/issues/1,1.0,2021-04-06T04:43:26Z,MEMBER,https://api.github.com/repos/TesseractCoding/NeoAlgo-Docs,Setup Docusaurus,"This Issue would require: 

- Setting up Docusaurus 
- Deploying the site over Vercel 
- Adding some basic information about NeoAlgo",Setup Docusaurus This Issue would require: - Setting up Docusaurus - Deploying the site over Vercel - Adding some basic information about NeoAlgo
19318,19318,21499,https://api.github.com/repos/Kyrodan/KeeAnywhere/issues/212,0.0,2020-02-10T20:31:59Z,NONE,https://api.github.com/repos/Kyrodan/KeeAnywhere,Can't connect to google drive account,"Hello,

Thx for your plugin. 
I have a database on my google drive.

I installed in Keepass 2.44 portable and KeeAnywhere 1.60 on windows 10.
When I tried to configure my account. After google login and password. I have this screen in the pop up.
![Keeanywhere](https://user-images.githubusercontent.com/6814217/74187386-b704ec00-4c4c-11ea-85af-f3e15547b146.PNG)


I tried to connect to my google account with my firefox, chrome and internet explorer on the same laptop with success.

Searching on the web, I found several explanations but not solutions for me.
The user agent could be bad for google. 
Or my account would be too much secure.
https://support.google.com/accounts/thread/22873505?hl=en
But I already tried to enable ""less security apps"" settings without success.","Can't connect to google drive account Hello, Thx for your plugin. I have a database on my google drive. I installed in Keepass 2.44 portable and KeeAnywhere 1.60 on windows 10. When I tried to configure my account. After google login and password. I have this screen in the pop up. ![Keeanywhere](https://user-images.githubusercontent.com/6814217/74187386-b704ec00-4c4c-11ea-85af-f3e15547b146.PNG) I tried to connect to my google account with my firefox, chrome and internet explorer on the same laptop with success. Searching on the web, I found several explanations but not solutions for me. The user agent could be bad for google. Or my account would be too much secure. https://support.google.com/accounts/thread/22873505?hl=en But I already tried to enable ""less security apps"" settings without success."
5761,5761,6431,https://api.github.com/repos/Aaltuj/VxFormGenerator/issues/18,0.0,2021-02-01T10:41:53Z,NONE,https://api.github.com/repos/Aaltuj/VxFormGenerator,Handle Nullable<bool> in the InputCheckbox component,"Hi,
I'm getting this error:
```
blazor.server.js:19 [2021-02-01T10:38:34.738Z] Error: System.InvalidOperationException: Unable to set property 'ValueChanged' on object of type 'VxFormGenerator.Form.Components.Bootstrap.BootstrapInputCheckbox'. The error was: Unable to cast object of type 'Microsoft.AspNetCore.Components.EventCallback`1[System.Nullable`1[System.Boolean]]' to type 'Microsoft.AspNetCore.Components.EventCallback`1[System.Boolean]'.
 ---> System.InvalidCastException: Unable to cast object of type 'Microsoft.AspNetCore.Components.EventCallback`1[System.Nullable`1[System.Boolean]]' to type 'Microsoft.AspNetCore.Components.EventCallback`1[System.Boolean]'.
   at Microsoft.AspNetCore.Components.Reflection.PropertySetter.CallPropertySetter[TTarget,TValue](Action`2 setter, Object target, Object value)
   at Microsoft.AspNetCore.Components.Reflection.ComponentProperties.<SetProperties>g__SetProperty|2_0(Object target, PropertySetter writer, String parameterName, Object value)
   --- End of inner exception stack trace ---
   at Microsoft.AspNetCore.Components.Reflection.ComponentProperties.<SetProperties>g__SetProperty|2_0(Object target, PropertySetter writer, String parameterName, Object value)
   at Microsoft.AspNetCore.Components.Reflection.ComponentProperties.SetProperties(ParameterView& parameters, Object target)
   at Microsoft.AspNetCore.Components.Forms.InputBase`1.SetParametersAsync(ParameterView parameters)
   at Microsoft.AspNetCore.Components.Rendering.ComponentState.SetDirectParameters(ParameterView parameters)
   at Microsoft.AspNetCore.Components.RenderTree.RenderTreeDiffBuilder.InitializeNewComponentFrame(DiffContext& diffContext, Int32 frameIndex)
   at Microsoft.AspNetCore.Components.RenderTree.RenderTreeDiffBuilder.InitializeNewSubtree(DiffContext& diffContext, Int32 frameIndex)
   at Microsoft.AspNetCore.Components.RenderTree.RenderTreeDiffBuilder.InsertNewFrame(DiffContext& diffContext, Int32 newFrameIndex)
   at Microsoft.AspNetCore.Components.RenderTree.RenderTreeDiffBuilder.AppendDiffEntriesForRange(DiffContext& diffContext, Int32 oldStartIndex, Int32 oldEndIndexExcl, Int32 newStartIndex, Int32 newEndIndexExcl)
   at Microsoft.AspNetCore.Components.RenderTree.RenderTreeDiffBuilder.ComputeDiff(Renderer renderer, RenderBatchBuilder batchBuilder, Int32 componentId, ArrayRange`1 oldTree, ArrayRange`1 newTree)
   at Microsoft.AspNetCore.Components.Rendering.ComponentState.RenderIntoBatch(RenderBatchBuilder batchBuilder, RenderFragment renderFragment)
   at Microsoft.AspNetCore.Components.RenderTree.Renderer.RenderInExistingBatch(RenderQueueEntry renderQueueEntry)
   at Microsoft.AspNetCore.Components.RenderTree.Renderer.ProcessRenderQueue()
```

Class property 
`public bool? IsBundle { get; set; }`","Handle Nullable<bool> in the InputCheckbox component Hi, I'm getting this error: ``` blazor.server.js:19 [2021-02-01T10:38:34.738Z] Error: System.InvalidOperationException: Unable to set property 'ValueChanged' on object of type 'VxFormGenerator.Form.Components.Bootstrap.BootstrapInputCheckbox'. The error was: Unable to cast object of type 'Microsoft.AspNetCore.Components.EventCallback`1[System.Nullable`1[System.Boolean]]' to type 'Microsoft.AspNetCore.Components.EventCallback`1[System.Boolean]'. ---> System.InvalidCastException: Unable to cast object of type 'Microsoft.AspNetCore.Components.EventCallback`1[System.Nullable`1[System.Boolean]]' to type 'Microsoft.AspNetCore.Components.EventCallback`1[System.Boolean]'. at Microsoft.AspNetCore.Components.Reflection.PropertySetter.CallPropertySetter[TTarget,TValue](Action`2 setter, Object target, Object value) at Microsoft.AspNetCore.Components.Reflection.ComponentProperties.<SetProperties>g__SetProperty|2_0(Object target, PropertySetter writer, String parameterName, Object value) --- End of inner exception stack trace --- at Microsoft.AspNetCore.Components.Reflection.ComponentProperties.<SetProperties>g__SetProperty|2_0(Object target, PropertySetter writer, String parameterName, Object value) at Microsoft.AspNetCore.Components.Reflection.ComponentProperties.SetProperties(ParameterView& parameters, Object target) at Microsoft.AspNetCore.Components.Forms.InputBase`1.SetParametersAsync(ParameterView parameters) at Microsoft.AspNetCore.Components.Rendering.ComponentState.SetDirectParameters(ParameterView parameters) at Microsoft.AspNetCore.Components.RenderTree.RenderTreeDiffBuilder.InitializeNewComponentFrame(DiffContext& diffContext, Int32 frameIndex) at Microsoft.AspNetCore.Components.RenderTree.RenderTreeDiffBuilder.InitializeNewSubtree(DiffContext& diffContext, Int32 frameIndex) at Microsoft.AspNetCore.Components.RenderTree.RenderTreeDiffBuilder.InsertNewFrame(DiffContext& diffContext, Int32 newFrameIndex) at Microsoft.AspNetCore.Components.RenderTree.RenderTreeDiffBuilder.AppendDiffEntriesForRange(DiffContext& diffContext, Int32 oldStartIndex, Int32 oldEndIndexExcl, Int32 newStartIndex, Int32 newEndIndexExcl) at Microsoft.AspNetCore.Components.RenderTree.RenderTreeDiffBuilder.ComputeDiff(Renderer renderer, RenderBatchBuilder batchBuilder, Int32 componentId, ArrayRange`1 oldTree, ArrayRange`1 newTree) at Microsoft.AspNetCore.Components.Rendering.ComponentState.RenderIntoBatch(RenderBatchBuilder batchBuilder, RenderFragment renderFragment) at Microsoft.AspNetCore.Components.RenderTree.Renderer.RenderInExistingBatch(RenderQueueEntry renderQueueEntry) at Microsoft.AspNetCore.Components.RenderTree.Renderer.ProcessRenderQueue() ``` Class property `public bool? IsBundle { get; set; }`"
449367,449367,499443,https://api.github.com/repos/nvim-treesitter/nvim-treesitter/issues/1067,0.0,2021-03-20T14:36:40Z,NONE,https://api.github.com/repos/nvim-treesitter/nvim-treesitter,Error executing lua Vim:E484: Can't open file lock file.json,"<!--
Before reporting please do :

Update your neovim version to latest _master_.
Update your plugin to latest version.
Run `TSUpdate`.
//-->

Everytime I open `nvim`, `nvim-treesitter` fails to compile. I can't run neither of the commands: `TSUpdate` `TSUpdate all` etc. receive the following error message:

```
E5108: Error executing lua Vim:E484: Can't open file /Users/rbanyi/.local/share/nvim/site/pack/packer/start/nvim-treesitter/lock
file.json

```

```
   19 health#nvim_treesitter#check
   18 ========================================================================
   17 ## Installation
   16   - OK: `tree-sitter` found  0.19.4(parser generator, used for :TSInstallFromGrammar)
   15   - OK: `git` executable found.
   14   - OK: `cc` executable found.
   13
   12 ## Parser/Features H L F I
   11   - supercollider     
   10   - glimmer         . . .
    9   - json              
    8   - yaml              

```

```tree-sitter 0.19.4```

```
NVIM v0.5.0-dev+1161-gfa4ee00fa
Build type: Release
LuaJIT 2.1.0-beta3
Compilation: /Applications/Xcode_12.4.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc -U_FORTIFY_SOURCE -D_FORTIFY_SOURCE=1 -O2 -DNDEBUG -Wall -Wextra -pedantic -Wno-unused-parameter -Wstrict-prototypes -std=gnu99 -Wshadow -Wconversion -Wmissing-prototypes -Wimplicit-fallthrough -Wvla -fstack-protector-strong -fno-common -fdiagnostics-color=always -DINCLUDE_GENERATED_DECLARATIONS -D_GNU_SOURCE -DNVIM_MSGPACK_HAS_FLOAT32 -DNVIM_UNIBI_HAS_VAR_FROM -DMIN_LOG_LEVEL=3 -I/Users/runner/work/neovim/neovim/build/config -I/Users/runner/work/neovim/neovim/src -I/Users/runner/work/neovim/neovim/.deps/usr/include -I/Applications/Xcode_12.4.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX11.1.sdk/usr/include -I/Library/Frameworks/Mono.framework/Headers -I/Users/runner/work/neovim/neovim/build/src/nvim/auto -I/Users/runner/work/neovim/neovim/build/include
Compiled by runner@Mac-1616216137969.local

Features: +acl +iconv +tui
See "":help feature-compile""

   system vimrc file: ""$VIM/sysinit.vim""
  fall-back for $VIM: ""/share/nvim""

Run :checkhealth for more info

```","Error executing lua Vim:E484: Can't open file lock file.json <!-- Before reporting please do : Update your neovim version to latest _master_. Update your plugin to latest version. Run `TSUpdate`. //--> Everytime I open `nvim`, `nvim-treesitter` fails to compile. I can't run neither of the commands: `TSUpdate` `TSUpdate all` etc. receive the following error message: ``` E5108: Error executing lua Vim:E484: Can't open file /Users/rbanyi/.local/share/nvim/site/pack/packer/start/nvim-treesitter/lock file.json ``` ``` 19 health#nvim_treesitter#check 18 ======================================================================== 17 ## Installation 16 - OK: `tree-sitter` found 0.19.4(parser generator, used for :TSInstallFromGrammar) 15 - OK: `git` executable found. 14 - OK: `cc` executable found. 13 12 ## Parser/Features H L F I 11 - supercollider     10 - glimmer  . . . 9 - json     8 - yaml     ``` ```tree-sitter 0.19.4``` ``` NVIM v0.5.0-dev+1161-gfa4ee00fa Build type: Release LuaJIT 2.1.0-beta3 Compilation: /Applications/Xcode_12.4.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc -U_FORTIFY_SOURCE -D_FORTIFY_SOURCE=1 -O2 -DNDEBUG -Wall -Wextra -pedantic -Wno-unused-parameter -Wstrict-prototypes -std=gnu99 -Wshadow -Wconversion -Wmissing-prototypes -Wimplicit-fallthrough -Wvla -fstack-protector-strong -fno-common -fdiagnostics-color=always -DINCLUDE_GENERATED_DECLARATIONS -D_GNU_SOURCE -DNVIM_MSGPACK_HAS_FLOAT32 -DNVIM_UNIBI_HAS_VAR_FROM -DMIN_LOG_LEVEL=3 -I/Users/runner/work/neovim/neovim/build/config -I/Users/runner/work/neovim/neovim/src -I/Users/runner/work/neovim/neovim/.deps/usr/include -I/Applications/Xcode_12.4.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX11.1.sdk/usr/include -I/Library/Frameworks/Mono.framework/Headers -I/Users/runner/work/neovim/neovim/build/src/nvim/auto -I/Users/runner/work/neovim/neovim/build/include Compiled by runner@Mac-1616216137969.local Features: +acl +iconv +tui See "":help feature-compile"" system vimrc file: ""$VIM/sysinit.vim"" fall-back for $VIM: ""/share/nvim"" Run :checkhealth for more info ```"
563722,563722,626472,https://api.github.com/repos/idea-statica/iom-examples/issues/42,0.0,2020-09-22T07:05:33Z,NONE,https://api.github.com/repos/idea-statica/iom-examples,[BUG] Cuts are wrong in BeamData,"Export the attached [iom99.zip](https://github.com/idea-statica/iom-examples/files/5259606/iom99.zip)  iom to Idea Connection.


Cuts applied on `Stiffening member 1` are wrong unless I am not understanding correctly how to apply cuts.
This is the connection I am exporting to Idea Connection:

![image](https://user-images.githubusercontent.com/66376954/93850693-e71a7000-fcae-11ea-9b55-ae6c547dbf5f.png)

And in Idea Connection I get:

* Without activating cuts on `BeamData `(just as starting point):
![image](https://user-images.githubusercontent.com/66376954/93850756-10d39700-fcaf-11ea-9fe5-6db6954417c6.png)

* Activating just `Cut 3`:
![image](https://user-images.githubusercontent.com/66376954/93852314-1c748d00-fcb2-11ea-8df1-c235d39a4ba0.png)
I tried to change dZ=-1 and there were no changes.

* With all cuts:
![image](https://user-images.githubusercontent.com/66376954/93850929-74f65b00-fcaf-11ea-8593-7745e1294c61.png)

What is not clear for me is the way that a cut plane is applied. I mean, what is the part of the object that is removed by the plane?
The one on the side of the normal vector, or the opposite side of the normal vector?
For example, in the following example, if I apply a cut plane to the yellow `BeamData`, what is the expected result, A or B?
I would expect A, that is, the removed portion is the one on the normal vector side.
![image](https://user-images.githubusercontent.com/66376954/93852856-16cb7700-fcb3-11ea-9b9d-e5ece801b345.png)

Best regards

 - OS: Windows 10 Pro-1909
 - IOM Version 20.0,104.57553
 - IdeaStatiCa Version 20.0,104.57553","[BUG] Cuts are wrong in BeamData Export the attached [iom99.zip](https://github.com/idea-statica/iom-examples/files/5259606/iom99.zip) iom to Idea Connection. Cuts applied on `Stiffening member 1` are wrong unless I am not understanding correctly how to apply cuts. This is the connection I am exporting to Idea Connection: ![image](https://user-images.githubusercontent.com/66376954/93850693-e71a7000-fcae-11ea-9b55-ae6c547dbf5f.png) And in Idea Connection I get: * Without activating cuts on `BeamData `(just as starting point): ![image](https://user-images.githubusercontent.com/66376954/93850756-10d39700-fcaf-11ea-9fe5-6db6954417c6.png) * Activating just `Cut 3`: ![image](https://user-images.githubusercontent.com/66376954/93852314-1c748d00-fcb2-11ea-8df1-c235d39a4ba0.png) I tried to change dZ=-1 and there were no changes. * With all cuts: ![image](https://user-images.githubusercontent.com/66376954/93850929-74f65b00-fcaf-11ea-8593-7745e1294c61.png) What is not clear for me is the way that a cut plane is applied. I mean, what is the part of the object that is removed by the plane? The one on the side of the normal vector, or the opposite side of the normal vector? For example, in the following example, if I apply a cut plane to the yellow `BeamData`, what is the expected result, A or B? I would expect A, that is, the removed portion is the one on the normal vector side. ![image](https://user-images.githubusercontent.com/66376954/93852856-16cb7700-fcb3-11ea-9b9d-e5ece801b345.png) Best regards - OS: Windows 10 Pro-1909 - IOM Version 20.0,104.57553 - IdeaStatiCa Version 20.0,104.57553"
445183,445183,494823,https://api.github.com/repos/eggplantiny/m-journal-nuxt/issues/39,0.0,2021-01-06T10:16:24Z,OWNER,https://api.github.com/repos/eggplantiny/m-journal-nuxt,[Frontend] Back Button 愿 媛諛,"- [x] Dialog 媛 대ㅼ  Back Button 쇰 リ린
- [x] Diary 댁 Back 대 留湲
",[Frontend] Back Button 愿 媛諛 - [x] Dialog 媛 대ㅼ  Back Button 쇰 リ린 - [x] Diary 댁 Back 대 留湲 
307018,307018,341361,https://api.github.com/repos/aizatazhar/can-i-eat-this/issues/4,1.0,2020-12-04T11:09:16Z,OWNER,https://api.github.com/repos/aizatazhar/can-i-eat-this,Implement manual searching for ingredients,,Implement manual searching for ingredients 
4258,4258,4746,https://api.github.com/repos/PumpkinSeed/sqlfuzz/issues/19,1.0,2021-03-15T08:40:54Z,OWNER,https://api.github.com/repos/PumpkinSeed/sqlfuzz,Foreign key constrains and multiple table options,"Feature request from reddit:

_Does it support and understand constraints when given multiple tables?
And does it handle FK? Eg; If my T2 has a FK to T1 and i fuzz them in the correct order will the tool figure it out?_

So make the tool understand constrains even if the one table passed and add the feature to handle more tables with comma separated.",Foreign key constrains and multiple table options Feature request from reddit: _Does it support and understand constraints when given multiple tables? And does it handle FK? Eg; If my T2 has a FK to T1 and i fuzz them in the correct order will the tool figure it out?_ So make the tool understand constrains even if the one table passed and add the feature to handle more tables with comma separated.
414250,414250,460453,https://api.github.com/repos/nss-day-cohort-46/rare-rest-rare-api-determined-dugora/issues/12,1.0,2021-05-17T14:27:48Z,NONE,https://api.github.com/repos/nss-day-cohort-46/rare-rest-rare-api-determined-dugora,Basic Authentication,"As the Rare product owner, I would like all users to be authenticated in order to perform any activity in the system so that the system will be able to record which user created post, comment, etc... and EVENTUALLY restrict access to certain features based on user and user type permissions.

**Given** an unauthenticated user is in the Rare application  
**When** they click any link  
**Then** they should be prompted to login using their email address  

**Given** an unauthenticated user is viewing the login form  
**When** they enter an email address that matches an existing User Profile  
**Then** they should be authenticated into the system  
**And** they should be directed to the application home page  

**Given** an unauthenticated user is viewing the login form  
**When** they enter an email address that does not match an existing User Profile  
**Then** an error message should be displayed  
**And** the user should be given another change to enter a valid email address  

> **NOTE:** For the time being it is acceptable to treat all users as `admin` users. There is a future story about enforcing user permissions.




","Basic Authentication As the Rare product owner, I would like all users to be authenticated in order to perform any activity in the system so that the system will be able to record which user created post, comment, etc... and EVENTUALLY restrict access to certain features based on user and user type permissions. **Given** an unauthenticated user is in the Rare application **When** they click any link **Then** they should be prompted to login using their email address **Given** an unauthenticated user is viewing the login form **When** they enter an email address that matches an existing User Profile **Then** they should be authenticated into the system **And** they should be directed to the application home page **Given** an unauthenticated user is viewing the login form **When** they enter an email address that does not match an existing User Profile **Then** an error message should be displayed **And** the user should be given another change to enter a valid email address > **NOTE:** For the time being it is acceptable to treat all users as `admin` users. There is a future story about enforcing user permissions. "
672041,672041,746928,https://api.github.com/repos/polyaxon/polyaxon/issues/1206,1.0,2021-01-13T09:06:11Z,CONTRIBUTOR,https://api.github.com/repos/polyaxon/polyaxon,Use read-only editor for viewing Polyaxonfiles in the dashboard,"### Discussion

```
Hi all, I have a feature request! would it make sense to use the editor similar to the one used in the job submission for showing the content and compiled specification

Hi ykovic, can you explain what do you mean by this feature. is this a bug?  also what version are you currently using? thanks

Some files are large, we use several fields in the environment section, some files have too many inputs and outputs. I like the features of the other editor as it allows to fold sections.

I use 1.3.x, not sure if this was merged in v1.4 or v1.5, but it was the same read-only editor since v1.1
```
","Use read-only editor for viewing Polyaxonfiles in the dashboard ### Discussion ``` Hi all, I have a feature request! would it make sense to use the editor similar to the one used in the job submission for showing the content and compiled specification Hi ykovic, can you explain what do you mean by this feature. is this a bug? also what version are you currently using? thanks Some files are large, we use several fields in the environment section, some files have too many inputs and outputs. I like the features of the other editor as it allows to fold sections. I use 1.3.x, not sure if this was merged in v1.4 or v1.5, but it was the same read-only editor since v1.1 ``` "
582739,582739,647555,https://api.github.com/repos/sixteenmillimeter/spiritsInObjects/issues/28,1.0,2021-05-01T16:40:59Z,OWNER,https://api.github.com/repos/sixteenmillimeter/spiritsInObjects,Remove confirm dialog from sonifyStart,Do not ask each time the sonification process is run,Remove confirm dialog from sonifyStart Do not ask each time the sonification process is run
95594,95594,106251,https://api.github.com/repos/Daimler/sechub/issues/440,1.0,2020-11-04T17:58:07Z,CONTRIBUTOR,https://api.github.com/repos/Daimler/sechub,WebScan Introduce Wait Setting For Login Script,"At the time of writing, it is not possible to define a wait parameter for every step in a script which is used to login into a more complex website. Waiting for some time is important, as the page could take a while to load the entire Document Object Model (DOM). 

It should be possible to provide the wait parameter for every step in the form login script. The value of the `wait` parameter should be in milliseconds (ms).

An example on how the `wait` parameter could look like is shown below.
~~~
{
  ""apiVersion"": ""1.0"",
  ""server"": ""https://sechub.example.com"",
  ""project"": ""sechub"",
  ""webScan"": {
      ""uris"": [""https://target.example.org""],
      ""login"": {
            ""url"": ""https://target.example.org/login"",
            ""form"": {
                ""script"": [
                    {
                        ""step"": ""username"", 
                        ""selector"": ""#username"",
                        ""value"": ""my_user"",
                        ""wait"": 2000
                    },
                    {
                        ""step"": ""password"",
                        ""selector"": ""#password"",
                        ""value"": ""top4xSecret!""
                    },
                    {
                        ""step"": ""click"",
                        ""selector"": ""#loginButton""
                    }
                ]
            }
        }
  }
}
~~~

---
<sup>Jeremias Eppler <jeremias.eppler@daimler.com>, Daimler TSS GmbH, [imprint](https://github.com/Daimler/daimler-foss/blob/master/LEGAL_IMPRINT.md)</sup>","WebScan Introduce Wait Setting For Login Script At the time of writing, it is not possible to define a wait parameter for every step in a script which is used to login into a more complex website. Waiting for some time is important, as the page could take a while to load the entire Document Object Model (DOM). It should be possible to provide the wait parameter for every step in the form login script. The value of the `wait` parameter should be in milliseconds (ms). An example on how the `wait` parameter could look like is shown below. ~~~ { ""apiVersion"": ""1.0"", ""server"": ""https://sechub.example.com"", ""project"": ""sechub"", ""webScan"": { ""uris"": [""https://target.example.org""], ""login"": { ""url"": ""https://target.example.org/login"", ""form"": { ""script"": [ { ""step"": ""username"", ""selector"": ""#username"", ""value"": ""my_user"", ""wait"": 2000 }, { ""step"": ""password"", ""selector"": ""#password"", ""value"": ""top4xSecret!"" }, { ""step"": ""click"", ""selector"": ""#loginButton"" } ] } } } } ~~~ --- <sup>Jeremias Eppler <jeremias.eppler@daimler.com>, Daimler TSS GmbH, [imprint](https://github.com/Daimler/daimler-foss/blob/master/LEGAL_IMPRINT.md)</sup>"
801011,801011,779210,https://api.github.com/repos/mild-blue/covid-vaxx/issues/158,0.0,2021-03-15T14:54:58Z,MEMBER,https://api.github.com/repos/mild-blue/covid-vaxx,Patients data persisted in session storage even after registration-done,"* zaregistroval jsem pacienta a dostal se na done stranku
* pak jsem sel zpet na registraci / nebo jsem reloadnul stranku na registraci a data o pacientovi v session storage zustaly
![image](https://user-images.githubusercontent.com/14038818/111172759-61fd7d00-85a6-11eb-991b-cb94c66ab30d.png)

* je treba je po zobrazeni/prvnim precteni smazat ze session storage, aby k nim nikdo jiz nemel pristup","Patients data persisted in session storage even after registration-done * zaregistroval jsem pacienta a dostal se na done stranku * pak jsem sel zpet na registraci / nebo jsem reloadnul stranku na registraci a data o pacientovi v session storage zustaly ![image](https://user-images.githubusercontent.com/14038818/111172759-61fd7d00-85a6-11eb-991b-cb94c66ab30d.png) * je treba je po zobrazeni/prvnim precteni smazat ze session storage, aby k nim nikdo jiz nemel pristup"
5869,5869,6549,https://api.github.com/repos/AllTheMods/ATM-6/issues/1086,0.0,2021-02-17T12:59:44Z,NONE,https://api.github.com/repos/AllTheMods/ATM-6,Server appear offline,"<!--- Issues without a pack version will be closed without comment. -->
**Describe the bug**
The server can be join without issues, but is appearing offline in the server list. When someone hit refresh or connect, i can see this error in the console :
`[Netty Epoll Server IO #1/ERROR] [net.minecraft.network.NettyPacketEncoder/]: io.netty.handler.codec.EncoderException: String too big (was 36195 bytes encoded, max 32767)`

I think it's since the 1.5.2 update, because it worked before that. But i'm not 100% sure","Server appear offline <!--- Issues without a pack version will be closed without comment. --> **Describe the bug** The server can be join without issues, but is appearing offline in the server list. When someone hit refresh or connect, i can see this error in the console : `[Netty Epoll Server IO #1/ERROR] [net.minecraft.network.NettyPacketEncoder/]: io.netty.handler.codec.EncoderException: String too big (was 36195 bytes encoded, max 32767)` I think it's since the 1.5.2 update, because it worked before that. But i'm not 100% sure"
